- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Exploring Supervised Deep Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索监督深度学习
- en: '*Chapters 2* to *6* explored the core workhorse behind **deep learning** (**DL**)
    technology and included some minimal technical implementations for easy digestion.
    It is important to understand the intricacies of how different **neural networks**
    (**NNs**) work. One reason is that when things go wrong with any NN model, you
    can identify what the root cause is and mitigate it. Those chapters are also important
    to showcase how flexible DL architectures are to solve different types of real-world
    problems. But what are the problems exactly? Also, how should we train a DL model
    effectively in varying situations?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*第二章*到*第六章*探讨了**深度学习**（**DL**）技术背后的核心工作原理，并包括了一些最基础的技术实现，便于理解。理解不同**神经网络**（**NNs**）工作原理的细节是很重要的。一个原因是，当任何神经网络模型出现问题时，你能够识别出根本原因并加以解决。这些章节也很重要，因为它们展示了深度学习架构如何灵活地解决各种现实问题。但这些问题到底是什么？我们应该如何在不同情况下有效训练深度学习模型？'
- en: 'In this chapter, we will attempt to answer the preceding two points specifically
    for supervised deep learning, but we will leave answering the same questions for
    unsupervised deep learning for the next chapter. This chapter will cover the following
    topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将尝试具体回答前面提到的两个问题，针对监督深度学习进行讨论，但针对无监督深度学习的问题会留到下一章。本章将涵盖以下主题：
- en: Exploring supervised use cases and problem types
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索监督学习的应用场景和问题类型
- en: Implementing neural network layers for foundational problem types
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现神经网络层以解决基础问题类型
- en: Training supervised deep learning models effectively
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效训练监督深度学习模型
- en: Exploring general techniques to realize and improve supervised deep learning-based
    solutions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索实现和改进基于监督深度学习的解决方案的一般技术
- en: Breaking down the multitask paradigm in supervised deep learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析监督深度学习中的多任务范式
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter includes some practical implementations in the Python programming
    language. To complete it, you will need to have a computer with the following
    libraries installed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括一些Python编程语言中的实际实现。为了完成这些内容，你需要一台安装了以下库的计算机：
- en: '`pytorch`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytorch`'
- en: '`catalyst==22.04`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`catalyst==22.04`'
- en: '`numpy`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`'
- en: '`scikit-learn`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scikit-learn`'
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_8](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_8).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到本章的代码文件，链接：[https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_8](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_8)。
- en: Exploring supervised use cases and problem types
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索监督学习的应用场景和问题类型
- en: 'Supervised learning requireslabeled data. Labels, targets, and ground truth
    all refer to the same thing. The provided labels essentially supervise the learning
    process of the **machine learning** (**ML**) model and provide the feedback needed
    for a DL model to generate gradients and update itself. Labels can exist in many
    different forms. They are **continuous numerical format**, **categorical format**,
    **text format**, **multiple categorical formats**, **image format**, **video format**,
    **audio format**, and **multiple target formats**. All of these are then categorized
    as either of the following supervised problem types:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习需要标签数据。标签、目标和真实值指的都是同一件事。提供的标签本质上监督着**机器学习**（**ML**）模型的学习过程，并为深度学习（DL）模型生成梯度和更新自身提供反馈。标签可以以多种形式存在，包括**连续数值格式**、**类别格式**、**文本格式**、**多类别格式**、**图像格式**、**视频格式**、**音频格式**以及**多目标格式**。所有这些都可以被归类为以下监督问题类型之一：
- en: '**Binary classification**: This is when the target has categorical data with
    only two unique values.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二分类**：这是指目标只有两个唯一值的分类数据。'
- en: '**Multiclassification**: This is when the target has categorical data with
    more than two unique values.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多分类**：这是指目标具有多个唯一值的分类数据。'
- en: '**Regression**: This is when the target has continuous numerical data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：这是指目标具有连续的数值数据。'
- en: '**Multi-target/problem**:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多目标/问题**：'
- en: '**Multilabel**: This is when the target has more than one binary associated
    with a single data row.'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多标签**：这是指目标与单一数据行关联的多个二进制标签。'
- en: '**Multi-regression**: This is when the target has more than one regression
    target associated with a single data row.'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多回归**：这是指目标与单一数据行关联的多个回归目标。'
- en: '**Multiple problems**: Either multiple targets associated with a single data
    row in a single dataset or a chain of problems that is sequential in nature and
    multiple models are learned through different datasets.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supervised representation learning**: This can be in many forms, and the
    main goal is to learn meaningful data representations given input data. The results
    of learned representation can subsequently be utilized for many purposes, including
    **transfer learning** (**TL**), and to realize recommendation systems.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The definition of these problems may be hard to understand by itself. To create
    a better understanding of the different problems, we will check out an extensive
    set of use cases that can take advantage of DL technologies. Given the problems
    specified previously, the following table lists their use cases:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '| **Problem Types** | **Supervised Deep Learning Model** **Use Cases** |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Binary classification |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: Gender prediction of babies with ultrasound imagery
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semiconductor chip-quality rejection prediction in manufacturing with image
    data
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using email data that can contain text, images, documents, audio, or any data
    to predict spam
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '| Multiclassification |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: Document data topic classification
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hate/toxic speech or text classification
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General image object classification
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment prediction of text or speech data
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '| Regression |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '**Click-through rate** (**CTR**) prediction of advertisements with image or
    text or both'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human age prediction with a facial input image
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting GPS location from an image
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '| Multi-target |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '**Text topic classification**: Multilabel, multiple topics can exist in a single
    text data row.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image object detection**: A multiple-target problem consisting of multiple
    regression targets and multiclass classification. First, with an image bounding
    box as multiple regression targets, a single *x* and *y* numerical coordinate,
    and its width and height as the two extra targets forms a rectangular-shaped bounding
    box. Next, the bounding box will be used to extract a cropped image for multiclassification
    purposes to predict the type of object.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image segmentation**: A kind of multilabel problem, where every pixel will
    serve as binary targets.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '| Supervised representation learning |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: Face feature representation for face recognition.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Audio representation for speaker recognition using **K-Nearest** **Neighbors**
    (**KNN**).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Representing categories with their own representative feature vectors. This
    can be achieved with a method called **categorical embeddings,** which is an NN
    layer type that holds a feature vector for each category in a categorical feature
    column. It is learnable and serves as a lookup table. The method can reduce the
    feature dimensions of high-cardinality categorical data when compared to basic
    one-hot-encoding but still maintain around the same performance.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.1 – A table of DL problem use cases
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification, multiclass classification, and regression problems are
    rather straightforward to approach. Multi-target types, however, pose complicated
    setups and require more architecting to be done depending on the nature of the
    problem. Multi-target tasks also can be straightforward, such as multilabel or
    multi-regression problems. This task falls into the bigger envelope of multitask
    solutions and will be discussed further in the *Exploring general techniques to
    realize and improve DL-based solutions* section of this chapter.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类、多类分类和回归问题的处理相对直接。然而，多目标类型的问题设置较为复杂，需根据问题的性质进行更多的架构设计。多目标任务也可以是直接的，例如多标签或多回归问题。该任务属于更广泛的多任务解决方案的范畴，将在本章的*探索实现和改进基于深度学习的解决方案*部分进一步讨论。
- en: Next, we will implement the basic NN layers of realizing the foundational problems,
    which include binary classification, multiclass classification, and regression
    problems.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将实现实现基础问题的基本神经网络层，包括二分类、多类分类和回归问题。
- en: Implementing neural network layers for foundational problem types
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现基础问题类型的神经网络层
- en: In *Chapters 2* to *7*, although many types of NN layers were introduced, the
    core layers for the problem types were either not used or not explained. Here,
    we will go through each of them for clarity and intuition.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第2章*到*第7章*中，尽管介绍了许多类型的神经网络层，但针对问题类型的核心层要么没有使用，要么没有解释。这里，我们将逐一讲解每一层，以便更清晰地理解和掌握直觉。
- en: Implementing the binary classification layer
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现二分类层
- en: Binary means two options for categorical data. Note that this does not necessarily
    mean a strict rule for the categories to be true or false nor positive or negative
    in the raw data. The two options can be in any format possible in terms of raw
    data, in strings, numbers, or symbols. However, note that NNs can always only
    produce numerical outputs. This means that the target itself has to be represented
    numerically, for which the optimal numbers are the binary values of zero and one.
    This means that the data column to be used as a target for training with only
    two unique values must go through preprocessing to map itself into zero or one.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类意味着类别数据有两个选项。请注意，这并不一定意味着原始数据中的类别严格表示为真或假，或者是正面或负面。两个选项可以是原始数据中的任何格式，可以是字符串、数字或符号。然而，请注意，神经网络始终只能产生数值输出。这意味着目标本身必须以数值形式表示，其中最优的数值是零和一的二进制值。这意味着，用作训练目标的数据列如果只有两个唯一值，必须经过预处理，将其映射为零或一。
- en: Generally, there are two ways to define binary outputs in NNs. The first is
    to use a linear layer with a size of one. The second method is to use a linear
    layer with a size of two. There is no significant difference between the two in
    terms of task-quality metrics, but method one takes slightly less space for storage
    and memory, so feel free to always use that version. The outputs from method 1
    will be constrained to values between `0` and `1` by using a sigmoid layer. For
    method 2, the outputs need to be passed into a softmax layer so that the probabilities
    for the two outputs will add up to one. Both methods usually can be optimized
    using **cross-entropy**. Cross-entropy is also known as **log loss**. Log loss
    measures the difference between predicted probabilities and true labels using
    a logarithmic scale. This scale penalizes incorrect predictions more heavily,
    emphasizing the importance of a model’s ability to assign high probabilities to
    the correct class and low probabilities to the incorrect class.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在神经网络中有两种方式来定义二进制输出。第一种是使用一个大小为一的线性层。第二种方法是使用一个大小为二的线性层。就任务质量指标而言，这两者之间没有显著区别，但方法一在存储和内存方面稍微占用更少的空间，因此可以随时使用这种版本。方法一的输出将通过使用sigmoid层约束在`0`到`1`之间。对于方法二，输出需要传入softmax层，这样两个输出的概率加起来为一。两种方法通常都可以通过**交叉熵**来优化。交叉熵也被称为**对数损失**。对数损失通过对数刻度衡量预测概率与真实标签之间的差异。该刻度对错误预测进行更严厉的惩罚，强调模型能够为正确类别分配高概率，为错误类别分配低概率的重要性。
- en: 'Translating the layer from method one into actual `pytorch` code will look
    like the following using the `nn` module from `torch`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将方法一中的层转换为实际的`pytorch`代码，将使用`torch`中的`nn`模块，代码如下所示：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we will implement the multiclass classification layer.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将实现多类分类层。
- en: Implementing the multiclass classification layer
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现多类分类层
- en: '`pytorch` code for a 100-class multiclass classification problem with 10 logits
    will look like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 针对一个有 10 个 logits 的 100 类多分类问题，`pytorch` 代码如下所示：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Another sub-problem of multiclass classification is when the classes are ordinal.
    This sub-problem and task is called ordinal classification. This means that the
    classes have an incremental relationship with each other. A plain multiclass classification
    layer strategy represents ordinal classes sub-optimally as the classes in the
    multiclass are considered to have an equal relationship with each other. A good
    strategy here to add the information of ordinal classes is to utilize a technique
    based on the multilabel classification task, which is a multiple-binary classification
    task.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 多分类问题的另一个子问题是类别具有顺序关系时。这种子问题和任务被称为顺序分类。这意味着类别之间存在增量关系。一个普通的多分类层策略会将顺序类别表现为不理想，因为多分类中的类别被认为彼此之间具有平等关系。这里的一种好策略是使用基于多标签分类任务的技术，这是一个多二分类任务。
- en: 'Let’s say that we have five ordinal classes represented as numerical numbers
    from 1 to 5 for simplicity. In reality, this could be represented by any categorical
    data. In an NN, five binary classification heads would be used for this case where
    the classes will be assigned to the respective head in an ascending ordered manner.
    The raw predictions from this NN will be consumed in a way where the final predicted
    ordinal class will be derived from the position of the furthest consecutive positive
    binary prediction. Once there is a negative prediction, the rest of the prediction
    heads on the right will then be ignored. *Figure 8**.1* depicts this strategy
    by simulating the output predictions of the five binary classification heads:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有五个顺序类别，简化起见，将其表示为从 1 到 5 的数字。在实际应用中，这可以通过任何类别数据来表示。在神经网络中，这种情况将使用五个二分类头，其中类别将按升序依次分配到各个头。这个神经网络的原始预测将以一种方式被使用，最终预测的顺序类别将从最远连续的正二分类预测的位置中得出。一旦出现负预测，右侧其余的预测头将被忽略。*图
    8.1* 通过模拟五个二分类头的输出预测来描述这一策略：
- en: '![Figure 8.1 – Ordinal classification processing strategy using the output
    predictions of the five binary classification heads](img/B18187_08_001.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 使用五个二分类头的输出预测进行顺序分类处理策略](img/B18187_08_001.jpg)'
- en: Figure 8.1 – Ordinal classification processing strategy using the output predictions
    of the five binary classification heads
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 使用五个二分类头的输出预测进行顺序分类处理策略
- en: The learning process will be, as usual, using the cross-entropy loss for multiple
    binary targets. Additionally, the performance at every epoch can be monitored
    using robust metrics that don’t depend on probabilities such as recall or precision.
    The ordinal encoding method allows the model to learn that the targets have an
    ordinal relationship.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 学习过程将如常使用交叉熵损失来处理多个二进制目标。此外，可以使用不依赖于概率的强健指标（如召回率或精度）来监控每个 epoch 的性能。顺序编码方法使得模型能够学习目标之间的顺序关系。
- en: Next, we will dive into the implementation of a regression layer.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨回归层的实现。
- en: Implementing a regression layer
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现回归层
- en: '`pytorch` code will look like the following using the `nn` module from `torch`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytorch` 代码将如下所示，使用来自 `torch` 的 `nn` 模块：'
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`0` and `1`. Coupled with the scaling of target values, the bounds can then
    be enforced in the NN by using the sigmoid layer, which similarly scales activation
    values between `0` and `1`. During the inference stage, the predicted values can
    then be mapped into actual values by descaling values between `0` and `1` into
    the known minimum and maximum boundaries specified earlier.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`0` 和 `1`。结合目标值的缩放，边界可以通过使用 sigmoid 层在神经网络中强制执行，该层也会将激活值缩放到 `0` 和 `1` 之间。在推理阶段，预测值可以通过将
    `0` 和 `1` 之间的缩放值映射到先前指定的已知最小和最大边界，从而恢复为实际值。'
- en: The unbounded method allows for some form of generalization by allowing extrapolation,
    and the bounded method allows the addition of informed bias to the NN. Both methods
    have their own benefits and disadvantages, and thus the choice of approach needs
    to be evaluated on a case-by-case basis.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 无界方法通过允许外推来实现某种形式的泛化，而有界方法则允许在神经网络中加入已知的偏置。两种方法各有优缺点，因此选择哪种方法需要根据具体情况进行评估。
- en: Next, we will dive into the implementation of representation layers.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨表示层的实现。
- en: Implementing representation layers
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现表示层
- en: Most methods focus on the interactions between architectures for different data
    modalities or the training methods that optimize the represented features. These
    are topics we will dive into further in the next topic after this. One key layer
    type that truly represents the representation layer is the embedding layer. Embeddings
    are a type of layer structure that maps categorical data types into learnable
    vectors. Through this layer, each category will be able to learn a representation
    that is able to perform well against the specified target. The method can be used
    for converting text word tokens into more representative features or plainly as
    a replacement for one-hot encoding. Categorical embeddings make it possible to
    automate the feature engineering process for categorical data types. One-hot encoding
    produces an encoding that enforces the same distance between all the categories
    to every other category. Categorical embedding, however, allows for the possibility
    of obtaining an appropriate distance based on its interactions with the target
    variable and with other data if any extra data exists.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数方法侧重于不同数据模态的架构之间的相互作用或优化所代表特征的训练方法。这些是我们将在接下来的话题中进一步深入讨论的主题。一个真正代表表示层的关键层类型是嵌入层。嵌入层是一种将分类数据类型映射为可学习向量的层结构。通过这一层，每个类别将能够学习到一个能够与指定目标很好地对应的表示。该方法可用于将文本单词标记转换为更具代表性的特征，或者简单地作为独热编码的替代。分类嵌入使得对分类数据类型进行特征工程处理变得可能。独热编码生成的编码强制所有类别之间的距离相同。然而，分类嵌入允许根据其与目标变量及其他数据（如果有额外数据存在）的交互来获得适当的距离。
- en: However, categorical embeddings are also not a silver bullet for all ML use
    cases, even if they are decoupled from an actual NN model after training and just
    act as a featurizer. They can sometimes perform better against one-hot-encoding
    in general and, vice versa, can happen other times to perform worse against one-hot-encoding.
    The method still remains a key method to experiment with for any dataset with
    categorical data as input.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，分类嵌入并不是所有机器学习用例的灵丹妙药，即使它们在训练后与实际神经网络模型分离，只起到特征化作用。它们有时可以在总体上表现得比独热编码更好，反之亦然，有时可能会比独热编码表现得更差。这种方法仍然是对任何包含分类数据输入的数据集进行实验的关键方法。
- en: Training supervised deep learning models effectively
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有效训练监督深度学习模型
- en: 'In [*Chapter 1*](B18187_01.xhtml#_idTextAnchor015), *Deep Learning Life Cycle*,
    it is emphasized that ML projects have a cyclical life cycle. In other words,
    a lot of iterative processes are carried out in the course of the project’s lifetime.
    To train supervised deep learning models effectively, there are a lot of general
    directions that should be taken based on different conditions, but the one that
    absolutely stands out across every problem is proper tooling. The tooling is more
    commonly known as `pytorch` or `keras` with `tensorflow`, ease of deployment,
    ease of model comparisons using different metrics, ease of model tuning, good
    visualization of model training monitoring, and, finally, good feedback about
    the progress (this can be sent through messages and notifications for alerts).
    If no advanced tools that truly simplify the entire process are at your disposal,
    you can focus on the important bits of making a model work well instead of dealing
    with infrastructure issues such as coordinating the saving of models into different
    folders like **DataRobot**, a paid-for tool, then open sourced tools such as MLflow,
    Kubeflow, or Metaflow will be the next-best alternative. Once the tool of choice
    is picked, carrying out training in DL models will be a breeze. We will be using
    MLflow as an example tool to demonstrate some effective methods for DL model training
    in the following steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第1章*](B18187_01.xhtml#_idTextAnchor015)，*深度学习生命周期*中，强调了ML项目具有循环生命周期。换句话说，在项目生命周期中进行了大量迭代过程。为了有效训练监督学习深度模型，基于不同条件应采取许多通用方向，但绝对突出于各种问题的一点是适当的工具化。工具化更常见地称为`pytorch`或`keras`与`tensorflow`，部署的便利性，使用不同度量标准比较模型的便利性，模型调优的便利性，良好的模型训练监视可视化，以及关于进展的良好反馈（可以通过消息和通知发送警报）。如果没有真正简化整个流程的先进工具，您可以专注于使模型运行良好的重要部分，而不必处理基础设施问题，如协调将模型保存到不同文件夹中的**DataRobot**，一种付费工具，然后开源工具如MLflow、Kubeflow或Metaflow将成为下一个最佳替代方案。一旦选择了工具，进行DL模型训练将变得轻松。我们将使用MLflow作为示例工具，在以下步骤中展示DL模型训练的一些有效方法：
- en: Data preparation
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据准备
- en: Configuring and tuning DL hyperparameters
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置和调优DL超参数
- en: Executing, visualizing, tracking, and comparing experiments
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行、可视化、跟踪和比较实验
- en: Additionally, we will explore some extra tips when building a model before ending
    this topic.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将探讨在结束此主题之前构建模型时的一些额外提示。
- en: Let’s explore each in detail.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细探讨每一个。
- en: Preparing the data for DL training
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为DL训练准备数据
- en: 'Data is the core of any ML model. Data ultimately determines the achievable
    model performance, the quality of the final trained model, and the validity of
    the final trained model. In [*Chapter 1*](B18187_01.xhtml#_idTextAnchor015), *Deep
    Learning Life Cycle*, we explored what it takes for a dataset setup to be DL-worthy,
    along with the qualities needed when acquiring data, coupled with **exploratory
    data analysis** (**EDA**) to verify causality and validity. The general idea there
    was to identify and add extra features and data modalities that have causal effects
    toward the desired target. In this section, we will cover more in-depth essential
    steps that convert the data into a DL trainable state listed here:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何ML模型的核心。数据最终决定了可达到的模型性能、最终训练模型的质量以及最终训练模型的有效性。在[*第1章*](B18187_01.xhtml#_idTextAnchor015)，*深度学习生命周期*中，我们探讨了使数据集设置具备DL价值的条件，以及在获取数据时所需的特性，结合**探索性数据分析**（**EDA**）来验证因果关系和有效性。那里的一般想法是识别和添加对所需目标具有因果影响的额外特征和数据形式。在本节中，我们将更深入地讨论将数据转换为DL可训练状态的重要步骤，列在这里：
- en: Data partitioning
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据分区
- en: Data representation
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据表示
- en: Data augmentation
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据增强
- en: Partitioning the data for DL training
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为DL训练分区数据
- en: 'The first step we will cover is data partitioning. Having a good data-partitioning
    strategy for training, validating, and testing your model is essential for a good-performing
    model. The training partition will be the partition that will strictly be used
    for training. The validation partition will be the partition that will strictly
    be used for validating a model during training. In DL, a **validation partition**
    is often used as a guide to signal when to stop training or extract the best-performing
    weights using external data out of the training data. Since the validation data
    will affect the learning process of the model and add some bias that will cause
    overfitting toward the nature of the out-of-training validation data, a testing
    partition will be the final partition that will be used to verify the generalizability
    of the trained model. The testing partition is also known as the holdout partition.
    To be extra safe in preventing overfitting and to ensure the generalizability
    of the model, the validation partition can also be used exclusively to be validated
    only once after the model is trained instead of being used for validation at every
    epoch. This strategy, however, requires that a smaller internal validation partition
    is created from the original training partition. The following figure depicts
    the two different strategies:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍数据分区的步骤。对于训练、验证和测试模型来说，有一个良好的数据分区策略对于获得良好的性能模型至关重要。训练分区将严格用于训练。验证分区将在训练过程中严格用于验证模型。在深度学习中，**验证分区**通常被用作指导信号，用来指示何时停止训练或提取出使用外部数据训练的最佳性能权重。由于验证数据会影响模型的学习过程，并且会向着训练外验证数据的性质导致过拟合的方向发展，测试分区将是最终用于验证经过训练模型的泛化能力的分区。测试分区也被称为保留分区。为了更安全地防止过拟合，并确保模型的泛化能力，验证分区也可以专门用于在模型训练后仅验证一次，而不是在每个时期都用于验证。然而，这种策略要求从原始训练分区创建一个较小的内部验证分区。以下图展示了两种不同的策略：
- en: '![Figure 8.2 – Two different cross-validation data-partitioning strategies](img/B18187_08_002.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – 两种不同的交叉验证数据分区策略](img/B18187_08_002.jpg)'
- en: Figure 8.2 – Two different cross-validation data-partitioning strategies
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 两种不同的交叉验证数据分区策略
- en: 'This process of partitioning the data is called **cross-validation**. The preceding
    figure shows simple cross-validation strategies with only a single partitioning
    setting. This might create issues where the model’s performance metrics reported
    are biased toward a specific resulting partitioning setting. The resulting partitioning
    may have some inherent distribution or nature that allowed results to perform
    particularly well or badly toward it. When that happens, having mismatched expectations
    of performance during the deployment stage will create more operational issues.
    To safely remove the possibility of such bias, **k-fold cross-validation** is
    typically used to report a more comprehensive validation score that could better
    reflect the performance of the model in the wild. To perform this partitioning
    method, a single testing set is removed from the original dataset, and validation
    scores are averaged across different ordered *k* cross-validation training and
    validation partitions. This is better visualized in *Figure 8**.3*:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据分区的过程被称为**交叉验证**。前面的图展示了只有单个分区设置的简单交叉验证策略。这可能会导致模型的性能指标报告对特定的结果分区设置产生偏倚。结果的分区可能具有某种固有的分布或性质，使得结果在特定分区设置中表现特别好或特别差。当发生这种情况时，在部署阶段对性能期望不匹配会造成更多操作问题。为了安全地消除这种偏差可能性，通常使用**k
    折交叉验证**来报告更全面的验证分数，这些分数可以更好地反映模型在实际情况下的性能。为了执行这种分区方法，需要从原始数据集中移除单一测试集，并且在不同顺序的*k*交叉验证训练和验证分区上平均验证分数。这在*图
    8**.3*中更好地可视化：
- en: '![Figure 8.3 – K-fold cross-validation as a strategy to eliminate metric reporting
    bias](img/B18187_08_003.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – K 折交叉验证作为消除度量报告偏差的策略](img/B18187_08_003.jpg)'
- en: Figure 8.3 – K-fold cross-validation as a strategy to eliminate metric reporting
    bias
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – K 折交叉验证作为消除度量报告偏差的策略
- en: Finally, for testing performance reporting and deployment purposes, the model
    either gets retrained on the training and validation dataset combined or the model
    trained in the first fold is extracted for deployment purposes.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了测试性能报告和部署目的，模型可以重新在训练和验证数据集合并或从第一折训练的模型中提取出用于部署目的。
- en: Recall that stratified partitioning is a recommended strategy to split your
    data into the three mentioned partitions. This means that the data will be approximately
    evenly separated into three partitions based on the label associated with the
    dataset. This ensures that no labels get left out in any partition, which could
    potentially cause misinformation. Take a simple case of binary classification
    where the dataset is randomly partitioned into three partitions of training, validation,
    and testing with prespecified sizes. Since each data row was randomly placed into
    one of the three partitions, there is a probability the partitions will only contain
    one label from the two binary labels. Since the validation or testing partition
    is usually assigned with smaller data sizes, they have more potential to face
    this issue. Let’s say the model is mistakenly trained to predict only a single
    label. If the label is exactly the label that exclusively exists in the validation
    and testing of ML learning practitioners, we will mistakenly think the model is
    doing extremely well, but in fact, it is useless. You never know when you will
    be unlucky when doing full random partitioning, so use stratified random partitioning
    whenever you can!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，分层划分是将数据划分为三个提到的部分的推荐策略。这意味着数据将根据与数据集关联的标签大致平均地分为三部分。这确保了任何一个分区中都不会遗漏标签，从而避免了可能导致误信息的情况。以二分类为例，假设数据集被随机划分为训练集、验证集和测试集三个部分，且每个部分的大小是预先指定的。由于每行数据是随机地分配到这三部分中的一个，因此存在分区中可能只包含二分类标签中的一个标签的概率。由于验证集或测试集通常被分配较小的数据量，它们面临这种问题的潜在概率更大。假设模型错误地只训练来预测单一标签。如果该标签正好是只在验证集和测试集里存在的标签，机器学习的从业者可能会误以为模型表现极好，实际上，它是无用的。在进行完全随机划分时，你永远不知道什么时候会不走运，所以只要可能，尽量使用分层随机划分！
- en: The data-partitioning strategy described here builds only a single model that
    will be utilized during inference mode in model deployment. This strategy is the
    standard option when the inference runtime of the final model setup is a concern
    and having a faster model is more important than having small improvements in
    the accuracy metrics. When it is okay to trade runtime for some accuracy performance,
    an alternative strategy called **k-fold cross-validation ensemble** can be used.
    This is a method that is widely advocated in many ML competitions, especially
    in the ones hosted on Kaggle. The method uses the *k*-fold cross-validation described
    previously but actually uses *k* models trained during cross-validation and performs
    an ensemble of the k model’s predictions. An ensembling method called blending
    aggregates predictions of models and almost always improves the accuracy metrics
    from a single model. This process can be thought of as a method that leverages
    the best ideas and expertise of each *k* model, making the final outcome better
    as an aggregate. This aggregate can be as simple as an average or median of the
    *k* predictions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的数据划分策略只构建了一个模型，这个模型将在模型部署的推理模式下使用。当最终模型部署的推理运行时长是一个关注点时，这种策略是标准选择，尤其是在需要更快的模型，而不是稍微提高精度指标时。如果可以接受牺牲一些精度性能来换取运行时长，那么可以使用一种叫做**k折交叉验证集成**的替代策略。这是许多机器学习竞赛中广泛推荐的方法，尤其是在Kaggle上举办的竞赛中。该方法使用之前描述的*k*折交叉验证，但实际上使用在交叉验证过程中训练的*k*个模型，并对这*k*个模型的预测结果进行集成。一种叫做混合的方法将模型的预测结果聚合，几乎总是能提高单个模型的精度指标。这个过程可以被看作是一种利用每个*k*模型的最佳思路和专业知识的方法，从而使最终结果作为一个整体更好。这个整体可以是*k*个预测的平均值或中位数。
- en: A final tip before moving on to the next method is to always remember to make
    sure partitions match when comparing models between experiments. Misinformation
    often happens in the field when two models are separately developed using different
    data-partitioning strategies and data partitions. Even when one of the models
    achieves a significant performance advantage over the other, it does not mean
    anything and will not amount to any meaningful comparisons.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一个方法之前，有一个小贴士：在比较不同实验中的模型时，始终记得确保数据划分一致。误信息通常发生在当两个模型在不同的数据划分策略和数据划分下分别开发时。即使其中一个模型在性能上明显优于另一个，也并不意味着什么，这种比较没有任何意义。
- en: Next, we will dive into the data representation component for different data
    modalities.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨不同数据模态的数据表示组件。
- en: Representing different data modalities for training DL models
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为训练深度学习模型表示不同的数据模态
- en: So far, we have brushed over the utilization of numerical, categorical, text,
    audio, image, and video modalities. These are the most common modalities utilized
    across multiple industries. Representing different data modalities is a complicated
    topic as, in addition to the common modalities, there are actually a lot of rare
    data modalities out there. Examples of rare modalities are chemical formulas (a
    special structured form of textual data), document data (another special form
    of textual data with complex positional information), and graph data. In this
    section, we will only discuss the representation of the common unstructured modalities
    here to ensure the relevancy of content to our readers. Both numerical and categorical
    data are considered structured data and are have been covered properly in previous
    sections. Let’s now start with the text data modality.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Representing text data for supervised deep learning
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Text data representation in general has improved tremendously over the years.
    The following list shows a few relevant methods:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '**Term frequency-inverse document frequency (TF-IDF) with N-grams**: The term
    here is implemented with N-grams. An N-gram is an adjacent sequence of *n* textual
    characters. N-grams are produced by a method called tokenization. The tokenization
    can be a representation as low level as single characters, or it can be a higher-level
    representation such as words. Once represented as N-grams, TF-IDF is computed
    using the following formula.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TF-IDF = term frequency x inverse document frequency
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '**Term frequency** is simply the count array of a single row. **Inverse document
    frequency** is computed through the following formula:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: IDF = log( number of text samples   ______________________________________    number
    of documents containing the term for each term )
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: The representation is an efficient and lightweight way to extract useful information
    from text, where words that are rare have higher values and more frequent words
    such as “the” and “and” will be suppressed. Outputs of TF-IDF can be directly
    fed into a simple **multilayer perceptron** (**MLP**) or any ML model to produce
    a predictive model. In simpler use cases, this representation will be enough to
    achieve a good metric performance. However, in more complex use cases that require
    the decoding of complex interactions that can happen with the different compositions
    of text and labels, it will underperform.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**Word/token embeddings**: Word embeddings can be trained from scratch or pre-trained
    from a bigger dataset. Pre-trained embeddings can be pre-trained in either a supervised
    fashion or an unsupervised fashion, usually on a larger dataset. However, the
    embedding method suffers from the issue of token mismatch during the training,
    evaluation, and testing stages. This means that it is required to perform a lot
    of tinkering with the way the specific text token is preprocessed before looking
    up to the embeddings table. This occurrence is known as **out of vocabulary**
    (**OOV**) during the evaluation and testing stages. In the training stage, different
    variations of the same word will have their own meaning, which is inefficient
    in terms of learning and resource-space utilization. In practice, methods such
    as stemming, lemmatization, lowercasing, and known word-to-word replacements are
    applied to mitigate OOV, but the problem won’t be mitigated completely. These
    word embeddings can be paired with either **recurrent NNs** (**RNNs**) or transformers.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subword-based tokenization**: This family of methods attempts to solve the
    token mismatch issue and the large vocabulary size of tokens. *Subword* might
    sound unintuitive, as we as humans use full words to perceive the meaning of text.
    This family of algorithms only performs subword tokenization when the word can’t
    be identified or is considered to be rare. For common words, they will remain
    full word tokens. Examples of such methods include **byte-pair encoding** (**BPE**),
    **WordPiece**, and **SentencePiece**. We will go through these methods briefly
    as a simple guide:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BPE tokenization**: BPE treats the text as characters and groups up the most
    common consecutive characters iteratively during training. The number of iterations
    determines when the training iterations to group up the most common characters
    should be stopped. This formulation allows for rare words to remain as subword
    tokens and common words to be grouped up into a single token. This representation
    is notably used by **generative pre-trained transformer** (**GPT**) models. However,
    this representation faces an issue where there will be multiple ways to encode
    a particular word.'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**WordPiece**: WordPiece improves upon BPE by utilizing a language model to
    choose the most likely pair of tokens to group up. This enforces a kind of intelligent
    choice when deciding the way to encode a particular word. This algorithm is utilized
    by **Bidirectional Encoder Representations from Transformers** (**BERT**) and
    **Efficiently Learning an Encoder that Classifies Token Replacements** **Accurately**
    (**ELECTRA**).'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SentencePiece**: SentencePiece is a method that optimizes the tokens generated
    by base tokenizers such as BPE. It uses a couple of components, such as using
    a form of Unicode text conversion to ensure no language-dependent logic exists
    and using a method called subword regularization that performs a form of subword
    token group augmentation (probabilistically and randomly choose a single sample
    from the top-k predicted subword token to group up using language models) to solve
    multiple representation issues. This algorithm is used by XLNet and **A Lite BERT**
    (**ALBERT**) most notably.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Text data are represented as tokens for DL. This also means that there will
    be strict limits to the number of tokens so that the NN model can be initialized
    with the right parameters. Pick a token size limit that is reasonable for your
    use case based on what’s needed to get a good model performance. Since the size
    limit will affect model size, be sure to make sure the model size doesn’t get
    so big that it overshoots your inference runtime requirements.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: In terms of missing text data, which can happen in real-world use cases with
    multimodal data, using an empty string is the most natural way to work as an imputation
    method. Under the hood, these models would usually use all zeros to represent
    the text array.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve briefly covered supervised text data representations, let’s discover
    supervised audio data representations next.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Representing audio data for DL
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Audio data is time-series data with one or two arrays of values where each value
    in the array represents a single piece of audio data at a specific timestamp.
    Audio data can be either represented as a simple normalized form from the original
    raw data, represented as something called a spectrogram, which is a two-dimensional
    data, or as **Mel-frequency cepstral** **coefficients** (**MFCCs**).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: A spectrogram is the resulting output of a process called `wav2vec 2.0`, which
    is a type of transformer.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'The STFT process has hyperparameters that can affect the resulting representation.
    The following list summarizes these hyperparameters and tips on how to set it
    up properly:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling rate**: This specifies the samples per second (Hertz/Hz) parameter
    that will be used before applying STFT. Audio data might be recorded in different
    sampling rates, and to build a model, this data will be required to be unified
    to a single sampling rate through resampling algorithms. The most typically used
    value is 16,000 Hz. As this value will affect the size and runtime of the model
    given a fixed time window a model is built to handle, be sure to only increase
    it if it’s necessary in terms of metric performance.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**STFT window length**: Each window size will be responsible for the data for
    a fixed duration and specific position. Each window will produce a single value
    at the same time window for a range of frequencies. The typical value of this
    parameter is 4096 or 2048\. Configure this based on the prediction resolution
    you require for your use case if there is a strict requirement there. This parameter
    will also affect the model size.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Window stride**: This is similar to a convolutional layer filter stride and
    does not have many significant tuning methods. Using a small percentage of the
    window length, such as 10%, should be a good enough setting.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Whether to use Mel scaling**: A **Mel scale** is a logarithmic transformation
    of the audio signal’s frequency. Fundamentally, it is a transformation to mimic
    how humans perceive audio. It makes higher-frequency changes matter less and lower-frequency
    changes matter more. Use this when it involves some form of human judgment to
    improve the metric performance.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As for empty audio rows, imputing them with a single pre-generated random noise
    audio or using an array of zeros with the same length should work well in multimodal
    datasets.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve briefly covered supervised audio data representations, let’s
    discover supervised image and video data representations next.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Representing image and video data for DL
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Image data doesn’t require a lot of introduction here as we have gone through
    a few tutorials using them directly. The key is to perform some sort of normalization
    before feeding it to NN models such as CNNs, and the NN will extract great representations.
    Transformers have also been making tight competition with CNNs in image-based
    tasks and can be used to both extract representative features and predict directly
    on the task. One thing to note is that unless the resolution of the image is crucial
    in identifying certain patterns, it is usually much more effective as a model
    to utilize a smaller image resolution. One might not be able to visually certain
    patterns when the resolution of the image is smaller, but a computer would still
    be able to. The resolution of the image affects the runtime of the training, the
    runtime of the model in production, and sometimes the model size, as for transformers,
    so make sure this is done conservatively.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Video data, however, is an extended form of image data where a number of images
    are aligned sequentially to form a video. This means that video data is a form
    of sequential data just like text without absolute timestamp information. Each
    sequential image is known as a **frame**. Video can have a variety of frame rates.
    Commonly, this would be in rates of 24, 30, or 48 **frames per second** (**FPS**)
    but can generally be any number. For **computer vision** (**CV**) use cases, make
    sure to set a low FPS so that the processing load can be reduced depending on
    the use case. For example, the use case of lip reading has lower FPS requirements
    than for asking a model to identify whether a person is running or not. For the
    frame resolution, the same guide for image resolution applies here. Once the video
    properties have been decided, representative features have to be learned and extracted.
    The current SoTA features are extracted through models similar to image-based
    use cases. Examples of such models are 3D CNNs and 3D transformers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: There is, however, an intersection of these two data types, which are images
    extracted through video data. For this type of image data, it is possible to reduce
    the probability of predictive models making wrong predictions. ML models are not
    perfect predictors, so whenever there is a chance to reduce incorrect predictions
    such as false positives or false negatives without compromising the true predictions,
    do consider taking it. Consider using manual image processing techniques from
    the OpenCV library to perform any preliminary steps before a model takes the image
    as input. For example, the motion detection technique in OpenCV can be used as
    a preliminary condition checker before feeding the video array to the DL model.
    Since motion is required to identify most use cases of video data, it doesn’t
    make sense to predict anything if nothing is moving. This also reduces any false
    predictions that can happen from predicting on multiple unchanged video frames.
    The motion detector in OpenCV utilizes a simple change in pixel value without
    using a probabilistic model and thus is a far more reliable indicator of motion.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered representing different data modalities, let’s move on
    to the topic of data augmentation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Augmenting the data for training better DL models
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Augmentation is widely used in DL to increase the generalization of the resulting
    trained model and increase the metric performance of the model. By accounting
    for the additional unique variations brought in by augmentation, the model would
    be able to attend to these unique variations on external data during the validation,
    testing, and inference stage. Naturally, this will also reduce any over-dependence
    on a specific pattern and any benefits that come with a sufficiently sized dataset.
    Augmentation increases the amount of training data and thus the variations of
    patterns in the training data. The process is usually done randomly and individually
    in every training iteration in memory. This makes sure there are no limitations
    to the additional data variations available for training and also removes the
    need for additional storage. However, you can’t just randomly use all the available
    types of augmentation known for a specific modality. The following list shows
    the different types of augmentation you can perform on your data:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '**Image**: Image sharpening through **Contrast Limited Adaptive Histogram Equalization**
    (**CLAHE**), hue and saturation variation, color channel shuffling, contrast variation,
    brightness variation, horizontal/vertical flip, grayscale conversion, blurring,
    image masking, mixup (weighted combination of images and their labels), cutmix
    (mixup, but only by random patches from the original image), and more. Look into
    [https://github.com/albumentations-team/albumentations](https://github.com/albumentations-team/albumentations)
    for more than 70 augmentations!'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text**: Synonym replacement, back translation (a process that translates
    a text into another language and then translates it back into the original language),
    and more.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video**: Video mixup (same as image mixup but for videos), all the same augmentation
    for images.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`librosa` library.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the type of augmentation to use requires some understanding of the
    expected environment that you will face when you deploy a model. Bad choices add
    noise to the model and might confuse the model during the training process, resulting
    in a degraded metric performance. Good choices revolve around estimating the variations
    that can realistically happen in the wild. Let’s take an example of a manufacturing
    use case where the goal is to deploy an image-based model that will predict product
    characteristics on a conveyor belt for sorting purposes using a camera sensor.
    If you can assume the camera will be fixed almost perfectly straight on the machine
    in all the setups, using image rotation augmentation likely wouldn’t be smart.
    Even if you want to use the augmentation, the rotation variation you should use
    should only be in the low end, such as below 10 degrees variation. Grayscale augmentation
    would also be unintuitive if the cameras do not provide grayscale images.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the data preparation stage of training effective models. Next,
    we will dive into the model training stage of the workflow.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Configuring and tuning DL hyperparameters
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hyperparameter configuration and tuning play a crucial role in training DL models
    effectively. They control the learning process of the model and can significantly
    impact the model’s performance, generalization, and convergence. In this section,
    we will discuss some essential hyperparameters and their impact on training DL
    models.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The most general set of impactful hyperparameters that need to be configured
    for training each NN model are its epochs, early stopping epochs, and learning
    rate. These three parameters are considered a set of parameters that together
    form a **learning schedule**. There have been a few notable learning schedules
    that focused on obtaining the best model with the least amount of time spent.
    However, they depend a lot on the initial estimation of the total number of epochs
    a model can converge with the method. Methods that depend on an estimation of
    the total number of epochs needed are fragile, and their configuration strategies
    are not easily transferable from one problem to another. Here, we will focus on
    using a validation dataset to track the number of epochs needed to achieve the
    best possible metric performance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Early stopping epochs is a parameter that controls how many epochs you want
    to keep training before you stop. This strategy means that the epochs’ hyperparameter
    can either be set to an infinite number or a very large number so that the best-performing
    model on the validation dataset can be found. Early stopping reduces the number
    of training epochs you need to spend dynamically based on the validation dataset.
    By saving the best-performing model weights on the validation dataset, when the
    model is stopped early, you will then be able to load the best-performing weights.
    The typical early stopping epoch is `10`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: As for the learning rate, there are two general directions that work consistently
    well in practice. One is to immediately start with a large learning rate such
    as `0.1` and to gradually decay the learning rate. The gradual decay of the learning
    rate can be through percentage reductions from validation score monitoring when
    it doesn’t improve after `3` to `5` epochs. The second method is to use a smaller
    learning rate as a warmup method in initializing a base weight for the NN before
    using method 1\. In the initial stage of learning, as models are initially in
    a randomized state, the learning process can be very unstable where the loss will
    seem to not follow a proper improvement trend. Using a warmup helps to initialize
    the foundation needed to make stable loss progressions. Note that if pre-trained
    weights are used to initialize the model, a warmup is usually not needed as the
    model will already be in a stable state, especially if the pre-trained weights
    are obtained from a similar dataset.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Batch size is another crucial hyperparameter in the training of DL models, as
    it determines the number of training samples used in a single update of the model’s
    weights during the optimization process. The choice of batch size can significantly
    impact the model’s training speed, memory requirements, and convergence. Smaller
    batch sizes, such as 16 or 32, provide a more accurate estimate of the gradient,
    leading to more stable convergence, but may require more training iterations and
    can be slower due to less parallelism in computation. On the other hand, larger
    batch sizes, such as 128 or 256, increase the level of parallelism, speeding up
    the training process and reducing memory requirements, but may lead to a less
    accurate gradient estimate and potentially less stable convergence. In practice,
    it’s essential to experiment with different batch sizes to find the one that provides
    the best balance between training speed and convergence stability for your specific
    problem. Additionally, modern DL frameworks often support adaptive batch size
    techniques, which can automatically adjust the batch size during training to optimize
    the learning process.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: The foundational strategy discussed here is robust and can easily obtain the
    best-performing model most of the time while sacrificing some additional training
    time. It is worth noting that regularization methods, optimizers, and different
    activation functions have been covered in [*Chapter 2*](B18187_02.xhtml#_idTextAnchor040),
    *Designing Deep Learning Architectures*, and I encourage you to refer to that
    chapter for more information on those topics.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: As much as there can be a manual strategy for the configuration of these hyperparameters,
    there will always be space to tune the hyperparameters further to optimize the
    metric performance of the model. Commonly, tuning can be executed through either
    grid search, random search, or tuning through more intelligent searching mechanisms.
    Grid search, otherwise known as brute-force searching, explores and validates
    all possible combinations of specified hyperparameter values to identify the optimal
    configuration for a given problem through cross-validation. For more intelligent
    tuning methods, refer back to [*Chapter 7*](B18187_07.xhtml#_idTextAnchor107),
    *Deep Neural Architecture Search*, for more insights on it. Additionally, as model
    evaluation metrics contribute to this hyperparameter-tuning process, we will explore
    more on this in [*Chapter 10*](B18187_10.xhtml#_idTextAnchor161), *Exploring Model*
    *Evaluation Methods*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The core of hyperparameter tuning depends on the process and workflow to iteratively
    execute, visualize, track, and compare modeling experiments, with each configuration
    being part of a modeling experiment. This brings us to the next topic, diving
    into the actual workflow of training DL models effectively.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Executing, visualizing, tracking, and comparing experiments
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to executing ML projects effectively is to iterate quickly between experiments.
    A lot of exploration is needed in any ML project, both in the initial stage of
    the project to gauge the viability of the use case, and in the later stage to
    improve the model’s performance. When this exploration process can be optimized,
    things meant to fail can fail quickly, and things that are viable can succeed
    quickly. Failure in ML projects is very common in practice. Once we acknowledge
    that and fail quickly, we can utilize the recovered time to tackle more valuable
    use cases. A good MLOps platform will help us execute, visualize, track, and compare
    experiments effectively and efficiently.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go through an example practically with the Iris dataset and an MLP using
    the MLflow MLOps platform. We will also be using the `catalyst` library, which
    is also considered to be an MLOps platform, albeit partially and mostly focused
    on providing common `pytorch` DL model training tools. Since `catalyst` provides
    most of the model versioning and model storing mechanisms, we will only utilize
    the tracking feature in MLflow. The steps for this example are as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s import all the necessary libraries:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, as we will be using the `pytorch`-based MLP, we will again set the random
    seed in `pytorch`:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The dataset we will be using for the practical implementation here is the Iris
    dataset again. The dataset consists of the petal and sepal lengths of various
    flowers with three different iris types. We will now load this dataset:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Scaling is a type of regularization method that can reduce memorization and
    reduce bias. Let’s perform a straightforward minimum and maximum scaling here:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To train a model, we need a proper cross-validation strategy to verify the
    validity and performance of the model. We will use 77% of the data for training
    and 33% for validation. Let’s prepare the data for cross-validation:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we will need to prepare the data loaders using the prepared data in `numpy`
    format for cross-validation:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Since this is a multiclass problem of three classes, we will use the cross-entropy
    loss in `pytorch`:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We will be using the `pytorch` high-level wrapper library called `catalyst`
    here. To train a model in `catalyst`, we have to define a model trainer class
    instance called a runner:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will be using an MLP in this project with an MLP constructor class that
    allows us to specify the input data size, the hidden layer configuration, and
    the output data size. The hidden layer configuration is a list of layer sizes
    that simultaneously specifies the number of layers and the layer size at each
    layer. Let’s say that we want to randomly obtain 20 different hidden layer configurations
    and find out which performs the best on the validation partition. Let’s first
    define a method that generates the configuration randomly:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, let’s define a method that will allow us to train and evaluate the different
    MLP configurations:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The trial number here plainly differentiates the different experiments. Apart
    from layer configuration, we can also configure the epochs that we want to run.
    In this method, we will create an MLP model instance based on the layer configuration
    passed in:'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We will use the `Adam` optimizer for gradient descent and set the checkpoint
    directory:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we will define the MLflow logger helper class available in `catalyst`
    to log experiments in MLflow format. In this setup, we log the mean and standard
    deviation of the training and validation log loss:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, we will start the training process that trains for the specified number
    of epochs:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As the last code step, we will loop through each randomly generated layer configuration
    and perform the training and evaluation process:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we need to start up the MLflow server service. We can do this by running
    the following command in the command line in the same directory as the directory
    that contains the introduced code:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After running this command, the same directory should contain the following
    file named `.catalyst`, which instructs `catalyst` to enable MLflow support. This
    file should have the following content:'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once the command is executed, and by opening the HTTP website link, you should
    see the screen of MLflow, as shown in *Figure 8**.4*:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 8.4 – M\uFEFFLflow interface](img/B18187_08_004.jpg)"
  id: totrans-194
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – MLflow interface
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'The interface shows a convenient way to visualize performance differences between
    different experiments while showing the utilized parameters. The numerical metric
    values can be sorted to obtain the best-performing model on the validation partition,
    as shown in the figure. The process of preparing data and training a model requires
    iterative comparisons to be made between different setups or experiments. Experiments
    can be compared more objectively with quantitative metrics with their experimentation
    parameters. When displayed visually automatically through code in an interface
    instead of plugging it manually into an Excel or Google sheet, this makes the
    process much more dependable and organized. Additionally, if you click into any
    of the experiments, you’ll be able to check out the loss curves at each epoch
    interactively, as shown in *Figure 8**.5*:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 8.5 – M\uFEFFLflow interface showing an example loss curve of the\
    \ best model](img/B18187_08_005.jpg)"
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – MLflow interface showing an example loss curve of the best model
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: While ensuring speed of iteration, it is also required to organize and track
    all artifacts you generated for your model properly. This means that you need
    to version your model, your dataset, and any key components that affect the resulting
    model output. Artifacts can be model weights, metric performance reports, performance
    plots, embedding visualization, and loss visualization plots. This task can obviously
    be done manually through manual coding. However, organizing the artifacts of models’
    built-in experiments gets messy when the number of experiments goes up. Any custom
    files, graphs, and metrics can be tied into each of these experiment records and
    viewed in the MLflow interface. Experiments here can differ by using different
    models, different datasets, different featurization methods, different hyperparameters
    of a model, or a different sample size of the same dataset. Additionally, models
    can be stored directly in MLflow’s model registry, which allows MLflow to deploy
    the model directly.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Exploring model-building tips
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This practical content serves as an example of how an MLOps platform such as
    MLflow can ease the process of building and choosing the right model programmatically
    and visually. As much as MLOps is great and helps in training models efficiently,
    there are a few things that an MLOps platform does not handle for you but are
    considered key components before a model can be properly utilized and have its
    predictions consumed. These components are listed next:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction consistency validation test**: This is a test that ensures the
    predictions made by the same trained model are consistent on the same data. A
    model’s predictions can’t be utilized if its logic is not deterministic. This
    will be discussed further in [*Chapter 10*](B18187_10.xhtml#_idTextAnchor161),
    *Exploring Model* *Evaluation Methods*.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pytorch`, this can be done globally through the following code:'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In `tensorflow` and `keras`, this can be done globally through the following
    code:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This method automatically seeds both the `random` and `numpy` libraries. These
    global settings can help to set the random seed for layers that did not explicitly
    set random number generator seeds locally.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: One last piece of advice in experimentation is to make sure a baseline is created
    at the start of the project. A baseline is the simplest version of a solution
    possible. The solution can even be a non-DL model with simple features. Having
    a baseline can help ensure that any improvements or complications you add are
    justified by metric performance monitoring. Refrain from adding complications
    for the sake of them. Remember that the value of an ML project is not how complicated
    the process is but the results that can be extracted from it.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into actual techniques that can be used to realize and improve
    a solution that utilizes DL.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Exploring general techniques to realize and improve supervised deep learning
    based solutions
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Notice that earlier in the chapter we focused on use cases based on problem
    types and not the problems themselves. Solutions in turn solve and take care of
    the problem. DL and ML in general are great solvers of issues related to staffing
    difficulties and for the automation of mundane tasks. Furthermore, ML models in
    computers can process data much quicker than an average human can, allowing a
    much quicker response time and much more efficient scaling of any process. In
    many cases, ML models can help to increase the accuracy and efficiency of processes.
    Sometimes, they improve current processes, and other times, they make previously
    unachievable processes possible. However, a single DL model may or may not be
    enough to solve the problem. Let’s take an example of a solution that *can* be
    solved sufficiently with a single DL model.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Consider the use case of using a DL model to predict the genders of babies with
    ultrasound imagery. Traditionally, a doctor would perform a visual-based gender
    analysis of the resulting ultrasound imagery of a baby in the mother’s womb in
    real time and offline before finally providing their prediction of the gender.
    Based on the amount of prior experience and knowledge, the doctor would have different
    levels of competency and accuracy in decoding the gender. Things might get more
    complicated when there are abnormalities in the baby. The probable underlying
    problem would be that experienced and capable doctors are scarce and expensive
    to hire. If we had a system that could decode the gender from the ultrasound imagery
    automatically, it would either be of good assistance to the judgment of real doctors
    or a replacement as a cheaper alternative. The same analogies can be applied to
    identifying diseases or symptoms in any advanced imaging results such as X-ray
    images.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: This example depicts a DL model as a component of a solution and a solution
    where a single DL model is enough to obtain the desired output. This is an example
    of staffing issues but not so much on the efficiency side. Note that for some
    use cases, it is required to explain in some form the reasons that drove the predictions
    that were made. In other words, you’d have to explain the decisions that were
    made by the model. To provide assistance to a doctor, pinpointing where and which
    types of patterns contributed to the decision would be more helpful than the decision
    itself, as doctors would be able to utilize the extra information to make their
    own decisions. This will be thoroughly introduced in [*Chapter 11*](B18187_11.xhtml#_idTextAnchor172),
    *Explaining Neural* *Network Predictions*.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Explanations aside, not all solutions to problems can be accomplished by a single
    ML or DL model alone. At times, DL models have to be coupled with general ML methods,
    and at others, multiple DL models have to be coupled together. In some special
    cases, intermediate data needs to be specially processed and prepared before feeding
    it to the next task in a pipeline. Creating and architecting logical pipelines
    are essential when dealing with such problems. Let’s take an example of a problem
    and solution that requires multiple datasets, multiple DL models, and constructing
    a task pipeline.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the problem of finding criminals who have just robbed a bank. By using
    CCTV cameras deployed in the city, you can use a face detection and recognition
    solution if you have identified the face of the criminals that did the robbery.
    The following figure shows an example solution task pipeline for this problem:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Task pipeline of the solution for finding criminals through
    CCTV cameras](img/B18187_08_006.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Task pipeline of the solution for finding criminals through CCTV
    cameras
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Face detection is an image-object-detection process where there is an image
    bounding box regressor and a binary classifier that predicts whether the bounding
    box is a face or not. The representative facial features extraction utilizes a
    DL model that can be trained using supervised representation learning methods
    that are trained against the goal of optimizing the discriminative effects of
    facial features against the facial features of different persons. Next, a separate
    task is needed to build the database of criminal facial features that will be
    passed into the KNN ML algorithm to find the matched facial ID based on queried
    facial features obtained from CCTV cameras deployed in the city. This solution
    shows the need to break a solution into multiple components in order to obtain
    the final result of finding the criminals.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: The preceding example is part of a larger paradigm called multitask learning
    and multitask problems. The multitask paradigm is a set of topics that allows
    for greater advancement in the ML space, not only for DL but definitely much more
    achievable through DL, due to its inherent flexibility. In the next topic, we
    will dive into the multitask paradigm.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down the multitask paradigm in supervised deep learning
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Multitask is a paradigm that covers a wide spectrum of tasks that involves
    the execution of ML models on multiple problems coupled with their respective
    datasets to achieve a goal. This paradigm is usually built based on two reasons:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: To achieve better predictive performance and generalization.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To break down complicated goals into smaller tasks that are directly solvable
    using separate ML models. This reiterates the point made in the previous topic.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s dive into four multitask techniques, starting with multitask pipelines.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Multitask pipelines
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This variation of multitask systems revolves around realizing solutions that
    can’t be directly solved by using a single ML model. Breaking down highly complicated
    tasks into smaller tasks can allow solutions to be made with multiple ML models
    handling different smaller tasks. These tasks can be sequential or parallel in
    their paths and generally form a **directed acyclic graph** (**DAG**)-like pipeline,
    similar to the example shown in *Figure 8**.6*.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: However, this does not mean that the tasks should exclusively be ML models.
    Problems for different industries and businesses can be in many forms, and being
    flexible in assigning components needed to produce a solution is key to deriving
    value from ML technology. For example, if human supervision is needed to accomplish
    a certain task after breaking down the larger task, do not hesitate to utilize
    it along with ML models to achieve value. Let’s go through another use case that
    utilizes multitask pipelines to create a solution, which is **recommendation systems**.
    First, we need to perform either supervised or unsupervised representation learning
    for feature extraction. Second, using the features extracted, create a database
    used to match extracted query features. Third, obtain the top-k closest data from
    the database and apply a regression model to predict the rank of the top-k data
    for fine-tuned e-tuned high-performance ranking.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will discover another paradigm of multitasking, called **TL**.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: TL
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TL is a technique that involves using what was learned from one task in another
    task. The core reasons can be one of the following:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the metric performance.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decreasing the required number of epochs needed for the network to reach a state
    of convergence.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allowing more stable learning trajectories. In other cases, networks just take
    longer to converge when the initial learning process is unstable. However, in
    some other cases, networks cannot converge at all when networks don’t have a stable
    foundation to start learning. TL can help models that originally fail to learn
    anything reach convergence in the learning process.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increasing generalization and reducing the probability of overfitting. When
    the second task involves only a small subset of variations from the actual data
    population, knowledge learned from a first task that covers a wider range of variations
    helps to prevent narrow oversights.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concretely, TL in DL is achieved by using the network parameters that were learned
    from the first task in the second task. The parameters involve all the weights
    and biases that are associated with a network. The parameters can be used as an
    initialization step for the same network instead of the usual randomly initialized
    parameters. These are known as **pre-trained weights**. The process of network
    learning with pre-trained weights is called **fine-tuning**. Additionally, the
    network parameters can also opt to be completely frozen and plainly act as a **featurizer**
    component that provides features for another SL algorithm.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of automated strategies that focus on improving the results
    you can get with fine-tuning. However, these methods are not silver bullets and
    can take a lot of time to carry out. The practical strategy to achieve a better
    performance using TL is to choose the number of layers you want to train by gauging
    the transferability component of the two tasks. *Table 8.2* shows an easy way
    to decide on a TL strategy based on task similarity and dataset size of the second
    task:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Dataset Size** |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
- en: '| **Small** | **Big** |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
- en: '| Task similarity | Low | Train the entire network as usual. | Train the entire
    network as usual. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
- en: '| High | Freeze all base network parameters, add an extra linear prediction
    layer, and only train this linear layer on the dataset. | Train the entire network
    as usual. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
- en: Table 8.2 – Deep TL (DTL) strategy guide
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: For clarity purposes, let’s say “big” is when the dataset has at least 10,000
    examples. For task transferability/similarity, human intuition is required to
    obtain an evaluation on a case-by-case basis. Here in the guide, we assume that
    a big dataset size means a dataset with large variations that represent the population
    adequately. A hidden component not presented in the preceding figure, however,
    is the size of the dataset of the first task. TL has the best impact when the
    task similarity is high, the second task dataset size is small, and, additionally,
    when the dataset size of the first task is big. The size of the first dataset
    usually also limits the range of NN sizes that can be used. Let’s say that the
    first dataset size is small; the best-performing models in this case are usually
    smaller-sized models. When TL is highly beneficial, even when the dataset size
    of the second dataset size is medium or big, the smaller models can still outperform
    bigger-sized models. An act of balancing is required in complex cases such as
    this to obtain the ideal model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'One prominent issue in TL is called **catastrophic forgetting**. This is a
    phenomenon where the network performance regresses to earlier tasks as the network
    trains on new tasks. If the performance of the previous task is not of concern
    to you, this issue can be ignored. Practically, if it is required to maintain
    the performance of the previous task, you can follow these steps:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Use a unified metric that takes care of the performance of the first task and
    second task by additionally validating on the validation dataset of the first
    task.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Combine the dataset from the first task and second task and train it as a single
    model. If the targets are not relevant to each other, use different fully connected
    layer prediction heads.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lastly, there is an additional popular technique for TL known as **knowledge
    distillation**. This method involves two models, where one pre-trained teacher
    model is used to distill its knowledge to a student model. Typically, the teacher
    model is a bigger model that has the capacity to learn more accurate information
    but is slower in runtime, and the student model is a smaller model that can be
    run at reasonable speeds during runtime. The method distills knowledge by using
    an additional similarity-based loss of a chosen layer output between the teacher
    and student model, which is typically the logit layer, on top of the base cross-entropy
    loss. This method encourages the student model to produce similar features to
    the teacher model. The technique is typically used to obtain a smaller model with
    better accuracy than if trained without knowledge distillation, so the deployment
    infrastructure can be cheaper. This technique will be practically introduced in
    [*Chapter 13*](B18187_13.xhtml#_idTextAnchor196), *Exploring Bias and Fairness*,
    as a key technique to also mitigate bias.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into another type of multitask execution, called multiple
    objective learning.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Multiple objective learning
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multiple objective learning is a type of multitasking process that involves
    training with simultaneously different goals. Different goals direct the learning
    trajectory of a network toward different paths. Multiple objective learning can
    be further broken down into the following options:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Multiple losses on the same outputs.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multiple targets, which are taken care of by separate NN prediction heads,
    each with their respective losses. This can be further broken down into the following
    categories:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple targets with real impact and usage.
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A single or multiple main targets and a single or multiple auxiliary targets.
    Auxiliary targets are paired with their own losses called auxiliary losses.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aside from option *2(A)*, the other options (that is, *1* and *2(B)* ) for multiple
    objective learning are mainly used to improve metric performance. Metrics can
    be as simple as accuracy or log loss, or more intricate, such as the degree of
    bias toward a minority class. A simple more straightforward example of multiple
    objective learning is the multilabel target type. Multilabel is where multiple
    labels can be associated with a single data row. This means that the setup will
    be a multiple binary classification target, which is the case with *2(A)*.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Multiple targets and their associated losses mean there might be issues of conflicting
    gradients during the learning process. This phenomenon is more commonly known
    as **negative transfer**. A more extreme case of negative transfer is when gradients
    from the two losses cancel each other out when they have the same magnitude in
    exactly opposite directions. This will block the learning process of the model
    where the model will never converge. In reality, this issue can be at a lower
    scale and dampen the speed of convergence or, worse, introduce huge fluctuations
    that make it hard to learn anything. Unfortunately, there are no silver-bullet
    mitigation methods here other than to understand the background behind why a model
    learns poorly. Iterative experiments are usually required to figure out how to
    balance these losses properly to encourage a stable learning process.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into multimodal NN training.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal NN training
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multimodal NNs are a type of multitask system in the sense that networks responsible
    for different modalities learn in the same task in completely different paths.
    A common method of handling multimodality in NNs is to assign different neural
    blocks at the initial stage for different data modalities. Neural blocks contain
    the networks specific to each modality. The neural blocks for different modalities
    will then be merged using a series of intermediate fully connected layers and
    an output fully connected layer. This is depicted in *Figure 8**.7*:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Typical multimodal NN structure](img/B18187_08_007.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Typical multimodal NN structure
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of leveraging multimodality is that the additional data input can
    allow for more comprehensive patterns to be identified and thus should improve
    the overall metric performance. In reality, this commonly will not be the case
    without careful handling of the training process. Different modalities exist in
    entirely different distributions and learn at different rates with different paths.
    A single global optimization strategy applied to all the data modalities will
    likely produce suboptimal results. A common and effective strategy is to do the
    following:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Pretrain the individual modality neural block (unimodal) with a temporary prediction
    output layer until a certain degree of convergence
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove the temporary prediction output layer and train the multimodal NN as
    usual with the pre-trained weights from the unimodal training process
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other than that, freezing the weights of the unimodal trained NN and only training
    the multimodal aggregation fully connected layer prediction head is also a sound
    strategy. Many more complex strategies exist to tackle this issue but are out
    of scope in this book.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored supervised deep learning, including the types of
    problems it can be used to solve and the techniques for implementing and training
    DL models. Supervised deep learning involves training a model on labeled data
    to make predictions on new data. We also covered a variety of supervised learning
    use cases on different problem types, including binary classification, multiclassification,
    regression, and multitask and representation learning. The chapter also covered
    techniques for training DL models effectively, including regularization and hyperparameter
    tuning, and provided practical implementations in the Python programming language
    using popular DL frameworks.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Supervised deep learning can be used for a wide range of real-world applications
    in tasks such as image classification, **natural language processing** (**NLP**),
    and speech recognition. With the knowledge provided in this chapter, you should
    be able to identify supervised learning applications and train DL models effectively.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore **unsupervised learning** for DL.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
