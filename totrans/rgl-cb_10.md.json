["```py\npip install numpy matplotlib torch torchvision\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import CIFAR10\nimport torchvision.transforms as transforms\n```", "```py\n        transform = transforms.Compose([\n        ```", "```py\n            transforms.ToTensor(),\n        ```", "```py\n            transforms.Normalize((0.5, 0.5, 0.5),\n        ```", "```py\n                (0.5, 0.5, 0.5)),\n        ```", "```py\n        ])\n        ```", "```py\n    # Will download the dataset at first\n    ```", "```py\n    trainset = CIFAR10('./data', train=True,\n    ```", "```py\n        download=True, transform=transform)\n    ```", "```py\n    train_dataloader = DataLoader(trainset, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    testset = CIFAR10('./data', train=False,\n    ```", "```py\n        download=True, transform=transform)\n    ```", "```py\n    test_dataloader = DataLoader(testset, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    # Get a batch of images and labels\n    ```", "```py\n    images, labels = next(iter(train_dataloader))\n    ```", "```py\n    # Denormalize the images\n    ```", "```py\n    images = images / 2 + 0.5\n    ```", "```py\n    # Compute a grid image for visualization\n    ```", "```py\n    images = make_grid(images)\n    ```", "```py\n    # Switch from channel first to channel last\n    ```", "```py\n    images = np.transpose(images.numpy(), (1, 2, 0))\n    ```", "```py\n    # Display the result\n    ```", "```py\n    plt.figure(figsize=(14, 8))\n    ```", "```py\n    plt.imshow(images)\n    ```", "```py\n    plt.axis('off')\n    ```", "```py\n    class LeNet5(nn.Module):\n    ```", "```py\n        def __init__(self, n_classes: int):\n    ```", "```py\n            super(LeNet5, self).__init__()\n    ```", "```py\n            self.n_classes = n_classes\n    ```", "```py\n            self.c1 = nn.Conv2d(3, 6, kernel_size=5,\n    ```", "```py\n                stride=1, padding=0)\n    ```", "```py\n            self.s2 = nn.MaxPool2d(kernel_size=2)\n    ```", "```py\n            self.c3 = nn.Conv2d(6, 16, kernel_size=5,\n    ```", "```py\n                stride=1, padding=0)\n    ```", "```py\n            self.s4 = nn.MaxPool2d(kernel_size=2)\n    ```", "```py\n            self.c5 = nn.Linear(400, 120)\n    ```", "```py\n            self.f6 = nn.Linear(120, 84)\n    ```", "```py\n            self.output = nn.Linear(84, self.n_classes)\n    ```", "```py\n        def forward(self, x):\n    ```", "```py\n            x = F.relu(self.c1(x))\n    ```", "```py\n            x = self.s2(x)\n    ```", "```py\n            x = F.relu(self.c3(x))\n    ```", "```py\n            x = self.s4(x)\n    ```", "```py\n            # Flatten the 2D-array\n    ```", "```py\n            x = torch.flatten(x, 1)\n    ```", "```py\n            x = F.relu(self.c5(x))\n    ```", "```py\n            x = F.relu(self.f6(x))\n    ```", "```py\n            output = F.softmax(self.output(x), dim=1)\n    ```", "```py\n            return output\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    lenet5 = LeNet5(10)\n    ```", "```py\n    # check device\n    ```", "```py\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    ```", "```py\n    lenet5 = lenet5.to(device)\n    ```", "```py\n    # Generate randomly one random 32x32 RGB image\n    ```", "```py\n    random_data = torch.rand((1, 3, 32, 32), device=device)\n    ```", "```py\n    result = lenet5(random_data)\n    ```", "```py\n    print('Resulting output tensor:', result)\n    ```", "```py\n    print('Sum of the output tensor:', result.sum())\n    ```", "```py\nResulting output tensor: tensor([[0.0890, 0.1047, 0.1039, 0.1003, 0.0957, 0.0918, 0.0948, 0.1078, 0.0999,\n         0.1121]], grad_fn=<SoftmaxBackward0>)\nSum of the output tensor: tensor(1.0000, grad_fn=<SumBackward0>)\n```", "```py\n    criterion = nn.CrossEntropyLoss()\n    ```", "```py\n    optimizer = torch.optim.Adam(lenet5.parameters(), lr=0.001)\n    ```", "```py\n    def epoch_step_cifar(model, dataloader, device,\n    ```", "```py\n    training_set : bool) :\n    ```", "```py\n        running_loss = 0.\n    ```", "```py\n        correct = 0.\n    ```", "```py\n        for i, data in enumerate(dataloader, 0):\n    ```", "```py\n            inputs, labels = data\n    ```", "```py\n            inputs = inputs.to(device)\n    ```", "```py\n            labels = labels.to(device)\n    ```", "```py\n            if training_set:\n    ```", "```py\n                optimizer.zero_grad()\n    ```", "```py\n            outputs = model(inputs)\n    ```", "```py\n            loss = criterion(outputs, labels)\n    ```", "```py\n            if training_set:\n    ```", "```py\n                loss.backward()\n    ```", "```py\n                optimizer.step()\n    ```", "```py\n            correct += (outputs.argmax(\n    ```", "```py\n                dim=1) == labels).float().sum().cpu()\n    ```", "```py\n            running_loss += loss.item()\n    ```", "```py\n        return running_loss, correct\n    ```", "```py\n    def train_cifar_classifier(model, train_dataloader,\n    ```", "```py\n        test_dataloader, criterion, device, epochs):\n    ```", "```py\n            # Create empty lists to store the losses and accuracies\n    ```", "```py\n            train_losses = []\n    ```", "```py\n            test_losses = []\n    ```", "```py\n            train_accuracy = []\n    ```", "```py\n            test_accuracy = []\n    ```", "```py\n            # Loop over epochs\n    ```", "```py\n            for epoch in range(epochs):\n    ```", "```py\n                ## Train the model on the training set\n    ```", "```py\n                running_train_loss = 0.\n    ```", "```py\n                correct = 0.\n    ```", "```py\n                lenet5.train()\n    ```", "```py\n                running_train_loss,\n    ```", "```py\n                correct = epoch_step_cifar(\n    ```", "```py\n                    model, train_dataloader, device,\n    ```", "```py\n                    training_set=True\n    ```", "```py\n                )\n    ```", "```py\n                # Compute and store loss and accuracy for this epoch\n    ```", "```py\n            train_epoch_loss = running_train_loss / len(\n    ```", "```py\n                train_dataloader)\n    ```", "```py\n            train_losses.append(train_epoch_loss)\n    ```", "```py\n            train_epoch_accuracy = correct / len(trainset)\n    ```", "```py\n            train_accuracy.append(train_epoch_accuracy)\n    ```", "```py\n            ## Evaluate the model on the test set\n    ```", "```py\n            running_test_loss = 0.\n    ```", "```py\n            correct = 0.\n    ```", "```py\n            lenet5.eval()\n    ```", "```py\n            with torch.no_grad():\n    ```", "```py\n                running_test_loss,\n    ```", "```py\n                correct = epoch_step_cifar(\n    ```", "```py\n                    model, test_dataloader, device,\n    ```", "```py\n                    training_set=False\n    ```", "```py\n                )\n    ```", "```py\n                test_epoch_loss = running_test_loss / len(\n    ```", "```py\n                    test_dataloader)\n    ```", "```py\n                test_losses.append(test_epoch_loss)\n    ```", "```py\n                test_epoch_accuracy = correct / len(testset)\n    ```", "```py\n                test_accuracy.append(test_epoch_accuracy)\n    ```", "```py\n            # Print stats\n    ```", "```py\n            print(f'[epoch {epoch + 1}] Training: loss={train_epoch_loss:.3f} accuracy={train_epoch_accuracy:.3f} |\\\n    ```", "```py\n        \\t Test: loss={test_epoch_loss:.3f} accuracy={test_epoch_accuracy:.3f}')\n    ```", "```py\n        return train_losses, test_losses, train_accuracy,\n    ```", "```py\n            test_accuracy\n    ```", "```py\n    train_losses, test_losses, train_accuracy, \n    ```", "```py\n    test_accuracy = train_cifar_classifier(lenet5,\n    ```", "```py\n        train_dataloader, test_dataloader, criterion,\n    ```", "```py\n        device, epochs=50)\n    ```", "```py\n[epoch 50] Training: loss=1.740 accuracy=0.720 |   Test: loss=1.858 accuracy=0.600\n```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (CE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    plt.plot(train_accuracy, label='train')\n    ```", "```py\n    plt.plot(test_accuracy, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('Accuracy')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\npip install numpy matplotlib torch torchvision\n```", "```py\n    class LeNet5(nn.Module):\n    ```", "```py\n        def __init__(self, n_classes: int):\n    ```", "```py\n            super(LeNet5, self).__init__()\n    ```", "```py\n            self.n_classes = n_classes\n    ```", "```py\n            self.c1 = nn.Conv2d(3, 6, kernel_size=5,\n    ```", "```py\n                stride=1, padding=0, )\n    ```", "```py\n            self.s2 = nn.MaxPool2d(kernel_size=2)\n    ```", "```py\n            self.bnorm2 = nn.BatchNorm2d(6)\n    ```", "```py\n            self.c3 = nn.Conv2d(6, 16, kernel_size=5,\n    ```", "```py\n                stride=1, padding=0)\n    ```", "```py\n            self.s4 = nn.MaxPool2d(kernel_size=2)\n    ```", "```py\n            self.bnorm4 = nn.BatchNorm1d(400)\n    ```", "```py\n            self.c5 = nn.Linear(400, 120)\n    ```", "```py\n            self.bnorm5 = nn.BatchNorm1d(120)\n    ```", "```py\n            self.f6 = nn.Linear(120, 84)\n    ```", "```py\n            self.bnorm6 = nn.BatchNorm1d(84)\n    ```", "```py\n            self.output = nn.Linear(84, self.n_classes)\n    ```", "```py\n        def forward(self, x):\n    ```", "```py\n            x = F.relu(self.c1(x))\n    ```", "```py\n            x = self.bnorm2(self.s2(x))\n    ```", "```py\n            x = F.relu(self.c3(x))\n    ```", "```py\n            x = self.s4(x)\n    ```", "```py\n            # Flatten the 2D-array\n    ```", "```py\n            x = self.bnorm4(torch.flatten(x, 1))\n    ```", "```py\n            x = self.bnorm5(F.relu(self.c5(x)))\n    ```", "```py\n            x = self.bnorm6(F.relu(self.f6(x)))\n    ```", "```py\n            output = F.softmax(self.output(x), dim=1)\n    ```", "```py\n            return output\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    lenet5 = LeNet5(10)\n    ```", "```py\n    # check device\n    ```", "```py\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    ```", "```py\n    lenet5 = lenet5.to(device)\n    ```", "```py\n    # Instantiate loss and optimizer\n    ```", "```py\n    criterion = nn.CrossEntropyLoss()\n    ```", "```py\n    optimizer = torch.optim.Adam(lenet5.parameters(), lr=0.001)\n    ```", "```py\n    train_losses, test_losses, train_accuracy, \n    ```", "```py\n    test_accuracy = train_cifar_classifier(lenet5,\n    ```", "```py\n        train_dataloader, test_dataloader, criterion,\n    ```", "```py\n        device, epochs=20)\n    ```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (CE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    plt.plot(train_accuracy, label='train')\n    ```", "```py\n    plt.plot(test_accuracy, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('Accuracy')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\nfrom torchvision import utils\ndef visualize_kernels(tensor, ch=0, all_kernels=False, nrow=8, padding=1, title=None):\n    n,c,w,h = tensor.shape\n    if all_kernels:\n        tensor = tensor.view(n*c, -1, w, h)\n    elif c != 3:\n        tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n    grid = utils.make_grid(tensor, nrow=nrow,\n        normalize=True, padding=padding)\n    # Display\n    plt.figure(figsize=(nrow, rows))\n    if title is not None:\n        plt.title(title)\n    plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n    plt.axis('off')\n    plt.show()\n```", "```py\nvisualize_kernels(lenet5.c1.weight.data, all_kernels=False,\n    title='C1 layer')\nvisualize_kernels(lenet5.c3.weight.data, title='C3 layer')\n```", "```py\npip install ultralytics\n```", "```py\n    kaggle datasets download -d saumyapatel/traffic-vehicles-object-detection --unzip\n    ```", "```py\n    mv 'Traffic Dataset' traffic\n    ```", "```py\n    mkdir datasets\n    ```", "```py\n    mv traffic datasets/\n    ```", "```py\ntraffic\n├── images\n│   ├── train: 738 images\n│   ├── val: 185 images\n│   ├── test: 278 images\n├── labels\n    ├── train\n    ├── val\n```", "```py\n        import cv2\n        ```", "```py\n        from glob import glob\n        ```", "```py\n        import matplotlib.pyplot as plt\n        ```", "```py\n        from ultralytics import YOLO\n        ```", "```py\n    plt.figure(figsize=(14, 10))\n    ```", "```py\n    # Get all images paths\n    ```", "```py\n    images = glob('datasets/traffic/images/train/*.jpg')\n    ```", "```py\n    # Plot 8 of them\n    ```", "```py\n    for i, path in enumerate(images[:8]):\n    ```", "```py\n        img = plt.imread(path)\n    ```", "```py\n        plt.subplot(2, 4, i+1)\n    ```", "```py\n        plt.imshow(img)\n    ```", "```py\n        plt.axis('off')\n    ```", "```py\n    with open('datasets/traffic/labels/train/00 (10).txt') as file:\n    ```", "```py\n        print(file.read())\n    ```", "```py\n        file.close()\n    ```", "```py\n2 0.543893 0.609375 0.041985 0.041667\n5 0.332061 0.346354 0.129771 0.182292\n5 0.568702 0.479167 0.351145 0.427083\n```", "```py\ndef plot_labels(image_path, labels_path, classes):\n    image = plt.imread(image_path)\n    with open(labels_path, 'r') as file:\n        lines = file.readlines()\n        for line in lines:\n            cls, xc, yc, w, h= line.strip().split(' ')\n            xc = int(float(xc)*image.shape[1])\n            yc = int(float(yc)*image.shape[0])\n            w = int(float(w)*image.shape[1])\n            h = int(float(h)*image.shape[0])\n            cv2.rectangle(image, (xc - w//2,\n                yc - h//2), (xc + w//2 ,yc + h//2),\n                (255,0,0), 2)\n            cv2.putText(image, f'{classes[int(cls)]}',\n                (xc-w//2, yc - h//2 - 10),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n                (255,0,0), 1)\n    file.close()\n    plt.imshow(image)\nclasses = ['Car', 'Number Plate', 'Blur Number Plate',\n    'Two Wheeler', 'Auto', 'Bus', 'Truck']\nplot_labels(\n    'datasets/traffic/images/train/00 (10).jpg',\n    'datasets/traffic/labels/train/00 (10).txt',\n    classes\n)\n```", "```py\n    train: traffic/images/train\n    ```", "```py\n    val: traffic/images/val\n    ```", "```py\n    nc: 7\n    ```", "```py\n    names: ['Car', 'Number Plate', 'Blur Number Plate',\n    ```", "```py\n        'Two Wheeler', 'Auto', 'Bus', 'Truck']\n    ```", "```py\n        # Create a new YOLO model with random weights\n        ```", "```py\n        model = YOLO('yolov8n.yaml')\n        ```", "```py\n    # Train the model for 100 epochs\n    ```", "```py\n    model.train(data='dataset.yaml', epochs=100,\n    ```", "```py\n        name='untrained_traffic')\n    ```", "```py\n    plt.figure(figsize=(14, 10))\n    ```", "```py\n    plt.imshow(plt.imread(\n    ```", "```py\n        'runs/detect/untrained_traffic/results.png'))\n    ```", "```py\n    plt.axis('off')\n    ```", "```py\n    def plot_results_one_image(result):\n    ```", "```py\n        image = result[0].orig_img.copy()\n    ```", "```py\n        raw_res = result[0].boxes.data\n    ```", "```py\n        for detection in raw_res:\n    ```", "```py\n            x1, y1, x2, y2, p,\n    ```", "```py\n            cls = detection.cpu().tolist()\n    ```", "```py\n            cv2.rectangle(image, (int(x1), int(y1)),\n    ```", "```py\n                (int(x2), int(y2)), (255,0,0), 2)\n    ```", "```py\n            cv2.putText(image, f'{classes[int(cls)]}',\n    ```", "```py\n                (int(x1), int(y1) - 10),\n    ```", "```py\n                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n    ```", "```py\n        plt.imshow(image)\n    ```", "```py\n    # Compute the model inference on a test image\n    ```", "```py\n    result = model.predict(\n    ```", "```py\n        'datasets/traffic/images/test/00 (100).png')\n    ```", "```py\n    # Plot the results\n    ```", "```py\n    plot_results_one_image(result)\n    ```", "```py\n    # Load a pretrained YOLO model\n    ```", "```py\n    pretrained_model = YOLO('yolov8n.pt')\n    ```", "```py\n    # Train the model for 100 epochs\n    ```", "```py\n    pretrained_model.train(data='dataset.yaml',\n    ```", "```py\n        epochs=100, name='pretrained_traffic')\n    ```", "```py\n    plt.figure(figsize=(14, 10))\n    ```", "```py\n    plt.imshow(plt.imread(\n    ```", "```py\n        'runs/detect/pretrained_traffic/results.png'))\n    ```", "```py\n    plt.axis('off')\n    ```", "```py\n    result = pretrained_model.predict(\n    ```", "```py\n        'datasets/traffic/images/test/00 (100).png')\n    ```", "```py\n    plot_results_one_image(result)\n    ```", "```py\nkaggle datasets download -d santurini/semantic-segmentation-dronedataset --unzip\n```", "```py\npip install matplotlib pillow torch torchvision segmentation-models-pytorch\n```", "```py\n    from torch.utils.data import DataLoader, Dataset\n    ```", "```py\n    import torch\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    import torchvision.transforms as transforms\n    ```", "```py\n    import numpy as np\n    ```", "```py\n    import tqdm\n    ```", "```py\n    from glob import glob\n    ```", "```py\n    from PIL import Image\n    ```", "```py\n    import segmentation_models_pytorch as smp\n    ```", "```py\n    import torch.nn as nn\n    ```", "```py\n    import torch.optim as optim\n    ```", "```py\n    class DroneDataset(Dataset):\n    ```", "```py\n        def __init__(self, images_path: str,\n    ```", "```py\n            masks_path: str, transform, train: bool,\n    ```", "```py\n            num_classes: int = 5):\n    ```", "```py\n                self.images_path = sorted(glob(\n    ```", "```py\n                    f'{images_path}/*.png'))\n    ```", "```py\n                self.masks_path = sorted(glob(\n    ```", "```py\n                    f'{masks_path}/*.png'))\n    ```", "```py\n                self.num_classes = num_classes\n    ```", "```py\n                if train:\n    ```", "```py\n                    self.images_path = self.images_path[\n    ```", "```py\n                       :int(.8*len(self.images_path))]\n    ```", "```py\n                    Self.masks_path = self.masks_path[\n    ```", "```py\n                        :int(.8*len(self.masks_path))]\n    ```", "```py\n                else:\n    ```", "```py\n                    self.images_path = self.images_path[\n    ```", "```py\n                        int(.8*len(self.images_path)):]\n    ```", "```py\n                    self.masks_path = self.masks_path[\n    ```", "```py\n                        int(.8*len(self.masks_path)):]\n    ```", "```py\n                self.transform = transform\n    ```", "```py\n        def __len__(self):\n    ```", "```py\n            return len(self.images_path)\n    ```", "```py\n        def __getitem__(self, idx):\n    ```", "```py\n            image = np.array(Image.open(\n    ```", "```py\n                self.images_path[idx]))\n    ```", "```py\n            mask = np.array(Image.open(\n    ```", "```py\n                self.masks_path[idx]))\n    ```", "```py\n            return self.transform(image), torch.tensor(\n    ```", "```py\n                mask, dtype=torch.long)\n    ```", "```py\n    transform = transforms.Compose([\n    ```", "```py\n        transforms.ToTensor(),\n    ```", "```py\n        transforms.Normalize((0.5, 0.5, 0.5),\n    ```", "```py\n            (0.5, 0.5, 0.5))\n    ```", "```py\n    ])\n    ```", "```py\n    batch_size = 4\n    ```", "```py\n    learning_rate = 0.005\n    ```", "```py\n    classes = ['obstacles', 'water', 'soft-surfaces',\n    ```", "```py\n        'moving-objects', 'landing-zones']\n    ```", "```py\n    device = torch.device(\n    ```", "```py\n        'cuda' if torch.cuda.is_available() else 'cpu')\n    ```", "```py\n    train_dataset = DroneDataset(\n    ```", "```py\n        'classes_dataset/classes_dataset/original_images/',\n    ```", "```py\n        'classes_dataset/classes_dataset/label_images_semantic/',\n    ```", "```py\n        transform,\n    ```", "```py\n        train=True\n    ```", "```py\n    )\n    ```", "```py\n    train_dataloader = DataLoader(train_dataset,\n    ```", "```py\n        batch_size=batch_size, shuffle=True)\n    ```", "```py\n    test_dataset = DroneDataset(\n    ```", "```py\n        'classes_dataset/classes_dataset/original_images/',\n    ```", "```py\n        'classes_dataset/classes_dataset/label_images_semantic/',\n    ```", "```py\n        transform,\n    ```", "```py\n        train=False\n    ```", "```py\n    )\n    ```", "```py\n    test_dataloader = DataLoader(test_dataset,\n    ```", "```py\n        batch_size=batch_size, shuffle=True)\n    ```", "```py\n    # Get a batch of images and labels\n    ```", "```py\n    images, labels = next(iter(train_dataloader))\n    ```", "```py\n    # Plot the image and overlay the labels\n    ```", "```py\n    plt.figure(figsize=(12, 10))\n    ```", "```py\n    plt.imshow(images[0].permute(\n    ```", "```py\n        1, 2, 0).cpu().numpy() * 0.5 + 0.5)\n    ```", "```py\n    plt.imshow(labels[0], alpha = 0.8)\n    ```", "```py\n    plt.axis('off')\n    ```", "```py\n    model = smp.Unet(\n    ```", "```py\n        encoder_name='efficientnet-b5',\n    ```", "```py\n        encoder_weights='imagenet',\n    ```", "```py\n        in_channels=3,\n    ```", "```py\n        classes=len(classes),\n    ```", "```py\n        )\n    ```", "```py\n    optimizer = optim.Adam(model.parameters(),\n    ```", "```py\n        lr=learning_rate)\n    ```", "```py\n    criterion = smp.losses.DiceLoss(\n    ```", "```py\n        smp.losses.MULTICLASS_MODE, from_logits=True)\n    ```", "```py\n    def compute_metrics(stats):\n    ```", "```py\n        tp = torch.cat([x[\"tp\"] for x in stats])\n    ```", "```py\n        fp = torch.cat([x[\"fp\"] for x in stats])\n    ```", "```py\n        fn = torch.cat([x[\"fn\"] for x in stats])\n    ```", "```py\n        tn = torch.cat([x[\"tn\"] for x in stats])\n    ```", "```py\n        iou = smp.metrics.iou_score(tp, fp, fn, tn,\n    ```", "```py\n            reduction='micro')\n    ```", "```py\n        f1_score = smp.metrics.f1_score(tp, fp, fn, tn,\n    ```", "```py\n            reduction='micro')\n    ```", "```py\n        return iou, f1_score\n    ```", "```py\n    def epoch_step_unet(model, dataloader, device,\n    ```", "```py\n        num_classes, training_set: bool):\n    ```", "```py\n            stats = []\n    ```", "```py\n            for i, data in tqdm.tqdm(enumerate(\n    ```", "```py\n                dataloader, 0)):\n    ```", "```py\n                inputs, labels = data\n    ```", "```py\n                inputs = inputs.to(device)\n    ```", "```py\n                labels = labels.to(device)\n    ```", "```py\n                if training_set:\n    ```", "```py\n                    optimizer.zero_grad()\n    ```", "```py\n                    outputs = model(inputs)\n    ```", "```py\n                    loss = criterion(outputs, labels)\n    ```", "```py\n                if training_set:\n    ```", "```py\n                    loss.backward()\n    ```", "```py\n                    optimizer.step()\n    ```", "```py\n            tp, fp, fn, tn = smp.metrics.get_stats(\n    ```", "```py\n                torch.argmax(outputs, dim=1), labels,\n    ```", "```py\n                mode='multiclass',\n    ```", "```py\n                num_classes=num_classes)\n    ```", "```py\n            stats.append({'tp': tp, 'fp': fp, 'fn':fn,\n    ```", "```py\n                'tn': tn, 'loss': loss.item()})\n    ```", "```py\n        return stats\n    ```", "```py\n    def train_unet(model, train_dataloader,\n    ```", "```py\n        test_dataloader, criterion, device,\n    ```", "```py\n        epochs: int = 10, num_classes: int = 5,\n    ```", "```py\n        scheduler=None):\n    ```", "```py\n        train_metrics = {'loss': [], 'iou': [], 'f1': [],\n    ```", "```py\n            'lr': []}\n    ```", "```py\n        test_metrics = {'loss': [], 'iou': [], 'f1': []}\n    ```", "```py\n        model = model.to(device)\n    ```", "```py\n        for epoch in range(epochs):\n    ```", "```py\n      # loop over the dataset multiple times\n    ```", "```py\n            # Train\n    ```", "```py\n            model.train()\n    ```", "```py\n            #running_loss = 0.0\n    ```", "```py\n            train_stats = epoch_step_unet(model,\n    ```", "```py\n                train_dataloader, device, num_classes,\n    ```", "```py\n                training_set=True)\n    ```", "```py\n            # Eval\n    ```", "```py\n            model.eval()\n    ```", "```py\n            with torch.no_grad():\n    ```", "```py\n                test_stats = epoch_step_unet(model,\n    ```", "```py\n                    test_dataloader, device, num_classes,\n    ```", "```py\n                    training_set=False)\n    ```", "```py\n            if scheduler is not None:\n    ```", "```py\n                train_metrics['lr'].append(\n    ```", "```py\n                    scheduler.get_last_lr())\n    ```", "```py\n                scheduler.step()\n    ```", "```py\n            train_metrics['loss'].append(sum(\n    ```", "```py\n                [x['loss'] for x in train_stats]) / len(\n    ```", "```py\n                    train_dataloader))\n    ```", "```py\n            test_metrics['loss'].append(sum(\n    ```", "```py\n                [x['loss'] for x in test_stats]) / len(\n    ```", "```py\n                    test_dataloader))\n    ```", "```py\n            iou, f1 = compute_metrics(train_stats)\n    ```", "```py\n            train_metrics['iou'].append(iou)\n    ```", "```py\n            train_metrics['f1'].append(f1)\n    ```", "```py\n            iou, f1 = compute_metrics(test_stats)\n    ```", "```py\n            test_metrics['iou'].append(iou)\n    ```", "```py\n            test_metrics['f1'].append(f1)\n    ```", "```py\n            print(f\"[{epoch + 1}] train loss: {train_metrics['loss'][-1]:.3f} IoU: {train_metrics['iou'][-1]:.3f} | \\\n    ```", "```py\n                    test loss: {\n    ```", "```py\n                        test_metrics['loss'][-1]:.3f} IoU:\n    ```", "```py\n                        {test_metrics['iou'][-1]:.3f}\")\n    ```", "```py\n        return train_metrics, test_metrics\n    ```", "```py\n    train_metrics, test_metrics = train_unet(model,\n    ```", "```py\n        train_dataloader, test_dataloader, criterion,\n    ```", "```py\n        device, epochs=50, num_classes=len(classes))\n    ```", "```py\n    plt.figure(figsize=(10, 10))\n    ```", "```py\n    plt.subplot(3, 1, 1)\n    ```", "```py\n    plt.plot(train_metrics['loss'], label='train')\n    ```", "```py\n    plt.plot(test_metrics['loss'], label='test')\n    ```", "```py\n    plt.ylabel('Dice loss')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.subplot(3, 1, 2)\n    ```", "```py\n    plt.plot(train_metrics['iou'], label='train')\n    ```", "```py\n    plt.plot(test_metrics['iou'], label='test')\n    ```", "```py\n    plt.ylabel('IoU')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.subplot(3, 1, 3)\n    ```", "```py\n    plt.plot(train_metrics['f1'], label='train')\n    ```", "```py\n    plt.plot(test_metrics['f1'], label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('F1-score')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    def freeze_encoder(model, max_level: int = None):\n    ```", "```py\n        for I, child in enumerate(model.encoder.children()):\n    ```", "```py\n            if max_level is not None and i >= max_level:\n    ```", "```py\n                    return\n    ```", "```py\n            for param in child.parameters():\n    ```", "```py\n                param.requires_grad = False\n    ```", "```py\n        return\n    ```", "```py\n    def unfreeze(model):\n    ```", "```py\n        for child in model.children():\n    ```", "```py\n            for param in child.parameters():\n    ```", "```py\n                param.requires_grad = True\n    ```", "```py\n        return\n    ```", "```py\n    model = smp.Unet(\n    ```", "```py\n        encoder_name='efficientnet-b5',\n    ```", "```py\n        encoder_weights='imagenet',\n    ```", "```py\n        in_channels=3,\n    ```", "```py\n        classes=len(classes),\n    ```", "```py\n        )\n    ```", "```py\n    print''Total number of trainable parameters'', sum(p.numel() for p in model.parameters() if p.requires_grad))\n    ```", "```py\nTotal number of trainable parameters: 31216581\n```", "```py\n    # Freeze the of the encoder\n    ```", "```py\n    freeze_encoder(model, 3)\n    ```", "```py\n    print('Total number of trainable parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n    ```", "```py\nTotal number of trainable parameters: 3928469\n```", "```py\n    optimizer = optim.Adam(model.parameters(),\n    ```", "```py\n        lr=learning_rate)\n    ```", "```py\n    scheduler = optim.lr_scheduler.ExponentialLR(\n    ```", "```py\n        optimizer, gamma=0.95)\n    ```", "```py\n    train_metrics, test_metrics = train_unet(model,\n    ```", "```py\n        train_dataloader, test_dataloader, criterion,\n    ```", "```py\n        device, epochs=20, num_classes=len(classes),\n    ```", "```py\n        scheduler=scheduler)\n    ```", "```py\n    unfreeze(model)\n    ```", "```py\n    print('Total number of trainable parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n    ```", "```py\nTotal number of trainable parameters: 31216581\n```", "```py\n    train_metrics_unfreeze, test_metrics_unfreeze = train_unet(\n    ```", "```py\n    model, train_dataloader, test_dataloader,\n    ```", "```py\n        criterion, device, epochs=30,\n    ```", "```py\n        num_classes=len(classes), scheduler=scheduler)\n    ```", "```py\n    plt.figure(figsize=(10, 10))\n    ```", "```py\n    plt.subplot(3, 1, 1)\n    ```", "```py\n    plt.plot(train_metrics['loss'] + train_metrics_unfreeze['loss'], label='train')\n    ```", "```py\n    plt.plot(test_metrics['loss'] + test_metrics_unfreeze['loss'], label='test')\n    ```", "```py\n    plt.ylabel('Dice loss')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.subplot(3, 1, 2)\n    ```", "```py\n    plt.plot(train_metrics['iou'] + train_metrics_unfreeze['iou'], label='train')\n    ```", "```py\n    plt.plot(test_metrics['iou'] + test_metrics_unfreeze['iou'], label='test')\n    ```", "```py\n    plt.ylabel('IoU')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.subplot(3, 1, 3)\n    ```", "```py\n    plt.plot(train_metrics['f1'] + train_metrics_unfreeze['f1'], label='train')\n    ```", "```py\n    plt.plot(test_metrics['f1'] + test_metrics_unfreeze['f1'], label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('F1-score')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    plt.plot(train_metrics['lr'] + train_metrics_unfreeze['lr'])\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('Learning rate')\n    ```", "```py\n    plt.show()\n    ```", "```py\nsmp.metrics.iou_score(tp, fp, fn, tn, reduction='micro')\n```"]