<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer053" class="Content">
			<h1 id="_idParaDest-60"><a id="_idTextAnchor059"/>Section 3 – Running Deep Learning Pipelines at Scale</h1>
			<p>In this section, we will learn how to run <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) pipelines in different execution environments and perform hyperparameter tuning, or <strong class="bold">hyperparameter optimization</strong> (<strong class="bold">HPO</strong>), at scale. We will start with an overview of the scenarios and requirements for executing DL pipelines in different environments. We will then learn how to use MLflow's <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) to run in four different execution scenarios in a distributed environment. From there on, we will learn how to choose the best HPO framework by comparing <strong class="bold">Ray Tune</strong>, <strong class="bold">Optuna</strong>, and <strong class="bold">HyperOpt</strong> for tuning hyperparameters of a DL pipeline. Finally, we will concentrate on how to implement and run HPO for DL at scale using state-of-the-art HPO frameworks such as Ray Tune and MLflow. </p>
			<p>This section comprises the following chapters:</p>
			<ul>
				<li><a href="B18120_05_ePub.xhtml#_idTextAnchor060"><em class="italic">Chapter 5</em></a>, <em class="italic">Running DL Pipelines in Different Environments</em></li>
				<li><a href="B18120_06_ePub.xhtml#_idTextAnchor069"><em class="italic">Chapter 6</em></a>, <em class="italic">Running Hyperparameter Tuning at Scale</em></li>
			</ul>
		</div>
	</div></body></html>