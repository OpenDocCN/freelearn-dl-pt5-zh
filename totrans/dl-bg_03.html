<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Setup and Introduction to Deep Learning Frameworks
                </header>
            
            <article>
                
<p>At this point, you are now familiar with <strong>machine learning</strong> (<strong>ML</strong>) and <strong>deep learning</strong> (<strong>DL</strong>) - this is great! You should feel ready to begin making the preparations for writing and running your own programs. This chapter helps you in the process of setting up TensorFlow and Keras, and introduces their usefulness and purpose in deep learning. Dopamine is presented as the new reinforcement learning framework that we will use later on. This chapter also briefly introduces other deep learning libraries that are important to know. </p>
<p>The topics that will be covered in this chapter are as follows:</p>
<ul>
<li>Introduction to Colaboratory</li>
<li>Introduction and setup of TensorFlow</li>
<li>Introduction and setup of Keras</li>
<li>Introduction to PyTorch</li>
<li>Introduction to Dopamine</li>
<li>Other deep learning libraries</li>
</ul>
<h1 id="uuid-264ecbc9-b660-468d-bc74-6ea68b3fea7b">Introduction to Colaboratory</h1>
<p>What is Colaboratory? Colaboratory is a web-based research tool for doing machine learning and deep learning. It is essentially like Jupyter Notebook. C<span>olab</span><span>ora</span><span>tory </span>is becoming very popular these days as it requires no setup.</p>
<div class="packt_infobox"><span>Throughout this book, we will be using Python 3 running on Colaboratory which will have installed all the libraries we may need. </span></div>
<p><span>Colaboratory</span> <span>is free to use and is compatible with most major browsers. The company in charge of the development of the Colaboratory tool is Google<sup>™</sup>. As opposed to Jupyter notebooks, in Colaboratory you are running everything on the cloud and not on your own computer. Here is the catch: you need a Google account since all the Colaboratory notebooks are saved into your personal Google Drive space. However, if you do not have a Google account, you can still continue reading to see how you can install every piece of Python library you will need to run things on your own. Still, I highly recommend you create a Google account, if only just to learn deep learning using the Colaboratory notebooks of this book.</span></p>
<p>When you run your code on <span>Colaboratory, it runs on a dedicated virtual machine, and here is the fun part: you can have a GPU allocated to use! Or you can also use a CPU if you want. Whenever you are not running something, Colaboratory will deallocate resources (you know, because we all want to work), but you can reconnect them at any time.</span></p>
<p>If you are ready, go ahead and navigate to this link: <a href="https://colab.research.google.com/">https://colab.research.google.com/</a><a href="https://colab.research.google.com/"/></p>
<p>If you are interested in more information and a further introduction to Colaboratory, search for <em>Welcome to Colaboratory!</em>. Now that you have accessed the previous link, let us get started with TensorFlow.</p>
<div class="packt_tip packt_infobox"><span>From now on, we will refer to <strong>Colaboratory</strong> as</span> <strong>Colab</strong><span> for short. This is actually how people refer to it.</span></div>
<h1 id="uuid-dd4013ef-9ed5-4ef1-8bb6-3a8d54bdf6cb">Introduction and setup of TensorFlow</h1>
<p><strong>TensorFlow</strong> (<strong>TF</strong>) has in its name the word <em>Tensor</em>, which is a synonym of vector. TF, thus, is a Python framework that is designed to excel at vectorial operations pertaining to the modeling of neural networks. It is the most popular library for machine learning.</p>
<p>As data scientists, we have a preference towards TF because it is free, opensource with a strong user base, and it uses state-of-the-art research on the graph-based execution of tensor operations. </p>
<h2 id="uuid-25485646-38e2-47d1-9756-2034eb20a875">Setup</h2>
<p><span>Let us now begin with instructions to set up or verify that you have the proper setup:</span></p>
<ol>
<li>To begin the installation of TF, run the following command in your Colaboratory:</li>
</ol>
<pre style="padding-left: 60px">%tensorflow_version 2.x<br/>!pip install tensorflow</pre>
<p style="padding-left: 60px">This will install about 20 libraries that are required to run TF, including <kbd>numpy</kbd>, for example.</p>
<div class="packt_infobox">Notice the exclamation mark (!) at the beginning of the command? This is how you will run shell commands on Colaboratory. For example, say that you want to remove a file named <kbd>model.h5</kbd>, then you would issue the command <kbd>!rm model.h5</kbd>.</div>
<ol start="2">
<li>If the execution of the installation ran properly, you will be able to run the following command, which will print the version of TF that is installed on your Colaboratory:</li>
</ol>
<pre style="padding-left: 60px">import tensorflow as tf<br/>print(tf.__version__)</pre>
<p style="padding-left: 60px">This will produce the following output:</p>
<pre style="padding-left: 60px"><span>2.1.0</span></pre>
<ol start="3">
<li>This version of TF is the current version of TF at the time of writing this book. However, we all know that TF versions change frequently and it is likely that there will be a new version of TF when you are reading this book. If that is the case, you can install a specific version of TF as follows:</li>
</ol>
<pre style="padding-left: 60px">!pip install tensorflow==2.1.0</pre>
<div class="packt_tip packt_infobox">We are assuming that you are familiar with Python, thus, we will trust you with the responsibility of matching the proper libraries to the versions that we are using in this book. This is not difficult and can easily be done as shown previously, for example, using the <kbd>==</kbd> sign to specify the version. We will be showing the versions used as we continue.</div>
<h3 id="uuid-5f201b5c-4e84-4647-bea2-7f11ab80216b">TensorFlow with GPU support</h3>
<p>Colaboratory, by default, has GPU support automatically enabled for TensorFlow. However, if you have access to your own system with a GPU and want to set up TensorFlow with GPU support, the installation is very simple. Just type the following command on your personal system:</p>
<div>
<pre><strong>$ pip install tensorflow-gpu</strong></pre></div>
<p>Notice, however, that this assumes that you have set up all the necessary drivers for your system to give access to the GPU. However, fear not, there is plenty of documentation about this process that can be searched on the internet, for example, <a href="https://www.tensorflow.org/install/gpu">https://www.tensorflow.org/install/gpu</a>. If you run into any problems and you need to move forward, I highly recommend that you come back and do the work on Colaboratory, as it is the easiest way to learn. </p>
<p>Let us now address how TensorFlow works and how its graph paradigm makes it very robust.</p>
<h2 id="uuid-fa366c90-37e7-45df-8b6a-4a911543b125">Principles behind TensorFlow</h2>
<p>This book is for absolute beginners in deep learning. As such, here is what we want you to know about how TF works. TF creates a graph that contains the execution from its input tensors, up to the highest level of abstraction of operations. </p>
<p>For example, let's say that we have tensors <em><strong>x</strong></em> and <em><strong>w</strong></em> that are known input vectors, and that we have a known constant <em>b</em>, and say that you want to perform this operation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/af40ade0-45f9-4dcb-acc5-f5c7296f964b.png" style="width:4.67em;height:1.42em;"/></p>
<p>If we create this operation by declaring and assigning tensors, the graph will look like the one in <em>Figure 2.1</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1d9b0258-46f6-44c7-a14d-425d966d2247.png" style="width:21.08em;height:15.83em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 2.1 - Example of a tensor multiplication and addition operation</div>
<p>In this figure, there is a tensor multiplication operation, <em>mul</em>, whose result is a scalar and needs to be added, <em>add</em>, with another scalar, <em>b</em>. Note that this might be an intermediate result and, in real computing graphs, the outcome of this goes up higher in the execution tree. For more detailed information on how TF uses graphs, please refer to this paper (Abadi, M., et.al., 2016). </p>
<p>In a nutshell, TF finds the best way to execute tensor operations delegating specific parts to GPUs if available, or otherwise parallelizing operations on the CPU cores if available. It is open source with a growing community of users around the world. Most deep learning professionals know about TF. </p>
<p><span>Now let us discuss how to set up Keras and how it abstracts TensorFlow functionalities</span><span>.</span> </p>
<h1 id="uuid-c2b26f54-dc43-4d7c-b720-0c8d7f3297ce">Introduction and setup of Keras</h1>
<p><span>If you search on the internet for sample TensorFlow code, you will find that it may not be super easy to understand or follow. You can find tutorials for beginners but, in reality, things can get complicated very easily and editing someone else's code can be very difficult. Keras comes as an API solution to develop deep learning Tensorflow model prototypes with relative ease. In fact, Keras supports running not only on top of TensorFlow, but also over CNTK and Theano.</span></p>
<p>We can think of Keras as an abstraction to actual TensorFlow models and methods. This symbiotic relationship has become so popular that TensorFlow now unofficially<em> </em>encourages its use for those who are beginning to use TensorFlow. Keras is very user friendly, it is easy to follow in Python, and it is easy to learn in a general sense.</p>
<h2 id="uuid-153a3a89-59bc-4ce5-a5c3-cc1563944eac">Setup</h2>
<p>To set up Keras on your Colab, do the following:</p>
<ol>
<li>Run the following command:</li>
</ol>
<pre style="padding-left: 60px">!pip install keras</pre>
<ol start="2">
<li>The system will proceed to install the necessary libraries and dependencies. Once finished, type and run the following code snippet:</li>
</ol>
<pre style="padding-left: 60px">import keras<br/>print(keras.__version__)</pre>
<p style="padding-left: 60px">This outputs a confirmation message of it using TensorFlow as the backend as well as the latest version of Keras, which <span>at the time of writing this book is 2.2.4. Thus, the output looks </span>like this:</p>
<pre style="padding-left: 60px">Using TensorFlow backend.<br/>2.2.4</pre>
<h2 id="uuid-c566d779-bf90-40d6-a5a8-e41c51ebc8e7">Principles behind Keras</h2>
<p>There are two major ways in which Keras provides functionality to its users: a sequential model and the Functional API.</p>
<p>These can be summarized as follows:</p>
<ul>
<li><strong>Sequential model</strong>: This refers to a way of using Keras that allows you to linearly (or sequentially) stack layer instances. A layer instance, in this case, has the same meaning as in our previous discussions in <a href="e3181710-1bb7-4069-825a-a235355bc116.xhtml">Chapter 1</a>, <em>Introduction to Machine Learning</em>. That is, a layer has some type of input, some type of behavior or main model operation, and some type of output.</li>
<li><strong>Functional API</strong>: This is the best way to go deeper in defining more complex models, such as merge models, models with multiple outputs, models with multiple shared layers, and many other possibilities. Don't worry, these are advanced topics that will become clear in further chapters. The Functional API paradigm gives the coder more freedom to do different innovative things.</li>
</ul>
<p>We can think of the sequential model as an easy way of starting with Keras, and the Functional API as the way to go for more complex problems. </p>
<p>Remember the shallow neural network from <a href="https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=25&amp;action=edit#post_24">Chapter 1</a><span>, </span><em>Introduction to Machine Learning</em>? Well, this is how you would do that model using the sequential model paradigm in Keras:</p>
<pre>from keras.models import Sequential<br/>from keras.layers import Dense, Activation<br/><br/>model = Sequential([<br/>    Dense(10, input_shape=(10,)),<br/>    Activation('relu'),<br/>    Dense(8),<br/>    Activation('relu'),<br/>    Dense(4),<br/>    Activation('softmax'),<br/>])</pre>
<p>The first two lines of code import the <kbd>Sequential</kbd> model and the <kbd>Dense</kbd> and <kbd>Activation</kbd> layers, respectively. A <kbd>Dense</kbd> layer is a fully connected neural network, whereas an <kbd>Activation</kbd> layer is a very specific way of invoking a rich set of activation functions, such as ReLU and SoftMax, as in the previous example (these will be explained in detail later).</p>
<p>Alternatively, you could do the same model, but using the <kbd>add()</kbd> method:</p>
<pre>from keras.models import Sequential<br/>from keras.layers import Dense, Activation<br/><br/>model = Sequential()<br/>model.add(Dense(10, input_dim=10))<br/>model.add(Activation('relu'))<br/>model.add(Dense(8))<br/>model.add(Activation('relu'))<br/>model.add(Dense(4))<br/>model.add(Activation('softmax'))</pre>
<p>This second way of writing the code for the neural model looks more linear, while the first one looks more like a Pythonic way to do so with a list of items. It is really the same thing and you will probably develop a preference for one way or the other. However, remember, both of the previous examples use the Keras sequential model.</p>
<p>Now, just for comparison purposes, this is how you would code the exact same neural network architecture, but using the Keras Functional API paradigm:</p>
<pre>from keras.layers import Input, Dense<br/>from keras.models import Model<br/><br/>inputs = Input(shape=(10,))<br/><br/>x = Dense(10, activation='relu')(inputs)<br/>x = Dense(8, activation='relu')(x)<br/>y = Dense(4, activation='softmax')(x)<br/><br/>model = Model(inputs=inputs, outputs=y)</pre>
<p>If you are an experienced programmer, you will notice that the Functional API style allows more flexibility. It allows you to define input tensors to use them as input to different pieces of the model, if needed. However, using the Functional API does assume that you are familiar with the sequential model. Therefore, in this book, we will start with the sequential model and move forward with the Functional API paradigm as we make progress toward more complex neural models.</p>
<p>Just like Keras, there are other Python libraries and frameworks that allow us to do machine learning with relatively low difficulty. At the time of writing this book, the most popular is Keras and the second most popular is PyTorch.</p>
<h1 id="uuid-38761ec6-dd15-40a6-8f5c-76bca85685a6">Introduction to PyTorch</h1>
<p><span>At the time of writing this book, PyTorch is the third most popular overall deep learning framework. Its popularity has been increasing in spite of being relatively new in the world compared to TensorFlow. One of the interesting things about PyTorch is that it allows some customizations that TensorFlow does not. Furthermore, PyTorch has the support of Facebook™. </span></p>
<p><span>Although this book covers TensorFlow and Keras, I think it is important for all of us to remember that PyTorch is a good alternative and it looks very similar to Keras. As a mere reference, here is how the exact same shallow neural network we showed earlier would look if coded in PyTorch:</span></p>
<pre>import torch<br/><br/>device = torch.device('cpu')<br/><br/>model = torch.nn.Sequential(<br/>          torch.nn.Linear(10, 10),<br/>          torch.nn.ReLU(),<br/>          torch.nn.Linear(10, 8),<br/>          torch.nn.ReLU(),<br/>          torch.nn.Linear(8, 2),<br/>          torch.nn.Softmax(2)<br/>        ).to(device)</pre>
<p>The similarities are many. Also, the transition from Keras to PyTorch should not be too difficult for the motivated reader, and it could be a nice skill to have in the future. However, for now, most of the interest of the community is on TensorFlow and all its derivatives, especially Keras. If you want to know more about the beginnings and basic principles of PyTorch, you might find this reading useful (Paszke, A., et.al., <span class="underline">2017)</span>.</p>
<h1 id="uuid-5c8cd57a-a2b2-4ce1-8e2f-87d273a81d78">Introduction to Dopamine</h1>
<p>An interesting recent development in the world of deep reinforcement learning is Dopamine. Dopamine is a framework for the fast prototyping of deep reinforcement learning algorithms. This book will deal very briefly with reinforcement learning, but you need to know how to install it.</p>
<p>Dopamine is known for being easy to use for new users in the world of reinforcement learning. Also, although it is not an official product of Google, most of its developers are Googlers. In its current state, at the time of writing this book, the framework is very compact and provides ready-to-use algorithms.</p>
<p>To install Dopamine, you can run the following command:</p>
<pre>!pip install dopamine-rl</pre>
<p>You can test the correct installation of Dopamine by simply executing the following command:</p>
<pre class="mce-root">import dopamine</pre>
<p class="mce-root">This provides no output, unless there are errors. Usually, Dopamine will make use of a lot of libraries outside of it to allow doing many more interesting things. Right now, some of the most interesting things one can do with reinforcement learning is to train agents with reward policies, which has direct applications in gaming.</p>
<p class="mce-root">As an example, see <em>Figure 2.2</em>, which displays a time snapshot of a video game as it learns, using policies that reinforce desired behavior depending on the actions taken by an agent:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/63c1363e-7bef-466b-92ce-e1314d83ce37.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 2.2 - Sample visualization of Dopamine's agent in a reinforcement learning problem in gaming </div>
<div class="packt_infobox">An agent in <span>reinforcement learning </span>is the piece that decides what action to take next. The agent accomplishes this by observing the world and the rules of the world. The more defined the rules are, the more constrained the result will be. If the rules are too loose, the agent may not make good decisions on what actions to take.</div>
<p>Although this book does not dive a great deal into reinforcement learning, we will cover an interesting gaming application in the last chapter of the book. For now, you can read the following white paper for more information about Dopamine (Castro, P. S., et.al., 2018).</p>
<h1 id="uuid-476fd0fd-f98b-4f68-9b5a-5df0061e169e">Other deep learning libraries</h1>
<p>Besides the big two, TensorFlow and Keras, there are other competitors that are making their way in the world of deep learning. We already discussed PyTorch, but there are more. Here we talk about them briefly.</p>
<h2 id="uuid-f6571a23-929b-40da-9d7a-7a908fb2936d">Caffe</h2>
<p>Caffe is also a popular framework developed at UC Berkeley (Jia, Y., et.al. 2014). It became very popular in 2015-2016. A few employers still demand this skillset and scholarly articles still mention its usage. However, its usage is in decay in part due to the major success of TF and the accessibility of Keras. </p>
<div class="packt_infobox">For more information about Caffe, visit: <a href="https://caffe.berkeleyvision.org">https://caffe.berkeleyvision.org</a>.<a href="https://caffe.berkeleyvision.org"/></div>
<p>Note also the existence of Caffe2, which is developed by Facebook and is open source. It was built based on Caffe, but now Facebook has its new champion, PyTorch.</p>
<h2 id="uuid-096b7729-ec62-4cf8-b029-3d8583fdc3ce" class="mce-root"><span>Theano</span></h2>
<p class="mce-root">Theano was developed by Yoshua Bengio's group at the University of Montreal in 2007 (<span>Al-Rfou, R., <em>et.al. </em>2016)</span>. Theano has a relatively old user base that probably saw the rise of TF. The latest major release was made in late 2017 and, although there are no clear plans of new major releases, updates are still being made by the community.</p>
<div class="mce-root packt_infobox">For more information about Theano, please visit: <br/>
<a href="http://deeplearning.net/software/theano/">http://deeplearning.net/software/theano/</a> </div>
<h2 id="uuid-b1035e4f-1a02-43e6-87e5-893572d3f6e0">Honorable mentions</h2>
<p>There are other alternatives out there that may not be as popular, for a variety of reasons, but are worth mentioning here in case their future changes. These are as follows:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p><strong>Name</strong></p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><strong>Developed by</strong></p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p class="mce-root"><strong>More information</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>MXNET</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p>Apache</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><a href="https://mxnet.apache.org/">https://mxnet.apache.org/</a></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>CNTK</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><span>Microsoft</span></p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><a href="https://cntk.ai">https://cntk.ai</a></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>Deeplearning4J</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><span>Skymind</span></p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><a href="https://deeplearning4j.org/">https://deeplearning4j.org/</a></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>Chainer</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><span>Preferred Networks</span></p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><a href="https://chainer.org/">https://chainer.org/</a></p>
</td>
</tr>
<tr>
<td class="CDPAlignLeft CDPAlign">
<p>FastAI</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p>Jeremy Howard</p>
</td>
<td class="CDPAlignLeft CDPAlign">
<p><a href="https://www.fast.ai/">https://www.fast.ai/</a></p>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"/>
<h1 id="uuid-08021b8e-c617-45b8-ac65-753752bc4084">Summary </h1>
<p>This introductory chapter showed how to set up the necessary libraries to run TensorFlow, Keras, and Dopamine. Hopefully, you will use Colabs to make things easier for you to learn. You also learned the basic mindset and design concept behind these frameworks. Although such frameworks are the most popular at the time of writing this book, there are other competitors out there, which we also introduced briefly.</p>
<p>At this point, you are all set to begin the journey to mastering deep learning. Our first milestone is to know how to prepare data for deep learning applications. This item is crucial for the success of the model. No matter how good the models are and how deep they are, if the data is not properly formatted or treated, it can lead to catastrophic performance results. For that reason, we will now go to <a href="8300fba9-620e-4bc3-8d81-3b02c5043a0d.xhtml">Chapter 3</a>, <em>Preparing Data.</em><span> </span>In that chapter, you will learn how to take a dataset and prepare it for the specific task you are trying to solve with a specific type of deep learning model. However, before you go there, please try to quiz yourself with the following questions. </p>
<h1 id="uuid-84142dca-d65b-481e-8ab5-78106aa77082">Questions and answers</h1>
<ol>
<li><strong>Does Colab run on my personal computer?</strong></li>
</ol>
<p style="padding-left: 60px">No, it runs in the cloud, but with some skill and setup, you could connect it to your own personal cloud.</p>
<p> </p>
<ol start="2">
<li><strong>Does Keras use GPUs? </strong></li>
</ol>
<p style="padding-left: 60px">Yes. Since Keras runs on TensorFlow (in the setup of this book) and TensorFlow uses GPUs, then Keras also does.</p>
<ol start="3">
<li><strong>What are the two main coding paradigms in Keras?</strong></li>
</ol>
<p style="padding-left: 60px">(A) Sequential model; (B) Functional API.</p>
<ol start="4">
<li><strong>Why do we care about Dopamine?</strong></li>
</ol>
<p style="padding-left: 60px">Because there are only a few reinforcement learning frameworks you can trust out there, and Dopamine is one of them.</p>
<h1 id="uuid-9bf22a42-810f-46a9-a51b-341ce5baab4e">References</h1>
<ul>
<li><span>Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., and Kudlur, M. (2016). <em>Tensorflow: A system for large-scale machine learning.</em> In<em> </em></span><em>12th {USENIX} Symposium on Operating Systems Design and Implementation</em> ({OSDI} 16)<span> (pp. 265-283).</span></li>
<li>Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., <span>Lin, Z., Desmaison, A., Antiga, L.</span> and Lerer, A. (2017). <em>Automatic differentiation in pytorch.</em></li>
<li>Castro, P. S., Moitra, S., Gelada, C., Kumar, S., and Bellemare, M. G. (2018). <em>Dopamine: A research framework for deep reinforcement learning</em>. arXiv preprint arXiv:1812.06110.</li>
<li><span>Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., and Darrell, T. (2014, November). <em>Caffe: Convolutional architecture for fast feature embedding.</em> In </span><em>Proceedings of the 22nd ACM</em> <em>international conference on Multimedia</em><span> (pp. 675-678). <em>ACM</em>.</span></li>
<li><span>Al-Rfou, R., Alain, G., Almahairi, A., Angermueller, C., Bahdanau, D., Ballas, N., Bastien, F., Bayer, J., Belikov, A., Belopolsky, A. and Bengio, Y. (2016). <em>Theano: A Python framework for fast computation of</em> <em>mathematical expressions</em>. </span>arXiv preprint arXiv:1605.02688<span>.</span></li>
</ul>


            </article>

            
        </section>
    </body></html>