["```py\nfrom torch import nn\nfinal_fc_layer = nn.Sequential(\n  nn.Linear(10, 1),\n  nn.Softmax(),\n)\n```", "```py\nfinal_fc_layer = nn.Sequential(\n  nn.Linear(10, 100),\n  nn.Softmax(),\n)\n```", "```py\nfinal_fc_layer = nn.Linear(10, 1)\n```", "```py\n    import json\n    import osimport numpy as np\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from catalyst import dl, utils\n    from catalyst.contrib.datasets import MNIST\n    from sklearn import datasets\n    from sklearn.metrics import log_loss\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import MinMaxScaler\n    from torch import nn as nn\n    from torch import optim\n    from torch.utils.data import DataLoader\n    from torch.utils.data import TensorDataset\n    from catalyst.loggers.mlflow import MLflowLogger\n    ```", "```py\n    torch.manual_seed(0)\n    ```", "```py\n    iris = datasets.load_iris()\n    iris_input_dataset = iris['data']\n    target = torch.from_numpy(iris['target'])\n    ```", "```py\n    scaler = MinMaxScaler()\n    scaler.fit(iris_input_dataset)\n    iris_input_dataset = torch.from_numpy(scaler.transform(iris_input_dataset)).float()\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(iris_input_dataset, target, test_size=0.33, random_state=42)\n    ```", "```py\n    training_dataset = TensorDataset(X_train, y_train)\n    validation_dataset =  TensorDataset(X_test, y_test)\n    train_loader = DataLoader(training_dataset, batch_size=10, num_workers=1)\n    valid_loader = DataLoader(validation_dataset, batch_size=10, num_workers=1)\n    loaders = {\"train\": train_loader, \"valid\": valid_loader}\n    ```", "```py\n    criterion = nn.CrossEntropyLoss()\n    ```", "```py\n    runner = dl.SupervisedRunner(\n        input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n    )\n    ```", "```py\n    def get_random_configurations(\n      number_of_configurations, rng\n    ):\n      layer_configurations = []\n      for _ in range(number_of_configurations):\n        layer_configuration = []\n        number_of_hidden_layers = rng.randint(low=1, high=6)\n        for _ in range(number_of_hidden_layers):\n          layer_configuration.append(rng.randint(low=2, high=100))\n          layer_configurations.append(\n            layer_configuration\n            )\n          layer_configurations = np.array(\n            layer_configurations\n          )\n      return layer_configurations\n    rng = np.random.RandomState(1234)\n    number_of_configurations = 20\n    layer_configurations = get_random_configurations(\n      number_of_configurations, rng\n    )\n    ```", "```py\n    def train_and_evaluate_mlp(\n        trial_number, layer_configuration, epochs,\n    ):\n    ```", "```py\n        model = MLP(\n            input_layer_size=iris_input_dataset.shape[1],\n            layer_configuration=layer_configuration,\n            output_layer_size=len(np.unique(target)),\n        )\n    ```", "```py\n        optimizer = optim.Adam(model.parameters(), lr=0.02)\n    checkpoint_logdir = \"experiments\"\n    ```", "```py\n        loggers = {\n          \"mlflow\": MLflowLogger(\n            experiment=\"test_exp\", run=\"test_run\"\n          )\n        }\n    ```", "```py\n        runner.train(\n            model=model,\n            hparams=hparams,\n            criterion=criterion,\n            optimizer=optimizer,\n            loaders=loaders,\n            num_epochs=epochs,\n            callbacks=[\n                dl.CheckpointCallback(\n                    logdir=checkpoint_logdir,\n                    #save_n_best=0,\n                    loader_key=\"valid\",\n                    metric_key=\"loss\",\n                    mode=\"model\",\n                )\n            ],\n            logdir=\"./logs\",\n            valid_loader=\"valid\",\n            valid_metric=\"loss\",\n            minimize_valid_metric=True,\n            verbose=verbose,\n            loggers=loggers\n        )\n    ```", "```py\n    for layer_config in layer_configurations:\n        train_and_evaluate_mlp(\n            trial_number,\n            layer_config,\n            epochs=10,\n            load_on_stage_start=False\n        )\n    ```", "```py\n     mlflow server –backend-store-uri mlruns\n    ```", "```py\n    [catalyst]\n    cv_required = false\n    mlflow_required = true\n    ml_required = true\n    neptune_required = false\n    optuna_required = false\n    ```", "```py\n    import torch\n    import random\n    import numpy as np\n    torch.manual_seed(0)\n    random.seed(seed)\n    np.random.seed(seed)\n    ```", "```py\n    import tensorflow as tf\n    tf.keras.utils.set_random_seed(seed)\n    ```"]