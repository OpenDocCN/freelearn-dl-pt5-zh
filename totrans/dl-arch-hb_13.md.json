["```py\n    import os\n    import albumentations as albu\n    import numpy as np\n    import pandas as pd\n    import torch\n    import torch.nn as nn\n    from albumentations.pytorch.transforms import ToTensorV2\n    from PIL import Image\n    from sklearn.model_selection import StratifiedShuffleSplit\n    from torch.optim import SGD, Adam\n    from torch.utils.data import DataLoader, Dataset\n    from torchvision import models\n    from torchvision.models import resnet50\n    import mlflow\n    from catalyst import dl, utils, metrics\n    from catalyst.contrib.layers import ArcFace\n    from catalyst.loggers.mlflow import MLflowLogger\n    from captum.attr import IntegratedGradients\n    from captum.attr import NoiseTunnel\n    from captum.attr import visualization as viz\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n    ```", "```py\n    batch_size = 64\n    val_batch_size = 100\n    lr = 0.05\n    num_epochs = 20\n    early_stopping_epochs = 12\n    reduce_lr_patience = 3\n    ```", "```py\n    priviledged_group = 'Male'\n    unpriviledged_group = 'Female'\n    ```", "```py\n    experiment_mlflow = \"bias_mitigation_v1\"\n    logdir = 'experiments/face_modelv1'\n    only_male=False\n    distill_model=False\n    ```", "```py\n    train = pd.read_csv('face_age_gender.csv')\n    image_path = train['image_path'].values\n    targets = train['target'].values\n    gender_data = train['gender'].values\n    ```", "```py\n    name2class = {name: idx for idx, name in enumerate(sorted(set(targets)))}\n    id_targets = np.array([name2class[target] for target in targets])\n    num_classes = len(name2class)\n    ```", "```py\n    splitter = StratifiedShuffleSplit(test_size=.20, n_splits=2, random_state = 7)\n    split = splitter.split(image_path, targets)\n    train_inds, val_inds = next(split)\n    train_images = image_path[train_inds]\n    val_images = image_path[val_inds]\n    train_targets = id_targets[train_inds]\n    val_targets = id_targets[val_inds]\n    train_gender_data = gender_data[train_inds]\n    val_gender_data = gender_data[val_inds]\n    if only_male:\n        pass\n    ```", "```py\n    class ARCResNet50(nn.Module):\n        def __init__(self, num_classes):\n            super(ARCResNet50, self).__init__()\n            self.model =  models.resnet50(pretrained=True)\n            s=2**0.5*np.log(num_classes - 1)\n            s=13\n            self.model.fc = nn.Linear(self.model.fc.in_features, self.model.fc.in_features)\n            self.head = ArcFace(self.model.fc.out_features, num_classes, s=s, m=0.15)\n        def get_last_conv_features(self, x):\n            pass\n        def special_forward(self, x, targets=None):\n            pass\n        def forward(self, x, targets=None):\n            outputs = self.model(x)\n            outputs = self.head(outputs, targets)\n            return outputs\n    ```", "```py\n    if distill_model:\n        pass\n    model = ARCResNet50(num_classes=num_classes)\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=reduce_lr_patience, factor=0.1)\n    ```", "```py\n    class ImagesDataset(Dataset):\n        def __init__(self, files, sensitive_attributes, targets=None, transforms=None, teacher_model_features=None):\n            self.files = files\n            self.sensitive_attributes = sensitive_attributes\n            self.targets = targets\n            self.transforms = transforms\n            self.teacher_model_features = teacher_model_features\n        def __len__(self):\n            return len(self.files)\n        def __getitem__(self, index):\n            file = self.files[index]\n            img = np.array(Image.open(file))\n            if self.transforms is not None:\n                img = self.transforms(image=img)[\"image\"]\n            if self.targets is None:\n                return img\n            target = self.targets[index]\n            sensitive_attribute = self.sensitive_attributes[index]\n            if self.teacher_model_features is None:\n                return img, sensitive_attribute, target\n            else:\n                teacher_model_feature = torch.from_numpy(self.teacher_model_features[index])\n                return img, sensitive_attribute, target, teacher_model_feature\n    ```", "```py\n    def get_transforms(dataset: str):\n         if dataset.lower() == \"train\":\n               return albu.Compose([\n               albu.Resize(224, 224),\n                albu.HorizontalFlip(),\n                albu.Normalize(),\n                ToTensorV2()\n            ])\n        else:\n          return albu.Compose([ albu.Resize(224, 224), albu.Normalize(), ToTensorV2()])\n    ```", "```py\n    if distill_model:\n        pass\n    else:\n        train_dataset = ImagesDataset(train_images, train_gender_data, train_targets,  get_transforms('train'))\n        val_dataset =  ImagesDataset(val_images, val_gender_data, val_targets, get_transforms('valid'))\n    loaders = {\"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8),\n               \"valid\": DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=8)}\n    ```", "```py\n    def compute_classwise_stats(y_pred, y_true):\n        unique_classes = np.unique(y_true)\n        num_classes = len(unique_classes)\n        false_positives = np.zeros(num_classes)\n        total_negatives = np.zeros(num_classes)\n        true_positives = np.zeros(num_classes)\n        total_positives = np.zeros(num_classes)\n        for c_idx in range(num_classes):\n            class_label = unique_classes[c_idx]\n            class_predictions = (y_pred == class_label)\n            class_labels = (y_true == class_label)\n            false_positives[c_idx] = np.sum(class_predictions & ~class_labels)\n            total_negatives[c_idx] = np.sum(~class_labels)\n            true_positives[c_idx] = np.sum(class_predictions & class_labels)\n            total_positives[c_idx] = np.sum(class_labels)\n        return {\n            \"false_positives\":false_positives,\n            \"total_negatives\": total_negatives,\n            \"true_positives\": true_positives,\n            \"total_positives\": total_positives,\n            \"total\": total_negatives + total_positives,\n        }\n    def safe_division(a, b):\n        return a/b if b else 0.0\n    ```", "```py\n    def compute_multiclass_fairness_metrics(\n      y_pred, y_true, sensitive_attribute, priviledged_group, unpriviledged_group\n    ):\n    ```", "```py\n      y_pred = y_pred.argmax(1)\n      group_stats = {}\n      for group in [priviledged_group, unpriviledged_group]:\n        group_idx = sensitive_attribute == group\n        group_stats[group] = compute_classwise_stats(\n          y_pred[group_idx], y_true[group_idx])\n    ```", "```py\n      disparities = []\n      priviledged_true_positive_ratio = safe_division(\n        np.sum(group_stats[priviledged_group][\"true_positives\"]),np.sum(group_stats[unpriviledged_group][\"total\"]))\n      unpriviledged_true_positive_ratio = safe_division(\n        np.sum(group_stats[unpriviledged_group][\"true_positives\"]),np.sum(group_stats[unpriviledged_group][\"total\"]))\n    ```", "```py\n      disparate_impact = safe_division(unpriviledged_true_positive_ratio, priviledged_true_positive_ratio)\n      statistical_parity_diff = priviledged_true_positive_ratio - unpriviledged_true_positive_ratio\n    ```", "```py\n      for group in [priviledged_group, unpriviledged_group]:\n        group_stats[group][\"fpr\"] = safe_division(\n          np.sum(group_stats[priviledged_group][\"false_positives\"]),np.sum(group_stats[priviledged_group][\"total_negatives\"]))\n        group_stats[group][\"tpr\"] = safe_division(\n          np.sum(group_stats[priviledged_group][\"true_positives\"]),\n    np.sum(group_stats[priviledged_group][\"total_positives\"])\n            )\n      AOD = (\n            (group_stats[unpriviledged_group][\"fpr\"] - group_stats[priviledged_group][\"fpr\"])\n            + (group_stats[unpriviledged_group][\"tpr\"] - group_stats[priviledged_group][\"fpr\"])\n        ) / 2\n      AAOD = (\n            np.abs(group_stats[unpriviledged_group][\"fpr\"] - group_stats[priviledged_group][\"fpr\"])\n            + np.abs(group_stats[unpriviledged_group][\"tpr\"] - group_stats[priviledged_group][\"fpr\"])\n        ) / 2\n        return {\n            \"disparate_impact\": disparate_impact,\n            \"statistical_parity_diff\": statistical_parity_diff,\n            \"average_odds_diff\": AOD,\n            \"average_abs_odds_diff\": AAOD\n        }\n    ```", "```py\n    mlflow_params = dict(\n        batch_size=batch_size,\n        lr=lr,\n        num_epochs=num_epochs,\n        early_stopping_epochs=early_stopping_epochs,\n        reduce_lr_patience=reduce_lr_patience,\n        experiment_mlflow=experiment_mlflow,\n        logdir=logdir,\n        only_male=only_male,\n        distill_model=distill_model,\n    )\n    all_metrics = [\n        \"loss\", \"accuracy\", \"disparate_impact\",\"statistical_parity_diff\", \"average_odds_diff\",\"average_abs_odds_diff\"\n    ]\n    mlflow_logger = MLflowLogger(experiment=experiment_mlflow, tracking_uri=\"experiment/\")\n    mlflow_logger.log_hparams(mlflow_params)\n    ```", "```py\n    class CustomRunner(dl.Runner):\n      def on_loader_start(self, runner):\n        super().on_loader_start(runner)\n        self.meters = {key: metrics.AdditiveMetric(compute_on_call=False)\n                for key in all_metrics}\n    ```", "```py\n      def handle_batch(self, batch):\n        is_distill_mode = len(batch) == 4\n        if is_distill_mode:\n          pass\n        else:\n          features, sensitive_attribute, targets = batch\n          logits = self.model(features, targets)\n          loss = self.criterion(logits, targets)\n        accuracy = (logits.argmax(1) == targets).float().mean().detach().cpu()\n        batch_metrics = {\n          \"loss\": loss.item(),\"accuracy\": accuracy.item()}\n        batch_metrics.update(\n    **compute_multiclass_fairness_metrics(logits.detach().cpu().numpy(), targets.detach().cpu().numpy(), np.array(sensitive_attribute),priviledged_group,\n    unpriviledged_group))\n    ```", "```py\n        self.batch_metrics.update(batch_metrics)\n          for key in all_metrics:\n            self.meters[key].update(\n              self.batch_metrics[key], self.batch_size\n            )\n            if self.is_train_loader:\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n    ```", "```py\n      def on_loader_end(self, runner):\n            for key in all_metrics:\n                self.loader_metrics[key] = self.meters[key].compute()[0]\n            if runner.is_valid_loader:\n                runner.scheduler.step(self.loader_metrics[self._valid_metric])\n            super().on_loader_end(runner)\n      def get_loggers(self):\n            return {\n                \"console\": dl.ConsoleLogger(),\n                \"mlflow\": mlflow_logger\n            }\n    ```", "```py\n    runner = CustomRunner()\n    runner.train(\n        model=model,\n        criterion=criterion,\n        optimizer=optimizer,\n        loaders=loaders,\n        logdir=logdir,\n        num_epochs=num_epochs,\n        valid_loader=\"valid\",\n        valid_metric=\"loss\", # loss\"\n        minimize_valid_metric=True,\n        fp16=False,\n        verbose=True,\n        load_best_on_end=True,\n        scheduler=scheduler,\n        callbacks=[\n            dl.EarlyStoppingCallback(\n                patience=early_stopping_epochs, loader_key=\"valid\", metric_key=\"loss\", minimize=True\n            ),\n            dl.CheckpointCallback(\n                logdir=logdir, save_best=True, load_best_on_end=True, metric_key='loss'\n            )\n        ]\n    )\n    ```", "```py\n    resize_transform = albu.Resize(224, 224)\n    norm_transform = albu.Compose([\n                albu.Normalize(),\n                ToTensorV2()\n            ])\n    ```", "```py\n    val_df = pd.read_csv('val_pose_info.csv')\n    straight_indexes = val_df[\n        (val_df['pitch']>-10) &\n        (val_df['pitch']<10) &\n        (val_df['yaw']>-10) &\n        (val_df['yaw']<10)\n    ].index.values\n    ```", "```py\n    integrated_gradients = IntegratedGradients(model)\n    noise_tunnel = NoiseTunnel(integrated_gradients)\n    for val_idx in straight_indexes[:5]: #range(1):\n        image_path = val_images[val_idx]\n        pred_label_idx = val_targets[val_idx]\n        pil_image = Image.open(image_path)\n        img = np.array(pil_image)\n        transformed_image = resize_transform(image=img)[\"image\"]\n        input =  norm_transform(image=img)[\"image\"].unsqueeze(0)\n        attributions_ig_nt = noise_tunnel.attribute(\n            input, nt_samples=5, nt_type=\"smoothgrad_sq\",\n            target=int(pred_label_idx)\n        )\n        _ = viz.visualize_image_attr_multiple(\n            np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n            transformed_image,\n            [\"original_image\", \"heat_map\"],\n            [\"all\", \"positive\"],\n            cmap=\"turbo\",\n            show_colorbar=True\n        )\n    ```", "```py\n    batch_size = 64\n    lr = 0.05\n    num_epochs = 22\n    early_stopping_epochs = 12\n    reduce_lr_patience = 3\n    experiment_mlflow = \"bias_mitigation_v2\"\n    logdir = 'experiments/face_modelv2'\n    only_male=False\n    distill_model=False\n    ```", "```py\n    if only_male:\n      train_raw_targets = targets[train_inds]\n      val_raw_targets = targets[val_inds]\n      train_male_inds = np.where(train_gender_data=='Male')[0]\n      train_images = train_images[train_male_inds]\n      train_targets = train_targets[train_male_inds]\n      train_gender_data = train_gender_data[train_male_inds]                          val_male_inds = np.where(\n      val_gender_data=='Male')[0]\n      val_images = val_images[val_male_inds]\n      val_targets = val_targets[val_male_inds]\n      val_gender_data = val_gender_data[val_male_inds]\n    ```", "```py\n    def get_last_conv_features(self, x):\n            x = self.model.conv1(x)\n            x = self.model.bn1(x)\n            x = self.model.relu(x)\n            x = self.model.maxpool(x)\n            x = self.model.layer1(x)\n            x = self.model.layer2(x)\n            x = self.model.layer3(x)\n            x = self.model.layer4(x)\n            x = self.model.avgpool(x)\n            x = torch.flatten(x, 1)\n            return x\n        def special_forward(self, x, targets=None):\n            model_features = self.get_last_conv_features(x)\n            outputs = self.model.fc(model_features)\n            outputs = self.head(outputs, targets)\n            return outputs, model_features\n    ```", "```py\n    device = torch.device(\"cuda\")\n    if distill_model:\n      if os.path.exists('all_teacher_model_features.npy'):\n        all_teacher_model_features = np.load('all_teacher_model_features.npy')\n     else:\n        teacher_model = ARCResNet50(num_classes=num_classes)\n        state_dict = torch.load(os.path.join(distill_model, \"model.last.pth\"))\n        teacher_model.load_state_dict(state_dict)\n        teacher_model.to(device)\n        cpu_device = torch.device('cpu')\n        entire_dataset =  ImagesDataset(image_path, gender_data, targets=id_targets, transforms=get_transforms('valid'))\n        entire_data_loader = DataLoader(entire_dataset, batch_size=val_batch_size, shuffle=False, num_workers=8)\n        all_teacher_model_features = []\n        for batch in tqdm_notebook(entire_data_loader):\n          inputs, sensitive_attribute, targets = batch\n          with torch.no_grad():\n            outputs = teacher_model.get_last_conv_features(inputs.to(device)).to(cpu_device).numpy()\n          all_teacher_model_features.append(outputs)\n        del teacher_model\n        all_teacher_model_features = np.vstack(all_teacher_model_features)\n        np.save('all_teacher_model_features.npy', all_teacher_model_features)\n        train_teacher_model_features = all_teacher_model_features[train_inds]\n        val_teacher_model_features = all_teacher_model_features[val_inds]\n    ```", "```py\n    if distill_model:\n        train_dataset = ImagesDataset(\n            train_images,\n            train_gender_data,\n            train_targets,\n            get_transforms('train'),\n            train_teacher_model_features,\n        )\n        val_dataset =  ImagesDataset(\n            val_images,\n            val_gender_data,\n            val_targets,\n            get_transforms('valid'),\n            val_teacher_model_features,\n        )\n    ```", "```py\n    if is_distill_mode:\n      features, sensitive_attribute, targets, teacher_model_features = batch\n      logits, child_model_features = self.model.special_forward(features, targets)\n      loss = self.criterion(logits, targets) + nn.functional.cosine_similarity(teacher_model_features, child_model_features).mean()\n    ```", "```py\n    batch_size = 64\n    val_batch_size = 100\n    lr = 0.05\n    num_epochs = 150\n    early_stopping_epochs = 5\n    reduce_lr_patience = 2\n    experiment_mlflow = \"bias_mitigation_v3\"\n    logdir = 'experiments/face_modelv3'\n    only_male=False\n    distill_model = 'experiments/face_modelv2'\n    ```"]