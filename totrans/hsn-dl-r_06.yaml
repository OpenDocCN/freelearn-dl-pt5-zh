- en: CNNs for Image Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn to use **convolutional neural networks** (**CNNs**)
    for image recognition. Convolutional neural networks are a variation of neural
    networks that are particularly well-suited to image recognition because they take
    into account the relationship between data points in space.
  prefs: []
  type: TYPE_NORMAL
- en: We will cover how convolutional neural networks differ from the basic feedforward,
    fully connected neural network that we created in the last chapter. The main difference
    is that the hidden layers in a CNN are not all fully connected dense layers—CNNs
    include a number of special layers. One of these is the convolutional layer, which
    convolves a filter around the image space. The other special layer is a pooling
    layer, which reduces the size of the input and only persists particular values.
    We will go into more depth on these layers later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: As we learn about these concepts, we will see why they are so critical for image
    recognition. When we think about classifying images, we know that we need to detect
    patterns among arrays of pixels and that the neighboring pixels are important
    for finding certain shapes. By learning more about the convolution layer, you
    will know how to adjust the filter or lens to detect different patterns depending
    on your image data. You will also learn how to adjust the pooling layer depending
    on the size of your data to help make your model run more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, this chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Image recognition with shallow nets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image recognition with convolutional neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhancing the model with appropriate activation layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing the most appropriate activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting optimal epochs using dropout and early stopping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the code files of this chapter on the GitHub link at [https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R](https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R).
  prefs: []
  type: TYPE_NORMAL
- en: Image recognition with shallow nets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image classifiers can be created without using deep-learning algorithms and
    methods. To demonstrate, let's use the **Fashion MNIST** dataset, which is an
    alternative to the MNIST handwriting dataset. The name MNIST stands for the **Modified
    National Institute of Standards and Technology** database, and as the name suggests,
    it is a modified version of the original dataset created by the National Institute
    of Standards and Technology. While MNIST is a series of hand-drawn numbers, Fashion
    MNIST uses small images of different types of clothing. The clothing in the dataset
    is labeled with one of ten categories. Fashion MNIST has nothing to do with the
    National Institute of Standards and Technology; however, the MNIST name carried
    over since it is well-known as a database to use for image recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this dataset is not very large and each image is only 28 x 28 pixels,
    we can use a machine-learning algorithm, such as `RandomForest`, to train a classifier.
    We will train a very simple `RandomForest` model and achieve surprisingly good
    results; however, at the end of the chapter, we will discuss why these same results
    will not scale as the dataset gets larger and the individual images get larger.
    We will now code our image recognition model using traditional machine-learning
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by loading the `tidyverse` suite of packages, as shown in the
    following code. In this case, we only need `readr` for reading in the data; however,
    we will use other packages later. We will also load `randomForest` for training
    our model and `caret` for evaluating our model performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The code here will not return any values to the console; however, within the
    RStudio environment, we will see a checkmark next to these packages in the Packages
    window indicating that they are ready to be used. Your Packages pane should look
    like the following image, which shows that two of three packages have been loaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef79de23-1f1c-4dec-a4b8-363f52a0cf02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we read in the train and test data for the Fashion MNIST dataset with
    the help of the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will place two data objects in our environment called `fm` and `fm_test`.
    The Environment pane should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed554320-b06f-479e-9879-3d053ff5b72b.png)'
  prefs: []
  type: TYPE_IMG
- en: We will use `fm` to train our model. The data from `fm` will be used to compute
    weights for splits along this tree-based model. We will then use our model, which
    contains information on how the independent variable values relate to the target
    variables, to predict target variables for the `fm_test` data using the independent
    variable values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will train our model. We set a seed for reproducibility so that we
    get the same quasirandom numbers every time we run the model, and as such, we
    always get the same results. We convert the label to a factor. The label, in this
    case, is an integer between `0` and `9`; however, we do not want the model to
    treat these values numerically. Instead, they should be treated as different categories.
    The remaining columns aside from the label are all pixel values. We use `~`. to
    denote that we will use all the remaining columns (all the pixel values) as independent
    variables for our model. We will grow 10 trees because this is simply an example
    that image classification can be done this way. Lastly, we will choose 5 variables
    at random during every split in our tree. We will train our `RandomForest` model
    in this way using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When we execute the code, the model will run, which can take several minutes.
    During this time, we will be unable to execute any code in the console. We can
    see that the model is now in our environment. The following screenshot shows some
    of the details contained in the model object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/da2a3770-a604-46c2-a5d3-8504de4975dc.png)'
  prefs: []
  type: TYPE_IMG
- en: We can use this model object to make predictions on new data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then use our model to make predictions on the test dataset and use the `ConfusionMatrix`
    function to evaluate performance. The following code will populate the vector
    of predicted values and then evaluate the accuracy of the predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code will create one last data object, which is a vector that
    holds the predicted values for each case based on the model being trained on the
    independent variables for that dataset. We also printed some output to our console
    with performance metrics. The output that you receive will look like the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/290bca6f-c0fa-4d7d-867c-2bc193432f05.png)'
  prefs: []
  type: TYPE_IMG
- en: The metrics are based on comparing the actual target variables for the test
    dataset with the predicted values from modeling on the test data.
  prefs: []
  type: TYPE_NORMAL
- en: Surprisingly, this model produced decent results. We have achieved an accuracy
    of 84.6%. This shows that a simple approach can work for a dataset like this;
    however, as the data scales up, this type of model will have worse performance.
  prefs: []
  type: TYPE_NORMAL
- en: To understand why, we should first explain how images are stored as data for
    modeling. When we view a grayscale image, we see lighter and darker areas. In
    fact, every pixel holds an integer from 0 for white to 255 for black and anywhere
    in between. These numbers are converted into tones so that we can visualize the
    image; however, for our purposes, we use these raw pixel values. When modeling
    with `RandomForest`, each pixel value is compared in isolation with all the other
    images; however, this is rarely ideal. Usually, we want to look for larger patterns
    of pixels within each image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explore how to create a shallow neural network with just one layer.
    The hidden layer of the neural network will perform a calculation using all input
    values so that the entire image is considered. We are going to make this a simple
    binominal classification problem for illustration purposes and use a method to
    create our neural network that is similar to the method we used in the last chapter.
    If you completed that chapter, then this will likely look familiar. Completing
    the previous chapter is not a prerequisite as we will walk through all the steps
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting, we will load two more libraries for the following code: the
    `neuralnet` package for training our model and the `Metrics` package for evaluation
    functions. In particular, we will use the AUC metric later to evaluate our model.
    Both of these libraries can be loaded by running the following lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will not cause anything to happen in the console; however, we will
    see checks by these packages in the Package pane indicating that these packages
    are ready to use. Your Packages pane will look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb517d20-8e51-418d-beb9-ff46289e7e4b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First, we will change the **target** column so that it is a simple binary response
    rather than include all ten categories. This is done so that we can keep this
    neural network very straightforward, as this is just to create a benchmark for
    comparing with our CNN later and to show how coding the two styles of neural networks
    differs. This filtering is accomplished by running the following lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this code, we will see that the size of our data objects has
    changed and reduced in size as a result of our filtering. You should see that
    your data objects have changed from having 60,000 and 10,000 observations respectively
    to 12,000 and 2,000, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d415b2a-5859-452d-a0da-928b777adca7.png)'
  prefs: []
  type: TYPE_IMG
- en: With the data in this format, we are now able to proceed with writing our code
    as a binary response task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, using the following code, we will remove the target variable from the
    test set and isolate it in a separate vector for evaluation later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this code you will notice two changes: there is one less variable
    or column in the `fm_test` object and there is a new data object called `test_label`,
    which is a vector containing the values that were in the label column of the `fm_test`
    object. Your Environment pane should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b22efddd-8ddf-4e73-b21e-696ec062c3b4.png)'
  prefs: []
  type: TYPE_IMG
- en: We have made this change because we do not want the label in our test object.
    In this object, we need to treat the data as if we do not know the true classes
    so that we can try to predict the classes. We then use the labels from the vector
    later to evaluate how well we predicted the correct values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create the formula for our neural network. Using the `neuralnet`
    function from the `neuralnet` package, we need our formula to be formatted with
    the target variable on one side of a tilde (`~`) and all of our independent variables
    on the other side connected by plus (`+`) signs. In the following code, we collect
    all columns names into a vector `n` and then use `paste` to concatenate each term
    from this vector with a plus sign in between:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this code, we can see the changes in our Environment pane. We
    will see the vector `n` that contains all the column names and the `formula` object
    that has the dependent variable and independent variables placed together in the
    proper format. Your Environment pane should now look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62fabd77-496c-4c49-8dd8-9e5123e58fd1.png)'
  prefs: []
  type: TYPE_IMG
- en: We ran the preceding code in order to create this `formula` object as it is
    a requirement for training a neural network using the `neuralnet` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, we can write the code to train our model. We will set a seed for
    reproducibility as we always do with modeling. We will include one hidden layer
    with the number of units set to approximately one-third the number of predictor
    variables. We will set the `linear.output` argument to `false` to denote that
    this will be a classification model. We will also set the activation function
    to `logistic` because this is a classification problem. We train our model in
    the way we described earlier using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the code, we now have a new object in our Environment pane that
    contains all the details gathered from training our model that can now be applied
    to make predictions on new data. Your Environment pane should contain a model
    object similar to the one shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb9fd321-7063-49a5-be27-e18439503605.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have run this code, we have a model that we can use to make predictions
    on our test data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we can make our predictions and evaluate our results with the help
    of the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code will print the accuracy metric to the console. Your console
    should contain output just like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f1b7f45-9822-4112-a552-62f676557d51.png)'
  prefs: []
  type: TYPE_IMG
- en: Looking at this output, we see that we have a significant improvement already.
    Accuracy is now up to 97.487%. When the pixels were considered in concert, it
    did improve results. We should remember that this model only used two target variables,
    and the selection of these target variables could also be part of the reason for
    the significant increase. In any case, with larger images, it is not efficient
    to push all pixel values to an activation function. This is where convolutional
    neural networks come in to solve this problem. They are able to look at smaller
    groupings of pixel values to look for patterns. They also contain a means of reducing
    dimensionality.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now explore what separates convolutional neural networks from traditional
    neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Image recognition with convolutional neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Convolutional neural networks are a special form of neural network. In a traditional
    neural network, the input is passed to the model as vectors; however, for image
    data, it is more helpful to have the data arranged as matrices because we want
    to capture the relationship of the pixel values in two-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks are able to capture these two-dimensional relationships
    through the use of a filter that convolves over the image data. The filter is
    a matrix with constant values and dimensions that are smaller than the image data.
    The constant values are multiplied by the underlying values and the sum of the
    resulting products is passed through to an activation function.
  prefs: []
  type: TYPE_NORMAL
- en: The activation function step, which can also be considered a separate layer,
    evaluates whether a given pattern is present in an image. In a traditional neural
    network, the activation layer determines whether the calculated value from the
    input values exceeds a threshold and should be fed forward in the model. In a
    convolutional neural network, the activation layer operates in a very similar
    way; however, because it uses matrix multiplication, it is able to evaluate whether
    a two-dimensional shape is present in the data.
  prefs: []
  type: TYPE_NORMAL
- en: After the activation layer, the data is further processed by a pooling layer.
    The function of the pooling layer is to concentrate the signal captured in the
    previous step while also reducing the dimensionality of the data. The pooling
    layer will result in a matrix that is smaller than the input data. Often a 2 x
    2 pooling layer will be used that reduces the size of the input data by half.
    In this case, the values within every 2 x 2 section are pooled through some sort
    of aggregation. These values can be aggregated using any means, such as summing
    and averaging the values; however, in most cases, the max value is used and this
    value is passed to the pooling layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the preceding method has been implemented, the processed and reduced
    image data is flattened and the vectors are then fed forward to essentially a
    traditional neural network as the last step. Let’s start here with just this final
    step, since we are familiar with using a traditional neural network to model from
    the previous code. Here, we will see two things: firstly, that we can train a
    model on image data using just this final step, and secondly, that the syntax
    is slightly different but generally recognizable when compared with training this
    type of model using the `neuralnet` package.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now code a neural network consisting of fully connected dense hidden
    layers using the `keras` package:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will load the `keras` library and the Fashion MNIST dataset that
    comes with the package. This is accomplished by running the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the preceding code, we will see that we get both the train and
    test data together in one list object. Your Environment pane should now look like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1831ae17-0d4e-4668-807c-ef73dc73030e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we can split the dataset into its component parts. It is conveniently
    set up so that it is easy to extract the training and test datasets and target
    variables. In the previous code, we used a version of the Fashion MNIST data that
    has already been preprocessed so that every pixel was in a separate column; however,
    in the following code, we will start with a large array of 28 x 28 matrices and
    demonstrate how to transform this data so that all pixel values for a given image
    are in the same row. The first step in the process is to separate out the four
    data objects from the list using the preceding code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'When you look at your Environment pane now, you will see the image data stored
    in 28 x 28 matrices and the target variables in vectors within an array. Your
    Environment pane will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f3af5e2f-a0a4-46d2-9e87-5350ca95db66.png)'
  prefs: []
  type: TYPE_IMG
- en: With our data in this format, we could apply our convolutional filters, which
    we will do soon; however, at this point, we are going to code a dense, fully connected
    neural network, and in order to do so, we will need to get all the data to one
    row per image instead of a two-dimensional matrix per image. Since we need the
    data in both formats at different stages of coding a convolutional neural network,
    it is a straightforward conversion process that we will complete in step six.
  prefs: []
  type: TYPE_NORMAL
- en: 'Image data consists of a matrix or matrices of pixel values between `0` and
    `255`. To process this data with our neural network, we need to convert these
    values to floats between `0` and `1`. As shown in the following code, we will
    use the `normalize()` convenience function to achieve this result and the `range()`
    function to test whether the values are now between `0` and `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this code, we may not see a noticeable change in the Environment
    pane for our data objects; however, when we run the `range()` function, we can
    see that all values are now between `0` and `1`. The output to your console after
    running the `range()` function on the data object will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/571d3c33-fc60-4bf0-8940-fddec74afffa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we can begin to train our model using the `keras` syntax. In the following
    code, we begin by declaring that we will be creating a sequential model, which
    means that data will pass through each subsequent layer in turn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the preceding code initiates the model object; however, it doesn''t
    contain any data yet. You can see this in your Environment pane, which will look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4029ead7-1740-456c-ba08-99a76b13cb69.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The steps we take next are the final steps of a convolutional neural network
    and represent the part of the process where the data is converted in such a way
    that it can be processed by a traditional neural network. The first step will
    be to define the layer that takes the data from a large array of matrices and
    transforms the data so that all values for a given image are in one single row.
    To do this, we use the `layer_flatten()` function and pass the matrix shape in
    as an argument, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code and the remainder of the steps that define the model will
    not cause a noticeable change in your R environment. This step adds a layer to
    the model object, though. This layer flattens our data so that the data for every
    image will be contained in a single row.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will include one hidden layer as we have done previously. The way this is
    done in `keras` is to use the `layer_dense` function. We then note how many units
    we would like our hidden layer to have and the activation function that should
    be used to decide whether the signal from a unit should feed forward. In this
    case, we select a unit count that is approximately one-third the size of our total
    number of independent variable columns and **rectified linear units** (**ReLU**)
    as our activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Again, this step produces no output or noticeable change to the environment.
    This adds one dense, fully connected layer to the model. The layer will contain
    256 units or neurons. It will use the ReLU function to determine which signals
    get sent forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we have 10 possible target classes, so we include 10
    units in our output layer, one for each class. Since this is a multinomial classification
    problem, we use the `softmax` function to compute the probabilities that any given
    set of image data belongs to one of the 10 classes of clothing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This line of code will add the last layer to this current neural network. This
    will be our output layer, which is another dense, fully connected layer where
    units are equal to the number of target classes. The `softmax` function will be
    used at this step to determine the probability that a given set of data belongs
    to each of the possible target classes. This step again produces no output or
    change in the R environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on to the `compile` step, we need to convert our target vectors
    to a matrix, which can be done simply with the `to_categorical` functions using
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the code, we will see a change in our Environment pane. The `target`
    variable objects that were vectors are now matrices where every row contains a
    single value equal to `1` at the index point for the class to which it belongs.
    Your Environment pane will now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bd5e7a69-cb31-46d1-84fa-83cf040811eb.png)'
  prefs: []
  type: TYPE_IMG
- en: This step is a requirement for training a multinominal classification model
    with `keras`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is used to define the arguments for the `compile` step.
    Here, we select the `optimizer`, `loss`, and `evaluation` metrics. The `optimizer`
    is the algorithm that calculates the error rate between the model results and
    the actual values to adjust weights. We define the compile portion of the model
    using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we did the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We chose **Adaptive Moment Estimation** (**Adam**). The loss function is the
    formula that is used to calculate the error rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When working with a multinominal classification problem like this one, the most
    suitable loss function is categorical crossentropy, which is another term for
    multiclass log loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to use this loss function, the target variable must be stored as a
    matrix, which is why we performed that data type conversion in the previous step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The metrics argument stores the measurement for evaluating model performance,
    and we used categorical accuracy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The step to fit our model at this point requires just three arguments. We pass
    in the training dataset, the target variables of the training data, and the number
    of times we would like the model to run. As shown in the following code, we will
    choose `10` epochs at this point so that our model finishes running quickly; however,
    if you have time to run the model for longer, then you will likely get better
    results. Train a neural network on the train data with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run this code, we will get a printout to our console with the results
    from every epoch. The output to your console will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6662fc0f-2302-4c51-a4ee-9b98345b52ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In addition to the console output, the preceding code also produces a plot,
    which is a graphical representation of the same information. In your **Viewer**
    pane, you will see a plot like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/521d7502-2d54-4344-ae13-f8f7efdc7556.png)'
  prefs: []
  type: TYPE_IMG
- en: The two pieces of output show that our model improves a lot at first and then
    improves at a much slower pace after additional iterations of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, we can run our model on our test dataset and use the test target
    variables to evaluate our model, as shown in the following screenshot. We can
    calculate the loss and categorical accuracy metric and print out the categorical
    accuracy metric by running the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following printed out to your console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b1b03f4-e508-4c57-bd38-3025041eb042.png)'
  prefs: []
  type: TYPE_IMG
- en: We have achieved a categorical accuracy of 88.66%. This is a decrease from our
    previous accuracy; however, keep in mind that the accuracy metric before pertained
    to a binary response and this describes predictions for all classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Making predictions using the model is achieved through the `predict()` function.
    In the following code, `predict_classes` can be used to choose one of the 10 classes
    that are most likely based on the probability scores, while `preds` will calculate
    the probabilities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the preceding code, we can see the difference in our **Environment**
    pane, which contains two new data objects. Your **Environment** pane will look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cea0f813-d0e8-4ede-8c1a-66453262c63e.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that `preds` is a large matrix with a probability value for each
    class, while `predicted_classes` is a vector where every value indicates the most
    probable class for each case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can use a confusion matrix to review our results. In order to run
    this code, we will need our test target labels back in vector format rather than
    in a matrix. To do this, we will just read in the test target file again, as shown
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the code will produce an evaluation metric output to print to our console.
    Your console will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d22457d1-da11-46f3-b2ce-10a6576b3e33.png)'
  prefs: []
  type: TYPE_IMG
- en: Our accuracy score has actually decreased from 97.487% to 88.66%. This is in
    part due to limiting our model to 10 runs and also, again, because we are now
    building a classifier for 10 categories, whereas the other score was achieved
    with a binary classifier. At this point, improving the accuracy score is not the
    priority in any case. The preceding code is here to show how to code a neural
    network using the `keras` syntax.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, during the compile stage, we chose an optimizer, loss
    function, and evaluation metric; however, we should note the other options that
    we could have selected and the difference between the available choices. We'll
    look at these in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at the following optimizers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stochastic gradient descent** (**SGD**): This is the simplest optimizer.
    For every weight, the model stores an error rate. Depending on the direction of
    the error, whether the predicted value is greater than or less than the true value,
    a small learning rate is applied to the weight to change the next round of results
    so that the predicted values are incrementally moving in the opposite direction
    as the error. This process is simple, but for deep neural networks, the fine adjustments
    at every iteration mean that it can take a long time for the model to converge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Momentum**: Momentum itself is not an optimizer, but is something that can
    be incorporated with different optimizers. The idea of momentum is that it takes
    the decaying average of all the corrections that have occurred previously and
    uses these in combination with the correction calculated for the current move.
    For this, we can imagine momentum working just like it would if an object was
    rolled down a hill and then continued to roll up another hill using its own momentum.
    For every movement that it made, there would be a force pulling it back down the
    hill; however, for a period of time, the momentum to continue up the hill would
    be stronger than the force pulling it back down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adagrad/Adadelta**: Adagrad improves on SGD through the use of a matrix of
    all previous errors per node rather than one error rate for all nodes; however,
    the use of this matrix of values means that the learning rate can be canceled
    out of the model runs for too long. Adadelta is the correction for the limitation
    of Adagrad. Adadelta uses momentum to solve the growing error rate matrix problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RMSprop**: This is a separate correction to Adagrad. It is similar to Adadelta,
    however, with RMSprop, the learning rate is not only divided by a matrix of local
    per-node decaying average error rates, but also by a global decaying average of
    all squared error rates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adam**: This algorithm further corrects and builds upon the algorithms before.
    Adam includes not only an exponentially decaying average of squared error rates,
    as seen in RMSprop, but also an exponentially decaying average of error rates
    (not squared), which is momentum. In this way, Adam is more or less RMSprop with
    momentum. The combination of the two means that there is a correction to momentum
    similar to friction, which decreases the effect of momentum and thereby leads
    to faster convergence, in many cases making Adam a popular optimizer at the time
    of writing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loss functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the preceding optimizers, you can select whichever one you like and try
    different algorithms to see which produces the best results. With the loss function,
    there are some choices that are more appropriate than others based on the problem
    being solved:'
  prefs: []
  type: TYPE_NORMAL
- en: '`binary_crossentropy`: This loss function is used for classification problems
    where the requirement is to assign input data to one of two classes. This can
    also be used when assigning input data to more than one or two classes if it is
    possible for a given case to belong to more than one class. In this case, each
    target class is treated as a separate binary class (for each target class the
    given case belongs to or does not belong to). This can also be used for regression
    when the target values are between 0 and 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`categorical_crossentropy`: Categorical crossentropy is used with a multinominal
    classification problem where any given row of input data can only belong to one
    of the more than two classes. As we noted with binary crossentropy, in order to
    use categorical crossentropy, the target vector must be converted to a matrix
    so that there is a value of 1 for the index associated with the target class for
    every given row. If the target vector contains integers that are meant to be treated
    as integers and not categorical classes, then `sparse_categorical_crossentropy`
    can be used without performing the matrix conversion required for categorical
    crossentropy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MSE (**mean squared error**): Mean squared error is an appropriate choice for
    regression problems since the predicted values and true values can be any number.
    This loss function takes the square of the difference between the predicted values
    and the target values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The evaluation metric is used to measure model performance. While similar to
    the loss functions, it is not used for making corrections while training the model.
    It is only used after the model has been trained to evaluate performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy**: This metric measures how often the correct class is predicted.
    By default, 0.5 is used as a threshold, which means that if the predicted probability
    is below 0.5, then the predicted class is 0; otherwise, it is 1\. The total number
    of cases where the predicted class matches the target class is divided by the
    total number of target variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cosine similarity**: Compares the similarity between two vectors by evaluating
    the similarity of terms in *n*-dimensional space. This is used often to evaluate
    the similarity of text data. For this, we can imagine a piece of text with the
    word cat four times and the word dog once, and another with the word cat four
    times and the word dog twice. In this case, with two dimensions, we could envision
    a line from the origin through the point where *y* = 4 and *x* = 1 for the first
    piece of text and another line through the point where *y* = 4 and *x* = 2 for
    the next piece of text. If we evaluate the angle between the two lines, we will
    arrive at the cosine value used to determine similarity. If the lines overlap,
    then the documents have a perfect similarity score of 1, and the larger the angle
    between the lines, the less similar and the lower the similarity score will be.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean absolute error**: The average value for all absolute errors. The absolute
    error is the difference between the predicted variable and the target variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mean squared error**: The average value for all squared errors. The squared
    error is the square of the difference between the predicted variable and the target
    variable. Through squaring the errors, an increased penalty is applied to larger
    errors relative to mean absolute error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hinge**: To use the hinge evaluation metric, all target variables should
    be -1 or 1\. From here, the formula is to subtract the product of the predicted
    value and the target variable from 1 and then to use this value or 0, whichever
    is greater for evaluation. Results are evaluated as more correct the closer the
    metric value is to 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**KL divergence**: This metric compares the distribution of true results with
    the distribution of predicted results and evaluates the similarity of the distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have, so far, used a tree-based classifier and a traditional neural network
    to classify our image data. We have also reviewed the `keras` syntax and looked
    at our options for several functions within the modeling pipeline using this framework.
    Next, we will add the additional layers before the neural network that we just
    coded to create a convolutional neural network. For this special type of neural
    network, we will include a convolution layer and a pooling layer. A dropout layer
    is often also included; however, we will add this later as it serves a slightly
    different purpose than the convolution and pooling layers. When used together,
    these layers find more complex patterns in our data and also reduce the size of
    our data, which is especially important when working with large image files.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing the model with additional layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we add two important layers: the convolution layer, and pooling
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before beginning, we make one small change to the data structure. We will add
    a fourth dimension that is a constant value. We add the extra dimension using
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'When we make this change, we can see the added dimension for these data objects
    in the Environment pane, which will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/807acb3e-c10c-41d4-a945-8d26d60f87c1.png)'
  prefs: []
  type: TYPE_IMG
- en: We make this change to the structure because it is a requirement of modeling
    a CNN using `keras`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, the first step in the modeling process is to establish that we will
    be building a sequential model by calling the `keras_model_sequential()` function
    with no arguments using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Running the preceding code will place the model object into our Environment
    pane, however, it contains no data at the moment and no output is printed to console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will add our convolving layer for a two-dimensional object. In the
    following code, we will decide on the number of filters or subsets of the data
    and the size of these subsets as well as the activation function used to determine
    whether the subset contains a certain pattern:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s looks at the preceding code in a little more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: We chose to include 484 filters and a kernel size that is 7 pixels high and
    wide.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We applied a filter the size of the kernel on the image and, using the constant
    values on the filter, the model determined whether it detects a pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The stride value of 1 that is used in this example means that the kernel slides
    over the surface of the image by 1 pixel after every filter has been evaluated,
    though this number can be changed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After this, we will use a max pooling layer in the following code to create
    a new downsampled version of our data that represents the maximum values within
    the pool size after the convolving round:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This line of code causes no noticeable changes to the Environment pane and prints
    no output to the console. It adds a layer to our model that will reduce the size
    of our data to one-quarter of the original size.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, the steps continue in the same way as we described in the previous
    example from the *Image recognition with convolutional neural networks* section.
    Let''s have a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the preceding code, we will get model diagnostic data printed
    to the console, which will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60457c3a-0a74-4e39-b620-7048c639f12a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You will also get a plot with the same data, which looks like the following
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4815302-74f6-4740-bdfc-b3e23911ce91.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code also produces performance metrics and prints them to the
    console. Your console will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b59da266-148f-460d-bcdf-e5c2a5bb9710.png)'
  prefs: []
  type: TYPE_IMG
- en: By adding our convolution layer and our pooling layer, we have already increased
    our accuracy score from 88.66% to 90.51%, and we did so with five fewer rounds
    to prevent using a long-running model while learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'As discussed previously, deep learning occurs when there are many layers for
    the signal to pass through, so in the following method, we will see how we can
    continue to add more layers. Using this, you can continue to add as many layers
    as you need as you refine your model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by redefining our model. We will state again that it is a sequential
    model in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will reset the model object; however, no noticeable changes
    will occur in the Environment pane and nothing will print to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next step, we will use a convolving layer with 128 filters and then
    a pooling layer. In this case, we also add `padding = "same"` to prevent dimension
    reduction after the convolution layer. This is in order to make it possible to
    add additional layers. If we reduce the dimensionality of our data too quickly,
    then we will not be able to fit a filter of any kernel size on the data later.
    We define our first convolving layer and pooling layer using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code results in no noticeable changes to the Environment pane
    and nothing will print to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following code, we will add in another convolving layer with
    64 filters and a pooling layer. We add these two additional layers using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code results in no noticeable changes to the Environment pane
    and nothing will print to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then add in one more convolving layer. This time, we will use 32 filters
    and a pooling layer, as shown in the following code. We add these two additional
    layers using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code results in no noticeable changes to the Environment pane
    and nothing will print to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in the following code, we flatten the values and proceed in the same
    way as we have in the previous examples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces model diagnostics in our console. Your console
    will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42678786-19c3-41bd-9015-a133f90ad9b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code also produces a plot. You will see a plot in your Viewer
    pane that looks like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c853b96-fe00-4bee-9763-99c0241a4bcb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We also produce additional performance metrics and print these to our console.
    You will see the following output in your console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/159ab197-a120-4b36-b59d-88fffaa447d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Our accuracy score remains almost the same at 89.97%. We could likely get the
    accuracy to improve with more filters per layer; however, this will significantly
    increase run time, so that is why we keep the filter count per layer as it is.
    We have seen here how to write code to create a CNN and a CNN with a deeper layer
    structure, and we noticed how it improved performance. We have so far used the
    ReLU activation function, which is a very popular and common activation function;
    however, we know there are other options, so next, we will write code to select
    a different activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the most appropriate activation function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using `keras`, you can use a number of different activation functions. Some
    of these have been discussed in previous chapters; however, there are some that
    have not been previously covered. We can begin by listing the ones we have already
    covered with a quick note on each function:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear**: Also known as the identity function. Uses the value of *x*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid**: Uses 1 divided by 1 plus the exponent of negative *x*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hyperbolic tangent** (**tanh**): Uses the exponent of *x* minus the exponent
    of negative *x* divided by *x* plus the exponent of negative *x*. This has the
    same shape as the sigmoid function; however, the range along the *y*-axis goes
    from 1 to -1 instead of from 1 to 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rectified Linear Units** (**ReLU**): Uses the value of *x* if *x* is greater
    than 0; otherwise, it assigns a value of 0 if *x* is less than or equal to 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leaky ReLU**: Uses the same formula as ReLU; however, it applies a small
    alpha value when *x* is less than 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Softmax**: Provides a probability for each possible target class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at all the functions that were not mentioned in previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exponential Linear Unit** (**ELU**): Uses the exponent of *x* - 1 multiplied
    by a constant alpha value if the value for *x* is less than 0'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaled Exponential Linear Unit** (**SELU**): Uses the ELU function and then
    multiplies the result of the function by a constant scale value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Thresholded ReLU**: Uses the same formula as ReLU; however, instead of using
    0 as the threshold for whether *x* is *x* or 0, it uses a user-defined value of
    theta to determine this threshold.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parametric Rectified Linear Unit** (**PReLU**): The same as the formula for
    Leaky ReLu; however, it uses an array of values for alpha rather than a single
    value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Softplus**: Uses the log of the exponent of *x* plus 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Softsign**: Uses *x* divided by the absolute value of *x* + 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exponential**: Uses the exponent of *x*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hard Sigmoid**: Uses a modified and faster version of the sigmoid function.
    If *x* is less than -2.5, then the value is 0 and if *x* is greater than 2.5,
    then the value is 1; otherwise, it uses 0.2 * *x* + 0.5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So far, we have used the ReLU activation function by assigning the `relu` value to
    the activation argument within our layer function call. For some activation functions,
    such as the sigmoid function, we can simply swap out the `relu` value with the
    `sigmoid` value; however, more advanced activation functions require a separate
    activation function layer. Let''s switch the activation function from ReLu to
    Leaky ReLU in our code by removing the activation argument from the layer function
    call and adding a Leaky ReLU activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code prints model diagnostic data to our console. Your console
    will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf800383-b76f-44e2-a9a5-46f2af9382ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code also produces a plot with model performance data. You will
    see a plot like the following image in your Viewer pane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6296662-30bb-4780-86ab-43046649d7a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code also produces performance metrics. These will print to your
    console and will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51e4f360-e562-45b7-ac40-12e7717e4299.png)'
  prefs: []
  type: TYPE_IMG
- en: After switching our activation function, our accuracy score is 90.95%, which
    is very similar to the score we have been getting so far. In this case, switching
    our activation function did not improve performance; however, there will be times
    when this will be helpful, so it is important to know how to make this modification.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting optimal epochs using dropout and early stopping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To avoid overfitting, we can use two techniques. The first is adding a dropout
    layer. The dropout layer will remove a subset of the layer output. This makes
    the data a little different at every iteration so that the model generalizes better and
    doesn''t fit the solution too specifically to the training data. In the preceding
    code, we add the dropout layer after the pooling layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code prints model diagnostic data to our console. Your console
    will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d0947cd-aa5b-416b-a197-f82689a0f31a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code also produces a plot with model performance data. You will
    see a plot like the following image in your Viewer pane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec8e5b34-0189-4414-ade2-b328f32a771e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding code also produces some performance metrics. The output printed
    to your console will look like the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7db9be8b-473b-4e95-98ab-7cc34fd33542.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, using this tactic caused our accuracy score to decrease slightly
    to 90.07%. This could be due to working with a dataset of such small images that
    the model suffered from the removal of data at every step. With larger datasets,
    this will likely help make models more efficient and generalize better.
  prefs: []
  type: TYPE_NORMAL
- en: The other tactic for preventing overfitting is using early stopping. Early stopping
    will monitor progress and stop the model from continuing to train on the data
    when the model no longer improves. In the following code, we have set the patience
    argument to `2`, which means that the evaluation metric must fail to improve for
    two epochs in a row.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, with epochs kept at `5`, the model will complete all
    five rounds; however, if you have time, feel free to run all the preceding code
    and then, when it is time to fit the model, increase the number of epochs to see
    when the early stopping function stops the model. We add early stopping functionality
    to our model using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding code, we can deduce the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Using dropout and early stopping, we demonstrated methods for discovering the
    optimal number of epochs or rounds for our model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When thinking of the number of epochs we should use, the goal is twofold.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want our model to run efficiently so that we are not waiting for our model
    to finish running, even though the additional rounds are not improving performance.
    We also want to avoid overfitting where a model is trained too specifically on
    the training data and is unable to generalize to new data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dropout helps with the second issue by arbitrarily removing some data on each
    round. It also introduces randomness that prevents the model from learning too
    much about the whole dataset.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Early stopping helps with the first problem by monitoring performance and stopping
    the model when the model is no longer producing better results for a given length
    of time.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these two techniques together will allow you to find the epoch number
    that allows the model to run efficiently and also generalize well.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started by showing how image classification models can be
    created using standard machine-learning techniques; however, this has limitations
    as the images get larger and more complex. We can use convolutional neural networks
    to combat this issue. Using this approach, we demonstrated how we could perform
    dimensionality reduction and make it more computationally efficient to train a
    classification model on image data. We built a model with one convolution and
    pooling layer and then showed how we could make the model even deeper by adding
    further layers. Lastly, we used dropout layers and early stopping to avoid overfitting
    our model. Using all of these tactics in concert, we are now able to build models
    for classifying any type of image data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to code a multilayer perceptron. The
    multilayer perceptron is a feedforward neural network that includes only dense,
    fully connected hidden layers. With fewer options to adjust, we will take a deeper
    dive into what is available for us to tune. In addition, we will use the MXNet
    package for the first time, aside from the brief introduction in [Chapter 2](b614d2ff-1494-4a53-bd21-3c5d108be87c.xhtml),
    *CNNs for Image Recognition*.
  prefs: []
  type: TYPE_NORMAL
