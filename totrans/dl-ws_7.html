<html><head></head><body>
		<div>
			<div id="_idContainer210" class="Content">
			</div>
		</div>
		<div id="_idContainer211" class="Content">
			<h1 id="_idParaDest-197">7. <a id="_idTextAnchor223"/>Generative Adversarial Networks</h1>
		</div>
		<div id="_idContainer247" class="Content">
			<p class="callout-heading">Introduction</p>
			<p class="callout">In this chapter, you will embark on another interesting topic within the deep learning domain: <strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>). You will get introduced to GANs and their basic components, along with some of their use cases. This chapter will give you hands-on experience of creating a GAN to generate a data distribution produced by a sine function. You will also be introduced to deep convolutional GANs and will perform an exercise to generate an MNIST data distribution. By the end of this chapter, you will have tested your understanding of GANs by generating the MNIST fashion dataset.</p>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor224"/>Introduction</h1>
			<p>The power of creativity was always the exclusive domain of the human mind. This was one of the facts touted as one of the major differences between the human mind and the artificial intelligence domain. However, in the recent past, deep learning has been making baby steps in the path to being creative. Imagine you were at the Sistine Chapel in the Vatican and were looking up with bewilderment at the frescos immortalized by Michelangelo, wishing your deep learning models were able to recreate something like that. Well, maybe 10 years back, people would have scoffed at your thought. Not anymore, though – deep learning models have made great strides in regenerating immortal works. Applications like these are made possible by a class of networks called <strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>).</p>
			<p>Many applications have been made possible with GANs. Take a look at the following image:</p>
			<div>
				<div id="_idContainer212" class="IMG---Figure">
					<img src="image/B15385_07_01.jpg" alt="Figure 7.1: Image translation using GANs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1: Image translation using GANs</p>
			<p class="callout-heading">Note:</p>
			<p class="callout">The preceding image is sourced from the research paper titled <em class="italic">Image-to-Image Translation with Conditional Adversarial Networks</em>: Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros, available at <a href="https://arxiv.org/pdf/1611.07004.pdf">https://arxiv.org/pdf/1611.07004.pdf</a>.</p>
			<p>The preceding image demonstrates how the input image, which has a very different color scheme, has been transformed by the GAN into an image that looks very similar to the real one. This application of GANs is called image translation. </p>
			<p>In addition to these examples, many other use cases are finding traction. Some of the notable ones are as follows:</p>
			<ul>
				<li>Synthetic data generation for data augmentation</li>
				<li>Generating cartoon characters</li>
				<li>Text to image translation</li>
				<li>Three-dimensional object generation</li>
			</ul>
			<p>The list goes on. As the days go by, applications of GANs increasingly become mainstream. </p>
			<p>So, what exactly are GANs? What are the inner dynamics of GANs? How do you generate images or other data distributions from totally unconnected distributions? In this chapter, we'll find out the answers to those questions. </p>
			<p>In the previous chapter, we learned about <strong class="bold">recurrent neural networks</strong> (<strong class="bold">RNNs</strong>), a class of deep learning networks used for sequence data. In this chapter, we will embark on a fascinating safari to the world of GANs. First, we will start with an introduction to GANs. Then, we'll focus on generating a data distribution that is similar to a known mathematical expression. We'll then move on to <strong class="bold">deep convolutional GANs</strong> (<strong class="bold">DCGANs</strong>). To see how well our generative models work, we will generate a data distribution similar to the MNIST handwritten digits. We'll start this journey by learning about GANs.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Depending on your system configuration, some of the exercises and activities in this chapter may take quite a long time to execute. </p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor225"/>Key Components of Generative Adversarial Networks</h2>
			<p>GANs are used to create a data distribution from random noise data and make it look similar to a real data distribution. GANs are a family of deep neural networks that comprise two networks that are competing against each other. One of these networks is called the <strong class="bold">generator network</strong>, while the other is called the <strong class="bold">discriminator network</strong>. The functions of these two networks are to compete against each other to generate a probability distribution that closely mimics an existing probability distribution. To state an example of generating a new probability distribution, let's say we have a collection of images of cats and dogs (real images). Using a GAN, we can generate a different set of images (fake images) of cats and dogs from a very random distribution of numbers. The success of a GAN is in generating the best set of cat and dog images to the point that it is difficult for people to differentiate between the fake ones and the real ones.</p>
			<p>Another example where GANs can become useful is in data privacy. The data of companies, especially in domains such as finance and healthcare, is extremely sensitive. However, there might be instances where data has to be shared with third parties for research purposes. In such scenarios, to maintain the confidentiality of data, companies can use GANs to generate datasets that are similar in nature to their existing datasets. There is a multitude of such business use cases where GANs can come in really handy.</p>
			<p>Let's understand GANs better by mapping out some of their components, as shown in the following diagram:</p>
			<div>
				<div id="_idContainer213" class="IMG---Figure">
					<img src="image/B15385_07_02.jpg" alt="Figure 7.2: Example of GAN structure&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2: Example of GAN structure</p>
			<p>The preceding figure provides a concise overview of the components of a GAN and how they come in handy in generating fake images from real ones. Let's understand the process in the context of the preceding diagram:</p>
			<ol>
				<li>The set of images at the top-left corner of the preceding figure represents a probability distribution of real data (for example, MNIST, images of cats and dogs, pictures of human faces, and more).</li>
				<li>The generative network shown in the bottom-left part of the diagram generates fake images (probability distributions) from a random noise distribution. </li>
				<li>The trained discriminative network classifies whether the image that is fed in is fake or real.</li>
				<li>A feedback loop (the diamond-shaped box) working through the backpropagation algorithm gives feedback to the generator network, thereby refining the parameters of the generator model. </li>
				<li>The parameters continue to be refined until the discriminator network can't discriminate between the fake images and the real ones.</li>
			</ol>
			<p>Now that we have an overview of each of the components, let's dive deeper and understand them better through a problem statement.</p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor226"/>Problem Statement – Generating a Distribution Similar to a Given Mathematical Function</h2>
			<p>In this problem, we will use GANs to generate a distribution that is similar to a data distribution from a mathematical function. The function we will be using to generate the real data is a simple <strong class="bold">sine wave</strong>. We will train a GAN to generate a fake distribution of data that will be similar to the data we generated from the known mathematical function. We will progressively build each component that's required while we traverse the solution for this problem statement. </p>
			<p>The process we will follow is explained in the following figure. We will follow a pedagogical approach as per the steps detailed in this figure:</p>
			<div>
				<div id="_idContainer214" class="IMG---Figure">
					<img src="image/B15385_07_03.jpg" alt="Figure 7.3: Four-step process to building a GAN from a known function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3: Four-step process to building a GAN from a known function</p>
			<p>Now, let's explore each of these processes.</p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor227"/>Process 1 – Generating Real Data from the Known Function</h2>
			<p>To begin our journey, we need a real distribution of data. This distribution of data will comprise two features – the first one is the sequence and the second one is the sine of the sequence. The first feature is a sequence of data points spaced at equal intervals. To generate this sequence, we need to randomly generate a data point from a normal distribution and then find other numbers spaced in sequence at equal intervals. The second feature will be the <strong class="source-inline">sine()</strong> of the first feature. Both these features will form our real data distribution. Before we get into an exercise that generates the real dataset, let's look at some of the functions in the <strong class="source-inline">numpy</strong> library we will use in this process.</p>
			<p><strong class="bold">Random Number Generation</strong></p>
			<p>First, we will generate a random number from a normal distribution using the following function:</p>
			<p class="source-code">numpy.random.normal(loc,scale,size)</p>
			<p>This function takes three arguments:</p>
			<ul>
				<li><strong class="source-inline">loc</strong>: This is the mean of the data distribution.</li>
				<li><strong class="source-inline">scale</strong>: This is the standard deviation of the data distribution.</li>
				<li><strong class="source-inline">size</strong>: This defines the number of data points we want.</li>
			</ul>
			<p><strong class="bold">Arranging the Data into a Sequence</strong></p>
			<p>To arrange data in a sequence, we use the following function:</p>
			<p class="source-code">numpy.arange(start,end,spacing)</p>
			<p>The arguments are the following:</p>
			<ul>
				<li><strong class="source-inline">start</strong>: This is the point that the sequence should start from.</li>
				<li><strong class="source-inline">end</strong>: The point where the sequence ends.</li>
				<li><strong class="source-inline">spacing</strong>: The frequency between each successive number in the sequence. For example, if we start off with 1 and generate a series with a spacing of <strong class="source-inline">0.1</strong>, the series will look as follows:</li>
			</ul>
			<p class="source-code"> 1, 1.1,1.2 …….. </p>
			<p><strong class="bold">Generating the Sine Wave</strong></p>
			<p>To generate the sine of a number, we use the following command:</p>
			<p class="source-code">numpy.sine()</p>
			<p>Let's use these concepts in the following exercise and learn how to generate a real data distribution. </p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor228"/>Exercise 7.01: Generating a Data Distribution from a Known Function</h2>
			<p>In this exercise, we will generate a data distribution from a simple sine function. By completing this exercise, you will learn how to generate a random number from a normal distribution and create a sequence of equally spaced data with the random number as its center. This sequence will be the first feature. The second feature will be created by calculating the <strong class="source-inline">sine()</strong> for the first feature. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and name it <strong class="source-inline">Exercise 7.01</strong>. Run the following command to import the necessary library packages:<p class="source-code"># Importing the necessary library packages</p><p class="source-code">import numpy as np</p></li>
				<li>Generate a random number from a normal distribution that has a mean of 3 and a standard deviation of 1:<p class="source-code">"""</p><p class="source-code">Generating a random number from a normal distribution </p><p class="source-code">with mean 3 and sd = 1</p><p class="source-code">"""</p><p class="source-code">np.random.seed(123)</p><p class="source-code">loc = np.random.normal(3,1,1)</p><p class="source-code">loc</p><p class="callout-heading">Note</p><p class="callout">The triple-quotes ( <strong class="source-inline">"""</strong> ) shown in the code snippet above are used to denote the start and end points of a multi-line code comment. Comments are added into code to help explain specific bits of logic.</p><p>For reproducing the results, we use <strong class="source-inline">random.seed(123)</strong>.</p><p>You should get the following output:</p><p class="source-code">array([1.9143694])</p></li>
				<li>Using the previously generated random number as a midpoint, we will generate equal sequences of numbers to the right and left of the midpoint. We will generate a batch of 128 numbers. So, we take 64 numbers each to the right and left of the midpoint with a spacing of 0.1. The following code generates a sequence to the right of the midpoint:<p class="source-code"># Generate numbers to right of the mid point</p><p class="source-code">xr = np.arange(loc,loc+(0.1*64),0.1)</p></li>
				<li>Generate 64 numbers to the left of the midpoint:<p class="source-code"># Generate numbers to left of the random point</p><p class="source-code">xl = np.arange(loc-(0.1*64),loc,0.1)</p></li>
				<li>Concatenate both these sequences to generate the first feature:<p class="source-code"># Concatenating both these numbers </p><p class="source-code">X1 = np.concatenate((xl,xr))</p><p class="source-code">print(X1)</p><p>You should get an output similar to the one shown here:</p><div id="_idContainer215" class="IMG---Figure"><img src="image/B15385_07_04.jpg" alt="Figure 7.4: Sequence of numbers with equal spacing&#13;&#10;"/></div><p class="figure-caption">Figure 7.4: Sequence of numbers with equal spacing</p><p>The preceding is the distribution of <strong class="source-inline">128</strong> numbers equally spaced from one another. This sequence will be our first feature for the data distribution.</p></li>
				<li>Generate the second feature, which is the <strong class="source-inline">sine()</strong> of the first feature:<p class="source-code"># Generate second feature</p><p class="source-code">X2 = np.sin(X1)</p></li>
				<li>Plot the distribution:<p class="source-code"># Plot the distribution </p><p class="source-code">import matplotlib.pyplot as plot</p><p class="source-code">plot.plot(X1, X2)</p><p class="source-code">plot.xlabel('Data Distribution')</p><p class="source-code">plot.ylabel('Sine of data distribution')</p><p class="source-code">plot.show()</p><p>You should get the following output:</p><div id="_idContainer216" class="IMG---Figure"><img src="image/B15385_07_05.jpg" alt="Figure 7.5: Plot for the sine function&#13;&#10;"/></div><p class="figure-caption">Figure 7.5: Plot for the sine function</p><p>The preceding plot shows the distribution that you would be trying to mimic using GANs.</p></li>
				<li>Reshape each feature before concatenating them:<p class="source-code"># Reshaping the individual data sets</p><p class="source-code">X1 = X1.reshape(128,1)</p><p class="source-code">X2 = X2.reshape(128,1)</p></li>
				<li>Concatenate both features to form a single DataFrame:<p class="source-code"># Concatenate both features to form the real data set</p><p class="source-code">realData = np.concatenate((X1,X2),axis=1)</p><p class="source-code">realData.shape</p><p>You should get the following output:</p><p class="source-code">(128, 2)</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3gHhv42">https://packt.live/3gHhv42</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2O62M6r">https://packt.live/2O62M6r</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>In this exercise, we created a data distribution from a mathematical function. We will be using this data distribution later to train the GAN to generate a distribution similar to this. In a production environment, you will be provided with a real dataset, similar to the MNIST or <strong class="source-inline">Imagenet</strong> datasets. In this case, our real dataset is a known mathematical function. Later in this chapter, we will use some random noise data and train the GAN to make that random noise data similar to this real data distribution. </p>
			<p>Now that we have seen the real data distribution, the next section will be all about creating a basic generative network. </p>
			<h2 id="_idParaDest-203"><a id="_idTextAnchor229"/>Process 2 – Creating a Basic Generative Network</h2>
			<p>In the previous process, we worked on an example that will generate a distribution from a known function. As we mentioned earlier, the purpose of the generative network is to sample data from any arbitrary distribution and then transform that data into generative samples that look similar to the known distribution. </p>
			<p>The way the generative network achieves this is through the dynamics of the generator, the discriminator, and the training process. The success of the generative network relies on its ability to create data distributions that the discriminator can't differentiate between – in other words, it can't determine whether the distribution is fake or not. This ability of the generative network to create distributions that can fool the discriminator is acquired by the training process. We will talk more about the discriminator and the training process later in this chapter. For now, let's see how a generator network can be constructed to generate fake data distributions from some random distribution. </p>
			<h2 id="_idParaDest-204"><a id="_idTextAnchor230"/>Building the Generative Network</h2>
			<p>Generative networks are neural networks that are trained to transform an arbitrary distribution so that it looks similar to the known distribution. We can use any type of neural network for this, such as <strong class="bold">multi-layer perceptrons </strong>(<strong class="bold">MLPs</strong>), <strong class="bold">convolutional neural networks</strong> (<strong class="bold">CNNs</strong>), and more, to build the generator network. The input data to these networks are the samples that we take from any arbitrary distribution. In this example, we will be using an MLP to build a generative network. Before we start building the network, let's revisit some of the building blocks of a neural network that you will have learned about in the previous chapters. We will be building the network using the Keras library.</p>
			<h2 id="_idParaDest-205"><a id="_idTextAnchor231"/>Sequential()</h2>
			<p>As you might already know, a neural network consists of different layers of nodes that have connections between them. The <strong class="source-inline">Sequential()</strong> API is the mechanism through which you can create those layers in Keras. The <strong class="source-inline">Sequential()</strong> API is instantiated using the following code: </p>
			<p class="source-code">from tensorflow.keras import Sequential</p>
			<p class="source-code">Genmodel= Sequential()</p>
			<p>In the first part of the code, the <strong class="source-inline">Sequential()</strong> class is imported from the <strong class="source-inline">tensorflow.Keras</strong> module. It is then instantiated as a variable model in the second line of code.</p>
			<h3 id="_idParaDest-206"><a id="_idTextAnchor232"/>Kernel Initializers</h3>
			<p>In <em class="italic">Chapter 2</em>, <em class="italic">Neural Networks</em>, you learned that the training process involves updating the weights and biases of a neural network so that the function that maps the inputs to the outputs is learned effectively. As a first step in the training process, we initialize some values for the weights and biases. These get updated more during the backpropagation stage. The initialization of the weights and biases is done through a parameter called the <strong class="bold">kernel initializer</strong>. Different types of kernel initializers are used in a network in Keras. We will be using a kernel initializer called <strong class="source-inline">he_uniform</strong> in the exercise that follows. A kernel initializer will be added as a parameter within the network. </p>
			<h3 id="_idParaDest-207"><a id="_idTextAnchor233"/>Dense Layers</h3>
			<p>The basic dynamics within each layer in a neural network is the matrix multiplication (dot product) between the weights for the layer and the input to the layer, and the further addition of a bias. This is represented by the <strong class="source-inline">dot(X,W) + B</strong> equation, where <strong class="source-inline">X</strong> is the input to the layer, <strong class="source-inline">W</strong> is the weight or the kernel, and <strong class="source-inline">B</strong> is the bias. This operation of the neural network is done using the dense layer in Keras. This is implemented in code as follows:</p>
			<p class="source-code">from tensorflow.keras.layers import Dense </p>
			<p class="source-code">Genmodel.add(Dense(hidden_layer,activation,\</p>
			<p class="source-code">                   kernel_initializer,input_dim))</p>
			<p class="source-code">Genmodel.add(Dense(hidden_layer,activation,kernel_initializer))</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The above code block is solely meant to explain how the code is implemented. It may not result in a desirable output when run in its current form. For now, try to understand the syntax completely; we will be putting this code into practice in <em class="italic">Exercise 7.02</em>, <em class="italic">Building a Generative Network</em>.</p>
			<p>As you can see, we add a dense layer to the instantiation of the <strong class="source-inline">Sequential()</strong> class (<strong class="source-inline">Genmodel</strong>) we created earlier. Some of the key parameters that need to be given to define a dense layer are as follows:</p>
			<ul>
				<li><strong class="bold">Hidden Layers</strong> <strong class="source-inline">(hidden_layer)</strong>: As you might know, hidden layers are the intermediate layers in a neural network. The number of nodes of a hidden layer is defined as the first parameter.</li>
				<li><strong class="bold">Activation functions</strong> <strong class="source-inline">(activation)</strong>: The other parameter is the type of activation function that will be used. Activation functions will be discussed in detail in the next section.</li>
				<li><strong class="bold">Kernel Initializer</strong> <strong class="source-inline">(kernel_initializer)</strong>: The kind of kernel initializer that is used for the layer is defined within the dense layer.</li>
				<li><strong class="bold">Input dimensions</strong> <strong class="source-inline">(input_dim)</strong>: For the first layer of the network, we have to define the dimensions of the input (<strong class="source-inline">input_dim</strong>). For the subsequent layers, this is deduced automatically based on the output dimensions of each layer.</li>
			</ul>
			<h3 id="_idParaDest-208"><a id="_idTextAnchor234"/>Activation Functions</h3>
			<p>As you might know, activation functions introduce non-linearity to the outputs of a neuron. In a neural network, activation functions are introduced just after the dense layer. The output of the dense layer is the input of the activation function. Different activation functions will be used within the following exercise. They are as follows:</p>
			<ul>
				<li><strong class="bold">ReLU</strong>: This stands for <strong class="bold">Rectified Linear Unit</strong>. This activation function only outputs positive values. All negative values will be output as zero. This is one of the most widely used activation functions.</li>
				<li><strong class="bold">ELU</strong>: This stands for <strong class="bold">Exponential Linear Unit</strong>. This is very similar to ReLU except for the fact that it outputs negative values as well. </li>
				<li><strong class="bold">Linear</strong>: This is a straight-line activation function. In this function, the activations are proportional to the inputs.</li>
				<li><strong class="bold">SELU</strong>: This stands for <strong class="bold">Scaled Exponential Linear Unit</strong>. This activation function is a relatively lesser-used one. It enables an idea called internal normalization, which ensures that the mean and variance from the previous layers are maintained.</li>
				<li><strong class="bold">Sigmoid</strong>: This is a very standard activation function. A sigmoid function squashes any input into a value between 0 and 1. Therefore, the output from a sigmoid function can also be treated as a probability distribution as the values are between 0 and 1.</li>
			</ul>
			<p>Now that we have seen some of the basic building blocks of the network, let's go ahead and build our generative network in the next exercise.</p>
			<p>Before we start the exercise, let's see where the next exercise lies in the overall scheme of things. In <em class="italic">Exercise 7.01</em>, <em class="italic">Generating a Data Distribution from a Known Function</em>, we created a data distribution from a known mathematical function, which is a <strong class="source-inline">sine()</strong> function. We created the entire distribution by arranging the first feature with equal intervals and then creating the second feature by taking the <strong class="source-inline">sine()</strong> function of the first feature. So, we literally controlled the entire process of creating this dataset. That's why this is called a real data distribution because the data is created from a known function. The ultimate aim of a GAN is to transform a random noise distribution and make it look like a real data distribution; that is, make a random distribution look like the structured <strong class="source-inline">sine()</strong> distribution. This will be achieved in later exercises. However, as a first step, we will create a generative network that will create a random noise distribution. This is what we will do in the next exercise.</p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor235"/>Exercise 7.02: Building a Generative Network</h2>
			<p>In this exercise, we will build a generative network. The purpose of the generative network is to generate fake data distribution from a random noise data. We'll do this by generating random data points as input to the generator network. Then, we'll build a six-layer network, layer by layer. Finally, we'll predict the output from the network and plot the output distribution. This data distribution will be our fake distribution. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and name it <strong class="source-inline">Exercise 7.02</strong>. Import the following library packages:<p class="source-code"># Importing the library packages</p><p class="source-code">import tensorflow as tf</p><p class="source-code">import numpy as np</p><p class="source-code">from numpy.random import randn</p><p class="source-code">from tensorflow.keras.models import Sequential</p><p class="source-code">from tensorflow.keras.layers import Dense</p><p class="source-code">from matplotlib import pyplot</p></li>
				<li>In this step, we define the number of input features and output features for the network:<p class="source-code"># Define the input features and output features</p><p class="source-code">infeats = 10</p><p class="source-code">outfeats = 2</p><p>We will have 10 features as input and the output will be two features. The input features of <strong class="source-inline">10</strong> are arbitrarily selected. The output features of <strong class="source-inline">2</strong> are selected because our real dataset contains two features.</p></li>
				<li>Now, we will generate a batch of random numbers. Our batch size will be <strong class="source-inline">128</strong>:<p class="source-code"># Generate a batch of random numbers</p><p class="source-code">batch = 128</p><p class="source-code">genInput = randn(infeats * batch)</p><p>We can select any batch size. A batch size of <strong class="source-inline">128</strong> is selected so that we take cognizance of the computation resources we have. Since the input size is 10, we should generate 128 × 10 random numbers. Also, in the preceding code, <strong class="source-inline">randn()</strong> is the function to generate random numbers. Inside the function, we specify how many data points we want, which is (128 × 10) in our case.</p></li>
				<li>Let's reshape the random data into the input format we want using the following code:<p class="source-code"># Reshape the data </p><p class="source-code">genInput = genInput.reshape(batch,infeats)</p><p class="source-code">print(genInput.shape)</p><p>You should get the following output:</p><p class="source-code">(128, 10)</p></li>
				<li>In this step, we will define the generator. This network will have six layers:<p class="source-code"># Defining the Generator model</p><p class="source-code">Genmodel = Sequential()</p><p class="source-code">Genmodel.add(Dense(32,activation = 'linear',\</p><p class="source-code">                   kernel_initializer='he_uniform',\</p><p class="source-code">                   input_dim=infeats))</p><p class="source-code">Genmodel.add(Dense(32,activation = 'relu',\</p><p class="source-code">                   kernel_initializer='he_uniform'))</p><p class="source-code">Genmodel.add(Dense(64,activation = 'elu',\</p><p class="source-code">                   kernel_initializer='he_uniform'))</p><p class="source-code">Genmodel.add(Dense(32,activation = 'elu',\</p><p class="source-code">                   kernel_initializer='he_uniform'))</p><p class="source-code">Genmodel.add(Dense(32,activation = 'selu',\</p><p class="source-code">                   kernel_initializer='he_uniform'))</p><p class="source-code">Genmodel.add(Dense(outfeats,activation = 'selu'))</p><p>From the network, we can see that, in the first layer, we define the dimension of the input, which is 10, and in the last layer, we define the output dimension, which is 2. This is based on the input data dimensions that we generated in <em class="italic">Step 4</em> (10) and the output features that we want, which is similar to the number of features of the real data distribution.</p></li>
				<li>We can see the summary of this network by using the <strong class="source-inline">model.summary()</strong> function call:<p class="source-code"># Defining the summary of the network</p><p class="source-code">Genmodel.summary()</p><p>You should get the following output:</p><div id="_idContainer217" class="IMG---Figure"><img src="image/B15385_07_06.jpg" alt="Figure 7.6: Summary of the generator network&#13;&#10;"/></div><p class="figure-caption">Figure 7.6: Summary of the generator network</p><p>From the summary, you can see the shapes of the output from each layer. For example, the output from the dense layer has a shape of (<em class="italic">size of batch</em>, <strong class="source-inline">32</strong>) since the first hidden layer has <strong class="source-inline">32</strong> neurons. <strong class="source-inline">None</strong> in the shape layer denotes the number of examples, which in this case means the input batch size. The figure of 352 for the first layer is the size of the parameters, which includes both the weights and bias. The weight matrix will have a size of (10 × 32) as the number of inputs to the first layer is 10 and the next layer (hidden layer 1) has 32 neurons. The number of bias will be (32 × 1), which will be equivalent to the number of hidden layer neurons in the first layer. So, in total, there are 320 + 32 = 352 parameters. The second layer would be (32 × 32) + ( 32 × 1) = 1,056 and so on for all subsequent layers.</p></li>
				<li>Now that we have defined the generator network, let's generate the output from the network. We can do that using the <strong class="source-inline">predict()</strong> function:<p class="source-code"># Generating fake samples from network</p><p class="source-code">fakeSamps = Genmodel.predict(genInput)</p><p class="source-code">fakeSamps.shape</p><p>You should get the following output:</p><p class="source-code">(128, 2)</p><p>We can see that the output from the generator function generates a sample with two features and several examples equal to the batch size we have given.</p></li>
				<li>Plot the distribution:<p class="source-code"># Plotting the fake distribution</p><p class="source-code">from matplotlib import pyplot</p><p class="source-code">pyplot.scatter(fakeSamps[:,0],fakeSamps[:,1])</p><p class="source-code">pyplot.xlabel('Feature 1 of the distribution')</p><p class="source-code">pyplot.ylabel('Feature 2 of the distribution')</p><p class="source-code">pyplot.show()</p><p>You should get an output similar to the following. Please note that modeling will be stochastic in nature and therefore you might not get the same output:</p><div id="_idContainer218" class="IMG---Figure"><img src="image/B15385_07_07.jpg" alt="Figure 7.7: Plot of the fake data distribution&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 7.7: Plot of the fake data distribution</p>
			<p>As we can see, very random data has been generated. As you will see in upcoming exercises, this random data will be transformed so that it looks like the real data distribution.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2W0FxyZ">https://packt.live/2W0FxyZ</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2WhZpOn">https://packt.live/2WhZpOn</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>In this exercise, we defined the generator network, which had six layers and then generated the first fake samples from the generator network. You may be wondering how we arrived at those six layers. What about the choice of the activation functions? Well, the network architecture was arrived at after a lot of experimentation for this problem statement. There are no real shortcuts in terms of finding the right architecture. We have to arrive at the most optimal architecture after experimenting with different parameters such as the number of layers, type of activations, and more. </p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor236"/>Setting the Stage for the Discriminator Network</h2>
			<p>In the previous exercise, we defined the generator network. Now, it is time to set the stage before we define the discriminator network. Looking at the output we got from the generator network, we can see that the data points are randomly distributed. Let's take a step back and assess where we are really headed. In our introduction to generative networks, we stated that we want the output from the generative network to be similar to the real distribution we are trying to mimic. In other words, we want the output from the generative network to look similar to the output from the real distribution, as shown in the following plot:</p>
			<div>
				<div id="_idContainer219" class="IMG---Figure">
					<img src="image/B15385_07_08.jpg" alt="Figure 7.8: Real data distribution&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.8: Real data distribution</p>
			<p>We can see that the current distribution that has been generated by the generator network is nowhere near the distribution we want to mimic. Why do you think this is happening? Well, the reason is quite obvious; we have not done any training yet. You will also have noticed that we don't have an optimizer function as part of the network. The optimizer function in Keras is defined using the <strong class="source-inline">compile()</strong> function, as shown in the following code, where we define the type of loss function and what kind of optimizers we want to adopt:</p>
			<p class="source-code">model.compile(loss='binary_crossentropy',\</p>
			<p class="source-code">              optimizer='adam',metrics=['accuracy'])</p>
			<p>We have excluded the <strong class="source-inline">compile()</strong> function on purpose. Later, when we are introduced to the GAN model, we will use the <strong class="source-inline">compile()</strong> function to optimize the generator network. So, hang on until then. For now, we will go ahead with the next step of the process, which is defining the discriminator network.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor237"/>Process 3 – Discriminator Network</h2>
			<p>In the previous process, we were introduced to the generative network, a neural network that generated fake samples. The discriminator network is also another neural network, albeit with different functionality from the generator network. The purpose of the discriminator function is to identify whether a given example is a real one or a fake one. Using an analogy, if the generator network is a conman who makes fake currency, then the discriminator network is the super cop who identifies that the currency is fake. Once caught by the super cop, the conman will try to perfect their craft to make better counterfeits so that they can fool the super cop. However, the super cop will also undergo lots of training to know the nuances of different currencies and work toward perfecting the craft of catching whatever the conman generates. We can see here that both these protagonists are in adversarial positions all the time. This is the reason why the network is called a <em class="italic">generative adversarial network.</em></p>
			<p>Taking a cue from the preceding analogy, training a discriminator is similar to the super cop undergoing more training to identify fake currency. The discriminator network is like any binary classifier you would have learned about in machine learning. As part of the training process, the discriminator will be provided with two classes of examples, one generated from the real distribution and the other from the generator distribution. Each of these sets of examples will have their respective labels too. The real distribution will have a label of "1", while the fake distribution will have a label of "0". The discriminator, after being trained, will have to correctly classify whether an example is real or fake, which is a typical binary classification problem.</p>
			<h3 id="_idParaDest-212"><a id="_idTextAnchor238"/>Implementing the Discriminator Network</h3>
			<p>The core structure of the discriminator network would be similar to the generator network we implemented in the previous section. The complete process behind building the discriminator network is as follows:</p>
			<ol>
				<li value="1">Generate batches of real distribution.</li>
				<li>Using the generator network, it generates batches of fake distribution.</li>
				<li>Train the discriminator network with examples of both these distributions. The real distribution will have a label of 1, while the fake distribution will have a label of 0.</li>
				<li>Evaluate the performance of the discriminator.</li>
			</ol>
			<p>In <em class="italic">Steps 1</em> and <em class="italic">2</em>, we have to generate batches of both the real and fake distributions. This will necessitate making use of the real distribution we built in <em class="italic">Exercise 7.01</em>, <em class="italic">Generating a Data Distribution from a Known Function,</em> and the generator network we developed in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>. Since we have to use these two distributions, it would be convenient to package them into two types of functions to efficiently train the discriminator network. Let's look at the two types of functions we will build.</p>
			<h3 id="_idParaDest-213"><a id="_idTextAnchor239"/>Function to Generate Real Samples</h3>
			<p>The content of this function, which is used to generate real samples, is the same as the code we developed in <em class="italic">Exercise 7.01,</em> <em class="italic">Generating a Data Distribution from a Known Function</em>. The only notable addition is the label for the input data. As we stated earlier, the real samples will have a label of 1. So, as labels, we will generate an array of 1s with the same size as the batch size. There is a utility function in <strong class="source-inline">numpy</strong> that can be used to generate a series of 1s called <strong class="source-inline">np.ones((batch,1)</strong>. This will generate an array of 1s whose size is equal to the batch size. Let's revisit the different steps in this function:</p>
			<ol>
				<li value="1">Generate equally spaced numbers to the right and left of a random number.</li>
				<li>Concatenate both sets to get a series that is equal in length to the batch size we require. This is our first feature.</li>
				<li>Generate the second feature by taking the <strong class="source-inline">sine()</strong> function of the first feature we generated in <em class="italic">Step 2</em>.</li>
				<li>Reshape both features so their size is equal to <strong class="source-inline">(batch,1)</strong> and then concatenate them along the columns. This will result in an array of shape <strong class="source-inline">(batch,2)</strong>.</li>
				<li>Generate the labels using the <strong class="source-inline">np.ones((batch,1))</strong> function. The label array will have a dimension of <strong class="source-inline">(batch,1)</strong>.</li>
			</ol>
			<p>The arguments that we will provide to the function are the random number and the batch size. One subtle change to note in <em class="italic">Step 1</em> is that since we want a series equal in length to the batch size, we will take equally spaced numbers to the left and right equal to half of the batch size (batch size /2). In this way, when we combine both series to the left and right, we get a series equal to the batch size we want.</p>
			<h3 id="_idParaDest-214"><a id="_idTextAnchor240"/>Functions to Generate Fake Samples</h3>
			<p>The function(s) to generate fake samples will be the same as what we developed in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>. However, we will have to divide this into three separate functions. The reason for dividing the code we implemented in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em> into three separate functions is for convenience and efficiency during the training process. Let's take a look at these three functions:</p>
			<ul>
				<li><strong class="bold">Function 1</strong>: The first of these functions is used to generate the inputs for generating fake samples. This is the part of <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em> where we gave a batch size and the number of input features and generated random normal numbers using the <strong class="source-inline">randn()</strong> function. The output will be an array of size (<strong class="source-inline">batch,input features</strong>). The arguments to this function are <strong class="source-inline">batch size</strong> and <strong class="source-inline">input feature size</strong>.</li>
				<li><strong class="bold">Function 2</strong>: The second function is the complete six-layer generator network we developed in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>. The inputs to this function are <strong class="source-inline">input feature size</strong> and <strong class="source-inline">output feature size</strong>.</li>
				<li><strong class="bold">Function 3</strong>: The third function is a function that calls both the first and second functions to generate fake samples. In addition to generating fake samples, the function also generates the labels, which in the case of the generator network should be 0. Just like in the discriminator network where we generated a series of 1s, we have a utility function in <strong class="source-inline">numpy</strong> to generate 0s called <strong class="source-inline">np.zeros((batch,1))</strong>. </li>
			</ul>
			<p>Let's look at the complete process for these three functions:</p>
			<ol>
				<li value="1">Generate fake inputs using <em class="italic">function 1</em>.</li>
				<li>Use the generator model function (<em class="italic">function 2</em>) to predict a fake output.</li>
				<li>Generate labels, which is a series of 0s, using the <strong class="source-inline">np.zeros()</strong> function. This is part of <em class="italic">function 3</em>.</li>
			</ol>
			<p>The arguments to the third function are <strong class="source-inline">generator model</strong>, <strong class="source-inline">batch size</strong>, and <strong class="source-inline">input feature size</strong>.</p>
			<h3 id="_idParaDest-215"><a id="_idTextAnchor241"/>Building the Discriminator Network</h3>
			<p>The discriminator network will be built along the same lines as the generator network; that is, it will be created using the <strong class="source-inline">Sequential()</strong> class, the dense layer, and the activation and initialization functions. The only notable exception is that we will also have the optimization layer in the form of the <strong class="source-inline">compile()</strong> function. In the optimization layer, we will define the loss function, which in this case will be <strong class="source-inline">binary_crossentropy</strong> as the discriminator network is a binary classification network. For the optimizer, we will be using the <strong class="source-inline">adam optimizer</strong> as this is found to be very efficient and is a very popular choice.</p>
			<h3 id="_idParaDest-216"><a id="_idTextAnchor242"/>Training the Discriminator Network</h3>
			<p>Now that we have gone through all the components for implementing the discriminator network, let's look at the steps involved in training the discriminator network:</p>
			<ol>
				<li value="1">Generate a random number and then generate a batch of real samples and its labels using the function to generate real samples.</li>
				<li>Generate a batch of fake samples and its labels using the third function described to generate fake samples. The third function will use both the other functions to generate the fake samples.</li>
				<li>Train the discriminator model using the <strong class="source-inline">train_on_batch()</strong> function with the batch of real samples and fake samples. </li>
				<li>Steps <em class="italic">1</em> to <em class="italic">3</em> are repeated for the number of epochs we want the training to run for. This is done through a <strong class="source-inline">for</strong> loop over the number of epochs.</li>
				<li>At every intermediate step, we calculate the accuracy of the model on the fake samples and real samples using the <strong class="source-inline">evaluate()</strong> function. The accuracy of the model is printed.</li>
			</ol>
			<p>Now that we have seen the steps involved in implementing the discriminator network, we'll implement this in the next exercise.</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor243"/>Exercise 7.03: Implementing the Discriminator Network</h2>
			<p>In this exercise, we will build the discriminator network and train the network on both the real samples and fake samples. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and name it <strong class="source-inline">Exercise 7.03</strong>. Import the following library packages:<p class="source-code"># Import the required library functions</p><p class="source-code">import tensorflow as tf</p><p class="source-code">import numpy as np</p><p class="source-code">from numpy.random import randn</p><p class="source-code">from tensorflow.keras.models import Sequential</p><p class="source-code">from tensorflow.keras.layers import Dense</p><p class="source-code">from matplotlib import pyplot</p></li>
				<li>Let's define a function that will generate the features of our real data distribution. The return values of this function will be the real dataset and its label:<p class="source-code-heading">Exercise7.03.ipynb</p><p class="source-code"># Function to generate real samples</p><p class="source-code">def realData(loc,batch):</p><p class="source-code">    """</p><p class="source-code">    loc is the random location or mean around which samples are centred</p><p class="source-code">    """</p><p class="source-code">    """</p><p class="source-code">    Generate numbers to right of the random point</p><p class="source-code">    """</p><p class="source-code">    xr = np.arange(loc,loc+(0.1*batch/2),0.1)</p><p class="source-code">    xr = xr[0:int(batch/2)]</p><p class="source-code">    """</p><p class="source-code">    Generate numbers to left of the random point</p><p class="source-code">    """</p><p class="source-code">    xl = np.arange(loc-(0.1*batch/2),loc,0.1)</p><p class="source-code-link">The complete code for this step can be found at <a href="https://packt.live/3fe02j3">https://packt.live/3fe02j3</a>.</p><p>The function we are defining here comprises code that was used to generate the <strong class="source-inline">sine()</strong> wave dataset in <em class="italic">Exercise 7.01</em>, <em class="italic">Generating a Data Distribution from a Known Function</em>. The inputs to this function are the random number and the batch size. Once the random number is provided, the series is generated with the same process we followed in <em class="italic">Exercise 7.01</em>, <em class="italic">Generating a Data Distribution from a Known Function</em>. We also generate the labels for the real data distribution, which will be 1. The final return value will be the two features and the label. </p></li>
				<li>Let's define a function called <strong class="source-inline">fakeInputs</strong> to generate inputs for the generator function (this is <em class="italic">function 1</em>, which we explained in the <em class="italic">Functions to Generate Fake Samples</em> section):<p class="source-code"># Function to generate inputs for generator function</p><p class="source-code">def fakeInputs(batch,infeats):</p><p class="source-code">    """</p><p class="source-code">    Sample data points equal to (batch x input feature size) </p><p class="source-code">    from a random distribution</p><p class="source-code">    """</p><p class="source-code">    genInput = randn(infeats * batch)</p><p class="source-code">    # Reshape the input</p><p class="source-code">    X = genInput.reshape(batch ,infeats)</p><p class="source-code">    return X</p><p>In this function, we're generating random numbers in the format we want <strong class="source-inline">([batch size , input features])</strong>. This function generates the fake data that was sampled from the random distribution as the return value. </p></li>
				<li>Next, we'll be defining a function that will return a generator model:<p class="source-code"># Function for the generator model</p><p class="source-code">def genModel(infeats,outfeats):</p><p class="source-code">    #Defining the Generator model</p><p class="source-code">    Genmodel = Sequential()</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'linear',\</p><p class="source-code">                       kernel_initializer='he_uniform',\</p><p class="source-code">                       input_dim=infeats))</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'relu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(64,activation = 'elu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'elu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'selu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(outfeats,activation = 'selu'))</p><p class="source-code">    return Genmodel</p><p>This is the same model that we implemented in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>. The return value for this function will be the generator model.</p></li>
				<li>The following function will be used to create fake samples using the generator model:<p class="source-code"># Function to create fake samples using the generator model</p><p class="source-code">def fakedataGenerator(Genmodel,batch,infeats):</p><p class="source-code">    # first generate the inputs to the model</p><p class="source-code">    genInputs = fakeInputs(batch,infeats)</p><p class="source-code">    """</p><p class="source-code">    use these inputs inside the generator model </p><p class="source-code">    to generate fake distribution</p><p class="source-code">    """</p><p class="source-code">    X_fake = Genmodel.predict(genInputs)</p><p class="source-code">    # Generate the labels of fake data set</p><p class="source-code">    y_fake = np.zeros((batch,1))</p><p class="source-code">    return X_fake,y_fake</p><p>In the preceding code, we are implementing <em class="italic">function 3</em>, which we covered in the <em class="italic">Functions to Generate Fake Samples</em> section. As you can see, we call the generator model we defined in <em class="italic">Step 4</em> as input, along with the batch size and the input features. The return values for this function are the fake data that's generated, along with its label (<strong class="source-inline">0</strong>).</p></li>
				<li>Now, let's define the parameters to be used in the functions we have just created:<p class="source-code">"""</p><p class="source-code">Define the arguments like batch size,input feature size </p><p class="source-code">and output feature size</p><p class="source-code">"""</p><p class="source-code">batch = 128</p><p class="source-code">infeats = 10</p><p class="source-code">outfeats = 2</p></li>
				<li>Let's build the discriminator model using the following code: <p class="source-code"># Define the discriminator model</p><p class="source-code">Discmodel = Sequential()</p><p class="source-code">Discmodel.add(Dense(16, activation='relu',\</p><p class="source-code">                    kernel_initializer = 'he_uniform',\</p><p class="source-code">                    input_dim=outfeats))</p><p class="source-code">Discmodel.add(Dense(16,activation='relu' ,\</p><p class="source-code">                    kernel_initializer = 'he_uniform'))</p><p class="source-code">Discmodel.add(Dense(16,activation='relu' ,\</p><p class="source-code">                    kernel_initializer = 'he_uniform'))</p><p class="source-code">Discmodel.add(Dense(1,activation='sigmoid'))</p><p class="source-code"># Compiling the model</p><p class="source-code">Discmodel.compile(loss='binary_crossentropy',\</p><p class="source-code">                  optimizer='adam', metrics=['accuracy'])</p><p>The mode of construction for the discriminator model is similar to what we did in the generator network. Please note that the activation function for the last layer will be a sigmoid as we need a probability regarding whether the output is a real network or a fake network.</p></li>
				<li>Print the summary of the discriminator network:<p class="source-code"># Print the summary of the discriminator model</p><p class="source-code">Discmodel.summary()</p><p>You should get the following output:</p><div id="_idContainer220" class="IMG---Figure"><img src="image/B15385_07_09.jpg" alt="Figure 7.9: Model summary&#13;&#10;"/></div><p class="figure-caption">Figure 7.9: Model summary</p><p>From the summary, we can see the size of the network based on the architecture we defined. We can see that the first three dense layers have 16 neurons each, which we defined in <em class="italic">Step 7</em> when we built the discriminator network. The final layer will only have one output as this is a sigmoid layer. This outputs the probability of whether the data distribution is real (<strong class="source-inline">1</strong>) or fake (<strong class="source-inline">0</strong>).</p></li>
				<li>Invoke the generator model function to be used in the training process:<p class="source-code"># Calling the Generator model function</p><p class="source-code">Genmodel = genModel(infeats,outfeats)</p><p class="source-code">Genmodel.summary()</p><p>You should get the following output:</p><div id="_idContainer221" class="IMG---Figure"><img src="image/B15385_07_10.jpg" alt="Figure 7.10: Model summary&#13;&#10;"/></div><p class="figure-caption">Figure 7.10: Model summary</p><p>You will notice that the architecture is the same as what we developed in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>.</p></li>
				<li>Now, we need to define the number of epochs to train the network for, as follows:<p class="source-code"># Defining the number of epochs</p><p class="source-code">nEpochs = 20000</p></li>
				<li>Now, let's start training the discriminator network:</li>
			</ol>
			<p class="source-code-heading">Exercise7.03.ipynb</p>
			<p class="source-code"># Train the discriminator network</p>
			<p class="source-code">for i in range(nEpochs):</p>
			<p class="source-code">    # Generate the random number for generating real samples</p>
			<p class="source-code">    loc = np.random.normal(3,1,1)</p>
			<p class="source-code">    """</p>
			<p class="source-code">    Generate samples equal to the bath size </p>
			<p class="source-code">    from the real distribution</p>
			<p class="source-code">    """</p>
			<p class="source-code">    x_real, y_real = realData(loc,batch)</p>
			<p class="source-code">    #Generate fake samples using the fake data generator function</p>
			<p class="source-code">    x_fake, y_fake = fakedataGenerator(Genmodel,batch,infeats)</p>
			<p class="source-code-link">The complete code for this step can be found at <a href="https://packt.live/3fe02j3">https://packt.live/3fe02j3</a>.</p>
			<p>Here, we iterate the training of the model on both the real and fake data for 20,000 epochs. The number of epochs is arrived at after some level of experimentation. We should try this out with different values for the number of epochs until we get some good accuracy figures. For every 4,000 epochs, we print the accuracy of the model on both the real dataset and the fake dataset. The printing frequency is arbitrary and is based on the number of plots you want to see to check the progress of the training process. After training, you will see that the discriminator achieves very good accuracy levels.</p>
			<p>You should get an output similar to the following:</p>
			<p class="source-code">Real accuracy:0.265625,Fake accuracy:0.59375</p>
			<p class="source-code">Real accuracy:1.0,Fake accuracy:0.828125</p>
			<p class="source-code">Real accuracy:1.0,Fake accuracy:0.90625</p>
			<p class="source-code">Real accuracy:1.0,Fake accuracy:0.9453125</p>
			<p class="source-code">Real accuracy:1.0,Fake accuracy:0.9453125</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Since we are working with random values here, the output you get may vary from the one you see here. It will also vary with every run.</p>
			<p>From the accuracy levels, we can see that the discriminator was very good (accuracy = 1) at identifying the real dataset initially and shows relatively poor accuracy levels for the fake dataset. After around 4,000 epochs, we can see that the discriminator has become good at identifying both the fake and real datasets as both the accuracies are near 1.0.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fe02j3">https://packt.live/3fe02j3</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2ZYiYMG">https://packt.live/2ZYiYMG</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>In this exercise, we defined different helper functions and also built the discriminator function. Finally, we trained the discriminator model on real data and fake data. At the end of the training process, we saw that the discriminator learned to discriminate between the real dataset and fake dataset really well. Having trained the discriminator network, it's now time to move on to the climax, which is building the GAN. </p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor244"/>Process 4 – Implementing the GAN</h2>
			<p>We have finally arrived at the moment we have been waiting for all this while. In the previous three processes, we have been progressively building all the building blocks for the GAN, such as the fake data generator, real data generator, generator network, and discriminator network. The GAN is, in fact, the integration of all these building blocks. The real game in the GAN is the process in which we integrate these components with each other. Let's address this right away.</p>
			<h3 id="_idParaDest-219"><a id="_idTextAnchor245"/>Integrating All the Building Blocks</h3>
			<p>When building the discriminator network, we generated real samples and fake samples and fed them to the discriminator during training. The training process made the discriminator "smart", which enabled it to correctly identify what is fake and what is real. In probability terms, this would mean that when the discriminator gets a fake sample, it will predict a probability close to "0" and when the sample is real, it will predict a probability close to "1". However, getting the discriminator to be smart is not our end objective. Our end objective is to get the generator model smart so that it starts generating examples that look like real samples and, in the process, fools the discriminator. This can be achieved by training the generator and updating its parameters (that is, the weights and bias) to enable it to generate samples that look like real samples. However, there is still a problem, because in the generator network, we did not include an optimizer step and therefore the generator network by itself cannot be trained. The way to get around this problem is by building another network (let's call it <strong class="bold">Ganmodel</strong>) that connects the generator and discriminator in sequence and then include an optimizer function in the new network so that it goes and updates the parameters of its constituents when backpropagation happens. In terms of pseudocode, this network will look something like this:</p>
			<p class="source-code">Ganmodel = Sequential()</p>
			<p class="source-code"># First adding the generator model</p>
			<p class="source-code">Ganmodel.add(Genmodel)</p>
			<p class="source-code">"""</p>
			<p class="source-code">Next adding the discriminator model </p>
			<p class="source-code">without training the parameters</p>
			<p class="source-code">"""</p>
			<p class="source-code">Ganmodel.add(Discmodel)</p>
			<p class="source-code"># Compile the model for loss to optimise the Generator model</p>
			<p class="source-code">Ganmodel.compile(loss='binary_crossentropy',optimizer = 'adam')</p>
			<p>In this model, the generator model will generate fake samples that are fed into the discriminator model, which in turn will then generate a probability as to whether the example is fake or real. Based on the label of the example, it will have a certain loss that will be propagated through the discriminator to the generator, updating the parameters of both the models. In other words, based on the loss, the backpropagation algorithm will update each parameter based on the gradient of the parameter with respect to the loss. So, this will solve our problem of not having defined an optimizer function for the generator.</p>
			<p>However, there is one more catch to this network. Our discriminator network has already been trained and was made really smart when we trained the discriminator network separately. We don't want to train the discriminator model again in this new network and make it smarter. This can be solved by defining that we don't want to train the discriminator parameters in the network. With this new change, the <strong class="bold">Ganmodel</strong> would look as follows:</p>
			<p class="source-code"># First define that discriminator model cannot be trained</p>
			<p class="source-code">Discmodel.trainable = False</p>
			<p class="source-code">Ganmodel = Sequential()</p>
			<p class="source-code"># First adding the generator model</p>
			<p class="source-code">Ganmodel.add(Genmodel)</p>
			<p class="source-code">"""</p>
			<p class="source-code">Next adding the discriminator model </p>
			<p class="source-code">without training the parameters</p>
			<p class="source-code">"""</p>
			<p class="source-code">Ganmodel.add(Discmodel)</p>
			<p class="source-code"># Compile the model for loss to optimise the Generator model</p>
			<p class="source-code">Ganmodel.compile(loss='binary_crossentropy',optimizer = 'adam')</p>
			<p>By making <strong class="source-inline">Discmodel.trainable = False</strong>, we're telling the network that we don't want to update the parameters of the discriminator network during backpropagation. So, the discriminator network will act as a conduit to pass on the error during the backpropagation stage to the generator network.</p>
			<p>If you think all our problems have been solved, you are in for a rude awakening. We know that when the discriminator model is presented with a fake distribution, it will predict the probability to a value very close to <strong class="source-inline">0</strong>. We also know that the labels of the fake dataset are also <strong class="source-inline">0</strong>. So, in terms of loss, there would be very minimal loss being propagated back to the generator. With such a minuscule loss, the subsequent update to the parameters of the generator model will also be very minuscule. This will not enable the generator to generate samples that are like the real samples. The generator will only be able to learn if a large loss is generated and propagated to it so that its parameters are updated in the direction of real parameters. So, how do we get the loss to be high? What if, instead of defining the labels of the fake samples as <strong class="source-inline">0</strong>, we define them as <strong class="source-inline">1</strong>? If we do this, the discriminator model, as usual, will predict a probability close to 0 for fake examples. However, we now have a situation where the loss function would be large because the labels are 1. When this large loss function gets propagated back to the generator network, the parameters will be updated significantly, which will enable it to be smarter. Subsequently, what will happen is the generator will start generating samples that look more like the real samples, and they would meet our objective. </p>
			<p>This concept can be explained with the following figure. Here, we can see that at the initial level of training, the probability for the fake data is close to zero (<strong class="source-inline">0.01</strong>) and the label that we've given for the fake data is <strong class="source-inline">1</strong>. This will ensure that we get a large loss that gets backpropagated to the generator network:</p>
			<p> </p>
			<div>
				<div id="_idContainer222" class="IMG---Figure">
					<img src="image/B15385_07_11.jpg" alt="Figure 7.11: GAN process&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.11: GAN process</p>
			<p>Now that we have seen the dynamics of the GAN model, let's tie all the pieces together to define the process we will follow in order to build the GAN.</p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor246"/>Process for Building the GAN </h2>
			<p>The complete process for the GAN is all about tying together the pieces we have built into a logical order. We will use all the functions we built when we defined the discriminator function. In addition, we will also make new functions; for instance, a function for the discriminator network and another function for the GAN model. All these functions will be called at specific points to make the GAN model. The end-to-end process will be as follows:</p>
			<ol>
				<li value="1">Define the function to generate a real data distribution. This function is the same function we developed in <em class="italic">Exercise 7.03</em>, <em class="italic">Implementing the Discriminator Network</em> for the discriminator network.</li>
				<li>Define the three functions that were created for generating fake samples. These are a function for generating fake inputs, a function for the generator network, and a function for generating fake samples and labels. All these functions are the same as the ones we developed in <em class="italic">Exercise 7.03</em>, <em class="italic">Implementing the Discriminator Network </em>for the discriminator network.</li>
				<li>Create a new function for the discriminator network, just like we created in <em class="italic">Exercise 7.03</em>, <em class="italic">Implementing the Discriminator Network</em>. This function will have the output features (2) as its input as both the real dataset and fake dataset have two features. This function will return the discriminator model. </li>
				<li>Create a new function for the GAN model as per the pseudocode we developed in the previous section (<em class="italic">Process 4 – Building a GAN</em>). This function will have the generator model and the discriminator model as its inputs.</li>
				<li>Start the training process.</li>
			</ol>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor247"/>The Training Process</h2>
			<p>The training process here is similar to the process we implemented in <em class="italic">Exercise 7.03</em>, <em class="italic">Implementing the Discriminator Network</em> for the discriminator network. The steps for the training process are as follows:</p>
			<ol>
				<li value="1">Generate a random number and then generate a batch of real samples and its labels using the function to generate real samples.</li>
				<li>Generate a batch of fake samples and its labels using the third function we described regarding the functions for generating fake samples. The third function will use both the other functions to generate the fake samples.</li>
				<li>Train the discriminator model using the <strong class="source-inline">train_on_batch()</strong> function using the batch of real samples and fake samples. </li>
				<li>Generate another batch of fake inputs to train the GAN model. These fake samples are generated using <em class="italic">function 1</em> in the fake sample generation process.</li>
				<li>Generate the labels for the fake samples that are intended to fool the discriminator. These labels will be 1s instead of 0s.</li>
				<li>Train the GAN model using the <strong class="source-inline">train_on_batch()</strong> function using the fake samples and its labels, as described in <em class="italic">Steps 4</em> and <em class="italic">5</em>.</li>
				<li><em class="italic">Steps 1</em> to <em class="italic">6 </em>are repeated for the number of epochs we want the training to run for. This is done through a <strong class="source-inline">for</strong> loop over the number of epochs.</li>
				<li>At every intermediate step, we calculate the accuracy of the model on the fake samples and real samples using the <strong class="source-inline">evaluate()</strong> function. The accuracy of the model is also printed.</li>
				<li>We also generate output plots at certain epochs.</li>
			</ol>
			<p>Now that we have seen the complete process behind training a GAN, let's dive into <em class="italic">Exercise 7.04</em>, <em class="italic">Implementing the GAN</em>, which implements this process.</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor248"/>Exercise 7.04: Implementing the GAN</h2>
			<p>In this exercise, we will build and train the GAN by implementing the process we discussed in the previous section. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and name it <strong class="source-inline">Exercise 7.04</strong>. Import the following library packages:<p class="source-code"># Import the required library functions</p><p class="source-code">import tensorflow as tf</p><p class="source-code">import numpy as np</p><p class="source-code">from numpy.random import randn</p><p class="source-code">from tensorflow.keras.models import Sequential</p><p class="source-code">from tensorflow.keras.layers import Dense</p><p class="source-code">from matplotlib import pyplot</p></li>
				<li>Let's create a function to generate the real samples:<p class="source-code-heading">Exercise7.04.ipynb</p><p class="source-code"># Function to generate real samples</p><p class="source-code">def realData(loc,batch):</p><p class="source-code">    """</p><p class="source-code">    loc is the random location or mean </p><p class="source-code">    around which samples are centred</p><p class="source-code">    """</p><p class="source-code">    # Generate numbers to right of the random point</p><p class="source-code">    xr = np.arange(loc,loc+(0.1*batch/2),0.1)</p><p class="source-code">    xr = xr[0:int(batch/2)]</p><p class="source-code">    # Generate numbers to left of the random point</p><p class="source-code">    xl = np.arange(loc-(0.1*batch/2),loc,0.1)</p><p class="source-code-link">The complete code for this step can be found on <a href="https://packt.live/3iIJHVS">https://packt.live/3iIJHVS</a></p><p>The function we're creating here follows the same process we implemented in <em class="italic">Exercise 7.01</em>, <em class="italic">Generating a Data Distribution from a Known Function</em>. The inputs to this function are the random number and the batch size. We get the real data distribution with both our features, along with the label for the real data distribution as return values, from this function. The return values from this function are the real dataset and its label.</p></li>
				<li>Here, let's define the function to generate inputs for the generator network:<p class="source-code"># Function to generate inputs for generator function</p><p class="source-code">def fakeInputs(batch,infeats):</p><p class="source-code">"""</p><p class="source-code">    Sample data points equal to (batch x input feature size)</p><p class="source-code"> from a random distribution</p><p class="source-code">    """</p><p class="source-code">    genInput = randn(infeats * batch)</p><p class="source-code">    # Reshape the input</p><p class="source-code">    X = genInput.reshape(batch ,infeats)</p><p class="source-code">    return X</p><p>This function generates the fake data that was sampled from the random distribution as output.</p></li>
				<li>Now, let's go ahead and define the function for building the generator network:<p class="source-code"># Function for the generator model</p><p class="source-code">def genModel(infeats,outfeats):</p><p class="source-code">    # Defining the Generator model</p><p class="source-code">    Genmodel = Sequential()</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'linear',\</p><p class="source-code">                       kernel_initializer='he_uniform',\</p><p class="source-code">                       input_dim=infeats))</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'relu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(64,activation = 'elu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'elu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(32,activation = 'selu',\</p><p class="source-code">                       kernel_initializer='he_uniform'))</p><p class="source-code">    Genmodel.add(Dense(outfeats,activation = 'selu'))</p><p class="source-code">    return Genmodel</p><p>This is the same function we built in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>. This function returns the generator model.</p></li>
				<li>In this step, we will define the function that will create fake samples using the generator network:<p class="source-code"># Function to create fake samples using the generator model</p><p class="source-code">def fakedataGenerator(Genmodel,batch,infeats):</p><p class="source-code">    # first generate the inputs to the model</p><p class="source-code">    genInputs = fakeInputs(batch,infeats)</p><p class="source-code">    """</p><p class="source-code">    use these inputs inside the generator model </p><p class="source-code">    to generate fake distribution</p><p class="source-code">    """</p><p class="source-code">    X_fake = Genmodel.predict(genInputs)</p><p class="source-code">    # Generate the labels of fake data set</p><p class="source-code">    y_fake = np.zeros((batch,1))</p><p class="source-code">    return X_fake,y_fake</p><p>The function we are defining here takes the random data distribution as input (to the generator network we defined in the previous step) and generates the fake distribution. The label for the fake distribution, which is 0, is also generated within the function. In other words, the outputs from this function are the fake dataset and its label.</p></li>
				<li>Now, let's define the parameters that we will be using within the different functions:<p class="source-code">"""</p><p class="source-code">Define the arguments like batch size,input feature size </p><p class="source-code">and output feature size</p><p class="source-code">"""</p><p class="source-code">batch = 128</p><p class="source-code">infeats = 10</p><p class="source-code">outfeats = 2</p></li>
				<li>Next, let's build the discriminator model as a function:<p class="source-code"># Discriminator model as a function</p><p class="source-code">def discModel(outfeats):</p><p class="source-code">    Discmodel = Sequential()</p><p class="source-code">    Discmodel.add(Dense(16, activation='relu',\</p><p class="source-code">                        kernel_initializer = 'he_uniform',\</p><p class="source-code">                        input_dim=outfeats))</p><p class="source-code">    Discmodel.add(Dense(16,activation='relu' ,\</p><p class="source-code">                        kernel_initializer = 'he_uniform'))</p><p class="source-code">    Discmodel.add(Dense(16,activation='relu' ,\</p><p class="source-code">                        kernel_initializer = 'he_uniform'))</p><p class="source-code">    Discmodel.add(Dense(1,activation='sigmoid'))</p><p class="source-code">    # Compiling the model</p><p class="source-code">    Discmodel.compile(loss='binary_crossentropy',\</p><p class="source-code">                      optimizer='adam',metrics=['accuracy'])</p><p class="source-code">    return Discmodel</p><p>The network architecture will be like the one we developed in <em class="italic">Exercise 7.03</em>, <em class="italic">Implementing the Discriminator Network</em>. This function will return the discriminator.</p></li>
				<li>Print the summary of the discriminator network:<p class="source-code"># Print the summary of the discriminator model</p><p class="source-code">Discmodel = discModel(outfeats)</p><p class="source-code">Discmodel.summary()</p><p>You should get the following output:</p><p> </p><div id="_idContainer223" class="IMG---Figure"><img src="image/B15385_07_12.jpg" alt="Figure 7.12: Discriminator model summary&#13;&#10;"/></div><p class="figure-caption">Figure 7.12: Discriminator model summary</p><p>This output is the same as the one we received for the network we implemented in <em class="italic">Exercise 7.03</em>, <em class="italic">Implementing the Discriminator Network</em>, where we defined the discriminator function. </p></li>
				<li>Invoke the generator model function for use in the training process:<p class="source-code"># Calling the Generator model function</p><p class="source-code">Genmodel = genModel(infeats,outfeats)</p><p class="source-code">Genmodel.summary()</p><p>You should get the following output:</p><div id="_idContainer224" class="IMG---Figure"><img src="image/B15385_07_13.jpg" alt="Figure 7.13: Generator model summary &#13;&#10;"/></div><p class="figure-caption">Figure 7.13: Generator model summary </p><p>You will notice that the architecture is the same as what we developed in <em class="italic">Exercise 7.02,</em> <em class="italic">Building a Generative Network</em>.</p></li>
				<li>Before we begin training, let's visualize the fake data distribution. For this, we generate the fake dataset using the <strong class="source-inline">fakedataGenerator()</strong> function and then visualize it using <strong class="source-inline">pyplot</strong>:<p class="source-code"># Let us visualize the initial fake data</p><p class="source-code">x_fake, _ = fakedataGenerator(Genmodel,batch,infeats)</p><p class="source-code"># Plotting the fake data using pyplot</p><p class="source-code">pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')</p><p class="source-code"># Adding x and y labels</p><p class="source-code">pyplot.xlabel('Feature 1 of the distribution')</p><p class="source-code">pyplot.ylabel('Feature 2 of the distribution')</p><p class="source-code">pyplot.show()</p><p>You should get an output similar to the following. Please note that data generation is stochastic in nature (random) and that you might not get the same plot:</p><p> </p><div id="_idContainer225" class="IMG---Figure"><img src="image/B15385_07_14.jpg" alt="Figure 7.14: Plot from the fake input distribution&#13;&#10;"/></div><p class="figure-caption">Figure 7.14: Plot from the fake input distribution</p><p>From the preceding plot, you can see that the data distribution is quite random. We need to convert this random data into a form similar to the sine wave, which was our real data distribution.</p></li>
				<li>Now, let's define the GAN model as a function. This function is similar to the pseudocode we developed in <em class="italic">Process 4</em>, where we defined the GAN. The GAN is a wrapper model around the generator model and the discriminator model. Please note that we define the discriminator model as <strong class="bold">not trainable</strong> within this function:<p class="source-code">"""</p><p class="source-code">Define the combined generator and discriminator model, </p><p class="source-code">for updating the generator</p><p class="source-code">"""</p><p class="source-code">def ganModel(Genmodel,Discmodel):</p><p class="source-code">    # First define that discriminator model cannot be trained</p><p class="source-code">    Discmodel.trainable = False</p><p class="source-code">    Ganmodel = Sequential()</p><p class="source-code">    # First adding the generator model</p><p class="source-code">    Ganmodel.add(Genmodel)</p><p class="source-code">    """</p><p class="source-code">    Next adding the discriminator model </p><p class="source-code">    without training the parameters</p><p class="source-code">    """</p><p class="source-code">    Ganmodel.add(Discmodel)</p><p class="source-code">    # Compile the model for loss to optimise the Generator model</p><p class="source-code">    Ganmodel.compile(loss='binary_crossentropy',optimizer = 'adam')</p><p class="source-code">    return Ganmodel</p><p>This function will return the GAN model.</p></li>
				<li>Now, let's invoke the GAN function. Please note that the inputs to the GAN model are the previously defined generator model and the discriminator model:<p class="source-code"># Initialise the gan model</p><p class="source-code">gan_model = ganModel(Genmodel,Discmodel)</p></li>
				<li>Print the summary of the GAN model:<p class="source-code"># Print summary of the GAN model</p><p class="source-code">gan_model.summary()</p><p>You should get the following output:</p><p> </p><div id="_idContainer226" class="IMG---Figure"><img src="image/B15385_07_15.jpg" alt="Figure 7.15: Summary of the GAN model&#13;&#10;"/></div><p class="figure-caption">Figure 7.15: Summary of the GAN model</p><p>Note that the parameters of each layer of the GAN model are equivalent to the parameters of the generator and discriminator models. The GAN model is just a wrapper around these two models we defined earlier.</p></li>
				<li>Let's define the number of epochs to train the network:<p class="source-code"># Defining the number of epochs</p><p class="source-code">nEpochs = 20000</p></li>
				<li>Now, we start the process of training the network:</li>
			</ol>
			<p class="source-code-heading">Exercise7.04.ipynb</p>
			<p class="source-code"># Train the GAN network</p>
			<p class="source-code">for i in range(nEpochs):</p>
			<p class="source-code">    # Generate the random number for generating real samples</p>
			<p class="source-code">    loc = np.random.normal(3,1,1)</p>
			<p class="source-code">    """</p>
			<p class="source-code">    Generate samples equal to the bath size </p>
			<p class="source-code">    from the real distribution</p>
			<p class="source-code">    """</p>
			<p class="source-code">    x_real, y_real = realData(loc,batch)</p>
			<p class="source-code">    #Generate fake samples using the fake data generator function</p>
			<p class="source-code">    x_fake, y_fake = fakedataGenerator(Genmodel,batch,infeats)</p>
			<p class="source-code">    # train the  discriminator on the real samples</p>
			<p class="source-code">    Discmodel.train_on_batch(x_real, y_real)</p>
			<p class="source-code">    # train the discriminator on the fake samples</p>
			<p class="source-code">    Discmodel.train_on_batch(x_fake, y_fake)</p>
			<p class="source-code-link">The complete code for this step can be found at <a href="https://packt.live/3iIJHVS">https://packt.live/3iIJHVS</a></p>
			<p>It needs to be noted here that the training of the discriminator model with the fake and real samples and the training of the GAN model happens concurrently. The only difference is that training the GAN model proceeds without updating the parameters of the discriminator model. The other thing to note is that, inside the GAN, the labels for the fake samples would be 1. This is to generate large loss terms that will be backpropagated through the discriminator network to update the generator parameters.</p>
			<p class="callout-heading">Note:</p>
			<p class="callout">Please note that the third line of code from the bottom (<strong class="source-inline">filename = 'GAN_Training_Plot%03d.png' % (i)</strong>) saves a plot once every 2,000 epochs. The plots will be saved in the same folder that your Jupyter Notebook is located in. You can also specify the path you want to save the plots at. This can be done as follows:</p>
			<p class="callout"><strong class="source-inline">filename = 'D:/Project/GAN_Training_Plot%03d.png' % (i)</strong></p>
			<p class="callout">You can access the plots that were generated through this exercise at <a href="https://packt.live/2W1FjaI">https://packt.live/2W1FjaI</a>.</p>
			<p>You should get an output similar to the one shown here. Since the predictions are stochastic in nature (that is to say, they're random), you might not get the same plots shown in this example. Your values may vary; however, they will be similar to what's shown here:</p>
			<p class="source-code">Real accuracy:0.2421875,Fake accuracy:0.0234375</p>
			<p class="source-code">Real accuracy:0.625,Fake accuracy:0.609375</p>
			<p class="source-code">Real accuracy:0.6484375,Fake accuracy:0.9609375</p>
			<p class="source-code">Real accuracy:0.84375,Fake accuracy:0.734375</p>
			<p class="source-code">Real accuracy:0.3671875,Fake accuracy:0.734375</p>
			<p class="source-code">Real accuracy:0.53125,Fake accuracy:0.703125</p>
			<p class="source-code">Real accuracy:0.578125,Fake accuracy:0.640625</p>
			<p class="source-code">Real accuracy:0.640625,Fake accuracy:0.8203125</p>
			<p class="source-code">Real accuracy:0.515625,Fake accuracy:0.7109375</p>
			<p class="source-code">Real accuracy:0.5625,Fake accuracy:0.859375</p>
			<p>From the preceding output, you can see that the real dataset accuracy levels are progressively going down and that the fake dataset's accuracy is going up. In ideal situations, the accuracy of the discriminator network has to be around the 0.5 level, which indicates that the discriminator is really confused as to whether a sample is fake or real. Now, let's look at some of the plots that were generated at different epoch levels as to how the data points are converging to look like the real function. The following plot is the distribution of the random data point before it was fed into the GAN (<em class="italic">Step 10</em>):</p>
			<p> </p>
			<div>
				<div id="_idContainer227" class="IMG---Figure">
					<img src="image/B15385_07_16.jpg" alt="Figure 7.16: Plot from the fake input distribution&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.16: Plot from the fake input distribution</p>
			<p>Notice the distribution of the data where the data points are mostly centered on a mean of 0. This is because the random points are generated from a normal distribution that has a mean of 0 and a standard deviation of 1. Now, using the raw data, let's study the progression of the fake dataset as the generator is trained.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3iIJHVS">https://packt.live/3iIJHVS</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3gF5DPW">https://packt.live/3gF5DPW</a>. You must execute the entire Notebook in order to get the desired result.</p>
			<p>The three plots shown below map the progression of the fake data distribution vis-a-vis the real data distribution. The <em class="italic">x</em> axis represents feature 1, while the <em class="italic">y</em> axis represents feature 2. In the plots, the red points pertain to the data from the real distribution and the blue plots pertain to the data from the fake distribution. From the following plot, we can see that at epoch <strong class="source-inline">2000</strong>, the fake plots are within the domain; however, they are not aligned to the shape of the real data distribution.</p>
			<div>
				<div id="_idContainer228" class="IMG---Figure">
					<img src="image/B15385_07_17.jpg" alt="Figure 7.17: Plot of fake data distribution vis-à-vis the real data distribution at epoch 2000&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.17: Plot of fake data distribution vis-à-vis the real data distribution at epoch 2000</p>
			<p>By epoch <strong class="source-inline">10000</strong>, which is when the generator has been trained almost halfway, there is a consolidation nearer to the real data distribution:</p>
			<div>
				<div id="_idContainer229" class="IMG---Figure">
					<img src="image/B15385_07_18.jpg" alt="Figure 7.18: Plot of fake data distribution vis-à-vis the real data distribution at epoch 10000&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.18: Plot of fake data distribution vis-à-vis the real data distribution at epoch 10000</p>
			<p>By epoch <strong class="source-inline">18000</strong>, we can see that most of the points are aligned to the real data distribution, which is an indicator that the GAN has been trained reasonably well.</p>
			<div>
				<div id="_idContainer230" class="IMG---Figure">
					<img src="image/B15385_07_19.jpg" alt="Figure 7.19: Plot of fake data distribution vis-à-vis the real data distribution at epoch 18000&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.19: Plot of fake data distribution vis-à-vis the real data distribution at epoch 18000</p>
			<p>However, you can see that the data points after <strong class="source-inline">x = 4</strong> have a lot more noise than the ones on the left. One reason for this could be the random data distribution we generated before we trained the <em class="italic">GAN(Step 10)</em> contains data that is distributed predominantly between  <strong class="source-inline">-2</strong> and <strong class="source-inline">4</strong>. Such data is aligning well to the target distribution (sine wave) within the same range and is a little wobbly around the target distribution to the right of <strong class="source-inline">x = 4</strong>. However, you should also note that getting 100% alignment to the target distribution is an extremely difficult proposition that would involve experimenting with different model architectures and more experiments. We encourage you to experiment and be innovative with different components within the architecture to get the distribution more aligned.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The results we have gotten in the above exercise will vary every time we run the code. </p>
			<p>This brings us to the end of the complete process of progressively building a GAN. Through a series of exercises, we have learned what a GAN is, its constituents, and how all of them are tied together to train a GAN. We will take what we've learned forward and develop more advanced GANs using different datasets.</p>
			<h1 id="_idParaDest-223"><a id="_idTextAnchor249"/>Deep Convolutional GANs</h1>
			<p>In the previous sections, where we implemented a GAN, we made use of an architecture based on the <strong class="bold">Multi-Layer Perceptron</strong> (<strong class="bold">MLP</strong>). As you may recall from the previous chapters, MLPs have fully connected layers. This implies that all the neurons in each layer have connections to all the neurons of the subsequent layer. For this reason, MLPs are also called fully connected layers. The GAN that we developed in the previous section can also be called a <strong class="bold">Fully Connected GAN</strong> (<strong class="bold">FCGAN</strong>). In this section, we will learn about another architecture called <strong class="bold">Deep Convolutional GANs</strong> (<strong class="bold">DCGANS</strong>). As the name implies, this is based on the <strong class="bold">Convolutional Neural Network</strong> (<strong class="bold">CNN</strong>) architecture that you learned about in <em class="italic">Chapter 4</em>, <em class="italic">Deep Learning for Text – Embeddings</em>. Let's revisit some of the building blocks of DCGANs.</p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor250"/>Building Blocks of DCGANs</h2>
			<p>Most of the building blocks of DCGANs are similar to what you learned about when you were introduced to CNNs in <em class="italic">Chapter 3</em>, <em class="italic">Image Classification with Convolutional Neural Networks</em>. Let's revisit some of the important ones.</p>
			<p><strong class="bold">Convolutional Layers</strong></p>
			<p>As you learned in <em class="italic">Chapter 3</em>, <em class="italic">Image Classification with Convolutional Neural Networks</em>, convolutional operations involve filters or kernels moving over the input image to generate a set of feature maps. The convolutional layer can be implemented in Keras using the following line of code:</p>
			<p class="source-code">from tensorflow.keras import Sequential</p>
			<p class="source-code">model = Sequential()</p>
			<p class="source-code">model.add(Conv2D(64, kernel_size=(5, 5),\</p>
			<p class="source-code">                 strides=(2,2), padding='same'))</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The above code block is solely meant to explain how the code is implemented. It may not result in a desirable output when run in its current form. For now, try to understand the syntax completely; we will be putting this code into practice soon.</p>
			<p>In the first part of the preceding code, the <strong class="source-inline">Sequential()</strong> class is imported from the <strong class="source-inline">tensorflow.keras</strong> module. It is then instantiated to a variable model in the second line of code. The convolutional layer is added to the <strong class="source-inline">Sequential()</strong> class by defining the number of filters, kernel size, the required strides, and the padding indicators. In the preceding line of code, 64 indicates the number of feature maps. A <strong class="source-inline">kernel_size</strong> value of <strong class="source-inline">(5,5)</strong> indicates the size of the filters that will be convolved over the input image to generate the feature maps. The <strong class="source-inline">strides</strong> value of <strong class="source-inline">(2,2)</strong> indicates that the filters will move two cells at a time, both horizontally and vertically, in the process of generating the feature maps. <strong class="source-inline">padding = 'same'</strong> indicates that we want the output of the convolutional operation to be of the same size as the input. </p>
			<p class="callout-heading">Note:</p>
			<p class="callout">The choice of architecture to use, such as the number of filters, size of kernels, stride, and more, is an art and can be mastered with lots of experimentation on the domain.</p>
			<p><strong class="bold">Activation Functions</strong></p>
			<p>In the previous section, we implemented some activation functions such as ReLU, ELU, SELU, and linear. In this section, we will be introduced to another activation function called LeakyReLU. LeakyReLU is another variation of ReLU. Unlike ReLU, which doesn't allow any negative values, LeakyReLU allows a small non-zero gradient that is controlled by a factor, <strong class="source-inline">α</strong>. This factor, <strong class="source-inline">α</strong>, controls the slope of the gradient for the negative values. </p>
			<p><strong class="bold">Upsampling Operation</strong></p>
			<p>In a CNN, an image gets down-sampled to lower dimensions by operations such as max pooling and convolutional operations. However, in a GAN, the dynamics of a generator network operate in a direction opposite to the convolutional operation; that is, from lower or coarser dimensions, we have to transform an image to a denser form (that is, with more dimensions). One way to do that is through an operation called <strong class="source-inline">UpSampling</strong>. In this operation, the input dimensions are doubled. Let's understand this operation in more detail using a small example.</p>
			<p>The following code can be used to import the required library files. The function that's specific for <strong class="source-inline">UpSampling</strong> is <strong class="source-inline">UpSampling2D</strong> from <strong class="source-inline">keras.layers</strong>:</p>
			<p class="source-code">from tensorflow.keras.models import Sequential</p>
			<p class="source-code">from tensorflow.keras.layers import UpSampling2D</p>
			<p>The following code creates a simple model that takes an array of shape <strong class="source-inline">(3,3,1)</strong> as input in the <strong class="source-inline">UpSampling</strong> layer:</p>
			<p class="source-code"># A model for UpSampling2d</p>
			<p class="source-code">model = Sequential()</p>
			<p class="source-code">model.add(UpSampling2D(input_shape=(3,3,1)))</p>
			<p class="source-code">model.summary()</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer231" class="IMG---Figure">
					<img src="image/B15385_07_20.jpg" alt="Figure 7.20: Model summary for UpSampling2D&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.20: Model summary for UpSampling2D</p>
			<p>From the summary, we can see that the output has been doubled to <strong class="source-inline">(None, 6,6,1)</strong>, wherein the middle two dimensions have been doubled. To understand what change this makes to an array of shape <strong class="source-inline">(3,3,1)</strong>, we will need to define an array of size <strong class="source-inline">(3,3)</strong>, as follows:</p>
			<p class="source-code"># Defining an array of shape (3,3)</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">X = np.array([[1,2,3],[4,5,6],[7,8,9]])</p>
			<p class="source-code">X.shape</p>
			<p>The output will be as follows:</p>
			<p class="source-code">(3, 3)</p>
			<p>The array we've defined has only two dimensions. However, the input to the model we defined needs four dimensions, where the dimensions are in the order (<strong class="source-inline">examples, width, height, channels</strong>). We can create the additional dimensions using the <strong class="source-inline">reshape()</strong> function, as follows:</p>
			<p class="source-code"># Reshaping the array</p>
			<p class="source-code">X = X.reshape((1,3,3,1))</p>
			<p class="source-code">X.shape</p>
			<p>The output will be as follows:</p>
			<p class="source-code">(1, 3, 3, 1)</p>
			<p>We can use the following code to make some predictions with the <strong class="source-inline">UpSampling</strong> model we created and observe the dimensions of the resultant array:</p>
			<p class="source-code"># Predicting with the model</p>
			<p class="source-code">y = model.predict(X)</p>
			<p class="source-code"># Printing the output shape</p>
			<p class="source-code">y[0,:,:,0]</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer232" class="IMG---Figure">
					<img src="image/B15385_07_21.jpg" alt="Figure 7.21: Output shape of the unsampled model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.21: Output shape of the unsampled model</p>
			<p>From the preceding output, we can see how the resultant array has been transformed. As we can see, each of the inputs has been doubled to get the resultant array. We will be using the <strong class="source-inline">UpSampling</strong> method in <em class="italic">Exercise 7.05</em>, <em class="italic">Implementing the DCGAN</em>.</p>
			<p><strong class="bold">Transpose Convolution</strong></p>
			<p>Transpose convolution is different from the <strong class="source-inline">UpSampling</strong> method we just saw. <strong class="source-inline">UpSampling</strong> was more or less a naïve doubling of the input values. However, transpose convolutions have weights that are learned during the training phase. Transpose convolutions work similarly to convolutional operations but in reverse. Instead of reducing the dimensions, transpose convolutions expand the dimensions of the input through a combination of the kernel size and its strides. As learned in <em class="italic">Chapter 3</em>, <em class="italic">Image Processing with Convolutional Neural Networks</em>, strides are the step sizes where we convolve or move the filters over the image to get an output. We also control the output of transpose convolutions with the <strong class="source-inline">padding = 'same'</strong> parameter, just like we do in convolutional operations.</p>
			<p>Let's take a look at a code example of how transpose convolutions work.</p>
			<p>First, we will need to import the necessary library files. The function that's specific to transpose convolution operations is <strong class="source-inline">Conv2DTranspose</strong> from <strong class="source-inline">keras.layers</strong>:</p>
			<p class="source-code">from tensorflow.keras.models import Sequential</p>
			<p class="source-code">from tensorflow.keras.layers import Conv2DTranspose</p>
			<p>Now, we can create a simple model that takes an image of shape <strong class="source-inline">(3,3,1)</strong> in the transpose convolution layer:</p>
			<p class="source-code"># A model for transpose convolution</p>
			<p class="source-code">model = Sequential()</p>
			<p class="source-code">model.add(Conv2DTranspose(1,(4,4),(2,2),\</p>
			<p class="source-code">          input_shape=(3,3,1),padding='same'))</p>
			<p class="source-code">model.summary()</p>
			<p>In the transpose convolution layer, the first parameter <strong class="source-inline">(1)</strong> is the number of filters. The second one <strong class="source-inline">(4,4)</strong> is the size of kernel and the last one <strong class="source-inline">(2,2)</strong> is the strides. With <strong class="source-inline">padding = 'same'</strong>, the output will not be dependent on the size of the kernel but will be multiples of the stride and the input dimension. The summary that will be generated by the preceding code will be as follows:</p>
			<div>
				<div id="_idContainer233" class="IMG---Figure">
					<img src="image/B15385_07_22.jpg" alt="Figure 7.22: Summary of the model &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.22: Summary of the model </p>
			<p>From the summary, we can see that the output has been doubled to <strong class="source-inline">(None, 6,6,1)</strong>, which would work like the multiplying the strides by the input dimensions (None, 2 × 3, 2 × 3, 1).</p>
			<p>Now, let's see what changes occur to a real array of shape <strong class="source-inline">(1,3,3,1)</strong>. Remember that we also created this array earlier:</p>
			<p class="source-code"># Defining an array of shape (3,3)</p>
			<p class="source-code">X = np.array([[1,2,3],[4,5,6],[7,8,9]])</p>
			<p class="source-code">X = X.reshape((1,3,3,1))</p>
			<p class="source-code">X.shape</p>
			<p>The output is as follows:</p>
			<p class="source-code">(1, 3, 3, 1)</p>
			<p>To generate the transposed array, we need to make some predictions using the transpose convolution model we created. By printing the shape, we can also observe the dimensions of the resultant array:</p>
			<p class="source-code"> # Predicting with the model</p>
			<p class="source-code">y = model.predict(X)</p>
			<p class="source-code"># Printing the shape</p>
			<p class="source-code">print(y.shape)</p>
			<p class="source-code"># Printing the output shape</p>
			<p class="source-code">y[0,:,:,0]</p>
			<p>The output will be as follows:</p>
			<div>
				<div id="_idContainer234" class="IMG---Figure">
					<img src="image/B15385_07_23.jpg" alt="Figure 7.23: Transformed array&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.23: Transformed array</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The output you get may vary from the one we have shown above. </p>
			<p>From the preceding output, we can see how the resultant array has been transformed. The values in the generated array are the end result of the dynamics between the weights of the kernel on the input image.</p>
			<p>Now that we have seen some of the basic building blocks of a DCGAN, we'll go ahead and build it in the next exercise.</p>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor251"/>Generating Handwritten Images Using DCGANs</h2>
			<p>Now, we will try to generate a data distribution similar to the data pertaining to handwritten digits using a DCGAN. We will be using the MNIST handwritten digits dataset as the real dataset. This dataset has a training set of 60,000 examples, all of which are handwritten images of digits from 0 to 9. The implementation process for this GAN will be similar to <em class="italic">Exercise 7.04</em>, <em class="italic">Implementing the GAN</em>, where we implemented the GAN for the known function. Let's look at the steps we will follow for this problem statement.</p>
			<p>First, we'll need to define the function that will be used to generate a real data distribution:</p>
			<p class="source-code"># Get the MNIST data </p>
			<p class="source-code">    (X_train, _), (_, _) = mnist.load_data()</p>
			<p>The preceding function will generate the real data distribution from the MNIST dataset. The train and test sets can be generated using the <strong class="source-inline">mnist.load_data()</strong> function. Using this function, we get all the related datasets in the form <strong class="source-inline">(X_train,y_train)</strong>,<strong class="source-inline">(X_test,y_test)</strong>. Since we only require the <strong class="source-inline">X_train</strong> data, we do not store the other datasets in variables. </p>
			<p>The MNIST data is two-dimensional; that is, (width, height). Since we require three-dimensional data (width, height, channel) for convolutional operations, we need to create the third dimension as 1 using the <strong class="source-inline">np.newaxis</strong> function. Please note that the first dimensions will be the number of examples:</p>
			<p class="source-code"># Reshaping the input data to include channel</p>
			<p class="source-code">    X = X_train[:,:,:,np.newaxis]</p>
			<p class="source-code"># Generating a batch of data</p>
			<p class="source-code">    imageBatch = X[np.random.randint(0, X.shape[0], size=batch)]</p>
			<p>The other process is to generate batches of the training data. To generate batches of data, we sample some integers between 0 and the number of examples in the training set. The sample's size will be equal to the batch size we want. This is implemented as follows:</p>
			<p class="source-code"># Generating a batch of data</p>
			<p class="source-code">    imageBatch = X[np.random.randint(0, X.shape[0], size=batch)]</p>
			<p>We will only be returning the <strong class="source-inline">X</strong> variable. The labels that are batches of 1s will be separately generated during the training process.</p>
			<p>Then, we need to define the three functions that will be used for generating fake samples. These are a function for generating fake inputs, a function for the generator network, and a function for generating fake samples and labels. Most of these functions are the same as what we developed in <em class="italic">Exercise 7.04</em>, <em class="italic">Implementing the GAN</em>. The generator model will be constructed as a convolutional model with intermittent use of <strong class="bold">Up-Sampling/Converse2Dtranspose</strong> operations.</p>
			<p>Next, we need to create a new function for the discriminator network. This discriminator model will, again, be a convolutional model with the final layer as a sigmoid layer where we output a probability, that is, the probability of an image being real or fake. The input dimensions to the discriminator model will be the dimensions of the images generated from MNIST and the fake images, which will be (batch size, 28,28,1).</p>
			<p>The GAN model will be the same as the one we created in <em class="italic">Exercise 7.04</em>, <em class="italic">Implementing the GAN.</em> This function will have the generator model and the discriminator model as its inputs.</p>
			<h3 id="_idParaDest-226"><a id="_idTextAnchor252"/>The Training Process</h3>
			<p>The training process will be similar to the process we implemented in <em class="italic">Exercise 7.04,</em> <em class="italic">Implementing the GAN</em>. The steps for the training process are as follows:</p>
			<ol>
				<li value="1">Generate a batch of MNIST data using the function to generate a real dataset.</li>
				<li>Generate a batch of fake samples using <em class="italic">function 3</em> described in the functions for generating fake samples. </li>
				<li>Concatenate the real samples and fake samples into one DataFrame. This will be the input variable for the discriminator model.</li>
				<li>The labels will be a series of 1s and 0s corresponding to the real data and fake data that was concatenated earlier. </li>
				<li>Train the discriminator model using the <strong class="source-inline">train_on_batch()</strong> function using the <strong class="source-inline">X</strong> variable and the labels.</li>
				<li>Generate another batch of fake inputs for training the GAN model. These fake samples are generated using <em class="italic">function 1</em> in the fake sample generation process.</li>
				<li>Generate the labels for the fake samples that are intended to fool the discriminator. These labels will be 1s instead of 0s.</li>
				<li>Train the GAN model using the <strong class="source-inline">train_on_batch()</strong> function using the fake samples and its labels, as described in <em class="italic">Steps 6</em> and <em class="italic">7</em>.</li>
				<li><em class="italic">Steps 1</em> to <em class="italic">8</em> are repeated for the number of epochs we want the training to run for. This is done through a <strong class="source-inline">for</strong> loop over the number of epochs.</li>
				<li>At every intermediate step, we calculate the accuracy of the discriminator model. </li>
				<li>We also generate output plots at certain epochs. </li>
			</ol>
			<p>Now that we have seen the complete process behind training a DCGAN, let's dive into the next exercise, which implements this process.</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor253"/>Exercise 7.05: Implementing the DCGAN</h2>
			<p>In this exercise, we will build and train the DCGAN on the MNIST dataset. We will use the MNIST dataset as the real data distribution. We will then generate fake data from a random distribution. After that, we will train the GAN to generate data that is similar to the MNIST dataset's. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and name it <strong class="source-inline">Exercise 7.05</strong>. Import the following library packages and the MNIST dataset:<p class="source-code"># Import the required library functions</p><p class="source-code">import numpy as np</p><p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">from matplotlib import pyplot</p><p class="source-code">import tensorflow as tf</p><p class="source-code">from tensorflow.keras.layers import Input</p><p class="source-code">from tensorflow.keras.initializers import RandomNormal</p><p class="source-code">from tensorflow.keras.models import Model, Sequential</p><p class="source-code">from tensorflow.keras.layers \</p><p class="source-code">import Reshape, Dense, Dropout, Flatten,Activation</p><p class="source-code">from tensorflow.keras.layers import LeakyReLU,BatchNormalization</p><p class="source-code">from tensorflow.keras.layers \</p><p class="source-code">import Conv2D, UpSampling2D,Conv2DTranspose</p><p class="source-code">from tensorflow.keras.datasets import mnist</p><p class="source-code">from tensorflow.keras.optimizers import Adam </p></li>
				<li>Define the function that will be used to generate real datasets. The real dataset is generated from the MNIST data:<p class="callout-heading">Note:</p><p class="callout">Alternatively, you can download the MNIST dataset from <a href="https://packt.live/2X4xeCL">https://packt.live/2X4xeCL</a></p><p class="source-code"># Function to generate real data samples</p><p class="source-code">def realData(batch):</p><p class="source-code">    # Get the MNIST data </p><p class="source-code">    (X_train, _), (_, _) = mnist.load_data()</p><p class="source-code">    # Reshaping the input data to include channel</p><p class="source-code">    X = X_train[:,:,:,np.newaxis]</p><p class="source-code">    # normalising the data</p><p class="source-code">    X = (X.astype('float32') - 127.5)/127.5</p><p class="source-code">    # Generating a batch of data</p><p class="source-code">    imageBatch = X[np.random.randint(0, X.shape[0], size=batch)]</p><p class="source-code">    return imageBatch</p><p>The return value from this function is the batch of MNIST data. Note that we normalize the input data by subtracting <strong class="source-inline">127.5</strong>, which is half the maximum pixel values (255), and divide by the same amount. This will help with converging the solution faster.</p></li>
				<li>Now, let's generate a set of images from the MNIST dataset:<p class="source-code"># # Generating a batch of images</p><p class="source-code">mnistData = realData(25) </p></li>
				<li>Next, let's visualize the plots using <strong class="source-inline">matplotlib</strong>:<p class="source-code"># Plotting the image</p><p class="source-code">for j in range(5*5):</p><p class="source-code">    pyplot.subplot(5,5,j+1)</p><p class="source-code">    # turn off axis </p><p class="source-code">    pyplot.axis('off') </p><p class="source-code">    pyplot.imshow(mnistData[j,:,:,0],cmap='gray_r')</p><p>You should get an output similar to the following:</p><div id="_idContainer235" class="IMG---Figure"><img src="image/B15385_07_24.jpg" alt="Figure 7.24: Visualized data – digits from the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 7.24: Visualized data – digits from the dataset</p><p>From the output, we can see the visualization of some of the digits. We can see that the image is centrally positioned within a white background.</p><p class="callout-heading">Note</p><p class="callout">The digits that are visualized when you run the code will differ from the ones we've shown here. </p></li>
				<li>Define the function to generate inputs for the generator network. The fake data will be random data points generated from a uniform distribution:<p class="source-code"># Function to generate inputs for generator function</p><p class="source-code">def fakeInputs(batch,infeats):</p><p class="source-code">    #Generate random noise data with shape (batch,input features)</p><p class="source-code">    x_fake = np.random.uniform(-1,1,size=[batch,infeats])</p><p class="source-code">    return x_fake</p></li>
				<li>Let's define the function for building the generator network. Building the generator network is similar to building any CNN network. In this generator network, we will use the <strong class="source-inline">UpSampling</strong> method:<p class="source-code-heading">Exercise7.05.ipynb</p><p class="source-code"># Function for the generator model</p><p class="source-code">def genModel(infeats):</p><p class="source-code">    # Defining the Generator model</p><p class="source-code">    Genmodel = Sequential()</p><p class="source-code">    Genmodel.add(Dense(512,input_dim=infeats))</p><p class="source-code">    Genmodel.add(Activation('relu'))</p><p class="source-code">    Genmodel.add(BatchNormalization())</p><p class="source-code">    # second layer of FC =&gt; RElu =&gt; BN layers</p><p class="source-code">    Genmodel.add(Dense(7*7*64))</p><p class="source-code">    Genmodel.add(Activation('relu'))</p><p class="source-code-link">The complete code for this step can be found on <a href="https://packt.live/2ZPg8cJ">https://packt.live/2ZPg8cJ</a>.</p><p>In the model, we can see the progressive use of the transpose convolution operation. The initial input has the dimensions of 100. This is progressively increased to the desired image size of batch size x 28 x 28 through a series of transpose convolution operations.</p></li>
				<li>Next, we define the function to create fake samples. In this function, we only return the <strong class="source-inline">X</strong> variable: <p class="source-code"># Function to create fake samples using the generator model</p><p class="source-code">def fakedataGenerator(Genmodel,batch,infeats):</p><p class="source-code">    # first generate the inputs to the model</p><p class="source-code">    genInputs = fakeInputs(batch,infeats)</p><p class="source-code">    """</p><p class="source-code">    use these inputs inside the generator model </p><p class="source-code">    to generate fake distribution</p><p class="source-code">    """</p><p class="source-code">    X_fake = Genmodel.predict(genInputs)   </p><p class="source-code">    </p><p class="source-code">    return X_fake</p><p>The return value from this function is the fake dataset.</p></li>
				<li>Define the parameters that we will use, along with the summary of the generator network:<p class="source-code"># Define the arguments like batch size and input feature</p><p class="source-code">batch = 128</p><p class="source-code">infeats = 100</p><p class="source-code">Genmodel = genModel(infeats)</p><p class="source-code">Genmodel.summary()</p><p>You should get the following output:</p><div id="_idContainer236" class="IMG---Figure"><img src="image/B15385_07_25.jpg" alt="Figure 7.25 Summary of the model&#13;&#10;"/></div><p class="figure-caption">Figure 7.25 Summary of the model</p><p>From the summary, please note how the dimension of the input changes with each transpose convolution operation. Finally, we get an output that is equal in dimension to the real data set: <strong class="source-inline">(None,28 ,28,1)</strong>.</p></li>
				<li>Let's use the generator function to generate a fake sample before training:<p class="source-code"># Generating a fake sample and printing the shape</p><p class="source-code">fake = fakedataGenerator(Genmodel,batch,infeats)</p><p class="source-code">fake.shape</p><p>You should get the following output:</p><p class="source-code">(128, 28, 28, 1)</p></li>
				<li>Now, let's plot the generated fake sample:<p class="source-code"># Plotting the fake sample</p><p class="source-code">plt.imshow(fake[1, :, :, 0], cmap='gray_r')</p><p class="source-code">plt.xlabel('Fake Sample Image')</p><p>You should get an output similar to the one shown here:</p><div id="_idContainer237" class="IMG---Figure"><img src="image/B15385_07_26.jpg" alt="Figure 7.26: Plot of the fake sample image&#13;&#10;"/></div><p class="figure-caption">Figure 7.26: Plot of the fake sample image</p><p>This is the plot of the fake sample before training. After training, we want samples like these to look like the MNIST samples we visualized earlier in this exercise.</p></li>
				<li>Now, let's build the discriminator model as a function. The network will be a CNN network like the one you learned about in <em class="italic">Chapter 3</em>, <em class="italic">Image Classification with Convolutional Neural Networks</em>:<p class="source-code-heading">Exercise7.05.ipynb</p><p class="source-code"># Descriminator model as a function</p><p class="source-code">def discModel():</p><p class="source-code">    Discmodel = Sequential()</p><p class="source-code">    Discmodel.add(Conv2D(32,kernel_size=(5,5),strides=(2,2), \</p><p class="source-code">                         padding='same',input_shape=(28,28,1)))</p><p class="source-code">    Discmodel.add(LeakyReLU(0.2))</p><p class="source-code">    # second layer of convolutions</p><p class="source-code">    Discmodel.add(Conv2D(64, kernel_size=(5,5), \</p><p class="source-code">                         strides=(2, 2), padding='same'))</p><p class="source-code-link">The complete code for this step can be found on <a href="https://packt.live/2ZPg8cJ">https://packt.live/2ZPg8cJ</a>.</p><p>In the discriminator network, we have included all the necessary layers, such as the convolutional operations and LeakyReLU activations. Please note that the last layer is a sigmoid layer as we want the output as a probability of the sample to be real (1) or fake (0).</p></li>
				<li>Print the summary of the discriminator network:<p class="source-code"># Print the summary of the discriminator model</p><p class="source-code">Discmodel = discModel()</p><p class="source-code">Discmodel.summary()</p><p>You should get the following output:</p><div id="_idContainer238" class="IMG---Figure"><img src="image/B15385_07_27.jpg" alt="Figure 7.27: Summary of the model architecture &#13;&#10;"/></div><p class="figure-caption">Figure 7.27: Summary of the model architecture </p><p>The preceding screenshot shows the summary of the model architecture. This is based on the different layers we implemented using the <strong class="source-inline">Sequential</strong> class. For example, we can see that the first layer has 32 filter maps, the second layer has 64 filter maps, and the last layer has one output that corresponds to the sigmoid activation.</p></li>
				<li>Next, define the GAN model as a function:<p class="source-code">"""</p><p class="source-code">Define the combined generator and discriminator model, </p><p class="source-code">for updating the generator</p><p class="source-code">"""</p><p class="source-code">def ganModel(Genmodel,Discmodel):</p><p class="source-code">    # First define that discriminator model cannot be trained</p><p class="source-code">    Discmodel.trainable = False</p><p class="source-code">    Ganmodel = Sequential()</p><p class="source-code">    # First adding the generator model</p><p class="source-code">    Ganmodel.add(Genmodel)</p><p class="source-code">    """</p><p class="source-code">    Next adding the discriminator model </p><p class="source-code">    without training the parameters</p><p class="source-code">    """</p><p class="source-code">    Ganmodel.add(Discmodel)</p><p class="source-code">    # Compile the model for loss to optimise the Generator model</p><p class="source-code">    Ganmodel.compile(loss='binary_crossentropy',\</p><p class="source-code">                     optimizer = 'adam')</p><p class="source-code">    return Ganmodel</p><p>The structure of the GAN model is similar to the one we developed in <em class="italic">Exercise 7.04</em>, <em class="italic">Implementing the GAN</em>.</p></li>
				<li>Now, it's time to invoke the GAN function. Please note that the inputs to the GAN model are the previously defined generator and discriminator models:<p class="source-code"># Initialise the gan model</p><p class="source-code"><a id="_idTextAnchor254"/>gan_model = ganModel(Genmodel,Discmodel)</p><p class="source-code"># Print summary of the GAN model</p><p class="source-code">gan_model.summary()</p><p>From the preceding code, we can see that the inputs to the GAN model are the previously defined generator and discriminator models. You should get the following output:</p><div id="_idContainer239" class="IMG---Figure"><img src="image/B15385_07_28.jpg" alt="Figure 7.28: Model summary&#13;&#10;"/></div><p class="figure-caption">Figure 7.28: Model summary</p><p>Please note that the parameters of each layer of the GAN model are equivalent to the parameters of the generator and discriminator models. The GAN model is just a wrapper around the models we defined earlier.</p></li>
				<li>Define the number of epochs to train the network:<p class="source-code"># Defining the number of epochs</p><p class="source-code">nEpochs = 5000</p></li>
				<li>Now, let's train the GAN:<p class="callout-heading">Note:</p><p class="callout">Before you run the code that follows, make sure you have a folder titled <strong class="source-inline">handwritten</strong> in the same path as your Jupyter Notebook.</p><p class="source-code-heading">Exercise7.05.ipynb</p><p class="source-code"># Train the GAN network</p><p class="source-code">for i in range(nEpochs):</p><p class="source-code">    """</p><p class="source-code">    Generate samples equal to the bath size </p><p class="source-code">    from the real distribution</p><p class="source-code">    """</p><p class="source-code">    x_real = realData(batch)</p><p class="source-code">    #Generate fake samples using the fake data generator function</p><p class="source-code">    x_fake = fakedataGenerator(Genmodel,batch,infeats)</p><p class="source-code">    # Concatenating the real and fake data </p><p class="source-code">    X = np.concatenate([x_real,x_fake])</p><p class="source-code">    #Creating the dependent variable and initializing them as '0'</p><p class="source-code">    Y = np.zeros(batch * 2)</p><p class="source-code-link">The full code for this step can be found at <a href="https://packt.live/2ZPg8cJ">https://packt.live/2ZPg8cJ</a>.</p><p>From the preceding code, we can see that the training of the discriminator model with the fake and real samples and the training of the GAN model happens concurrently. The only difference is the training of the GAN model proceeds without updating the parameters of the discriminator model. The other thing to note is that, inside the GAN, the labels for the fake samples would be 1 to generate large loss terms that will be backpropagated through the discriminator network to update the generator parameters. We also display the predicted probability of the GAN for every 10 epochs. When calculating the probability, we combine a sample of real data and fake data and then take the mean of the predicted probability. We also save a copy of the generated image. </p><p class="callout-heading">Note:</p><p class="callout">We'll analyze the plots that will be generated in the section that follows.</p><p>You should get an output similar to the following:</p><p class="source-code">Discriminator probability:0.6213402152061462</p><p class="source-code">Discriminator probability:0.7360671758651733</p><p class="source-code">Discriminator probability:0.6130768656730652</p><p class="source-code">Discriminator probability:0.5046337842941284</p><p class="source-code">Discriminator probability:0.5005484223365784</p><p class="source-code">Discriminator probability:0.50015789270401</p><p class="source-code">Discriminator probability:0.5000558495521545</p><p class="source-code">Discriminator probability:0.5000174641609192</p><p class="source-code">Discriminator probability:0.5000079274177551</p><p class="source-code">Discriminator probability:0.4999823570251465</p><p class="source-code">Discriminator probability:0.5000027418136597</p><p class="source-code">Discriminator probability:0.5000032186508179</p><p class="source-code">Discriminator probability:0.5000043511390686</p><p class="source-code">Discriminator probability:0.5000077486038208</p><p class="callout-heading">Note</p><p class="callout">The output for the preceding code may not be an exact match with what you get when you run the code.</p><p>From the predicted probability of the test data, we can see that the values are hovering around the <strong class="source-inline">.55</strong> mark. This is an indication that the discriminator is confused about whether the image is fake or real. If the discriminator were sure that an image was real, it would predict a probability close to 1, while it would predict a probability close to 0 if it were sure that the image was fake. In our case, we can see that the probability is around the .55 mark, which indicates that the generator is learning to generate images similar to the real images. This has confused the discriminator. <em class="italic">A value close to 50% accuracy for the discriminator is the desired value.</em></p></li>
				<li>Now, let's generate fake images after the training process and visualize them:<p class="source-code"># Images predicted after training</p><p class="source-code">x_fake = fakedataGenerator(Genmodel,25,infeats)</p><p class="source-code"># Visualizing the plots</p><p class="source-code">for j in range(5*5):</p><p class="source-code">    pyplot.subplot(5,5,j+1)</p><p class="source-code">    # turn off axis </p><p class="source-code">    pyplot.axis('off')</p><p class="source-code">    pyplot.imshow(x_fake[j,:,:,0],cmap='gray_r')</p><p>The output will be as follows:</p><div id="_idContainer240" class="IMG---Figure"><img src="image/B15385_07_29.jpg" alt="Figure 7.29: Predicted image post training&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 7.29: Predicted image post training</p>
			<p>We can see that the generated images from the trained generator model closely resonate with the real handwritten digits.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2ZPg8cJ">https://packt.live/2ZPg8cJ</a>.</p>
			<p class="callout">This section does not currently have an online interactive example, and will need to be run locally.</p>
			<p>In this exercise, we developed a GAN to generate distributions similar to MNIST handwritten digits. In the section that follows, we will analyze the images that were generated at each epoch during this exercise.</p>
			<h2 id="_idParaDest-228"><a id="_idTextAnchor255"/>Analysis of Sample Plots</h2>
			<p>Now, let's look at the output sample plots from the previous exercise to see what the generated images look like. By completing the previous exercise, these should have been saved in the same path where your Jupyter Notebook is located, under a subfolder called <strong class="source-inline">handwritten</strong>:</p>
			<div>
				<div id="_idContainer241" class="IMG---Figure">
					<img src="image/B15385_07_30.jpg" alt="Figure 7.30: Sample plot after 10 iterations&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.30: Sample plot after 10 iterations</p>
			<p>The preceding images are those that were generated after 10 iterations. We can see that these images look more like random noise. However, we can also see that there are traces of white patches forming within the image, which indicates the GAN is learning some of the features of the real image:</p>
			<div>
				<div id="_idContainer242" class="IMG---Figure">
					<img src="image/B15385_07_31.jpg" alt=" Figure 7.31: Sample plot after 500 iterations&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 7.31: Sample plot after 500 iterations</p>
			<p>The preceding images are the plots after 500 iterations. From these images, we can see some semblance of the real image. We can see that the white background of the real images is being formed. We can also see the distribution getting aggregated at the center of the image:</p>
			<div>
				<div id="_idContainer243" class="IMG---Figure">
					<img src="image/B15385_07_32.jpg" alt=" Figure 7.32: Sample plot after 2,000 iterations&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 7.32: Sample plot after 2,000 iterations</p>
			<p>The preceding image is after 2,000 iterations. We can see that many digits have started to form; for example, 8, 5 ,3 ,9 ,4, 7, 0, and so on. We can also see that the dark shades of the images have started to become more pronounced. Now, let's look at the images that were generated during the last iteration:</p>
			<p> </p>
			<div>
				<div id="_idContainer244" class="IMG---Figure">
					<img src="image/B15385_07_33.jpg" alt="Figure 7.33: Sample plot after 5,000 iterations&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.33: Sample plot after 5,000 iterations</p>
			<p>A question to ask at this stage is, are these images perfect? Absolutely not. Would running the training for more epochs improve the results further? Not necessarily. Getting those perfect images would entail hours of training and experimentation with different model architectures. You can take this as a challenge to improve the output through your choices of architecture and the parameters within the model.  </p>
			<p>GANs are a really active area of research and the possibilities they are opening up point to the direction of computers slowly becoming creative. However, there are some common problems when implementing GANs. Let's look at some of them.</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor256"/>Common Problems with GANs</h2>
			<p>GANs are difficult networks to train and stabilize. There are different failure modes for GANs. Let's get a perspective of some of the common failure modes.</p>
			<h3 id="_idParaDest-230"><a id="_idTextAnchor257"/>Mode Collapse</h3>
			<p>A very common failure mode of GANs, especially on multi-modal data, is a situation called <strong class="bold">mode collapse</strong>. This refers to a situation where the generator learns only some specific variety of the distribution within the data. For example, in an MNIST data distribution, if the GAN generates only one particular digit (say, 5) after training, then this is a case of mode collapse.</p>
			<p>One way to combat mode collapse is to group data according to the different classes and train the discriminator accordingly. This will give the discriminator the ability to identify different modes that are present in the data.</p>
			<h3 id="_idParaDest-231"><a id="_idTextAnchor258"/>Convergence Failure</h3>
			<p>Another prominent failure mode in GANs is convergence failure. In this failure mode, the network fails to converge with the loss as it never settles during the training phase. Some methods that researchers have used to get over this problem include adding noise to discriminatory networks and penalizing discriminator weights through regularization techniques.</p>
			<p>Notwithstanding the numerous challenges inherent in training and building GANs, it still remains one of the most active areas of research within the deep learning community. The promises and the applications that are made possible by GANs are what make this area one of the most sought-after domains in deep learning. Now that we have laid some of the foundations for GANs, let's use what we've learned to build a GAN for a different dataset. </p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor259"/>Activity 7.01: Implementing a DCGAN for the MNIST Fashion Dataset</h2>
			<p>In this activity, you will implement a DCGAN to generate images similar to the ones found in the MNIST fashion dataset. The MNIST fashion dataset is similar to the handwritten digital images dataset that you implemented in <em class="italic">Exercise 7.05</em>, <em class="italic">Implementing the DCGAN</em>. This dataset consists of grayscale images of 10 different fashion accessories and comprises 60,000 training samples. The following is a sample of the images included in this dataset:</p>
			<div>
				<div id="_idContainer245" class="IMG---Figure">
					<img src="image/B15385_07_34.jpg" alt="Figure 7.34: Sample of the MNIST fashion dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.34: Sample of the MNIST fashion dataset</p>
			<p>The objective of this activity is to build a GAN and generate images similar to the fashion dataset. The high-level steps for this activity will be similar to <em class="italic">Exercise 7.05</em>, <em class="italic">Implementing the DCGAN</em>, where you implemented a DCGAN for handwritten digits. You will be completing this activity in two parts, first by creating the relevant functions and then by training the model.</p>
			<p><strong class="bold">Generating Key Functions</strong>: Here, you will be creating the required functions, such as the generator function and the discriminator function:</p>
			<ol>
				<li value="1">Define the function that will generate a real data distribution. This function has to generate the real data distribution from the MNIST fashion dataset. The fashion dataset can be imported using the following code:<p class="source-code">from tensorflow.keras.datasets import fashion_mnist</p><p>The training set can be generated using the <strong class="source-inline">fashion_mnist.load_data()</strong> function.</p><p class="callout-heading">Note:</p><p class="callout">Alternatively, you can download the dataset from <a href="https://packt.live/2X4xeCL">https://packt.live/2X4xeCL</a>.</p></li>
				<li>Define the three functions that will be used to generate fake samples; that is, the function for generating fake inputs, the function for the generator network, and the function for generating fake samples and labels. Use <em class="italic">Converse2Dtranspose</em> operations within the generator function.</li>
				<li>Create a new function for the discriminator network.</li>
				<li>Create the GAN model. You can take cues from <em class="italic">Exercise 7.05</em>, <em class="italic">Implementing the DCGAN</em>, on how to do this.</li>
			</ol>
			<p><strong class="bold">The Training Process</strong>: You will follow a process similar to the one in <em class="italic">Exercise 7.05</em>, <em class="italic">Implementing the DCGAN</em>:</p>
			<ol>
				<li value="1">Generate a batch of MNIST data using the function for generating a real dataset.</li>
				<li>Generate a batch of fake samples using the third function described in the functions for generating fake samples. </li>
				<li>Concatenate the real samples and fake samples into one DataFrame and generate their labels.</li>
				<li>Train the discriminator model using the <strong class="source-inline">train_on_batch()</strong> function using the <strong class="source-inline">X</strong> variable and the labels.</li>
				<li>Generate another batch of fake inputs for training the GAN model, along with their labels.</li>
				<li>Train the GAN model using the <strong class="source-inline">train_on_batch()</strong> function using the fake samples and their labels. </li>
				<li>Repeat the training for around 5,000 epochs.</li>
				<li>At every intermediate step, calculate the accuracy of the discriminator model.</li>
			</ol>
			<p>The discriminator probabilities you'll get should be around <strong class="source-inline">0.5</strong>. The expected output will be a generated image that looks similar to the one shown here:</p>
			<div>
				<div id="_idContainer246" class="IMG---Figure">
					<img src="image/B15385_07_35.jpg" alt="Figure 7.35: Expected output for this activity&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.35: Expected output for this activity</p>
			<p class="callout-heading">Note:</p>
			<p class="callout">The detailed steps for this activity, along with the solutions and additional commentary, are presented on page 426.</p>
			<h1 id="_idParaDest-233"><a id="_idTextAnchor260"/>Summary</h1>
			<p>You have come a long way from being introduced to one of the most promising areas in deep learning. Let's revisit some of the concepts that we learned about in this chapter.</p>
			<p>We started this chapter by understanding what GANs are and their major applications. We then went on to understand the various building blocks of GANs, such as the real datasets, fake datasets, the discriminator operation, the generator operation, and the GAN operation.</p>
			<p>We executed a problem statement to progressively build a <strong class="bold">fully connected GAN</strong> (<strong class="bold">FCGAN</strong>) to solve a real function. In the process of building the GAN, we also implemented exercises for creating real datasets, creating fake datasets, creating a generator network, creating a discriminator network, and finally combining all these individual components to create the GAN. We visualized the different plots and understood how the generated data distribution mimicked the real data distribution.</p>
			<p>In the next section, we understood the concept of DCGANs. We also visited some of the unique concepts in DCGANs such as upsampling and transpose convolutions. We implemented a GAN for the MNIST digital handwritten images and visualized the fake images we generated using a DCGAN. Finally, we also implemented a DCGAN for the MNIST fashion dataset in an activity.</p>
			<p>Having laid the foundations, the next question is, where do we go from here? GANs are a large area by itself and there's quite a lot of buzz around it these days. To start with, it would be good to tweak the models you have already learned by tweaking the architecture and activation functions and trying out other parameters such as batch normalization. After playing around with different variations of the current models, it will be time to explore other networks such as the <strong class="bold">Least Squares GAN</strong> (<strong class="bold">LSGAN</strong>) and <strong class="bold">Wasserstein GAN</strong> (<strong class="bold">WGAN</strong>). Then, there is this large playing field of conditional GANs such as the <strong class="bold">Conditional GAN</strong> (<strong class="bold">cGan</strong>), InfoGAN, <strong class="bold">Auxiliary Classifier GAN</strong> (<strong class="bold">AC-GAN</strong>), and <strong class="bold">Semi-Supervised GAN</strong> (<strong class="bold">SGAN</strong>). Once you've done this, you'll have set the stage for advanced topics such as CycleGAN, BigGAN, and StyleGAN. </p>
			<p>This chapter also brings down the curtain on the amazing journey you've made throughout this book. First, you were introduced to what deep learning is and the different use cases that are possible with deep learning. Subsequently, you learned the basics of neural networks, which are the foundations of deep learning. From there, you went on to learn about advanced techniques such as CNNs, which are the workhorses for use cases such as image recognition. Along with that, you learned about recurrent neural networks, which can be used for sequence data. Finally, you were introduced to GANs, a class of networks that's making lots of waves within the domain. Having equipped yourself with this set of tools now is the time to apply your learning to your domain. The possibilities and opportunities are endless. All we need to do is consolidate our current learning and move ahead step by step. I wish you all the best on your journey in scaling new peaks in the deep learning domain.</p>
		</div>
		<div>
			<div id="_idContainer248" class="Content">
			</div>
		</div>
	</body></html>