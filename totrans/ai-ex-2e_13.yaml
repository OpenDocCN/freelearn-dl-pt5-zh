- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visualizing Networks with TensorFlow 2.x and TensorBoard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to take a peek inside a machine's "mind" while
    it's "thinking" through the layers of a deep learning neural network. The number
    of lines of code required to build a sequential classifier for a **convolutional
    neural network** (**CNN**) has been drastically reduced with TensorFlow 2\. Running
    the classifier only takes a click. However, to understand the program when something
    goes wrong is a more difficult task, and visualizing the outputs of the layers
    can be very productive.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the output of the layers of a CNN can provide an in-depth knowledge
    of each individual step comprising the whole process.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, as in several of the preceding chapters, we will define the
    layers of a CNN. This time, we will add more layers and extract the output of
    each layer to create output images. We will build this process from scratch in
    a bottom-to-top approach in TensorFlow 2 in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Once the outputs have been defined, we will display the output of the convolutional,
    pooling, dropout, flattening, and dense layers.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing the output of the layers provides an intuitive sense of what the layers
    are doing. Being able to visualize the global graph of the model makes the architecture
    of the CNN visible.
  prefs: []
  type: TYPE_NORMAL
- en: We will use TensorBoard to explore the conceptual model, the epochs versus the
    accuracy, and the detail of the operations of mathematical functions. These graphs
    and measurements will be built using a top-to-bottom approach using Google Colaboratory.
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory provides a free server with ready-to-use libraries and modules.
    We will use a Google Colaboratory notebook to explore TensorBoard functions. The
    chapter is divided into three main sections. The first two sections describe how
    to build a sequential classifier with TensorFlow 2.2 and display the outputs of
    the layers with TensorFlow 2.2\. The third section describes how to display the
    graph information and accuracy measurement with the TensorFlow 2 version of TensorBoard.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics covered in this chapter will provide visual insights into CNNs:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a CNN layer by layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying the output of the layers of the CNN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Google Colaboratory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing the architecture of a neural network with TensorBoard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing accuracy measurements with TensorBoard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start off this chapter by discussing how we can explore the output of
    the layers within a CNN.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the output of the layers of a CNN in two steps with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many corporate contracts in the field of business intelligence require an explanation
    process for any algorithm that makes automatic and critical decisions. It is often
    mandatory for the editor of algorithms, artificial intelligence or not, to provide
    an explanation. We need to be prepared for that.
  prefs: []
  type: TYPE_NORMAL
- en: Also, maintenance becomes critical once artificial intelligence runs in production.
    Developers often move from one department to another, from one company to another.
    The person that has to maintain the program needs to understand it in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring and visualizing a CNN is a good way to get our hands dirty, open the hood
    of our roadster and see how the engine works!
  prefs: []
  type: TYPE_NORMAL
- en: First, we will first build the CNN layer by layer. We will be building the sequential
    classifier with TensorFlow 2 from the bottom to the top.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will not be using a Keras model directly; we''ll use TensorFlow''s integrated
    Keras module, which brings the number of lines of header down to only two lines:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then we will explore the visual output of the layers to gain insights into the
    way it "thinks."
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, let's get on with building!
  prefs: []
  type: TYPE_NORMAL
- en: Building the layers of a CNN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A CNN was described in *Chapter 9*, *Abstract Image Classification with Convolutional
    Neural Networks (CNNs)*. In the example to follow, the CNN will contain more layers
    to visualize the way a neural network extracts features step by step.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using a dataset that uses a single image to explore the layers of
    a CNN. This image is repeated several times for the training dataset and the test
    dataset is enough to build and run the model to visualize the layers of the neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains an image of a flower repeated several times—an iris.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: The image of the image we are exploring in this chapter'
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is not to have many variations of the image, but to simply see how
    a CNN represents an iris layer by layer. The dataset contains a repeated image.
    However, you can change these images and use a dataset of your own then display
    the images as follows using the same code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be a figure with lines of images from the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.2: Displaying the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first import the neural network modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Building the CNN only takes a few lines. This makes it deceptively simple because
    it appears to be a black box. In our example, the structure described in *Chapter
    9*, *Abstract Image Classification with Convolutional Neural Networks (CNNs)*,
    in its enhanced version here, only requires a few minutes to create from lines
    30 to 68:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We will go back to these layers in the next section when we explore their output.
    The main point to focus on here remains the simplicity of the code. Building a
    CNN as a black box in a few minutes might work. However, understanding each layer
    when a problem comes up requires a deeper understanding of the representations
    of the layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before exploring those layers, the program prints the structure of the classifier
    (CNN):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The model contains a fair number of layers to explore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Keep an eye on this summary. It will prove useful when choosing the number of
    layers you wish to explore to visualize the outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model is then compiled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then training and test datasets are processed (rescaled) and defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If we stop here, the CNN will work. But will we have really understood the model?
    I don't think so. Of course, it only takes a simple click to get the CNN to run
    after installing a ready-to-use dataset. This black box approach can work, but
    exploring the visual output of a layer provides a better representation of the
    network. Let's take a look at that next.
  prefs: []
  type: TYPE_NORMAL
- en: Processing the visual output of the layers of a CNN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The idea is to focus on an image and actually *see* the "mental," visual, representation
    a CNN calculates, layer by layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To process the layers, the program first selects an image for the activation
    model to work on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the visualization process runs in a few steps, which will take us inside
    the CNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selecting the number of layers to visualize using the** `e` **variable**:
    Going back to the model summary displayed previously, you can choose the layer you
    want to stop at. In this example, we''re stopping at `e=12`. You can choose to
    start with `e=4` to visualize the first convolutional and pooling layers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If `e=3`, the program will stop at `max_pooling2d`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Selecting the top n layers that will be explored**: The program refers to
    `layer_outputs` to extract the information it needs to visualize the target layers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Applying the activation model to extract the requested layers**: Activating
    the model forces the classifier to get to work and run through the layers. That
    way, we can peek inside its "thought" process and see how it represents inputs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Retrieving the layer names to display, along with the visual representation
    of the layer**: Layer names help us understand what we are looking at. Use the
    model summary we printed earlier as a map to see where you are when the layer
    name is displayed, along with the representation of the output of that same layer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Processing layer outputs and organizing them into grids**: To avoid having
    to watch a sequential display of the variations of the representations in a given
    layer, we are going to organize them in one grid image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Displaying the processed layer outputs**: Now that the work is done, we just
    have to display the layer names along with the corresponding grids:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that the figures are saved by `plt.savefig` in an output directory for
    later use.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will obtain a list of figures with the name of the layer for the layers
    you chose to visualize. For example, you can view the images of the first seven
    layers. You can look at them in the following figures or by running the program.
    In any case, the best way to analyze the layers is to look closely at the first
    layer and then at the last layer. You will see that the CNN is carefully extracting
    an abstract representation of the image and displaying higher dimensions. The
    reason the differences between the layers are difficult to perceive with the human
    eye comes from two factors:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of elements to analyze is extremely difficult for us to observe.
    Usually our brain does this without us having to think about it!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several convolutional layers versus one layer that would rush through
    the process of obtaining an abstract representation of the image. It's going layer
    by layer, just like a human brain processes an image step-by-step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look at the following first layer then the last one, then go back and observe
    the differences between the layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant équipement électronique, capture d’écran  Description
    générée automatiquement](img/B15438_13_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.3: Convolutional layer'
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant équipement électronique, afficher  Description générée
    automatiquement](img/B15438_13_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.4: Convolutional layer'
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant équipement électronique, afficher  Description générée
    automatiquement](img/B15438_13_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.5: Pooling layer'
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant équipement électronique, afficher  Description générée
    automatiquement](img/B15438_13_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.6: Dropout layer'
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant tableau de points, afficher, équipement électronique  Description
    générée automatiquement](img/B15438_13_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.7: Convolutional layer'
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant tableau de points, texte  Description générée automatiquement](img/B15438_13_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.8: Convolutional layer'
  prefs: []
  type: TYPE_NORMAL
- en: '![Une image contenant tableau de points, texte  Description générée automatiquement](img/B15438_13_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.9: Pooling layer'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the output of the layers of a CNN provides a fantastic way to understand and
    analyze a neural network. Let's go a step further and analyze the layers.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the visual output of the layers of a CNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An input image is chaos until some form of intelligence makes sense of it. Any
    form of intelligence will detect patterns and structures. Machine intelligence
    works on the same grounds by increasing the level of abstraction through dimensionality
    reduction. The process of going from chaos to an organized representation is at
    the heart of the fantastic invention of present-day neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: When running `cnn_layers.py`, the layer outputs will be displayed. Let's explore
    some of the layers. You can explore some or all of them by simply changing the
    value of the `e = <number-of-layers>` variable on line 107.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional layer activation functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One of the key options of a convolutional layer is the activation function.
    `relu` is used in the following `cnn_layers.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: For more on ReLU, please go the explanation in *Chapter 9*, *Abstract Image
    Classification with Convolutional Neural Networks (CNNs)*.
  prefs: []
  type: TYPE_NORMAL
- en: '`relu` produces the following output for the `Conv2d` layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.10: conv2d output 1'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now go to line 33 and replace `relu` with `softmax` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is quite different, as we can see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.11: conv2d output 2'
  prefs: []
  type: TYPE_NORMAL
- en: It takes some time for the human eye to adjust to the change. Look at each version.
    Try to memorize it for a few seconds by closing your eyes and then looking at
    the other one. Our brain does this implicitly which is why it takes an effort
    to do this explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: Which one should you use? Welcome to deep learning! There is no certain answer
    to that question. It is a trial-and-error process. An activation function might
    fit one model and not another. Even if the accuracy of the network is acceptable
    during the training process, you might have to change the activation function
    over time when new data produces bad results.
  prefs: []
  type: TYPE_NORMAL
- en: For more on softmax, please go back to the explanation in *Chapter 2*, *Building
    a Reward Matrix – Designing Your Datasets*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try the logistic sigmoid activation function, `sigmoid`, also described
    in *Chapter 2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.12: conv2d output 3'
  prefs: []
  type: TYPE_NORMAL
- en: Notice the differences again. Observe the last image on row 1 for each activation
    function. The differences are fascinating because they provide a variety of possible
    representations.
  prefs: []
  type: TYPE_NORMAL
- en: Try other activation functions to get the feel of the way an artificial neural
    network transforms what it perceives into a higher level of abstraction through
    a reduction of the dimensions that it has to process.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional layers higher-level representations through the layers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Notice the incredible level of abstraction the sequential classifier reaches
    through the following outputs going from `conv2d` to `conv2d_5`, which is, in
    fact, the sixth (0 to 5) convolutional layer of `cnn_layers.py`.
  prefs: []
  type: TYPE_NORMAL
- en: The network starts at a relatively figurative representation to reach a highly
    abstract level at `conv2d_5`. We are literally inside the machine's "mind," watching
    it think and learn!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.13: Initial conv2d output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.14: conv2d_1 output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.15: conv2d_2 output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.16: conv2d_3 output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.17: conv2d_4 output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.18: conv2d_5 output'
  prefs: []
  type: TYPE_NORMAL
- en: This abstraction process owes a lot to the other layers, such as the pooling
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: Pooling layers to obtain higher-level representations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The pooling layer is going to reduce the number of dimensions of its input
    and choose the most representative features it finds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s explore the evolution of the first two pooling layers in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.19: max_pooling2d output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.20: max_pooling2d_1 output'
  prefs: []
  type: TYPE_NORMAL
- en: Once again, we can see the powerful level of abstraction a CNN can attain.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on the pooling layer, please read the explanations in *Chapter
    9*, *Abstract Image Classification with Convolutional Neural Networks (CNNs)*.
  prefs: []
  type: TYPE_NORMAL
- en: Dropout layer higher-level representations through the layers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The dropout layers provide a way to abandon many features in order to reach
    a simplified higher level of representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It is not always necessary to add a dropout layer because it depends on the
    productivity and architecture of the model you are exploring. For this example,
    the first two dropout layers are quite instructive. Dropouts are also a way to
    avoid overfitting. The model learns how to extract key features to obtain an abstract
    representation, not a literal one.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.21: dropout output'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.22: dropout_1 output'
  prefs: []
  type: TYPE_NORMAL
- en: Observe again how the dropout layers accelerate the abstraction process. We
    can see the CNN's "mind" working.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: I recommend you try different activation functions and various options for the layers of
    this example. Then run the program and get a feel of what is going inside a CNN's
    "machine thinking" process. Even if it is a purely mathematical architecture,
    it provides a good idea of how a CNN, while not human at all, has its own "machine
    thinking" approach.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have explored a CNN from bottom to top, let's see how to observe
    the accuracy of a CNN from top to bottom using TensorBoard.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the accuracy of a CNN using TensorBoard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will first get started with a free Google Colaboratory server
    and then explore some of the TensorBoard ANN measurement functions.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Google Colaboratory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can get access to your free instance of Google Colaboratory server in just
    a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have a Google account and log into it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the following link, which takes leads you to Google Colaboratory:
    [https://colab.research.google.com/notebooks/welcome.ipynb#recent=true](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will be taken to the following page:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B15438_13_23.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 13.23: Colaboratory initial landing page'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **UPLOAD** option in the top right:![](img/B15438_13_24.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 13.24: Upload option'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can choose or drag and drop a file, then upload it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Upload `TF_2_graphs.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can download the program from this link and then upload it: [https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/blob/master/CH13/TF_2_graphs.ipynb](https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/blob/master/CH1)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once the program is open, you will see the following page:![](img/B15438_13_25.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 13.25: A Colaboratory notebook'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Go to **File** in the menu and save the notebook to your Google Drive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B15438_13_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.26: The File menu'
  prefs: []
  type: TYPE_NORMAL
- en: Once the file is saved, you are ready to go!
  prefs: []
  type: TYPE_NORMAL
- en: You have many runtime options, such as making a choice between using a CPU or
    a GPU, display options (background, for example), and many more ways to use Google
    Colaboratory. I recommend reading the document to find the many options available.
  prefs: []
  type: TYPE_NORMAL
- en: You are on your free Colaboratory server, and you're ready to explore your notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Defining and training the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will run the notebook and then analyze the results. This should provide an
    introduction to both Google Colaboratory and some TensorBoard functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, run the program by clicking on the **Run all** option in the **Runtime**
    menu:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.27: Runtime options'
  prefs: []
  type: TYPE_NORMAL
- en: The program will then go through its cells and provide information on the training
    process. To obtain this information, we will explore some of TensorBoard's key
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: We will first install TensorFlow and then run TensorBoard.
  prefs: []
  type: TYPE_NORMAL
- en: '**Installing TensorFlow and getting TensorBoard running**: As you saw in the previous
    section, you do not need to run the program cell by cell unless a cell contains
    an error. In that case, click on the run button in the cell:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B15438_13_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.28: Running a cell'
  prefs: []
  type: TYPE_NORMAL
- en: 'The cell will execute the code. In this case, it will install TensorFlow 2.x:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Once the installation is finished and TensorBoard is loaded, the program runs
    through the headers to import the necessary modules.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful with TensorBoard versions! You might have a previous or different
    version installed that you are using for another project. Before running this
    program, check any application that is using TensorBoard in your environment.
    Check your configuration carefully before doing anything. If there is a risk,
    use another environment or just read the notebook without running it.
  prefs: []
  type: TYPE_NORMAL
- en: '**The program now defines a simplified model you are now familiar with**: The
    following model has been simplified. The goal here is to show how TensorBoard
    works. You can, of course, add more layers once you have explored the notebook:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**The model is then compiled with an optimizer and accuracy metrics**: The
    model now needs to be compiled and run to provide measurement output:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For more on the Adam optimizer and cross-entropy, see *Chapter 9*, *Abstract
    Image Classification with Convolutional Neural Networks (CNNs)*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The model is now trained and ready for metric callbacks for TensorBoard.
  prefs: []
  type: TYPE_NORMAL
- en: While the program was running the training, it was saving a log of the main
    functionalities to display. The graph of the model can be displayed in TensorBoard
    with one line along with many other functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph of the model contains many details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.29: TensorFlow graph'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to have a simplified view, a conceptual view of the model is also
    displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_13_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.30: A partial view of the TensorFlow graph'
  prefs: []
  type: TYPE_NORMAL
- en: We have explored the architecture of a neural network model using TensorBoard graphs.
    Let's see how to visualize the measurements of the training process of our model.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing some of the measurements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While training, the program saved key information in its log directory that
    can now be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: '**Epoch accuracy**: If the accuracy increases with the epochs, the classifier
    is progressing, and it is learning correctly. If it decreases, we are in trouble!
    We will have to go back and check the dataset, the activation functions, and how
    the layers were designed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B15438_13_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.31: Accuracy of the model'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic flow, including an activation function**: TensorBoard has drill-down
    functionality. You can drill down into the actual operations TensorFlow 2.x is calculating:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B15438_13_32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.32: The activation function'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploring the details of an activation function**: Once you have seen the
    flow of an operation, you can even peek inside it to see how it is built:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B15438_13_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.33: The activation function'
  prefs: []
  type: TYPE_NORMAL
- en: These TensorBoard graphs and measurements help you dig into the mechanics of
    your model. They provide insights that will add to the ones you acquired when
    exploring the outputs of layers in the first section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have explored the architecture functions of TensorBoard
    through the many graphs available as well as tools to measure the training performance
    of our model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored deep learning from the inside. We saw that building
    a CNN is now easy with TensorFlow 2.x, but peeking inside the way it "thinks"
    gives critical insight.
  prefs: []
  type: TYPE_NORMAL
- en: We first built a CNN with many layers. The level of abstraction of a CNN increases
    through each layer. Reducing the number of dimensions per layer makes patterns
    appear. A neural network can be described as a process that goes from chaos to
    meaning.
  prefs: []
  type: TYPE_NORMAL
- en: After building the CNN, we wrote a program that can read the "mental" images
    of the layers. The output of each layer shows how the network is creating patterns
    and structures. Since we humans often think using mental images, the output images of
    the CNN help us understand how a machine learns.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we used a Google Colaboratory server to visualize the measurements
    of the CNN's learning process with TensorBoard running on top of TensorFlow 2.x.
    Measuring the accuracy of the training process of a CNN is critical. Visualizing
    these measurements makes it easier to see what is going wrong. TensorBoard provides
    a graph of a model to help us go from source code to a mental representation of
    an ANN.
  prefs: []
  type: TYPE_NORMAL
- en: To sum this chapter up in a nutshell, we can say that artificial intelligence,
    through mathematics, transforms the chaos surrounding us into intelligible structures
    and patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we are going to go further and learn how to visualize
    another aspect of a neural network: weights. We are going to use the weights of
    a restricted Boltzmann machine (RBM) to create a visual representation in TensorBoard
    using principal component analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A CNN always has the same number of layers. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ReLU is the best activation function. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is not necessary to compile a sequential classifier. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of a layer is best viewed without running a prediction. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The names of the layers mean nothing when viewing their outputs. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: TensorFlow 2.x does not include Keras. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Google Colaboratory is just a repository, like GitHub. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Google Colaboratory cannot run notebooks. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is possible to run TensorBoard in Google Colaboratory notebooks. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accuracy is displayed in TensorBoard. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For more information on activation functions, visit [https://keras.io/activations/](https://keras.io/activations/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Click on this link for more information on Google Colaboratory: [https://colab.research.google.com/notebooks/welcome.ipynb#recent=true](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
