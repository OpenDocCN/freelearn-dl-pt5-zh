["```py\n>>> x = np.random.rand(10, 1, 28, 28) # Generate data randomly\n>>> x.shape\n(10, 1, 28, 28)\n```", "```py\n>>> x[0].shape # (1, 28, 28)\n>>> x[1].shape # (1, 28, 28)\n```", "```py\n>>> x[0, 0] # or x[0][0]\n```", "```py\nim2col (input_data, filter_h, filter_w, stride=1, pad=0)\n```", "```py\nimport sys, os\nsys.path.append(os.pardir)\nfrom common.util import im2col\nx1 = np.random.rand(1, 3, 7, 7)\ncol1 = im2col(x1, 5, 5, stride=1, pad=0)\nprint(col1.shape) # (9, 75)\nx2 = np.random.rand(10, 3, 7, 7)\ncol2 = im2col(x2, 5, 5, stride=1, pad=0)\nprint(col2.shape) # (90, 75)\n```", "```py\nclass Convolution:\n    def __init__(self, W, b, stride=1, pad=0):\n        self.W = W\n        self.b = b\n        self.stride = stride\n        self.pad = pad\n    def forward(self, x):\n        FN, C, FH, FW = self.W.shape\n        N, C, H, W = x.shape\n        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n        col = im2col(x, FH, FW, self.stride, self.pad)\n        col_W = self.W.reshape(FN, -1).T # Expand the filter\n        out = np.dot(col, col_W) + self.b\n        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n        return out\n```", "```py\nclass Pooling:\n    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n        self.pool_h = pool_h\n        self.pool_w = pool_w\n        self.stride = stride\n        self.pad = pad\n    def forward(self, x):\n        N, C, H, W = x.shape\n        out_h = int(1 + (H - self.pool_h) / self.stride)\n        out_w = int(1 + (W - self.pool_w) / self.stride)\n        # Expansion (1)\n        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n        col = col.reshape(-1, self.pool_h*self.pool_w)\n        # Maximum value (2)\n        out = np.max(col, axis=1)\n        # Reshape (3)\n        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n            return out\n```", "```py\nclass SimpleConvNet:\n    def __init__(self, input_dim=(1, 28, 28),\n                conv_param={'filter_num':30, 'filter_size':5,\n                    'pad':0, 'stride':1},\n                hidden_size=100, output_size=10, weight_init_std=0.01):\n        filter_num = conv_param['filter_num']\n        filter_size = conv_param['filter_size']\n        filter_pad = conv_param['pad']\n        filter_stride = conv_param['stride']\n        input_size = input_dim[1]\n        conv_output_size = (input_size - filter_size + 2*filter_pad) / \\\n                        filter_stride + 1\n        pool_output_size = int(filter_num * (conv_output_size/2) *(conv_output_size/2))\n```", "```py\n    self.params = {}\n    self.params['W1'] = weight_init_std * \\\n    np.random.randn(filter_num, input_dim[0],\n    filter_size, filter_size)\n    self.params['b1'] = np.zeros(filter_num)\n    self.params['W2'] = weight_init_std * \\\n    np.random.randn(pool_output_size,hidden_size)\n    self.params['b2'] = np.zeros(hidden_size)\n    self.params['W3'] = weight_init_std * \\\n    np.random.randn(hidden_size, output_size)\n    self.params['b3'] = np.zeros(output_size)\n```", "```py\n    self.layers = OrderedDict( )\n    self.layers['Conv1'] = Convolution(self.params['W1'],\n                                self.params['b1'],\n                                conv_param['stride'],\n                                conv_param['pad'])\n    self.layers['Relu1'] = Relu( )\n    self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n    self.layers['Affine1'] = Affine(self.params['W2'],\n                                self.params['b2'])\n    self.layers['Relu2'] = Relu( )\n    self.layers['Affine2'] = Affine(self.params['W3'],\n                                self.params['b3'])\n    self.last_layer = SoftmaxWithLoss( )\n```", "```py\ndef predict(self, x):\n    for layer in self.layers.values( ):\n        x = layer.forward(x)\n    return x\ndef loss(self, x, t):\n    y = self.predict(x)\nreturn self.lastLayer.forward(y, t)\n```", "```py\ndef gradient(self, x, t):\n    # forward\n    self.loss(x, t)\n    # backward\n    dout = 1\n    dout = self.lastLayer.backward(dout)\n    layers = list(self.layers.values( ))\n    layers.reverse( )\n    for layer in layers:\n        dout = layer.backward(dout)\n    # Settings\n    grads = {}\n    grads['W1'] = self.layers['Conv1'].dW\n    grads['b1'] = self.layers['Conv1'].db\n    grads['W2'] = self.layers['Affine1'].dW\n    grads['b2'] = self.layers['Affine1'].db\n    grads['W3'] = self.layers['Affine2'].dW\n    grads['b3'] = self.layers['Affine2'].db\n    return grads\n```"]