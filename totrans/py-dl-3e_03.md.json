["```py\nimport tensorflow.keras\n```", "```py\nimport keras\n```", "```py\n    import tensorflow as tf\n    (X_train, Y_train), (X_validation, Y_validation) = \\\n                 tf.keras.datasets.mnist.load_data()\n    ```", "```py\n    X_train = X_train.reshape(60000, 784) / 255\n    X_validation = X_validation.reshape(10000, 784) / 255\n    ```", "```py\n    classes = 10\n    Y_train = tf.keras.utils.to_categorical(Y_train,\n                classes)\n    Y_validation = tf.keras.utils.to_categorical(\n                Y_validation, classes)\n    ```", "```py\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, BatchNormalization, Activation\n    input_size = 784\n    hidden_units = 100\n    model = Sequential([\n        Dense(\n            hidden_units, input_dim=input_size),\n        BatchNormalization(),\n        Activation('relu'),\n        Dense(classes),\n        Activation('softmax')\n    ])\n    ```", "```py\n    model.compile(\n        loss='categorical_crossentropy',\n        metrics=['accuracy'],\n        optimizer='adam')\n    ```", "```py\n    model.fit(X_train, Y_train, batch_size=100, epochs=20,\n              verbose=1)\n    ```", "```py\n    score = model.evaluate(X_validation, Y_validation,\n              verbose=1)\n    print('Validation accuracy:', score[1])\n    ```", "```py\n    weights = model.layers[0].get_weights()\n    ```", "```py\n    import matplotlib.pyplot as plt\n    import matplotlib.cm as cm\n    import numpy\n    fig = plt.figure()\n    w = weights[0].T\n    for unit in range(hidden_units):\n        ax = fig.add_subplot(10, 10, unit + 1)\n        ax.axis(\"off\")\n        ax.imshow(numpy.reshape(w[unit], (28, 28)),\n        cmap=cm.Greys_r)\n    plt.show()\n    ```", "```py\n    import torch\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    ```", "```py\n    from torchvision import datasets\n    from torchvision.transforms import ToTensor, Lambda, Compose\n    train_data = datasets.MNIST(\n        root='data',\n        train=True,\n        transform=Compose(\n            [ToTensor(),\n            Lambda(lambda x: torch.flatten(x))]),\n            download=True,\n        )\n    validation_data = datasets.MNIST(\n        root='data',\n        train=False,\n        transform=Compose(\n            [ToTensor(),\n            Lambda(lambda x: torch.flatten(x))]),\n        )\n    ```", "```py\n    from torch.utils.data import DataLoader\n    train_loader = DataLoader(\n        dataset=train_data,\n        batch_size=100,\n        shuffle=True)\n    validation_loader = DataLoader(\n        dataset=validation_data,\n        batch_size=100,\n        shuffle=True)\n    ```", "```py\n    torch.manual_seed(1234)\n    hidden_units = 100\n    classes = 10\n    model = torch.nn.Sequential(\n        torch.nn.Linear(28 * 28, hidden_units),\n        torch.nn.BatchNorm1d(hidden_units),\n        torch.nn.ReLU(),\n        torch.nn.Linear(hidden_units, classes),\n    )\n    ```", "```py\n    cost_func = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters())\n    ```", "```py\n    def train_model(model, cost_function, optimizer, data_loader):\n        # send the model to the GPU\n        model.to(device)\n        # set model to training mode\n        model.train()\n        current_loss = 0.0\n        current_acc = 0\n        # iterate over the training data\n        for i, (inputs, labels) in enumerate(data_loader):\n            # send the input/labels to the GPU\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            with torch.set_grad_enabled(True):\n                # forward\n                outputs = model(inputs)\n                _, predictions = torch.max(outputs, 1)\n                loss = cost_function(outputs, labels)\n                # backward\n                loss.backward()\n                optimizer.step()\n            # statistics\n            current_loss += loss.item() * inputs.size(0)\n            current_acc += torch.sum(predictions == labels.data)\n        total_loss = current_loss / len(data_loader.dataset)\n        total_acc = current_acc.double() / len(data_loader.dataset)\n        print('Train Loss: {:.4f}; Accuracy: /\n            {:.4f}'.format(total_loss, total_acc))\n    ```", "```py\n    def test_model(model, cost_function, data_loader):\n        # send the model to the GPU\n        model.to(device)\n        # set model in evaluation mode\n        model.eval()\n        current_loss = 0.0\n        current_acc = 0\n        # iterate over    the validation data\n        for i, (inputs, labels) in enumerate(data_loader):\n            # send the input/labels to the GPU\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            # forward\n            with torch.set_grad_enabled(False):\n                outputs = model(inputs)\n                _, predictions = torch.max(outputs, 1)\n                loss = cost_function(outputs, labels)\n            # statistics\n            current_loss += loss.item() * inputs.size(0)\n            current_acc += torch.sum(predictions == labels.data)\n        total_loss = current_loss / len(data_loader.dataset)\n        total_acc = current_acc.double() / len(data_loader.dataset)\n        print('Test Loss: {:.4f}; Accuracy: /\n            {:.4f}'.format(total_loss, total_acc))\n        return total_loss, total_acc\n    ```", "```py\n    for epoch in range(20):\n        train_model(model, cost_func, optimizer,\n            train_loader)\n    test_model(model, cost_func, validation_loader)\n    ```"]