- en: '*Chapter 3*: Contextual Bandits'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A more advanced version of the multi-armed bandit is the **contextual bandit**
    (**CB**) problem, where decisions are tailored to the context they are made in.
    In the previous chapter, we identified the best-performing ad in an online advertising
    scenario. In doing so, we did not use any information about, for instance, the
    user persona, age, gender, location, or previous visits, which would have increased
    the likelihood of a click. CBs allow us to leverage this information, which means,
    they play a role in central role in commercial personalization and recommendation
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Context is similar to state in a multi-step **reinforcement** **learning** (**RL**)
    problem, with one key difference. In a multi-step RL problem, the action an agent
    takes, affects the states it is likely to visit in the subsequent steps. For example,
    when playing tic-tac-toe, an agent's action in the current state changes the board
    configuration (state) in a particular way, which then affects what actions the
    opponent can take, and so on. In CB problems, however, the agent simply observes
    the context, makes a decision, and observes the reward. The next context the agent
    will observe does not depend on the current context/action. This setup, although
    simpler than multi-step RL, occurs in a very broad set of applications. So, you
    will add a key tool to your arsenal with what we cover in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue to solve different versions of the online advertising problem,
    using more advanced tools, such as neural networks, together with CB models. Specifically,
    in this chapter, you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Why we need function approximations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using function approximations for context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using function approximations for actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other applications of multi-armed bandits and CBs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why we need function approximations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While solving (contextual) multi-armed bandit problems, our goal is to learn
    action values for each arm (action) from our observations, which we have denoted
    by ![](img/Formula_03_001.png). In the online advertising example, it represented
    our estimate for the probability of a user clicking the ad if we displayed ![](img/Formula_03_002.png).
    Now, assume that we have two pieces of information about the user seeing the ad,
    namely the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Device type (mobile or desktop)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Location (domestic/US or international/non-US)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is quite likely that ad performances will differ by device type and location,
    which make up the context in this example. A CB model will therefore leverage
    this information, estimate the action values for each context, and choose the
    actions accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'This would look like filling in a table for each ad similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 3.1 – Sample action values for ad D'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Table_3.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.1 – Sample action values for ad D
  prefs: []
  type: TYPE_NORMAL
- en: 'This means solving four MAB problems, one for each context:'
  prefs: []
  type: TYPE_NORMAL
- en: Mobile – Domestic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mobile – International
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Desktop – Domestic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Desktop – International
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While this could work fine in this simple example, think about what happens
    when you add additional information to the context, for example, age. This introduces
    a number of challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we may not have enough observations to (accurately) learn action values
    for each context (Mobile, International, 57). However, we want to be able to cross-learn
    and estimate the action values (or improve the estimate) for a 57-year-old user
    if we have data on users of close ages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, the number of possible contexts increases by a factor of 100\. We could
    of course mitigate this problem by defining age groups, but then we would have
    to spend time and data on calibrating the groups, which is not a trivial undertaking.
    In addition, the growth of the context space would be more limited (growth by
    a factor of 10 instead of 100), but still exponential. As we add more and more
    dimensions to the context, which is very likely in any realistic implementation,
    the problem could easily become intractable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we address this problem using function approximations. This will allow
    us to work with very complex and high-dimensional contexts. Later, we will also
    use function approximations for actions, which will enable us to work with changing
    and/or high-dimensional action spaces.
  prefs: []
  type: TYPE_NORMAL
- en: Using function approximations for context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Function approximations allow us to model the dynamics of a process from which
    we have observed data, such as contexts and ad clicks. As in the previous chapter,
    consider an online advertising scenario with five different ads (A, B, C, D, and
    E), with the context comprising user device, location, and age. In this section,
    our agent will learn five different Q functions, one per ad, each receiving a
    context of ![](img/Formula_03_004.png), and return the action value estimate.
    This is illustrated in *Figure 3.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – We learn a function for each action that receives the context
    and returns the action value'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14160_03_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.1 – We learn a function for each action that receives the context and
    returns the action value
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have a supervised machine learning problem to solve for each
    action. We can use different models to obtain the Q functions, such as logistic
    regression or a neural network (which actually allows us to use a single network
    that estimates values for all actions). Once we choose the type of function approximation,
    we can use the exploration strategies that we covered in the previous chapter
    to determine the ad to display given the context. But first, let's create a synthetic
    process to generate click data mimicking user behavior for our example.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – contextual online advertising with synthetic user data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Assume that the true user click behavior follows a logistic function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_03_005.jpg)![](img/Formula_03_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/Formula_03_007.png) is the probability of a user click when the
    context is ![](img/Formula_03_008.png) and ad ![](img/Formula_03_009.png) is shown.
    Also, let''s assume that *device* is 1 for mobile and 0 otherwise; and *location*
    is 1 for US and 0 otherwise. There are two important things to note here:'
  prefs: []
  type: TYPE_NORMAL
- en: This behavior, particularly the ![](img/Formula_03_010.png) parameters, is unknown
    to the advertiser, which they will try to uncover.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note the ![](img/Formula_03_011.png) superscript in ![](img/Formula_03_012.png),
    which denotes that the impact of these factors on user behavior is potentially
    different for each ad.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s now implement this in Python, using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Chapter03/Contextual Bandits.ipynb
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s import the Python packages we will need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These include libraries for scientific computation, such as NumPy and SciPy,
    and Plotly, a powerful visualization tool.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we create a class, `UserGenerator`, to simulate the user dynamics. Set
    some true ![](img/Formula_03_013.png) parameters here, which the advertiser (the
    agent) will try to learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s define the methods to generate a click or no clicks given the user context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that each ad has a different set of ![](img/Formula_03_014.png) values.
    When an ad is displayed to a user, the `logistic` method calculates the probability
    of a click and the `display_ad` method generates a click with that probability.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We define a method that will generate users with different contexts randomly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the `generate_user_with_context` method generates a US user
    with 60% chance. Also, with 80% chance, the ad is displayed on a mobile device.
    Finally, the user ages vary between 10 and 70, with a mean age of 34\. These are
    some numbers we set somewhat arbitrarily for the sake of the example. For simplicity,
    we don't assume any correlations between these user attributes. You can modify
    these parameters and introduce correlations to create more realistic scenarios.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can create some functions (outside of the class) to visualize, for our own
    intuition, the relationship between the context and the probability of a click
    associated with it. To this end, we need a function to create a scatter plot for
    a given ad type and data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we define a function to plot how the click probabilities change with age,
    shown in different subplots for each device type and location pair:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s create an object instance to generate users and visualize user
    behavior:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is shown in *Figure 3.2*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Comparison of the true ad click probabilities given the context'
  prefs: []
  type: TYPE_NORMAL
- en: '(x axis: age, y axis: click probability)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14160_03_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.2 – Comparison of the true ad click probabilities given the context
    (x axis: age, y axis: click probability)'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the plots in *Figure 3.2*, we should expect our algorithms to figure
    out, for example, to display ad E for users aged around 40, who connect from the
    US on a mobile device. Also, note that these probabilities are unrealistically
    high. More realistic `p` calculation in the `logistic` class by 0.05\. We will
    keep this as it is for now to make the problem easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we have implemented a process to generate user clicks. Here is how the
    scenario will flow:'
  prefs: []
  type: TYPE_NORMAL
- en: We will generate a user and get the associated context using the `generate_user_with_context`
    method in the `ug` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A CB model will use the context to display one of the five ads: A, B, C, D,
    or E.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The chosen ad will be passed to the `display_ad` method in the `ug` object,
    giving a reward of 1 (click) or 0 (no click).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The CB model will be trained based on the reward, and this cycle will go on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before actually implementing this flow, let's dive into the CB approaches we
    will use.
  prefs: []
  type: TYPE_NORMAL
- en: Function approximation with regularized logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We want our CB algorithms to observe the user responses to the ads, update
    the models that estimate the action values (function approximations), and determine
    which ad to display given the context, the action value estimates, and the exploration
    strategy. Note that in most realistic settings where the user traffic is high,
    the models would be updated not after every observation but after a batch of observations.
    With that, let''s start by discussing what kind of function approximator to use.
    There are numerous options, including many custom and sophisticated algorithms
    designed for CBs. Many of these models are based on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees/random forest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In terms of the exploration strategy, we''ll continue to focus on the following
    three fundamental approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: ε-greedy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upper confidence bounds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thompson/Bayesian sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s assume that, as subject matter experts, we know that the CTR can
    be modeled using logistic regression. We also mentioned that it is not practical
    to update the model after every single observation, so we prefer batch updates
    to our models. Finally, we would like to have Thompson sampling in our exploration
    toolbox, therefore we need posterior distributions on the parameters of the logistic
    regression models. To this end, we use a regularized logistic regression algorithm
    with batch updates provided by the agent(Chapelle et al., 2011). The algorithm
    does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Approximates the posterior distribution on the model weights by a Gaussian distribution.
    This allows us to use the posterior distribution as the prior in the next batch,
    and also use Gaussian for the likelihood function, since the Gaussian family is
    conjugate to itself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses a diagonal covariance matrix for the weights, meaning we assume the weights
    are not correlated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses Laplace approximation to obtain the mean and the variance estimates of
    the weight distributions, one of the common methods in statistics to estimate
    the posterior parameters from observed data if the posterior is assumed to be
    Gaussian.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Info
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can learn more about Laplace approximation for computing the posterior mean
    at [https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html](https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's see this algorithm in action next.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing regularized logistic regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will follow these steps to implement the regularized logistic regression,
    which we will use later:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a class and initialize the parameters we will keep track of:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s better understand what these parameters are:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a) `name` is to identify which ad an object instance is estimating the action
    value of. Again, we have a separate model for each of the ads and they are updated
    separately based on their own click data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) The `alpha` hyperparameter controls the exploration and exploitation trade-off.
    Smaller values reduce the variance (for example, 0.25), which therefore encourages
    exploitation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) This is a regularized regression, meaning that we have a regularization term,
    λ. This is a hyperparameter to be tuned. We also use it to initialize the `q`
    array.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) `n_dim` is to indicate the dimension of the ![](img/Formula_03_015.png) parameter
    vector, one for each element of the context input and a bias term.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: e) The weights of the logistic function are denoted by the array of `w`, such
    that `w[i]` corresponds to ![](img/Formula_03_016.png) in our bandit dynamics
    model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: f) The mean estimate of `w[i]` is given by `m[i]`, and the variance estimate
    is the inverse of `q[i]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we define a method to sample the parameters of the logistic regression
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that we need this to use Thompson sampling, which requires sampling the
    `w` array parameters from the posterior, rather than using the mean values. Again,
    the posterior is a normal distribution here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the loss function and a fit function, which will carry out the training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s elaborate on how the fitting part works:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a) We update the model using the `fit` method and the `loss` function with a
    given set of contexts and associated click data (1 for a click, 0 for no click).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) We use SciPy's minimize function for the model training. To prevent numerical
    overflows in the exponential terms, we impose bounds on `w`. These bounds need
    to be adjusted depending on the range of the input values. For the binary features
    of device type and the age input, location [-10, +10] and [-1, +1], respectively,
    are reasonable ranges for our use case.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) In each model update with a new batch of data, the previous `w` values serve
    as the prior.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Implement the upper confidence bounds on predictions, which is one of the exploration
    methods we will experiment with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement two types of prediction methods, one using the mean values parameter
    estimates and the other using the sampled parameters to be used with Thompson
    sampling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, before actually diving into solving the problem, we will define a metric
    to compare the alternative exploration strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Objective – regret minimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A common metric that is used to compare MAB and CB algorithms is called **regret**.
    We define the total regret by the time we have observed the ![](img/Formula_03_017.png)
    user as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_03_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_03_019.png) is the context for the ![](img/Formula_03_020.png)
    user, ![](img/Formula_03_021.png) is the best action (ad) to take that gives the
    highest expected CTR, and ![](img/Formula_03_022.png) is the expected CTR for
    the selected action (ad). Note that we are able to calculate the regret because
    we have access to the true action values (expected CTRs), which would not be the
    case in reality (although regret can still be estimated). Note that the minimum
    possible regret at any step is zero.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: With a good exploration strategy, we should see a decelerating cumulative regret
    over time as the algorithm discovers the best actions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the following code to calculate the regret given the context and
    the selected ad:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let's write the code to actually solve the problem using different
    exploration strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Solving the online advertising problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have already defined all the auxiliary methods to use the three exploration
    strategies we mentioned earlier, selecting the actions accordingly will be trivial.
    Now, let''s implement the functions for these strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with writing a function to implement the ε-greedy actions, which selects
    the best action most of the time and explores a random action otherwise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we write a function to implement action selection using the upper confidence
    bounds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we define a function to implement action selection using Thompson sampling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we perform the actual experiment, which will run and compare each
    strategy sequentially. We start with initializing the ad names, the experiment
    names, and the necessary data structures:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to implement an outer `for` loop to kick off a clean experiment with
    each of the exploration strategies. We initialize all the algorithm parameters
    and data structures:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we implement an inner loop to run the active strategy for 10K user impressions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s unpack this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a) We generate a user and use the context to decide which ad to display given
    the exploration strategy in each iteration.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) We observe and record the outcome. We also calculate the regret after each
    impression to be able to compare the strategies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) We update the logistic regression models in batches, namely after every 500
    ad impressions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After executing this code block, we can visualize the results using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives the plot that is shown in Figure 3.3:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Comparison of exploration strategies in the online advertising
    example'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14160_03_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 3.3 – Comparison of exploration strategies in the online advertising
    example
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We clearly see that Thompson sampling is outperforming the ε-greedy and `alpha`
    for UCB, which could have led to better performances. But this is exactly the
    point: Thompson sampling provides a very effective exploration strategy pretty
    much out of the box. This is what *Chapelle et al., 2011* empirically showed and
    helped the method gain popularity nearly a century after it was introduced.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In a real production system, it makes more sense to use well-maintained libraries
    for the supervised learning portion in CBs rather than a custom implementation
    as we did here. One such library for probabilistic programming is PyMC3 ([https://docs.pymc.io/](https://docs.pymc.io/)).
    Using PyMC3, you can fit supervised learning models to your data and then sample
    the model parameters. As an exercise, consider implementing Thompson sampling
    using a logistic regression model in PyMC3.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s close this section by visualizing the parameter estimates of the models.
    For example, when we used the ε-greedy strategy, the ![](img/Formula_03_023.png)
    coefficients for ad A were estimated as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Visualization of the posterior distribution of  for ad A at
    the end of the experiment with ε-greedy exploration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14160_03_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.4 – Visualization of the posterior distribution of ![](img/Formula_03_024.png)
    for ad A at the end of the experiment with ε-greedy exploration
  prefs: []
  type: TYPE_NORMAL
- en: The logistic regression model estimates the coefficients as ![](img/Formula_03_025.png)
    whereas the actual coefficients are ![](img/Formula_03_026.png). The model is
    especially certain about its estimate for ![](img/Formula_03_027.png), which is
    indicated by a very narrow distribution in the plot.
  prefs: []
  type: TYPE_NORMAL
- en: Terrific job! This was a rather long exercise, but one that will set you up
    for success in your real-life implementations. Take a deep breath and a break,
    and next, we will look at an even more realistic version of online advertising
    where the ad inventory changes over time.
  prefs: []
  type: TYPE_NORMAL
- en: Using function approximations for actions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our online advertising examples so far, we have assumed that we have a fixed
    set of ads (actions/arms) to choose from. However, in many applications of CBs,
    the set of available actions changes over time. Take the example of a modern advertising
    network that uses an ad server to match ads to websites/apps. This is a very dynamic
    operation that involves, leaving the pricing aside, three major components:'
  prefs: []
  type: TYPE_NORMAL
- en: Website/app content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewer/user profile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ad inventory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Previously, we considered only the user profile for the context. An ad server
    needs to take the website/app content into account additionally, but this does
    not really change the structure of the problem we solved before. However, now,
    we cannot use a separate model for each ad since the ad inventory is dynamic.
    We handle this by using a single model to which we feed ad features. This is illustrated
    in *Figure 3.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Function approximation of action values with context and action
    inputs in the ad network example'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14160_03_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.5 – Function approximation of action values with context and action
    inputs in the ad network example
  prefs: []
  type: TYPE_NORMAL
- en: While making a decision, we take the context as given. So, the decision is about
    which ad to display from the ad inventory that is available at the time. So, to
    make this decision, we generate action values for all available ads using this
    single model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it is time to talk about what kind of model to use in this situation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember what the model does: it learns how a given user would react to a given
    ad that they see on a given website/app and estimates the probability of a click.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you think about all possible user and website/app contexts, and all possible
    ads, this is a very complicated relationship to figure out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such a model needs to be trained on a lot of data and it should be sophisticated
    enough to be able to come up with a good approximation of the true dynamics of
    a click.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we have this much complexity, and hopefully enough data, there is one
    obvious choice: **deep neural networks** (**DNNs**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the previous section, we compared different exploration strategies and showed
    that Thompson sampling is a very competitive choice. However, Thompson sampling
    requires us to be able to sample from the posterior of the model parameters; this
    is often intractable for complex models such as neural networks. To overcome this
    challenge, we rely on approximate Bayesian methods available in the literature.
  prefs: []
  type: TYPE_NORMAL
- en: Info
  prefs: []
  type: TYPE_NORMAL
- en: There are many approximation methods and their comparison is beyond the scope
    here. *Riquelme et al., 2018* provide a great comparison along with code in the
    TensorFlow repository.
  prefs: []
  type: TYPE_NORMAL
- en: One of these approximations involves using dropout regularization in the DNN
    and keeping it active during inference time. As a reminder, dropout regularization
    deactivates each neuron in the DNN with respect to a given probability and increases
    generalization. Typically, dropout is only used during training. When it is kept
    active during inference, since neurons are disabled probabilistically, the output
    varies accordingly. *Gal et al., 2015* have shown that this works as an approximate
    Bayesian inference, which we need for Thompson sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – contextual online advertising with user data from the US Census
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let's talk about the example we will use in this section. Previously, we
    crafted our own examples. This time, we'll use a dataset that is modified from
    the 1994 US Census and adapt it to an online advertising setting. The dataset
    is known as the Census Income dataset and is available at [https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this dataset, we use the following information on the individuals who participated
    in the census: age, work class, education, marital status, occupation, relationship,
    race, gender, work hours per week, native country, and income level.'
  prefs: []
  type: TYPE_NORMAL
- en: With that, let's discuss how to turn this data into an online advertising scenario.
  prefs: []
  type: TYPE_NORMAL
- en: The scenario
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Consider an ad server that knows all of the preceding information about a user,
    except the education level. On the other hand, the ad network is managing ads
    that address a specific education level. For example, at any given time, the ad
    server has one ad that is targeting users with a college education and one ad
    that is targeting users with elementary school education. If the target audience
    of the ad that is shown to a user matches the user's education level, there is
    a high probability of a click. If not, the probability of a click decreases gradually
    as the discrepancy between the target education level and the user's education
    level grows. In other words, the ad server is implicitly trying to predict users'
    education levels as close as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's prepare the dataset for our scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Follow these steps to clean and prepare the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with importing the necessary packages to use later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we need to download the data and select the columns of interest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s drop the rows with missing data, marked by `?` entries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Normally, a missing entry could itself be a valuable indicator that the model
    could use. In addition, it is a bit wasteful to drop a whole record just because
    of a single missing entry. However, data imputation is beyond our scope here,
    so let's keep focusing on the CB problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s also collapse the different education levels to four categories: `Elementary`,
    `Middle`, `Undergraduate`, and `Graduate`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we convert categorical data into one-hot vectors to be able to feed into
    a DNN. We preserve the education column as is, since that is not part of the context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By doing this conversion at the beginning, we assume that we know all possible
    work class categories and native countries.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: That's it! We have the data ready. Next, we implement logic to simulate an ad
    click based on the actual education level of the user and the education level
    that the ad displayed targets.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating ad clicks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this example, the availability of ads is random and the ad clicks are stochastic.
    We need to come up with some logic to simulate this behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with determining the ad availability probabilities for each education
    category and implement the sampling of ads:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As mentioned, the ad server will have at most one ad for each target group.
    We also ensure that there is at least one ad in the inventory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we define a function to generate a click probabilistically, where the
    likelihood of a click increases to the degree that the user''s education level
    and the ad''s target match:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, when an ad is shown to a user, if the ad's target matches the user's education
    level, there will be ![](img/Formula_03_028.png) chance of a click. This probability
    decreases by ![](img/Formula_03_029.png) for each level of mismatch. For example,
    a person with a high school diploma has a ![](img/Formula_03_030.png) chance of
    clicking on an ad that targets a user group of elementary school graduates (or
    college graduates). Note that this information is not known to the CB algorithm.
    It will be used only to simulate the clicks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We have the problem set up. Next, we'll turn to implementing a CB model.
  prefs: []
  type: TYPE_NORMAL
- en: Function approximation using a neural network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned, we use a (not so) DNN, which will estimate the action value, given
    the context and the action. The DNN we'll use has two layers, with 256 hidden
    units in each layer. This model is pretty easy to create using Keras, TensorFlow's
    high-level API.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Note that in our model, we use dropout that we leave active for the inference
    time as a Bayesian approximation that we need for Thompson sampling. This is configured
    by setting `training=True` in the dropout layer.
  prefs: []
  type: TYPE_NORMAL
- en: The network outputs a scalar, which is an estimate for the action value given
    the context and the action feature (target user group). Using binary cross-entropy
    suits such an output the best, so we'll use it in our model. Finally, we'll use
    the popular Adam optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: Info
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://www.tensorflow.org/guide/keras](https://www.tensorflow.org/guide/keras)
    if you need to get started with Keras or to refresh your memory. It is very simple
    to build the standard DNN models with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create the functions for model creation and updates:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a function that returns a compiled DNN model with given input dimensions
    and a dropout rate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will update this model in batches as data becomes available. Next, write
    a function to train the model for 10 epochs with each batch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then define a function that returns a one-hot representation for a specified
    ad based on the education level it targets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We implement the Thompson sampling to select an ad given the context and the
    ad inventory at hand:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The ad to be displayed is chosen based on the largest action value estimate
    that we obtain from the DNN. We obtain this by trying all available ads in the
    inventory – and remember, we have at most one ad per target user group – with
    the context of the user. Note that the target user group is equivalent to `action`,
    which we feed to the DNN in the format of a one-hot vector.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, we write a function to generate users through a random selection from
    the dataset. The function will return the user data as well as the derived context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This concludes what we need to decide on the ad to display using Thompson sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the regret
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll continue to use regret for comparing various versions of the CB algorithm.
    We calculate it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: With the regret calculation also in place, let's now actually solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Solving the online advertising problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we are ready to put all these components together. We''ll try this algorithm
    with different dropout probabilities over 5,000 impressions. We''ll update the
    DNN parameters after every 500 iterations. Here is the implementation in Python
    for various dropout rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The cumulative regrets over time are stored in the `df_cbandits` `pandas` DataFrame.
    Let''s visualize how they compare:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Comparison of cumulative regret with various dropout rates'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14160_03_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.6 – Comparison of cumulative regret with various dropout rates
  prefs: []
  type: TYPE_NORMAL
- en: The results in *Figure 3.6* show that our bandit models learn after some observation
    on how to select the ads given the user characteristics. As various dropout rates
    have led to different algorithm performances, an important question again becomes
    how to select the dropout rate. One obvious answer is to try different rates over
    time to identify what works best in similar online advertising problems. This
    approach usually works if the business has to solve similar problems again and
    again over a long time period. A better approach, though, is to learn the optimal
    dropout rate.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: '**Concrete dropout** is a variant that tunes the dropout probabilities automatically.
    (Collier & Llorens, 2018) have successfully used this method on CB problems and
    reported superior performance over fixed dropout selections. For a TensorFlow
    implementation of concrete dropout, see [https://github.com/Skydes/Concrete-Dropout](https://github.com/Skydes/Concrete-Dropout).'
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, we conclude our discussion on CBs. Note that we focused on two components
    while formulating the CB problem:'
  prefs: []
  type: TYPE_NORMAL
- en: Function approximation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploration strategy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can often mix and match different function approximations with various exploration
    techniques. While Thompson sampling with DNNs is probably the most common choice,
    we encourage you to take a look at the literature for other approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Other applications of multi-armed bandits and CBs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have focused on online advertising as our running example. If you
    are wondering how common bandit algorithms are in practice in this field, they
    are actually quite common. For example, Microsoft has a service, called Personalizer,
    based on bandit algorithms (disclaimer: the author is a Microsoft employee at
    the time of writing this book). The example here is itself inspired by the work
    at HubSpot – a marketing solutions company (Collier & Llorens, 2018). Moreover,
    bandit problems have a vast array of practical applications other than advertising.
    In this section, we''ll briefly go over some of those applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Recommender systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The bandit problems we formulated and solved in this chapter are a type of
    recommender system: they recommend which ad to display, potentially leveraging
    information available about users. There are many other recommender systems that
    use bandits in a similar way, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Artwork selection for movie titles, as Netflix famously implements (Chandrashekar,
    Amat, Basilico, & Jebara, 2017)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Article recommendations on a news portal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Post recommendations on a social media platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product/service recommendations on an online retail platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tailoring search results to the user on a search engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web page/app feature design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most famous websites and apps that we visit every day decide which design to
    use for different features after extensive tests. For example, they create different
    designs of the "buy" button on the shopping cart and observe which design generates
    the most sales. These experiments are conducted nonstop for hundreds of features.
    An efficient way of conducting these experiments is to use multi-armed bandits.
    This way, bad feature designs could be identified early on and eliminated to minimize
    the user disturbance throughout these experiments (Lomas et al., 2016).
  prefs: []
  type: TYPE_NORMAL
- en: Healthcare
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bandit problems have important applications in healthcare. Especially with the
    increasing availability of patient data, through well-maintained patient databases
    and data collection via mobile devices, many treatments can now be personalized
    to individuals. CBs are therefore an important tool to use when deciding which
    treatment to apply to a patient in randomized controlled trials. Another application
    in which CBs have successfully been used is for deciding the treatment dose of
    drugs, such as Warfarin, which regulates blood coagulation (Bastani and Bayati,
    2015). One more application is related to the optimal allocation of data sampling
    to various animal models to assess the effectiveness of a treatment. CBs have
    proven to increase the efficiency of this process by identifying promising treatments
    better than conventional methods (Durand et al., 2018).
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic pricing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An important challenge for online retailers is to dynamically adjust their prices
    on millions of products. This can be modeled as a CB problem where the context
    could include product demand forecasts, inventory levels, product cost, and location.
  prefs: []
  type: TYPE_NORMAL
- en: Finance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CBs are used in literature for optimal portfolio construction through mixing
    passive and active investments to achieve a balance between the risk and expected
    return.
  prefs: []
  type: TYPE_NORMAL
- en: Control systems tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many mechanical systems use variants of **proportional-integral-derivative**
    (**PID**) controllers to control the system. PID controllers require tuning, which
    is often done by subject matter experts for each system separately. This is because
    optimal gains for the controller depend on the specifics of the equipment, such
    as the material, temperature, and wear and tear. This manual process can be automated
    using a CB model that assesses system characteristics and tunes the controller
    accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we concluded our discussion on bandit problems with CBs. As
    we mentioned, bandit problems have many practical applications. So, it would not
    be a surprise if you already had a problem in your business or research that can
    be modeled as a bandit problem. Now that you know how to formulate and solve one,
    go out and apply what you have learned! Bandit problems are also important to
    develop an intuition on how to solve an exploration-exploitation dilemma, which
    will exist in almost every RL setting.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a solid understanding of how to solve one-step RL, it is time
    to move on to full-blown multi-step RL. In the next chapter, we will go into the
    theory behind multi-step RL with Markov decision processes, and build the foundation
    for modern deep RL methods, which we will cover in the subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Bouneffouf, D., & Rish, I. (2019). *A Survey on Practical Applications of Multi-Armed
    and Contextual Bandits*. Retrieved from arXiv: [https://arxiv.org/abs/1904.10040](https://arxiv.org/abs/1904.10040)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chandrashekar, A., Amat, F., Basilico, J., & Jebara, T. (2017, December 7).
    Netflix Technology Blog. Retrieved from Artwork Personalization at Netflix: [https://netflixtechblog.com/artwork-personalization-c589f074ad76](https://netflixtechblog.com/artwork-personalization-c589f074ad76)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapelle, O., & Li, L. (2011). *An Empirical Evaluation of Thompson Sampling.
    Advances in Neural Information Processing Systems*, 24, (pp. 2249-2257)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Collier, M., & Llorens, H. U. (2018). *Deep Contextual Multi-armed Bandits*.
    Retrieved from arXiv: [https://arxiv.org/abs/1807.09809](https://arxiv.org/abs/1807.09809)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gal, Y., Hron, J., & Kendall, A. (2017). *Concrete Dropout. Advances in Neural
    Information Processing Systems*, 30, (pp. 3581-3590)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marmerola, G. D. (2017, November 28). *Thompson Sampling for Contextual bandits*.
    Retrieved from Guilherme''s blog: [https://gdmarmerola.github.io/ts-for-contextual-bandits](https://gdmarmerola.github.io/ts-for-contextual-bandits)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Riquelme, C., Tucker, G., & Snoek, J. (2018). *Deep Bayesian Bandits Showdown:
    An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling*. International
    Conference on Learning Representations (ICLR)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russo, D., Van Roy, B., Kazerouni, A., Osband, I., & Wen, Z. (2018). *A Tutorial
    on Thompson Sampling. Foundations and Trends in Machine Learning*, (pp. 1-96)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lomas, D., Forlizzi, J., Poonawala, N., Patel, N., Shodhan, S., Patel, K., Koedinger,
    K., & Brunskill, E. (2016). *Interface Design Optimization as a Multi-Armed Bandit
    Problem*. (pp. 4142-4153). 10.1145/2858036.2858425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Durand, A., Achilleos, C., Iacovides, D., Strati, K., Mitsis, G.D., & Pineau,
    J. (2018). *Contextual Bandits for Adapting Treatment in a Mouse Model of de Novo
    Carcinogenesis*. Proceedings of the 3rd Machine Learning for Healthcare Conference,
    in PMLR 85:67-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bastani, H. & Bayati, M. (2015). *Online decision-making with high-dimensional
    covariates*. Available at SSRN 2661896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
