- en: 7\. Generative Adversarial Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will embark on another interesting topic within the deep
    learning domain: **Generative Adversarial Networks** (**GANs**). You will get
    introduced to GANs and their basic components, along with some of their use cases.
    This chapter will give you hands-on experience of creating a GAN to generate a
    data distribution produced by a sine function. You will also be introduced to
    deep convolutional GANs and will perform an exercise to generate an MNIST data
    distribution. By the end of this chapter, you will have tested your understanding
    of GANs by generating the MNIST fashion dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The power of creativity was always the exclusive domain of the human mind. This
    was one of the facts touted as one of the major differences between the human
    mind and the artificial intelligence domain. However, in the recent past, deep
    learning has been making baby steps in the path to being creative. Imagine you
    were at the Sistine Chapel in the Vatican and were looking up with bewilderment
    at the frescos immortalized by Michelangelo, wishing your deep learning models
    were able to recreate something like that. Well, maybe 10 years back, people would
    have scoffed at your thought. Not anymore, though – deep learning models have
    made great strides in regenerating immortal works. Applications like these are
    made possible by a class of networks called **Generative Adversarial Networks**
    (**GANs**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Many applications have been made possible with GANs. Take a look at the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1: Image translation using GANs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.1: Image translation using GANs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding image is sourced from the research paper titled *Image-to-Image
    Translation with Conditional Adversarial Networks*: Phillip Isola, Jun-Yan Zhu,
    Tinghui Zhou, Alexei A. Efros, available at [https://arxiv.org/pdf/1611.07004.pdf](https://arxiv.org/pdf/1611.07004.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding image demonstrates how the input image, which has a very different
    color scheme, has been transformed by the GAN into an image that looks very similar
    to the real one. This application of GANs is called image translation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to these examples, many other use cases are finding traction. Some
    of the notable ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data generation for data augmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating cartoon characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text to image translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three-dimensional object generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list goes on. As the days go by, applications of GANs increasingly become mainstream.
  prefs: []
  type: TYPE_NORMAL
- en: So, what exactly are GANs? What are the inner dynamics of GANs? How do you generate
    images or other data distributions from totally unconnected distributions? In
    this chapter, we'll find out the answers to those questions.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about **recurrent neural networks** (**RNNs**),
    a class of deep learning networks used for sequence data. In this chapter, we
    will embark on a fascinating safari to the world of GANs. First, we will start
    with an introduction to GANs. Then, we'll focus on generating a data distribution
    that is similar to a known mathematical expression. We'll then move on to **deep
    convolutional GANs** (**DCGANs**). To see how well our generative models work,
    we will generate a data distribution similar to the MNIST handwritten digits.
    We'll start this journey by learning about GANs.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your system configuration, some of the exercises and activities
    in this chapter may take quite a long time to execute.
  prefs: []
  type: TYPE_NORMAL
- en: Key Components of Generative Adversarial Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GANs are used to create a data distribution from random noise data and make
    it look similar to a real data distribution. GANs are a family of deep neural
    networks that comprise two networks that are competing against each other. One
    of these networks is called the **generator network**, while the other is called
    the **discriminator network**. The functions of these two networks are to compete
    against each other to generate a probability distribution that closely mimics
    an existing probability distribution. To state an example of generating a new
    probability distribution, let's say we have a collection of images of cats and
    dogs (real images). Using a GAN, we can generate a different set of images (fake
    images) of cats and dogs from a very random distribution of numbers. The success
    of a GAN is in generating the best set of cat and dog images to the point that
    it is difficult for people to differentiate between the fake ones and the real
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: Another example where GANs can become useful is in data privacy. The data of
    companies, especially in domains such as finance and healthcare, is extremely
    sensitive. However, there might be instances where data has to be shared with
    third parties for research purposes. In such scenarios, to maintain the confidentiality
    of data, companies can use GANs to generate datasets that are similar in nature
    to their existing datasets. There is a multitude of such business use cases where
    GANs can come in really handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand GANs better by mapping out some of their components, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2: Example of GAN structure'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.2: Example of GAN structure'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding figure provides a concise overview of the components of a GAN
    and how they come in handy in generating fake images from real ones. Let''s understand
    the process in the context of the preceding diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: The set of images at the top-left corner of the preceding figure represents
    a probability distribution of real data (for example, MNIST, images of cats and
    dogs, pictures of human faces, and more).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The generative network shown in the bottom-left part of the diagram generates
    fake images (probability distributions) from a random noise distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The trained discriminative network classifies whether the image that is fed
    in is fake or real.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A feedback loop (the diamond-shaped box) working through the backpropagation
    algorithm gives feedback to the generator network, thereby refining the parameters
    of the generator model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The parameters continue to be refined until the discriminator network can't
    discriminate between the fake images and the real ones.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have an overview of each of the components, let's dive deeper and
    understand them better through a problem statement.
  prefs: []
  type: TYPE_NORMAL
- en: Problem Statement – Generating a Distribution Similar to a Given Mathematical Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this problem, we will use GANs to generate a distribution that is similar
    to a data distribution from a mathematical function. The function we will be using
    to generate the real data is a simple **sine wave**. We will train a GAN to generate
    a fake distribution of data that will be similar to the data we generated from
    the known mathematical function. We will progressively build each component that's
    required while we traverse the solution for this problem statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process we will follow is explained in the following figure. We will follow
    a pedagogical approach as per the steps detailed in this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3: Four-step process to building a GAN from a known function'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.3: Four-step process to building a GAN from a known function'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's explore each of these processes.
  prefs: []
  type: TYPE_NORMAL
- en: Process 1 – Generating Real Data from the Known Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To begin our journey, we need a real distribution of data. This distribution
    of data will comprise two features – the first one is the sequence and the second
    one is the sine of the sequence. The first feature is a sequence of data points
    spaced at equal intervals. To generate this sequence, we need to randomly generate
    a data point from a normal distribution and then find other numbers spaced in
    sequence at equal intervals. The second feature will be the `sine()` of the first
    feature. Both these features will form our real data distribution. Before we get
    into an exercise that generates the real dataset, let's look at some of the functions
    in the `numpy` library we will use in this process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Number Generation**'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will generate a random number from a normal distribution using the
    following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This function takes three arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`loc`: This is the mean of the data distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scale`: This is the standard deviation of the data distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`size`: This defines the number of data points we want.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Arranging the Data into a Sequence**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To arrange data in a sequence, we use the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The arguments are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`start`: This is the point that the sequence should start from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end`: The point where the sequence ends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spacing`: The frequency between each successive number in the sequence. For
    example, if we start off with 1 and generate a series with a spacing of `0.1`,
    the series will look as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Generating the Sine Wave**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate the sine of a number, we use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Let's use these concepts in the following exercise and learn how to generate
    a real data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.01: Generating a Data Distribution from a Known Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will generate a data distribution from a simple sine function.
    By completing this exercise, you will learn how to generate a random number from
    a normal distribution and create a sequence of equally spaced data with the random
    number as its center. This sequence will be the first feature. The second feature
    will be created by calculating the `sine()` for the first feature. Follow these
    steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and name it `Exercise 7.01`. Run the following
    command to import the necessary library packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate a random number from a normal distribution that has a mean of 3 and
    a standard deviation of 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the previously generated random number as a midpoint, we will generate
    equal sequences of numbers to the right and left of the midpoint. We will generate
    a batch of 128 numbers. So, we take 64 numbers each to the right and left of the
    midpoint with a spacing of 0.1\. The following code generates a sequence to the
    right of the midpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate 64 numbers to the left of the midpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Concatenate both these sequences to generate the first feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the one shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.4: Sequence of numbers with equal spacing'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.4: Sequence of numbers with equal spacing'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding is the distribution of `128` numbers equally spaced from one another.
    This sequence will be our first feature for the data distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate the second feature, which is the `sine()` of the first feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.5: Plot for the sine function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.5: Plot for the sine function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding plot shows the distribution that you would be trying to mimic
    using GANs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Reshape each feature before concatenating them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Concatenate both features to form a single DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3gHhv42](https://packt.live/3gHhv42).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2O62M6r](https://packt.live/2O62M6r).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this exercise, we created a data distribution from a mathematical function.
    We will be using this data distribution later to train the GAN to generate a distribution
    similar to this. In a production environment, you will be provided with a real
    dataset, similar to the MNIST or `Imagenet` datasets. In this case, our real dataset
    is a known mathematical function. Later in this chapter, we will use some random
    noise data and train the GAN to make that random noise data similar to this real
    data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen the real data distribution, the next section will be all
    about creating a basic generative network.
  prefs: []
  type: TYPE_NORMAL
- en: Process 2 – Creating a Basic Generative Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous process, we worked on an example that will generate a distribution
    from a known function. As we mentioned earlier, the purpose of the generative
    network is to sample data from any arbitrary distribution and then transform that
    data into generative samples that look similar to the known distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The way the generative network achieves this is through the dynamics of the
    generator, the discriminator, and the training process. The success of the generative
    network relies on its ability to create data distributions that the discriminator
    can't differentiate between – in other words, it can't determine whether the distribution
    is fake or not. This ability of the generative network to create distributions
    that can fool the discriminator is acquired by the training process. We will talk
    more about the discriminator and the training process later in this chapter. For
    now, let's see how a generator network can be constructed to generate fake data
    distributions from some random distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Generative Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative networks are neural networks that are trained to transform an arbitrary
    distribution so that it looks similar to the known distribution. We can use any
    type of neural network for this, such as **multi-layer perceptrons** (**MLPs**),
    **convolutional neural networks** (**CNNs**), and more, to build the generator
    network. The input data to these networks are the samples that we take from any
    arbitrary distribution. In this example, we will be using an MLP to build a generative
    network. Before we start building the network, let's revisit some of the building
    blocks of a neural network that you will have learned about in the previous chapters.
    We will be building the network using the Keras library.
  prefs: []
  type: TYPE_NORMAL
- en: Sequential()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you might already know, a neural network consists of different layers of
    nodes that have connections between them. The `Sequential()` API is the mechanism
    through which you can create those layers in Keras. The `Sequential()` API is
    instantiated using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the first part of the code, the `Sequential()` class is imported from the
    `tensorflow.Keras` module. It is then instantiated as a variable model in the
    second line of code.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Initializers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In *Chapter 2*, *Neural Networks*, you learned that the training process involves
    updating the weights and biases of a neural network so that the function that
    maps the inputs to the outputs is learned effectively. As a first step in the
    training process, we initialize some values for the weights and biases. These
    get updated more during the backpropagation stage. The initialization of the weights
    and biases is done through a parameter called the `he_uniform` in the exercise
    that follows. A kernel initializer will be added as a parameter within the network.
  prefs: []
  type: TYPE_NORMAL
- en: Dense Layers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The basic dynamics within each layer in a neural network is the matrix multiplication
    (dot product) between the weights for the layer and the input to the layer, and
    the further addition of a bias. This is represented by the `dot(X,W) + B` equation,
    where `X` is the input to the layer, `W` is the weight or the kernel, and `B`
    is the bias. This operation of the neural network is done using the dense layer
    in Keras. This is implemented in code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The above code block is solely meant to explain how the code is implemented.
    It may not result in a desirable output when run in its current form. For now,
    try to understand the syntax completely; we will be putting this code into practice
    in *Exercise 7.02*, *Building a Generative Network*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, we add a dense layer to the instantiation of the `Sequential()`
    class (`Genmodel`) we created earlier. Some of the key parameters that need to
    be given to define a dense layer are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(hidden_layer)`: As you might know, hidden layers are the intermediate layers
    in a neural network. The number of nodes of a hidden layer is defined as the first
    parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(activation)`: The other parameter is the type of activation function that
    will be used. Activation functions will be discussed in detail in the next section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(kernel_initializer)`: The kind of kernel initializer that is used for the
    layer is defined within the dense layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(input_dim)`: For the first layer of the network, we have to define the dimensions
    of the input (`input_dim`). For the subsequent layers, this is deduced automatically
    based on the output dimensions of each layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As you might know, activation functions introduce non-linearity to the outputs
    of a neuron. In a neural network, activation functions are introduced just after
    the dense layer. The output of the dense layer is the input of the activation
    function. Different activation functions will be used within the following exercise.
    They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ReLU**: This stands for **Rectified Linear Unit**. This activation function
    only outputs positive values. All negative values will be output as zero. This
    is one of the most widely used activation functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ELU**: This stands for **Exponential Linear Unit**. This is very similar
    to ReLU except for the fact that it outputs negative values as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linear**: This is a straight-line activation function. In this function,
    the activations are proportional to the inputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SELU**: This stands for **Scaled Exponential Linear Unit**. This activation
    function is a relatively lesser-used one. It enables an idea called internal normalization,
    which ensures that the mean and variance from the previous layers are maintained.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid**: This is a very standard activation function. A sigmoid function
    squashes any input into a value between 0 and 1\. Therefore, the output from a
    sigmoid function can also be treated as a probability distribution as the values
    are between 0 and 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have seen some of the basic building blocks of the network, let's
    go ahead and build our generative network in the next exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start the exercise, let's see where the next exercise lies in the
    overall scheme of things. In *Exercise 7.01*, *Generating a Data Distribution
    from a Known Function*, we created a data distribution from a known mathematical
    function, which is a `sine()` function. We created the entire distribution by
    arranging the first feature with equal intervals and then creating the second
    feature by taking the `sine()` function of the first feature. So, we literally
    controlled the entire process of creating this dataset. That's why this is called
    a real data distribution because the data is created from a known function. The
    ultimate aim of a GAN is to transform a random noise distribution and make it
    look like a real data distribution; that is, make a random distribution look like
    the structured `sine()` distribution. This will be achieved in later exercises.
    However, as a first step, we will create a generative network that will create
    a random noise distribution. This is what we will do in the next exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.02: Building a Generative Network'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will build a generative network. The purpose of the generative
    network is to generate fake data distribution from a random noise data. We''ll
    do this by generating random data points as input to the generator network. Then,
    we''ll build a six-layer network, layer by layer. Finally, we''ll predict the
    output from the network and plot the output distribution. This data distribution
    will be our fake distribution. Follow these steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and name it `Exercise 7.02`. Import the following
    library packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this step, we define the number of input features and output features for
    the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will have 10 features as input and the output will be two features. The input
    features of `10` are arbitrarily selected. The output features of `2` are selected
    because our real dataset contains two features.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we will generate a batch of random numbers. Our batch size will be `128`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can select any batch size. A batch size of `128` is selected so that we take
    cognizance of the computation resources we have. Since the input size is 10, we
    should generate 128 × 10 random numbers. Also, in the preceding code, `randn()`
    is the function to generate random numbers. Inside the function, we specify how
    many data points we want, which is (128 × 10) in our case.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s reshape the random data into the input format we want using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this step, we will define the generator. This network will have six layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the network, we can see that, in the first layer, we define the dimension
    of the input, which is 10, and in the last layer, we define the output dimension,
    which is 2\. This is based on the input data dimensions that we generated in *Step
    4* (10) and the output features that we want, which is similar to the number of
    features of the real data distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can see the summary of this network by using the `model.summary()` function
    call:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.6: Summary of the generator network'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.6: Summary of the generator network'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the summary, you can see the shapes of the output from each layer. For
    example, the output from the dense layer has a shape of (*size of batch*, `32`)
    since the first hidden layer has `32` neurons. `None` in the shape layer denotes
    the number of examples, which in this case means the input batch size. The figure
    of 352 for the first layer is the size of the parameters, which includes both
    the weights and bias. The weight matrix will have a size of (10 × 32) as the number
    of inputs to the first layer is 10 and the next layer (hidden layer 1) has 32
    neurons. The number of bias will be (32 × 1), which will be equivalent to the
    number of hidden layer neurons in the first layer. So, in total, there are 320
    + 32 = 352 parameters. The second layer would be (32 × 32) + ( 32 × 1) = 1,056
    and so on for all subsequent layers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now that we have defined the generator network, let''s generate the output
    from the network. We can do that using the `predict()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that the output from the generator function generates a sample with
    two features and several examples equal to the batch size we have given.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot the distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the following. Please note that modeling
    will be stochastic in nature and therefore you might not get the same output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.7: Plot of the fake data distribution'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.7: Plot of the fake data distribution'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, very random data has been generated. As you will see in upcoming
    exercises, this random data will be transformed so that it looks like the real
    data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2W0FxyZ](https://packt.live/2W0FxyZ).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2WhZpOn](https://packt.live/2WhZpOn).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we defined the generator network, which had six layers and
    then generated the first fake samples from the generator network. You may be wondering
    how we arrived at those six layers. What about the choice of the activation functions?
    Well, the network architecture was arrived at after a lot of experimentation for
    this problem statement. There are no real shortcuts in terms of finding the right
    architecture. We have to arrive at the most optimal architecture after experimenting
    with different parameters such as the number of layers, type of activations, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the Stage for the Discriminator Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous exercise, we defined the generator network. Now, it is time
    to set the stage before we define the discriminator network. Looking at the output
    we got from the generator network, we can see that the data points are randomly
    distributed. Let''s take a step back and assess where we are really headed. In
    our introduction to generative networks, we stated that we want the output from
    the generative network to be similar to the real distribution we are trying to
    mimic. In other words, we want the output from the generative network to look
    similar to the output from the real distribution, as shown in the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8: Real data distribution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.8: Real data distribution'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that the current distribution that has been generated by the generator
    network is nowhere near the distribution we want to mimic. Why do you think this
    is happening? Well, the reason is quite obvious; we have not done any training
    yet. You will also have noticed that we don''t have an optimizer function as part
    of the network. The optimizer function in Keras is defined using the `compile()`
    function, as shown in the following code, where we define the type of loss function
    and what kind of optimizers we want to adopt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We have excluded the `compile()` function on purpose. Later, when we are introduced
    to the GAN model, we will use the `compile()` function to optimize the generator
    network. So, hang on until then. For now, we will go ahead with the next step
    of the process, which is defining the discriminator network.
  prefs: []
  type: TYPE_NORMAL
- en: Process 3 – Discriminator Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous process, we were introduced to the generative network, a neural
    network that generated fake samples. The discriminator network is also another
    neural network, albeit with different functionality from the generator network.
    The purpose of the discriminator function is to identify whether a given example
    is a real one or a fake one. Using an analogy, if the generator network is a conman
    who makes fake currency, then the discriminator network is the super cop who identifies
    that the currency is fake. Once caught by the super cop, the conman will try to
    perfect their craft to make better counterfeits so that they can fool the super
    cop. However, the super cop will also undergo lots of training to know the nuances
    of different currencies and work toward perfecting the craft of catching whatever
    the conman generates. We can see here that both these protagonists are in adversarial
    positions all the time. This is the reason why the network is called a *generative
    adversarial network.*
  prefs: []
  type: TYPE_NORMAL
- en: Taking a cue from the preceding analogy, training a discriminator is similar
    to the super cop undergoing more training to identify fake currency. The discriminator
    network is like any binary classifier you would have learned about in machine
    learning. As part of the training process, the discriminator will be provided
    with two classes of examples, one generated from the real distribution and the
    other from the generator distribution. Each of these sets of examples will have
    their respective labels too. The real distribution will have a label of "1", while
    the fake distribution will have a label of "0". The discriminator, after being
    trained, will have to correctly classify whether an example is real or fake, which
    is a typical binary classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the Discriminator Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The core structure of the discriminator network would be similar to the generator
    network we implemented in the previous section. The complete process behind building
    the discriminator network is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate batches of real distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the generator network, it generates batches of fake distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the discriminator network with examples of both these distributions. The
    real distribution will have a label of 1, while the fake distribution will have
    a label of 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the performance of the discriminator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In *Steps 1* and *2*, we have to generate batches of both the real and fake
    distributions. This will necessitate making use of the real distribution we built
    in *Exercise 7.01*, *Generating a Data Distribution from a Known Function,* and
    the generator network we developed in *Exercise 7.02,* *Building a Generative
    Network*. Since we have to use these two distributions, it would be convenient
    to package them into two types of functions to efficiently train the discriminator
    network. Let's look at the two types of functions we will build.
  prefs: []
  type: TYPE_NORMAL
- en: Function to Generate Real Samples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The content of this function, which is used to generate real samples, is the
    same as the code we developed in *Exercise 7.01,* *Generating a Data Distribution
    from a Known Function*. The only notable addition is the label for the input data.
    As we stated earlier, the real samples will have a label of 1\. So, as labels,
    we will generate an array of 1s with the same size as the batch size. There is
    a utility function in `numpy` that can be used to generate a series of 1s called
    `np.ones((batch,1)`. This will generate an array of 1s whose size is equal to
    the batch size. Let''s revisit the different steps in this function:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate equally spaced numbers to the right and left of a random number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Concatenate both sets to get a series that is equal in length to the batch size
    we require. This is our first feature.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the second feature by taking the `sine()` function of the first feature
    we generated in *Step 2*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reshape both features so their size is equal to `(batch,1)` and then concatenate
    them along the columns. This will result in an array of shape `(batch,2)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the labels using the `np.ones((batch,1))` function. The label array
    will have a dimension of `(batch,1)`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The arguments that we will provide to the function are the random number and
    the batch size. One subtle change to note in *Step 1* is that since we want a
    series equal in length to the batch size, we will take equally spaced numbers
    to the left and right equal to half of the batch size (batch size /2). In this
    way, when we combine both series to the left and right, we get a series equal
    to the batch size we want.
  prefs: []
  type: TYPE_NORMAL
- en: Functions to Generate Fake Samples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The function(s) to generate fake samples will be the same as what we developed
    in *Exercise 7.02,* *Building a Generative Network*. However, we will have to
    divide this into three separate functions. The reason for dividing the code we
    implemented in *Exercise 7.02,* *Building a Generative Network* into three separate
    functions is for convenience and efficiency during the training process. Let''s
    take a look at these three functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`randn()` function. The output will be an array of size (`batch,input features`).
    The arguments to this function are `batch size` and `input feature size`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input feature size` and `output feature size`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy` to generate 0s called `np.zeros((batch,1))`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at the complete process for these three functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate fake inputs using *function 1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the generator model function (*function 2*) to predict a fake output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate labels, which is a series of 0s, using the `np.zeros()` function. This
    is part of *function 3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The arguments to the third function are `generator model`, `batch size`, and
    `input feature size`.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Discriminator Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The discriminator network will be built along the same lines as the generator
    network; that is, it will be created using the `Sequential()` class, the dense
    layer, and the activation and initialization functions. The only notable exception
    is that we will also have the optimization layer in the form of the `compile()`
    function. In the optimization layer, we will define the loss function, which in
    this case will be `binary_crossentropy` as the discriminator network is a binary
    classification network. For the optimizer, we will be using the `adam optimizer`
    as this is found to be very efficient and is a very popular choice.
  prefs: []
  type: TYPE_NORMAL
- en: Training the Discriminator Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have gone through all the components for implementing the discriminator
    network, let''s look at the steps involved in training the discriminator network:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a random number and then generate a batch of real samples and its labels
    using the function to generate real samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a batch of fake samples and its labels using the third function described
    to generate fake samples. The third function will use both the other functions
    to generate the fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the discriminator model using the `train_on_batch()` function with the
    batch of real samples and fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Steps *1* to *3* are repeated for the number of epochs we want the training
    to run for. This is done through a `for` loop over the number of epochs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At every intermediate step, we calculate the accuracy of the model on the fake
    samples and real samples using the `evaluate()` function. The accuracy of the
    model is printed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have seen the steps involved in implementing the discriminator network,
    we'll implement this in the next exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.03: Implementing the Discriminator Network'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will build the discriminator network and train the network
    on both the real samples and fake samples. Follow these steps to complete this
    exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and name it `Exercise 7.03`. Import the following
    library packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s define a function that will generate the features of our real data distribution.
    The return values of this function will be the real dataset and its label:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function we are defining here comprises code that was used to generate the
    `sine()` wave dataset in *Exercise 7.01*, *Generating a Data Distribution from
    a Known Function*. The inputs to this function are the random number and the batch
    size. Once the random number is provided, the series is generated with the same
    process we followed in *Exercise 7.01*, *Generating a Data Distribution from a
    Known Function*. We also generate the labels for the real data distribution, which
    will be 1\. The final return value will be the two features and the label.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s define a function called `fakeInputs` to generate inputs for the generator
    function (this is *function 1*, which we explained in the *Functions to Generate
    Fake Samples* section):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this function, we're generating random numbers in the format we want `([batch
    size , input features])`. This function generates the fake data that was sampled
    from the random distribution as the return value.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we''ll be defining a function that will return a generator model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the same model that we implemented in *Exercise 7.02,* *Building a Generative
    Network*. The return value for this function will be the generator model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following function will be used to create fake samples using the generator model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, we are implementing *function 3*, which we covered in
    the *Functions to Generate Fake Samples* section. As you can see, we call the
    generator model we defined in *Step 4* as input, along with the batch size and
    the input features. The return values for this function are the fake data that's
    generated, along with its label (`0`).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s define the parameters to be used in the functions we have just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s build the discriminator model using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The mode of construction for the discriminator model is similar to what we did
    in the generator network. Please note that the activation function for the last
    layer will be a sigmoid as we need a probability regarding whether the output
    is a real network or a fake network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the summary of the discriminator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.9: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.9: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the summary, we can see the size of the network based on the architecture
    we defined. We can see that the first three dense layers have 16 neurons each,
    which we defined in *Step 7* when we built the discriminator network. The final
    layer will only have one output as this is a sigmoid layer. This outputs the probability
    of whether the data distribution is real (`1`) or fake (`0`).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Invoke the generator model function to be used in the training process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.10: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.10: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You will notice that the architecture is the same as what we developed in *Exercise
    7.02,* *Building a Generative Network*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we need to define the number of epochs to train the network for, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s start training the discriminator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Here, we iterate the training of the model on both the real and fake data for
    20,000 epochs. The number of epochs is arrived at after some level of experimentation.
    We should try this out with different values for the number of epochs until we
    get some good accuracy figures. For every 4,000 epochs, we print the accuracy
    of the model on both the real dataset and the fake dataset. The printing frequency
    is arbitrary and is based on the number of plots you want to see to check the
    progress of the training process. After training, you will see that the discriminator
    achieves very good accuracy levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should get an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Since we are working with random values here, the output you get may vary from
    the one you see here. It will also vary with every run.
  prefs: []
  type: TYPE_NORMAL
- en: From the accuracy levels, we can see that the discriminator was very good (accuracy
    = 1) at identifying the real dataset initially and shows relatively poor accuracy
    levels for the fake dataset. After around 4,000 epochs, we can see that the discriminator
    has become good at identifying both the fake and real datasets as both the accuracies
    are near 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3fe02j3](https://packt.live/3fe02j3).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2ZYiYMG](https://packt.live/2ZYiYMG).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we defined different helper functions and also built the discriminator
    function. Finally, we trained the discriminator model on real data and fake data.
    At the end of the training process, we saw that the discriminator learned to discriminate
    between the real dataset and fake dataset really well. Having trained the discriminator
    network, it's now time to move on to the climax, which is building the GAN.
  prefs: []
  type: TYPE_NORMAL
- en: Process 4 – Implementing the GAN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have finally arrived at the moment we have been waiting for all this while.
    In the previous three processes, we have been progressively building all the building
    blocks for the GAN, such as the fake data generator, real data generator, generator
    network, and discriminator network. The GAN is, in fact, the integration of all
    these building blocks. The real game in the GAN is the process in which we integrate
    these components with each other. Let's address this right away.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating All the Building Blocks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When building the discriminator network, we generated real samples and fake
    samples and fed them to the discriminator during training. The training process
    made the discriminator "smart", which enabled it to correctly identify what is
    fake and what is real. In probability terms, this would mean that when the discriminator
    gets a fake sample, it will predict a probability close to "0" and when the sample
    is real, it will predict a probability close to "1". However, getting the discriminator
    to be smart is not our end objective. Our end objective is to get the generator
    model smart so that it starts generating examples that look like real samples
    and, in the process, fools the discriminator. This can be achieved by training
    the generator and updating its parameters (that is, the weights and bias) to enable
    it to generate samples that look like real samples. However, there is still a
    problem, because in the generator network, we did not include an optimizer step
    and therefore the generator network by itself cannot be trained. The way to get
    around this problem is by building another network (let''s call it **Ganmodel**)
    that connects the generator and discriminator in sequence and then include an
    optimizer function in the new network so that it goes and updates the parameters
    of its constituents when backpropagation happens. In terms of pseudocode, this
    network will look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: In this model, the generator model will generate fake samples that are fed into
    the discriminator model, which in turn will then generate a probability as to
    whether the example is fake or real. Based on the label of the example, it will
    have a certain loss that will be propagated through the discriminator to the generator,
    updating the parameters of both the models. In other words, based on the loss,
    the backpropagation algorithm will update each parameter based on the gradient
    of the parameter with respect to the loss. So, this will solve our problem of
    not having defined an optimizer function for the generator.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, there is one more catch to this network. Our discriminator network
    has already been trained and was made really smart when we trained the discriminator
    network separately. We don''t want to train the discriminator model again in this
    new network and make it smarter. This can be solved by defining that we don''t
    want to train the discriminator parameters in the network. With this new change,
    the **Ganmodel** would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: By making `Discmodel.trainable = False`, we're telling the network that we don't
    want to update the parameters of the discriminator network during backpropagation.
    So, the discriminator network will act as a conduit to pass on the error during
    the backpropagation stage to the generator network.
  prefs: []
  type: TYPE_NORMAL
- en: If you think all our problems have been solved, you are in for a rude awakening.
    We know that when the discriminator model is presented with a fake distribution,
    it will predict the probability to a value very close to `0`. We also know that
    the labels of the fake dataset are also `0`. So, in terms of loss, there would
    be very minimal loss being propagated back to the generator. With such a minuscule
    loss, the subsequent update to the parameters of the generator model will also
    be very minuscule. This will not enable the generator to generate samples that
    are like the real samples. The generator will only be able to learn if a large
    loss is generated and propagated to it so that its parameters are updated in the
    direction of real parameters. So, how do we get the loss to be high? What if,
    instead of defining the labels of the fake samples as `0`, we define them as `1`?
    If we do this, the discriminator model, as usual, will predict a probability close
    to 0 for fake examples. However, we now have a situation where the loss function
    would be large because the labels are 1\. When this large loss function gets propagated
    back to the generator network, the parameters will be updated significantly, which
    will enable it to be smarter. Subsequently, what will happen is the generator
    will start generating samples that look more like the real samples, and they would
    meet our objective.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concept can be explained with the following figure. Here, we can see that
    at the initial level of training, the probability for the fake data is close to
    zero (`0.01`) and the label that we''ve given for the fake data is `1`. This will
    ensure that we get a large loss that gets backpropagated to the generator network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11: GAN process'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.11: GAN process'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen the dynamics of the GAN model, let's tie all the pieces
    together to define the process we will follow in order to build the GAN.
  prefs: []
  type: TYPE_NORMAL
- en: Process for Building the GAN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The complete process for the GAN is all about tying together the pieces we
    have built into a logical order. We will use all the functions we built when we
    defined the discriminator function. In addition, we will also make new functions;
    for instance, a function for the discriminator network and another function for
    the GAN model. All these functions will be called at specific points to make the
    GAN model. The end-to-end process will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the function to generate a real data distribution. This function is the
    same function we developed in *Exercise 7.03*, *Implementing the Discriminator
    Network* for the discriminator network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the three functions that were created for generating fake samples. These
    are a function for generating fake inputs, a function for the generator network,
    and a function for generating fake samples and labels. All these functions are
    the same as the ones we developed in *Exercise 7.03*, *Implementing the Discriminator
    Network* for the discriminator network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new function for the discriminator network, just like we created in
    *Exercise 7.03*, *Implementing the Discriminator Network*. This function will
    have the output features (2) as its input as both the real dataset and fake dataset
    have two features. This function will return the discriminator model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new function for the GAN model as per the pseudocode we developed in
    the previous section (*Process 4 – Building a GAN*). This function will have the
    generator model and the discriminator model as its inputs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start the training process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Training Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The training process here is similar to the process we implemented in *Exercise
    7.03*, *Implementing the Discriminator Network* for the discriminator network.
    The steps for the training process are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a random number and then generate a batch of real samples and its labels
    using the function to generate real samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a batch of fake samples and its labels using the third function we
    described regarding the functions for generating fake samples. The third function
    will use both the other functions to generate the fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the discriminator model using the `train_on_batch()` function using the
    batch of real samples and fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate another batch of fake inputs to train the GAN model. These fake samples
    are generated using *function 1* in the fake sample generation process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the labels for the fake samples that are intended to fool the discriminator.
    These labels will be 1s instead of 0s.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the GAN model using the `train_on_batch()` function using the fake samples
    and its labels, as described in *Steps 4* and *5*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Steps 1* to *6* are repeated for the number of epochs we want the training
    to run for. This is done through a `for` loop over the number of epochs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At every intermediate step, we calculate the accuracy of the model on the fake
    samples and real samples using the `evaluate()` function. The accuracy of the
    model is also printed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also generate output plots at certain epochs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have seen the complete process behind training a GAN, let's dive
    into *Exercise 7.04*, *Implementing the GAN*, which implements this process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.04: Implementing the GAN'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will build and train the GAN by implementing the process
    we discussed in the previous section. Follow these steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and name it `Exercise 7.04`. Import the following
    library packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create a function to generate the real samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function we're creating here follows the same process we implemented in
    *Exercise 7.01*, *Generating a Data Distribution from a Known Function*. The inputs
    to this function are the random number and the batch size. We get the real data
    distribution with both our features, along with the label for the real data distribution
    as return values, from this function. The return values from this function are
    the real dataset and its label.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here, let''s define the function to generate inputs for the generator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function generates the fake data that was sampled from the random distribution
    as output.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s go ahead and define the function for building the generator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the same function we built in *Exercise 7.02,* *Building a Generative
    Network*. This function returns the generator model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this step, we will define the function that will create fake samples using
    the generator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function we are defining here takes the random data distribution as input
    (to the generator network we defined in the previous step) and generates the fake
    distribution. The label for the fake distribution, which is 0, is also generated
    within the function. In other words, the outputs from this function are the fake
    dataset and its label.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s define the parameters that we will be using within the different functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let''s build the discriminator model as a function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The network architecture will be like the one we developed in *Exercise 7.03*,
    *Implementing the Discriminator Network*. This function will return the discriminator.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the summary of the discriminator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.12: Discriminator model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.12: Discriminator model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This output is the same as the one we received for the network we implemented
    in *Exercise 7.03*, *Implementing the Discriminator Network*, where we defined
    the discriminator function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Invoke the generator model function for use in the training process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.13: Generator model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.13: Generator model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You will notice that the architecture is the same as what we developed in *Exercise
    7.02,* *Building a Generative Network*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Before we begin training, let''s visualize the fake data distribution. For
    this, we generate the fake dataset using the `fakedataGenerator()` function and
    then visualize it using `pyplot`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the following. Please note that data generation
    is stochastic in nature (random) and that you might not get the same plot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.14: Plot from the fake input distribution'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.14: Plot from the fake input distribution'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the preceding plot, you can see that the data distribution is quite random.
    We need to convert this random data into a form similar to the sine wave, which
    was our real data distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s define the GAN model as a function. This function is similar to
    the pseudocode we developed in *Process 4*, where we defined the GAN. The GAN
    is a wrapper model around the generator model and the discriminator model. Please
    note that we define the discriminator model as **not trainable** within this function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function will return the GAN model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s invoke the GAN function. Please note that the inputs to the GAN
    model are the previously defined generator model and the discriminator model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the summary of the GAN model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.15: Summary of the GAN model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.15: Summary of the GAN model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that the parameters of each layer of the GAN model are equivalent to the
    parameters of the generator and discriminator models. The GAN model is just a
    wrapper around these two models we defined earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s define the number of epochs to train the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we start the process of training the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: It needs to be noted here that the training of the discriminator model with
    the fake and real samples and the training of the GAN model happens concurrently.
    The only difference is that training the GAN model proceeds without updating the
    parameters of the discriminator model. The other thing to note is that, inside
    the GAN, the labels for the fake samples would be 1\. This is to generate large
    loss terms that will be backpropagated through the discriminator network to update
    the generator parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please note that the third line of code from the bottom (`filename = ''GAN_Training_Plot%03d.png''
    % (i)`) saves a plot once every 2,000 epochs. The plots will be saved in the same
    folder that your Jupyter Notebook is located in. You can also specify the path
    you want to save the plots at. This can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`filename = ''D:/Project/GAN_Training_Plot%03d.png'' % (i)`'
  prefs: []
  type: TYPE_NORMAL
- en: You can access the plots that were generated through this exercise at [https://packt.live/2W1FjaI](https://packt.live/2W1FjaI).
  prefs: []
  type: TYPE_NORMAL
- en: 'You should get an output similar to the one shown here. Since the predictions
    are stochastic in nature (that is to say, they''re random), you might not get
    the same plots shown in this example. Your values may vary; however, they will
    be similar to what''s shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'From the preceding output, you can see that the real dataset accuracy levels
    are progressively going down and that the fake dataset''s accuracy is going up.
    In ideal situations, the accuracy of the discriminator network has to be around
    the 0.5 level, which indicates that the discriminator is really confused as to
    whether a sample is fake or real. Now, let''s look at some of the plots that were
    generated at different epoch levels as to how the data points are converging to
    look like the real function. The following plot is the distribution of the random
    data point before it was fed into the GAN (*Step 10*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16: Plot from the fake input distribution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.16: Plot from the fake input distribution'
  prefs: []
  type: TYPE_NORMAL
- en: Notice the distribution of the data where the data points are mostly centered
    on a mean of 0\. This is because the random points are generated from a normal
    distribution that has a mean of 0 and a standard deviation of 1\. Now, using the
    raw data, let's study the progression of the fake dataset as the generator is
    trained.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3iIJHVS](https://packt.live/3iIJHVS).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3gF5DPW](https://packt.live/3gF5DPW).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: The three plots shown below map the progression of the fake data distribution
    vis-a-vis the real data distribution. The *x* axis represents feature 1, while
    the *y* axis represents feature 2\. In the plots, the red points pertain to the
    data from the real distribution and the blue plots pertain to the data from the
    fake distribution. From the following plot, we can see that at epoch `2000`, the
    fake plots are within the domain; however, they are not aligned to the shape of
    the real data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.17: Plot of fake data distribution vis-à-vis the real data distribution
    at epoch 2000'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.17: Plot of fake data distribution vis-à-vis the real data distribution
    at epoch 2000'
  prefs: []
  type: TYPE_NORMAL
- en: 'By epoch `10000`, which is when the generator has been trained almost halfway,
    there is a consolidation nearer to the real data distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.18: Plot of fake data distribution vis-à-vis the real data distribution
    at epoch 10000'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.18: Plot of fake data distribution vis-à-vis the real data distribution
    at epoch 10000'
  prefs: []
  type: TYPE_NORMAL
- en: By epoch `18000`, we can see that most of the points are aligned to the real
    data distribution, which is an indicator that the GAN has been trained reasonably
    well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.19: Plot of fake data distribution vis-à-vis the real data distribution
    at epoch 18000'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.19: Plot of fake data distribution vis-à-vis the real data distribution
    at epoch 18000'
  prefs: []
  type: TYPE_NORMAL
- en: However, you can see that the data points after `x = 4` have a lot more noise
    than the ones on the left. One reason for this could be the random data distribution
    we generated before we trained the *GAN(Step 10)* contains data that is distributed
    predominantly between `-2` and `4`. Such data is aligning well to the target distribution
    (sine wave) within the same range and is a little wobbly around the target distribution
    to the right of `x = 4`. However, you should also note that getting 100% alignment
    to the target distribution is an extremely difficult proposition that would involve
    experimenting with different model architectures and more experiments. We encourage
    you to experiment and be innovative with different components within the architecture
    to get the distribution more aligned.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The results we have gotten in the above exercise will vary every time we run
    the code.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to the end of the complete process of progressively building
    a GAN. Through a series of exercises, we have learned what a GAN is, its constituents,
    and how all of them are tied together to train a GAN. We will take what we've
    learned forward and develop more advanced GANs using different datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Convolutional GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, where we implemented a GAN, we made use of an architecture
    based on the **Multi-Layer Perceptron** (**MLP**). As you may recall from the
    previous chapters, MLPs have fully connected layers. This implies that all the
    neurons in each layer have connections to all the neurons of the subsequent layer.
    For this reason, MLPs are also called fully connected layers. The GAN that we
    developed in the previous section can also be called a **Fully Connected GAN**
    (**FCGAN**). In this section, we will learn about another architecture called
    **Deep Convolutional GANs** (**DCGANS**). As the name implies, this is based on
    the **Convolutional Neural Network** (**CNN**) architecture that you learned about
    in *Chapter 4*, *Deep Learning for Text – Embeddings*. Let's revisit some of the
    building blocks of DCGANs.
  prefs: []
  type: TYPE_NORMAL
- en: Building Blocks of DCGANs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most of the building blocks of DCGANs are similar to what you learned about
    when you were introduced to CNNs in *Chapter 3*, *Image Classification with Convolutional
    Neural Networks*. Let's revisit some of the important ones.
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional Layers**'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you learned in *Chapter 3*, *Image Classification with Convolutional Neural
    Networks*, convolutional operations involve filters or kernels moving over the
    input image to generate a set of feature maps. The convolutional layer can be
    implemented in Keras using the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The above code block is solely meant to explain how the code is implemented.
    It may not result in a desirable output when run in its current form. For now,
    try to understand the syntax completely; we will be putting this code into practice
    soon.
  prefs: []
  type: TYPE_NORMAL
- en: In the first part of the preceding code, the `Sequential()` class is imported
    from the `tensorflow.keras` module. It is then instantiated to a variable model
    in the second line of code. The convolutional layer is added to the `Sequential()`
    class by defining the number of filters, kernel size, the required strides, and
    the padding indicators. In the preceding line of code, 64 indicates the number
    of feature maps. A `kernel_size` value of `(5,5)` indicates the size of the filters
    that will be convolved over the input image to generate the feature maps. The
    `strides` value of `(2,2)` indicates that the filters will move two cells at a
    time, both horizontally and vertically, in the process of generating the feature
    maps. `padding = 'same'` indicates that we want the output of the convolutional
    operation to be of the same size as the input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: The choice of architecture to use, such as the number of filters, size of kernels,
    stride, and more, is an art and can be mastered with lots of experimentation on
    the domain.
  prefs: []
  type: TYPE_NORMAL
- en: '**Activation Functions**'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous section, we implemented some activation functions such as ReLU,
    ELU, SELU, and linear. In this section, we will be introduced to another activation
    function called LeakyReLU. LeakyReLU is another variation of ReLU. Unlike ReLU,
    which doesn't allow any negative values, LeakyReLU allows a small non-zero gradient
    that is controlled by a factor, `α`. This factor, `α`, controls the slope of the
    gradient for the negative values.
  prefs: []
  type: TYPE_NORMAL
- en: '**Upsampling Operation**'
  prefs: []
  type: TYPE_NORMAL
- en: In a CNN, an image gets down-sampled to lower dimensions by operations such
    as max pooling and convolutional operations. However, in a GAN, the dynamics of
    a generator network operate in a direction opposite to the convolutional operation;
    that is, from lower or coarser dimensions, we have to transform an image to a
    denser form (that is, with more dimensions). One way to do that is through an
    operation called `UpSampling`. In this operation, the input dimensions are doubled.
    Let's understand this operation in more detail using a small example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can be used to import the required library files. The function
    that''s specific for `UpSampling` is `UpSampling2D` from `keras.layers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code creates a simple model that takes an array of shape `(3,3,1)`
    as input in the `UpSampling` layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.20: Model summary for UpSampling2D'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.20: Model summary for UpSampling2D'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the summary, we can see that the output has been doubled to `(None, 6,6,1)`,
    wherein the middle two dimensions have been doubled. To understand what change
    this makes to an array of shape `(3,3,1)`, we will need to define an array of
    size `(3,3)`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The array we''ve defined has only two dimensions. However, the input to the
    model we defined needs four dimensions, where the dimensions are in the order
    (`examples, width, height, channels`). We can create the additional dimensions
    using the `reshape()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the following code to make some predictions with the `UpSampling`
    model we created and observe the dimensions of the resultant array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.21: Output shape of the unsampled model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.21: Output shape of the unsampled model'
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding output, we can see how the resultant array has been transformed.
    As we can see, each of the inputs has been doubled to get the resultant array.
    We will be using the `UpSampling` method in *Exercise 7.05*, *Implementing the DCGAN*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transpose Convolution**'
  prefs: []
  type: TYPE_NORMAL
- en: Transpose convolution is different from the `UpSampling` method we just saw.
    `UpSampling` was more or less a naïve doubling of the input values. However, transpose
    convolutions have weights that are learned during the training phase. Transpose
    convolutions work similarly to convolutional operations but in reverse. Instead
    of reducing the dimensions, transpose convolutions expand the dimensions of the
    input through a combination of the kernel size and its strides. As learned in
    *Chapter 3*, *Image Processing with Convolutional Neural Networks*, strides are
    the step sizes where we convolve or move the filters over the image to get an
    output. We also control the output of transpose convolutions with the `padding
    = 'same'` parameter, just like we do in convolutional operations.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at a code example of how transpose convolutions work.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to import the necessary library files. The function that''s
    specific to transpose convolution operations is `Conv2DTranspose` from `keras.layers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create a simple model that takes an image of shape `(3,3,1)` in
    the transpose convolution layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'In the transpose convolution layer, the first parameter `(1)` is the number
    of filters. The second one `(4,4)` is the size of kernel and the last one `(2,2)`
    is the strides. With `padding = ''same''`, the output will not be dependent on
    the size of the kernel but will be multiples of the stride and the input dimension.
    The summary that will be generated by the preceding code will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.22: Summary of the model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.22: Summary of the model'
  prefs: []
  type: TYPE_NORMAL
- en: From the summary, we can see that the output has been doubled to `(None, 6,6,1)`,
    which would work like the multiplying the strides by the input dimensions (None,
    2 × 3, 2 × 3, 1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see what changes occur to a real array of shape `(1,3,3,1)`. Remember
    that we also created this array earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'To generate the transposed array, we need to make some predictions using the
    transpose convolution model we created. By printing the shape, we can also observe
    the dimensions of the resultant array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.23: Transformed array'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.23: Transformed array'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The output you get may vary from the one we have shown above.
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding output, we can see how the resultant array has been transformed.
    The values in the generated array are the end result of the dynamics between the
    weights of the kernel on the input image.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen some of the basic building blocks of a DCGAN, we'll go
    ahead and build it in the next exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Generating Handwritten Images Using DCGANs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will try to generate a data distribution similar to the data pertaining
    to handwritten digits using a DCGAN. We will be using the MNIST handwritten digits
    dataset as the real dataset. This dataset has a training set of 60,000 examples,
    all of which are handwritten images of digits from 0 to 9\. The implementation
    process for this GAN will be similar to *Exercise 7.04*, *Implementing the GAN*,
    where we implemented the GAN for the known function. Let's look at the steps we
    will follow for this problem statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll need to define the function that will be used to generate a real
    data distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The preceding function will generate the real data distribution from the MNIST
    dataset. The train and test sets can be generated using the `mnist.load_data()`
    function. Using this function, we get all the related datasets in the form `(X_train,y_train)`,`(X_test,y_test)`.
    Since we only require the `X_train` data, we do not store the other datasets in
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The MNIST data is two-dimensional; that is, (width, height). Since we require
    three-dimensional data (width, height, channel) for convolutional operations,
    we need to create the third dimension as 1 using the `np.newaxis` function. Please
    note that the first dimensions will be the number of examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The other process is to generate batches of the training data. To generate
    batches of data, we sample some integers between 0 and the number of examples
    in the training set. The sample''s size will be equal to the batch size we want.
    This is implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: We will only be returning the `X` variable. The labels that are batches of 1s
    will be separately generated during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we need to define the three functions that will be used for generating
    fake samples. These are a function for generating fake inputs, a function for
    the generator network, and a function for generating fake samples and labels.
    Most of these functions are the same as what we developed in *Exercise 7.04*,
    *Implementing the GAN*. The generator model will be constructed as a convolutional
    model with intermittent use of **Up-Sampling/Converse2Dtranspose** operations.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to create a new function for the discriminator network. This discriminator
    model will, again, be a convolutional model with the final layer as a sigmoid
    layer where we output a probability, that is, the probability of an image being
    real or fake. The input dimensions to the discriminator model will be the dimensions
    of the images generated from MNIST and the fake images, which will be (batch size,
    28,28,1).
  prefs: []
  type: TYPE_NORMAL
- en: The GAN model will be the same as the one we created in *Exercise 7.04*, *Implementing
    the GAN.* This function will have the generator model and the discriminator model
    as its inputs.
  prefs: []
  type: TYPE_NORMAL
- en: The Training Process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The training process will be similar to the process we implemented in *Exercise
    7.04,* *Implementing the GAN*. The steps for the training process are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a batch of MNIST data using the function to generate a real dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a batch of fake samples using *function 3* described in the functions
    for generating fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Concatenate the real samples and fake samples into one DataFrame. This will
    be the input variable for the discriminator model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The labels will be a series of 1s and 0s corresponding to the real data and
    fake data that was concatenated earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the discriminator model using the `train_on_batch()` function using the
    `X` variable and the labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate another batch of fake inputs for training the GAN model. These fake
    samples are generated using *function 1* in the fake sample generation process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the labels for the fake samples that are intended to fool the discriminator.
    These labels will be 1s instead of 0s.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the GAN model using the `train_on_batch()` function using the fake samples
    and its labels, as described in *Steps 6* and *7*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Steps 1* to *8* are repeated for the number of epochs we want the training
    to run for. This is done through a `for` loop over the number of epochs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At every intermediate step, we calculate the accuracy of the discriminator model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also generate output plots at certain epochs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have seen the complete process behind training a DCGAN, let's dive
    into the next exercise, which implements this process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.05: Implementing the DCGAN'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will build and train the DCGAN on the MNIST dataset. We
    will use the MNIST dataset as the real data distribution. We will then generate
    fake data from a random distribution. After that, we will train the GAN to generate
    data that is similar to the MNIST dataset''s. Follow these steps to complete this
    exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and name it `Exercise 7.05`. Import the following
    library packages and the MNIST dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the function that will be used to generate real datasets. The real dataset
    is generated from the MNIST data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The return value from this function is the batch of MNIST data. Note that we
    normalize the input data by subtracting `127.5`, which is half the maximum pixel
    values (255), and divide by the same amount. This will help with converging the
    solution faster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s generate a set of images from the MNIST dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let''s visualize the plots using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.24: Visualized data – digits from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.24: Visualized data – digits from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the output, we can see the visualization of some of the digits. We can
    see that the image is centrally positioned within a white background.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The digits that are visualized when you run the code will differ from the ones
    we've shown here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the function to generate inputs for the generator network. The fake
    data will be random data points generated from a uniform distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s define the function for building the generator network. Building the
    generator network is similar to building any CNN network. In this generator network,
    we will use the `UpSampling` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the model, we can see the progressive use of the transpose convolution operation.
    The initial input has the dimensions of 100\. This is progressively increased
    to the desired image size of batch size x 28 x 28 through a series of transpose
    convolution operations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we define the function to create fake samples. In this function, we only
    return the `X` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The return value from this function is the fake dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the parameters that we will use, along with the summary of the generator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.25 Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 7.25 Summary of the model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'From the summary, please note how the dimension of the input changes with each
    transpose convolution operation. Finally, we get an output that is equal in dimension
    to the real data set: `(None,28 ,28,1)`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s use the generator function to generate a fake sample before training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s plot the generated fake sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the one shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.26: Plot of the fake sample image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.26: Plot of the fake sample image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the plot of the fake sample before training. After training, we want
    samples like these to look like the MNIST samples we visualized earlier in this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s build the discriminator model as a function. The network will be
    a CNN network like the one you learned about in *Chapter 3*, *Image Classification
    with Convolutional Neural Networks*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the discriminator network, we have included all the necessary layers, such
    as the convolutional operations and LeakyReLU activations. Please note that the
    last layer is a sigmoid layer as we want the output as a probability of the sample
    to be real (1) or fake (0).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the summary of the discriminator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.27: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.27: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding screenshot shows the summary of the model architecture. This is
    based on the different layers we implemented using the `Sequential` class. For
    example, we can see that the first layer has 32 filter maps, the second layer
    has 64 filter maps, and the last layer has one output that corresponds to the
    sigmoid activation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, define the GAN model as a function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The structure of the GAN model is similar to the one we developed in *Exercise
    7.04*, *Implementing the GAN*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, it''s time to invoke the GAN function. Please note that the inputs to
    the GAN model are the previously defined generator and discriminator models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From the preceding code, we can see that the inputs to the GAN model are the
    previously defined generator and discriminator models. You should get the following
    output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.28: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.28: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Please note that the parameters of each layer of the GAN model are equivalent
    to the parameters of the generator and discriminator models. The GAN model is
    just a wrapper around the models we defined earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the number of epochs to train the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s train the GAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the preceding code, we can see that the training of the discriminator model
    with the fake and real samples and the training of the GAN model happens concurrently.
    The only difference is the training of the GAN model proceeds without updating
    the parameters of the discriminator model. The other thing to note is that, inside
    the GAN, the labels for the fake samples would be 1 to generate large loss terms
    that will be backpropagated through the discriminator network to update the generator
    parameters. We also display the predicted probability of the GAN for every 10
    epochs. When calculating the probability, we combine a sample of real data and
    fake data and then take the mean of the predicted probability. We also save a
    copy of the generated image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The output for the preceding code may not be an exact match with what you get
    when you run the code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the predicted probability of the test data, we can see that the values
    are hovering around the `.55` mark. This is an indication that the discriminator
    is confused about whether the image is fake or real. If the discriminator were
    sure that an image was real, it would predict a probability close to 1, while
    it would predict a probability close to 0 if it were sure that the image was fake.
    In our case, we can see that the probability is around the .55 mark, which indicates
    that the generator is learning to generate images similar to the real images.
    This has confused the discriminator. *A value close to 50% accuracy for the discriminator
    is the desired value.*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s generate fake images after the training process and visualize them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.29: Predicted image post training'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.29: Predicted image post training'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the generated images from the trained generator model closely
    resonate with the real handwritten digits.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2ZPg8cJ](https://packt.live/2ZPg8cJ).
  prefs: []
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we developed a GAN to generate distributions similar to MNIST
    handwritten digits. In the section that follows, we will analyze the images that
    were generated at each epoch during this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis of Sample Plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s look at the output sample plots from the previous exercise to see
    what the generated images look like. By completing the previous exercise, these
    should have been saved in the same path where your Jupyter Notebook is located,
    under a subfolder called `handwritten`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.30: Sample plot after 10 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.30: Sample plot after 10 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding images are those that were generated after 10 iterations. We
    can see that these images look more like random noise. However, we can also see
    that there are traces of white patches forming within the image, which indicates
    the GAN is learning some of the features of the real image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 7.31: Sample plot after 500 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.31: Sample plot after 500 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding images are the plots after 500 iterations. From these images,
    we can see some semblance of the real image. We can see that the white background
    of the real images is being formed. We can also see the distribution getting aggregated
    at the center of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 7.32: Sample plot after 2,000 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_32.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.32: Sample plot after 2,000 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding image is after 2,000 iterations. We can see that many digits
    have started to form; for example, 8, 5 ,3 ,9 ,4, 7, 0, and so on. We can also
    see that the dark shades of the images have started to become more pronounced.
    Now, let''s look at the images that were generated during the last iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.33: Sample plot after 5,000 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_33.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.33: Sample plot after 5,000 iterations'
  prefs: []
  type: TYPE_NORMAL
- en: A question to ask at this stage is, are these images perfect? Absolutely not.
    Would running the training for more epochs improve the results further? Not necessarily.
    Getting those perfect images would entail hours of training and experimentation
    with different model architectures. You can take this as a challenge to improve
    the output through your choices of architecture and the parameters within the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: GANs are a really active area of research and the possibilities they are opening
    up point to the direction of computers slowly becoming creative. However, there
    are some common problems when implementing GANs. Let's look at some of them.
  prefs: []
  type: TYPE_NORMAL
- en: Common Problems with GANs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GANs are difficult networks to train and stabilize. There are different failure
    modes for GANs. Let's get a perspective of some of the common failure modes.
  prefs: []
  type: TYPE_NORMAL
- en: Mode Collapse
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A very common failure mode of GANs, especially on multi-modal data, is a situation
    called **mode collapse**. This refers to a situation where the generator learns
    only some specific variety of the distribution within the data. For example, in
    an MNIST data distribution, if the GAN generates only one particular digit (say,
    5) after training, then this is a case of mode collapse.
  prefs: []
  type: TYPE_NORMAL
- en: One way to combat mode collapse is to group data according to the different
    classes and train the discriminator accordingly. This will give the discriminator
    the ability to identify different modes that are present in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Convergence Failure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another prominent failure mode in GANs is convergence failure. In this failure
    mode, the network fails to converge with the loss as it never settles during the
    training phase. Some methods that researchers have used to get over this problem
    include adding noise to discriminatory networks and penalizing discriminator weights
    through regularization techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Notwithstanding the numerous challenges inherent in training and building GANs,
    it still remains one of the most active areas of research within the deep learning
    community. The promises and the applications that are made possible by GANs are
    what make this area one of the most sought-after domains in deep learning. Now
    that we have laid some of the foundations for GANs, let's use what we've learned
    to build a GAN for a different dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 7.01: Implementing a DCGAN for the MNIST Fashion Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this activity, you will implement a DCGAN to generate images similar to
    the ones found in the MNIST fashion dataset. The MNIST fashion dataset is similar
    to the handwritten digital images dataset that you implemented in *Exercise 7.05*,
    *Implementing the DCGAN*. This dataset consists of grayscale images of 10 different
    fashion accessories and comprises 60,000 training samples. The following is a
    sample of the images included in this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.34: Sample of the MNIST fashion dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_34.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.34: Sample of the MNIST fashion dataset'
  prefs: []
  type: TYPE_NORMAL
- en: The objective of this activity is to build a GAN and generate images similar
    to the fashion dataset. The high-level steps for this activity will be similar
    to *Exercise 7.05*, *Implementing the DCGAN*, where you implemented a DCGAN for
    handwritten digits. You will be completing this activity in two parts, first by
    creating the relevant functions and then by training the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Generating Key Functions**: Here, you will be creating the required functions,
    such as the generator function and the discriminator function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the function that will generate a real data distribution. This function
    has to generate the real data distribution from the MNIST fashion dataset. The
    fashion dataset can be imported using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The training set can be generated using the `fashion_mnist.load_data()` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Note:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Alternatively, you can download the dataset from [https://packt.live/2X4xeCL](https://packt.live/2X4xeCL).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Define the three functions that will be used to generate fake samples; that
    is, the function for generating fake inputs, the function for the generator network,
    and the function for generating fake samples and labels. Use *Converse2Dtranspose*
    operations within the generator function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new function for the discriminator network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the GAN model. You can take cues from *Exercise 7.05*, *Implementing
    the DCGAN*, on how to do this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The Training Process**: You will follow a process similar to the one in *Exercise
    7.05*, *Implementing the DCGAN*:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a batch of MNIST data using the function for generating a real dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a batch of fake samples using the third function described in the functions
    for generating fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Concatenate the real samples and fake samples into one DataFrame and generate
    their labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the discriminator model using the `train_on_batch()` function using the
    `X` variable and the labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate another batch of fake inputs for training the GAN model, along with
    their labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the GAN model using the `train_on_batch()` function using the fake samples
    and their labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the training for around 5,000 epochs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At every intermediate step, calculate the accuracy of the discriminator model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The discriminator probabilities you''ll get should be around `0.5`. The expected
    output will be a generated image that looks similar to the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.35: Expected output for this activity'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_07_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.35: Expected output for this activity'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: The detailed steps for this activity, along with the solutions and additional
    commentary, are presented on page 426.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have come a long way from being introduced to one of the most promising
    areas in deep learning. Let's revisit some of the concepts that we learned about
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We started this chapter by understanding what GANs are and their major applications.
    We then went on to understand the various building blocks of GANs, such as the
    real datasets, fake datasets, the discriminator operation, the generator operation,
    and the GAN operation.
  prefs: []
  type: TYPE_NORMAL
- en: We executed a problem statement to progressively build a **fully connected GAN**
    (**FCGAN**) to solve a real function. In the process of building the GAN, we also
    implemented exercises for creating real datasets, creating fake datasets, creating
    a generator network, creating a discriminator network, and finally combining all
    these individual components to create the GAN. We visualized the different plots
    and understood how the generated data distribution mimicked the real data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we understood the concept of DCGANs. We also visited some
    of the unique concepts in DCGANs such as upsampling and transpose convolutions.
    We implemented a GAN for the MNIST digital handwritten images and visualized the
    fake images we generated using a DCGAN. Finally, we also implemented a DCGAN for
    the MNIST fashion dataset in an activity.
  prefs: []
  type: TYPE_NORMAL
- en: Having laid the foundations, the next question is, where do we go from here?
    GANs are a large area by itself and there's quite a lot of buzz around it these
    days. To start with, it would be good to tweak the models you have already learned
    by tweaking the architecture and activation functions and trying out other parameters
    such as batch normalization. After playing around with different variations of
    the current models, it will be time to explore other networks such as the **Least
    Squares GAN** (**LSGAN**) and **Wasserstein GAN** (**WGAN**). Then, there is this
    large playing field of conditional GANs such as the **Conditional GAN** (**cGan**),
    InfoGAN, **Auxiliary Classifier GAN** (**AC-GAN**), and **Semi-Supervised GAN**
    (**SGAN**). Once you've done this, you'll have set the stage for advanced topics
    such as CycleGAN, BigGAN, and StyleGAN.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also brings down the curtain on the amazing journey you've made
    throughout this book. First, you were introduced to what deep learning is and
    the different use cases that are possible with deep learning. Subsequently, you
    learned the basics of neural networks, which are the foundations of deep learning.
    From there, you went on to learn about advanced techniques such as CNNs, which
    are the workhorses for use cases such as image recognition. Along with that, you
    learned about recurrent neural networks, which can be used for sequence data.
    Finally, you were introduced to GANs, a class of networks that's making lots of
    waves within the domain. Having equipped yourself with this set of tools now is
    the time to apply your learning to your domain. The possibilities and opportunities
    are endless. All we need to do is consolidate our current learning and move ahead
    step by step. I wish you all the best on your journey in scaling new peaks in
    the deep learning domain.
  prefs: []
  type: TYPE_NORMAL
