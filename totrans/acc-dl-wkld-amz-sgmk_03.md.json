["```py\n    conda create -n sagemaker python=3.9\n    ```", "```py\n    conda activate sagemaker\n    pip install boto3 awscli sagemaker\n    ```", "```py\n    aws configure\n    ```", "```py\n    conda install -c conda-forge jupyterlabpython -m ipykernel install --user --name sagemaker\n    ```", "```py\n    jupyter lab\n    ```", "```py\n    import sagemaker, boto3\n    from sagemaker import get_execution_role\n    session = sagemaker.Session()\n    account = boto3.client('sts').get_caller_identity().get('Account')\n    role = f\"arn:aws:iam::{account}:role/service-role/AmazonSageMaker-ExecutionRole-<YOUR_ROLE_ID>\" \n    ```", "```py\n    from sagemaker.pytorch import PyTorch\n    import os\n    pytorch_estimator = PyTorch(\n                            session=session,\n                            entry_point=f'{os.getcwd()}/sources/cifar10.py',\n                            role=role,\n                            instance_type=\"ml.m4.xlarge\",\n                            instance_count=1,\n                            job_name=\"test\",\n                            framework_version=\"1.9.0\",\n                            py_version=\"py38\",\n                            hyperparameters={\n                                \"epochs\": 1,\n                                \"batch-size\": 16\n                                }\n                            )\n    pytorch_estimator.fit()\n    ```", "```py\n    pytorch_estimator.latest_training_job.describe()\n    ```", "```py\n    pip install 'sagemaker[local]' –upgrade\n    ```", "```py\n    import boto3\n    from sagemaker.local import LocalSession\n    sagemaker_local_session = LocalSession()\n    sagemaker_local_session.config = {'local': {'local_code': True}}\n    account = boto3.client('sts').get_caller_identity().get('Account')\n    role = f\"arn:aws:iam::{account}:role/service-role/AmazonSageMaker-ExecutionRole-<YOUR_ROLE_ID>\" \n    ```", "```py\n    ! aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n    ```", "```py\n    import subprocess\n    instance_type = \"local\"\n    try:\n        if subprocess.call(\"nvidia-smi\") == 0:\n            instance_type = \"local_gpu\"\n    except:\n        print(\"GPU device with CUDA is not available\")\n    print(\"Instance type = \" + instance_type)\n    ```", "```py\n    from sagemaker.pytorch import PyTorch\n    import os\n    # Configure an MXNet Estimator (no training happens yet)\n    pytorch_estimator = PyTorch(\n                            session=sagemaker_local_session,\n                            entry_point=f'{os.getcwd()}/sources/cifar10.py',\n                            role=role,\n                            instance_type=instance_type,\n                            instance_count=1,\n                            job_name=\"test\",\n                            framework_version=\"1.9.0\",\n                            py_version=\"py38\",\n                            hyperparameters={\n                                \"epochs\": 1,\n                                \"batch-size\": 16\n                                }\n                            )\n    pytorch_estimator.fit()\n    ```", "```py\n    pytorch_estimator.deploy(initial_instance_count=1, instance_type=instance_type)\n    ```", "```py\n    import requests\n    import json \n    payload = trainset[0][0].numpy().tobytes()\n    url = 'http://127.0.0.1:8080/invocations'\n    content_type = 'application/x-npy'\n    accept_type = \"application/json\"\n    headers = {'content-type': content_type, 'accept': accept_type}\n    response = requests.post(url, data=payload, headers=headers)\n    print(json.loads(response.content)[0])\n    ```"]