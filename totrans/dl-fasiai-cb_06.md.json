["```py\n    path = untar_data(URLs.CIFAR)\n    ```", "```py\n    path.ls()\n    ```", "```py\n    dls = ImageDataLoaders.from_folder(path, train='train', valid='test')\n    ```", "```py\n    dls.train.show_batch(max_n=4, nrows=1)\n    ```", "```py\n    (path/'train').ls()\n    ```", "```py\n    (path/'train/dog').ls()\n    ```", "```py\n    test and train directories have subdirectories for each of the 10 categories of the dataset:\n\n    ```", "```py\n\n    ```", "```py\n    img_files = get_image_files(path)\n    img = PILImage.create(img_files[100])\n    img\n    ```", "```py\n    img = PILImage.create(img_files[3000])\n    img\n    ```", "```py\n    learn = cnn_learner(dls, resnet18, \n                        loss_func=LabelSmoothingCrossEntropy(), \n                        metrics=accuracy))\n    ```", "```py\n    learn.fine_tune(5)\n    ```", "```py\n    img_test_files = get_image_files(path/\"test\")\n    img2 = PILImage.create(img_test_files[700])\n    img2\n    ```", "```py\n    img3 = PILImage.create(img_test_files[8000])\n    img3\n    ```", "```py\n    learn.predict(img2)\n    ```", "```py\n    learn.predict(img3)\n    ```", "```py\n    learn.path = Path('/notebooks/temp')\n    learn.export('cifar_apr20_2021.pkl') \n    ```", "```py\ndog_files = get_image_files(path/\"train/dog\")\ndog_img = PILImage.create(dog_files[30])\ndog_img\n```", "```py\ncat_files = get_image_files(path/\"train/cat\")\ncat_img = PILImage.create(cat_files[30])\ncat_img\n```", "```py\nlearn = cnn_learner(dls, resnet18, \n                    loss_func=LabelSmoothingCrossEntropy(), \n                    metrics=accuracy))\n```", "```py\nlearn.fine_tune(5)\n```", "```py\n    learn = cnn_learner(dls, resnet18, pretrained=False,\n                        loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy)\n    ```", "```py\n    learn.fit_one_cycle(5)\n    ```", "```py\n    path = untar_data(URLs.COCO_TINY)\n    ```", "```py\n    path.ls()\n    ```", "```py\n    with open(path/'train.json') as json_file:\n        data = json.load(json_file)\n        # each nested structure is a list of dictionaries\n        categories = data['categories']\n        images = data['images']\n        annotations = data['annotations']  \n    ```", "```py\n    print(\"categories \", categories)\n    print()\n    print(\"subset of images\",list(images)[:5])\n    print()\n    print(\"subset of annotations\",list(annotations)[:5])\n    ```", "```py\n    image_files, bbox_lbl = get_annotations(path/'train.json')\n    img_bbox_combo = dict(zip(image_files, bbox_lbl))\n    ```", "```py\n    img_bbox_combo[image_files[5]]\n    ```", "```py\n    image_subpath = 'train/'+image_files[5]\n    img = PILImage.create(path/image_subpath)\n    img\n    ```", "```py\n    def get_bbox(filename):\n        return np.array(img_bbox_combo[os.path.basename(filename)][0])\n    ```", "```py\n    def get_lbl(filename):\n        return np.array(img_bbox_combo[os.path.basename(filename)][1],dtype=object)\n    ```", "```py\n    def get_items(noop):\n        return get_image_files(path/'train')\n    ```", "```py\n    db = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n                     get_items=get_image_files,\n                     splitter=RandomSplitter(),\n                     get_y=[get_bbox, get_lbl],\n                     n_inp=1)\n    ```", "```py\n    dls = db.dataloaders(path,bs=32)\n    ```", "```py\n    dls.show_batch(max_n=4, figsize=(10,10))\n    ```", "```py\ndls.show_batch(max_n=4, figsize=(10,10))\n```", "```py\nwith open(path/'train.json') as json_file:\n    data = json.load(json_file)\n    # each nested structure is a list of dictionaries\n    categories = data['categories']\n    images = data['images']\n    annotations = data['annotations']  \n```", "```py\nprint(\"categories \", categories)\n```", "```py\nwith open(path/'train.json') as json_file:\n    data = json.load(json_file)\n    # each nested structure is a list of dictionaries\n    categories = data['categories']\n    images = data['images']\n    annotations = data['annotations']  \n```", "```py\nprint(\"subset of annotations\",list(annotations)[:5])\n```", "```py\nget_bbox(path/'train/000000071159.jpg')\n```", "```py\n    notebooks/temp directory, make a new /notebooks/temp directory:\n\n    ```", "```py\n\n    ```", "```py\n    cd /notebooks/temp\n    ```", "```py\n    unzip archive.zip -d /storage/archive\n    ```", "```py\n    cd /storage/archive/fruits-360\n    ```", "```py\n    ls\n    ```", "```py\n    path = URLs.path('fruits-360')\n    ```", "```py\n    path.ls()\n    ```", "```py\n    dls = ImageDataLoaders.from_folder(path, train='Training', valid='Test')\n    ```", "```py\n    dls.train.show_batch(max_n=4, nrows=1)\n    ```", "```py\n    (path/'Training').ls() \n    ```", "```py\n    img_files = get_image_files(path)\n    img = PILImage.create(img_files[100])\n    img\n    ```", "```py\n    learn = cnn_learner(dls, resnet18, \n                        loss_func=LabelSmoothingCrossEntropy(), \n                        metrics=accuracy))\n    ```", "```py\n    learn.fine_tune(5)\n    ```", "```py\n    img_test_files = get_image_files(path/\"Test\")\n    img2 = PILImage.create(img_test_files[700])\n    img2\n    ```", "```py\n    img3 = PILImage.create(img_test_files[8000])\n    img3\n    ```", "```py\n    learn.predict(img2)\n    ```", "```py\n    learn.predict(img3)\n    ```", "```py\n    avocado_files = get_image_files(path/\"Test/Avocado\")\n    avocado_img = PILImage.create(avocado_files[30])\n    avocado_img\n    ```", "```py\n    walnut_files = get_image_files(path/\"Test/Walnut\")\n    walnut_img = PILImage.create(walnut_files[30])\n    walnut_img\n    ```", "```py\n    learn.predict(avocado_img)\n    ```", "```py\n    learn.predict(walnut_img) \n    ```", "```py\n    learn.save(\"fruits_model\"+modifier)\n    ```", "```py\n    path = untar_data(URLs.CIFAR)\n    ```", "```py\n    path = URLs.path('fruits-360')\n    ```", "```py\n    path = untar_data(URLs.PASCAL_2007)\n    ```", "```py\n    path.ls()\n    ```", "```py\n    with open(path/'train.json') as json_file:\n        data = json.load(json_file)\n        # each nested structure is a list of dictionaries\n        categories = data['categories']\n        images = data['images']\n        annotations = data['annotations']\n    ```", "```py\n    print(\"categories \", categories)\n    print()\n    print(\"subset of images\",list(images)[:5])\n    print()\n    print(\"subset of annotations\",list(annotations)[:5])\n    ```", "```py\n    image_files, bbox_lbl = get_annotations(path/'train.json')\n    img_bbox_combo = dict(zip(image_files, bbox_lbl))\n    ```", "```py\n    img_bbox_combo[image_files[5]]\n    ```", "```py\n    image_subpath = 'train/'+image_files[5]\n    img = PILImage.create(path/image_subpath)\n    img\n    ```", "```py\n    def get_category(in_key_value,in_key,out_key,dict_list):\n        return([cat[out_key] for cat in dict_list if cat[in_key]==in_key_value] )\n    ```", "```py\n    def get_lbl(filename):\n        return np.array(img_bbox_combo[os.path.basename(filename)][1],dtype=object)\n    ```", "```py\n    get_lbl('/storage/data/pascal_2007/train/007911.jpg') \n    ```", "```py\n    image_subpath = 'train/007911.jpg'\n    img = PILImage.create(path/image_subpath)\n    img\n    ```", "```py\n    print(\"number of training images: \",len(get_image_files(path/'train')))\n    print(\"number of testing images: \",len(get_image_files(path/'test')))\n    ```", "```py\n    print(\"number of categories is: \",len(categories))\n    ```", "```py\n    def get_items(noop):\n        return_list = []\n        empty_list = []\n        # filter the training files and keep only the ones with valid info in the JSON file\n        for file_path in get_image_files(path/'train'):\n            file_id_list = get_category(os.path.basename(file_path),'file_name','id',images)\n            if len(file_id_list) > 0:\n                return_list.append(file_path)\n            else:\n                empty_list.append(file_path)\n        print(\"len(return_list): \",len(return_list))\n        print(\"len(empty_list): \",len(empty_list))\n        return(return_list)\n    ```", "```py\n    db = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                     get_items = get_items,               \n                     splitter=RandomSplitter(),\n                     get_y=[get_lbl],\n                     item_tfms = RandomResizedCrop(128,\\\n    min_scale=0.35),\n                     n_inp=1)\n    ```", "```py\n    dls = db.dataloaders(path,bs=32)\n    ```", "```py\n    dls.show_batch(max_n=4, figsize=(10,10))\n    ```", "```py\n    learn = cnn_learner(dls, resnet18)\n    ```", "```py\n    learn.fine_tune(10)\n    ```", "```py\n    img_test_files = get_image_files(path/\"test\")\n    img2 = PILImage.create(img_test_files[100])\n    img2\n    ```", "```py\n    learn.predict(img2)\n    ```", "```py\n    img3 = PILImage.create(img_test_files[200])\n    img3\n    ```", "```py\n    learn.predict(img3)\n    ```", "```py\nfind /storage/archive/fruits-360/Training -type f | wc -l\n```", "```py\n    learn = cnn_learner(dls, resnet18)\n    ```", "```py\n    learn.summary()\n    ```", "```py\n    learn.fine_tune(20)\n    ```", "```py\n    learn.summary()\n    ```", "```py\n    db = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                     get_items = get_items, \n                     splitter=RandomSplitter(),\n                     get_y=[get_lbl],\n                     item_tfms = RandomResizedCrop(168,\\\n    min_scale=0.3),\n                     n_inp=1)\n    ```", "```py\n    db = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                     get_items = get_items, \n                     splitter=RandomSplitter(),\n                     get_y=[get_lbl],\n                     item_tfms = Resize(168),\n                     n_inp=1)\n    ```"]