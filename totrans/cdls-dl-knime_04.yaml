- en: '*Chapter 3:* Getting Started with Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into the practical implementation of deep learning networks using
    KNIME Analytics Platform and its integration with the Keras library, we will briefly
    introduce a few theoretical concepts behind neural networks and deep learning.
    This is the only purely theoretical chapter in this book, and it is needed to
    understand the how and why of the following practical implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural Networks and Deep Learning – Basic Concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing your Network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a Neural Network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will start with the basic concepts of neural networks and deep learning:
    from the first artificial neuron as a simulation of the biological neuron to the
    training of a network of neurons, a fully connected feedforward neural network,
    using a backpropagation algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: We will then discuss the design of a neural architecture as well as the training
    of the final neural network. Indeed, when designing a neural architecture, we
    need to appropriately select its topology, neural layers, and activation functions,
    and introduce some techniques to avoid overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, before training, we need to know when to use which loss function and
    what the different parameters that have to be set for training are. This will
    be described in the last part of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Neural Networks and Deep Learning – Basic Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All you hear about at the moment is deep learning. Deep learning stems from
    the traditional discipline of neural networks, in the realm of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The field of neural networks has gone through a number of stop-and-go phases.
    Since the early excitement for the first perceptron in the '60s and the subsequent
    lull when it became evident what the perceptron could not do; through the renewed
    enthusiasm for the backpropagation algorithm applied to multilayer feedforward
    neural networks and the subsequent lull when it became apparent that training
    recurrent networks required hardware capabilities that were not available at the
    time; right up to today's new deep learning paradigms, units, and architectures
    running on much more powerful, possibly GPU-equipped, hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start from the beginning and, in this section, go through the basic concepts
    behind neural networks and deep learning. While these basic notions might be familiar
    to you, especially if you have already attended a neural networks or deep learning
    course, we would still like to describe them here as a reference for descriptions
    of KNIME deep learning functionalities in the coming chapters, and for anyone
    who might be a neophyte to this field.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Neuron and Artificial Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Artificial Neural Networks** (**ANNs**) began with simulating the biological
    neuron, depicted on the left in *Figure 3.1* (Abbott, L.F. (1999) *Lapique''s
    introduction of the integrate-and-fire model neuron* (*1907*[): https://web.archive.org/web/20070613230629/http:/neurotheory.columbia.edu/~larry/AbbottBrResBul99.](https://web.archive.org/web/20070613230629/http:/neurotheory.columbia.edu/~larry/AbbottBrResBul99.pdf)pdf.
    *Brain Research Bulletin. 50 (5/6)*: 303–304). The biological neuron is a nerve
    cell consisting of a body (soma), a few input dendrites, and one output axon with
    one or more terminals. When activated, it generates a sharp electrical potential
    spike. The dendrites accept electrical input signals, usually from other neurons,
    through chemical synapses. The chemical reaction happening in the synapse enhances
    or reduces – in other words, it weighs – the input electrical signal before it
    reaches the body of the neuron. If the total electrical signal in the soma is
    high enough, the neuron produces an electrical spike along its axon. The axon
    terminals then bring out the spike to other neurons, again through chemical reactions
    in synapses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – On the left, a biological neuron with inputs xj at dendrites
    and output y at the axon terminal (image from Wikipedia). On the right, an artificial
    neuron (perceptron) with inputs xj connected to weights wj and producing output
    y](img/B16391_03_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – On the left, a biological neuron with inputs xj at dendrites and
    output y at the axon terminal (image from Wikipedia). On the right, an artificial
    neuron (perceptron) with inputs xj connected to weights wj and producing output
    y
  prefs: []
  type: TYPE_NORMAL
- en: The simplest simulation tries to reproduce a biological neuron with just two
    inputs and one output, like on the right in *Figure 3.1*. The input signals at
    the dendrites are now called ![](img/Formula_B16391_03_001.png) and ![](img/Formula_B16391_03_002.png)
    and reach the soma of the artificial cell via two weights, ![](img/Formula_B16391_03_003.png)
    and ![](img/Formula_B16391_03_004.png) simulating the chemical reactions in the
    synapses. If the total input signal reaching the soma is higher than a given threshold
    ![](img/Formula_B16391_03_005.png), simulating the "high enough" concept, an output
    signal ![](img/Formula_B16391_03_006.png) is generated. This simple artificial
    neuron is called a **perceptron**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two details to clarify here: the total input signal and the threshold function.
    There are many neural electrical input-output voltage models (Hodgkin, A. L.;
    Huxley, A. F. (1952), *A quantitative description of membrane current and its
    application to conduction and excitation in* [*nerve*, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1392413)1392413,
    *The Journal of Physiology. 117 (4)*: 500–544). The simplest way to represent
    the total input signal uses a weighted sum of all input signals, where the weights
    represent the role of the synapse reactions. The firing function of the neuron
    soma can be described via a step function ![](img/Formula_B16391_03_007.png).
    Thus, for our simplified simulation in *Figure 3.1*, the output ![](img/Formula_B16391_03_006.png)
    is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/Formula_B16391_03_010.png) is a step function with threshold
    ![](img/Formula_B16391_03_011.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_012.png) with ![](img/Formula_B16391_03_013.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generalizing to a neuron with ![](img/Formula_B16391_03_014.png) input signals
    and with any other activation function ![](img/Formula_B16391_03_015.png), we
    get the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_016.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the threshold ![](img/Formula_B16391_03_017.png) has been transformed
    into a weight ![](img/Formula_B16391_03_018.png) connected to an input signal
    ![](img/Formula_B16391_03_019.png) that is constantly on – that is, constantly
    set to 1.
  prefs: []
  type: TYPE_NORMAL
- en: However, one single artificial neuron, just like one single biological neuron,
    does not have high computational capability. It can implement just a few simple
    functions, as we will see later in the next sub-section, *Understanding the need
    for hidden layers*. As in the biological world, networks of neurons have a much
    bigger computational potential than one single neuron alone. Networks of biological
    neurons, such as even simple brains, can learn and carry out very complex tasks.
    Similarly, networks of artificial neurons can learn and carry out very complex
    tasks. The key to the success of neural networks is this flexibility in forming
    more or less complex architectures and in training them to perform more or less
    complex tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a network of perceptrons is shown in *Figure 3.2*. This network
    has three layers of neurons: an input layer accepting the input signals ![](img/Formula_B16391_03_020.png);
    a first hidden layer with two neurons connected to the outputs of the input layer;
    a second hidden layer with three neurons connected to the outputs of the first
    hidden layer; and finally an output layer with one neuron only, fed by the outputs
    of the hidden layer and producing the final output ![](img/Formula_B16391_03_021.png)
    of the network. Neurons are indicated by a circle including the ![](img/Formula_B16391_03_022.png)
    symbol for the weighted sum of the input signals and the ![](img/Formula_B16391_03_023.png)
    symbol for the activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – On the left, a network of biological neurons (image from Wikipedia).
    On the right, a network of artificial neurons (multi-layer perceptron)](img/B16391_03_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – On the left, a network of biological neurons (image from Wikipedia).
    On the right, a network of artificial neurons (multi-layer perceptron)
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that in this particular architecture, all connections move from the
    input to the output layer: this is a fully connected feedforward architecture.
    Of course, a **feedforward neural network** can have as many hidden layers as
    you want, and each neural layer can have as many artificial neurons as you want.
    A feedforward network of perceptrons is called a **Multi-Layer Perceptron** (**MLP**).'
  prefs: []
  type: TYPE_NORMAL
- en: Signal Propagation within a Feedforward Neural Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A simple fully connected feedforward neural network can then be described as
    a function that transforms the input values ![](img/Formula_B16391_03_024.png)
    into the output value ![](img/Formula_B16391_03_021.png), through a series of
    intermediate values ![](img/Formula_B16391_03_026.png): the outputs of the hidden
    layers. For example, for the network in *Figure 3.3*, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_027.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B16391_03_028.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_029.png) is the number of input values (and
    input units) ![](img/Formula_B16391_03_024.png), ![](img/Formula_B16391_03_031.png)
    is the number of hidden neurons with output values ![](img/Formula_B16391_03_032.png),
    ![](img/Formula_B16391_03_021.png) is the final output value (the only one in
    this architecture), and ![](img/Formula_B16391_03_034.png) is the neurons' activation
    functions. If we number the neural layers progressively from the input to the
    output, we will label layer 1 as the input layer, layer 2 as the hidden layer,
    and layer 3 as the output layer. This progressive numbering of the neural layers
    is also contained in the weight and hidden unit notations. ![](img/Formula_B16391_03_035.png)
    is the output value of the ![](img/Formula_B16391_03_036.png) neural unit in the
    ![](img/Formula_B16391_03_037.png) (hidden) layer, and ![](img/Formula_B16391_03_038.png)
    is the weight connecting neural unit ![](img/Formula_B16391_03_039.png) in layer
    ![](img/Formula_B16391_03_040.png) with neural unit ![](img/Formula_B16391_03_036.png)
    in layer ![](img/Formula_B16391_03_042.png).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Notice that, in this notation, ![](img/Formula_B16391_03_043.png) and ![](img/Formula_B16391_03_044.png)
    in ![](img/Formula_B16391_03_045.png) and in ![](img/Formula_B16391_03_046.png)
    are NOT exponents. They just describe the network layer of the output unit for
    ![](img/Formula_B16391_03_045.png) and the destination layer for ![](img/Formula_B16391_03_048.png).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Fully connected feedforward neural network with just one hidden
    layer and one output unit](img/B16391_03_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Fully connected feedforward neural network with just one hidden
    layer and one output unit
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many types of **activation functions** ![](img/Formula_B16391_03_049.png).
    We have seen the step function in the previous section, which however has a main
    flaw: it is neither continuous nor derivable. Some similar activation functions
    have been introduced over the years, which are easier to handle since they are
    continuous and derivable everywhere. Common examples are the **sigmoid** and the
    **hyperbolic tangent,** ![](img/Formula_B16391_03_050.png). Recently, a new activation
    function, named **Rectified Linear Unit** (**ReLU**), has been introduced, which
    seems to perform better with fully connected feedforward neural networks with
    many hidden layers. We will describe these activation functions in detail in the
    coming chapters.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Usually, neurons in the same layer have the same activation function ![](img/Formula_B16391_03_051.png)
    Different layers, though, can have different activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Another parameter of a network is its **topology**, or architecture. We have
    seen a fully connected feedforward network, where all connections move from the
    input toward the output and, under this constraint, all units are connected to
    all units in the next layer. However, this is of course not the only possible
    neural topology. Cross-connections within the same layer ![](img/Formula_B16391_03_044.png),
    backward connections from layer ![](img/Formula_B16391_03_044.png) to layer ![](img/Formula_B16391_03_054.png),
    and autoconnections of a single neuron with itself are also possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Different connections and different architectures produce different data processing
    functions. For example, autoconnections introduce a time component, since the
    current output of neuron ![](img/Formula_B16391_03_036.png) at time ![](img/Formula_B16391_03_056.png)
    will be an additional input for the same neuron ![](img/Formula_B16391_03_036.png)
    at time ![](img/Formula_B16391_03_058.png); a feedforward neural network with
    as many outputs as inputs can implement an autoencoder and be used for compression
    or for outlier detection. We will see some of these different neural architectures
    and the tasks they can implement later in this book. For now, we just give you
    a little taste of possible neural topologies in *Figure 3.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Some examples of neural network topologies](img/B16391_03_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Some examples of neural network topologies
  prefs: []
  type: TYPE_NORMAL
- en: The first network from the left in *Figure 3.4* has its neurons all completely
    connected, so that the definition of the layer becomes unnecessary. This is a
    Hopfield network and is generally used as an associative memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second network is a feedforward autoencoder: three layers, as many ![](img/Formula_B16391_03_029.png)
    input units as many ![](img/Formula_B16391_03_029.png) output units, and a hidden
    layer with ![](img/Formula_B16391_03_061.png) units, where usually ![](img/Formula_B16391_03_062.png);
    this network architecture has been adopted for outlier detection or to implement
    a dimensionality reduction of the input space.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the third network presents units with autoconnections. As said before,
    autoconnections introduce a time component within the function implemented by
    the network and therefore are often adopted for time series analysis. This last
    network qualifies as a recurrent neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go back to fully connected feedforward neural networks. Now that we've
    seen how they are structured, let's try to understand why they are built this
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Need for Hidden Layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The question now is: do we really need such complex neural architectures? What
    can the perceptron in *Figure 3.1* do and what can it not do? A perceptron, using
    a step function as the activation function, implements a line (a linear combination
    of the input signals) as a discriminant surface in a two-dimensional space, the
    parameters of the line being the weights and threshold of the perceptron.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Classic examples are the **OR** and **AND** problems, which can be solved by
    a line separating the "1" outputs from the "0" outputs. Therefore, a perceptron
    can implement a solution to both problems. However, it cannot implement a solution
    to the **XOR** problem. The XOR function outputs "1" when the two inputs are different
    (one is "0" and one is "1") and outputs "0" when the two inputs are the same (both
    are "0" or both are "1"). Indeed, the XOR operator is a nonlinearly separable
    problem and one line only is not sufficient to separate the "1" outputs from the
    "0" outputs (*Figure 3.5*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – A perceptron implements a linear discriminant surface, which
    is a line in a two-dimensional space. All linearly separable problems can be solved
    by a single perceptron. A perceptron cannot solve non-linearly separable problems](img/B16391_03_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – A perceptron implements a linear discriminant surface, which is
    a line in a two-dimensional space. All linearly separable problems can be solved
    by a single perceptron. A perceptron cannot solve non-linearly separable problems
  prefs: []
  type: TYPE_NORMAL
- en: 'The only possibility to solve the XOR problem is to add one hidden layer with
    two units into the perceptron architecture, making it into an MLP (*Figure 3.6*).
    The two hidden units in green and red each implement one line to separate some
    "0"s and "1"s. The one unit in the output layer then builds a new line on top
    of the two previous lines and implements the final discriminant:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – One additional hidden layer with two units enables the MLP to
    solve the XOR problem](img/B16391_03_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – One additional hidden layer with two units enables the MLP to solve
    the XOR problem
  prefs: []
  type: TYPE_NORMAL
- en: 'The example in *Figure 3.7* shows a three-layer network: one input layer receiving
    input values ![](img/Formula_B16391_03_063.png) and ![](img/Formula_B16391_03_064.png),
    one hidden layer with two units, and one output layer with one unit only. The
    two hidden units implement two discrimination lines: ![](img/Formula_B16391_03_065.png)
    for the red unit and ![](img/Formula_B16391_03_066.png) for the orange unit. The
    output line implements a discrimination line on top of these two as ![](img/Formula_B16391_03_067.png),
    which is identified by the green area in the plane shown in *Figure 3.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – The network on the left fires up only for the points in the
    green zone in the input space, as depicted on the right](img/B16391_03_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – The network on the left fires up only for the points in the green
    zone in the input space, as depicted on the right
  prefs: []
  type: TYPE_NORMAL
- en: 'As you see, adding just one hidden layer makes the neural network much more
    powerful in terms of possible functions to implement. However, there is more.
    The **Universal Approximation Theorem** states that a simple feedforward network
    with a single hidden layer and a sufficient number of neurons can approximate
    any continuous function on compact subsets of ![](img/Formula_B16391_03_068.png),
    under mild assumptions on the activation function and assuming that the network
    has been sufficiently trained (Hornik K., Stinchcombe M., White H. (1989) *Multilayer
    feedforward networ*[*ks are universal approximators*: http://www.sciencedirect.com/scie](http://www.sciencedirect.com/science/article/pii/0893608089900208)nce/article/pii/0893608089900208
    *Neural Networks, Vol. 2, Issue 5*, (*1989*) Pages 359-366). This theorem proves
    that neural networks have a kind of *universality* property. That is, any function
    can be approximated by a sufficiently large and sufficiently trained neural network.
    Sufficiently large refers to the number of neurons in a feedforward network. In
    addition, the cited paper refers to network architectures with just one single
    hidden layer with enough neurons.'
  prefs: []
  type: TYPE_NORMAL
- en: Even very simple network architectures, thus, can be very powerful! Of course,
    this is all true under the assumption of a sufficiently large hidden layer (which
    might become too large for a reasonable training time) and a sufficient training
    time.
  prefs: []
  type: TYPE_NORMAL
- en: A feedforward network with a single layer is sufficient to represent any function,
    but the layer may be infeasibly large and may fail to learn and generalize correctly,
    (Goodfellow I., Bengio Y., Courville A. (2016). *Deep Learning*, *MIT Press*).
  prefs: []
  type: TYPE_NORMAL
- en: We have seen that introducing one or more hidden layers to a feedforward neural
    network makes it extremely powerful. Let's see how to train it.
  prefs: []
  type: TYPE_NORMAL
- en: Training a Multilayer Perceptron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A neural network includes a few free parameters: the topology, the weights,
    and the parameters of the activation functions. Let''s consider a fully connected
    feedforward network with a pre-defined activation function for all neurons, such
    as a sigmoid function, for example. Then, the only free parameters left are the
    weights.'
  prefs: []
  type: TYPE_NORMAL
- en: Training a neural network means showing examples from the training set repeatedly
    and each time adjusting the parameter values, the weights, to fit a loss function,
    calculated on the desired input-output behavior. To find the weights that best
    fit the loss functions, the gradient descent algorithm or variants of **Stochastic
    Gradient Descent** (**SGD**) are used. The idea is to update the weights by taking
    steps in the direction of steepest descent on the error surface. The direction
    of steepest descent is equivalent to the negative of the gradient. To calculate
    the gradient efficiently, the backpropagation algorithm is used. Let's find out
    how it works.
  prefs: []
  type: TYPE_NORMAL
- en: The math behind backpropagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A classic loss function for regression problems is the total squared error,
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_069.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_070.png) and ![](img/Formula_B16391_03_071.png)
    are respectively the desired target and the real answer for output unit ![](img/Formula_B16391_03_072.png),
    and the sum runs on all units of the output layer and on all examples in the training
    set ![](img/Formula_B16391_03_073.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'If we adopt the gradient descent strategy to reach a minimum in the loss function
    surface, at each training iteration, each weight of the network must be incremented
    in the opposite direction of the derivative of ![](img/Formula_B16391_03_074.png)
    in the weight space (Goodfellow I., Bengio Y., Courville A. (2016\. *Deep Learning*,
    MIT Press):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_075.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This partial derivative of the error with respect to the weight is calculated
    using the chain rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_076.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/Formula_B16391_03_077.png) is the loss function, ![](img/Formula_B16391_03_078.png)
    the output of neuron j, ![](img/Formula_B16391_03_079.png) its total input, and
    ![](img/Formula_B16391_03_080.png) its input weight from neuron ![](img/Formula_B16391_03_081.png)
    in the previous layer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the weights connecting to units **in the output layer**, the derivatives
    will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_082.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B16391_03_083.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B16391_03_084.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, finally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_085.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, the weight change for weights connecting to output units is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_086.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_087.png), ![](img/Formula_B16391_03_088.png)
    is the input ![](img/Formula_B16391_03_089.png) to the output node ![](img/Formula_B16391_03_072.png),
    and ![](img/Formula_B16391_03_091.png) is the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: For the weights connecting to the **units in a hidden layer**, the calculation
    of the derivative, and therefore of the weight change, is a bit more complicated.
    While the last two derivatives remain the same also when referring to neurons
    in hidden layers, ![](img/Formula_B16391_03_092.png) will need to be recalculated.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we consider the loss function ![](img/Formula_B16391_03_074.png) as a function
    of all input sums to all neurons ![](img/Formula_B16391_03_094.png) in the next
    layer connected to neuron j, as ![](img/Formula_B16391_03_095.png), after a few
    math operations we reach a recursive expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_096.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_097.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The update formula for all weights, leading to output or hidden neurons, is
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_098.png)'
  prefs: []
  type: TYPE_IMG
- en: This recursive formula tells us that ![](img/Formula_B16391_03_099.png) for
    unit ![](img/Formula_B16391_03_100.png) in the hidden layer ![](img/Formula_B16391_03_101.png)
    can be calculated as the linear combination of all ![](img/Formula_B16391_03_102.png)
    in layer ![](img/Formula_B16391_03_103.png), which will be ![](img/Formula_B16391_03_104.png)
    if this is the output layer or ![](img/Formula_B16391_03_105.png) if this is another
    hidden layer. This means that moving from the output layer backward toward the
    input layer, we can calculate all ![](img/Formula_B16391_03_106.png), starting
    from ![](img/Formula_B16391_03_107.png) and then through all ![](img/Formula_B16391_03_108.png),
    as a combination of ![](img/Formula_B16391_03_109.png)from the preceding layer,
    layer after layer. Together with ![](img/Formula_B16391_03_106.png), we can also
    calculate all weight updates ![](img/Formula_B16391_03_111.png).
  prefs: []
  type: TYPE_NORMAL
- en: The Idea Behind Backpropagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So, the training of a feedforward neural network can be seen as a two-step
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: All training vectors are presented, one after the other, to the input layer
    of the network, and the signal is propagated throughout all network connections
    (and weights) till the output layer. After all of the training examples have passed
    through the network, the total squared error is calculated at the output layer
    as the sum of the single squared errors. This is the **forward pass**:![Figure
    3.8 – In the forward pass of the backpropagation algorithm, all training examples
    are presented at the input layer and forward-propagated through the network till
    the output layer, to calculate the output values](img/B16391_03_008.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 3.8 – In the forward pass of the backpropagation algorithm, all training
    examples are presented at the input layer and forward-propagated through the network
    till the output layer, to calculate the output values
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'All ![](img/Formula_B16391_03_112.png) are calculated for all units in the
    output layer. Then, the ![](img/Formula_B16391_03_113.png)s are backpropagated
    from the output layer through all network connections (and weights) till the input
    layer and all ![](img/Formula_B16391_03_114.png) in the hidden layers are also
    calculated. This is the **backward pass**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.9 – In the backward pass of the backpropagation algorithm, all s
    are calculated at the output layer and backpropagated through the network till
    the input layer. After all examples from the training set have passed through
    the network forth and back, all weights are updated](img/B16391_03_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – In the backward pass of the backpropagation algorithm, all ![](img/Formula_B16391_03_115.png)s
    are calculated at the output layer and backpropagated through the network till
    the input layer. After all examples from the training set have passed through
    the network forth and back, all weights are updated
  prefs: []
  type: TYPE_NORMAL
- en: This algorithm is called **backpropagation**, as a reference to the ![](img/Formula_B16391_03_116.png)s
    backpropagating through the network during the second pass.
  prefs: []
  type: TYPE_NORMAL
- en: After all the training data has passed through the network forth and back, all
    weights are updated.
  prefs: []
  type: TYPE_NORMAL
- en: Also notice the first derivative of the unit activation function ![](img/Formula_B16391_03_117.png)
    in ![](img/Formula_B16391_03_118.png). Of course, using a continuous derivable
    function ![](img/Formula_B16391_03_119.png) helps with the calculations. This
    is the reason why the ![](img/Formula_B16391_03_120.png) and ![](img/Formula_B16391_03_121.png)
    function have been so popular with neural architectures.
  prefs: []
  type: TYPE_NORMAL
- en: The gradient descent algorithm is not guaranteed to reach the global minimum
    of the error function, but it often ends up in a local minimum. If the local minimum
    does not ensure satisfactory performance of the network, the training process
    must be repeated starting from new initial conditions, meaning new initial values
    for the weights of the network.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are very powerful in implementing input-output models and very
    flexible in terms of architecture and parameters. It is extremely easy to build
    huge neural networks, by adding more and more neurons and more and more hidden
    layers. Besides the longer training times, an additional risk is to run quickly
    into the **overfitting** of the training data. Overfitting is a drawback of too
    complex models, usually with too many free parameters to fit a simple task. The
    result of an over-dimensioned model for a simple task is that the model, at some
    point, will start using the extra parameters to memorize noise and errors in the
    training set, considerably worsening the model's performance. The power and flexibility
    of neural networks make them prone to overfitting, especially if we are dealing
    with small training sets.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Another big objection that has been leveled against neural networks since their
    introduction is their non-interpretability. The adjustment of the weights has
    no correspondence with any entity in the data domain. When dealing with neural
    networks, we need to accept that we are dealing with **black boxes** and we might
    not understand the decision process.
  prefs: []
  type: TYPE_NORMAL
- en: If interpretability is a requirement for our project, then maybe neural networks
    are not the tool for us. A few techniques have been proposed recently to extract
    knowledge on the decision process followed in black-box models, such as the **SHAPLEY**
    values or **Partial Dependency Plots** (Molnar C. *Interpretable Machine Learning*,
    https://christophm.github.io/interpretable-ml-book/index.html, GitHub). They are
    currently in their infancy and not immune from criticism. However, they constitute
    an interesting attempt to fix the interpretability problem of neural networks.
    These are beyond the scope of this book, so we will not be exploring them in any
    more detail.
  prefs: []
  type: TYPE_NORMAL
- en: With the basic theory covered, let's get into the design of a network.
  prefs: []
  type: TYPE_NORMAL
- en: Designing your Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we learned that neural networks are characterized by
    a topology, weights, and activation functions. In particular, feedforward neural
    networks have an input and an output layer, plus a certain number of hidden layers
    in between. While the values for the network weights are automatically estimated
    via the training procedure, the network topology and the activation functions
    have to be predetermined during network design before training. Different network
    architectures and different activation functions implement different input-output
    tasks. Designing the appropriate neural architecture for a given task is still
    an active research field in the deep learning area (Goodfellow I., Bengio Y.,
    Courville A. (2016). *Deep Learning*, MIT Press).
  prefs: []
  type: TYPE_NORMAL
- en: Other parameters are involved in the training algorithm of neural networks,
    such as the learning rate or the loss function. We have also seen that neural
    networks are prone to overfitting; this means that their flexibility makes it
    easy for them to run into the overfitting problem. Would it be possible to contain
    the weight growth, to change the loss function, or to self-limit the network structure
    during training as to avoid the overfitting problem?
  prefs: []
  type: TYPE_NORMAL
- en: 'This section gives you an overview of all those remaining parameters: the topology
    of the network, the parameters in the training algorithm, the possible activation
    functions, the loss functions, regularization terms, and more, always keeping
    an eye on containing the overfitting effect, making the training algorithm more
    efficient, and developing more powerful neural architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: Commonly Used Activation Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In summary, a single neural layer has a number of inputs ![](img/Formula_B16391_03_122.png)
    and a number of outputs ![](img/Formula_B16391_03_123.png) The calculation of
    the output value of a neuron ![](img/Formula_B16391_03_124.png) is performed in
    two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculation of the weighted sum of the inputs plus a bias ![](img/Formula_B16391_03_125.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_126.png) for ![](img/Formula_B16391_03_127.png) and
    ![](img/Formula_B16391_03_128.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Application of an activation function ![](img/Formula_B16391_03_129.png) or
    ![](img/Formula_B16391_03_130.png)to calculate the output ![](img/Formula_B16391_03_131.png)
    based on the weight matrix ![](img/Formula_B16391_03_132.png) and either on ![](img/Formula_B16391_03_133.png)
    or on ![](img/Formula_B16391_03_134.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_135.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that ![](img/Formula_B16391_03_136.png)is the weighted sum of the input
    values to the ![](img/Formula_B16391_03_137.png) th neuron and ![](img/Formula_B16391_03_138.png)
    is the vector of all weighted input sums.
  prefs: []
  type: TYPE_NORMAL
- en: A network can then also be seen as a chain of functions ![](img/Formula_B16391_03_139.png),
    where each function implements a neural layer. Depending on the network architecture,
    each neural layer has different input values and uses a different activation function
    ![](img/Formula_B16391_03_140.png), and therefore implements a different function
    ![](img/Formula_B16391_03_141.png), using the two calculation steps described
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: The complexity of the total function implemented by the full network also depends
    on the number of layers involved; that is, it depends on the network depth.
  prefs: []
  type: TYPE_NORMAL
- en: A layer where all neurons are connected to all outputs of the previous layer
    is called a **dense layer**. Fully connected feedforward networks are just a chain
    of dense layers, where each layer has its own activation function. In feedforward
    neural networks, then, a function ![](img/Formula_B16391_03_142.png) is based
    on the number of the layer's neurons, the number of inputs, and the activation
    function. The key difference between layers is then the activation function. Let's
    look at the most commonly used activation functions in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **sigmoid function** is an S-shaped function with values between ![](img/Formula_B16391_03_143.png)
    and ![](img/Formula_B16391_03_144.png). For the ![](img/Formula_B16391_03_137.png)th
    neuron in the layer, the function is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_146.png)'
  prefs: []
  type: TYPE_IMG
- en: It is plotted on the left in *Figure 3.10*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For binary classification problems, this is the go-to function for the output
    neural layer, as the value range ![](img/Formula_B16391_03_147.png) allows us
    to interpret the output as the probability of one of the two classes. In this
    case, the output neural layer consists of only one neuron, AKA unit size 1, with
    the sigmoidal activation function. Of course, the same function can also be used
    as an activation function for output and hidden layers with a bigger unit size:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – The sigmoid function (on the left) can be used as the activation
    function of the single output neuron of a network implementing the solution to
    a binary classification problem (in the center). It can be used generically as
    an activation function for neurons placed in hidden or output layers in a network
    (on the right)](img/B16391_03_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – The sigmoid function (on the left) can be used as the activation
    function of the single output neuron of a network implementing the solution to
    a binary classification problem (in the center). It can be used generically as
    an activation function for neurons placed in hidden or output layers in a network
    (on the right)
  prefs: []
  type: TYPE_NORMAL
- en: One of the biggest advantages of the sigmoid function is its derivability everywhere
    and its easy derivative expression. Indeed, when using the sigmoid activation
    function, the weight update rule for the backpropagation algorithm becomes very
    simple, since the first derivative of the activation function is simply ![](img/Formula_B16391_03_148.png),
    where ![](img/Formula_B16391_03_149.png) is the output of neuron j.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, one of the biggest disadvantages of using sigmoid as the
    neurons' activation function in more complex or deep neural architectures is the
    vanishing gradient problem. Indeed, when calculating the derivatives to update
    the network weights, the chain multiplication of output values (< 1) from sigmoid
    functions might produce very small values. In this case, too small gradients are
    produced at each training iteration, leading to slow convergence for the training
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperbolic Tangent (Tanh)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A similar activation function is **hyperbolic tangent**, **tanh** for short.
    It is also an S-shaped function with the difference that the output values fall
    between ![](img/Formula_B16391_03_150.png) and 1, instead of between ![](img/Formula_B16391_03_151.png)
    and ![](img/Formula_B16391_03_152.png) For the ![](img/Formula_B16391_03_124.png)
    th neuron, the function is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_154.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is plotted on the left in *Figure 3.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – The hyperbolic tangent function, tanh(), is also often used
    as an activation function for neural units. In this case, the neuron output value
    falls in (-1, +1)](img/B16391_03_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – The hyperbolic tangent function, tanh(), is also often used as
    an activation function for neural units. In this case, the neuron output value
    falls in (-1, +1)
  prefs: []
  type: TYPE_NORMAL
- en: Here also, one of the biggest advantages of the ![](img/Formula_B16391_03_155.png)
    function is its continuity and its derivability everywhere, which leads to simpler
    formulas for the updates of the weights in the training algorithm. ![](img/Formula_B16391_03_156.png)
    also has the advantage of being centered at 0, which can help to stabilize the
    training process.
  prefs: []
  type: TYPE_NORMAL
- en: Again, one of the biggest disadvantages of using tanh as an activation function
    in complex or deep neural architectures is the vanishing gradient problem.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A special activation function is the **linear activation function**, also known
    as the identity function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_157.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When would such a function be used? A neural layer with a linear activation
    function implements a linear regression model. Sometimes, a neural layer with
    a linear activation function is also introduced to keep the original network response,
    before it is transformed to get the required range or probability score. In this
    case, the last layer of the network is split into two layers: one with the linear
    activation function preserves the original output and the other one applies another
    activation function for the required output format.'
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230), *Implementing
    NLP Applications*, where we describe the *Generating Product Name* case study,
    this approach is used to introduce a new parameter called **temperature** after
    the linear activation function layer.
  prefs: []
  type: TYPE_NORMAL
- en: Rectified Linear Unit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have seen that deep neural networks, using the sigmoid or tanh activation
    functions, often suffer from the problem of vanishing gradient.
  prefs: []
  type: TYPE_NORMAL
- en: 'An activation function that helps to overcome the problem of vanishing gradient
    is the **Rectified Linear Unit** function, **ReLU** for short. The ReLU function
    is like the linear function, at least from 0 on. Indeed, the ReLU function is
    ![](img/Formula_B16391_03_158.png) for negative values of ![](img/Formula_B16391_03_159.png)
    and is the identity function for positive values of ![](img/Formula_B16391_03_159.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_161.png).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.12* shows a plot of the ReLU function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – The ReLU activation function](img/B16391_03_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 – The ReLU activation function
  prefs: []
  type: TYPE_NORMAL
- en: The ReLU activation function, while helping with the vanishing gradient problem,
    is not differentiable for ![](img/Formula_B16391_03_162.png). In practice, this
    is not a problem when training neural networks as usually one of the one-sided
    derivatives is used rather than reporting that the derivative is not defined.
  prefs: []
  type: TYPE_NORMAL
- en: Softmax Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All activation functions introduced until now are functions that have a single
    value as output. This means only the weighted sum ![](img/Formula_B16391_03_163.png)
    is used to calculate the output value of the ![](img/Formula_B16391_03_164.png)th
    neuron, independently from weighted sums ![](img/Formula_B16391_03_165.png), with
    ![](img/Formula_B16391_03_166.png) being used to calculate the outputs of the
    other neurons in the same layer. The **softmax function**, on the other hand,
    works on the whole output vector ![](img/Formula_B16391_03_167.png) and not just
    on one single value ![](img/Formula_B16391_03_168.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, the softmax function transforms a vector ![](img/Formula_B16391_03_169.png)
    of size ![](img/Formula_B16391_03_170.png) into a vector ![](img/Formula_B16391_03_171.png),
    which is a vector ![](img/Formula_B16391_03_172.png) of the same size ![](img/Formula_B16391_03_173.png)
    with values between ![](img/Formula_B16391_03_158.png) and ![](img/Formula_B16391_03_175.png),
    with the constraint that all values ![](img/Formula_B16391_03_176.png) sum to
    ![](img/Formula_B16391_03_175.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_178.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This additional constraint allows us to interpret the components of vector
    ![](img/Formula_B16391_03_179.png) as probabilities of different classes. Therefore,
    the softmax activation function is often the function of choice for the last neural
    layer in a multiclass classification problem. The ![](img/Formula_B16391_03_180.png)th
    element of the output vector is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_181.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3.13* shows an example network that uses the softmax function in the
    last layer, where all output values sum up to 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13 – A simple neural layer with the softmax activation function](img/B16391_03_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 – A simple neural layer with the softmax activation function
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The softmax function is also used by the logistic regression algorithm for multiclass
    classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: Other supported activation functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many more activation functions have been introduced over the years, since the
    sigmoid.
  prefs: []
  type: TYPE_NORMAL
- en: Variants of ReLU are **Leaky Rectified Linear Unit** and **Parametric Rectified
    Linear Unit** (**PReLU**). LeakyReLU offers an almost zero line (![](img/Formula_B16391_03_182.png))
    for negative values of the function argument rather than just zero as in the pure
    ReLU. PReLU makes this line with parametric slope (![](img/Formula_B16391_03_183.png))
    rather than fixed slope as in the LeakyReLU. Parameter ![](img/Formula_B16391_03_184.png)
    becomes part of the parameters that the network must train.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the definitions of LeakyReLU and PreLU:'
  prefs: []
  type: TYPE_NORMAL
- en: 'LeakyReLU: ![](img/Formula_B16391_03_185.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PReLU: ![](img/Formula_B16391_03_186.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other variants of ReLU, introduced to remedy dead ReLUs, are **Exponential
    Linear Unit** (**ELU**) and **Scaled Exponential Linear Unit** (**SELU**). Similar
    to LeakyReLU, ELU has a small slope for negative values. Instead of a straight
    line, it uses a log curve. Scaled ELU adds one more parameter ![](img/Formula_B16391_03_187.png)
    to ELU for the network to train:'
  prefs: []
  type: TYPE_NORMAL
- en: 'ELU: ![](img/Formula_B16391_03_188.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SELU: ![](img/Formula_B16391_03_189.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An approximation of the sigmoid activation function is the **hard sigmoid activation
    function**. It is faster to calculate than sigmoid. Despite being an approximation
    of the sigmoid activation function, it still provides reasonable results on classification
    tasks. However, since it''s just an approximation, it performs worse on regression
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hard-Sigmoid: ![](img/Formula_B16391_03_190.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **SoftPlus** activation function is also quite popular. This is a smoothed
    version of the ReLU activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'SoftPlus: ![](img/Formula_B16391_03_191.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at *Figure 3.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14 – Plots of some additional popular activation functions, mainly
    variants of ReLU and sigmoid functions](img/B16391_03_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 – Plots of some additional popular activation functions, mainly
    variants of ReLU and sigmoid functions
  prefs: []
  type: TYPE_NORMAL
- en: The images in *Figure 3.14* show the plots of the aforementioned activation
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization Techniques to Avoid Overfitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: No matter what kind of algorithm you use, the goal is always a model that not
    only performs well on the training data but also generalizes to new data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Large neural networks, trained on too small datasets, often incur the problem
    of fitting the training data too well and missing the capability to generalize
    to new data. This problem is known as overfitting. *Figure 3.15* shows a regression
    input-output function implemented by a neural network on the training data (full
    crosses) and on the test data (empty crosses). On the left, we see a regression
    function that does not even manage to fit the training data properly, much less
    the test data. This is probably due to an insufficient architecture size or short
    training time (**underfitting**). In the center, we find a regression curve decently
    fitting both training and test data. On the right, we have a regression curve
    fitting the training data perfectly and failing in the fit on the test data; this
    is the **overfitting** problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.15 – From left to right, the regression curve implemented by a network
    underfitting, fitting just fine, and overfitting the training data](img/B16391_03_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 – From left to right, the regression curve implemented by a network
    underfitting, fitting just fine, and overfitting the training data
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we know in advance the right size of the neural architecture and the
    right number of epochs for the training algorithm? A few tricks can be adopted
    to address the problem of overfitting without worrying too much about the exact
    size of the network and the number of epochs: norm regularization, dropout, and
    early stopping.'
  prefs: []
  type: TYPE_NORMAL
- en: Norm Regularization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One sign of overfitting is the high values of the weights. Thus, the idea behind
    norm regularization is to penalize weights with high values by adding a penalty
    term ![](img/Formula_B16391_03_192.png) to the objective function, AKA the loss
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_193.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/Formula_B16391_03_194.png) are the true values and ![](img/Formula_B16391_03_195.png)
    are the predicted values. A new loss function ![](img/Formula_B16391_03_196.png)
    is obtained with the addition of this penalty term:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_197.png)'
  prefs: []
  type: TYPE_IMG
- en: The training algorithm, thus, while minimizing this new loss function, will
    reach a weight configuration with smaller values. This is a well-known **regularization**
    approach you might already know from the linear or logistic regression algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The parameter ![](img/Formula_B16391_03_198.png) is used to control the penalty
    effect. ![](img/Formula_B16391_03_199.png)is equivalent to no regularization.
    Higher values of ![](img/Formula_B16391_03_200.png) implement a stronger regularization
    effect and lead to smaller weights.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two commonly used penalty norm functions: the **L1 norm** and the
    **L2 norm**. The L1 norm is the sum of the absolute values of the weights and
    the L2 norm is the sum of the squares of the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_201.png) ![](img/Formula_B16391_03_202.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B16391_03_203.png) and ![](img/Formula_B16391_03_204.png) are
    both common methods to avoid overfitting with one big difference. ![](img/Formula_B16391_03_205.png)
    regularization generally leads to smaller weights but lacks the ability to reduce
    the weights all the way to zero. On the other hand, ![](img/Formula_B16391_03_206.png)
    regularization allows for a few larger weights while reducing all other weights
    to zero. When designing a loss function, it is also possible to use a mixture
    of both ![](img/Formula_B16391_03_206.png) and ![](img/Formula_B16391_03_208.png)
    regularization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, you can also apply regularization terms to weights of selected
    layers. Three different norm regularizations have been designed to act on single
    layers: **kernel regularization**, **bias regularization**, and **activity regularization**.'
  prefs: []
  type: TYPE_NORMAL
- en: Kernel regularization penalizes the weights, but not the biases; bias regularization
    penalizes the biases only; and activity regularization leads to smaller output
    values for the selected layer.
  prefs: []
  type: TYPE_NORMAL
- en: Dropout
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another common approach in machine learning to avoid overfitting is to introduce
    the dropout technique, which is another regularization technique.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is, at each training iteration, to ignore (drop) randomly some of the
    neurons in either the input layer or a hidden layer with all its input and output
    connections. At each iteration, different neurons are dropped. Therefore, the
    number of neurons in the architecture, and which of them are trained, effectively
    changes from iteration to iteration. The randomization introduced in this way
    helps to control the overfitting effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dropout makes sure that individual neurons and layers do not rely on single
    neurons in the preceding layers, thus becoming more robust and less prone to overfitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16 – The dropout technique selects some neurons in each layer and
    drops them from being updated in the current training iteration. The full network
    on the left is trained only partially in the four training iterations described
    on the right.](img/B16391_03_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 – The dropout technique selects some neurons in each layer and drops
    them from being updated in the current training iteration. The full network on
    the left is trained only partially in the four training iterations described on
    the right.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dropout** is applied to each layer of the network separately. This often
    translates into a temporary layer, the dropout layer, being inserted after the
    layer we want to randomize. The dropout layer controls how many neurons of the
    previous layer are dropped at each training iteration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To control how many neurons in a layer are dropped, a new parameter is introduced:
    the **drop rate**. The drop rate defines the fraction of neurons in the layer
    that should be dropped from training at each iteration.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are two quick tips for dropout:'
  prefs: []
  type: TYPE_NORMAL
- en: First, dropout leads to layers with fewer neurons and therefore reduces the
    layer capacity. It is recommended to start with a high number of neurons per layer.
  prefs: []
  type: TYPE_NORMAL
- en: Second, dropout is only applied to the input or hidden layers, not to the output
    layer since we want the response of the model to always be the same at each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Early Stopping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another option to avoid overfitting is to stop the training process before the
    network starts overfitting, which is known as **early stopping**. To detect the
    point where the algorithm starts to fit the training data better than the test
    data, an additional validation set with new data is used. During training, the
    network performances are monitored on both the training set and the validation
    set. At the beginning of the training phase, the network performance on both the
    training and validation sets improves. At some point, though, the performance
    of the network on the training set keeps improving while on the validation set
    it starts deteriorating. Once the performance starts to get worse on the validation
    set, the training is stopped.
  prefs: []
  type: TYPE_NORMAL
- en: Other Commonly used Layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, we have introduced two different kinds of layers: dense layers to design
    fully connected neural networks with different activation functions and the dropout
    layer for regularization. With these layers, you can design, for example, an autoencoder,
    as we will do in [*Chapter 5*](B16391_05_Final_NM_ePUB.xhtml#_idTextAnchor152),
    *Autoencoder for Fraud Detection*. But actually, there are many more layers available
    for all kinds of different tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Layers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One area where neural networks are extremely powerful is image analysis, for
    example, image classification. Feedforward neural networks are also frequently
    used in this area. Often, though, the sequence of dense layers is not used alone,
    but in combination with another series of convolutional layers. **Convolutional
    layers** are placed after the input of the neural network, to extract features
    and then create a better representation of the image to pass to the next dense
    layers – the feedforward architecture – for the classification. These networks
    are called **Convolutional Neural Networks**, **CNNs** for short.
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316), *Convolutional
    Neural Networks for Image Classification*, explains in detail how convolutional
    layers work. It will also introduce some other related neural layers that are
    suitable to analyze data with spatial relationships, such as the flatten layer
    and the max pooling layer.'
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A family of neural networks that doesn't belong to feedforward networks is that
    of **Recurrent Neural Networks**, **RNNs** for short. RNNs are obtained by introducing
    auto- or backward connections (recurrent connections) into feedforward neural
    networks. This allows the network to take context into account, since it remembers
    inputs from the past, and therefore it can capture the dynamic of a signal. These
    networks are really powerful when it comes to sequential data, such as times series
    data or text.
  prefs: []
  type: TYPE_NORMAL
- en: Different layers for RNNs have been introduced in the past, for example, **Long
    Short-Term Memory** (**LSTM**) layers or **Gated Recurrent Unit** (**GRU**) layers.
    [*Chapter 6*](B16391_06_Final_VK_ePUB.xhtml#_idTextAnchor181), *Recurrent Neural
    Networks for Demand Prediction*, covers RNNs in detail as well as the architecture
    of LSTM units.
  prefs: []
  type: TYPE_NORMAL
- en: Training a Neural Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After network architecture and activation functions, the last design step before
    you can start training a neural network is the choice of loss function.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with an overview of possible loss functions for regression, binary
    classification, and multiclass classification problems. Then, we will introduce
    some optimizers and additional training parameters for the training algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to train a feedforward neural network, an appropriate error function,
    often called a **loss function**, and a matching last layer have to be selected.
    Let's start with an overview of commonly used loss functions for regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions for Regression Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the case of a regression problem, where the goal is to predict one single
    numerical value, the output layer should have one unit only and use the linear
    activation function. Possible loss functions to train this kind of network must
    refer to numerical error metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean Squared Error** (**MSE**) **Loss**: The mean squared error is the default
    error metric for regression problems. For ![](img/Formula_B16391_03_209.png) training
    samples, it is calculated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_210.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_211.png) are the true values and ![](img/Formula_B16391_03_212.png)
    are the predicted values. The MSE gives more importance to large error values
    and it is always positive. A perfect predictor would have an ![](img/Formula_B16391_03_213.png)
    of ![](img/Formula_B16391_03_214.png).
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean Squared Logarithmic Error** (**MSLE**) **Loss**: The MSLE is a loss
    function that penalizes large errors less than the MSE. It is calculated by applying
    the logarithm on the predicted and the true values, before using the MSE. For
    ![](img/Formula_B16391_03_215.png) training samples, it is calculated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_216.png)'
  prefs: []
  type: TYPE_IMG
- en: MSLE applies to numbers greater or equal to ![](img/Formula_B16391_03_158.png),
    such as prices. 1 is added to both ![](img/Formula_B16391_03_218.png) and ![](img/Formula_B16391_03_219.png)
    to avoid having ![](img/Formula_B16391_03_220.png)
  prefs: []
  type: TYPE_NORMAL
- en: This loss function is recommended if the range of the target values is large
    and larger errors shouldn't be penalized significantly more than smaller errors.
    The MSLE is always positive and a perfect model has a loss of ![](img/Formula_B16391_03_221.png).
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean Absolute Error** (**MAE**) **Loss**: The MAE loss function is a more
    robust loss function with regards to outliers. This means it punishes large errors
    even less than the previous two loss functions, MSE and MSLE. For ![](img/Formula_B16391_03_222.png)
    training samples, it is calculated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_223.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In summary, we can say that we can choose between three different loss functions
    for regression problems: MSE, MSLE, and MAE. Let''s continue with loss functions
    for binary and multiclass classification problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions for Binary Classification Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The common approach for binary classification is to encode the two classes with
    ![](img/Formula_B16391_03_224.png) and ![](img/Formula_B16391_03_225.png) and
    to train a network to predict the probability for class ![](img/Formula_B16391_03_226.png).
    Here the output layer consists of just one unit with the sigmoid activation function.
    For this approach, the recommended default loss function is **binary cross entropy**.
  prefs: []
  type: TYPE_NORMAL
- en: 'On a training set of ![](img/Formula_B16391_03_227.png) samples, the binary
    cross-entropy can be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_228.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_229.png) is the class label, the true value
    (![](img/Formula_B16391_03_230.png) 1) for the *i*th sample in the training set,
    and ![](img/Formula_B16391_03_231.png) is the probability predicted by the network
    for that class. Since this a binary classification problem, the second part of
    the loss function calculates exactly the same value for the other class. ![](img/Formula_B16391_03_232.png)
    is the predicted value ![](img/Formula_B16391_03_233.png) in the previously shown
    loss functions.
  prefs: []
  type: TYPE_NORMAL
- en: Other possible loss functions for binary classification problems are **Hinge**
    and **Squared Hinge**. In this case, the two classes have to be encoded as ![](img/Formula_B16391_03_150.png)
    and ![](img/Formula_B16391_03_175.png) and therefore the unit in the output layer
    must use the tanh activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions for Multiclass Classification Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In multiclass classification problems, usually, each class is represented by
    an integer value (class = 1, 2, 3, …) and a one-hot encoding is used to represent
    the different classes. The output layer should have as neural units as many classes
    all with softmax activation function, so as to predict a score that can be interpreted
    as the probability of each class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default loss function for multiclass classification problems is **categorical
    cross-entropy**. On a training set of ![](img/Formula_B16391_03_209.png) samples,
    the categorical cross-entropy can be calculated as an extension to C classes of
    the binary cross-entropy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_237.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_238.png) is the class label k, the true value
    (![](img/Formula_B16391_03_239.png) 1) for the *i*th sample in the training set,
    and ![](img/Formula_B16391_03_240.png) is the corresponding probability predicted
    by the network for class *k*. Again, ![](img/Formula_B16391_03_241.png) is the
    predicted value ![](img/Formula_B16391_03_242.png) by output neuron k for training
    sample *i*.
  prefs: []
  type: TYPE_NORMAL
- en: For multiclass classification problems with too many different classes, such
    as language modeling where each word in the dictionary is one class, **sparse
    categorical cross-entropy** is used.
  prefs: []
  type: TYPE_NORMAL
- en: Another commonly used loss function here is the **Kullback-Leibler divergence**.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the commonly used loss functions, as introduced previously, it
    is also possible to define custom loss functions to best fit the use case at hand.
  prefs: []
  type: TYPE_NORMAL
- en: Parameters and Optimization of the Training Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that our network is designed, using the correct activation function in
    the output layer as well as an appropriate loss function, we can start training
    the network. Modern training algorithms are generally based on the SGD strategy,
    using backpropagation to update the values of the network weights. Over the last
    few years, different variants of SGD algorithms (optimizers) have been produced,
    optimized to train networks on datasets with different properties. For example,
    **Adagrad** and its extension **Adadelta** work well on sparse data. **Adam**
    involves a moving average of the gradient and of the squared gradient for the
    weight updates. The Keras documentation page gives an overview of all the available
    training algorithms: [https://keras.io/optimizers/](https://keras.io/optimizers/).'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation is typically referred to as the algorithm that calculates the
    gradients of the weights. The algorithm to train a neural network is usually some
    variant of SGD and it makes use of backpropagation to update the network weights.
  prefs: []
  type: TYPE_NORMAL
- en: A big role in the training algorithm is played by the **learning rate** ![](img/Formula_B16391_03_243.png).
    The learning rate defines the size of the step taken along the direction of the
    gradient descent on the error surface during the learning phase. A too-small ![](img/Formula_B16391_03_244.png)
    produces tiny steps and therefore takes a long time to reach the minimum of the
    loss function, especially if the loss function happens to have flat slopes. A
    too-large ![](img/Formula_B16391_03_245.png) produces large steps that might overshoot
    and miss the minimum of the loss function, especially if the loss function is
    narrow and with steep slopes. The choice of the right value of learning rate ![](img/Formula_B16391_03_246.png)
    is critical. A possible solution could be to use an adaptive learning rate, starting
    large and progressively decreasing with the number of training iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 3.17*, there are examples for moving on the loss function with a
    too-small, too-large, and adaptive learning rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.17 – The progressive decrease of the error with a too-small learning
    rate  (on the left), a too-large learning rate  (in the center), and an adaptive
    learning rate  in a one-dimensional weight space](img/B16391_03_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 – The progressive decrease of the error with a too-small learning
    rate ![](img/Formula_B16391_03_247.png) (on the left), a too-large learning rate
    ![](img/Formula_B16391_03_248.png) (in the center), and an adaptive learning rate
    ![](img/Formula_B16391_03_249.png) in a one-dimensional weight space
  prefs: []
  type: TYPE_NORMAL
- en: All loss functions are defined as a sum over all training samples. This leads
    to algorithms that update the weights after all training samples have passed through
    the network. This training strategy is called **batch training**. It is the correct
    way to proceed; however, it is also computationally expensive and often slow.
  prefs: []
  type: TYPE_NORMAL
- en: The alternative is to use the **online training** strategy, where weights are
    updated after the pass of each training sample. This strategy is less computationally
    expensive, but it is just an approximation of the original backpropagation algorithm.
    It is also prone to running into oscillations. In this case, it is good practice
    to use smaller values for the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: Virtually all modern deep learning frameworks make use of a mixture of batch
    and online training, where they use small batches of training examples to perform
    a single update step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Momentum** term is added to the weight delta ![](img/Formula_B16391_03_250.png)
    to increase the weight update as long as they have the same sign as the previous
    delta. Momentum speeds up the training on long flat error surfaces and can help
    the network pass a local minimum. The weight update then would include an extra
    term:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_03_251.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_03_252.png) is the current training iteration and
    ![](img/Formula_B16391_03_253.png) is the momentum term.
  prefs: []
  type: TYPE_NORMAL
- en: Additional Training Parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Two other important setting options for the training process are the training
    batch size and the number of epochs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Training batch size**: The training **batch size** defines the number of
    samples used in one training iteration. If the training batch size is set to the
    full number of samples in the training set, the training will run in the so-called
    batch mode, which is computationally expensive and slow. In general, it is recommended
    to train a model in mini-batch mode, where only part of the data is used for each
    iteration. It is recommended to shuffle the data before each epoch, to have different
    batches in different epochs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of epochs**: The number of epochs defines the number of cycles that
    run over the full training dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To summarize, the algorithm goes through the whole training set ![](img/Formula_B16391_03_031.png)
    times, where ![](img/Formula_B16391_03_255.png) is the number of epochs. Each
    epoch consists of a number of iterations and, for each iteration, a subset of
    the training set (a batch) is used. At the end of each iteration, weights are
    updated following the online training strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have reached the end of this chapter, where we have learned the basic theoretical
    concepts behind neural networks and deep learning networks. All of this will be
    helpful to understand the steps for the practical implementation of deep learning
    networks described in the coming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We started with the artificial neuron and moved on to describe how to assemble
    and train a network of neurons, a fully connected feedforward neural network,
    via a variant of the gradient descent algorithm, using the backpropagation algorithm
    to calculate the gradient.
  prefs: []
  type: TYPE_NORMAL
- en: We concluded the chapter with a few hints on how to design and train a neural
    network. First, we described some commonly used network topologies, neural layers,
    and activation functions to design the appropriate neural architecture.
  prefs: []
  type: TYPE_NORMAL
- en: We then moved to analyze the effects of some parameters involved in the training
    algorithm. We introduced a few more parameters and techniques to optimize the
    training algorithm against a selected loss function.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how you can perform all the steps we introduced
    in this chapter using KNIME Analytics Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Questions and Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Test how well you have understood the concepts in this chapter by answering
    the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A feedforward neural network is an architecture where:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Each neuron from the previous layer is connected to each neuron in the next
    layer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. There are auto and backward connections.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. There is just one unit in the output layer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. There are as many input units as there are output units.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Why do we need hidden layers in a feedforward neural network?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. For more computational power
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. To speed up calculations
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. To implement more complex functions
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. For symmetry
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The backpropagation algorithm updates the network weights proportionally to:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. The output errors backpropagated through the network
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. The input values forward propagated through the network
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. The batch size
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. The deltas calculated at the output layer and backpropagated through the
    network
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which loss function is commonly used for a multiclass classification problem?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. MAE
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. RMSE
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Categorical cross-entropy
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Binary cross-entropy
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What kind of networks are suited for image analysis?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. RNNs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. CNNs
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Fully connected feedforward networks
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. Autoencoders
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How is the last layer of a network commonly configured when solving a binary
    classification problem?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Two units with the sigmoid activation function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. One unit with the linear activation function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. Two units with the ReLU activation function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. One unit with the sigmoid activation function
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When are RNNs used?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. On data with many missing values
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b. On image data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c. On sequential data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d. On sparse datasets
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
