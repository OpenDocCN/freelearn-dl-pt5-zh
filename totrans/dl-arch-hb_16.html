<html><head></head><body>
<div id="_idContainer143">
<h1 class="chapter-number" id="_idParaDest-229"><a id="_idTextAnchor238"/><span class="koboSpan" id="kobo.1.1">16</span></h1>
<h1 id="_idParaDest-230"><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.2.1">Governing Deep Learning Models</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Deploying a model is just the beginning of its journey. </span><span class="koboSpan" id="kobo.3.2">Once it’s out in the real world, it’s like a living thing – it requires efficient use to make the most of it, upgrades to stay sharp, care to perform consistently well, and, eventually, a graceful exit. </span><span class="koboSpan" id="kobo.3.3">Imagine a car on the road: you start driving, but you also need to use the car effectively, fuel it, maintain it, and eventually replace it or its components. </span><span class="koboSpan" id="kobo.3.4">The same goes for deep learning models </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">in action.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Model governance acts as the guiding force that oversees the use of a model and maintains constant vigilance over its performance and context to ensure the continuous, consistent, and dependable delivery of value through the model. </span><span class="koboSpan" id="kobo.5.2">In the realm of deep learning, model governance is crucial for ensuring that these complex models adhere to the highest standards of quality, reliability, </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">and fairness.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">This chapter delves into the three fundamental pillars of model governance for deep learning models: steering the ship of model utilization, which focuses on the appropriate application of deep learning models, keeping a watchful eye on its performance on all fronts with model monitoring, and ensuring it stays at its best in the ever-evolving landscape of deep learning with model maintenance. </span><span class="koboSpan" id="kobo.7.2">By implementing a robust model governance framework, deep learning architects can effectively manage the challenges posed by these intricate models and harness their immense potential to drive valuable insights and decisions in production. </span><span class="koboSpan" id="kobo.7.3">In this chapter, we will learn about these pillars of model governance in detail. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.8.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.9.1">.1</span></em><span class="koboSpan" id="kobo.10.1"> shows a holistic view of the concept of model governance that we will explore in </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">this chapter:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer130">
<span class="koboSpan" id="kobo.12.1"><img alt="Figure 16.1 – Holistic overview of model governance in the context of concepts that will be introduced in this chapter" src="image/B18187_16_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.13.1">Figure 16.1 – Holistic overview of model governance in the context of concepts that will be introduced in this chapter</span></p>
<p><span class="koboSpan" id="kobo.14.1">Specifically, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.16.1">Governing deep learning </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">model utilization</span></span></li>
<li><span class="koboSpan" id="kobo.18.1">Governing a deep learning model </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">through monitoring</span></span></li>
<li><span class="koboSpan" id="kobo.20.1">Governing a deep learning model </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">through maintenance</span></span></li>
</ul>
<h1 id="_idParaDest-231"><a id="_idTextAnchor240"/><span class="koboSpan" id="kobo.22.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.23.1">This chapter covers a practical example of monitoring metrics and setting up alerts, leveraging the code from the previous tutorial in </span><a href="B18187_15.xhtml#_idTextAnchor217"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.24.1">Chapter 15</span></em></span></a><span class="koboSpan" id="kobo.25.1">, </span><em class="italic"><span class="koboSpan" id="kobo.26.1">Deploying Deep Learning Models in Production</span></em><span class="koboSpan" id="kobo.27.1">. </span><span class="koboSpan" id="kobo.27.2">This tutorial requires you to have a Linux machine with an NVIDIA GPU device ideally in Ubuntu with Python 3.10 and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.28.1">nvidia-docker</span></strong><span class="koboSpan" id="kobo.29.1"> tool installed. </span><span class="koboSpan" id="kobo.29.2">Additionally, we will require the following Python libraries to </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">be installed:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.31.1">numpy</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.32.1">transformers==4.21.3</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.33.1">nvidia-tensorrt==8.4.1.5</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.34.1">torch==1.12.0</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.35.1">transformers-deploy</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.36.1">Tritonclient</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.37.1">The code files are available on </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">GitHub: </span></span><a href="https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_16"><span class="No-Break"><span class="koboSpan" id="kobo.39.1">https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_16</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.40.1">.</span></span></p>
<h1 id="_idParaDest-232"><a id="_idTextAnchor241"/><span class="koboSpan" id="kobo.41.1">Governing deep learning model utilization</span></h1>
<p><span class="koboSpan" id="kobo.42.1">Model utilization, the first</span><a id="_idIndexMarker1194"/><span class="koboSpan" id="kobo.43.1"> pillar of model governance for deep learning models, is crucial for the responsible and ethical deployment of these sophisticated tools. </span><span class="koboSpan" id="kobo.43.2">In this section, we will explore the integral aspects of model utilization, including guardrail filters, accountability, compliance, validation, shared access, transparency, and decision support systems. </span><span class="koboSpan" id="kobo.43.3">By comprehensively addressing these aspects, deep learning architects can ensure effective model utilization that maximizes value from the model while mitigating potential risks and unintended consequences. </span><span class="koboSpan" id="kobo.43.4">Let’s dive deeper into </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">these aspects:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.45.1">Guardrail filters</span></strong><span class="koboSpan" id="kobo.46.1">: These play a crucial role in ensuring that models operate within established boundaries, minimizing the risks associated with inaccurate or harmful predictions. </span><span class="koboSpan" id="kobo.46.2">These filters help maintain the original purpose of the models. </span><span class="koboSpan" id="kobo.46.3">While the objectives of using a model’s predictions can significantly vary based on individual use cases, several common types of guardrails are </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">widely applicable:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.48.1">Prevent harmful use on a per-prediction basis</span></strong><span class="koboSpan" id="kobo.49.1">: Harmful use of the model or its predictions can encompass a wide range of issues, including biases related to sensitive attributes, malicious attacks such as adversarial attacks, and harassment-related text generation. </span><em class="italic"><span class="koboSpan" id="kobo.50.1">Figure 16.2</span></em><span class="koboSpan" id="kobo.51.1"> shows the OpenAI ChatGPT’s way of displaying its predictions after the guardrail of harmful use has </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">been triggered.</span></span></li></ul></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer131">
<span class="koboSpan" id="kobo.53.1"><img alt="Figure 16.2 – OpenAI ChatGPT’s harmful use guardrail triggered response" src="image/B18187_16_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.54.1">Figure 16.2 – OpenAI ChatGPT’s harmful use guardrail triggered response</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.55.1">Prevent usage of unconfident predictions on a per-prediction basis</span></strong><span class="koboSpan" id="kobo.56.1">: To maintain the reliability of a model’s output, it is essential to prevent the use of predictions with low confidence. </span><span class="koboSpan" id="kobo.56.2">The issue, however, is that regression model predictions do not have prediction values that could be treated as a confidence score. </span><span class="koboSpan" id="kobo.56.3">Additionally, although classification model prediction typically has a softmax operation applied to allow predictions to add up to 1, it is not properly calibrated toward actual statistical probabilities. </span><em class="italic"><span class="koboSpan" id="kobo.57.1">Conformal predictions</span></em><span class="koboSpan" id="kobo.58.1"> are a more battle-tested statistical and robust technique to provide a robust confidence interval for each prediction, allowing for a better understanding of the model’s certainty. </span><span class="koboSpan" id="kobo.58.2">Additionally, input data that goes out of training data bounds or has drifted may deteriorate the model’s performance and can be treated as a special case of unconfident predictions without even generating </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">the predictions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.60.1">Prevent the use of an inaccurate model</span></strong><span class="koboSpan" id="kobo.61.1">: By continuously monitoring and assessing a model’s accuracy performance, one can determine when to stop the usage of a model, especially in high-risk use cases, and proceed to perform model maintenance, which is to retrain and update </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">the model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.63.1">Mitigating bias</span></strong><span class="koboSpan" id="kobo.64.1">: Guardrail filters can help minimize bias related to sensitive attributes, such as race, gender, or ethnicity. </span><span class="koboSpan" id="kobo.64.2">By preventing the model from producing predictions that may lead to discriminatory outcomes, guardrail filters contribute to a more equitable and fair application of </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">these technologies.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.66.1">Prevent known data conditions that can negatively affect the model’s performance</span></strong><span class="koboSpan" id="kobo.67.1">: For example, face recognition systems should only predict on frontal, unobstructed faces without masks or glasses. </span><span class="koboSpan" id="kobo.67.2">Adversarial </span><a id="_idIndexMarker1195"/><span class="koboSpan" id="kobo.68.1">performance analysis, introduced in </span><em class="italic"><span class="koboSpan" id="kobo.69.1">Chapter 14</span></em><span class="koboSpan" id="kobo.70.1">, </span><em class="italic"><span class="koboSpan" id="kobo.71.1">Analyzing Adversarial Performance</span></em><span class="koboSpan" id="kobo.72.1">, must be performed prior to deployment to identify the traits that could negatively affect the model’s performance. </span><span class="koboSpan" id="kobo.72.2">During deployment, appropriate thresholds of the identified traits that are estimated to deteriorate the model’s performance can be applied as a guardrail for </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">prediction prevention.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.74.1">Implement human-in-the-loop oversight only for critical predictions</span></strong><span class="koboSpan" id="kobo.75.1">: In high-stakes scenarios, such as medical drug recommendations, it is vital to involve human experts in the decision-making process, and higher-level experts when specific predictions </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">are made.</span></span></li>
</ul>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.77.1">Accountability</span></strong><span class="koboSpan" id="kobo.78.1">: This entails the clear assignment of roles and responsibilities, and addresses questions related to model ownership, compliance with regulations, training data, and the approval process at each stage of development. </span><span class="koboSpan" id="kobo.78.2">Accountability is a critical aspect of AI and machine learning systems, ensuring that there is a clear understanding of roles, responsibilities, and ownership throughout the model’s life cycle. </span><span class="koboSpan" id="kobo.78.3">It encompasses the following </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">two facets:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.80.1">Model ownership</span></strong><span class="koboSpan" id="kobo.81.1">: Clearly defining who owns the model is essential for establishing accountability. </span><span class="koboSpan" id="kobo.81.2">This includes determining the parties responsible for the model’s development, maintenance, and updates, as well as those who will be held liable for any adverse consequences resulting from the model’s use. </span><span class="koboSpan" id="kobo.81.3">Some additional key considerations related to model ownership are </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">the following:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.83.1">Handling personnel changes</span></strong><span class="koboSpan" id="kobo.84.1">: In the event of a model owner’s departure or role change within the organization, a well-defined process should be in place to transfer ownership and responsibilities to another suitable individual or team. </span><span class="koboSpan" id="kobo.84.2">This ensures that the model continues to receive proper oversight and maintenance and that accountability </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">remains clear.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.86.1">Shared access and default admin roles</span></strong><span class="koboSpan" id="kobo.87.1">: To promote effective model governance and minimize potential disruptions, it is vital to establish shared access and default admin roles. </span><span class="koboSpan" id="kobo.87.2">This allows multiple team members to oversee the model’s development, maintenance, and updates, reducing the dependency on a single individual. </span><span class="koboSpan" id="kobo.87.3">Such shared access should be accompanied by clear guidelines on roles and responsibilities to avoid confusion and </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">maintain accountability.</span></span></li></ul></li><li><strong class="bold"><span class="koboSpan" id="kobo.89.1">Handling open source models</span></strong><span class="koboSpan" id="kobo.90.1">: Proprietary models are typically developed within a single organization, which makes it straightforward to deal with accountability with the considerations discussed previously. </span><span class="koboSpan" id="kobo.90.2">In open source models, the development process often involves multiple contributors from diverse backgrounds, which makes establishing accountability more challenging. </span><span class="koboSpan" id="kobo.90.3">To address this, it is essential to provide clear guidelines for contributions, maintain transparent documentation of the model’s development history, and implement community-driven governance structures or assign a core group of maintainers to oversee the project. </span><span class="koboSpan" id="kobo.90.4">As an alternative, a key model owner can be established in an organization that assumes all responsibility for using the open source model in </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">that organization.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.92.1">Predictions ownership</span></strong><span class="koboSpan" id="kobo.93.1">: Predictions ownership in high-risk use cases is crucial for maintaining accountability and ensuring accurate, reliable outcomes. </span><span class="koboSpan" id="kobo.93.2">Since raw predictions may not always be easily understandable, post-processing</span><a id="_idIndexMarker1196"/><span class="koboSpan" id="kobo.94.1"> steps are often needed to convert them into more digestible insights or nested outcomes. </span><span class="koboSpan" id="kobo.94.2">Approvals of the outcomes at each post-processing stage further ensure the quality and relevance of the final outcomes, fostering the responsible and effective use of AI and machine </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">learning models.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.96.1">Model and prediction transparency</span></strong><span class="koboSpan" id="kobo.97.1">: This is essential for fostering trust and understanding in AI systems. </span><span class="koboSpan" id="kobo.97.2">This entails offering clear explanations and relevant information about the model’s development, including its architecture, training data, and methodology. </span><span class="koboSpan" id="kobo.97.3">Providing such insights enables users to grasp how the model generates predictions and ensures that the AI system aligns with ethical and responsible practices, ultimately contributing to better decision-making and more reliable outcomes. </span><span class="koboSpan" id="kobo.97.4">These can be the same explanations that were used to understand and compare different models and predictions during the model </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">development stage.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.99.1">Decision support systems</span></strong><span class="koboSpan" id="kobo.100.1">: This involves building interfaces or platforms that enable decision-makers to interact with model predictions and insights. </span><span class="koboSpan" id="kobo.100.2">This includes providing user-friendly dashboards, reports, and visualization tools in the system while incorporating business rules, regulations, and policies into the decision-making process. </span><span class="koboSpan" id="kobo.100.3">This is again useful in high-risk </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">use cases.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.102.1">Now, we will dive into the second </span><a id="_idIndexMarker1197"/><span class="koboSpan" id="kobo.103.1">component of model governance, which is about monitoring </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">deployed models.</span></span></p>
<h1 id="_idParaDest-233"><a id="_idTextAnchor242"/><span class="koboSpan" id="kobo.105.1">Governing a deep learning model through monitoring</span></h1>
<p><span class="koboSpan" id="kobo.106.1">Model monitoring is essential for </span><a id="_idIndexMarker1198"/><span class="koboSpan" id="kobo.107.1">maintaining the performance, reliability, and fairness of deep learning models throughout their life cycle. </span><span class="koboSpan" id="kobo.107.2">As data landscapes and business requirements evolve, continuous monitoring enables the early detection of issues such as model drift, performance degradation, and potential biases, thereby ensuring the consistent delivery of accurate and valuable predictions. </span><span class="koboSpan" id="kobo.107.3">This process involves the collection and analysis of key performance metrics, the ongoing evaluation of model outputs against ground-truth data, and the identification of any emerging trends that could impact the model’s efficacy. </span><span class="koboSpan" id="kobo.107.4">By implementing a robust model monitoring framework, deep learning architects can proactively address challenges and make informed decisions about model updates, refinements, and retraining, ultimately optimizing the model’s value and mitigating risks associated with </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">its deployment.</span></span></p>
<p><span class="koboSpan" id="kobo.109.1">Model monitoring holds value only when it results in corrective actions addressing deteriorating performance or concerning conditions. </span><span class="koboSpan" id="kobo.109.2">Thus, the objective of monitoring should be to identify and rectify undesirable behavior. </span><span class="koboSpan" id="kobo.109.3">The actions that can be taken are more broadly grouped into the third pillar of model governance, called model maintenance, which we will discuss separately in the next section. </span><span class="koboSpan" id="kobo.109.4">Now, let’s delve into the various categories and specific metrics for a deployed machine learning model, accompanied by examples of conditions that can prompt the initiation of model </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">maintenance procedures:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.111.1">Model accuracy-based performance metrics</span></strong><span class="koboSpan" id="kobo.112.1">: These are the typical model evaluation metrics we introduced</span><a id="_idIndexMarker1199"/><span class="koboSpan" id="kobo.113.1"> more comprehensively in </span><a href="B18187_10.xhtml#_idTextAnchor161"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.114.1">Chapter 10</span></em></span></a><span class="koboSpan" id="kobo.115.1">, </span><em class="italic"><span class="koboSpan" id="kobo.116.1">Exploring Model Evaluation Methods</span></em><span class="koboSpan" id="kobo.117.1">, such as accuracy, recall, precision, F1 score, AUC-ROC, and log-loss. </span><span class="koboSpan" id="kobo.117.2">The same metrics that were used for model evaluation in the model development and delivery model insights stage should be reused here. </span><span class="koboSpan" id="kobo.117.3">These metrics can be monitored when the true labels can be obtained at a future time, in </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">two ways:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.119.1">Naturally</span></strong><span class="koboSpan" id="kobo.120.1">: When the use case is a time-series use case to predict a future target or the target is just not immediately accessible to the model owner, the targets can be obtained in the </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">future naturally</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.122.1">Manual labeling</span></strong><span class="koboSpan" id="kobo.123.1">: Labeling is recommended to be carried out in a regular cadence with a sample of the historical production input data to verify the validity of the </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">model performance</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.125.1">Conditions that can cause a trigger of model maintenance here are using the same use case validity thresholds that were referred to in the model building and evaluation experimentation process. </span><span class="koboSpan" id="kobo.125.2">As emphasized in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.126.1">Chapter 10</span></em></span><span class="koboSpan" id="kobo.127.1">, </span><em class="italic"><span class="koboSpan" id="kobo.128.1">Exploring Model Evaluation Methods</span></em><span class="koboSpan" id="kobo.129.1">, this threshold should ideally be tied to the business metrics threshold in </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">some way.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.131.1">Data quality metrics</span></strong><span class="koboSpan" id="kobo.132.1">: Data quality metrics provide essential insights into the validity, characteristics, and consistency of the input data. </span><span class="koboSpan" id="kobo.132.2">Data quality is linked to the accuracy and bias performance of the model and thus any deviations from the norm can potentially cause accuracy degradations. </span><span class="koboSpan" id="kobo.132.3">Examples of such metrics are </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">the following:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.134.1">Missing or incomplete data count</span></strong><span class="koboSpan" id="kobo.135.1">: This refers to the number of instances in the dataset where the data is either absent or not fully available. </span><span class="koboSpan" id="kobo.135.2">This can impact the accuracy and reliability of the model, as it may not have enough information to infer a </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">prediction from.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.137.1">Invalid data bounds count</span></strong><span class="koboSpan" id="kobo.138.1">: This refers to the instances where data values fall outside the acceptable or expected range. </span><span class="koboSpan" id="kobo.138.2">This can lead to incorrect model predictions, as the model may infer from incorrect data points that were not </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">learned from.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.140.1">Outlier and anomaly indicator metrics</span></strong><span class="koboSpan" id="kobo.141.1">: They are used to identify unusual or extreme data points that deviate significantly from the overall pattern or trend in the dataset. </span><span class="koboSpan" id="kobo.141.2">This has the same root cause as invalid </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">data bounds.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.143.1">Data drift</span></strong><span class="koboSpan" id="kobo.144.1">: This occurs when the distribution of input features in the data changes over time. </span><span class="koboSpan" id="kobo.144.2">This can happen due to various reasons, such as evolving data sources, changing user behavior, or external factors influencing the data generation process. </span><span class="koboSpan" id="kobo.144.3">Data drift may lead to a decline in model performance as the model was trained on a different distribution of data and may not generalize well to the new distribution. </span><span class="koboSpan" id="kobo.144.4">Monitoring for data drift helps in identifying when retraining or adjusting the model is necessary to maintain its accuracy and effectiveness. </span><span class="koboSpan" id="kobo.144.5">In </span><a href="B18187_17.xhtml#_idTextAnchor247"><em class="italic"><span class="koboSpan" id="kobo.145.1">Chapter 17</span></em></a><span class="koboSpan" id="kobo.146.1">, </span><em class="italic"><span class="koboSpan" id="kobo.147.1">Managing Drift Effectively in a Dynamic Environment</span></em><span class="koboSpan" id="kobo.148.1">, we will dive into the techniques that we can use to detect data drift focused on deep learning-specific </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">data inputs.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.150.1">Concept drift</span></strong><span class="koboSpan" id="kobo.151.1">: It refers to the change in the relationship between input features and the target variable over time. </span><span class="koboSpan" id="kobo.151.2">This change </span><a id="_idIndexMarker1200"/><span class="koboSpan" id="kobo.152.1">can cause a previously accurate model to degrade in performance as the model’s</span><a id="_idIndexMarker1201"/><span class="koboSpan" id="kobo.153.1"> learned patterns no longer align with the evolving relationships. </span><span class="koboSpan" id="kobo.153.2">This is also related to the label consistency metric introduced in the data quality section in </span><a href="B18187_01.xhtml#_idTextAnchor015"><em class="italic"><span class="koboSpan" id="kobo.154.1">Chapter 1</span></em></a><span class="koboSpan" id="kobo.155.1">, </span><em class="italic"><span class="koboSpan" id="kobo.156.1">Deep Learning </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.157.1">Life Cycle</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.159.1">System performance metrics</span></strong><span class="koboSpan" id="kobo.160.1">: These metrics help ensure that the deployed model meets the operational requirements. </span><span class="koboSpan" id="kobo.160.2">The key subgroups under system performance metrics are </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">the following:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.162.1">Inference latency</span></strong><span class="koboSpan" id="kobo.163.1">: Refers to the measurement of the time taken by the model to generate predictions or output from the input data. </span><span class="koboSpan" id="kobo.163.2">Low latency is crucial for real-time applications and user experiences, as it ensures the model provides quick and </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">timely results.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.165.1">Throughput</span></strong><span class="koboSpan" id="kobo.166.1">: Measures the number of predictions or outputs the model can generate within a specific time frame. </span><span class="koboSpan" id="kobo.166.2">High throughput is vital for handling large-scale data processing and maintaining the desired level of performance, especially in </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">high-demand scenarios.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.168.1">Resource utilization</span></strong><span class="koboSpan" id="kobo.169.1">: Evaluates the efficiency of resource usage, such as CPU, memory, and storage, by the model during its operation. </span><span class="koboSpan" id="kobo.169.2">Optimizing resource utilization ensures that the model can run efficiently on the available infrastructure, reducing costs and allowing for </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">better scalability.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.171.1">Queueing delay and request counts</span></strong><span class="koboSpan" id="kobo.172.1">: Queueing delay refers to the waiting time experienced by each request before being processed by the deployed deep learning model. </span><span class="koboSpan" id="kobo.172.2">Monitoring the queueing delay and the number of requests can help identify potential bottlenecks in the system and optimize the model’s capacity to handle multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">requests simultaneously.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.174.1">Alert and incident metrics</span></strong><span class="koboSpan" id="kobo.175.1">: These metrics help ensure timely identification and resolution of problems, enabling optimal system performance. </span><span class="koboSpan" id="kobo.175.2">They are </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">as follows:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.177.1">Alert frequency</span></strong><span class="koboSpan" id="kobo.178.1">: This metric refers to the number of alerts generated over a specific time period, indicating potential issues or anomalies in the system. </span><span class="koboSpan" id="kobo.178.2">Monitoring alert frequency helps identify patterns and trends, enabling proactive measures to prevent or mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">recurring problems.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.180.1">Alert severity</span></strong><span class="koboSpan" id="kobo.181.1">: This measures the degree of impact an issue has on overall system performance. </span><span class="koboSpan" id="kobo.181.2">By categorizing alerts based on severity, it is possible to prioritize and address the most critical issues first, ensuring efficient use of resources and minimizing negative impacts on </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">the system.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.183.1">Incident resolution time</span></strong><span class="koboSpan" id="kobo.184.1">: This is the time taken to address and resolve incidents arising from alerts. </span><span class="koboSpan" id="kobo.184.2">Tracking this metric helps evaluate the effectiveness of the incident response process and identify areas for improvement, ultimately leading to faster resolution times and better </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">system performance.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.186.1">Model fairness and bias metrics</span></strong><span class="koboSpan" id="kobo.187.1">: The same metrics that were introduced in </span><a href="B18187_13.xhtml#_idTextAnchor196"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.188.1">Chapter 13</span></em></span></a><span class="koboSpan" id="kobo.189.1">, </span><em class="italic"><span class="koboSpan" id="kobo.190.1">Exploring Bias and Fairness</span></em><span class="koboSpan" id="kobo.191.1">, to </span><a id="_idIndexMarker1202"/><span class="koboSpan" id="kobo.192.1">compare different models in development, can also be applied to monitor model fairness</span><a id="_idIndexMarker1203"/><span class="koboSpan" id="kobo.193.1"> on a </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">deployed model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.195.1">Business metrics</span></strong><span class="koboSpan" id="kobo.196.1">: Monitoring business-related metrics is crucial for evaluating the impact of a deployed deep learning model on the organization’s goals and ensuring its alignment with business objectives. </span><span class="koboSpan" id="kobo.196.2">Not everything can be monitored with numbers, so figure out the components that are quantifiable. </span><span class="koboSpan" id="kobo.196.3">Here are some metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">to consider:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.198.1">Key Performance Indicators</span></strong><span class="koboSpan" id="kobo.199.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.200.1">KPIs</span></strong><span class="koboSpan" id="kobo.201.1">): Identify </span><a id="_idIndexMarker1204"/><span class="koboSpan" id="kobo.202.1">and track KPIs that are directly influenced by the model’s predictions, such as revenue, customer satisfaction, return on investment, or operational efficiency. </span><span class="koboSpan" id="kobo.202.2">This helps assess the model’s overall contribution to </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">the business.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.204.1">User adoption and engagement</span></strong><span class="koboSpan" id="kobo.205.1">: Monitor how users interact with the model, including usage patterns, frequency, and feedback. </span><span class="koboSpan" id="kobo.205.2">This can provide insights into the model’s relevance, ease of use, and overall effectiveness in addressing </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">user needs.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.207.1">Incorporating the monitoring of the various metric groups not only provides a comprehensive view of deep learning model performance, reliability, and fairness but also facilitates the identification of emerging trends and patterns. </span><span class="koboSpan" id="kobo.207.2">By closely monitoring these metrics, potential issues, such as model drift, performance degradation, and biases, can be proactively addressed, ensuring consistent delivery of accurate predictions. </span><span class="koboSpan" id="kobo.207.3">This also means that analyzing patterns from the monitored metrics is crucial in developing improvement plans to enhance deep learning model performance and address any </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">potential issues.</span></span></p>
<p><span class="koboSpan" id="kobo.209.1">To effectively analyze and consume the metrics that are monitored, it is recommended to consolidate the key metrics in a comprehensive dashboard, which allows for easy tracking and assessment of the model’s overall health, and ultimately enhances the monitoring process. </span><span class="koboSpan" id="kobo.209.2">Grafana, a popular open source analytics and monitoring platform, can effectively meet these requirements by offering a variety of features and integrations. </span><span class="koboSpan" id="kobo.209.3">As we</span><a id="_idIndexMarker1205"/><span class="koboSpan" id="kobo.210.1"> move forward, we will explore a practical tutorial on monitoring deep learning models by using NVIDIA Triton Inference Server, Prometheus, </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">and Grafana.</span></span></p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor243"/><span class="koboSpan" id="kobo.212.1">Monitoring a deployed deep learning model with NVIDIA Triton Server, Prometheus, and Grafana</span></h2>
<p><span class="koboSpan" id="kobo.213.1">NVIDIA Triton Server </span><a id="_idIndexMarker1206"/><span class="koboSpan" id="kobo.214.1">hosts</span><a id="_idIndexMarker1207"/><span class="koboSpan" id="kobo.215.1"> configured</span><a id="_idIndexMarker1208"/><span class="koboSpan" id="kobo.216.1"> metrics via a REST HTTP API in Prometheus format, offering real-time insights </span><a id="_idIndexMarker1209"/><span class="koboSpan" id="kobo.217.1">without </span><a id="_idIndexMarker1210"/><span class="koboSpan" id="kobo.218.1">persisting </span><a id="_idIndexMarker1211"/><span class="koboSpan" id="kobo.219.1">historical data. </span><span class="koboSpan" id="kobo.219.2">To persist metrics data over time, Prometheus needs to be configured to connect with NVIDIA Triton Server. </span><span class="koboSpan" id="kobo.219.3">While Prometheus tracks and logs metrics over time, it lacks visualization capabilities. </span><span class="koboSpan" id="kobo.219.4">This is where Grafana comes in. </span><span class="koboSpan" id="kobo.219.5">It’s a platform that can leverage Prometheus-logged data to create dynamic dashboards with custom graphs and tables. </span><span class="koboSpan" id="kobo.219.6">Prometheus conveniently shares its logged information through a separate REST HTTP API, facilitating Grafana’s seamless connectivity. </span><span class="koboSpan" id="kobo.219.7">Additionally, Grafana allows alert rules to be set </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">up reliably.</span></span></p>
<p><span class="koboSpan" id="kobo.221.1">The first step in monitoring is to plan the metrics that we want to monitor, which we will </span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">discuss next.</span></span></p>
<h3><span class="koboSpan" id="kobo.223.1">Choosing metrics to monitor</span></h3>
<p><span class="koboSpan" id="kobo.224.1">Any deployed model </span><a id="_idIndexMarker1212"/><span class="koboSpan" id="kobo.225.1">hosted through NVIDIA Triton Server will by default support a variety of standard metrics. </span><span class="koboSpan" id="kobo.225.2">These metrics are </span><span class="No-Break"><span class="koboSpan" id="kobo.226.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.227.1">Inference request metrics</span></strong><span class="koboSpan" id="kobo.228.1">: Success count, failure count, inference count, and </span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">execution count</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.230.1">GPU-related metrics</span></strong><span class="koboSpan" id="kobo.231.1">: Power usage, power limit, energy consumption, GPU utilization, GPU total memory, and GPU </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">used memory</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.233.1">CPU-related metrics</span></strong><span class="koboSpan" id="kobo.234.1">: CPU utilization, CPU total memory, and CPU </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">used memory</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.236.1">Response cache metrics</span></strong><span class="koboSpan" id="kobo.237.1">: Cache hit count, cache miss count, cache hit time, and cache </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">miss time</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.239.1">Note that these metrics can be manually disabled. </span><span class="koboSpan" id="kobo.239.2">In this practical example, we will be leveraging the deployed language model implementation from the previous chapter in using NVIDIA Triton Server and additionally using the Prometheus and Grafana tools. </span><span class="koboSpan" id="kobo.239.3">The default standard metrics that NVIDIA Triton Server logs are useful, but we also need potential custom metrics that can be useful for a business and are specific to a language model. </span><span class="koboSpan" id="kobo.239.4">It is well documented that NVIDIA Triton Server supports custom metrics through their C API, which means you need to develop C code! </span><span class="koboSpan" id="kobo.239.5">However, a fairly new way to support custom metrics, since NVIDIA Triton Server version 23.05, is that you can define custom metrics for NVIDIA Triton Server using Python! </span><span class="koboSpan" id="kobo.239.6">We will be exploring this new feature in our practical tutorial, where we will be exploring the following custom metrics for a language model that can </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">be useful:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.241.1">Number of tokens processed</span></strong><span class="koboSpan" id="kobo.242.1">: The larger the input data, the longer a request </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">can take</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.244.1">Number of tokens generated</span></strong><span class="koboSpan" id="kobo.245.1">: The larger the number of output tokens, the longer a request </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">can take</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.247.1">Flesch reading score</span></strong><span class="koboSpan" id="kobo.248.1">: This is a reading comprehension metric that measures how well a text can be understood, which can be a useful business metric, as generated text needs to be well understood to</span><a id="_idIndexMarker1213"/> <span class="No-Break"><span class="koboSpan" id="kobo.249.1">be useful</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.250.1">Now we are ready to dive into the </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">practical example.</span></span></p>
<h3><span class="koboSpan" id="kobo.252.1">Tracking and visualizing the chosen metrics over time</span></h3>
<p><span class="koboSpan" id="kobo.253.1">Before we start, make sure </span><a id="_idIndexMarker1214"/><span class="koboSpan" id="kobo.254.1">you have installed </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1">nvidia-docker</span></strong><span class="koboSpan" id="kobo.256.1">, Prometheus, Node Exporter, and Grafana version v10.0.3. </span><span class="koboSpan" id="kobo.256.2">Also, make sure Prometheus and Grafana are callable from any location in the command line. </span><span class="koboSpan" id="kobo.256.3">Let’s start the process in a step-by-step manner, </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">as follows:</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.258.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.259.1">We are leveraging the code from </span><a href="B18187_15.xhtml#_idTextAnchor217"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.260.1">Chapter 15</span></em></span></a><span class="koboSpan" id="kobo.261.1">, </span><em class="italic"><span class="koboSpan" id="kobo.262.1">Deploying Deep Learning Models to Production</span></em><span class="koboSpan" id="kobo.263.1">. </span><span class="koboSpan" id="kobo.263.2">The first change that is needed here is that we will make changes on top of </span><strong class="source-inline"><span class="koboSpan" id="kobo.264.1">TritonPythonModel</span></strong><span class="koboSpan" id="kobo.265.1"> in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.266.1">model.py</span></strong><span class="koboSpan" id="kobo.267.1"> file. </span><span class="koboSpan" id="kobo.267.2">The Custom Metrics API in Python from NVIDIA allows you to define and log metrics directly in the three methods that you can define in </span><strong class="source-inline"><span class="koboSpan" id="kobo.268.1">TritonPythonModel</span></strong><span class="koboSpan" id="kobo.269.1">. </span><span class="koboSpan" id="kobo.269.2">These methods are </span><strong class="source-inline"><span class="koboSpan" id="kobo.270.1">initialize</span></strong><span class="koboSpan" id="kobo.271.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.272.1">execute</span></strong><span class="koboSpan" id="kobo.273.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.275.1">finalize</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">.</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.277.1">Firstly, the additional libraries that we will use are </span><strong class="source-inline"><span class="koboSpan" id="kobo.278.1">textstat</span></strong><span class="koboSpan" id="kobo.279.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.280.1">nltk</span></strong><span class="koboSpan" id="kobo.281.1">, which will be used to compute the </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">readability score:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.283.1">
import textstat
import nltk
nltk.download('punkt')</span></pre></li> <li><span class="koboSpan" id="kobo.284.1">The first step is to initialize the metric logging instance in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.285.1">initialize</span></strong><span class="koboSpan" id="kobo.286.1"> method. </span><span class="koboSpan" id="kobo.286.2">Prometheus supports four metric types: counters for increasing values, gauges for fluctuating values, histograms for observing value distribution, and summaries for tracking quantiles in data. </span><span class="koboSpan" id="kobo.286.3">The three custom metrics we plan to add are inherently fluctuating values, and any histograms can be created in Grafana. </span><span class="koboSpan" id="kobo.286.4">Let’s define the metric family that we will use. </span><span class="koboSpan" id="kobo.286.5">You can set the name, description, and type of metric for a family. </span><span class="koboSpan" id="kobo.286.6">Additionally, you can create many metric families for any metric logical group. </span><span class="koboSpan" id="kobo.286.7">For our case, all three metrics we plan for are business metrics and are </span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">fluctuating values:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.288.1">
self.metric_family = pb_utils.MetricFamily(
    name="business_metrics",
    description="",
    kind=pb_utils.MetricFamily.GAUGE
)</span></pre></li> <li><span class="koboSpan" id="kobo.289.1">Now, let’s define the metrics in this </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">metric family:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.291.1">
self.number_of_input_tokens_metric = self.metric_family.Metric(
    labels={"name": "Number of input tokens","version": "1"}
)
self.number_of_tokens_generated_metric = self.metric_family.Metric(
    labels={"name": "Number of tokens generated", "version": "1"}
)
self.readability_metric = self.metric_family.Metric(
    labels={"name": "Flesch Readability Score", "version": "1"}
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.292.1">Conveniently, you can do versioning of the metric in case any logic needs to be changed, which makes for a more robust </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">monitoring process.</span></span></p></li> <li><span class="koboSpan" id="kobo.294.1">Next, we will be logging the metrics in every execution. </span><span class="koboSpan" id="kobo.294.2">We will be defining a helper method that will in turn be executed at the end of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.295.1">execute</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.296.1"> method:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.297.1">
def _compute_custom_metrics(self, input_tokens, generated_tokens, generated_text):
   self.readability_metric.set(textstat.flesch_reading_ease((generated_text)))
    self.number_of_input_tokens_metric.set(input_tokens.shape[1])
    self.number_of_tokens_generated_metric.set(generated_tokens.shape[1])</span></pre></li> <li><span class="koboSpan" id="kobo.298.1">Finally, we will use this </span><a id="_idIndexMarker1215"/><span class="koboSpan" id="kobo.299.1">helper method under the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.300.1">execute</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.301.1"> method:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.302.1">
self._compute_custom_metrics(input_ids, output_seq, " ".join(decoded_texts))</span></pre></li> <li><span class="koboSpan" id="kobo.303.1">Now, we need to start the NVIDIA Triton Server </span><strong class="source-inline"><span class="koboSpan" id="kobo.304.1">nvidia-docker</span></strong><span class="koboSpan" id="kobo.305.1"> instance with the same command, which is </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">the following:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.307.1">sudo docker run --gpus=all -it --shm-size=256m --rm -p8000:8000 -p8001:8001 -p8002:8002 -v ${PWD}/models:/models nvcr.io/nvidia/tritonserver:23.05-py3</span></strong></pre></li> <li><span class="koboSpan" id="kobo.308.1">After that, we are in the Docker environment, where the next step is to install the </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">necessary libraries:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.310.1">pip install transformers==4.21.3 nvidia-tensorrt==8.4.1.5 git+https://github.com/ELS-RD/transformer-deploy torch==1.12.0  -f https://download.pytorch.org/whl/cu116/torch_stable.html textstat==0.7.3</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.311.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.312.1">For production usage, please be sure to create a Docker image where all the libraries are fixed, and you don’t need to manually install </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">libraries anymore.</span></span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.314.1">Now, you can execute the </span><strong class="source-inline"><span class="koboSpan" id="kobo.315.1">python triton_client.py</span></strong><span class="koboSpan" id="kobo.316.1"> command in the command line and get </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">your predictions.</span></span></li>
<li><span class="koboSpan" id="kobo.318.1">The default metrics and the custom metrics are immediately hosted in the URL </span><strong class="source-inline"><span class="koboSpan" id="kobo.319.1">http://localhost:8002/metrics</span></strong><span class="koboSpan" id="kobo.320.1">, where you can view the real-time metrics in text form. </span><strong class="source-inline"><span class="koboSpan" id="kobo.321.1">localhost</span></strong><span class="koboSpan" id="kobo.322.1"> can be replaced with the IP of your remote server if you are using one. </span><span class="koboSpan" id="kobo.322.2">The following snippet shows the </span><a id="_idIndexMarker1216"/><span class="koboSpan" id="kobo.323.1">real-time Prometheus-formatted metrics that can be found at the </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">preceding URL:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.325.1">
# HELP nv_gpu_power_usage GPU power usage in watts
# TYPE nv_gpu_power_usage gauge
nv_gpu_power_usage{gpu_uuid="GPU-246b298f-13e6-f93e-b6f1-0fb8933ce337"} 13.676
nv_gpu_power_usage{gpu_uuid="GPU-0fa69700-a702-0113-f30c-89d3fa1cec2f"} 19.626
# HELP nv_gpu_power_limit GPU power management limit in watts
# TYPE nv_gpu_power_limit gauge
nv_gpu_power_limit{gpu_uuid="GPU-246b298f-13e6-f93e-b6f1-0fb8933ce337"} 250
nv_gpu_power_limit{gpu_uuid="GPU-0fa69700-a702-0113-f30c-89d3fa1cec2f"} 260
# HELP nv_cpu_utilization CPU utilization rate [0.0 - 1.0]
# TYPE nv_cpu_utilization gauge
nv_cpu_utilization 0.04902789518174133
# HELP nv_cpu_memory_total_bytes CPU total memory (RAM), in bytes
# TYPE nv_cpu_memory_total_bytes gauge
nv_cpu_memory_total_bytes 67239776256
# HELP nv_cpu_memory_used_bytes CPU used memory (RAM), in bytes
# TYPE nv_cpu_memory_used_bytes gauge
nv_cpu_memory_used_bytes 14459383808
# TYPE business_metrics gauge
business_metrics{name="Flesch Readability Score",version="1"} 93.81
business_metrics{name="Number of tokens generated",version="1"} 128
business_metrics{name="Number of input tokens",version="1"} 11</span></pre></li> <li><span class="koboSpan" id="kobo.326.1">As these are only real-time metrics, we need to set up a local server or use an online Prometheus server. </span><span class="koboSpan" id="kobo.326.2">In this step, we will opt for a locally hosted Prometheus server where the following commands need to be run in the </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">command line:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.328.1">sudo systemctl start node_exporter</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.329.1">sudo systemctl start prometheus</span></strong></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.330.1">node_exporter</span></strong><span class="koboSpan" id="kobo.331.1"> here is a Prometheus exporter that collects system-level metrics from target machines, enabling Prometheus to monitor and analyze their resource usage </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">and performance.</span></span></p></li> <li><span class="koboSpan" id="kobo.333.1">Now, we need to add the NVIDIA Triton Server endpoint into the Prometheus configuration file to track metrics. </span><span class="koboSpan" id="kobo.333.2">To do that, execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.334.1">sudo gedit /etc/prometheus/prometheus.yml</span></strong><span class="koboSpan" id="kobo.335.1"> in the command line and add the following </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">job details:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.337.1">
- job_name: "triton"
    scrape_interval: 10s
    static_configs:
      - targets: ["localhost:8002"]</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.338.1">With that, Prometheus is all set up to log metrics from NVIDIA </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">Triton Server.</span></span></p></li> <li><span class="koboSpan" id="kobo.340.1">Prometheus hosts its web app by default with port </span><strong class="source-inline"><span class="koboSpan" id="kobo.341.1">9090</span></strong><span class="koboSpan" id="kobo.342.1">. </span><span class="koboSpan" id="kobo.342.2">So, accessing the link </span><strong class="source-inline"><span class="koboSpan" id="kobo.343.1">localhost:9090</span></strong><span class="koboSpan" id="kobo.344.1"> in a web browser will take </span><a id="_idIndexMarker1217"/><span class="koboSpan" id="kobo.345.1">you to the Prometheus home page. </span><span class="koboSpan" id="kobo.345.2">Going to the </span><strong class="bold"><span class="koboSpan" id="kobo.346.1">Status</span></strong><span class="koboSpan" id="kobo.347.1"> tab and clicking on </span><strong class="bold"><span class="koboSpan" id="kobo.348.1">Targets</span></strong><span class="koboSpan" id="kobo.349.1"> in the dropdown will show the following screenshot, which verifies that the Triton endpoint is </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">being tracked.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer132">
<span class="koboSpan" id="kobo.351.1"><img alt="Figure 16.3 – Prometheus web app home page on the left and targets that Prometheus is tracking and polling metrics from on the right" src="image/B18187_16_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.352.1">Figure 16.3 – Prometheus web app home page on the left and targets that Prometheus is tracking and polling metrics from on the right</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.353.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.354.1">Prometheus by default doesn’t include user account enforcement but it can be configured to </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">be enforced.</span></span></p>
<ol>
<li value="13"><span class="koboSpan" id="kobo.356.1">Next, we will set up Grafana to connect to the locally hosted Prometheus instance. </span><span class="koboSpan" id="kobo.356.2">First, we have to start up the Grafana service by executing the following command in the </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">command line:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.358.1">sudo systemctl start grafana-server</span></strong></pre></li> <li><span class="koboSpan" id="kobo.359.1">Grafana by default hosts its web app on port </span><strong class="source-inline"><span class="koboSpan" id="kobo.360.1">3000</span></strong><span class="koboSpan" id="kobo.361.1">, so accessing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.362.1">localhost:3000</span></strong><span class="koboSpan" id="kobo.363.1"> link in a web browser will bring you to the home page. </span><span class="koboSpan" id="kobo.363.2">The default username and password are </span><strong class="source-inline"><span class="koboSpan" id="kobo.364.1">admin</span></strong><span class="koboSpan" id="kobo.365.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.366.1">admin</span></strong><span class="koboSpan" id="kobo.367.1">. </span><span class="koboSpan" id="kobo.367.2">Once that is filled in, click on </span><strong class="bold"><span class="koboSpan" id="kobo.368.1">Log In</span></strong><span class="koboSpan" id="kobo.369.1"> and create a new password, after which you will be greeted with Grafana’s home page. </span><span class="koboSpan" id="kobo.369.2">We can set up the Prometheus link now by clicking on the three-line button on the top-left tab and clicking on the </span><strong class="bold"><span class="koboSpan" id="kobo.370.1">Data sources</span></strong><span class="koboSpan" id="kobo.371.1"> tab under the </span><strong class="bold"><span class="koboSpan" id="kobo.372.1">Administration</span></strong><span class="koboSpan" id="kobo.373.1"> dropdown, as </span><a id="_idIndexMarker1218"/><span class="koboSpan" id="kobo.374.1">shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.375.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.376.1">.4 (a)</span></em><span class="koboSpan" id="kobo.377.1">. </span><span class="koboSpan" id="kobo.377.2">This will result in the screen shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.378.1">Figure </span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.379.1">16</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.380.1">.4 (b)</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer133">
<span class="koboSpan" id="kobo.382.1"><img alt="Figure 16.4 – Screenshots showing how to navigate to the Add data source page in the Grafana web app" src="image/B18187_16_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.383.1">Figure 16.4 – Screenshots showing how to navigate to the Add data source page in the Grafana web app</span></p>
<ol>
<li value="15"><span class="koboSpan" id="kobo.384.1">Next, click on Prometheus as the data source, where you will be presented with the screen shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.385.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.386.1">.5 (a)</span></em><span class="koboSpan" id="kobo.387.1">. </span><span class="koboSpan" id="kobo.387.2">Set the Prometheus default hosted web app link to </span><strong class="source-inline"><span class="koboSpan" id="kobo.388.1">http://localhost:9090</span></strong><span class="koboSpan" id="kobo.389.1"> and click on </span><strong class="bold"><span class="koboSpan" id="kobo.390.1">Save &amp; Test</span></strong><span class="koboSpan" id="kobo.391.1">. </span><span class="koboSpan" id="kobo.391.2">This should result in the success screen shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.392.1">Figure </span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.393.1">16</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.394.1">.5 (b)</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer134">
<span class="koboSpan" id="kobo.396.1"><img alt="Figure 16.5 – Grafana Prometheus data source settings tab in (a) and successfully created screen (b)" src="image/B18187_16_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.397.1">Figure 16.5 – Grafana Prometheus data source settings tab in (a) and successfully created screen (b)</span></p>
<ol>
<li value="16"><span class="koboSpan" id="kobo.398.1">With that, you will see that the </span><a id="_idIndexMarker1219"/><span class="koboSpan" id="kobo.399.1">data source has been created as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.400.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.401.1">.6 (a)</span></em><span class="koboSpan" id="kobo.402.1">. </span><span class="koboSpan" id="kobo.402.2">At this point, we will be able to create a dashboard to visualize the metrics we are monitoring. </span><span class="koboSpan" id="kobo.402.3">Grafana allows you to create dashboards in three ways: importing through its publicly shared dashboard IDs, importing through an exported dashboard JSON file, and creating a new dashboard. </span><span class="koboSpan" id="kobo.402.4">In Grafana, you can create many types of visualizations manually using the in-built visualization UI builder system or </span><a id="_idIndexMarker1220"/><span class="koboSpan" id="kobo.403.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.404.1">PromQL</span></strong><span class="koboSpan" id="kobo.405.1">-based visualizations and choose how you want them to be displayed. </span><span class="koboSpan" id="kobo.405.2">However, in this tutorial, we will be using a ready-made dashboard with visualizations by importing it through a dashboard JSON file. </span><span class="koboSpan" id="kobo.405.3">To do that, navigate to the dashboard page using the same three-line button dropdown shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.406.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.407.1">.4 (a)</span></em><span class="koboSpan" id="kobo.408.1">. </span><span class="koboSpan" id="kobo.408.2">Once, you are on the dashboard </span><a id="_idIndexMarker1221"/><span class="koboSpan" id="kobo.409.1">page, click on </span><strong class="bold"><span class="koboSpan" id="kobo.410.1">New</span></strong><span class="koboSpan" id="kobo.411.1"> and then on </span><strong class="bold"><span class="koboSpan" id="kobo.412.1">Import</span></strong><span class="koboSpan" id="kobo.413.1">, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.414.1">Figure </span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.415.1">16</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.416.1">.6 (b)</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer135">
<span class="koboSpan" id="kobo.418.1"><img alt="Figure 16.6 – Grafana Data sources tab showing the created data source and the Dashboards tab showing the dropdown of the New button" src="image/B18187_16_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.419.1">Figure 16.6 – Grafana Data sources tab showing the created data source and the Dashboards tab showing the dropdown of the New button</span></p>
<ol>
<li value="17"><span class="koboSpan" id="kobo.420.1">Drag the provided </span><strong class="source-inline"><span class="koboSpan" id="kobo.421.1">Triton Inference Server-1692252636911.json</span></strong><span class="koboSpan" id="kobo.422.1"> file straight into the import area and then connect to the Prometheus database you created, and you’ll see the dashboard shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.423.1">Figure 16</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.424.1">.7</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer136">
<span class="koboSpan" id="kobo.426.1"><img alt="Figure 16.7 – A custom Grafana dashboard for the monitoring tutorial" src="image/B18187_16_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.427.1">Figure 16.7 – A custom Grafana dashboard for the monitoring tutorial</span></p>
<p><span class="koboSpan" id="kobo.428.1">Note that there were two GPUs in the machine that generated this metric, which is why there are two GPU stats. </span><span class="koboSpan" id="kobo.428.2">This visualization effectively represents most of the default NVIDIA Triton Server metrics, along with the three extra custom metrics we added, by displaying them on a graph that captures their historical values up to the </span><a id="_idIndexMarker1222"/><span class="koboSpan" id="kobo.429.1">present moment. </span><span class="koboSpan" id="kobo.429.2">However, hardware-resource-specific stats are an exception, as they are shown only </span><span class="No-Break"><span class="koboSpan" id="kobo.430.1">in real-time.</span></span></p>
<p><span class="koboSpan" id="kobo.431.1">Now, the component missing from monitoring is to create rules and conditions that would be considered an alarming incident, called the incident alerting component. </span><span class="koboSpan" id="kobo.431.2">Monitoring deployed deep learning models without alerts is like having a security camera but no alarm. </span><span class="koboSpan" id="kobo.431.3">You won’t know if something has gone wrong until it’s too late to do anything about it. </span><span class="koboSpan" id="kobo.431.4">Incidents can include deteriorating model accuracy, consistently delayed responses, consistent resource bottlenecks, consistently unexpected output variations during the monitoring </span><a id="_idIndexMarker1223"/><span class="koboSpan" id="kobo.432.1">of deployed deep learning models, and hardware failures. </span><span class="koboSpan" id="kobo.432.2">Grafana has an in-built alert management, notifications management, and contact management system that we will leverage in the </span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">following section.</span></span></p>
<h3><span class="koboSpan" id="kobo.434.1">Setting up alerts with Grafana</span></h3>
<p><span class="koboSpan" id="kobo.435.1">Let’s go through the </span><a id="_idIndexMarker1224"/><span class="koboSpan" id="kobo.436.1">steps on how to set up alerts </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">with Grafana:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.438.1">Click on the </span><strong class="bold"><span class="koboSpan" id="kobo.439.1">Alerting</span></strong><span class="koboSpan" id="kobo.440.1"> tab, shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.441.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.442.1">.4 (a)</span></em><span class="koboSpan" id="kobo.443.1">, and then on </span><strong class="bold"><span class="koboSpan" id="kobo.444.1">Alert rules</span></strong><span class="koboSpan" id="kobo.445.1">. </span><span class="koboSpan" id="kobo.445.2">You will see the screen shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.446.1">Figure 16</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.447.1">.8</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer137">
<span class="koboSpan" id="kobo.449.1"><img alt="Figure 16.8 – Alert rules tab settings for NVIDIA Triton request failure alert rule" src="image/B18187_16_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.450.1">Figure 16.8 – Alert rules tab settings for NVIDIA Triton request failure alert rule</span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.451.1">In this example, we will set an alert to trigger when there is any failed NVIDIA Triton Server inference request. </span><span class="koboSpan" id="kobo.451.2">So, in the same tab, choose the </span><strong class="source-inline"><span class="koboSpan" id="kobo.452.1">nv_inference_request_failure</span></strong><span class="koboSpan" id="kobo.453.1"> metric tab, and set the threshold to a number that is lower than 1 so that a single failed request will trigger the alarm. </span><span class="koboSpan" id="kobo.453.2">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.454.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.455.1">.8</span></em><span class="koboSpan" id="kobo.456.1">, the number is set </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.458.1">0.8</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.459.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.460.1">Next, set the evaluation interval to be one minute and to raise an alarm only if there are consistent request failures for five minutes straight, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.461.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.462.1">.9</span></em><span class="koboSpan" id="kobo.463.1">. </span><span class="koboSpan" id="kobo.463.2">Then, click on the </span><strong class="bold"><span class="koboSpan" id="kobo.464.1">Save and </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.465.1">exit</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.466.1"> button.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer138">
<span class="koboSpan" id="kobo.467.1"><img alt="Figure 16.9 – Evaluation interval settings for alert rules" src="image/B18187_16_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.468.1">Figure 16.9 – Evaluation interval settings for alert rules</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.469.1">There are three possible statuses that alerts in Grafana can have: </span><strong class="bold"><span class="koboSpan" id="kobo.470.1">Normal</span></strong><span class="koboSpan" id="kobo.471.1">, which indicates that the condition wasn’t triggered; </span><strong class="bold"><span class="koboSpan" id="kobo.472.1">Pending</span></strong><span class="koboSpan" id="kobo.473.1">, which indicates that the condition was partially triggered but there isn’t a consistent behavior yet; and </span><strong class="bold"><span class="koboSpan" id="kobo.474.1">Firing</span></strong><span class="koboSpan" id="kobo.475.1">, which indicates that the condition has been consistently satisfied and an </span><a id="_idIndexMarker1225"/><span class="koboSpan" id="kobo.476.1">alarm has been triggered. </span><span class="koboSpan" id="kobo.476.2">Now that an alert rule is saved and created, you will see the screen shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.477.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.478.1">.10 (a)</span></em><span class="koboSpan" id="kobo.479.1">, where the status is </span><strong class="bold"><span class="koboSpan" id="kobo.480.1">Normal</span></strong><span class="koboSpan" id="kobo.481.1">. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.482.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.483.1">.10 (b)</span></em><span class="koboSpan" id="kobo.484.1"> shows the </span><strong class="bold"><span class="koboSpan" id="kobo.485.1">Pending</span></strong><span class="koboSpan" id="kobo.486.1"> stage, where a failure has been detected but is not yet consistent enough to send an alert. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.487.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.488.1">.10 (c)</span></em><span class="koboSpan" id="kobo.489.1">, on the other hand, shows the </span><strong class="bold"><span class="koboSpan" id="kobo.490.1">Firing</span></strong><span class="koboSpan" id="kobo.491.1"> stage, where the failure has consistently happened per the configured </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">time interval.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer139">
<span class="koboSpan" id="kobo.493.1"><img alt="Figure 16.10 – Alert status of Normal in (a), Pending in (b), and Firing in (c)" src="image/B18187_16_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.494.1">Figure 16.10 – Alert status of Normal in (a), Pending in (b), and Firing in (c)</span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.495.1">To configure where and who these alerts will be sent to, we’ll work with the </span><strong class="bold"><span class="koboSpan" id="kobo.496.1">Contact points</span></strong><span class="koboSpan" id="kobo.497.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.498.1">Notification policies</span></strong><span class="koboSpan" id="kobo.499.1"> tabs in the </span><strong class="bold"><span class="koboSpan" id="kobo.500.1">Alerting</span></strong><span class="koboSpan" id="kobo.501.1"> section. </span><span class="koboSpan" id="kobo.501.2">Let’s start by clicking on the </span><strong class="bold"><span class="koboSpan" id="kobo.502.1">Contact points</span></strong><span class="koboSpan" id="kobo.503.1"> tab to set up the individuals who will receive notifications. </span><span class="koboSpan" id="kobo.503.2">You can even organize</span><a id="_idIndexMarker1226"/><span class="koboSpan" id="kobo.504.1"> these into groups, but for simplicity in this tutorial, we’ll have notifications sent to ourselves. </span><span class="koboSpan" id="kobo.504.2">Grafana offers various contact platform integrations: Alertmanager, Cisco Webex Teams, DingDing, Discord, Email, Google Chat, Kafka REST policy, LINE, Microsoft Teams, Opsgenie, PagerDuty, Pushover, Sensu Go, Slack, Telegram, Threema Gateway, VictorOps, Webhook, and WeCom. </span><span class="koboSpan" id="kobo.504.3">To keep things</span><a id="_idIndexMarker1227"/><span class="koboSpan" id="kobo.505.1"> straightforward, we’ll choose a widely available integration type: email. </span><span class="koboSpan" id="kobo.505.2">Grafana uses the </span><strong class="bold"><span class="koboSpan" id="kobo.506.1">sSMTP</span></strong><span class="koboSpan" id="kobo.507.1"> software for sending emails, so ensure you have an email account with credentials set up before proceeding. </span><span class="koboSpan" id="kobo.507.2">Within the contact points settings, provide your name and email, then click on </span><strong class="bold"><span class="koboSpan" id="kobo.508.1">Test</span></strong><span class="koboSpan" id="kobo.509.1"> to generate a test notification to confirm that the credentials are accurate. </span><span class="koboSpan" id="kobo.509.2">Once you’ve verified that you’ve received the email notification, save your settings. </span><span class="koboSpan" id="kobo.509.3">Refer to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.510.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.511.1">.11</span></em><span class="koboSpan" id="kobo.512.1"> for an example of the </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">settings interface.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer140">
<span class="koboSpan" id="kobo.514.1"><img alt="Figure 16.11 – Contact points tab with email set up" src="image/B18187_16_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.515.1">Figure 16.11 – Contact points tab with email set up</span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.516.1">Next, we need to link up the contact</span><a id="_idIndexMarker1228"/><span class="koboSpan" id="kobo.517.1"> as part of the default notification policy. </span><span class="koboSpan" id="kobo.517.2">Proceed to the </span><strong class="bold"><span class="koboSpan" id="kobo.518.1">Notification policies</span></strong><span class="koboSpan" id="kobo.519.1"> tab, click on </span><strong class="bold"><span class="koboSpan" id="kobo.520.1">Settings</span></strong><span class="koboSpan" id="kobo.521.1">, and change the default contact point to be the email contact we set in </span><em class="italic"><span class="koboSpan" id="kobo.522.1">step 4</span></em><span class="koboSpan" id="kobo.523.1">. </span><span class="koboSpan" id="kobo.523.2">You will then see a similar screen to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.524.1">Figure 16</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.525.1">.12</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer141">
<span class="koboSpan" id="kobo.527.1"><img alt="Figure 16.12 – The default notification policy set up to notify us" src="image/B18187_16_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.528.1">Figure 16.12 – The default notification policy set up to notify us</span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.529.1">Now, we are all set up to receive email notifications! </span><span class="koboSpan" id="kobo.529.2">As a challenge, try to figure out ways you can make the inference</span><a id="_idIndexMarker1229"/><span class="koboSpan" id="kobo.530.1"> server request fail, and if you can’t, change the rule to something that will definitely trigger so you can </span><a id="_idIndexMarker1230"/><span class="koboSpan" id="kobo.531.1">get an example actual alert notification come through email. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.532.1">Figure 16</span></em></span><em class="italic"><span class="koboSpan" id="kobo.533.1">.13</span></em><span class="koboSpan" id="kobo.534.1"> shows the example email that you will get through a mobile </span><span class="No-Break"><span class="koboSpan" id="kobo.535.1">phone interface.</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer142">
<span class="koboSpan" id="kobo.536.1"><img alt="Figure 16.13 – Example triggered alert email notification with the Firing status" src="image/B18187_16_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.537.1">Figure 16.13 – Example triggered alert email notification with the Firing status</span></p>
<p><span class="koboSpan" id="kobo.538.1">With that, we have successfully set up a monitoring and alerting system for a deployed deep learning model! </span><span class="koboSpan" id="kobo.538.2">A notable caveat in this implementation is the fact that metrics are bundled up in the same execution as the model. </span><span class="koboSpan" id="kobo.538.3">A solution to make it decoupled to not increase the runtime for prediction-specific inference is to use the C API instead to build the custom metrics. </span><span class="koboSpan" id="kobo.538.4">If the time needed to get the metrics logged is not crucial, you can also consider hosting another “model” in NVIDIA Triton Server that takes in outputs from the prediction-specific model and log metrics. </span><span class="koboSpan" id="kobo.538.5">NVIDIA Triton Server also provides a tool called </span><strong class="source-inline"><span class="koboSpan" id="kobo.539.1">perf_client</span></strong><span class="koboSpan" id="kobo.540.1">, which evaluates the runtime of different configurations, helping you optimize your system’s performance. </span><span class="koboSpan" id="kobo.540.2">Specifically, the tool measures and reports the throughput and latency with different </span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">load conditions.</span></span></p>
<p><span class="koboSpan" id="kobo.542.1">However, just having monitoring and alerts doesn’t provide a full picture of model monitoring. </span><span class="koboSpan" id="kobo.542.2">We need to dive into those numbers, cross-reference them, spot connections, and find patterns. </span><span class="koboSpan" id="kobo.542.3">It’s like checking the fuel efficiency, tire pressure, and engine temperature of a car to ensure a </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">smooth ride.</span></span></p>
<p><span class="koboSpan" id="kobo.544.1">Additionally, alerts</span><a id="_idIndexMarker1231"/><span class="koboSpan" id="kobo.545.1"> alone won’t fix issues. </span><span class="koboSpan" id="kobo.545.2">They’re like the car’s warning lights – they tell you something’s up, but you still need to pull over, pop</span><a id="_idIndexMarker1232"/><span class="koboSpan" id="kobo.546.1"> the hood, and fix the problem. </span><span class="koboSpan" id="kobo.546.2">That’s where model maintenance comes in. </span><span class="koboSpan" id="kobo.546.3">In the next section, we’ll explore how to not only detect issues but also take action to keep your model running smoothly and efficiently </span><span class="No-Break"><span class="koboSpan" id="kobo.547.1">over time.</span></span></p>
<h1 id="_idParaDest-235"><a id="_idTextAnchor244"/><span class="koboSpan" id="kobo.548.1">Governing a deep learning model through maintenance</span></h1>
<p><span class="koboSpan" id="kobo.549.1">Metrics logging, dashboard</span><a id="_idIndexMarker1233"/><span class="koboSpan" id="kobo.550.1"> building, logged metrics analysis, and alerts are essential components of model monitoring, but they are only effective when followed by appropriate actions, which are covered under model maintenance. </span><span class="koboSpan" id="kobo.550.2">Model maintenance is akin to a skilled pit crew in a car race, regularly fine-tuning and optimizing the performance of deep learning models to keep them running efficiently and effectively. </span><span class="koboSpan" id="kobo.550.3">Like how a pit crew conducts rapid repairs, refuels, and adjusts the car’s components to adapt to changing race conditions, model maintenance involves updating the models to account for environmental changes, improving and refining the models with new data obtained from feedback loops, and performing incident responses on miscellaneous issues. </span><span class="koboSpan" id="kobo.550.4">This ensures that the models consistently stay on track, deliver valuable insights, and drive informed decision-making in the ever-evolving landscape of data and </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">business requirements.</span></span></p>
<p><span class="koboSpan" id="kobo.552.1">Key aspects of model maintenance comprehensively include </span><span class="No-Break"><span class="koboSpan" id="kobo.553.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.554.1">Establishing a feedback loop</span></strong><span class="koboSpan" id="kobo.555.1">: Establishing a feedback loop is vital for capturing real-world outcomes and validating model predictions, enabling deep learning practitioners to identify areas for improvement, and adapting the </span><span class="No-Break"><span class="koboSpan" id="kobo.556.1">model accordingly.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.557.1">Retraining</span></strong><span class="koboSpan" id="kobo.558.1">: Retraining is an essential part of model maintenance, ensuring that the model stays up to date with the latest data and trends, thereby maintaining its accuracy and relevance. </span><span class="koboSpan" id="kobo.558.2">Regular retraining enables the model to learn from new insights and adapt to evolving data landscapes, ensuring consistent performance. </span><span class="koboSpan" id="kobo.558.3">Fortunately, for deep learning models, a fine-tuning process can be employed, which is much faster than a full retraining process. </span><span class="koboSpan" id="kobo.558.4">Two use cases that highlight the importance of frequent updates with model retraining are </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">the following:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.560.1">E-commerce product recommendation</span></strong><span class="koboSpan" id="kobo.561.1">: Consumer preferences and product availability change rapidly in e-commerce. </span><span class="koboSpan" id="kobo.561.2">To provide relevant product recommendations, deep learning models need to be retrained frequently, maybe weekly or even daily, to understand the latest trends and </span><span class="No-Break"><span class="koboSpan" id="kobo.562.1">customer behavior.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.563.1">Social media sentiment analysis</span></strong><span class="koboSpan" id="kobo.564.1">: Social media platforms are constantly evolving with new trends, hashtags, and user behaviors. </span><span class="koboSpan" id="kobo.564.2">To accurately gauge public sentiment and opinion, deep learning models need to be retrained frequently, maybe quarterly, to account for </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">these changes.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.566.1">Incident response handling</span></strong><span class="koboSpan" id="kobo.567.1">: When alerts signal potential issues, it’s vital to have a dedicated response team to triage</span><a id="_idIndexMarker1234"/><span class="koboSpan" id="kobo.568.1"> and address the problem promptly. </span><span class="koboSpan" id="kobo.568.2">This team should be well equipped to investigate the root cause, implement corrective measures, and prevent similar issues from recurring in the future. </span><span class="koboSpan" id="kobo.568.3">Let’s discover response-handling recommendations for different groups </span><span class="No-Break"><span class="koboSpan" id="kobo.569.1">of incidents:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.570.1">Data-related incidents</span></strong><span class="koboSpan" id="kobo.571.1">: These incidents occur when the model receives incorrect, incomplete, or biased input data. </span><span class="koboSpan" id="kobo.571.2">To handle such issues, the response team should work closely with the data provider to identify the cause, correct the data, and retrain the model </span><span class="No-Break"><span class="koboSpan" id="kobo.572.1">as needed.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.573.1">Model performance incidents</span></strong><span class="koboSpan" id="kobo.574.1">: These incidents involve the model generating inaccurate or unexpected predictions. </span><span class="koboSpan" id="kobo.574.2">Proper handling requires collaboration between the model owner (responsible for model creation or approving the model usage) and the prediction owner (responsible for approving the usage of the predictions), as described in the </span><em class="italic"><span class="koboSpan" id="kobo.575.1">Governing deep learning model utilization</span></em><span class="koboSpan" id="kobo.576.1"> section earlier. </span><span class="koboSpan" id="kobo.576.2">They should analyze the model’s performance, identify potential issues in its architecture or training, and implement improvements to ensure better performance in </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">the future.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.578.1">Infrastructure-related incidents</span></strong><span class="koboSpan" id="kobo.579.1">: These incidents are caused by hardware or software failures, affecting the model’s deployment environment. </span><span class="koboSpan" id="kobo.579.2">The response team should work with the infrastructure provider or team to resolve the issue and ensure the model </span><span class="No-Break"><span class="koboSpan" id="kobo.580.1">runs smoothly.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.581.1">Security incidents</span></strong><span class="koboSpan" id="kobo.582.1">: These incidents involve unauthorized access, data breaches, or other malicious activities targeting the model. </span><span class="koboSpan" id="kobo.582.2">The response team should follow the organization’s security policies, identify the threat, and take appropriate measures to mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">the risk.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.584.1">Compliance and regulatory incidents</span></strong><span class="koboSpan" id="kobo.585.1">: These incidents occur when the model’s output or operation violates legal or regulatory requirements. </span><span class="koboSpan" id="kobo.585.2">The response</span><a id="_idIndexMarker1235"/><span class="koboSpan" id="kobo.586.1"> team should work with legal and compliance teams to address the violation and modify the model to comply with the </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1">necessary regulations.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.588.1">By comprehensively considering </span><a id="_idIndexMarker1236"/><span class="koboSpan" id="kobo.589.1">model maintenance components shared here, organizations can effectively address challenges associated with deployed deep learning models, ensuring their continuous improvement and alignment with business requirements. </span><span class="koboSpan" id="kobo.589.2">Traditionally, these maintenance actions are executed manually after alerts are raised. </span><span class="koboSpan" id="kobo.589.3">However, it is possible to schedule custom tasks to be executed automatically given an alert event. </span><span class="koboSpan" id="kobo.589.4">Consider using Apache Airflow to orchestrate your desired automated tasks from your model monitoring alerts. </span><span class="koboSpan" id="kobo.589.5">Apache Airflow is like a conductor for your data tasks, allowing you to choreograph and schedule complex workflows in a directed acyclic graph format. </span><span class="koboSpan" id="kobo.589.6">It lets you define, automate, and </span><a id="_idIndexMarker1237"/><span class="koboSpan" id="kobo.590.1">monitor sequences of tasks, making sure they happen in the right order and at the right time. </span><span class="koboSpan" id="kobo.590.2">However, there are some inherent limitations and risks with creating automated tasks from model monitoring alerts, which we will briefly </span><span class="No-Break"><span class="koboSpan" id="kobo.591.1">explore next.</span></span></p>
<h2 id="_idParaDest-236"><a id="_idTextAnchor245"/><span class="koboSpan" id="kobo.592.1">Exploring limitations and risks of using automated tasks triggered by model monitoring alerts</span></h2>
<p><span class="koboSpan" id="kobo.593.1">While automating tasks based on model monitoring</span><a id="_idIndexMarker1238"/><span class="koboSpan" id="kobo.594.1"> alerts can save time and resources, it also comes with limitations and potential risks that need to be considered when implementing such an approach. </span><span class="koboSpan" id="kobo.594.2">Some limitations of automating tasks based on model monitoring alerts are </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.596.1">Complexity of issues</span></strong><span class="koboSpan" id="kobo.597.1">: Some issues may be too complex </span><a id="_idIndexMarker1239"/><span class="koboSpan" id="kobo.598.1">or nuanced to be handled effectively by an automated process. </span><span class="koboSpan" id="kobo.598.2">For example, in a deep learning model for medical image analysis, an automated task might be triggered to retrain the model when the monitoring alerts indicate a drop in accuracy. </span><span class="koboSpan" id="kobo.598.3">However, the complexity of the issue may stem from an imbalance in the training data, such as an underrepresentation of a certain disease, which cannot be resolved by simply retraining the model. </span><span class="koboSpan" id="kobo.598.4">In this case, automated processes might not be able to effectively address the root cause of </span><span class="No-Break"><span class="koboSpan" id="kobo.599.1">the problem.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.600.1">Lack of context</span></strong><span class="koboSpan" id="kobo.601.1">: Automated tasks may lack the ability to consider the broader context of an issue or understand its potential impact on other aspects of </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">the system.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.603.1">Consider a deep learning model that predicts customer churn based on various behavioral and demographic factors. </span><span class="koboSpan" id="kobo.603.2">An automated task might be set up to send promotional offers to customers identified as high risk for churn. </span><span class="koboSpan" id="kobo.603.3">However, the task may not have the context to consider external factors, such as a recent negative publicity event or a widespread service outage, which might be causing a temporary increase in churn risk. </span><span class="koboSpan" id="kobo.603.4">This lack of context may lead to unnecessary promotional offers and an ineffective use </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">of resources.</span></span></p></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.605.1">Inadequate or inappropriate responses</span></strong><span class="koboSpan" id="kobo.606.1">: Automated tasks might not always choose the most appropriate action in response to an alert, potentially leading to suboptimal outcomes. </span><span class="koboSpan" id="kobo.606.2">For example, an AI model monitoring social media posts for harmful content may detect a post containing offensive language. </span><span class="koboSpan" id="kobo.606.3">An automated response system might remove the post or ban the user immediately, without considering</span><a id="_idIndexMarker1240"/><span class="koboSpan" id="kobo.607.1"> the possibility of false positives or the post’s broader context (e.g., quoting offensive language to </span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">criticize it).</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.609.1">As for risks associated with enabling</span><a id="_idIndexMarker1241"/><span class="koboSpan" id="kobo.610.1"> automated tasks with model monitoring alerts, they are </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.612.1">Over-reliance on automation</span></strong><span class="koboSpan" id="kobo.613.1">: Relying too heavily on automated tasks can lead to a lack of human oversight and expertise in the model maintenance process. </span><span class="koboSpan" id="kobo.613.2">This may result in overlooking subtle patterns and trends that only human intuition can detect, potentially leading to suboptimal </span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">model performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.615.1">Inaccurate or premature triggers</span></strong><span class="koboSpan" id="kobo.616.1">: Automated tasks are often triggered by specific conditions in the monitored metrics. </span><span class="koboSpan" id="kobo.616.2">If these conditions are not carefully defined, tasks may be triggered inaccurately or prematurely, leading to unnecessary or even detrimental actions being taken on </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1">the model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.618.1">Inflexibility</span></strong><span class="koboSpan" id="kobo.619.1">: Automated tasks are typically designed for specific scenarios or issues and may not be flexible enough to handle unforeseen or complex situations. </span><span class="koboSpan" id="kobo.619.2">This could limit their effectiveness in addressing unique challenges that arise during </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">model maintenance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.621.1">Risk of compounding errors</span></strong><span class="koboSpan" id="kobo.622.1">: When automated tasks are executed based on erroneous alerts or inaccurate metrics, they can compound the issue by making unnecessary or incorrect adjustments to the model. </span><span class="koboSpan" id="kobo.622.2">This may lead to further deterioration in model performance or even </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">irreversible damage.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.624.1">Security risks</span></strong><span class="koboSpan" id="kobo.625.1">: Automating tasks based on alerts can expose the model and its infrastructure to potential security risks, especially if the automation system is not adequately secured. </span><span class="koboSpan" id="kobo.625.2">Unauthorized access or manipulation of the automation system could lead to unintended</span><a id="_idIndexMarker1242"/><span class="koboSpan" id="kobo.626.1"> consequences or malicious actions on </span><span class="No-Break"><span class="koboSpan" id="kobo.627.1">the model.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.628.1">To mitigate these limitations</span><a id="_idIndexMarker1243"/><span class="koboSpan" id="kobo.629.1"> and risks, it is essential to strike a balance between automation and human involvement in the model maintenance process. </span><span class="koboSpan" id="kobo.629.2">This can be achieved by incorporating human-in-the-loop systems, ensuring proper validation and calibration of monitoring metrics and alerts, and implementing robust security measures to protect the </span><span class="No-Break"><span class="koboSpan" id="kobo.630.1">automation infrastructure.</span></span></p>
<p><span class="koboSpan" id="kobo.631.1">With that, we have covered all the components of deep learning model governance. </span><span class="koboSpan" id="kobo.631.2">This holistic three-pillar approach to model governance ultimately enables organizations to consistently and continuously harness the full potential of deep learning models, driving valuable insights and informed decision-making in the </span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">real world.</span></span></p>
<h1 id="_idParaDest-237"><a id="_idTextAnchor246"/><span class="koboSpan" id="kobo.633.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.634.1">In this chapter, we explored the three fundamental pillars of model governance for deep learning models: model utilization, model monitoring, and model maintenance. </span><span class="koboSpan" id="kobo.634.2">Model utilization ensures the effective, efficient, ethical, and responsible utilization of deep learning models, while model monitoring allows for ongoing evaluation of performance, identification of potential bias or drift, and infrastructure-related metrics. </span><span class="koboSpan" id="kobo.634.3">Model maintenance, on the other hand, focuses on regular updates and refinements to keep models aligned with evolving data landscapes and </span><span class="No-Break"><span class="koboSpan" id="kobo.635.1">business requirements.</span></span></p>
<p><span class="koboSpan" id="kobo.636.1">We also dove into and learned about the technical steps for monitoring deep learning models using NVIDIA Triton Server, Prometheus, and Grafana. </span><span class="koboSpan" id="kobo.636.2">By diligently considering the components for model governance, deep learning architects can effectively manage the challenges posed by these complex models in production and consistently harness their potential for driving valuable insights </span><span class="No-Break"><span class="koboSpan" id="kobo.637.1">and decisions.</span></span></p>
<p><span class="koboSpan" id="kobo.638.1">In the next chapter, we will further dive deeper into the details of drift detection for deep </span><span class="No-Break"><span class="koboSpan" id="kobo.639.1">learning models.</span></span></p>
</div>
</body></html>