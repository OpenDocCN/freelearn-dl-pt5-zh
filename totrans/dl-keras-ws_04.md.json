["```py\nkeras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params)\n# wrappers for classification estimators\nkeras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)\n# wrappers for regression estimators\n```", "```py\n# import data\nimport pandas as pd\ncolnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', \\\n            'NdsCH', 'NdssC','MLOGP', 'LC50']\ndata = pd.read_csv('../data/qsar_fish_toxicity.csv', \\\n                   sep=';', names=colnames)\nX = data.drop('LC50', axis=1)\ny = data['LC50']\n# Print the sizes of the dataset\nprint(\"Number of Examples in the Dataset = \", X.shape[0])\nprint(\"Number of Features for each example = \", X.shape[1])\n# print output range\nprint(\"Output Range = [%f, %f]\" %(min(y), max(y)))\n```", "```py\nNumber of Examples in the Dataset =  908\nNumber of Features for each example =  6\nOutput Range = [0.053000, 9.612000]\n```", "```py\n    from keras.models import Sequential\n    from keras.layers import Dense, Activation\n    # Create the function that returns the keras model\n    def build_model():\n        # build the Keras model\n        model = Sequential()\n        model.add(Dense(8, input_dim=X.shape[1], \\\n                  activation='relu'))\n        model.add(Dense(1))\n        # Compile the model\n        model.compile(loss='mean_squared_error', \\\n                      optimizer='adam')\n        # return the model\n        return model  \n    ```", "```py\n    # build the scikit-Learn interface for the keras model\n    from keras.wrappers.scikit_learn import KerasRegressor\n    YourModel = KerasRegressor(build_fn= build_model, \\\n                               epochs=100, \\\n                               batch_size=20, \\\n                               verbose=1) \n    ```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split\\\n                                   (X, y, test_size=0.3, \\\n                                    random_state=0)\n```", "```py\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(YourModel, X, y, cv=5)\n```", "```py\nprint(scores.mean())\n```", "```py\nfrom sklearn.model_selection import LeaveOneOut\nloo = LeaveOneOut()\nscores = cross_val_score(YourModel, X, y, cv=loo)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n```", "```py\nfrom sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=5)\nscores = cross_val_score(YourModel, X, y, cv=skf)\n```", "```py\n    # import data\n    import pandas as pd\n    colnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', \\\n                'NdsCH', 'NdssC','MLOGP', 'LC50']\n    data = pd.read_csv('../data/qsar_fish_toxicity.csv', \\\n                       sep=';', names=colnames)\n    X = data.drop('LC50', axis=1)\n    y = data['LC50']\n    # Print the sizes of the dataset\n    print(\"Number of Examples in the Dataset = \", X.shape[0])\n    print(\"Number of Features for each example = \", X.shape[1])\n    # print output range\n    print(\"Output Range = [%f, %f]\" %(min(y), max(y)))\n    ```", "```py\n    Number of Examples in the Dataset =  908\n    Number of Features for each example =  6\n    Output Range = [0.053000, 9.612000]\n    ```", "```py\n    from keras.models import Sequential\n    from keras.layers import Dense, Activation\n    # Create the function that returns the keras model\n    def build_model():\n        # build the Keras model\n        model = Sequential()\n        model.add(Dense(8, input_dim=X.shape[1], \\\n                  activation='relu'))\n        model.add(Dense(1))\n        # Compile the model\n        model.compile(loss='mean_squared_error', \\\n                      optimizer='adam')\n        # return the model\n        return model\n    ```", "```py\n    # build the scikit-Learn interface for the keras model\n    from keras.wrappers.scikit_learn import KerasRegressor\n    import numpy as np\n    from tensorflow import random\n    seed = 1\n    np.random.seed(seed)\n    random.set_seed(seed)\n    YourModel = KerasRegressor(build_fn= build_model, \\\n                               epochs=100, batch_size=20, \\\n                               verbose=1 , shuffle=False)\n    ```", "```py\n    # define the iterator to perform 5-fold cross-validation\n    from sklearn.model_selection import KFold\n    kf = KFold(n_splits=5)\n    ```", "```py\n    # perform cross-validation on X, y\n    from sklearn.model_selection import cross_val_score\n    results = cross_val_score(YourModel, X, y, cv=kf) \n    ```", "```py\n    # print the result\n    print(f\"Final Cross-Validation Loss = {abs(results.mean()):.4f}\")\n    ```", "```py\n    Final Cross-Validation Loss = 0.9680\n    ```", "```py\nTest accuracy at fold 1 = 0.5198556184768677\nTest accuracy at fold 2 = 0.4693140685558319\nTest accuracy at fold 3 = 0.512635350227356\nTest accuracy at fold 4 = 0.5740072131156921\nTest accuracy at fold 5 = 0.5523465871810913\nFinal Cross Validation Test Accuracy: 0.5256317675113678\nStandard Deviation of Final Test Accuracy: 0.03584760640500936\n```", "```py\n# import data\nimport pandas as pd\nimport numpy as np\nfrom tensorflow import random\ncolnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', 'NdsCH', \\\n            'NdssC','MLOGP', 'LC50']\ndata = pd.read_csv('../data/qsar_fish_toxicity.csv', \\\n                   sep=';', names=colnames)\nX = data.drop('LC50', axis=1)\ny = data['LC50']\n```", "```py\n    # Define the Keras models\n    from keras.models import Sequential\n    from keras.layers import Dense\n    def build_model_1():\n        # build the Keras model_1\n        model = Sequential()\n        model.add(Dense(4, input_dim=X.shape[1], \\\n                        activation='relu'))\n        model.add(Dense(1))\n        # Compile the model\n        model.compile(loss='mean_squared_error', \\\n                      optimizer='adam')\n        # return the model\n        return model\n    def build_model_2():\n        # build the Keras model_2\n        model = Sequential()\n        model.add(Dense(8, input_dim=X.shape[1], \\\n                  activation='relu'))\n        model.add(Dense(1))\n        # Compile the model\n        model.compile(loss='mean_squared_error', \\\n                      optimizer='adam')\n        # return the model\n        return model\n    def build_model_3():\n        # build the Keras model_3\n        model = Sequential()\n        model.add(Dense(4, input_dim=X.shape[1], \\\n                        activation='relu'))\n        model.add(Dense(2, activation='relu'))\n        model.add(Dense(1))\n        # Compile the model\n        model.compile(loss='mean_squared_error', \\\n                      optimizer='adam')\n        # return the model\n        return model\n    ```", "```py\n    \"\"\"\n    define a seed for random number generator so the result will be reproducible\n    \"\"\"\n    seed = 1\n    np.random.seed(seed)\n    random.set_seed(seed)\n    # perform cross-validation on each model\n    from keras.wrappers.scikit_learn import KerasRegressor\n    from sklearn.model_selection import KFold\n    from sklearn.model_selection import cross_val_score\n    results_1 = []\n    models = [build_model_1, build_model_2, build_model_3]\n    # loop over three models\n    for m in range(len(models)):\n        model = KerasRegressor(build_fn=models[m], \\\n                               epochs=100, batch_size=20, \\\n                               verbose=0, shuffle=False)\n        kf = KFold(n_splits=3)\n        result = cross_val_score(model, X, y, cv=kf)\n        results_1.append(result)\n    ```", "```py\n    # print the cross-validation scores\n    print(\"Cross-Validation Loss for Model 1 =\", \\\n          abs(results_1[0].mean()))\n    print(\"Cross-Validation Loss for Model 2 =\", \\\n          abs(results_1[1].mean()))\n    print(\"Cross-Validation Loss for Model 3 =\", \\\n          abs(results_1[2].mean()))\n    ```", "```py\n    Cross-Validation Loss for Model 1 = 0.990475798256843\n    Cross-Validation Loss for Model 2 = 0.926532513151634\n    Cross-Validation Loss for Model 3 = 0.9735719371528117\n    ```", "```py\n    \"\"\"\n    define a seed for random number generator so the result will be reproducible\n    \"\"\"\n    np.random.seed(seed)\n    random.set_seed(seed)\n    results_2 = []\n    epochs = [100, 150]\n    batches = [20, 15]\n    # Loop over pairs of epochs and batch_size\n    for e in range(len(epochs)):\n        for b in range(len(batches)):\n            model = KerasRegressor(build_fn= build_model_3, \\\n                                   epochs= epochs[e], \\\n                                   batch_size= batches[b], \\\n                                   verbose=0, \\\n                                   shuffle=False)\n            kf = KFold(n_splits=3)\n            result = cross_val_score(model, X, y, cv=kf)\n            results_2.append(result)\n    ```", "```py\n    \"\"\"\n    Print cross-validation score for each possible pair of epochs, batch_size\n    \"\"\"\n    c = 0\n    for e in range(len(epochs)):\n        for b in range(len(batches)):\n            print(\"batch_size =\", batches[b],\", \\\n                  epochs =\", epochs[e], \", Test Loss =\", \\\n                  abs(results_2[c].mean()))\n            c += 1\n    ```", "```py\n    batch_size = 20 , epochs = 100 , Test Loss = 0.9359159401008821\n    batch_size = 15 , epochs = 100 , Test Loss = 0.9642481369794683\n    batch_size = 20 , epochs = 150 , Test Loss = 0.9561188386646661\n    batch_size = 15 , epochs = 150 , Test Loss = 0.9359079093029896\n    ```", "```py\n    # Modify build_model_2 function\n    def build_model_2(activation='relu', optimizer='adam'):\n        # build the Keras model_2\n        model = Sequential()\n        model.add(Dense(8, input_dim=X.shape[1], \\\n                  activation=activation))\n        model.add(Dense(1))\n        # Compile the model\n        model.compile(loss='mean_squared_error', \\\n                      optimizer=optimizer)\n        # return the model\n        return model\n    results_3 = []\n    activations = ['relu', 'tanh']\n    optimizers = ['sgd', 'adam', 'rmsprop']\n    \"\"\"\n    Define a seed for the random number generator so the result will be reproducible\n    \"\"\"\n    np.random.seed(seed)\n    random.set_seed(seed)\n    # Loop over pairs of activation and optimizer\n    for o in range(len(optimizers)):\n        for a in range(len(activations)):\n            optimizer = optimizers[o]\n            activation = activations[a]\n            model = KerasRegressor(build_fn= build_model_3, \\\n                                   epochs=100, batch_size=20, \\\n                                   verbose=0, shuffle=False)\n            kf = KFold(n_splits=3)\n            result = cross_val_score(model, X, y, cv=kf)\n            results_3.append(result)\n    ```", "```py\n    \"\"\"\n    Print cross-validation score for each possible pair of optimizer, activation\n    \"\"\"\n    c = 0\n    for o in range(len(optimizers)):\n        for a in range(len(activations)):\n            print(\"activation = \", activations[a],\", \\\n                  optimizer = \", optimizers[o], \", \\\n                  Test Loss = \", abs(results_3[c].mean()))\n            c += 1\n    ```", "```py\n    activation =  relu , optimizer =  sgd , Test Loss =  1.0123592540516995\n    activation =  tanh , optimizer =  sgd , Test Loss =  3.393908379781118\n    activation =  relu , optimizer =  adam , Test Loss =  0.9662686089392641\n    activation =  tanh , optimizer =  adam , Test Loss =  2.1369285960222144\n    activation =  relu , optimizer =  rmsprop , Test Loss =  2.1892826984214984\n    activation =  tanh , optimizer =  rmsprop , Test Loss =  2.2029884275363014\n    ```", "```py\nactivation =  relu , optimizer =  rmsprop , Test accuracy =  0.5234657049179077\nactivation =  tanh , optimizer =  rmsprop , Test accuracy =  0.49602887630462644\nactivation =  relu , optimizer =  adam , Test accuracy =  0.5039711117744445\nactivation =  tanh , optimizer =  adam , Test accuracy =  0.4989169597625732\nactivation =  relu , optimizer =  sgd , Test accuracy =  0.48953068256378174\nactivation =  tanh , optimizer =  sgd , Test accuracy =  0.5191335678100586\n```", "```py\noptimizer= adam  test error rate =  25.391812739372256\noptimizer= sgd  test error rate =  25.140230269432067\noptimizer= rmsprop  test error rate =  25.217947859764102\n```"]