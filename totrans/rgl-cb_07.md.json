["```py\n    import torch\n    ```", "```py\n    import torch.nn as nn\n    ```", "```py\n    import torch.nn.functional as F\n    ```", "```py\n    from torch.utils.data import DataLoader\n    ```", "```py\n    from torchvision.datasets import MNIST\n    ```", "```py\n    import torchvision.transforms as transforms\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\ntransform = transforms.Compose([transforms.ToTensor(),\n    transforms.Normalize((0.1307), (0.3081)),\n    transforms.Lambda(torch.flatten)])\n```", "```py\n    trainset = MNIST('./data', train=True, download=True,\n    ```", "```py\n        transform=transform)\n    ```", "```py\n    train_dataloader = DataLoader(trainset, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    testset = MNIST('./data', train=False, download=True,\n    ```", "```py\n        transform=transform)\n    ```", "```py\n    test_dataloader = DataLoader(testset, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    class Net(nn.Module):\n    ```", "```py\n        def __init__(self, input_shape: int,\n    ```", "```py\n        hidden_units: int = 24):\n    ```", "```py\n            super(Net, self).__init__()\n    ```", "```py\n            self.hidden_units = hidden_units\n    ```", "```py\n            self.fc1 = nn.Linear(input_shape,\n    ```", "```py\n                self.hidden_units)\n    ```", "```py\n            self.fc2 = nn.Linear(self.hidden_units,\n    ```", "```py\n                self.hidden_units)\n    ```", "```py\n            self.output = nn.Linear(self.hidden_units, 10)\n    ```", "```py\n        def forward(self,\n    ```", "```py\n            x: torch.Tensor) -> torch.Tensor:\n    ```", "```py\n                x = self.fc1(x)\n    ```", "```py\n                x = F.relu(x)\n    ```", "```py\n                x = self.fc2(x)\n    ```", "```py\n                x = F.relu(x)\n    ```", "```py\n                output = torch.softmax(self.output(x), dim=1)\n    ```", "```py\n                return output\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    net = Net(784)\n    ```", "```py\n    # Generate randomly one random 28x28 image as a 784 values tensor\n    ```", "```py\n    random_data = torch.rand((1, 784))\n    ```", "```py\n    result = net(random_data)\n    ```", "```py\n    print('Resulting output tensor:', result)\n    ```", "```py\n    print('Sum of the output tensor:', result.sum())\n    ```", "```py\nResulting output tensor: tensor([[0.0882, 0.1141, 0.0846, 0.0874, 0.1124, 0.0912, 0.1103, 0.0972, 0.1097,\n         0.1048]], grad_fn=<SoftmaxBackward0>)\nSum of the output tensor: tensor(1.0000, grad_fn=<SumBackward0>)\n```", "```py\n    criterion = nn.CrossEntropyLoss()\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(),\n    ```", "```py\n        lr=0.001, weight_decay=0.001)\n    ```", "```py\n    def epoch_step(net, dataloader, training_set: bool):\n    ```", "```py\n        running_loss = 0.\n    ```", "```py\n        correct = 0.\n    ```", "```py\n        for i, data in enumerate(dataloader, 0):\n    ```", "```py\n            # Get the inputs: data is a list of [inputs, labels]\n    ```", "```py\n            inputs, labels = data\n    ```", "```py\n            if training_set:\n    ```", "```py\n                # Zero the parameter gradients\n    ```", "```py\n                optimizer.zero_grad()\n    ```", "```py\n            # Forward + backward + optimize\n    ```", "```py\n            outputs = net(inputs)\n    ```", "```py\n            loss = criterion(outputs, labels)\n    ```", "```py\n            if training_set:\n    ```", "```py\n                loss.backward()\n    ```", "```py\n                optimizer.step()\n    ```", "```py\n            # Add correct predictions for this batch\n    ```", "```py\n            correct += (outputs.argmax(\n    ```", "```py\n                dim=1) == labels).float().sum()\n    ```", "```py\n            # Compute loss for this batch\n    ```", "```py\n            running_loss += loss.item()\n    ```", "```py\n        return running_loss, correct\n    ```", "```py\n# Create empty lists to store the losses and accuracies\ntrain_losses = []\ntest_losses = []\ntrain_accuracy = []\ntest_accuracy = []\n# Loop over the dataset 20 times for 20 epochs\nfor epoch in range(20):\n    ## Train the model on the training set\n    running_train_loss, correct = epoch_step(net,\n        dataloader=train_dataloader,\n        training_set=True)\n    # Compute and store loss and accuracy for this epoch\n    train_epoch_loss = running_train_loss / len(\n        train_dataloader)\n    train_losses.append(train_epoch_loss)\n    train_epoch_accuracy = correct / len(trainset)\n    train_accuracy.append(train_epoch_accuracy)\n    ## Evaluate the model on the test set\n    #running_test_loss = 0.\n    #correct = 0.\n    net.eval()\n    with torch.no_grad():\n        running_test_loss, correct = epoch_step(net,\n            dataloader=test_dataloader,\n            training_set=False)\n        test_epoch_loss = running_test_loss / len(\n            test_dataloader)\n        test_losses.append(test_epoch_loss)\n        test_epoch_accuracy = correct / len(testset)\n        test_accuracy.append(test_epoch_accuracy)\n    # Print stats\n    print(f'[epoch {epoch + 1}] Training: loss={\n        train_epoch_loss:.3f}accuracy={\n            train_epoch_accuracy:.3f} |\\\n            \\t Test: loss={test_epoch_loss:.3f}\n            accuracy={test_epoch_accuracy:.3f}')\nprint('Finished Training')\n```", "```py\n[epoch 20] Training: loss=1.505 accuracy=0.964 |   Test: loss=1.505 accuracy=0.962\nFinished Training\n```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (CE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    plt.plot(train_accuracy, label='train')\n    ```", "```py\n    plt.plot(test_accuracy, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('Accuracy')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n```", "```py\n    X, y = load_breast_cancer(return_X_y=True)\n    ```", "```py\n    X_train, X_val, y_train, y_val = train_test_split(\n    ```", "```py\n        X.astype(np.float32), y.astype(np.float32),\n    ```", "```py\n        test_size=0.2, random_state=0)\n    ```", "```py\n    class BreastCancerDataset(Dataset):\n    ```", "```py\n        def __init__(self, X: np.array, y: np.array,\n    ```", "```py\n            x_scaler: StandardScaler = None):\n    ```", "```py\n                if x_scaler is None:\n    ```", "```py\n                    self.x_scaler = StandardScaler()\n    ```", "```py\n                    X = self.x_scaler.fit_transform(X)\n    ```", "```py\n                else:\n    ```", "```py\n                    self.x_scaler = x_scaler\n    ```", "```py\n                    X = self.x_scaler.transform(X)\n    ```", "```py\n                self.X = torch.from_numpy(X)\n    ```", "```py\n                self.y = torch.from_numpy(y)\n    ```", "```py\n        def __len__(self) -> int:\n    ```", "```py\n            return len(self.X)\n    ```", "```py\n        def __getitem__(self, idx: int) -> tuple[torch.Tensor]:\n    ```", "```py\n            return self.X[idx], self.y[idx]\n    ```", "```py\n    training_data = BreastCancerDataset(X_train, y_train)\n    ```", "```py\n    val_data = BreastCancerDataset(X_val, y_val,\n    ```", "```py\n        training_data.x_scaler)\n    ```", "```py\n    train_dataloader = DataLoader(training_data,\n    ```", "```py\n        batch_size=64, shuffle=True)\n    ```", "```py\n    val_dataloader = DataLoader(val_data, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    class Net(nn.Module):\n    ```", "```py\n        def __init__(self, input_shape: int,\n    ```", "```py\n            hidden_units: int = 36):\n    ```", "```py\n                super(Net, self).__init__()\n    ```", "```py\n                self.hidden_units = hidden_units\n    ```", "```py\n                self.fc1 = nn.Linear(input_shape,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc2 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.output = nn.Linear(self.hidden_units,\n    ```", "```py\n                    1)\n    ```", "```py\n        def forward(self, x: torch.Tensor) ->\n    ```", "```py\n            torch.Tensor:\n    ```", "```py\n                x = self.fc1(x)\n    ```", "```py\n                x = F.relu(x)\n    ```", "```py\n                x = self.fc2(x)\n    ```", "```py\n                x = F.relu(x)\n    ```", "```py\n                output = torch.sigmoid(self.output(x))\n    ```", "```py\n                return output\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    net = Net(X_train.shape[1])\n    ```", "```py\n    # Generate randomly one random 28x28 image as a 784 values tensor\n    ```", "```py\n    random_data = torch.rand((1, X_train.shape[1]))\n    ```", "```py\n    result = net(random_data)\n    ```", "```py\n    print('Resulting output tensor:', result)\n    ```", "```py\nResulting output tensor: tensor([[0.5674]], grad_fn=<SigmoidBackward0>)\n```", "```py\n    criterion = nn.BCELoss()\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(),\n    ```", "```py\n        lr=0.001)\n    ```", "```py\n    def epoch_step(net, dataloader, training_set: bool):\n    ```", "```py\n        running_loss = 0.\n    ```", "```py\n        correct = 0.\n    ```", "```py\n        for i, data in enumerate(dataloader, 0):\n    ```", "```py\n            # Get the inputs: data is a list of [inputs, labels]\n    ```", "```py\n            inputs, labels = data\n    ```", "```py\n            labels = labels.unsqueeze(1)\n    ```", "```py\n            if training_set:\n    ```", "```py\n                # Zero the parameter gradients\n    ```", "```py\n                optimizer.zero_grad()\n    ```", "```py\n            # Forward + backward + optimize\n    ```", "```py\n            outputs = net(inputs)\n    ```", "```py\n            loss = criterion(outputs, labels)\n    ```", "```py\n            if training_set:\n    ```", "```py\n                loss.backward()\n    ```", "```py\n                optimizer.step()\n    ```", "```py\n            # Add correct predictions for this batch\n    ```", "```py\n            correct += ((\n    ```", "```py\n                outputs > 0.5) == labels).float().sum()\n    ```", "```py\n            # Compute loss for this batch\n    ```", "```py\n            running_loss += loss.item()\n    ```", "```py\n        return running_loss, correct\n    ```", "```py\ndef train_model(net, train_dataloader, val_dataloader, criterion, optimizer, epochs, patience=None):\n    # Create empty lists to store the losses and accuracies\n    train_losses = []\n    val_losses = []\n    train_accuracy = []\n    val_accuracy = []\n    best_val_loss = np.inf\n    best_val_loss_epoch = 0\n    # Loop over the dataset 20 times for 20 epochs\n    for epoch in range(500):\n        ## If the best epoch was more than the patience, just stop training\n        if patience is not None and epoch - best_val_loss_epoch > patience:\n            break\n        ## Train the model on the training set\n        net.train()\n        running_train_loss, correct = epoch_step(net,\n            dataloader=train_dataloader,\n            training_set=True)\n        # Compute and store loss and accuracy for this epoch\n        train_epoch_loss = running_train_loss / len(\n            train_dataloader)\n        train_losses.append(train_epoch_loss)\n        train_epoch_accuracy = correct / len(training_data)\n        train_accuracy.append(train_epoch_accuracy)\n        ## Evaluate the model on the val set\n        net.eval()\n        with torch.no_grad():\n            running_val_loss, correct = epoch_step(\n                net, dataloader=val_dataloader,\n                training_set=False)\n            val_epoch_loss = running_val_loss / len(\n                val_dataloader)\n            val_losses.append(val_epoch_loss)\n            val_epoch_accuracy = correct / len(val_data)\n            val_accuracy.append(val_epoch_accuracy)\n            # If the loss is better than the current best, update it\n            if best_val_loss >= val_epoch_loss:\n                best_val_loss = val_epoch_loss\n                best_val_loss_epoch = epoch + 1\n        # Print stats\n        print(f'[epoch {epoch + 1}] Training: loss={\n            train_epoch_loss:.3f} accuracy={\n            train_epoch_accuracy:.3f} |\\\n                \\t Valid: loss={val_epoch_loss:.3f}\n                accuracy={val_epoch_accuracy:.3f}')\n    return train_losses, val_losses, train_accuracy,\n        val_accuracy\n```", "```py\ntrain_losses, val_losses, train_accuracy,\n    val_accuracy = train_model(\n        net, train_dataloader, val_dataloader,\n        criterion, optimizer, epochs=500\n)\n```", "```py\n[epoch 500] Training: loss=0.000 accuracy=1.000 |   Validation: loss=0.099 accuracy=0.965\n```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(val_losses, label='valid')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (CE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    # Instantiate a fresh model\n    ```", "```py\n    net = Net(X_train.shape[1])\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n    ```", "```py\n    train_losses, val_losses, train_accuracy,\n    ```", "```py\n        val_accuracy = train_model(\n    ```", "```py\n            net, train_dataloader, val_dataloader,\n    ```", "```py\n            criterion, optimizer, patience=30, epochs=500\n    ```", "```py\n    )\n    ```", "```py\n[epoch 134] Training: loss=0.004 accuracy=1.000 |   Valid: loss=0.108 accuracy=0.982\n```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(val_losses, label='validation')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (BCE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\nimport numpy as np\nfrom sklearn.datasets\nimport fetch_california_housing\nfrom sklearn.model_selection\nimport train_test_split\nfrom sklearn.preprocessing\nimport StandardScaler\nfrom sklearn.metrics\nimport r2_score\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n```", "```py\n    X, y = fetch_california_housing(return_X_y=True)\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n    ```", "```py\n        X.astype(np.float32), y.astype(np.float32),\n    ```", "```py\n        test_size=0.2, random_state=0)\n    ```", "```py\n    scaler = StandardScaler()\n    ```", "```py\n    X_train = scaler.fit_transform(X_train)\n    ```", "```py\n    X_test = scaler.transform(X_test)\n    ```", "```py\n    class CaliforniaDataset(Dataset):\n    ```", "```py\n        def __init__(self, X: np.array, y: np.array):\n    ```", "```py\n            self.X = torch.from_numpy(X)\n    ```", "```py\n            self.y = torch.from_numpy(y)\n    ```", "```py\n        def __len__(self) -> int:\n    ```", "```py\n            return len(self.X)\n    ```", "```py\n        def __getitem__(self, idx: int) ->\n    ```", "```py\n            tuple[torch.Tensor]: return self.X[idx], self.y[idx]\n    ```", "```py\n    # Instantiate datasets\n    ```", "```py\n    training_data = CaliforniaDataset(X_train, y_train)\n    ```", "```py\n    test_data = CaliforniaDataset(X_test, y_test)\n    ```", "```py\n    # Instantiate data loaders\n    ```", "```py\n    train_dataloader = DataLoader(training_data,\n    ```", "```py\n        batch_size=64, shuffle=True)\n    ```", "```py\n    test_dataloader = DataLoader(test_data, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    class Net(nn.Module):\n    ```", "```py\n        def __init__(self, input_shape: int,\n    ```", "```py\n            hidden_units: int = 128):\n    ```", "```py\n                super(Net, self).__init__()\n    ```", "```py\n                self.hidden_units = hidden_units\n    ```", "```py\n                self.fc1 = nn.Linear(input_shape,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc2 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc3 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc4 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc5 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.output = nn.Linear(self.hidden_units, 1)\n    ```", "```py\n        def forward(self, x: torch.Tensor) -> torch.Tensor:\n    ```", "```py\n            x = self.fc1(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.fc2(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.fc3(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.fc4(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.fc5(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            output = self.output(x)\n    ```", "```py\n            return output\n    ```", "```py\n    # Instantiate the network\n    ```", "```py\n    net = Net(X_train.shape[1])\n    ```", "```py\n    # Generate one random sample of 8 features\n    ```", "```py\n    random_data = torch.rand((1, X_train.shape[1]))\n    ```", "```py\n    # Compute the forward propagation\n    ```", "```py\n    print(net(random_data))\n    ```", "```py\n    tensor([[0.0674]], grad_fn=<AddmmBackward0>)\n    ```", "```py\n    criterion = nn.MSELoss()\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n    ```", "```py\n    train_losses, test_losses = train_model(net,\n    ```", "```py\n        train_dataloader, test_dataloader, criterion,\n    ```", "```py\n        optimizer, 500)\n    ```", "```py\n[epoch 500] Training: loss=0.013 | Test: loss=0.312\nFinished Training\n```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (MSE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    # Compute the predictions with the trained neural network\n    ```", "```py\n    y_train_pred = net(\n    ```", "```py\n        torch.tensor((X_train))).detach().numpy()\n    ```", "```py\n    y_test_pred = net(\n    ```", "```py\n        torch.tensor((X_test))).detach().numpy()\n    ```", "```py\n    # Compute the R2-score\n    ```", "```py\n    print('R2-score on training set:', r2_score(y_train,\n    ```", "```py\n         y_train_pred))\n    ```", "```py\n    print('R2-score on test set:', r2_score(y_test,\n    ```", "```py\n        y_test_pred))\n    ```", "```py\nR2-score on training set: 0.9922777453770203\nR2-score on test set: 0.7610035849523354\n```", "```py\n    class Net(nn.Module):\n    ```", "```py\n        def __init__(self, input_shape: int,\n    ```", "```py\n            hidden_units: int = 16):\n    ```", "```py\n                super(Net, self).__init__()\n    ```", "```py\n            self.hidden_units = hidden_units\n    ```", "```py\n            self.fc1 = nn.Linear(input_shape,\n    ```", "```py\n                self.hidden_units)\n    ```", "```py\n            self.fc2 = nn.Linear(self.hidden_units,\n    ```", "```py\n                self.hidden_units)\n    ```", "```py\n            self.output = nn.Linear(self.hidden_units, 1)\n    ```", "```py\n        def forward(self, x: torch.Tensor) -> torch.Tensor:\n    ```", "```py\n            x = self.fc1(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.fc2(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            output = self.output(x)\n    ```", "```py\n            return output\n    ```", "```py\n    # Instantiate the network\n    ```", "```py\n    net = Net(X_train.shape[1])\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(),\n    ```", "```py\n        lr=0.001)\n    ```", "```py\n    train_losses, test_losses = train_model(net,\n    ```", "```py\n        train_dataloader, test_dataloader, criterion,\n    ```", "```py\n        optimizer, 500)\n    ```", "```py\n    [epoch 500] Training: loss=0.248 | Test: loss=0.273\n    ```", "```py\n    Finished Training\n    ```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (MSE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    # Compute the predictions with the trained neural network\n    ```", "```py\n    y_train_pred = net(\n    ```", "```py\n        torch.tensor((X_train))).detach().numpy()\n    ```", "```py\n    y_test_pred = net(\n    ```", "```py\n        torch.tensor((X_test))).detach().numpy()\n    ```", "```py\n    # Compute the R2-score\n    ```", "```py\n    print('R2-score on training set:', r2_score(y_train,\n    ```", "```py\n        y_train_pred))\n    ```", "```py\n    print('R2-score on test set:', r2_score(y_test,\n    ```", "```py\n        y_test_pred))\n    ```", "```py\nR2-score on training set: 0.8161885562733123\nR2-score on test set: 0.7906037325658601\n```", "```py\nsum(p.numel() for p in net.parameters() if p.requires_grad)\n```", "```py\nimport numpy as np\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\n```", "```py\n    X, y = load_digits(return_X_y=True)\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n    ```", "```py\n        X.astype(np.float32), y.astype(np.int64),\n    ```", "```py\n        test_size=0.2, random_state=0)\n    ```", "```py\n    class DigitsDataset(Dataset):\n    ```", "```py\n        def __init__(self, X: np.array, y: np.array):\n    ```", "```py\n            self.X = torch.from_numpy(X/255)\n    ```", "```py\n            self.y = torch.from_numpy(y)\n    ```", "```py\n        def __len__(self) -> int:\n    ```", "```py\n            return len(self.X)\n    ```", "```py\n        def __getitem__(self, idx: int) -> tuple[torch.Tensor]:\n    ```", "```py\n            return self.X[idx], self.y[idx]\n    ```", "```py\n    # Instantiate datasets\n    ```", "```py\n    training_data = DigitsDataset(X_train, y_train)\n    ```", "```py\n    test_data = DigitsDataset(X_test, y_test)\n    ```", "```py\n    # Instantiate data loaders\n    ```", "```py\n    train_dataloader = DataLoader(training_data,\n    ```", "```py\n        batch_size=64, shuffle=True)\n    ```", "```py\n    test_dataloader = DataLoader(test_data, batch_size=64,\n    ```", "```py\n        shuffle=True)\n    ```", "```py\n    class Net(nn.Module):\n    ```", "```py\n        def __init__(self, input_shape: int,\n    ```", "```py\n            hidden_units: int = 128,\n    ```", "```py\n            dropout: float = 0.25):\n    ```", "```py\n                super(Net, self).__init__()\n    ```", "```py\n                self.hidden_units = hidden_units\n    ```", "```py\n                self.fc1 = nn.Linear(input_shape,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc2 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.fc3 = nn.Linear(self.hidden_units,\n    ```", "```py\n                    self.hidden_units)\n    ```", "```py\n                self.dropout = nn.Dropout(p=dropout)\n    ```", "```py\n                self.output = nn.Linear(self.hidden_units, 10)\n    ```", "```py\n        def forward(self, x: torch.Tensor) -> torch.Tensor:\n    ```", "```py\n            x = self.fc1(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.dropout(x)\n    ```", "```py\n            x = self.fc2(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.dropout(x)\n    ```", "```py\n            x = self.fc3(x)\n    ```", "```py\n            x = F.relu(x)\n    ```", "```py\n            x = self.dropout(x)\n    ```", "```py\n            output = torch.softmax(self.output(x), dim=1)\n    ```", "```py\n            return output\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    net = Net(X_train.shape[1], dropout=0)\n    ```", "```py\n    # Generate randomly one random 28x28 image as a 784 values tensor\n    ```", "```py\n    random_data = torch.rand((1, 64))\n    ```", "```py\n    result = net(random_data)\n    ```", "```py\n    print('Resulting output tensor:', result)\n    ```", "```py\n    print('Sum of the output tensor:', result.sum())\n    ```", "```py\nResulting output tensor: tensor([[0.0964, 0.0908, 0.1043, 0.1083, 0.0927, 0.1047, 0.0949, 0.0991, 0.1012,\n         0.1076]], grad_fn=<SoftmaxBackward0>)\nSum of the output tensor: tensor(1., grad_fn=<SumBackward0>)\n```", "```py\n    criterion = nn.CrossEntropyLoss()\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n    ```", "```py\n    train_losses, test_losses, train_accuracy,\n    ```", "```py\n        test_accuracy = train_model(\n    ```", "```py\n            net, train_dataloader, test_dataloader,\n    ```", "```py\n            criterion, optimizer, epochs=500\n    ```", "```py\n    )\n    ```", "```py\n[epoch 500] Training: loss=1.475 accuracy=0.985 |       Test: loss=1.513 accuracy=0.947\nFinished Training\n```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (CE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    plt.plot(train_accuracy, label='train')\n    ```", "```py\n    plt.plot(test_accuracy, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('Accuracy')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    net = Net(X_train.shape[1], dropout=0.25)\n    ```", "```py\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n    ```", "```py\n    train_losses, test_losses, train_accuracy, test_accuracy = train_model(\n    ```", "```py\n        net, train_dataloader, test_dataloader, criterion,\n    ```", "```py\n            optimizer, epochs=500\n    ```", "```py\n    )\n    ```", "```py\n    [epoch 500] Training: loss=1.472 accuracy=0.990 |       Test: loss=1.488 accuracy=0.975\n    ```", "```py\n    Finished Training\n    ```", "```py\n    plt.plot(train_losses, label='train')\n    ```", "```py\n    plt.plot(test_losses, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('loss (CE)')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```", "```py\n    plt.plot(train_accuracy, label='train')\n    ```", "```py\n    plt.plot(test_accuracy, label='test')\n    ```", "```py\n    plt.xlabel('epoch')\n    ```", "```py\n    plt.ylabel('Accuracy')\n    ```", "```py\n    plt.legend()\n    ```", "```py\n    plt.show()\n    ```"]