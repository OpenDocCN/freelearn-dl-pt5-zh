<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
  <meta charset="utf-8"/>
  <meta name="generator" content="pandoc"/>
  <title>ch014.xhtml</title>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
</head>
<body epub:type="bodymatter">
<section id="chapter-9-next-steps-in-bayesian-deep-learning" class="level1 chapterHead" data-number="14">
<h1 class="chapterHead" data-number="14"><span class="titlemark">Chapter 9</span><br/>
<span id="x1-1780009"></span>Next Steps in Bayesian Deep Learning</h1>
<p>Throughout this book, we’ve covered the fundamental concepts behind Bayesian deep learning (BDL), from understanding what uncertainty is and its role in developing robust machine learning systems, right through to learning how to implement and analyze the performance of several fundamental BDL. While what you’ve learned will equip you to start developing your own BDL solutions, the field is moving quickly, and there are many new techniques on the horizon.</p>
<p>To wrap up the book, in this chapter we’ll take a look at the current trends in BDL, before we dive into some of the latest developments in the field. We’ll conclude by introducing some alternatives to BDL, and provide some advice on additional resources you can use to continue your journey into Bayesian machine learning methods.</p>
<p>We’ll cover the following sections:</p>
<ul>
<li><p>Current trends in BDL</p></li>
<li><p>How are BDL methods being applied to solve real-world problems?</p></li>
<li><p>Latest methods in BDL</p></li>
<li><p>Alternatives to BDL</p></li>
<li><p>Your next steps in BDL</p></li>
</ul>
<p><span id="x1-178001r273"></span></p>
<section id="current-trends-in-bdl" class="level2 sectionHead" data-number="14.1">
<h2 class="sectionHead" data-number="14.1" id="sigil_toc_id_101"><span class="titlemark">9.1 </span> <span id="x1-1790001"></span>Current trends in BDL</h2>
<p>In this section, we’ll explore the current trends in BDL.<span id="dx1-179001"></span> We’ll look at which models are particularly popular in the literature and discuss why certain models have been selected for certain applications. This should give you a good imdivssion of how the fundamentals covered throughout the book apply more broadly across a variety of application domains.</p>
<div class="IMG---Figure">
<img src="../media/file182.png" alt="PIC"/> <span id="x1-179002r1"></span> <span id="x1-179003"></span></div>
<p class="IMG---Caption">Figure 9.1: Popularity of key BDL search terms over time 
</p>
<p>As we see in <em>Figure</em> <a href="#x1-179002r1">9.1</a>, there’s been a marked increase in popularity of search terms related to BDL over the past decade. Unsurprisingly, this follows the trend in the popularity of deep learning search terms, as we see in <em>Figure</em> <a href="#x1-179004r2"><em>9.2</em></a>; as deep learning has become more popular, there has been increased interest in quantifying the uncertainty associated with the predictions produced by DNNs. Interestingly, these plots both show a similar dip in popularity in mid-late 2021, indicating that as long as deep learning is popular, there will also be interest in BDL.</p>
<div class="IMG---Figure">
<img src="../media/file183.png" alt="PIC"/> <span id="x1-179004r2"></span> <span id="x1-179005"></span></div>
<p class="IMG---Caption">Figure 9.2: Popularity of key deep learning search terms over time 
</p>
<p><em>Figure</em> <a href="#x1-179002r1">9.1</a> demonstrates another interesting point in that, generally speaking, the term <em>variational inference</em> is more popular than the other two BDL-related search terms we’ve used here. As mentioned in <a href="CH5.xhtml#x1-600005"><em>Chapter 5</em></a>, <a href="CH5.xhtml#x1-600005"><em>Principled Approaches</em> <em>for Bayesian Deep Learning</em></a> when we covered variational autoencoders, variational inference is one component of BDL that has made significant waves in the machine learning community, now being a feature of many different deep learning architectures. As such, it’s no surprise that it is generally more popular than the terms that explicitly include the word ”Bayesian.”</p>
<p>But where do the methods that we’ve explored in the book fit in terms of their popularity and integration into a wide variety of deep learning solutions?<span id="dx1-179006"></span> We can learn more about this simply by looking at the citations for each of the original papers.</p>
<div class="IMG---Figure">
<img src="../media/file184.png" alt="PIC"/> <span id="x1-179007r3"></span> <span id="x1-179008"></span></div>
<p class="IMG---Caption">Figure 9.3: Popularity of key deep learning search terms over time 
</p>
<p>In <em>Figure</em> <a href="#x1-179007r3"><em>9.3</em></a>, we see that the MC dropout paper is by far the most popular paper when it comes to citations – coming in at nearly double that of the next most popular method. At this point in the book, the reasons for this should be fairly clear: not only is it one of the easiest methods to implement (as we saw in <a href="CH6.xhtml#x1-820006"><em>Chapter 6</em></a>, <a href="CH6.xhtml#x1-820006"><em>Using the Standard Toolbox for Bayesian Deep Learning</em></a>), but it’s also one of the most attractive from a computation standpoint. It requires no more memory than a standard neural network and, as we saw in <a href="CH7.xhtml#x1-1130007"><em>Chapter 7</em></a>, <a href="CH7.xhtml#x1-1130007"><em>Practical</em> <em>Considerations for Bayesian Deep Learning</em></a>, it’s also one of the fastest models for running inference. These practical factors often weigh in more heavily than considerations such as uncertainty quality when it comes to selecting models.</p>
<p>Practical considerations are again likely the reason behind the second most popular method being deep ensembles. While this may not be the most efficient method in terms of training time, it’s often the speed of inference that counts the most: and again, looking back to <a href="CH7.xhtml#x1-1130007"><em>Chapter 7</em></a>, <a href="CH7.xhtml#x1-1130007"><em>Practical</em> <em>Considerations for Bayesian Deep Learning</em></a>’s results, we see that the ensemble excels here, despite needing to run inference on multiple different networks.</p>
<p>Deep ensembles often strike a good balance between ease of implementation and theoretical considerations: as discussed in <a href="CH6.xhtml#x1-820006"><em>Chapter 6</em></a>, <a href="CH6.xhtml#x1-820006"><em>Using the Standard Toolbox</em> <em>for Bayesian Deep Learning</em></a>, ensembling is a powerful tool within ML, and so it’s no surprise that NN ensembles perform well and often produce well-calibrated uncertainty estimates.</p>
<p>The last two methods, taking third and fourth place respectively, are BBB and PBP. While BBB is far easier to implement than PBP, the fact that it requires some probabilistic components often means that – while in many cases it may be the best tool for the job – machine learning engineers may not be aware of it or aren’t comfortable implementing it. PBP takes this to a further extreme: as we saw in <a href="CH5.xhtml#x1-600005"><em>Chapter 5</em></a>, <a href="CH5.xhtml#x1-600005"><em>Principled Approaches for</em> <em>Bayesian Deep Learning</em></a>, implementing PBP is not a straightforward task. At the time of writing, there are no deep learning frameworks that incorporate an easy-to-use and well-optimized implementation of PBP, and – apart from the BDL community – many machine learning researchers and practitioners just aren’t aware of its existence, as is made clear by the fact that it has fewer citations (although it still has a fairly impressive citation count!).</p>
<p>This analysis of the popularity of Bayesian deep learning methods seems to tell a pretty clear story: BNN approaches are chosen based primarily on the ease of implementation. Indeed, there is a significant amount of literature that discusses the use of BDL methods for their uncertainty estimates without considering the <em>quality</em> of the model uncertainty estimates. Fortunately, with the increasing popularity of uncertainty-aware methods, this trend is beginning to decline, and we hope that this book has equipped you with the necessary tools to allow you to be more principled in your selection of BNN methods.<span id="dx1-179009"></span> Irrespective of the methods used or how they’re selected, it’s clear that machine learning researchers and practitioners are increasingly interested in BDL approaches – so what are these methods being used for? Let’s take a look. <span id="x1-179010r275"></span></p>
</section>
<section id="how-are-bdl-methods-being-applied-to-solve-real-world-problems" class="level2 sectionHead" data-number="14.2">
<h2 class="sectionHead" data-number="14.2" id="sigil_toc_id_102"><span class="titlemark">9.2 </span> <span id="x1-1800002"></span>How are BDL methods being applied to solve real-world problems?</h2>
<p>Just as deep learning is having an impact on a diverse variety of application domains, BDL is becoming an increasingly important tool, particularly where large amounts of data are being used within safety-critical or mission-critical systems.<span id="dx1-180001"></span> In these cases – as is the case for most real-world applications – being able to quantify when models ”know they don’t know” is crucial to developing reliable and robust systems.</p>
<p>One significant application area for BDL is in safety-critical systems. In their 2019 paper titled <em>Safe Reinforcement Learning with Model Uncertainty</em> <em>Estimates</em>, Björn Lütjens <em>et al.</em> demonstrate that the use of BDL methods can produce safer behavior in collision-avoidance scenarios (the inspiration for our reinforcement learning example in <a href="CH8.xhtml#x1-1320008"><em>Chapter 8</em></a>, <a href="CH8.xhtml#x1-1320008"><em>Applying Bayesian Deep</em> <em>Learning</em></a>).</p>
<p>Similarly, in the paper <em>Uncertainty-Aware Deep Learning for Safe Landing</em> <em>Site Selection</em>, authors Katharine Skinner <em>et al.</em> explore how Bayesian neural networks can be used for autonomous hazard detection for landing sites on planetary surfaces. This technology is crucial for facilitating autonomous landing, and recently DNNs have demonstrated significant aptitude for this application. In their paper, Skinner <em>et al.</em> demonstrate that the use of uncertainty-aware models can improve the selection of safe landing sites, and even make it possible to select safe landing sites from sensor data with large amounts of noise. This is testament to BDL’s capacity to improve both the <em>safety</em> and <em>robustness</em> of deep learning methods.</p>
<p>Given their rising popularity in safety-critical scenarios, it should be no surprise that Bayesian neural networks have also been adopted within medical applications. As we touched on in <a href="CH1.xhtml#x1-150001"><em>Chapter 1</em></a>, <a href="CH1.xhtml#x1-150001"><em>Bayesian Inference in the Age of</em> <em>Deep Learning</em></a>, deep learning has exhibited particularly strong performance in the field of medical imaging. However, in these sorts of critical applications, uncertainty quantification is crucial: technicians and diagnosticians need to be able to understand the margin of error associated with model predictions. In the paper <em>Towards Safe Deep Learning: Accurately Quantifying Biomarker</em> <em>Uncertainty in Neural Network predictions</em>, Zach Eaton-Rosen <em>et al.</em> applied BDL methods for quantifying biomarker uncertainty when using deep networks for tumor volume estimation. Their work demonstrates that Bayesian neural networks can be used to design deep learning systems with well-calibrated error bars. These high-quality uncertainty estimates are necessary for the safe clinical use of models based on deep networks, making BDL methods crucial when it comes to incorporating these models in diagnostic applications.</p>
<p>As technology advances, so does our ability to collect and organize data. This trend is turning a lot of ”small data” problems into ”big data” problems – which is no bad thing, as more data means we’re able to learn much more about the underlying process generating the data. One such example is that of seismic monitoring: over recent years, there has been a significant increase in dense seismic monitoring networks. This is excellent from a monitoring standpoint: scientists now have more data than ever before, and are thus able to better understand and monitor geophysical processes. However, in order to do so, they also need to be able to learn from large amounts of high dimensional data.</p>
<p>In their paper, <em>Bayesian Deep Learning and Uncertainty Quantification Applied</em> <em>to Induced Seismicity Locations in the Groningen Gas Field in the Netherlands:</em> <em>What Do We Need for Safe AI?</em>, authors Chen Gu <em>et al.</em> tackle the problem of seismic monitoring of the Groningen gas reservoir. As they mention in the paper, while deep learning has been applied to many geophysical problems, the use of uncertainty-aware deep networks is rare. Their work demonstrates that Bayesian neural networks can successfully be applied to geophysical problems and, in the case of the Groningen gas reservoir, could be crucial from both a safety-critical <em>and</em> mission-critical standpoint. From the safety perspective, these methods can be used to leverage the vast amounts of data to develop models that can infer ground motion activity and be used for seismic early warning systems.<span id="dx1-180002"></span> From the mission-critical perspective, the same data can be ingested by these methods to produce models capable of reservoir production estimates.</p>
<p>In both cases, uncertainty quantification is key if these methods are going to be incorporated into any real-world systems, as the consequences for trusting incorrect predictions could be costly or even catastrophic.</p>
<p>These examples have given us some insight into how BDL is being applied in the real world. As with other machine learning solutions before them, we learn more about potential shortcomings as the methods are used in more and more diverse sets of applications. In the next section, we’ll learn about some of the latest developments in the field, building on the core approaches covered in the book to develop increasingly robust BNN approximations. <span id="x1-180003r279"></span></p>
</section>
<section id="latest-methods-in-bdl" class="level2 sectionHead" data-number="14.3">
<h2 class="sectionHead" data-number="14.3" id="sigil_toc_id_103"><span class="titlemark">9.3 </span> <span id="x1-1810003"></span>Latest methods in BDL</h2>
<p>In this book, we’ve introduced some of the core techniques used within BDL: Bayes by Backprop (BBB), Probabilistic Backpropagation (PBP), Monte-Carlo dropout (MC dropout), and deep ensembles.<span id="dx1-181001"></span> Many BNN approaches you’ll encounter in the literature will be based on one of these methods, and having these under your belt provides you with a versatile toolbox of approaches for developing your own BDL solutions. However, as with all aspects of machine learning, the field of BDL is progressing rapidly, and new techniques are being developed on a regular basis. In this section, we’ll explore a selection of recent developments from the field. <span id="x1-181002r255"></span></p>
<section id="combining-mc-dropout-and-deep-ensembles" class="level3 subsectionHead" data-number="14.3.1">
<h3 class="subsectionHead" data-number="14.3.1" id="sigil_toc_id_104"><span class="titlemark">9.3.1 </span> <span id="x1-1820001"></span>Combining MC dropout and deep ensembles</h3>
<p>Why use just one Bayesian neural network technique when you could use two?<span id="dx1-182001"></span> This is exactly the approach taken by University of Edinburgh researchers Remus Pop and Patric Fulop in their paper, <em>Deep Ensemble Bayesian</em> <em>Active Learning: Addressing the Mode Collapse Issue in Monte Carlo</em> <em>Dropout via Ensembles</em>. In this work, Pop and Fulop describe the problem of using <strong>active learning</strong> to make deep learning methods feasible in applications for which labeling data is time consuming or costly. The issue here is that, as we’ve discussed previously, deep learning methods have proven to be incredibly successful across a range of medical imaging tasks. The issue is that this data needs to be carefully labeled, and for deep networks to achieve high levels of performance, they need <em>a lot</em> of this data.</p>
<p>As such, active learning has been proposed by machine learning researchers to automatically evaluate new data points and add them to the dataset, using <strong>acquisition functions</strong> to determine when new data should be added to the training set. Model uncertainty estimates are a key piece of puzzle: they provide a key measure of how new data points relate to the model’s existing understanding of the domain. In their paper, Pop and Fulop demonstrate that a popular method for <strong>Deep Bayesian Active</strong> <strong>Learning (DBAL)</strong> has a key shortcoming: that of over-confidence stemming from the MC dropout models used in DBAL. In their paper, the authors address this through combining both deep ensembles and MC dropout in a single model. <span id="dx1-182002"></span>They demonstrate that the resulting model has better calibrated uncertainty estimates, thus correcting for the over-confident predictions exhibited by MC dropout. The resulting method, dubbed <strong>deep</strong> <strong>ensemble Bayesian active learning</strong>, provides a framework for robustly employing deep learning methods in applications for which data acquisition is difficult or expensive – demonstrating again how BDL is proving to be an important building block in deploying deep networks in the real world.</p>
<div class="IMG---Figure">
<img src="../media/file185.jpg" class="graphics" alt="PIC"/> <span id="x1-182003r4"></span> <span id="x1-182004"></span></div>
<p class="IMG---Caption">Figure 9.4: Illustration of a combined MC dropout and deep ensemble network 
</p>
<p>This approach of combining deep ensembles and MC dropout has also been applied in other applications. For example, the collision avoidance paper mentioned previously by Lütjens <em>et al.</em> also uses a combined MC dropout and deep ensemble network. This goes to show that it’s not always simply a case of choosing one network over another – sometimes combining approaches is key to developing robust, better calibrated BDL solutions. <span id="x1-182005r281"></span></p>
</section>
<section id="improving-deep-ensembles-by-promoting-diversity" class="level3 subsectionHead" data-number="14.3.2">
<h3 class="subsectionHead" data-number="14.3.2" id="sigil_toc_id_105"><span class="titlemark">9.3.2 </span> <span id="x1-1830002"></span>Improving deep ensembles by promoting diversity</h3>
<p>As we saw earlier in the chapter, judging by the number of citations, deep ensembles are the second most popular of the key BDL techniques covered in this book.<span id="dx1-183001"></span> As such, it’s no surprise that researchers have been investigating methods to improve on the standard implementation of deep ensembles.</p>
<p>In Tim Pearce <em>et al.</em>’s paper, <em>Uncertainty in Neural Networks: Approximately</em> <em>Bayesian Ensembling</em>, the authors highlight that the standard deep ensemble approach has been criticized for not being Bayesian and argue that the standard approach likely lacks diversity in many cases, thus producing a poorly descriptive posterior. In other words, deep ensembles often result in over-confident predictions due to a lack of diversity in the ensemble.</p>
<p>To remedy this, the authors propose a method they term <strong>anchored</strong> <strong>ensembling</strong>.<span id="dx1-183002"></span> Anchored ensembling, like deep ensembles, uses an ensemble of NNs. However, it uses a specially adapted loss function that penalizes the ensemble members’ parameters from drifting too far from their initial values. Let’s take a look:</p>
<div class="math-display">
<img src="../media/file186.jpg" class="math-display" alt="Lossj = 1-||y − ˆy||2+ -1||Γ 12 × (𝜃j − 𝜃anc,j)||2 N 2 N 2 "/>
</div>
<p>Here, the <em>Loss</em><sub><em>j</em></sub> is the loss computed for the <em>j</em>th network in the ensemble. We see a familiar loss in the equation in the form of <span class="cmsy-10x-x-109">||</span><strong>y</strong> <span class="cmsy-10x-x-109">−</span><span class="accenthat"><strong>y</strong></span><span class="cmsy-10x-x-109">||</span><sub><span class="cmr-8">2</span></sub><sup><span class="cmr-8">2</span></sup>. Γ is a diagonal regularization matrix, and <em>𝜃</em><sub><em>j</em></sub> are the parameters for the network. The key point here is the relationship between <em>𝜃</em><sub><em>j</em></sub> and the <em>𝜃</em><sub><em>anc,j</em></sub> variable. Here, the <em>anc</em> indicates the anchoring from which the method gets its name. These parameters, <em>𝜃</em><sub><em>anc,j</em></sub>, are the set of initial parameters for the <em>j</em>th network. As such (as we see by the multiplication), if this value is large – in other words, if <em>𝜃</em><sub><em>j</em></sub> and <em>𝜃</em><sub><em>anc,j</em></sub> are significantly different – the loss will increase. Thus, this penalizes the networks in the ensemble if they deviate too far from their initial values, forcing them to find parameter values that minimize the first term in the equation while staying as close to their initial values as possible.</p>
<p>This is important because, if we use an initialization strategy that is more likely to produce a diverse set of initial parameter values, then maintaining that diversity will ensure that our ensemble comprises diverse networks after training. As the authors demonstrate in the paper, this diversity is key to producing principled uncertainty estimates: ensuring that the network predictions converge for regions of high data, and diverge in regions of low data, just as we saw in our GP examples from <a href="CH2.xhtml#x1-250002"><em>Chapter 2</em></a>, <a href="CH2.xhtml#x1-250002"><em>Fundamentals of Bayesian</em> <em>Inference</em></a>:</p>
<div class="IMG---Figure">
<img src="../media/file52.png" alt="PIC"/> <span id="x1-183003r5"></span> <span id="x1-183004"></span></div>
<p class="IMG---Caption">Figure 9.5: Illustration of principled uncertainty estimates obtained using a Gaussian process 
</p>
<p>As a reminder, here the solid line is the true function, the dots are the samples from the function, the dotted line are the mean GP predictions, the faint dotted lines are a sample of possible functions, and the shaded area is the uncertainty.<span id="dx1-183005"></span></p>
<p>In their paper, Pearce <em>et al.</em> demonstrate that their anchored ensemble approach is able to approximate a descriptive posterior distribution such as this far more closely than the standard deep ensemble approach. <span id="x1-183006r283"></span></p>
</section>
<section id="uncertainty-in-very-large-networks" class="level3 subsectionHead" data-number="14.3.3">
<h3 class="subsectionHead" data-number="14.3.3" id="sigil_toc_id_106"><span class="titlemark">9.3.3 </span> <span id="x1-1840003"></span>Uncertainty in very large networks</h3>
<p>While the core aim topic of the book has been to introduce methods for approximating Bayesian inference in DNNs, we haven’t addressed how this is applied to one of the most successful NN architecture varieties of recent years: the transformer. Transformers<span id="dx1-184001"></span> – just as more typical deep networks before them – have achieved landmark performance in a variety of tasks. While deep networks were already crunching large amounts of data, transformers take this to the next level: crunching enormous volumes of data, and comprising hundreds of billions of parameters. One of the most well-known transformer networks is GPT-3, a transformer developed by OpenAI that comprises over 175 billion parameters.</p>
<p>Transformers were first used in <strong>Natural Language Processing</strong> (<strong>NLP</strong>) tasks, and demonstrated that, through the use of self-attention and sufficient volumes of data, competitive performance can be achieved without the use of recurrent neural networks.<span id="dx1-184002"></span> This was an important step in NN architecture development: demonstrating that sequential context can be learned through self-attention and providing architectures capable of learning from hitherto unprecedented volumes of data.</p>
<div class="IMG---Figure">
<img src="../media/file187.png" alt="PIC"/> <span id="x1-184003r6"></span> <span id="x1-184004"></span></div>
<p class="IMG---Caption">Figure 9.6: Illustration of the transformer architecture 
</p>
<p>However, just as with the trend of more typical deep networks before them, the parameters of transformers are point estimates, rather than distributions, thus preventing them from being used for uncertainty quantification.<span id="dx1-184005"></span> Authors Boyang Xue <em>et al.</em> sought to remedy this in their paper, <em>Bayesian Transformer</em> <em>Language Models for Speech Recognition</em>. In their work, they demonstrate the variational inference can be successfully applied to transformer models, facilitating approximate Bayesian inference. However, due to the large size of transformers, Bayesian parameter estimation for all parameters is incredibly expensive. As such, Xue <em>et al.</em> apply Bayesian estimation to a subset of model parameters, specifically the parameters in the feed-forward and multi-head self-attention modules. As we see from <em>Figure</em> <a href="#x1-184003r6"><em>9.6</em></a>, this excludes quite a few layers from the variational sampling process, thus saving compute cycles.</p>
<p>Another method proposed in the paper <em>Transformers Can Do Bayesian</em> <em>Inference</em>, by Samuel Müller <em>et al.</em>, approximates Bayesian inference by exploiting the large amount of data used to train transformers. In their approach, dubbed <strong>Prior-Data Fitted Networks (PFNs)</strong><span id="dx1-184006"></span>, the authors restate the problem of posterior approximation as a supervised learning task. That is to say, rather than obtaining a distribution of predictions via sampling, their method learns to approximate the posterior predictive distribution directly from dataset samples.</p>
<div class="algorithm">
<span id="x1-184007r1"></span> <span id="x1-184008"></span>
<span class="id">Algorithm 1: </span><span class="content">PFN model training procedure </span>
  <strong>Input:</strong> A prior distribution over datasets <em>p</em>(<em>D</em>), from which samples can be drawn and the number of samples <em>K</em> to draw
<p>  <strong>Output:</strong> A model <em>q𝜃</em> that will approximate the PPD Initialize the neural network <em>q𝜃</em></p>
<div class="algorithmic">
<strong>for</strong> <span class="cmitt-10x-x-109">i:=1 to 10</span> <strong>do</strong>- <span class="label-13.14pt"> <span class="cmr-9">1:</span> </span> <span class="algorithmic">  <code>Sample </code><em>D</em> <span class="cmsy-10x-x-109">∪</span> (<em>x</em><sub><em>i</em></sub><em>,y</em><sub><em>i</em></sub>)<sub><em>i</em><span class="cmr-8">=1</span></sub><sup><em>m</em></sup> <span class="cmsy-10x-x-109">≈ </span><em>p</em>(<em>D</em>) </span><br/>
<span class="label-13.14pt"> <span class="cmr-9">2:</span></span> <span class="algorithmic"> <code>Compute stochastic loss approximation</code> <span class="accentbar"><em>l</em></span><sub><em>𝜃</em></sub> = <span class="cmex-10x-x-109">∑</span> <sub><em>i</em><span class="cmr-8">=1</span></sub><sup><em>m</em></sup>(<span class="cmsy-10x-x-109">−</span>log <em>q</em><sub><em>𝜃</em></sub>(<em>y</em><sub><em>i</em></sub><span class="cmsy-10x-x-109">|</span><em>x</em><sub><em>i</em></sub><em>,D</em>)) </span><br/>
<span class="label-13.14pt"> <span class="cmr-9">3:</span></span> <span class="algorithmic"> <em>Update parameters</em> <em>𝜃</em> <em>with stochastic gradient descent on</em> <span class="msam-10x-x-109">▿</span><sub><em>𝜃</em></sub><span class="accentbar"><em>l</em></span><sub><em>𝜃</em></sub> =0</span>
</div>
</div>
<p>As represented in the pseudo code here, during training, the model samples multiple subsets of data comprising inputs <em>x</em> and labels <em>y</em>. It then masks one of the labels and learns to make a probabilistic prediction for this label based on the other data points. This allows the PFN to do probabilistic inference in a single forward pass – similarly to what we saw in <a href="CH5.xhtml#x1-600005"><em>Chapter 5</em></a>, <a href="CH5.xhtml#x1-600005"><em>Principled Approaches</em> <em>for Bayesian Deep Learning</em></a> with PBP. While approximating Bayesian inference in a single forward pass is desirable for any application, this is even more valuable with transformers<span id="dx1-184009"></span> given their huge numbers of parameters – thus making the PFN approach described here particularly attractive.</p>
<p>Of course, transformers are popularly used within transfer learning contexts: using the rich feature embeddings from transformers as inputs to smaller, less computationally demanding networks. As such, perhaps the most obvious way to use transformers in a Bayesian context would be to use its embeddings as an input to a BDL network – in fact, this is probably the most sensible first step in many cases.</p>
<p>In this section, we’ve explored some of the recent developments in BDL. All of these build on, and apply directly to, the methods we’ve introduced in the book, and you may want to consider implementing these when developing your own solutions for approximate Bayesian inference with deep networks. However, given the pace of research in machine learning, the list of improvements to Bayesian approximations is ever-growing, and we encourage you to explore the literature for yourself to discover the variety of ways in which researchers are learning to implement Bayesian inference at scale and with a variety of computational and theoretical advantages. That said, BDL isn’t always the correct solution, and in the next section, we’ll explore why. <span id="x1-184010r280"></span></p>
</section>
</section>
<section id="alternatives-to-bayesian-deep-learning" class="level2 sectionHead" data-number="14.4">
<h2 class="sectionHead" data-number="14.4" id="sigil_toc_id_107"><span class="titlemark">9.4 </span> <span id="x1-1850004"></span>Alternatives to Bayesian deep learning</h2>
<p>While the focus of the book is on Bayesian inference with DNNs, these aren’t always the best choice for the job. Generally speaking, they’re a great choice when you have large amounts of high dimensional data.<span id="dx1-185001"></span> As we discussed in <a href="CH3.xhtml#x1-350003"><em>Chapter 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a> (and as you probably know), deep networks excel in these scenarios, and thus adapting them for Bayesian inference is a sensible choice. On the other hand, if you have small amounts of low-dimensional data (with tens of features, fewer than 10,000 data points), then you may be better off with more traditional, well-principled Bayesian inference, such as via sampling or GPs.</p>
<p>That said, there has been interest in scaling GPs, and the research community has developed GP-based methods that both scale to large amounts of data and are capable of complex non-linear transformations. In this section, we’ll introduce these alternatives in case you wish to pursue them further. <span id="x1-185002r285"></span></p>
<section id="scalable-gaussian-processes" class="level3 subsectionHead" data-number="14.4.1">
<h3 class="subsectionHead" data-number="14.4.1" id="sigil_toc_id_108"><span class="titlemark">9.4.1 </span> <span id="x1-1860001"></span>Scalable Gaussian processes</h3>
<p>At the beginning of the book, we introduced GPs<span id="dx1-186001"></span> and discussed why they are the gold standard when <span id="dx1-186002"></span>it comes to principled and reasonably computationally tractable uncertainty quantification in machine learning. Crucially, we talked about the limits of GPs: they become computationally infeasible with high-dimensional data or large amounts of data.</p>
<p>However, GPs are extremely powerful tools, and the machine learning community wasn’t ready to give up on them. In <a href="CH2.xhtml#x1-250002"><em>Chapter 2</em></a>, <a href="CH2.xhtml#x1-250002"><em>Fundamentals of Bayesian</em> <em>Inference</em></a>, we discussed the key prohibitive factor in GP training and inference: inverting the covariance matrix. While methods exist for making this more computationally tractable (such as Cholesky decomposition), these methods only get us so far. As such, the key methods for making GPs scalable are termed <em>sparse GPs</em>, and they looks to solve the problem of intractable GP training by modifying the covariance matrix via sparse GP approximation. Simply put, if we can shrink or simplify the covariance matrix (for example, by reducing the number of data points), we can make the inversion of the covariance matrix tractable, and thus make GP training and inference tractable.</p>
<p>One of the most popular approaches for this was introduced in the paper, <em>Sparse</em> <em>Gaussian Processes using Pseudo-Inputs</em> by Edward Snelson and Zoubin Ghahramani.<span id="dx1-186003"></span> As with other sparse GP approaches, the authors developed a method for tractable GPs that leverages large datasets.<span id="dx1-186004"></span> In the paper, the authors show that they can closely approximate training with the full dataset by using a subset of data: they effectively circumvent the problem of large data by turning a <em>large data</em> problem into a <em>small data</em> problem. However, doing so requires selecting an appropriate subset of data points, which the authors term <strong>pseudo</strong> <strong>inputs</strong>.</p>
<p>The authors achieve this using a joint optimization process that selects the subset of data <em>M</em> from the full set <em>N</em> while also optimizing the hyperparameters of the kernel. This optimization process essentially finds the subset of data points that can be used to best describe the overall data: we illustrate this in <em>Figure</em> <a href="#x1-186005r7"><em>9.7</em></a>.</p>
<div class="IMG---Figure">
<img src="../media/file188.png" alt="PIC"/> <span id="x1-186005r7"></span> <span id="x1-186006"></span></div>
<p class="IMG---Caption">Figure 9.7: Simple illustration of pseudo inputs 
</p>
<p>In this diagram, all data points are illustrated, but we see that certain data points have been selected as they describe the key relationship between our variables. However, these points not only need to describe the relationship, in terms of mean, as a polynomial regression may do – they also need to replicate the <em>variance</em> in the underlying data, such that the GP still produces well-calibrated uncertainty estimates. That is to say, while the pseudo inputs effectively reduce the number of data points, the distribution of the pseudo inputs still needs to approximate that of the true inputs: if an area in the true data distribution is rich in data, thereby producing confident predictions in this region, this needs to be true for the pseudo inputs too.</p>
<p>Another method for scalable GPs was introduced more recently by Ke Wang <em>et</em> <em>al.</em> in their paper, <em>Exact Gaussian Processes on a Million Data Points</em>.<span id="dx1-186007"></span> In this work, the authors leverage recent developments in multi-GPU parallelization methods to implement scalable GPs. The method that enabled this is called <strong>Blackbox Matrix-Matrix Multiplication</strong> (<strong>BBMM</strong>),<span id="dx1-186008"></span> reduces the problem of GP inference to iterations of matrix multiplication. In so doing, it makes the process easier to parallelize, as the matrix multiplications can be partitioned and distributed over multiple GPUs. The authors show that doing so reduces the memory requirement for GP training to <em>O</em>(<em>n</em>) per GPU. This allows GPs to benefit from the kind of computational gains that have been benefiting deep learning methods for over a decade!<span id="dx1-186009"></span></p>
<p>Both of the methods presented here do a great job of addressing the scalability issues faced by GPs. The second method is particularly impressive as it achieves exact GP inference, but it does require significant compute infrastructure. The pseudo-inputs method, on the other hand, is practical for a larger proportion of use cases. However, neither of these approaches tackle one of the key advantages of BDL: the ability of deep networks to learn rich embeddings through complex non-linear transformations. <span id="x1-186010r289"></span></p>
</section>
<section id="deep-gaussian-processes" class="level3 subsectionHead" data-number="14.4.2">
<h3 class="subsectionHead" data-number="14.4.2" id="sigil_toc_id_109"><span class="titlemark">9.4.2 </span> <span id="x1-1870002"></span>Deep Gaussian processes</h3>
<p>Introduced by Andreas Damianou and Neil Lawrence in their straightforwardly titled paper, <em>Deep Gaussian Processes</em>, deep GPs tackle the problem of rich embeddings through having layers of GPs,<span id="dx1-187001"></span> much in the same way that deep networks have multiple layers of neurons.<span id="dx1-187002"></span> Unlike the scalable GP work mentioned previously, deep GPs were motivated by the inverse of the scalability problem: how can we get the performance of deep networks with very little data?</p>
<p>Faced with this problem, and with the knowledge that GPs perform very well on small amounts of data, Damianou and Lawrence set out to see whether GPs could be layered to produce similarly rich embeddings.</p>
<div class="IMG---Figure">
<img src="../media/file189.png" alt="PIC"/> <span id="x1-187003r8"></span> <span id="x1-187004"></span></div>
<p class="IMG---Caption">Figure 9.8: Illustration of a deep GP 
</p>
<p>Their approach, while complex in terms of implementation, is simple in principle: just as a DNN comprises many layers, each receiving an input from the layer before it and feeding its output into the layer after it, deep GPs also assume this form of graphical structure – as we see in <em>Figure</em> <a href="#x1-187003r8"><em>9.8</em></a>. Mathematically, just as with deep networks, a deep GP can be viewed as a composition of functions. The GP illustrated previously could thus be described as:</p>
<div class="math-display">
<img src="../media/file190.jpg" class="math-display" alt="y = g(x ) = f2(f1(x)) "/>
</div>
<p>While this introduces the kind of rich non-linear transformations we’re accustomed to in deep learning to GPs, it comes at a price. As we already know, standard GPs have limitations when it comes to scalability. Unfortunately for deep GPs, composing them in this way is analytically intractable. As such, Damianou and Lawrence had to find a tractable way of implementing deep GPs, and they did so using a tool that should now be familiar to you: variational approximation. Just as this forms an import building block for some of the BDL methods introduced in this book,<span id="dx1-187005"></span> it’s also a key component in making deep GPs possible. In their paper, they show how deep GPs can be implemented with the help of variational approximations – making it possible not only to produce rich, non-linear embeddings with GPs but for rich, non-linear embeddings to be achieved with <em>small</em> <em>amounts of data</em>. This makes deep GPs an important tool in the arsenal of Bayesian methods and is thus a method worth bearing in mind going forward.<span id="dx1-187006"></span> <span id="x1-187007r288"></span></p>
</section>
</section>
<section id="your-next-steps-in-bdl" class="level2 sectionHead" data-number="14.5">
<h2 class="sectionHead" data-number="14.5" id="sigil_toc_id_110"><span class="titlemark">9.5 </span> <span id="x1-1880005"></span>Your next steps in BDL</h2>
<p>Throughout this chapter, we’ve concluded our introduction to BDL by taking a look at a variety of techniques that could help you to improve on the fundamental methods explored in the book. We’ve also taken a look at how the powerful gold-standard of Bayesian inference – the GP – can be adapted to tasks generally reserved for deep learning. While it is indeed possible to adapt GPs to these tasks, we also advise that it’s generally easier and more practical to use the methods presented in this book, or methods derived from them. As always, it’s up to you as the machine learning engineer to determine what is best for the task at hand, and we are confident that the material from the book will equip you well for the challenges ahead.</p>
<p>While this book provides you with the necessary fundamentals to get started, there’s always more learn – particularly in such a rapidly moving field! In the next section, we’ll provide a few key final recommendations, helping you to plan your next steps in learning about and applying BDL.</p>
<p>We hope that you’ve found this introduction to Bayesian deep learning to be comprehensive, practical, and enjoyable. Thank you for reading – we wish you success in exploring these methods further and applying them within your own machine learning solutions. <span id="x1-188001r293"></span></p>
</section>
<section id="further-reading-6" class="level2 sectionHead" data-number="14.6">
<h2 class="sectionHead" data-number="14.6" id="sigil_toc_id_111"><span class="titlemark">9.6 </span> <span id="x1-1890006"></span>Further reading</h2>
<p>The following reading recommendations are provided for those who wish to learn more about the recent methods presented in this chapter. These give a great insight into current challenges in the field, looking beyond Bayesian neural networks and into scalable Bayesian inference more generally:</p>
<ul>
<li><p><em>Deep Ensemble Bayesian Active Learning</em>, Pop and Fulop: This paper demonstrates the advantages of combining deep ensembles with MC dropout to produce better-calibrated uncertainty estimates, as shown when applying their method to active learning tasks.</p></li>
<li><p><em>Uncertainty in Neural Networks: Approximately Bayesian Ensembling</em>, Pearce <em>et al.</em>: This paper introduces a simple and effective method for improving the performance of deep ensembles. The authors show that by promoting diversity through a simple adaptation to the loss function, the ensemble is able to produces better-calibrated uncertainty estimates.</p></li>
<li><p><em>Sparse Gaussian Processes Using Pseudo-Inputs</em>, Snelson and Gharamani: This paper introduces the concept of pseudo-input-based GPs, introducing a key method in scalable GP inference.</p></li>
<li><p><em>Exact Gaussian Processes on a Million Data Points</em>, Wang <em>et al.</em>: An important paper demonstrating that Gaussian Processes can benefit from developments in compute hardware through the use of BBMM, making exact GP inference possible for big data.</p></li>
<li><p><em>Deep Gaussian Processes</em>, Damianou and Lawrence: Introducing the concept of deep GPs, this paper demonstrates how GPs can be used to achieve complex non-linear transformations with datasets far smaller than those required for deep learning.</p></li>
</ul>
<p>We’ve selected a few key resources to help you in your next steps into BDL, allowing you to dive deeper into the theory and helping you to get the most out of the content presented here:</p>
<ul>
<li><p><em>Machine Learning: A Probabilistic Perspective</em>, Murphy: Released in 2012, this has since become one of the key texts on machine learning, presenting a well-principled approach to understanding all of the key methods within machine learning. The probabilistic angle of the book makes it a great addition to your collection of Bayesian literature.</p></li>
<li><p><em>Probabilistic Machine Learning: An Introduction</em>, Murphy: Another more recent Murphy text. Released in 2022, this is another important text providing a detailed treatment of probabilistic machine learning (including a section on Bayesian neural networks). While there is some overlap between this and Murphy’s previous text, both are worth having at your disposal.</p></li>
<li><p><em>Gaussian Processes for Machine Learning</em>, Rasmussen and Williams: Perhaps the most important text on Gaussian Processes, this is a hugely valuable text when it comes to Bayesian inference. The authors’ detailed explanation of GPs will give you a thorough understanding of this important piece of the Bayesian puzzle.</p></li>
<li><p><em>Bayesian Analysis with Python</em>, Martin: Covering all the fundamentals of Bayesian analysis, this title is an excellent piece of foundational literature and will help you to dive deeper into the fundamentals of Bayesian inference.</p></li>
</ul>
</section>
</section>
</body>
</html>