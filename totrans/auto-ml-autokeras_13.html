<html><head></head><body>
		<div id="_idContainer105">
			<h1 id="_idParaDest-137"><em class="italic"><a id="_idTextAnchor140"/>Chapter 10</em>: Exporting and Visualizing the Models</h1>
			<p>In this chapter, we will see how to export and import our AutoKeras models. Once trained, we will also learn to visualize in a graphic way and in real time what is happening during the training of our models.</p>
			<p>Once you have completed this chapter, you will be able to export and import your models to disk and you will have in your toolkit a powerful visualization tool that will help you to know what is happening during the training of your models.</p>
			<p>Specifically, in this chapter, we will cover these main points:</p>
			<ul>
				<li>Exporting your models: How to save and load your models from disk</li>
				<li>Visualizing your models with TensordBoard: How to visualize your models in real time using this powerful tool</li>
				<li>Visualizing and comparing your models with ClearML</li>
			</ul>
			<p>Let's start with the first point, but first make sure, as usual, that we have all the requirements installed.</p>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor141"/>Technical requirements </h1>
			<p>All coding examples in this book are available as Jupyter notebooks that can be downloaded from the website: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras">https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras</a>.</p>
			<p>As code cells can be executed, each notebook can be self-installable, adding a code snippet with the requirements you need. For this reason, at the beginning of each notebook, there is a code cell for environment setup, which installs AutoKeras and its dependencies.</p>
			<p>So, in order to run the coding examples, you only require a computer with Ubuntu Linux as the OS and can install the Jupyter notebook with the following command:</p>
			<p class="source-code">$ apt-get install python3-pip jupyter-notebook</p>
			<p>Alternatively, you can also run these notebooks using Google Colaboratory. In this instance, you will only require a web browser; refer to the <em class="italic">AutoKeras with Google Colaboratory</em> section in <a href="B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Autokeras</em>, for more details. Furthermore, in the main section, <em class="italic">Installing AutoKeras</em>, you will also find other installation options.</p>
			<p>Now, let's put the concepts of the previous section into practice with a practical example.</p>
			<h1 id="_idParaDest-139"><a id="_idTextAnchor142"/>Exporting your models</h1>
			<p>The <a id="_idIndexMarker348"/>best model found by AutoKeras can be easily exported as a Keras model.</p>
			<p>When saving your models to disk, this can be done in two different formats: the TensorFlow SavedModel format, and the older Keras H5 format. The recommended format is SavedModel, and this is the option used by default when we call to <strong class="source-inline">model.save()</strong>. </p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor143"/>How to save and load a model</h2>
			<p>Let's now <a id="_idIndexMarker349"/>see how to export <a id="_idIndexMarker350"/>and restore a model step by step:</p>
			<ol>
				<li>Export the model to a Keras model using the following code block:<p class="source-code">model = my_autokeras_model.export_model() </p><p>Now, try to save to the TensorFlow format using the h5 format as backup as something is wrong:</p><p class="source-code">try:</p><p class="source-code">    model.save("model_autokeras", save_format="tf")</p><p class="source-code">except:</p><p class="source-code">    model.save("model_autokeras.h5")</p></li>
				<li>Reload the model, as shown in the following code block:<p class="source-code">from tensorflow.keras.models import load_model</p><p class="source-code">loaded_model = load_model("model_autokeras", custom_objects=ak.CUSTOM_OBJECTS)</p></li>
			</ol>
			<p>The code<a id="_idIndexMarker351"/> is almost self-explanatory, but we are going to explain the loading function <a id="_idIndexMarker352"/>in a bit more detail. In this function, which is responsible for loading our model from disk into memory, we are passing the <strong class="source-inline">ak.CUSTOM_OBJECTS</strong> value as a <strong class="source-inline">custom_objects</strong> parameter. This indicates to the Keras function that the model we want to load has custom AutoKeras objects.</p>
			<p>Once we know how to import and export our models, it is time to move on to the next section, where we will learn to visualize during the training process. This will help us to extract perspectives from the learning processes.</p>
			<h1 id="_idParaDest-141"><a id="_idTextAnchor144"/>Visualizing your models with TensorBoard</h1>
			<p>To develop<a id="_idIndexMarker353"/> efficient and successful models, you will need to<a id="_idIndexMarker354"/> know what is happening during your experiments so that you can react as soon as possible by correcting possible anomalous or unwanted results, such as overfitting and slow learning. This is where the concept of a tactile callback comes into play.</p>
			<p>A callback is an object (a class instance that implements specific methods) that is passed to the model on the call to fit and that is called by the model at various points during training. You have access to all available data on the status of the model and its performance and, based on this, take measures including the following:</p>
			<ul>
				<li>Interrupt training, because you have stopped learning or are overfitting</li>
				<li>Save a model; in this way, the training could be resumed from the saved point in the future</li>
				<li>Record metrics, such as precision or loss</li>
				<li>Alter its state, and modify its structure or hyperparameters, such as the learning rate</li>
			</ul>
			<p>Here are some examples of the ways in which you can use callbacks:</p>
			<ul>
				<li>Model checkpoints: Save current model weights at different points during training.</li>
				<li>Early stop: Interrupt training when the loss of validation is no longer improving (and of course, saving the best model obtained during training).</li>
				<li>Dynamically adjust the value of certain parameters during training, such as the learning rate.</li>
				<li>Record training<a id="_idIndexMarker355"/> and validation metrics during training, or<a id="_idIndexMarker356"/> view representations learned by the model as they are updated.</li>
			</ul>
			<p>There are two especially useful callbacks for training, <strong class="source-inline">EarlyStopping</strong> and <strong class="source-inline">ModelCheckpoint</strong>. The first one serves to interrupt training once the observed metric has stopped improving for the number of times initially set. For example, this callback allows you to interrupt training as soon as you start overfitting, thereby avoiding having to retrain your model with fewer epochs. This callback is typically used in conjunction with <strong class="source-inline">ModelCheckpoint</strong>, which allows you to continuously save the model during training.</p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B16953_10_01.jpg" alt="Figure 10.1 – Example of how to train a model with callbacks&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – Example of how to train a model with callbacks</p>
			<p>AutoKeras always saves the best model during training and uses <strong class="source-inline">EarlyStopping</strong> by default, setting a number of epochs that varies depending on the type of model we are training. However, this behavior can be customized through the callback's parameter of the <strong class="source-inline">fit</strong> function.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor145"/>Using callbacks to log the model state</h2>
			<p>Callbacks that<a id="_idIndexMarker357"/> record metrics are essential for monitoring since <a id="_idIndexMarker358"/>they allow tools such as TensorBoard, which we will see here, to visualize in real time the learning progress of a model during its training.</p>
			<p>So, in our case, we will set the callbacks to log the training progress with the following command:</p>
			<p class="source-code">logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))</p>
			<p class="source-code">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)</p>
			<p>In the previous code, we defined a log directory (<strong class="source-inline">log_dir</strong>) and created a callback to save the model checkpoints there, which means that AutoKeras will automatically save the metrics for each epoch in multiple log files in this folder. We have also activated the histograms (<strong class="source-inline">histogram_freq=1</strong>), so in the <strong class="bold">Histograms</strong> tab of TensorBoard, you can view the histograms of activation values in each layer.</p>
			<p>In the next section, we will visualize the logs with TensorBoard, a web application for viewing information regarding TensorFlow models. Since AutoKeras has TensorFlow under the hood, we can use this tool in an easy way to visualize our models.</p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor146"/>Setting up and loading TensorBoard</h2>
			<p>TensorBoard <a id="_idIndexMarker359"/>allows us to visualize different metrics in real time, such as loss and precision, as well as render the model graph (by layers and operations), along with histograms of weights, biases, or other tensors.</p>
			<p>TensorBoard can be<a id="_idIndexMarker360"/> used directly in the Jupyter notebook and in Colab. This is done by loading the TensorBoard extension into the notebook. This is the approach we will use in this chapter.</p>
			<p class="callout-heading">Note </p>
			<p class="callout">If you have installed Jupyter and TensorBoard on the same virtualenv, you should be good to go. If you are using a more complicated setup, such as a global installation of Jupyter and kernels for different Conda/virtualenv environments, you need to make sure that the TensorBoard binary is in your <strong class="source-inline">PATH</strong> within the context of the Jupyter notebook.</p>
			<p>First, we have to set <strong class="source-inline">callbacks</strong>, as we explained in the previous section, to record the training progress in the <strong class="source-inline">logs</strong> directory:</p>
			<p class="source-code">logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))</p>
			<p class="source-code">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)</p>
			<p>Now we pass <a id="_idIndexMarker361"/><strong class="source-inline">callbacks</strong> to the training function:</p>
			<p class="source-code">model.fit(x_train, </p>
			<p class="source-code">        y_train,</p>
			<p class="source-code">        epochs=1, </p>
			<p class="source-code">        callbacks=[tensorboard_callback])</p>
			<p>Once the training is <a id="_idIndexMarker362"/>done, we are ready to load the <strong class="source-inline">tensorboard</strong> extension to visualize the results:</p>
			<p class="source-code">%load_ext tensorboard</p>
			<p class="source-code">%tensorboard --logdir logs</p>
			<p>The previous lines of code loads the TensorBoard dashboard, feeding it with the model <strong class="source-inline">logs</strong> directory:</p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/B16953_10_02.jpg" alt="Figure 10.2 – TensorBoard showing model training results&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – TensorBoard showing model training results</p>
			<p>In the <a id="_idIndexMarker363"/>previous screenshot, there are two graphs each with four different <a id="_idIndexMarker364"/>lines representing the learning progress of two candidate models.</p>
			<p>In the first graph, the two highest lines show the epoch accuracy on the training and validation set, respectively, while the lower lines show the accuracy of the epochs for the training and validation datasets of the other model.</p>
			<p>The same happens in the second graph, but in this case, it represents the loss instead of the accuracy.</p>
			<p>We can also see the <a id="_idIndexMarker365"/>elements of the model in the <strong class="bold">GRAPHS</strong> tab. The <strong class="bold">GRAPHS</strong> tab displays an interactive low-level TensorFlow graph display of the features used by <a id="_idIndexMarker366"/>your AutoKeras model:</p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/B16953_10_03.jpg" alt="Figure 10.3 – TensorBoard showing the model graph&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – TensorBoard showing the model graph</p>
			<p>In the preceding screenshot, we can see part of the model graph with its different layers and operations. As you can see, the model is much more complex than you might expect. When you define the classifier, it's only three lines of code, but under the hood, AutoKeras builds a fairly complex graph structure to make it work.</p>
			<p>Here, we can also <a id="_idIndexMarker367"/>visualize the weight/bias distributions in the different <a id="_idIndexMarker368"/>layers:</p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/B16953_10_04.jpg" alt="Figure 10.4 – TensorBoard showing the distribution of the model layers&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – TensorBoard showing the distribution of the model layers</p>
			<p>There are many more options available to us that we will not explain here. TensorBoard is a very powerful and complete tool, and its domain is beyond the scope of this book. The following URL is a very good starting point: <a href="https://www.tensorflow.org/tensorboard/get_started">https://www.tensorflow.org/tensorboard/get_started</a>.</p>
			<p>Let's see now in the next section how we can share our experiments with the world.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor147"/>Sharing your ML experiment results with TensorBoard.dev </h2>
			<p>TensorBoard.dev is a<a id="_idIndexMarker369"/> free public service that allows <a id="_idIndexMarker370"/>you to upload your TensorBoard records and get a permanent link that can be shared with whoever you want, while also being used in your academic articles, blog posts, social media, and so on. This can allow better reproducibility and collaboration.</p>
			<p>You can use TensorBoard.dev simply by running the following command:</p>
			<p class="source-code">!tensorboard dev upload \</p>
			<p class="source-code">  --logdir logs/fit \</p>
			<p class="source-code">  --name "(optional) My latest AutoKeras experiment" \</p>
			<p class="source-code">  --description "(optional) Simple comparison of several hyperparameters" \</p>
			<p class="source-code">  --one_shot</p>
			<p>The previous command uploads to TensorBoard.dev the model <strong class="source-inline">logs</strong> directory:</p>
			<p class="source-code">New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/TPcKbLPeRAqZ1GmRWDAdow/</p>
			<p>Now, clicking on the link will open a browser in which we will see the TensorBoard panel on the TensorBoard.dev website, as shown here:</p>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="image/B16953_10_05.jpg" alt="Figure 10.5 – Model training results shared on TensorBoard.dev"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – Model training results shared on TensorBoard.dev</p>
			<p>As we have seen, TensorBoard<a id="_idIndexMarker371"/> is a very powerful tool for monitoring your models, but if you need to track your experiments, as <a id="_idIndexMarker372"/>well as compare and share them with other teams, there is an AutoKeras extension called ClearML that is specially designed for monitoring and tracking experiments, allowing access to TensorBoard logs, and complementing it with many more added functions. Let's take a look at this in the next section.</p>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor148"/>Visualizing and comparing your models with ClearML</h1>
			<p>ClearML (formerly Trains) is <a id="_idIndexMarker373"/>a complete <a id="_idIndexMarker374"/>open source ML/DL experimentation solution that automatically tracks everything you need to document <a id="_idIndexMarker375"/>your work, visualize <a id="_idIndexMarker376"/>results, and reproduce, adjust, and compare <a id="_idIndexMarker377"/>experiments using an intuitive web interface.</p>
			<p>ClearML allows you <a id="_idIndexMarker378"/>to perform the following tasks:</p>
			<ul>
				<li>Visualize experiment<a id="_idIndexMarker379"/> results in the ClearML Web UI.</li>
				<li>Track and upload models.</li>
				<li>Track model performance and create tracking leaderboards.</li>
				<li>Rerun experiments, reproduce experiments on any target machine, and tune experiments.</li>
				<li>Compare<a id="_idIndexMarker380"/> experiments.</li>
			</ul>
			<p>To use it in your <a id="_idIndexMarker381"/>AutoKeras project, you just have to initialize a ClearML Task in your code, and ClearML automatically records scalars, graphs, and images reported to TensorBoard, Matplotlib, Plotly, and Seaborn, as well as all the other automatic logs and explicit reports that you add to your code.</p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor149"/>Adding ClearML to code</h2>
			<p>Just add these<a id="_idIndexMarker382"/> two lines of code to your project:</p>
			<p class="source-code">from clearml import Task</p>
			<p class="source-code">task = Task.init(project_name="myAutokerasProject", task_name="myAutokerasExperiment")</p>
			<p>When the code runs, it initializes a Task in ClearML Server. A hyperlink to the experiment's log is output to the console:</p>
			<p class="source-code">CLEARML Task: created new task id=c1f1dc6cf2ee4ec88cd1f6184344ca4e</p>
			<p class="source-code">CLEARML results page: https://app.clearml-master.hosted.allegro.ai/projects/1c7a45633c554b8294fa6dcc3b1f2d4d/experiments/c1f1dc6cf2ee4ec88cd1f6184344ca4e/output/log</p>
			<p>ClearML will inspect the AutoKeras training process and look for TensorBoard callbacks, as well as any kind of output, including logs, metrics, images, and so on.</p>
			<p>In the generated experiment link, you can see in real time the dashboards with different graphics related to the models autogenerated by AutoKeras. This is done during training, and their accuracy, their performance in the training and evaluation datasets, console outputs, and many more metrics can also be seen:</p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/B16953_10_06.jpg" alt="Figure 10.6 – ClearML dashboard showing TensorBoard metrics"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6 – ClearML dashboard showing TensorBoard metrics</p>
			<p>In the previous <a id="_idIndexMarker383"/>screenshot, we can see how the precision and loss of our models evolves throughout the epochs and, in the next one, we can see the distributions of the weights in one of the convolutional layers:</p>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/B16953_10_07.jpg" alt="Figure 10.7 – ClearML dashboard showing some model layer distributions"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7 – ClearML dashboard showing some model layer distributions</p>
			<p>In the previous <a id="_idIndexMarker384"/>screenshots, we can see ClearML panels similar to those shown previously in the TensorBoard dashboards.</p>
			<p>AutoKeras will generate multiple models during the training process, so let's see how ClearML shows us each model's results at the same time.</p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor150"/>Comparing experiments</h2>
			<p>With this tool, you can also <a id="_idIndexMarker385"/>compare experiments and contrast results in a powerful way. There are many comparison options, such as comparing model artifacts, hyperparameters, data series graphs, and debug samples for each iteration. It also allows you to browse samples with a viewer (for images and video) and a player (for audio):</p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B16953_10_08.jpg" alt="Figure 10.8 – ClearML dashboard comparing the training results of two models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.8 – ClearML dashboard comparing the training results of two models</p>
			<p>Detailed <a id="_idIndexMarker386"/>information on these options and many more can be found in the ClearML Web UI documentation.</p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor151"/>Summary</h1>
			<p>In this chapter, we have learned how to define Keras callbacks to monitor your models during training, how to use TensorBoard to view histograms, model graphs, and many more metrics besides, and how to monitor and track your experiments using the ClearML extension.</p>
			<p>With these new tools, you will be better equipped to build your deep learning models in the real world and debug potential problems.</p>
			<p>Throughout this book, we have learned the basic concepts necessary to use AutoKeras to solve any task based on text, images, or structured data, as well as the visualization techniques seen in this chapter. AutoKeras, Keras, and TensorFlow have excellent documentation that you can dig into for as long as you need. The foundations are already laid; now it's time to finish the building.</p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor152"/>A final few words</h2>
			<p>This is the end of <em class="italic">Automated Machine Learning with AutoKeras</em>! I hope you have learned that it will help you to implement your own AI projects or to improve the ones you already had, especially in the field of AI, where new concepts are born every day. Therefore, I encourage you to keep walking, delving into this exciting world, and enjoying every step.</p>
			<p>In Spain, on the Camino de Santiago, a phrase is often repeated that says "wanderer, there is no path. The path is made by walking."</p>
			<p>I hope this book serves as a starting point to continue on that path.</p>
		</div>
	</body></html>