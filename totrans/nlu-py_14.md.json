["```py\n# find out the total number of text files in the dataset and what the classes are\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\ntraining_ds = tf.keras.utils.text_dataset_from_directory(\n    'trec_processed/training')\nclass_names = training_ds.class_names\nprint(class_names)\nFound 5452 files belonging to 6 classes.\n['ABBR', 'DESC', 'ENTY', 'HUM', 'LOC', 'NUM']\n```", "```py\nfiles_dict = {}\nfor class_name in class_names:\n    files_count = training_ds.list_files(\n        'trec_processed/training/' + class_name + '/*.txt')\n    files_length = files_count.cardinality().numpy()\n    category_count = {class_name:files_length}\n    files_dict.update(category_count)\n# Sort the categories, largest first\nfrom collections import OrderedDict\nsorted_files_dict = sorted(files_dict.items(),\n    key=lambda t: t[1], reverse=True)\nprint(sorted_files_dict)\n# Conversion to Pandas series\npd_files_dict = pd.Series(dict(sorted_files_dict))\n# Setting figure, ax into variables\nfig, ax = plt.subplots(figsize=(20,10))\n# plot\nall_plot = sns.barplot(x=pd_files_dict.index,\n    y = pd_files_dict.values, ax=ax, palette = \"Set2\")\nplt.xticks(rotation = 90)\nplt.show()\n[('ENTY', 1250), ('HUM', 1223), ('ABBR', 1162),\n     ('LOC', 896), ('NUM', 835), ('DESC', 86)]\n```", "```py\ndef build_classifier_model():\n    text_input = tf.keras.layers.Input(shape=(),\n        dtype=tf.string, name='text')\n    preprocessing_layer = hub.KerasLayer(\n        tfhub_handle_preprocess, name='preprocessing')\n    encoder_inputs = preprocessing_layer(text_input)\n    encoder = hub.KerasLayer(tfhub_handle_encoder,\n        trainable=True, name='BERT_encoder')\n    outputs = encoder(encoder_inputs)\n    net = outputs['pooled_output']\n    net = tf.keras.layers.Dropout(0.1)(net)\n    net = tf.keras.layers.Dense(6, activation =\n        tf.keras.activations.softmax,\n        name='classifier')(net)\n    return tf.keras.Model(text_input, net)\n```", "```py\nloss=\"sparse_categorical_crossentropy\"\nmetrics = tf.metrics.CategoricalAccuracy()\n```", "```py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nscores = [[],[],[],[],[],[]]\nfor text_batch, label_batch in train_ds.take(100):\n    for i in range(160):\n        text_to_classify = [text_batch.numpy()[i]]\n        prediction = classifier_model.predict(\n            text_to_classify)\n        classification = np.max(prediction)\n        max_index = np.argmax(prediction)\n        scores[max_index].append(classification)\naverages = []\nfor i in range(len(scores)):\n    print(len(scores[i]))\n    averages.append(np.average(scores[i]))\nprint(averages)\n```", "```py\ndef make_histogram(score_data,class_name):\n    sns.histplot(score_data,bins = 100)\n    plt.xlabel(\"probability score\")\n    plt.title(class_name)\n    plt.show()\nfor i in range(len(scores)):\n    make_histogram(scores[i],class_names[i])\n```", "```py\ny_pred = classifier_model.predict(x_test)\ny_pred = np.where(y_pred > .5, 1,0)\nprint(y_pred)\nprint(y_test)\npredicted_classes = []\nfor i in range(len(y_pred)):\n    max_index = np.argmax(y_pred[i])\n    predicted_classes.append(max_index)\n# View the results as a confusion matrix\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,f1_score,classification_report\nconf_matrix = confusion_matrix(y_test,predicted_classes,\n    normalize=None)\n```", "```py\n# Displaying the confusion matrix\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 12})\ndisp = ConfusionMatrixDisplay(confusion_matrix =\n    conf_matrix, display_labels = class_names)\nprint(class_names)\ndisp.plot(xticks_rotation=75,cmap=plt.cm.Blues)\nplt.show()\n```", "```py\nprint(classification_report(y_test, predicted_classes, target_names = class_names))\n['ABBR', 'DESC', 'ENTY', 'HUM', 'LOC', 'NUM']\n              precision    recall  f1-score   support\n        ABBR       0.90      0.99      0.94       138\n        DESC       1.00      0.78      0.88         9\n        ENTY       0.97      0.80      0.88        94\n         HUM       0.97      0.97      0.97        65\n         LOC       0.96      0.98      0.97       113\n         NUM       0.94      0.96      0.95        81\n    accuracy                           0.94       500\n   macro avg       0.96      0.91      0.93       500\nweighted avg       0.94      0.94      0.94       500\n```", "```py\nfrom nltk.parse.generate import generate\nfrom nltk import CFG\ngrammar = CFG.fromstring(\"\"\"\nS -> SNP VP\nSNP -> Pro\nVP -> V NP PP\nPro -> 'I'\nNP -> Det Adj N\nDet -> 'a'\nN -> 'restaurant' | 'place'\nV -> 'am looking for' | 'would like to find'\nPP -> P Adv\nP -> 'near'| 'around'\nAdv -> 'here'\nAdj -> 'Japanese' | 'Chinese' | 'Middle Eastern' | 'Mexican'\nfor sentence in generate(grammar,n = 10):\n    print(\" \".join(sentence))\n```", "```py\nI am looking for a Japanese restaurant near here\nI am looking for a Japanese restaurant around here\nI am looking for a Japanese place near here\nI am looking for a Japanese place around here\nI am looking for a Chinese restaurant near here\nI am looking for a Chinese restaurant around here\nI am looking for a Chinese place near here\nI am looking for a Chinese place around here\nI am looking for a Middle Eastern restaurant near here\nI am looking for a Middle Eastern restaurant around here\n```"]