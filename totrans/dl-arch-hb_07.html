<html><head></head><body>
<div id="_idContainer088">
<h1 class="chapter-number" id="_idParaDest-106"><a id="_idTextAnchor107"/><span class="koboSpan" id="kobo.1.1">7</span></h1>
<h1 id="_idParaDest-107"><a id="_idTextAnchor108"/><span class="koboSpan" id="kobo.2.1">Deep Neural Architecture Search</span></h1>
<p><span class="koboSpan" id="kobo.3.1">The previous chapters introduced and recapped different </span><strong class="bold"><span class="koboSpan" id="kobo.4.1">neural networks</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.6.1">NNs</span></strong><span class="koboSpan" id="kobo.7.1">) that are designed to handle different types of data. </span><span class="koboSpan" id="kobo.7.2">Designing these networks requires knowledge and intuition that can only be gained by consuming years of research in the field. </span><span class="koboSpan" id="kobo.7.3">The bulk of these networks are hand-designed by experts and researchers. </span><span class="koboSpan" id="kobo.7.4">This includes inventing completely novel NN layers and constructing an actually usable architecture by combining and stacking NN layers that already exist. </span><span class="koboSpan" id="kobo.7.5">Both tasks require a ton of iterative experimentation time to burn to actually achieve success in creating a network that </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">is useful.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">Now, imagine a world where we can focus on inventing useful novel layers while the software takes care of automating the final architecture-building process. </span><span class="koboSpan" id="kobo.9.2">Automated architecture search methods help to accomplish exactly that by streamlining the task of designing the best final NN architecture, as long as appropriate search spaces are selected based on deep domain knowledge. </span><span class="koboSpan" id="kobo.9.3">In this chapter, we will focus on the task of constructing an actual usable architecture from already existing NN layers using an automated architecture creation process called </span><strong class="bold"><span class="koboSpan" id="kobo.10.1">neural architecture search</span></strong><span class="koboSpan" id="kobo.11.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.12.1">NAS</span></strong><span class="koboSpan" id="kobo.13.1">). </span><span class="koboSpan" id="kobo.13.2">By understanding the different types of NAS, you will be able to choose the most straightforward automated search optimization approach based on your current model-building setup, which ranges from simple to efficiently complicated. </span><span class="koboSpan" id="kobo.13.3">Specifically, the following topics will </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">be introduced:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.15.1">Understanding the big picture </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">of NAS</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Understanding general hyperparameter </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">search-based NAS</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">Understanding </span><strong class="bold"><span class="koboSpan" id="kobo.20.1">reinforcement learning</span></strong><span class="koboSpan" id="kobo.21.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.22.1">RL</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">)-based NAS</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">non-RL-based NAS</span></span></li>
</ul>
<h1 id="_idParaDest-108"><a id="_idTextAnchor109"/><span class="koboSpan" id="kobo.26.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.27.1">This chapter includes practical implementation in the Python programming language. </span><span class="koboSpan" id="kobo.27.2">These simple methods will need to have the following </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">libraries installed:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.29.1">numpy</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.30.1">pytorch</span></strong></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.31.1">catalyst == </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.32.1">21.12</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.33.1">scikit-learn</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.34.1">You can find the code files for this chapter on GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">at </span></span><a href="https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_7"><span class="No-Break"><span class="koboSpan" id="kobo.36.1">https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_7</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.37.1">.</span></span></p>
<h1 id="_idParaDest-109"><a id="_idTextAnchor110"/><span class="koboSpan" id="kobo.38.1">Understanding the big picture of NAS</span></h1>
<p><span class="koboSpan" id="kobo.39.1">Before we dive into the details of the big picture of NAS methods, it’s important to note that although NAS minimizes the</span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.40.1"> manual effort necessary for shaping the final architecture, it doesn’t completely negate the need for expertise in the field. </span><span class="koboSpan" id="kobo.40.2">As we discussed earlier, foundational knowledge in </span><strong class="bold"><span class="koboSpan" id="kobo.41.1">deep learning</span></strong><span class="koboSpan" id="kobo.42.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.43.1">DL</span></strong><span class="koboSpan" id="kobo.44.1">) is crucial for selecting </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.45.1">appropriate search spaces and interpreting the results of NAS accurately. </span><span class="koboSpan" id="kobo.45.2">Search spaces are the set of possible options or configurations that can be explored during a search. </span><span class="koboSpan" id="kobo.45.3">Furthermore, the performance of NAS heavily relies on the quality of the training data and the relevance of the search space to the task at hand. </span><span class="koboSpan" id="kobo.45.4">Therefore, domain expertise is still necessary to ensure that the final architecture is not only efficient but also accurate and relevant to the problem being solved. </span><span class="koboSpan" id="kobo.45.5">By the end of this section, you will have a better understanding of how to leverage your domain expertise to optimize the effectiveness </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">of NAS.</span></span></p>
<p><span class="koboSpan" id="kobo.47.1">The previous chapters on NNs have only introduced a few prominent NN layer types and only scratched the surface of the entire library of neural layers out there. </span><span class="koboSpan" id="kobo.47.2">Today, there are too many variations of NN layers, which makes it hard to design precisely which layers get used at which point in the architecture. </span><span class="koboSpan" id="kobo.47.3">The main problem is that the space of possible NN architectures is infinitely big. </span><span class="koboSpan" id="kobo.47.4">Additionally, evaluating any possible architectural design is slow and expensive in terms of resources. </span><span class="koboSpan" id="kobo.47.5">These are the reasons that make it impossible to evaluate all the possible NN architectures. </span><span class="koboSpan" id="kobo.47.6">Let’s take the training of a </span><strong class="bold"><span class="koboSpan" id="kobo.48.1">convolutional NN</span></strong><span class="koboSpan" id="kobo.49.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.50.1">CNN</span></strong><span class="koboSpan" id="kobo.51.1">) ResNet50</span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.52.1"> architecture on ImageNet, for example, to get a sense of how impossible this is. </span><span class="koboSpan" id="kobo.52.2">This would take around 3-4 days with a single RTX 3080 Ti Nvidia GPU, which is a GPU meant for normal consumers and available to be procured off-the-shelf. </span><span class="koboSpan" id="kobo.52.3">Business consumers, on the other hand, usually obtain industrial-grade GPU variants that have much greater processing power, which can bring down the runtime to under </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">a day.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">Typically, researchers will hand-design architectures with already available NN layers and operations by intuition. </span><span class="koboSpan" id="kobo.54.2">This manual method is a one-off effort, and doing so repeatedly when newer and better core NN layers are invented is not scalable. </span><span class="koboSpan" id="kobo.54.3">This is where NAS comes into play. </span><span class="koboSpan" id="kobo.54.4">NAS</span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.55.1"> leverages already invented NN layers and operations to build a more performant NN architecture. </span><span class="koboSpan" id="kobo.55.2">The core of NAS lies in using a smarter way to conceptually search through different architectures. </span><span class="koboSpan" id="kobo.55.3">The searching mechanism</span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.56.1"> of NAS can be implemented in three ways, namely: </span><strong class="bold"><span class="koboSpan" id="kobo.57.1">general hyperparameter search optimization</span></strong><span class="koboSpan" id="kobo.58.1">, RL, and NAS methods that do not </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">use RL.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">General hyperparameter search optimization pertains to methods that can be applied to any </span><strong class="bold"><span class="koboSpan" id="kobo.61.1">machine learning</span></strong><span class="koboSpan" id="kobo.62.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.63.1">ML</span></strong><span class="koboSpan" id="kobo.64.1">) algorithm hyperparameter optimizations. </span><span class="koboSpan" id="kobo.64.2">RL is another high-level ML method, alongside </span><strong class="bold"><span class="koboSpan" id="kobo.65.1">supervised learning</span></strong><span class="koboSpan" id="kobo.66.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.67.1">SL</span></strong><span class="koboSpan" id="kobo.68.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.69.1">unsupervised learning</span></strong><span class="koboSpan" id="kobo.70.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.71.1">UL</span></strong><span class="koboSpan" id="kobo.72.1">), that deals with</span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.73.1"> some form of optimizing actions taken in an</span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.74.1"> environment that produces states with a quantifiable reward or punishment. </span><span class="koboSpan" id="kobo.74.2">Non-RL-based NAS can be further broken down into three distinctive types: progressive architecture growing from a small architecture baseline, progressive architecture downsizing from a complex fully defined architecture graph, and evolutionary algorithms. </span><span class="koboSpan" id="kobo.74.3">The progressive architecture-growing method includes all algorithms that slowly grow a simple network to be a larger network with increasing depth or width. </span><span class="koboSpan" id="kobo.74.4">Vice versa, there are methods that first define an architecture with all the possible connections and operations and slowly drop these connections. </span><span class="koboSpan" id="kobo.74.5">Finally, </span><strong class="bold"><span class="koboSpan" id="kobo.75.1">evolutionary algorithms</span></strong><span class="koboSpan" id="kobo.76.1"> are</span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.77.1"> a branch of algorithms that are based on biological phenomena such as mutation and breeding. </span><span class="koboSpan" id="kobo.77.2">In this chapter, we will only cover some general hyperparameter search optimization methods, RL methods, a simple form of progressive growing-based NAS, and a competitive version of progressive downsizing-based NAS. </span><span class="koboSpan" id="kobo.77.3">Technical implementations will be available for the progressive growing-based NAS methods but not for the other more complicated methods. </span><span class="koboSpan" id="kobo.77.4">Open sourced implementations from the authors of the more complicated methods will be referred </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">to instead.</span></span></p>
<p><span class="koboSpan" id="kobo.79.1">Before diving into any of the mentioned NAS methods, you need to first understand the notion of </span><strong class="bold"><span class="koboSpan" id="kobo.80.1">microarchitecture</span></strong><span class="koboSpan" id="kobo.81.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.82.1">macroarchitecture</span></strong><span class="koboSpan" id="kobo.83.1">. </span><span class="koboSpan" id="kobo.83.2">Microarchitecture</span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.84.1"> refers to the details of the exact combination of layers being used in a logical block. </span><span class="koboSpan" id="kobo.84.2">As introduced in </span><a href="B18187_03.xhtml#_idTextAnchor051"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.85.1">Chapter 3</span></em></span></a><span class="koboSpan" id="kobo.86.1">, </span><em class="italic"><span class="koboSpan" id="kobo.87.1">Understanding Convolutional Neural Networks</span></em><span class="koboSpan" id="kobo.88.1">, some of these logical blocks can be repeatedly stacked onto each other to generate the architecture that will be actually used. </span><span class="koboSpan" id="kobo.88.2">There can also be different logical blocks with different layer configurations</span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.89.1"> in the final created architecture. </span><span class="koboSpan" id="kobo.89.2">Macroarchitecture, in comparison, refers to a higher-level overview of how the different blocks are combined to form the final NN architecture. </span><span class="koboSpan" id="kobo.89.3">The core idea behind NAS methods always revolves around reducing the search space based on already curated knowledge about which layer or which layer</span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.90.1"> configurations work the best. </span><span class="koboSpan" id="kobo.90.2">The methods that will be introduced in this chapter will either keep the macroarchitecture setup fixed while only searching in the microarchitecture space or have the flexibility to explore both the micro- and macroarchitecture space with creative tricks to make </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">searching feasible.</span></span></p>
<p><span class="koboSpan" id="kobo.92.1">First, let’s start with the simplest NAS method, which is general hyperparameter search </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">optimization algorithms.</span></span></p>
<h1 id="_idParaDest-110"><a id="_idTextAnchor111"/><span class="koboSpan" id="kobo.94.1">Understanding general hyperparameter search-based NAS</span></h1>
<p><span class="koboSpan" id="kobo.95.1">In ML, parameters typically refer to the weights</span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.96.1"> and biases that a model learns </span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.97.1">during training, while </span><strong class="bold"><span class="koboSpan" id="kobo.98.1">hyperparameters</span></strong><span class="koboSpan" id="kobo.99.1"> are values that are set before training begins and influence how the model learns. </span><span class="koboSpan" id="kobo.99.2">Examples of hyperparameters include learning rate and batch size. </span><span class="koboSpan" id="kobo.99.3">General hyperparameter search optimization algorithms are a type of NAS method to automatically search for the best hyperparameters to use for constructing a given NN architecture. </span><span class="koboSpan" id="kobo.99.4">Let’s go through a few of the</span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.100.1"> possible hyperparameters. </span><span class="koboSpan" id="kobo.100.2">In a </span><strong class="bold"><span class="koboSpan" id="kobo.101.1">multi-layer perceptron</span></strong><span class="koboSpan" id="kobo.102.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.103.1">MLP</span></strong><span class="koboSpan" id="kobo.104.1">), hyperparameters could be the number of layers that control the depth of the MLP, the width of each of the layers, and the type of intermediate layer activation used. </span><span class="koboSpan" id="kobo.104.2">In a CNN, hyperparameters could be the filter size of the convolutional layer, the stride size of each of the layers, and the type of intermediate layer activation used after each </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">convolutional layer.</span></span></p>
<p><span class="koboSpan" id="kobo.106.1">For NN architectures, the available types of hyperparameters that you can configure depend heavily on the capabilities of the helper tools and methods used to create and initialize the NN. </span><span class="koboSpan" id="kobo.106.2">For instance, consider the task of configuring the hidden layer size of three layers individually. </span><span class="koboSpan" id="kobo.106.3">Having a method that produces an MLP with a fixed number of layers of three makes it possible to perform a hyperparameter search only on the hidden layer sizes. </span><span class="koboSpan" id="kobo.106.4">This is achievable by simply adding three hyperparameters to the function, which sets the three hidden layer sizes respectively. </span><span class="koboSpan" id="kobo.106.5">However, to enable the flexibility to perform a </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.107.1">hyperparameter search for both the number of layers and the hidden layer size, you have to build a helper method that can dynamically apply these hyperparameters to create </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">an MLP.</span></span></p>
<p><span class="koboSpan" id="kobo.109.1">The simplest form of NAS leverages these tools to perform a slightly smarter search of the defined hyperparameters. </span><span class="koboSpan" id="kobo.109.2">Three well-known variations of hyperparameter search will be covered here; these include </span><strong class="bold"><span class="koboSpan" id="kobo.110.1">successive halving</span></strong><span class="koboSpan" id="kobo.111.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.112.1">Hyperband</span></strong><span class="koboSpan" id="kobo.113.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.114.1">Bayesian hyperparameter optimization</span></strong><span class="koboSpan" id="kobo.115.1">. </span><span class="koboSpan" id="kobo.115.2">We will go through these three algorithms using an MLP from </span><strong class="source-inline"><span class="koboSpan" id="kobo.116.1">pytorch</span></strong><span class="koboSpan" id="kobo.117.1">, as the implementation is short enough to fit in a chapter. </span><span class="koboSpan" id="kobo.117.2">Let’s start with </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">successive halving.</span></span></p>
<h2 id="_idParaDest-111"><a id="_idTextAnchor112"/><span class="koboSpan" id="kobo.119.1">Searching neural architectures by using successive halving</span></h2>
<p><span class="koboSpan" id="kobo.120.1">The most basic method to search with a reduced search space to optimize runtime is to randomly sample a few hyperparameter configurations and execute the full training and evaluation only of the sampled configurations. </span><span class="koboSpan" id="kobo.120.2">This method is simply called </span><strong class="bold"><span class="koboSpan" id="kobo.121.1">random search</span></strong><span class="koboSpan" id="kobo.122.1">. </span><span class="koboSpan" id="kobo.122.2">What if we know that </span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.123.1">certain configurations are almost certain to perform badly after a certain quantity of</span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.124.1"> resources </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">are consumed?</span></span></p>
<p><span class="koboSpan" id="kobo.126.1">Successive halving is an extension</span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.127.1"> of random search that helps to save resources while searching for the best neural architecture. </span><span class="koboSpan" id="kobo.127.2">The idea behind successive halving is to eliminate half of the poorly performing configurations at each step, allowing us to focus on the more promising ones. </span><span class="koboSpan" id="kobo.127.3">This way, we don’t waste time on configurations that are less likely to yield </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">good results.</span></span></p>
<p><span class="koboSpan" id="kobo.129.1">Let’s break down the concept using a simple example. </span><span class="koboSpan" id="kobo.129.2">Imagine you are trying to find the best configuration for an MLP with varying hyperparameters such as the number of layers and layer sizes. </span><span class="koboSpan" id="kobo.129.3">You start by randomly sampling 100 different configurations. </span><span class="koboSpan" id="kobo.129.4">Now, instead of training all 100 configurations to completion, you apply successive halving. </span><span class="koboSpan" id="kobo.129.5">You train each of the 100 configurations for a short period (for example, 5 epochs) and then evaluate their performance on a validation dataset. </span><span class="koboSpan" id="kobo.129.6">At this point, you eliminate the 50 worst-performing configurations and continue training the remaining 50 configurations for another </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">5 epochs.</span></span></p>
<p><span class="koboSpan" id="kobo.131.1">After this second round of training, you again evaluate the performance of the remaining configurations and eliminate the 25 worst-performing ones. </span><span class="koboSpan" id="kobo.131.2">The top 25 configurations can then continue to train until convergence. </span><span class="koboSpan" id="kobo.131.3">By applying successive halving, you save resources and time by focusing on the most promising configurations while discarding the poorly </span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.132.1">performing ones early in the process. </span><span class="koboSpan" id="kobo.132.2">This allows you to more efficiently search for the best neural architecture for </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">your problem.</span></span></p>
<p><span class="koboSpan" id="kobo.134.1">Let’s dive into the </span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.135.1">technical implementation of successive halving that will also set the stage for all the other methods under general hyperparameter </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">tuning-based NAS:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.137.1">Let’s start by importing the relevant libraries and setting the </span><strong class="source-inline"><span class="koboSpan" id="kobo.138.1">pytorch</span></strong><span class="koboSpan" id="kobo.139.1"> library seed to </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">ensure reproducibility:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.141.1">
import json
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from catalyst import dl, utils
from catalyst.contrib.datasets import MNIST
from sklearn import datasets
from sklearn.metrics import log_loss
from sklearn.model_selection import train_test_split from sklearn.preprocessing import MinMaxScaler from torch import nn as nn from torch import optim from torch.utils.data import DataLoader, TensorDataset torch.manual_seed(0)</span></pre></li> <li><span class="koboSpan" id="kobo.142.1">Next, let’s define a </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">pytorch</span></strong><span class="koboSpan" id="kobo.144.1"> MLP class that has the functionality to build an MLP dynamically</span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.145.1"> based on the number of hidden layers and hidden sizes of </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">each layer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.147.1">
class MLP(nn.Module):
  def __init__(self, input_layer_size, output_layer_size, layer_configuration, activation_type='relu'):
     super(MLP, self).__init__()
     self.fully_connected_layers = nn.ModuleDict()
     self.activation_type = activation_type
     hidden_layer_number = 0
     for hidden_layer_idx in range(len(layer_configuration)):
     if hidden_layer_idx == 0:
        self.fully_connected_layers[
           str(hidden_layer_number)
        ] = nn.Linear(
           input_layer_size,
           layer_configuration[hidden_layer_idx]
        )
        hidden_layer_number += 1
     if hidden_layer_idx == len(layer_configuration) - 1:
        self.fully_connected_layers[
           str(hidden_layer_number)
        ] = nn.Linear(
           layer_configuration[hidden_layer_idx],
           output_layer_size
        )
     else:
        self.fully_connected_layers[
           str(hidden_layer_number)
        ] = nn.Linear(
           layer_configuration[hidden_layer_idx],
           layer_configuration[hidden_layer_idx+1]
        )
        hidden_layer_number += 1
  def forward(self, x):
     for fc_key in self.fully_connected_layers:
        x = self.fully_connected_layers[fc_key](x)
        if fc_key != str(len(self.fully_connected_layers) -1):
           x = F.relu(x)
     return x</span></pre></li> <li><span class="koboSpan" id="kobo.148.1">Next, we need the</span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.149.1"> logic that trains this MLP when provided with a specific layer configuration list. </span><span class="koboSpan" id="kobo.149.2">Here, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.150.1">pytorch</span></strong><span class="koboSpan" id="kobo.151.1"> abstraction library called </span><strong class="source-inline"><span class="koboSpan" id="kobo.152.1">catalyst</span></strong><span class="koboSpan" id="kobo.153.1"> to train the</span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.154.1"> model and save the best and last epoch model with a few </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">convenient methods:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.156.1">
def train_and_evaluate_mlp(
  trial_number, layer_configuration, epochs,
  input_layer_size, output_layer_size ,
  load_on_stage_start=False, best_or_last='last',
  verbose=False
):
  criterion = nn.CrossEntropyLoss()
  runner = dl.SupervisedRunner(
     input_key="features", output_key="logits",
     target_key="targets", loss_key="loss"
  )
  model = MLP(
     input_layer_size=input_layer_size,
     layer_configuration=layer_configuration,
     output_layer_size=output_layer_size,
  )
  optimizer = optim.Adam(model.parameters(), lr=0.02)
  checkpoint_logdir = "logs/trial_{}".format(
     trial_number
  )
  runner.train(
     model=model, criterion=criterion,
     optimizer=optimizer, loaders=loaders,
     num_epochs=epochs,
     callbacks=[
        dl.CheckpointCallback(
           logdir=checkpoint_logdir,
           loader_key="valid",
           metric_key="loss",
           mode="all",
           load_on_stage_start="last_full" if load_on_stage_start else None,
        )
     ], logdir="./logs", valid_loader="valid",
     valid_metric="loss", minimize_valid_metric=True,
     verbose=verbose
  )
  with open(os.path.join(checkpoint_logdir, '_metrics.json'), 'r') as f:
     metrics = json.load(f)
     if best_or_last == 'last':
        valid_loss = metrics['last']['_score_']
     else:
        valid_loss = metrics['best']['valid']['loss']
  return valid_loss</span></pre></li> <li><span class="koboSpan" id="kobo.157.1">Next, we need a method that generates a random number of hyperparameters for the MLP. </span><span class="koboSpan" id="kobo.157.2">The hyperparameter is structured to be a list of hidden layer size specifications where the</span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.158.1"> number of items in the list determines the number of layers. </span><span class="koboSpan" id="kobo.158.2">We fix the range </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.159.1">number of hidden layers to be between 1 and 6 layers and hidden layer sizes to be between 2 </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">and 100:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.161.1">
def get_random_configurations(
  number_of_configurations, rng
):
  layer_configurations = []
  for _ in range(number_of_configurations):
     layer_configuration = []
     number_of_hidden_layers = rng.randint(
        low=1, high=6
     )
     for _ in range(number_of_hidden_layers):
        layer_configuration.append(
           rng.randint(low=2, high=100)
        )
     layer_configurations.append(layer_configuration)
  layer_configurations = np.array(
     layer_configurations
  )
  return layer_configurations</span></pre></li> <li><span class="koboSpan" id="kobo.162.1">Now, with the helpers defined, let’s set up our tabular dataset to apply MLP with. </span><span class="koboSpan" id="kobo.162.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.163.1">iris</span></strong><span class="koboSpan" id="kobo.164.1"> dataset from </span><strong class="source-inline"><span class="koboSpan" id="kobo.165.1">scikit-learn</span></strong><span class="koboSpan" id="kobo.166.1"> will be used here. </span><span class="koboSpan" id="kobo.166.2">We will load it, scale the values, split the dataset into train and validation partitions, and prepare it to be consumed </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.167.1">by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.168.1">catalyst</span></strong><span class="koboSpan" id="kobo.169.1"> library. </span><span class="koboSpan" id="kobo.169.2">Note that the code up until this </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.170.1">step will be reused for the next </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">two methods:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.172.1">
iris = datasets.load_iris()
iris_input_dataset = iris['data']
target = torch.from_numpy(iris['target'])
scaler = MinMaxScaler()
scaler.fit(iris_input_dataset)
iris_input_dataset = torch.from_numpy(
  scaler.transform(iris_input_dataset)
).float()
(
  X_train, X_test, y_train, y_test
) = train_test_split(
  iris_input_dataset, target, test_size=0.33,
  random_state=42
)
training_dataset = TensorDataset(X_train, y_train)
validation_dataset =  TensorDataset(X_test, y_test)
train_loader = DataLoader(
  training_dataset, batch_size=10, num_workers=1
)
valid_loader = DataLoader(
  validation_dataset, batch_size=10, num_workers=1
)
loaders = {"train": train_loader, "valid": valid_loader}</span></pre></li> <li><span class="koboSpan" id="kobo.173.1">The approach we are going to take here with successive halving is to use epochs as the resource component</span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.174.1"> where we will execute three iterations of </span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.175.1">successive halving once a predefined number of epochs for that iteration has been executed. </span><span class="koboSpan" id="kobo.175.2">Half of the top-performing configurations will continue to be trained in the next iteration. </span><span class="koboSpan" id="kobo.175.3">Here, we use 20 initial configurations and 3 iterations of successive halving with 5 epochs each. </span><span class="koboSpan" id="kobo.175.4">Let’s start by defining these values along with the seeded random number generator that controls the randomness of the </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">generated configurations:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.177.1">
rng = np.random.RandomState(1234)
number_of_configurations = 20
layer_configurations = get_random_configurations(
  number_of_configurations, rng
)
successive_halving_epochs = [5, 5, 5]</span></pre></li> <li><span class="koboSpan" id="kobo.178.1">Finally, we will define the execution logic for successive halving. </span><span class="koboSpan" id="kobo.178.2">Note that the last trained epoch weights </span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.179.1">are used here, at the next iteration, instead of the </span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.180.1">epoch with the best </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">validation score:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.182.1">
for succesive_idx, successive_halving_epoch in enumerate(successive_halving_epochs):
  valid_losses = []
  for idx, layer_configuration in enumerate(layer_configurations):
     trial_number = trial_numbers[idx]
     valid_loss = train_and_evaluate_mlp(
        trial_number, layer_configuration,
        epochs=successive_halving_epoch,
        load_on_stage_start=False if succesive_idx==0 else True
     )
     valid_losses.append(valid_loss)
     if succesive_idx != len(successive_halving_epochs) - 1:
        succesive_halved_configurations = np.argsort(
           valid_losses
        )[:int(len(valid_losses)/2)]
        layer_configurations = layer_configurations[
           succesive_halved_configurations
        ]
        trial_numbers = trial_numbers[
           succesive_halved_configurations
        ]</span></pre></li> <li><span class="koboSpan" id="kobo.183.1">The best configuration can then be found via the </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">following logic:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.185.1">
best_loss_idx = np.argmin(valid_losses)
best_layer_configuration = layer_configurations[best_loss_idx]
best_loss_trial_number = trial_numbers[best_loss_idx]</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.186.1">In successive halving, some </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.187.1">configurations might only be performant at the later stages of the training process, while some configurations can be performant from the early stages of the training process. </span><span class="koboSpan" id="kobo.187.2">Choosing either a longer wait time or a faster wait time will </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.188.1">put some models at a disadvantage and requires finding a balance that we might not know the truth about. </span><span class="koboSpan" id="kobo.188.2">The Hyperband method that will be introduced next is an attempt to solve </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">this issue.</span></span></p>
<h2 id="_idParaDest-112"><a id="_idTextAnchor113"/><span class="koboSpan" id="kobo.190.1">Searching neural architectures by using Hyperband</span></h2>
<p><span class="koboSpan" id="kobo.191.1">Hyperband improves</span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.192.1"> upon the caveats in</span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.193.1"> successive halving by executing multiple separate end-to-end iterations of successive halving called brackets. </span><span class="koboSpan" id="kobo.193.2">Each consecutive bracket would have smaller original sample configurations but has a higher number of resources allocated. </span><span class="koboSpan" id="kobo.193.3">This algorithm essentially allows some randomly sampled configurations to be trained longer, increasing the probability that the inherent potential for good performance is shown so that abandoning</span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.194.1"> these configurations won’t be a waste at the later brackets. </span><span class="koboSpan" id="kobo.194.2">The full algorithm is shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.195.1">Figure 7</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.196.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<span class="koboSpan" id="kobo.198.1"><img alt="Figure 7.1 – Hyperband algorithm pseudocode" src="image/B18187_07_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.199.1">Figure 7.1 – Hyperband algorithm pseudocode</span></p>
<p><span class="koboSpan" id="kobo.200.1">Two user input configurations are needed for this algorithm: specifically, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.201.1">R</span></span><span class="koboSpan" id="kobo.202.1">, the maximum amount of resources to train and evaluate a single configuration, and </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.203.1">η</span></span><span class="koboSpan" id="kobo.204.1">, the divider number that decides the number of configurations to keep at the end of every successive halving iteration. </span><span class="koboSpan" id="kobo.204.2">The total number of brackets, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.205.1">s</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.206.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.207.1">m</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.208.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.209.1">x</span></span><span class="koboSpan" id="kobo.210.1">, the total resource allocated for each bracket, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.211.1">B</span></span><span class="koboSpan" id="kobo.212.1">, the total number of configurations by bracket and iteration </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.213.1">n</span></span><span class="koboSpan" id="kobo.214.1"> and </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.215.1">n</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.216.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.217.1">i</span></span><span class="koboSpan" id="kobo.218.1">, and the resource allocated by brackets </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.219.1">r</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.220.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.221.1">i</span></span><span class="koboSpan" id="kobo.222.1">, are all computed by formula. </span><span class="koboSpan" id="kobo.222.2">To make this </span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.223.1">easier to digest, </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.224.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.225.1">.2</span></em><span class="koboSpan" id="kobo.226.1"> shows the example Hyperband resulting configuration results in each bracket when </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.227.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.228.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.229.1">81</span></span><span class="koboSpan" id="kobo.230.1">, and </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.231.1">η</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.232.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.233.1">3</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<span class="koboSpan" id="kobo.235.1"><img alt="Figure 7.2 – Example Hyperband resulting configuration results in each bracket" src="image/B18187_07_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.236.1">Figure 7.2 – Example Hyperband resulting configuration results in each bracket</span></p>
<p><span class="koboSpan" id="kobo.237.1">These settings produce a total of 5 brackets and produce a total of 10 final models. </span><span class="koboSpan" id="kobo.237.2">The best model out of these 10 </span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.238.1">models would then be used as the final produced model from the </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">search operation.</span></span></p>
<p><span class="koboSpan" id="kobo.240.1">Note that, in this method, expert knowledge can be explicitly injected into the process of the two search methods by, for example, fixing the macroarchitecture of the model and only searching the </span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.241.1">hyperparameters for a microarchitecture logical block. </span><span class="koboSpan" id="kobo.241.2">Let’s go through an implementation of Hyperband using the methods and dataset defined in the successive </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">halving topic:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.243.1">First, let’s define the additional library needed here to </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">compute logarithms:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.245.1">
import math</span></pre></li> <li><span class="koboSpan" id="kobo.246.1">Next, we will define the two input parameters needed for the Hyperband implementation, the maximum resource we want to run per configuration in terms of epochs, and the divisor of configurations, </span><strong class="source-inline"><span class="koboSpan" id="kobo.247.1">N</span></strong><span class="koboSpan" id="kobo.248.1">, after every successive halving operation in the </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">Hyperband algorithm:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.250.1">
resource_per_conf = 30  # R
N = 3</span></pre></li> <li><span class="koboSpan" id="kobo.251.1">Now, we will define the main logic of Hyperband according to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.252.1">Figure 7</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.253.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.255.1">
s_max = int(math.log(resource_per_conf, N))
bracket_resource = (s_max + 1) * resource_per_conf  bracket_best_valid_losses = []
bracket_best_layer_configuration = []
for s in range(s_max, -1, -1):
  number_of_configurations = int(
     (bracket_resource / resource_per_conf) *
     (N**s / (s+1))
  )
  r = resource_per_conf * N**-s
  layer_configurations = get_random_configurations(
     number_of_configurations, rng
  )
  trial_numbers = np.array(
     range(len(layer_configurations))
  )
  valid_losses = []
  for i in range(s+1):
     number_of_configurations_i = int(
        number_of_configurations * N**-i
     )
     r_i = int(r * N**i)
     valid_losses = []
     for idx, layer_configuration in enumerate(layer_configurations):
        trial_number = '{}_{}'.format(
           s, trial_numbers[idx]
        )
        valid_loss = train_and_evaluate_mlp(
           trial_number, layer_configuration,
           epochs=r_i, load_on_stage_start=False if
           s==s_max else True
        )
        valid_losses.append(valid_loss)
        if succesive_idx != len(successive_halving_epochs) - 1:
           succesive_halved_configurations = np.argsort(
            valid_losses
           )[:int(number_of_configurations_i/N)]
           layer_configurations = layer_configurations[
              succesive_halved_configurations
           ]
           trial_numbers = trial_numbers[
            succesive_halved_configurations
           ]
           best_loss_idx = np.argmin(valid_losses)
           best_layer_configuration = layer_configurations[best_loss_idx]
           best_loss_trial_number = trial_numbers[
              best_loss_idx
           ]
           bracket_best_valid_losses.append(
              valid_losses[best_loss_idx]
           )
           bracket_best_layer_configuration.append(
              best_layer_configuration
           )</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.256.1">The two methods utilize random </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.257.1">search heavily without being very smart about choosing the hyperparameters’ configuration. </span><span class="koboSpan" id="kobo.257.2">Next, we will explore a search method that optimizes the </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.258.1">next choice of hyperparameters after some initial searching has </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">been done.</span></span></p>
<h2 id="_idParaDest-113"><a id="_idTextAnchor114"/><span class="koboSpan" id="kobo.260.1">Searching neural architectures by using Bayesian hyperparameter optimization</span></h2>
<p><span class="koboSpan" id="kobo.261.1">Bayesian hyperparameter optimization is a</span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.262.1"> method that utilizes a surrogate performance estimation model to choose an estimated best set of configurations to sample and evaluate from. </span><span class="koboSpan" id="kobo.262.2">The act of sampling configurations to train and evaluate is formally called the </span><strong class="bold"><span class="koboSpan" id="kobo.263.1">acquisition function</span></strong><span class="koboSpan" id="kobo.264.1">. </span><span class="koboSpan" id="kobo.264.2">Instead of random sampling and</span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.265.1"> hoping that it’ll perform well, Bayesian optimization </span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.266.1">attempts to leverage the prior information gained from an initial random configuration sampling and actual training and evaluation to find new configurations that are estimated to perform well. </span><span class="koboSpan" id="kobo.266.2">Bayesian optimization takes the </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">following steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.268.1">Sample a number of </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">hyperparameter configurations.</span></span></li>
<li><span class="koboSpan" id="kobo.270.1">Perform full training and evaluation with these configurations to obtain </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">performance scores.</span></span></li>
<li><span class="koboSpan" id="kobo.272.1">Train a surrogate regression</span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.273.1"> model (typically, a </span><strong class="bold"><span class="koboSpan" id="kobo.274.1">Gaussian processes</span></strong><span class="koboSpan" id="kobo.275.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.276.1">GP</span></strong><span class="koboSpan" id="kobo.277.1">) model is used) with all the available data to estimate the performance scores based on </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">the hyperparameters.</span></span></li>
<li><span class="koboSpan" id="kobo.279.1">Either use all possible hyperparameter configurations or randomly sample a good amount of hyperparameter configurations and predict the performance score using the </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">surrogate model.</span></span></li>
<li><span class="koboSpan" id="kobo.281.1">Get the </span><em class="italic"><span class="koboSpan" id="kobo.282.1">k</span></em><span class="koboSpan" id="kobo.283.1"> hyperparameter configurations that have the minimum estimated performance scores from the </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">surrogate model.</span></span></li>
<li><span class="koboSpan" id="kobo.285.1">Repeat </span><em class="italic"><span class="koboSpan" id="kobo.286.1">step 1</span></em><span class="koboSpan" id="kobo.287.1"> to </span><em class="italic"><span class="koboSpan" id="kobo.288.1">step 5</span></em><span class="koboSpan" id="kobo.289.1"> either a predetermined number of times, until a good enough result is obtained, or until your resource budget is all </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">used up.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.291.1">The process essentially attempts to speed up the actual training and evaluation process by estimating the scores it will produce and only actually training the estimated top few configurations. </span><span class="koboSpan" id="kobo.291.2">The optimization only works if the surrogate model performance score estimation function is considerably faster than the actual training and evaluation of the main model. </span><span class="koboSpan" id="kobo.291.3">Note that the</span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.292.1"> standard Bayesian optimization works only in the continuous space and can’t deal with discrete hyperparameters properly. </span><span class="koboSpan" id="kobo.292.2">Let’s go through the technical implementation of</span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.293.1"> Bayesian optimization-based NAS using the same methods and dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">defined earlier:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.295.1">Let’s start by importing the main powerhouse behind the Bayesian optimization approach here, which is the GP regressor </span><span class="No-Break"><span class="koboSpan" id="kobo.296.1">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.299.1">
from sklearn.gaussian_process import GaussianProcessRegressor</span></pre></li> <li><span class="koboSpan" id="kobo.300.1">Next, let’s define the method that creates a structured fixed-sized column of 6, which is the maximum number of possible layers defined earlier. </span><span class="koboSpan" id="kobo.300.2">When there are fewer than 6 layers, the later columns will just have 0 layers as </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">a feature:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.302.1">
def get_bayesian_optimization_input_features(
  layer_configurations
):
  bo_input_features = []
  for layer_configuration in layer_configurations:
     bo_input_feature = layer_configuration + [0] * (6 - len(layer_configuration))
     bo_input_features.append(bo_input_feature)
  return bo_input_features</span></pre></li> <li><span class="koboSpan" id="kobo.303.1">Next, let’s define three important parameters for Bayesian optimization-based NAS using MLP. </span><span class="koboSpan" id="kobo.303.2">The first parameter is the number of configurations. </span><span class="koboSpan" id="kobo.303.3">The approach we are taking here is to initially train 100 configurations in the first iteration according to the specified epochs per configuration. </span><span class="koboSpan" id="kobo.303.4">After that, we build a GP regressor to predict the validation loss. </span><span class="koboSpan" id="kobo.303.5">Then, we will sample configurations in the next few iterations and use the model to predict and pick the top five </span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.304.1">configurations to perform full training. </span><span class="koboSpan" id="kobo.304.2">In every iteration, a new regressor model is built with all the available validation </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">loss data:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.306.1">
number_of_configurations = [100, 2000]
epochs_per_conf = 15
topk_models = 5</span></pre></li> <li><span class="koboSpan" id="kobo.307.1">Finally, let’s define the main logic that accomplishes a version of Bayesian optimization-based </span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.308.1">NAS </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">with MLP:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.310.1">
Trial_numbers = np.array(
  range(len(layer_configurations))
)
trial_number = 0
model = None
best_valid_losses_per_iteration = []
best_configurations_per_iteration = []
overall_bo_input_features = []
overall_bo_valid_losses = []
for number_of_configuration in number_of_configurations:
  valid_losses = []
  layer_configurations = get_random_configurations(
     number_of_configuration, rng
  )
  if model:
     bo_input_features = get_bayesian_optimization_input_features(layer_configurations)
     predicted_valid_losses = model.predict(
        bo_input_features
     )
     top_k_idx = np.argsort(
        predicted_valid_losses
     )[:topk_models]
     layer_configurations = layer_configurations[
        top_k_idx
     ]
  for idx, layer_configuration in enumerate(layer_configurations):
     trial_identifier = 'bo_{}'.format(trial_number)
     valid_loss = train_and_evaluate_mlp(
        trial_number, layer_configuration,
        epochs=epochs_per_conf,
        load_on_stage_start=False, best_or_last='best'
     )
     valid_losses.append(valid_loss)
     trial_number += 1
  best_loss_idx = np.argmin(valid_losses)
  best_valid_losses_per_iteration.append(
     valid_losses[best_loss_idx]
  )
  best_configurations_per_iteration.append(
     layer_configurations[best_loss_idx]
  )
  bo_input_features = get_bayesian_optimization_input_features(layer_configurations)
  overall_bo_input_features.extend(bo_input_features)
  overall_bo_valid_losses.extend(valid_losses)
  model = GaussianProcessRegressor()
  model.fit(
     overall_bo_input_features,
     overall_bo_valid_losses
  )</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.311.1">With that, we’ve </span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.312.1">achieved MLP hyperparameter search with </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">Bayesian optimization!</span></span></p>
<p><span class="koboSpan" id="kobo.314.1">In addition to the</span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.315.1"> hyperparameter search-based NAS methods discussed in this chapter, it is worth mentioning three other approaches, which are hierarchical search, proxy models, and </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">evolutionary algorithms:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.317.1">Hierarchical search focuses on optimizing architectures at different levels of granularity, allowing for a more efficient exploration of the </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">search space</span></span></li>
<li><span class="koboSpan" id="kobo.319.1">Proxy models serve as lightweight approximations of the target models, reducing the computational cost of evaluating candidate architectures during </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">the search</span></span></li>
<li><span class="koboSpan" id="kobo.321.1">Lastly, evolutionary algorithms are inspired by natural selection processes and can be applied to the NAS problem, enabling the exploration and optimization of architectures through mutation, crossover, and </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">selection operations</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.323.1">These methods can also be considered when choosing among hyperparameter search-based </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">NAS techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.325.1">NAS with general hyperparameter search methods provides a simple way to search different configurations in a smarter way than just plain random or brute-force search. </span><span class="koboSpan" id="kobo.325.2">It provides the most help when you already have the infrastructure ready to choose different hyperparameters</span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.326.1"> easily, along with the expert knowledge from the field already built in under </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">the hood.</span></span></p>
<p><span class="koboSpan" id="kobo.328.1">However, NAS with general hyperparameter search generally requires a lot of out-of-algorithm tooling for building the model and formalizing the helper methods that can reliably be controlled by hyperparameters. </span><span class="koboSpan" id="kobo.328.2">On top of that, it is still required to have quite a bit of knowledge of which types of layers to use along with out-of-algorithm crafting of the macro- and</span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.329.1"> microarchitecture of the </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1">NN model.</span></span></p>
<p><span class="koboSpan" id="kobo.331.1">In the next section, we will go through a line of NAS methods that covers more extensively all the steps needed to achieve NAS for any NN, called </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">RL-based NAS.</span></span></p>
<h1 id="_idParaDest-114"><a id="_idTextAnchor115"/><span class="koboSpan" id="kobo.333.1">Understanding RL-based NAS</span></h1>
<p><span class="koboSpan" id="kobo.334.1">RL is a family of learning algorithms that deal with the learning of a policy that allows an agent to make consecutive decisions</span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.335.1"> on its actions while interacting with states in an environment. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.336.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.337.1">.3</span></em><span class="koboSpan" id="kobo.338.1"> shows a general overview of </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">RL algorithms:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer077">
<span class="koboSpan" id="kobo.340.1"><img alt="Figure 7.3 – General overview of RL algorithms" src="image/B18187_07_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.341.1">Figure 7.3 – General overview of RL algorithms</span></p>
<p><span class="koboSpan" id="kobo.342.1">This line of algorithms is most popularly utilized to create intelligent bots for games that can act as offline players against real humans. </span><span class="koboSpan" id="kobo.342.2">In the context of a digital game, the environment represents the entire setting in which the agent operates, including aspects such as the position and status of the in-game character, as well as conditions of the in-game world. </span><span class="koboSpan" id="kobo.342.3">The state, on the other hand, is a snapshot of the environment at a given time, reflecting the current conditions of the game. </span><span class="koboSpan" id="kobo.342.4">One key component in RL is the environment feedback component that can provide either a reward or punishment. </span><span class="koboSpan" id="kobo.342.5">In digital games, examples of rewards and punishments are some forms of a competitive scoring system, in-game</span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.343.1"> cash, the leveling system, or sometimes negatively through death. </span><span class="koboSpan" id="kobo.343.2">When applied to the realm of NAS, the state will then be the generated NN architecture, and the environment will be the evaluation of the generated NN configurations. </span><span class="koboSpan" id="kobo.343.3">The rewards and punishments will then be the latency performance and metric performance of the resulting architecture after training and evaluating it on a chosen dataset. </span><span class="koboSpan" id="kobo.343.4">Another key </span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.344.1">component is the term </span><strong class="bold"><span class="koboSpan" id="kobo.345.1">policy</span></strong><span class="koboSpan" id="kobo.346.1">, which is the component responsible for producing an action based on </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">the state.</span></span></p>
<p><span class="koboSpan" id="kobo.348.1">Recall that in the general hyperparameter search-based NAS, the NN configuration sample acquisition is based on random sampling. </span><span class="koboSpan" id="kobo.348.2">In RL-based NAS approaches, the goal is not only to optimize the search process but also the acquisition process that produces NN configurations based on prior experiences. </span><span class="koboSpan" id="kobo.348.3">The exact methods of how the configurations can be produced, however, differ in different RL-based </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">NAS methods.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">In this section, we will dive into a few RL methods specific </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">to NAS:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.352.1">Founding NAS based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">RL method</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.354.1">Efficient NAS</span></strong><span class="koboSpan" id="kobo.355.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.356.1">ENAS</span></strong><span class="koboSpan" id="kobo.357.1">) via</span><a id="_idIndexMarker512"/> <span class="No-Break"><span class="koboSpan" id="kobo.358.1">parameter sharing</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.359.1">Mobile </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.360.1">NAS</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.361.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.362.1">MNAS</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.364.1">Let’s start with the first founding NAS based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">RL method.</span></span></p>
<h2 id="_idParaDest-115"><a id="_idTextAnchor116"/><span class="koboSpan" id="kobo.366.1">Understanding founding NAS based on RL</span></h2>
<p><span class="koboSpan" id="kobo.367.1">RL can be implemented with NNs, and</span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.368.1"> in the use case of </span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.369.1">NAS, a </span><strong class="bold"><span class="koboSpan" id="kobo.370.1">recurrent NN</span></strong><span class="koboSpan" id="kobo.371.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.372.1">RNN</span></strong><span class="koboSpan" id="kobo.373.1">) is used to act as the missing piece needed to probabilistically generate the main NN configurations at test time. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.374.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.375.1">.4</span></em><span class="koboSpan" id="kobo.376.1"> roughly shows an architectural overview of the foundational NAS with the </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">RL method:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer078">
<span class="koboSpan" id="kobo.378.1"><img alt="Figure 7.4 – Architectural overview of NAS with RL workflow" src="image/B18187_07_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.379.1">Figure 7.4 – Architectural overview of NAS with RL workflow</span></p>
<p><span class="koboSpan" id="kobo.380.1">The RNN is the policy that determines the state after a learning step from the previous environment interaction. </span><span class="koboSpan" id="kobo.380.2">In the case of NAS, the action is equivalent to the state. </span><span class="koboSpan" id="kobo.380.3">Recall that an RNN is composed of multiple sequential recurrent-based cells where each cell is capable of producing an intermediate sequential output. </span><span class="koboSpan" id="kobo.380.4">In NAS, these intermediate sequential outputs are </span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.381.1">designed to predict specific configurations for the main NN. </span><span class="koboSpan" id="kobo.381.2">The predictions are then fed into the next RNN cell as a cell input. </span><span class="koboSpan" id="kobo.381.3">Consider the NAS task to search for the best CNN architecture in the image domain. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.382.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.383.1">.5</span></em><span class="koboSpan" id="kobo.384.1"> shows the structure of this task using the RNN-based NN </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">configuration predictions:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer079">
<span class="koboSpan" id="kobo.386.1"><img alt="﻿Figure 7.5 – LSTM-based CNN layer configurations prediction for NAS" src="image/B18187_07_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.387.1">Figure 7.5 – LSTM-based CNN layer configurations prediction for NAS</span></p>
<p><span class="koboSpan" id="kobo.388.1">A convolutional layer has a few specifications that need to be decided: namely, the number of convolutional filters, the size of the convolutional filters, and the size of the stride. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.389.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.390.1">.5</span></em><span class="koboSpan" id="kobo.391.1"> shows the predictions for a single CNN layer. </span><span class="koboSpan" id="kobo.391.2">For subsequent CNN layers, the same </span><strong class="bold"><span class="koboSpan" id="kobo.392.1">long short-term memory</span></strong><span class="koboSpan" id="kobo.393.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.394.1">LSTM</span></strong><span class="koboSpan" id="kobo.395.1">) cells are repeatedly sequentially predicted with the state and cell outputs </span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.396.1">from the last LSTM cell as input. </span><span class="koboSpan" id="kobo.396.2">For a four-layered CNN, the LSTM would then be autoregressively executed four times to obtain all required </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">configuration predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.398.1">As for how the parameters of the LSTM are updated, a</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.399.1"> process called </span><strong class="bold"><span class="koboSpan" id="kobo.400.1">policy gradient</span></strong><span class="koboSpan" id="kobo.401.1"> will be used. </span><span class="koboSpan" id="kobo.401.2">Policy gradient is a group of methods that uses gradients to update the policy. </span><span class="koboSpan" id="kobo.401.3">Specifically, the </span><strong class="bold"><span class="koboSpan" id="kobo.402.1">reinforce</span></strong><span class="koboSpan" id="kobo.403.1"> rule</span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.404.1"> is used here to compute the gradients for updating the parameters. </span><span class="koboSpan" id="kobo.404.2">In more understandable terminology, the following formula shows how the gradients </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">are computed:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.406.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.407.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.408.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.409.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.410.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.411.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.412.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.413.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.414.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.415.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.416.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.417.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.418.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.419.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.420.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.421.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.422.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.423.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.424.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.425.1">(</span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.426.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.427.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.428.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.429.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.430.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.431.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.432.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.433.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.434.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.435.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.436.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.437.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.438.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.439.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.440.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.441.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.442.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.443.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.444.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.445.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.446.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.447.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.448.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.449.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.450.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.451.1">m</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.452.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.453.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.454.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.455.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.456.1">g</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.457.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.458.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.459.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.460.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.461.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.462.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.463.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.464.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.465.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.466.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.467.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.468.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.469.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.470.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.471.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.472.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.473.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.474.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.475.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.476.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.477.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.478.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.479.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.480.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.481.1">)</span></span><span class="koboSpan" id="kobo.482.1">) </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.483.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.484.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.485.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.486.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.487.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.488.1">l</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.489.1">s</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.490.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.491.1">m</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.492.1">p</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.493.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.494.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.495.1">d</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.496.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.497.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.498.1">c</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.499.1">h</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.500.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.501.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.502.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.503.1">c</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.504.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.505.1">u</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.506.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.507.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.508.1">s</span></span></span></p>
<p><span class="koboSpan" id="kobo.509.1">The cross-entropy loss here is specifically used to emphasize that the configuration prediction tasks are framed as a multiclass classification problem so that the number of search parameters can be </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.510.1">constrained to a small number while making sure boundaries are set. </span><span class="koboSpan" id="kobo.510.2">For example, you wouldn’t want a million filters for a single CNN layer or a million-neurons-sized fully connected layers in </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">an MLP.</span></span></p>
<p><span class="koboSpan" id="kobo.512.1">The RL process here is guided by the concept of exploration versus exploitation. </span><span class="koboSpan" id="kobo.512.2">If we continue to use only the predicted states of the RNN and use that as the labels for computing the cross-entropy loss, the policy will just become more and more biased toward its own parameters. </span><span class="koboSpan" id="kobo.512.3">Using the RNN predictions as labels is known as the </span><em class="italic"><span class="koboSpan" id="kobo.513.1">exploitation process</span></em><span class="koboSpan" id="kobo.514.1">, where the idea is to</span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.515.1"> just allow the RNN to be more confident about its own predictions. </span><span class="koboSpan" id="kobo.515.2">This process grows the model deeper toward its current intelligence instead of toward intelligence that can be gained from external data exploration. </span><em class="italic"><span class="koboSpan" id="kobo.516.1">Exploration</span></em><span class="koboSpan" id="kobo.517.1"> here is when network configurations are randomly sampled to act as the label for the cross-entropy loss at each RNN cell. </span><span class="koboSpan" id="kobo.517.2">The idea here is to start with lots of exploration and slowly reduce exploration going into later stages of policy learning and depending more </span><span class="No-Break"><span class="koboSpan" id="kobo.518.1">on exploitation.</span></span></p>
<p><span class="koboSpan" id="kobo.519.1">Until now, the steps only allow for a relatively simple form of CNN, but modifications can be added to the RNN agent to account for more complex CNN builds, such as parallel connections or skip connections from ResNet or DenseNet. </span><span class="koboSpan" id="kobo.519.2">In the original method, the addition of skip connections for complexity is attempted where an additional cell is added at the end of the five sequential RNN cells shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.520.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.521.1">.5</span></em><span class="koboSpan" id="kobo.522.1"> to act as </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.523.1">something called the </span><strong class="bold"><span class="koboSpan" id="kobo.524.1">anchor point</span></strong><span class="koboSpan" id="kobo.525.1">. </span><span class="koboSpan" id="kobo.525.2">An anchor point for a convolutional layer is combined individually with each anchor point of the convolutional layers prior to the referenced convolutional layer, applied with a </span><strong class="source-inline"><span class="koboSpan" id="kobo.526.1">tanh</span></strong><span class="koboSpan" id="kobo.527.1"> activation function, multiplied by a learnable weight, and finally applied with a sigmoid activation function that bounds the output values in between </span><strong class="source-inline"><span class="koboSpan" id="kobo.528.1">0</span></strong><span class="koboSpan" id="kobo.529.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.530.1">1</span></strong><span class="koboSpan" id="kobo.531.1">. </span><span class="koboSpan" id="kobo.531.2">The key information here is that the sigmoid function provides a probabilistic value that allows a binary classification task of “to add a skip connection or not” to be executed. </span><span class="koboSpan" id="kobo.531.3">A </span><strong class="source-inline"><span class="koboSpan" id="kobo.532.1">0.5</span></strong><span class="koboSpan" id="kobo.533.1"> value can be used to determine whether the output is </span><strong class="source-inline"><span class="koboSpan" id="kobo.534.1">1</span></strong><span class="koboSpan" id="kobo.535.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.536.1">0</span></strong><span class="koboSpan" id="kobo.537.1">. </span><span class="koboSpan" id="kobo.537.2">One </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.538.1">problem, however, is that the size of the outputs between different layers might not be compatible. </span><span class="koboSpan" id="kobo.538.2">A trick is automatically applied to solve the incompatibility by padding smaller output feature maps with zeros so that both feature maps have the </span><span class="No-Break"><span class="koboSpan" id="kobo.539.1">same size.</span></span></p>
<p><span class="koboSpan" id="kobo.540.1">This method allows you to dynamically add skip connections to a CNN in NAS. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.541.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.542.1">.6</span></em><span class="koboSpan" id="kobo.543.1"> shows the final architecture obtained from this NAS method using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.544.1">CIFAR-10</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.545.1">image dataset:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer080">
<span class="koboSpan" id="kobo.546.1"><img alt="Figure 7.6 – CNN obtained through NAS with RL from the https://arxiv.org/abs/1611.01578v2 paper" src="image/B18187_07_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.547.1">Figure 7.6 – CNN obtained through NAS with RL from the https://arxiv.org/abs/1611.01578v2 paper</span></p>
<p><span class="koboSpan" id="kobo.548.1">The architecture, although simple, is capable of deciding the best skip connections needed to achieve a good result. </span><span class="koboSpan" id="kobo.548.2">This resulting architecture shows how complex an architecture can be and shows how hard it would be for a human to design this outcome manually without proper searching algorithms. </span><span class="koboSpan" id="kobo.548.3">Note again that any complexity and modifications can</span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.549.1"> be added to the RNN policy to account for additional components such as the learning rate, pooling method, normalization method, or activation methods, which emphasizes the flexibility of the idea. </span><span class="koboSpan" id="kobo.549.2">Additionally, the NAS method can also be applied to search MLP or RNN main NNs. </span><span class="koboSpan" id="kobo.549.3">These additional adaptations and complexities, however, won’t be </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">covered here.</span></span></p>
<p><span class="koboSpan" id="kobo.551.1">Note that this technique fixed the microarchitecture structure in the sense that a standard convolutional layer is used. </span><span class="koboSpan" id="kobo.551.2">The technique, however, enabled some form of macroarchitecture designing by allowing skip connections. </span><span class="koboSpan" id="kobo.551.3">One of the main problems of this foundational technique is the time needed to evaluate the randomly generated or predicted architecture </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.552.1">configurations. </span><span class="koboSpan" id="kobo.552.2">Next, we will explore a method that attempts to minimize </span><span class="No-Break"><span class="koboSpan" id="kobo.553.1">this problem.</span></span></p>
<h2 id="_idParaDest-116"><a id="_idTextAnchor117"/><span class="koboSpan" id="kobo.554.1">Understanding ENAS</span></h2>
<p><span class="koboSpan" id="kobo.555.1">ENAS is a method that extends foundational NAS with the RL method by making the evaluation of generated architectures more efficient. </span><span class="koboSpan" id="kobo.555.2">Additionally, ENAS provides two different methods that allow either</span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.556.1"> the macroarchitecture or microarchitecture to be searched. </span><span class="koboSpan" id="kobo.556.2">Parameter </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.557.1">sharing is a concept that relates to </span><strong class="bold"><span class="koboSpan" id="kobo.558.1">transfer learning</span></strong><span class="koboSpan" id="kobo.559.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.560.1">TL</span></strong><span class="koboSpan" id="kobo.561.1">), where what is learned from one task can be transferred to another</span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.562.1"> task and fine-tuned for that subsequent task to get better results. </span><span class="koboSpan" id="kobo.562.2">Training and evaluating the main child architectures in this way provides an obvious way to speed up the process. </span><span class="koboSpan" id="kobo.562.3">However, it does rely heavily on weights pre-trained from the previous architectures and doesn’t provide an unbiased evaluation of the final searched architecture even if it performs well. </span><span class="koboSpan" id="kobo.562.4">Regardless, the method still proves to be valuable when combined with the novel </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">search space.</span></span></p>
<p><span class="koboSpan" id="kobo.564.1">ENAS applies RL using an RNN as well but does so in an entirely different searching direction and predicting different components with its RNN. </span><span class="koboSpan" id="kobo.564.2">The search space used by ENAS is through</span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.565.1"> a single </span><strong class="bold"><span class="koboSpan" id="kobo.566.1">directed acyclic graph</span></strong><span class="koboSpan" id="kobo.567.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.568.1">DAG</span></strong><span class="koboSpan" id="kobo.569.1">) where the number of nodes determines the number of layers of the child architecture. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.570.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.571.1">.7</span></em><span class="koboSpan" id="kobo.572.1"> shows an example of a </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">four-node DAG:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer081">
<span class="koboSpan" id="kobo.574.1"><img alt="Figure 7.7 – A four-node DAG representing the search space of ENAS" src="image/B18187_07_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.575.1">Figure 7.7 – A four-node DAG representing the search space of ENAS</span></p>
<p><span class="koboSpan" id="kobo.576.1">The RNN will then act as the controller that predicts two components for any architecture type: namely, which previous nodes to connect to and which computation operation to use. </span><span class="koboSpan" id="kobo.576.2">The RNN in this case will autoregressively predict the two components four times to account for four nodes. </span><span class="koboSpan" id="kobo.576.3">The red lines in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.577.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.578.1">.7</span></em><span class="koboSpan" id="kobo.579.1"> show the predicted previous nodes to connect to. </span><span class="koboSpan" id="kobo.579.2">There will be a fixed number of computation operations that can be chosen for every node. </span><span class="koboSpan" id="kobo.579.3">Since there will be a random sampling of the computation operation procedure to ensure an unbiased trajectory, the procedure will be based on the same search space. </span><span class="koboSpan" id="kobo.579.4">The parameter-sharing method is applied in the computation operation component for these nodes. </span><span class="koboSpan" id="kobo.579.5">After each training iteration, the weights for each computation </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.580.1">operation at each layer will be saved for future parameter-sharing use. </span><span class="koboSpan" id="kobo.580.2">Parameter sharing works in a way that each computation operation at each node number will be used as an identifier to save and reload weights whenever it is used again at the same layer with the same </span><span class="No-Break"><span class="koboSpan" id="kobo.581.1">computation operation.</span></span></p>
<p><span class="koboSpan" id="kobo.582.1">ENAS can be applied to search</span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.583.1"> for RNN architectures, CNN architectures, and MLP architectures and is generally extensible to any other architecture types. </span><span class="koboSpan" id="kobo.583.2">Let’s take the case of searching for CNN architectures for ENAS. </span><span class="koboSpan" id="kobo.583.3">For CNN, ENAS introduced two methods for searching; the first is to perform a macroarchitecture search, and the second is to perform a microarchitecture search. </span><span class="koboSpan" id="kobo.583.4">For the macroarchitecture search, six operations were proposed, which consisted of convolutional filters with filter sizes of 3 x 3 and 5 x 5, depthwise-separable convolutions with filter sizes 3 x 3 and 5 x 5, and max pooling and average pooling of kernel size 3 x 3. </span><span class="koboSpan" id="kobo.583.5">This set of operations allows for more diversity instead of just the plain convolutional layer, but instead of allowing more dynamic values of convolutional layer configuration, the same configurations are set to fixed values. </span><span class="koboSpan" id="kobo.583.6">Another implementation detail here is that when more than one previous node is selected for connection, the outputs from the layers of the previous nodes are concatenated along their depth dimension before being sent to the layer of the current node. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.584.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.585.1">.8</span></em><span class="koboSpan" id="kobo.586.1"> shows the result of a macroarchitecture search using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.587.1">CIFAR-10</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.588.1"> dataset:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer082">
<span class="koboSpan" id="kobo.589.1"><img alt="Figure 7.8 – Result of ENAS using the macroarchitecture search strategy" src="image/B18187_07_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.590.1">Figure 7.8 – Result of ENAS using the macroarchitecture search strategy</span></p>
<p><span class="koboSpan" id="kobo.591.1">The result was achieved using only 0.32 days using an outdated NVIDIA GTX 1080 Ti GPU, albeit on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.592.1">CIFAR-10</span></strong><span class="koboSpan" id="kobo.593.1"> dataset instead of ImageNet, and achieved only a 3.87 error rate on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.594.1">CIFAR-10</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.595.1">validation dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.596.1">As for the microarchitecture search, the idea is to build low-level logical blocks and repeat the same logical blocks</span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.597.1"> so that the architecture can be scaled easily. </span><span class="koboSpan" id="kobo.597.2">Two different logical blocks are searched in ENAS: a logical block consisting of the main convolutional operations, and a reduction logical block intended to reduce dimensionality. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.598.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.599.1">.9</span></em><span class="koboSpan" id="kobo.600.1"> shows the macroarchitecture of the final architecture used to scale microarchitecture </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.601.1">decisions </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">in ENAS:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<span class="koboSpan" id="kobo.603.1"><img alt="Figure 7.9 – Final macroarchitecture structure to scale a microarchitecture logical block" src="image/B18187_07_009.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.604.1">Figure 7.9 – Final macroarchitecture structure to scale a microarchitecture logical block</span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.605.1">N</span></em><span class="koboSpan" id="kobo.606.1"> is a fixed number that stays constant throughout the search duration. </span><span class="koboSpan" id="kobo.606.2">As this is microarchitecture, the architecture construction process was made to allow more complex interactions between layers, specifically the addition of operations to the output of previous nodes in skip connections. </span><span class="koboSpan" id="kobo.606.3">Due to this, for the convolutional logical block, the RNN was adapted by fixing the first two RNN cells for a node to specify which two previous node indexes to connect to and the subsequent RNN cells to predict the computation operation to apply individually for the two chosen previous node indexes. </span><span class="koboSpan" id="kobo.606.4">As for the reduction logical block, the main idea is to choose any operation and use a stride of two, which effectively reduces the spatial dimension of its input by two. </span><span class="koboSpan" id="kobo.606.5">The reduction logical block can be predicted along with the convolutional logical block using the same number of nodes and the same RNN. </span><span class="koboSpan" id="kobo.606.6">The parameter-sharing method in the microarchitecture case is adapted from the general case equivalently by similarly using the layer number and computation type </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.607.1">as an identifier to save and load trained child architecture weights. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.608.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.609.1">.10</span></em><span class="koboSpan" id="kobo.610.1"> shows the result of using the microarchitecture searching strategy </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">in ENAS:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<span class="koboSpan" id="kobo.612.1"><img alt="Figure 7.10 – Result of ENAS microarchitecture search strategy" src="image/B18187_07_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.613.1">Figure 7.10 – Result of ENAS microarchitecture search strategy</span></p>
<p><span class="koboSpan" id="kobo.614.1">The result was achieved in only 0.45 days using an outdated NVIDIA GTX 1080Ti GPU, albeit on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.615.1">CIFAR-10</span></strong><span class="koboSpan" id="kobo.616.1"> dataset</span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.617.1"> instead of ImageNet, and achieved only a 2.89 error rate on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.618.1">CIFAR-10</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.619.1">validation dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.620.1">Next, let’s go through the</span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.621.1"> final RL-based NAS method, </span><span class="No-Break"><span class="koboSpan" id="kobo.622.1">called MNAS.</span></span></p>
<h2 id="_idParaDest-117"><a id="_idTextAnchor118"/><span class="koboSpan" id="kobo.623.1">Understanding MNAS</span></h2>
<p><span class="koboSpan" id="kobo.624.1">MNAS is the searching method that was</span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.625.1"> used to create the CNN architecture called </span><strong class="bold"><span class="koboSpan" id="kobo.626.1">MnasNet</span></strong><span class="koboSpan" id="kobo.627.1">, which is a CNN-based architecture. </span><span class="koboSpan" id="kobo.627.2">MNAS was later utilized to build the EfficientNet architecture family introduced in </span><a href="B18187_03.xhtml#_idTextAnchor051"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.628.1">Chapter 3</span></em></span></a><span class="koboSpan" id="kobo.629.1">, </span><em class="italic"><span class="koboSpan" id="kobo.630.1">Understanding Convolutional Neural Networks</span></em><span class="koboSpan" id="kobo.631.1">. </span><span class="koboSpan" id="kobo.631.2">However, the method can still be used to generate other architecture types such as RNN or MLP. </span><span class="koboSpan" id="kobo.631.3">MNAS’s main goal is to account for the latency component, which is the main</span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.632.1"> concern for architectures meant to be run at the edge, or in mobile devices, as the name suggests. </span><span class="koboSpan" id="kobo.632.2">MNAS extends the RL NAS-based concept and introduces a search space that is more flexible than the microarchitecture search in ENAS, allowing the creation of more varied layers at different blocks, albeit with a fixed macroarchitecture. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.633.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.634.1">.11</span></em><span class="koboSpan" id="kobo.635.1"> shows an MNAS fixed macroarchitecture layout with seven blocks while allowing different types of configurations with different layers in each block. </span><span class="koboSpan" id="kobo.635.2">The seven-block structure is adapted from the </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">MobileNetV2 architecture:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer085">
<span class="koboSpan" id="kobo.637.1"><img alt="Figure 7.11 – Example of a fixed macroarchitecture of seven blocks along with the configurations for each block that will be randomly sampled or predicted" src="image/B18187_07_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.638.1">Figure 7.11 – Example of a fixed macroarchitecture of seven blocks along with the configurations for each block that will be randomly sampled or predicted</span></p>
<p><span class="koboSpan" id="kobo.639.1">An RNN is used here as the controller network to predict the following configurations for each </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">CNN block:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.641.1">Convolutional operation</span></strong><span class="koboSpan" id="kobo.642.1">: Standard Convolutional layer, depthwise convolutional layer, and the MBConv layer </span><span class="No-Break"><span class="koboSpan" id="kobo.643.1">from MobileNet.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.644.1">Convolutional filter size</span></strong><span class="koboSpan" id="kobo.645.1">: 3x3 </span><span class="No-Break"><span class="koboSpan" id="kobo.646.1">and 5x5.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.647.1">Squeeze-and-excitation ratio</span></strong><span class="koboSpan" id="kobo.648.1">: </span><span class="No-Break"><span class="koboSpan" id="kobo.649.1">0, 0.25.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.650.1">Skip connection operation</span></strong><span class="koboSpan" id="kobo.651.1">: Pooling, identity residual, or no </span><span class="No-Break"><span class="koboSpan" id="kobo.652.1">skip connection.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.653.1">The number of layers per block</span></strong><span class="koboSpan" id="kobo.654.1">: 0, +1, -1. </span><span class="koboSpan" id="kobo.654.2">This is structured to be in reference to the number of layers in the same block numbers </span><span class="No-Break"><span class="koboSpan" id="kobo.655.1">in MobileNetV2.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.656.1">Output filter size per layer</span></strong><span class="koboSpan" id="kobo.657.1">: 0.75, 1.0, 1.25. </span><span class="koboSpan" id="kobo.657.2">This is also structured to be in reference to the filter size of the convolution layer at the same positions </span><span class="No-Break"><span class="koboSpan" id="kobo.658.1">in MobileNetV2.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.659.1">The search space introduced is crucial to allow for a more efficient network and higher capacity to achieve better metric performance. </span><span class="koboSpan" id="kobo.659.2">In CNN, for example, a lot of the computation is dominated at the earlier layers as the feature sizes are much larger and require more efficient layers compared to </span><span class="No-Break"><span class="koboSpan" id="kobo.660.1">later layers.</span></span></p>
<p><span class="koboSpan" id="kobo.661.1">A big issue about latency is that it is a component that is dependent on both the software and </span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.662.1">hardware environment. </span><span class="koboSpan" id="kobo.662.2">For example, let’s say architecture </span><em class="italic"><span class="koboSpan" id="kobo.663.1">A</span></em><span class="koboSpan" id="kobo.664.1"> is faster than architecture </span><em class="italic"><span class="koboSpan" id="kobo.665.1">B</span></em><span class="koboSpan" id="kobo.666.1"> in hardware and software </span><em class="italic"><span class="koboSpan" id="kobo.667.1">C</span></em><span class="koboSpan" id="kobo.668.1">. </span><span class="koboSpan" id="kobo.668.2">When tested on another hardware and </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.669.1">software </span><em class="italic"><span class="koboSpan" id="kobo.670.1">D</span></em><span class="koboSpan" id="kobo.671.1">, it is possible for architecture </span><em class="italic"><span class="koboSpan" id="kobo.672.1">B</span></em><span class="koboSpan" id="kobo.673.1"> to be faster than architecture </span><em class="italic"><span class="koboSpan" id="kobo.674.1">A</span></em><span class="koboSpan" id="kobo.675.1">. </span><span class="koboSpan" id="kobo.675.2">Additionally, the number of parameters and </span><strong class="bold"><span class="koboSpan" id="kobo.676.1">floating-point operations per second</span></strong><span class="koboSpan" id="kobo.677.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.678.1">FLOPs</span></strong><span class="koboSpan" id="kobo.679.1">) specification</span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.680.1"> of the architecture is also a proxy to the actual latency that depends also on the degree of parallelism of the architecture and the computational cores of the hardware. </span><span class="koboSpan" id="kobo.680.2">Based on these reasons, MobileNet adds the latency component to the reward computation by evaluating it objectively in the software and hardware environment of a mobile phone, combining both the metric computation and latency. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.681.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.682.1">.12</span></em><span class="koboSpan" id="kobo.683.1"> shows an overview of the entire </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">MNAS process:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer086">
<span class="koboSpan" id="kobo.685.1"><img alt="Figure 7.12 – Overview of MNAS, a platform-aware NAS with a latency guarantee" src="image/B18187_07_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.686.1">Figure 7.12 – Overview of MNAS, a platform-aware NAS with a latency guarantee</span></p>
<p><span class="koboSpan" id="kobo.687.1">Latency can be computed on the actual target software and hardware environment and is not restricted to just using mobile phones. </span><span class="koboSpan" id="kobo.687.2">The reward is computed using the formula with the capability to input the desired target latency </span><span class="No-Break"><span class="koboSpan" id="kobo.688.1">in seconds:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.689.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.690.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.691.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.692.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.693.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.694.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.695.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.696.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.697.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.698.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.699.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.700.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.701.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.702.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.703.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.704.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.705.1">[</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.706.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.707.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.708.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.709.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.710.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.711.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.712.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.713.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.714.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.715.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.716.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.717.1">t</span></span><span class="_-----MathTools-_Math_Function_v-normal"><span class="koboSpan" id="kobo.718.1">arg</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.719.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.720.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.721.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.722.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.723.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.724.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.725.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.726.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.727.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.728.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.729.1">]</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.730.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.731.1">w</span></span></p>
<p><span class="koboSpan" id="kobo.732.1">Another key detail about MnasNet is that another policy gradient method called </span><strong class="bold"><span class="koboSpan" id="kobo.733.1">proximal policy optimization</span></strong><span class="koboSpan" id="kobo.734.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.735.1">PPO</span></strong><span class="koboSpan" id="kobo.736.1">) by </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.737.1">OpenAI was used to train the RNN policy network instead of the reinforce method. </span><span class="koboSpan" id="kobo.737.2">PPO is a method that accomplishes two things over the standard reinforcement policy </span><span class="No-Break"><span class="koboSpan" id="kobo.738.1">gradient, namely:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.739.1">Make smaller gradient </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.740.1">updates to the policy so that the policy learns in a stabler way and is thus capable of achieving more </span><span class="No-Break"><span class="koboSpan" id="kobo.741.1">efficient convergence</span></span></li>
<li><span class="koboSpan" id="kobo.742.1">Use the generated probabilities themselves as sampling probabilities for the random sample generation that automatically balances exploration </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">and exploitation</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.744.1">The first point is achieved by </span><span class="No-Break"><span class="koboSpan" id="kobo.745.1">two</span></span><span class="No-Break"><a id="_idIndexMarker543"/></span><span class="No-Break"><span class="koboSpan" id="kobo.746.1"> means:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.747.1">Weighing the loss using the probabilities of the current actor network with the old probabilities generated from the actor-network before a </span><span class="No-Break"><span class="koboSpan" id="kobo.748.1">parameter update</span></span></li>
<li><span class="koboSpan" id="kobo.749.1">Clipping the probabilities in an interval [1 - </span><span class="_-----MathTools-_Math_Symbol_Extended"><span class="koboSpan" id="kobo.750.1">ϵ</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.751.1">, 1 + </span><span class="_-----MathTools-_Math_Symbol_Extended"><span class="koboSpan" id="kobo.752.1">ϵ</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.753.1">], where </span><span class="_-----MathTools-_Math_Symbol_Extended"><span class="koboSpan" id="kobo.754.1">ϵ</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.755.1">can be varied but the value of 0.2 </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">was used</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.757.1">The method is performed through two networks instead of one, called actor-network and critic network. </span><span class="koboSpan" id="kobo.757.2">The critic network is structured to predict an unconstrained single value that serves as part of the evaluation logic of the generated architecture, along with the reward from measuring the metric performance. </span><span class="koboSpan" id="kobo.757.3">The actor-network, on the other hand, is the network we know is the main network responsible for generating ideal network architecture configurations. </span><span class="koboSpan" id="kobo.757.4">Both networks can be implemented with RNNs. </span><span class="koboSpan" id="kobo.757.5">This is depicted well in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.758.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.759.1">.12</span></em><span class="koboSpan" id="kobo.760.1">. </span><span class="koboSpan" id="kobo.760.2">The two network parameters are jointly updated per batch. </span><span class="koboSpan" id="kobo.760.3">The loss of the actor-network can be computed with the </span><span class="No-Break"><span class="koboSpan" id="kobo.761.1">following formula:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.762.1">L</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.763.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.764.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.765.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.766.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.767.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.768.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.769.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.770.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.771.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.772.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.773.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.774.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.775.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.776.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.777.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.778.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.779.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.780.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.781.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.782.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.783.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.784.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.785.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.786.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.787.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.788.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.789.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.790.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.791.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.792.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.793.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.794.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.795.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.796.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.797.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.798.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.799.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.800.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.801.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.802.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.803.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.804.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.805.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.806.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.807.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.808.1">   </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.809.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.810.1">____________________________</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.811.1">   </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.812.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.813.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.814.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.815.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.816.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.817.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.818.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.819.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.820.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.821.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.822.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.823.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.824.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.825.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.826.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.827.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.828.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.829.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.830.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.831.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.832.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.833.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.834.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.835.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.836.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.837.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.838.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.839.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.840.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.841.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.842.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.843.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.844.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.845.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.846.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.847.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.848.1"> </span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.849.1">x</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.850.1">A</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.851.1">d</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.852.1">v</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.853.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.854.1">n</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.855.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.856.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.857.1">g</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.858.1">e</span></span></span></p>
<p><span class="koboSpan" id="kobo.859.1">A minimum of this loss and another version of the loss with clipped probabilities will then be used as the final loss. </span><span class="koboSpan" id="kobo.859.2">The clipped loss is defined </span><span class="No-Break"><span class="koboSpan" id="kobo.860.1">as follows:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.861.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.862.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.863.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.864.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.865.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.866.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.867.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.868.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.869.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.870.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.871.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.872.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.873.1">(</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.874.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.875.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.876.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.877.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.878.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.879.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.880.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.881.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.882.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.883.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.884.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.885.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.886.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.887.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.888.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.889.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.890.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.891.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.892.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.893.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.894.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.895.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.896.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.897.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.898.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.899.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.900.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.901.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.902.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.903.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.904.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.905.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.906.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.907.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.908.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.909.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.910.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.911.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.912.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.913.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.914.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.915.1">   </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.916.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.917.1">____________________________</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.918.1">   </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.919.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.920.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.921.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.922.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.923.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.924.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.925.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.926.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.927.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.928.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.929.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.930.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.931.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.932.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.933.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.934.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.935.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.936.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.937.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.938.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.939.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.940.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.941.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.942.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.943.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.944.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.945.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.946.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.947.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.948.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.949.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.950.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.951.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.952.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.953.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.954.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.955.1"> </span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.956.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.957.1">1</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.958.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_Extended"><span class="koboSpan" id="kobo.959.1">ϵ</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.960.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.961.1">1</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.962.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_Extended"><span class="koboSpan" id="kobo.963.1">ϵ</span></span><span class="_-----MathTools-_Math_Symbol_Extended"><span class="koboSpan" id="kobo.964.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.965.1">x</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.966.1">A</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.967.1">d</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.968.1">v</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.969.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.970.1">n</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.971.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.972.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.973.1">g</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.974.1">e</span></span></span></p>
<p><span class="koboSpan" id="kobo.975.1">The advantage here is a custom loss logic that provides a quantified evaluation number of the sampled child architecture that uses both the reward (using metric performance) and the single value predicted from the critic network. </span><span class="koboSpan" id="kobo.975.2">In the reinforce method, the </span><strong class="bold"><span class="koboSpan" id="kobo.976.1">exponential moving average</span></strong><span class="koboSpan" id="kobo.977.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.978.1">EMA</span></strong><span class="koboSpan" id="kobo.979.1">) of previous</span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.980.1"> rewards was used. </span><span class="koboSpan" id="kobo.980.2">Similarly, here, a form of the EMA is used to reduce the advantage at different timesteps. </span><span class="koboSpan" id="kobo.980.3">The logic is slightly more scientific, but for</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.981.1"> those who would like to know more, it can be computed using the </span><span class="No-Break"><span class="koboSpan" id="kobo.982.1">following formula:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.983.1">A</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.984.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.985.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.986.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.987.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.988.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.989.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.990.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.991.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.992.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.993.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.994.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.995.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.996.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.997.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.998.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.999.1">n</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1000.1">t</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1001.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1002.1">D</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1003.1">I</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1004.1">S</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1005.1">T</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1006.1">A</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1007.1">N</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1008.1">C</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1009.1">E</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1010.1">F</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1011.1">R</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1012.1">O</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1013.1">M</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1014.1">F</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1015.1">I</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1016.1">R</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1017.1">S</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1018.1">T</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1019.1">T</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1020.1">I</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1021.1">M</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1022.1">E</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1023.1">S</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1024.1">T</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1025.1">E</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1026.1">P</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1027.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1028.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1029.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1030.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1031.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1032.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1033.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1034.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1035.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1036.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1037.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1038.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1039.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1040.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1041.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1042.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1043.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1044.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1045.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1046.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1047.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1048.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1049.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1050.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1051.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1052.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1053.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1054.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1055.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1056.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1057.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1058.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1059.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1060.1">t</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1061.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1062.1">λ</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1063.1">γ</span></span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1064.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1065.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1066.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1067.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1068.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1069.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1070.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1071.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1072.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1073.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1074.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1075.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1076.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1077.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1078.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1079.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1080.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1081.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1082.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1083.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1084.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1085.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1086.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1087.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1088.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1089.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.1090.1">(</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1091.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1092.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1093.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1094.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1095.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1096.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1097.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1098.1">γ</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1099.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1100.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1101.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1102.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1103.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1104.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1105.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1106.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1107.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1108.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1109.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1110.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1111.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1112.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1113.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1114.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1115.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1116.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1117.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1118.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1119.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1120.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1121.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1122.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1123.1">t</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1124.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1125.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1126.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1127.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1128.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1129.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1130.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1131.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1132.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1133.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1134.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1135.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1136.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1137.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1138.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1139.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1140.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1141.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1142.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1143.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1144.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1145.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1146.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1147.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1148.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1149.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1150.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1151.1">t</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.1152.1">)</span></span></p>
<p><span class="koboSpan" id="kobo.1153.1">The lambda, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1154.1">λ</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.1155.1">, and gamma, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1156.1">γ</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1157.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="koboSpan" id="kobo.1158.1">are constants with values between 0 and 1. </span><span class="koboSpan" id="kobo.1158.2">They each control the level of weight </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.1159.1">decay of the discount of advantages at each timestep moving forward. </span><span class="koboSpan" id="kobo.1159.2">Additionally, the gamma also controls the contribution of predicted critic values at future timesteps. </span><span class="koboSpan" id="kobo.1159.3">As for the loss of the critic network, it can be defined using the </span><span class="No-Break"><span class="koboSpan" id="kobo.1160.1">following formula:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1161.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1162.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1163.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1164.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1165.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1166.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1167.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1168.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1169.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1170.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1171.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1172.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1173.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1174.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1175.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1176.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1177.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1178.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1179.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1180.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1181.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1182.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1183.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1184.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1185.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1186.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1187.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1188.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1189.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1190.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1191.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1192.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1193.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1194.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1195.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1196.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1197.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1198.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1199.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1200.1">s</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1201.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1202.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1203.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1204.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1205.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1206.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1207.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1208.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1209.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1210.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1211.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1212.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1213.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1214.1">c</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1215.1">v</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1216.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1217.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1218.1">u</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1219.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1220.1">)</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1221.1"> </span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1222.1">2</span></span></span></p>
<p><span class="koboSpan" id="kobo.1223.1">The final total loss will be the summation of the critic loss and the actor loss. </span><span class="koboSpan" id="kobo.1223.2">PPO generally performs better than the vanilla reinforcement policy gradient in efficiency and convergence. </span><span class="koboSpan" id="kobo.1223.3">This sums up the PPO logic at a more </span><span class="No-Break"><span class="koboSpan" id="kobo.1224.1">intuitive level.</span></span></p>
<p><span class="koboSpan" id="kobo.1225.1">The RL search space here is not efficient and takes approximately 4.5 days to train on ImageNet directly with a whopping 64 TPUv2 devices. </span><span class="koboSpan" id="kobo.1225.2">However, this resulted in a child architecture called MnasNet that is more efficient than MobileNetV2 at the same accuracy, or more accurate than MobileNetV2 at the same latency when benchmarked on ImageNet. </span><span class="koboSpan" id="kobo.1225.3">The same MNAS methods eventually got adopted in EfficientNet, which has become one of the most efficient CNN model </span><span class="No-Break"><span class="koboSpan" id="kobo.1226.1">families today.</span></span></p>
<h2 id="_idParaDest-118"><a id="_idTextAnchor119"/><span class="koboSpan" id="kobo.1227.1">Summarizing NAS with RL methods</span></h2>
<p><span class="koboSpan" id="kobo.1228.1">RL allows a way for us to smartly learn the most performant NN architectures through sampling, training, and evaluation of neural architectures and apply the experience learned by predictively generating the most efficient neural architecture configurations. </span><span class="koboSpan" id="kobo.1228.2">Simply said, NAS with RL trains an NN</span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.1229.1"> to generate the best NN </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.1230.1">architecture! </span><span class="koboSpan" id="kobo.1230.2">The biggest problem with NAS with RL is still the expensive compute time needed. </span><span class="koboSpan" id="kobo.1230.3">A few tricks carried out by different methods to try to circumvent this issue are </span><span class="No-Break"><span class="koboSpan" id="kobo.1231.1">listed here:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1232.1">Training NAS with RL on a smaller but still representative dataset as a proxy task and training and evaluating the final obtained neural architecture on the main </span><span class="No-Break"><span class="koboSpan" id="kobo.1233.1">larger dataset</span></span></li>
<li><span class="koboSpan" id="kobo.1234.1">Parameter sharing by the unique layer number and computation type can, fortunately, be generically adapted for other methods </span><span class="No-Break"><span class="koboSpan" id="kobo.1235.1">from ENAS</span></span></li>
<li><span class="koboSpan" id="kobo.1236.1">Balancing the macroarchitecture and microarchitecture search flexibility to reduce the search space while making sure it is flexible enough to take advantage of key differences needed at different stages of a network to achieve efficiency and good </span><span class="No-Break"><span class="koboSpan" id="kobo.1237.1">metric performance</span></span></li>
<li><span class="koboSpan" id="kobo.1238.1">Directly embedding target and achieved latency as part of the reward structure and as a result searching only mostly architectures around the </span><span class="No-Break"><span class="koboSpan" id="kobo.1239.1">specified latency</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1240.1">Do note that the methods that were introduced here do not provide an exhaustive overview of RL and </span><span class="No-Break"><span class="koboSpan" id="kobo.1241.1">its potential.</span></span></p>
<p><span class="koboSpan" id="kobo.1242.1">Although RL provides a </span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.1243.1">concrete way to accomplish NAS, it is not strictly necessary. </span><span class="koboSpan" id="kobo.1243.2">In the next section, we will go through examples of a category of NAS-specific methods that do not </span><span class="No-Break"><span class="koboSpan" id="kobo.1244.1">use RL.</span></span></p>
<h1 id="_idParaDest-119"><a id="_idTextAnchor120"/><span class="koboSpan" id="kobo.1245.1">Understanding non-RL-based NAS</span></h1>
<p><span class="koboSpan" id="kobo.1246.1">The core of NAS is about intelligently searching through different child architecture configurations by making decisions based on prior search experience to find the best child architecture in a non-random and non-brute-force way. </span><span class="koboSpan" id="kobo.1246.2">The core of RL, on the other hand, involves utilizing a </span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.1247.1">controller-based system to achieve that intelligence. </span><span class="koboSpan" id="kobo.1247.2">Intelligent NAS can be achieved without using RL, and in this section, we will go through a simplified version of the progressive growing-from-scratch style of NAS without a controller and another competitive version of elimination from a complex fully defined NN macroarchitecture </span><span class="No-Break"><span class="koboSpan" id="kobo.1248.1">and microarchitecture.</span></span></p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor121"/><span class="koboSpan" id="kobo.1249.1">Understanding path elimination-based NAS</span></h2>
<p><span class="koboSpan" id="kobo.1250.1">First and foremost, </span><strong class="bold"><span class="koboSpan" id="kobo.1251.1">differentiable architecture search</span></strong><span class="koboSpan" id="kobo.1252.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1253.1">DARTS</span></strong><span class="koboSpan" id="kobo.1254.1">) is a method that extends the DAG search space defined in ENAS by removing the RL controller component. </span><span class="koboSpan" id="kobo.1254.2">Instead of</span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.1255.1"> choosing previous nodes to connect to and choosing which operation to use for a node, all</span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.1256.1"> operations are included in a big overparameterized architecture through the same DAG system during training. </span><span class="koboSpan" id="kobo.1256.2">A learnable weight vector with a size of the total number</span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.1257.1"> of operations is used to perform a weighted addition of all operations during training between nodes. </span><span class="koboSpan" id="kobo.1257.2">This weight vector is applied with a </span><strong class="source-inline"><span class="koboSpan" id="kobo.1258.1">softmax</span></strong><span class="koboSpan" id="kobo.1259.1"> activation before the weighted addition process. </span><span class="koboSpan" id="kobo.1259.2">During testing, the top </span><em class="italic"><span class="koboSpan" id="kobo.1260.1">k</span></em><span class="koboSpan" id="kobo.1261.1"> paths or operations between nodes are chosen to act as the actual network, whereas the other paths are pruned away. </span><span class="koboSpan" id="kobo.1261.2">When the weight vector gets updated, however, the child architecture essentially changes. </span><span class="koboSpan" id="kobo.1261.3">Instead of training and evaluating this new child architecture to obtain the new metric performance on the holdout or validation partition of the dataset, only a single training epoch is used for the entire architecture to obtain an estimate of the best validation performance using the training loss. </span><span class="koboSpan" id="kobo.1261.4">This estimate will be used to update the parameters of the overparameterized architecture through </span><span class="No-Break"><span class="koboSpan" id="kobo.1262.1">gradient descent.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.1263.1">Proxyless NAS</span></strong><span class="koboSpan" id="kobo.1264.1">, in turn, extends </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.1265.1">upon the DARTS algorithm with a few additions. </span><span class="koboSpan" id="kobo.1265.2">The first addition is adding a layer that uses binarized weights to represent the weight vector called </span><strong class="source-inline"><span class="koboSpan" id="kobo.1266.1">BinaryConnect</span></strong><span class="koboSpan" id="kobo.1267.1">. </span><span class="koboSpan" id="kobo.1267.2">These binarized weights act as gates that allow data to travel through only when it is enabled. </span><span class="koboSpan" id="kobo.1267.3">This addition helps to alleviate the biggest issue with any overparameterized architectures: the GPU memory size needed to hold the parameters of the defined architecture. </span><span class="koboSpan" id="kobo.1267.4">The second addition is the latency component to the overall loss component, which is crucial to make sure the search takes latency into consideration and doesn’t attempt to utilize more paths just to get better metric performance. </span><span class="koboSpan" id="kobo.1267.5">Let’s uncover the details step by step by first describing the overall training method</span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.1268.1"> used in </span><span class="No-Break"><span class="koboSpan" id="kobo.1269.1">proxyless NAS:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1270.1">Train only the BinaryConnect weight vector based on a single randomly sampled path for each node based on the probabilities specified by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1271.1">softmax</span></strong><span class="koboSpan" id="kobo.1272.1"> conditioned weight vector using the training dataset loss. </span><span class="koboSpan" id="kobo.1272.2">This is achieved by freezing the parameters of the rest of the architecture and using standard </span><span class="No-Break"><span class="koboSpan" id="kobo.1273.1">cross-entropy loss.</span></span></li>
<li><span class="koboSpan" id="kobo.1274.1">Train only the architecture parameters based on two randomly sampled paths for each based on the probabilities specified by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1275.1">softmax</span></strong><span class="koboSpan" id="kobo.1276.1"> conditioned weight vector using the validation dataset loss. </span><span class="koboSpan" id="kobo.1276.2">This is achieved by freezing the parameters of the</span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.1277.1"> weight vector and using an approximate gradient formula for the </span><span class="No-Break"><span class="koboSpan" id="kobo.1278.1">architecture parameters:</span></span><p class="list-inset"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1279.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1280.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1281.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1282.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1283.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1284.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1285.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1286.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1287.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1288.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1289.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1290.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1291.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1292.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1293.1">m</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1294.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1295.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1296.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1297.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1298.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1299.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1300.1">h</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1301.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1302.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1303.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1304.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1305.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1306.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1307.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1308.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1309.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1310.1">1</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1311.1">=</span></span> <span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1312.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1313.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1314.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1315.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1316.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1317.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1318.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1319.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1320.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1321.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1322.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1323.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1324.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1325.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1326.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1327.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1328.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1329.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1330.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1331.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1332.1">h</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1333.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1334.1">2</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1335.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1336.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1337.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1338.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1339.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1340.1">2</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1341.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1342.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1343.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1344.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1345.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1346.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1347.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1348.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1349.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1350.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1351.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1352.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1353.1">(</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1354.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1355.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1356.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1357.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1358.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1359.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1360.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1361.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1362.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1363.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1364.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1365.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1366.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1367.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1368.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1369.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1370.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1371.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1372.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1373.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1374.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1375.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1376.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1377.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1378.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1379.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1380.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1381.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1382.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1383.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1384.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1385.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1386.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1387.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1388.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1389.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1390.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1391.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1392.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1393.1">h</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1394.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1395.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1396.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1397.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1398.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1399.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1400.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1401.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1402.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1403.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1404.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1405.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1406.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1407.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1408.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1409.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1410.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1411.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1412.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1413.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1414.1">(</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1415.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1416.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1417.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1418.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1419.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1420.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1421.1">2</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1422.1">p</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1423.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1424.1">o</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1425.1">b</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1426.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1427.1">b</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1428.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1429.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1430.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1431.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1432.1">y</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1433.1">)</span></span></span></p><p class="list-inset"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1434.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1435.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1436.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1437.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1438.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1439.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1440.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1441.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1442.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1443.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1444.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1445.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1446.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1447.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1448.1">m</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1449.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1450.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1451.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1452.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1453.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1454.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1455.1">h</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1456.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1457.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1458.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1459.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1460.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1461.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1462.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1463.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1464.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1465.1">2</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1466.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1467.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1468.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1469.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1470.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1471.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1472.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1473.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1474.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1475.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1476.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1477.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1478.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1479.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1480.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1481.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1482.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1483.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1484.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1485.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1486.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1487.1">h</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1488.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1489.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1490.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1491.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1492.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1493.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1494.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1495.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1496.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1497.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1498.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1499.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1500.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1501.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1502.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1503.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1504.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1505.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1506.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1507.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1508.1">(</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1509.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1510.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1511.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1512.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1513.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1514.1">2</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1515.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1516.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1517.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1518.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1519.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1520.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1521.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1522.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1523.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1524.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1525.1">y</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1526.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1527.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1528.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1529.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1530.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1531.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1532.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1533.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1534.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1535.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1536.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1537.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1538.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1539.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1540.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1541.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1542.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1543.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1544.1">w</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1545.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1546.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1547.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1548.1">h</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1549.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1550.1">2</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1551.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1552.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1553.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1554.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1555.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1556.1">2</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1557.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1558.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1559.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1560.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1561.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1562.1">b</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1563.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1564.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1565.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1566.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1567.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1568.1">x</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1569.1">(</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1570.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1571.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1572.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1573.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1574.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1575.1">h</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1576.1">1</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1577.1">p</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1578.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1579.1">o</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1580.1">b</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1581.1">a</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1582.1">b</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1583.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1584.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1585.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1586.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1587.1">y</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1588.1">)</span></span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.1589.1">The formula computes gradients for path 1 and path 2. </span><span class="koboSpan" id="kobo.1589.2">The loss used is cross-entropy loss summed with a predicted latency after pruning the paths similar to DARTS. </span><span class="koboSpan" id="kobo.1589.3">The latency is predicted with an external ML model trained to predict latency based on the parameters of the architecture due to the reason that latency evaluations take up too much time and usually require an average of multiple runs to get a reliable estimate. </span><span class="koboSpan" id="kobo.1589.4">Any ML model can be used to build the latency predictor </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.1590.1">model and is a one-off process before starting the </span><span class="No-Break"><span class="koboSpan" id="kobo.1591.1">NAS process.</span></span></p></li>
<li><span class="koboSpan" id="kobo.1592.1">Repeat </span><em class="italic"><span class="koboSpan" id="kobo.1593.1">steps 1-2</span></em><span class="koboSpan" id="kobo.1594.1"> until convergence, a predefined number of epochs, or any early stopping without improvements on the validation loss for a predefined number </span><span class="No-Break"><span class="koboSpan" id="kobo.1595.1">of epochs.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.1596.1">Recall that BinaryConnect is used to achieve binary weights that act as gates. </span><span class="koboSpan" id="kobo.1596.2">One detail is that the standard unconstrained non-binary weight vector itself is still present but a binarization operation is applied. </span><span class="koboSpan" id="kobo.1596.3">The binarization process is executed by the </span><span class="No-Break"><span class="koboSpan" id="kobo.1597.1">following steps:</span></span></p><ol><li class="upper-roman"><span class="koboSpan" id="kobo.1598.1">Set all binary weights </span><span class="No-Break"><span class="koboSpan" id="kobo.1599.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1600.1">0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1601.1">.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.1602.1">Sample the desired number of chosen paths by using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1603.1">softmax</span></strong><span class="koboSpan" id="kobo.1604.1"> conditioned weight vector </span><span class="No-Break"><span class="koboSpan" id="kobo.1605.1">as probabilities.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.1606.1">Set the chosen path’s binary weights </span><span class="No-Break"><span class="koboSpan" id="kobo.1607.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1608.1">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1609.1">.</span></span></li></ol></li>
<li><span class="koboSpan" id="kobo.1610.1">BinaryConnect saves memory by only loading nonzero paths </span><span class="No-Break"><span class="koboSpan" id="kobo.1611.1">to memory.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.1612.1">PNAS manages to achieve an 85.1 top-1 accuracy on ImageNet directly without using a proxy dataset such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.1613.1">CIFAR-10</span></strong><span class="koboSpan" id="kobo.1614.1">, using</span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.1615.1"> only 8.3 days of search using the NVIDIA GTX 1080 </span><span class="No-Break"><span class="koboSpan" id="kobo.1616.1">Ti GPU.</span></span></p>
<p><span class="koboSpan" id="kobo.1617.1">Next, we will go through a simple progressive growth-based NAS method as </span><span class="No-Break"><span class="koboSpan" id="kobo.1618.1">an introduction.</span></span></p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor122"/><span class="koboSpan" id="kobo.1619.1">Understanding progressive growth-based NAS</span></h2>
<p><span class="koboSpan" id="kobo.1620.1">The progressive growth-based NAS method’s key differentiator is that the method can be structured to be unbounded in</span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.1621.1"> both macroarchitecture and microarchitecture. </span><span class="koboSpan" id="kobo.1621.2">Most of the techniques introduced in this chapter have placed a lot</span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.1622.1"> of domain knowledge in terms of general structures found to be useful. </span><span class="koboSpan" id="kobo.1622.2">Growth-based NAS is naturally non-finite in terms of search space and can potentially help to discover novel macroarchitectural structures that work well. </span><span class="koboSpan" id="kobo.1622.3">This line of NAS will continue to evolve to a stage where it can be competitive with other NAS methods, but, in </span><a id="_idIndexMarker561"/><span class="koboSpan" id="kobo.1623.1">this book, we will only go into a method to search the microarchitectural structure of the child architecture called </span><strong class="bold"><span class="koboSpan" id="kobo.1624.1">progressive NAS</span></strong><span class="koboSpan" id="kobo.1625.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1626.1">PNAS</span></strong><span class="koboSpan" id="kobo.1627.1">) to act as </span><span class="No-Break"><span class="koboSpan" id="kobo.1628.1">an introduction.</span></span></p>
<p><span class="koboSpan" id="kobo.1629.1">PNAS adopts a progressive growth-based approach in NAS by simply using concepts defined in Bayesian optimization introduced earlier in this chapter and searching at the microarchitecture level while fixing the macroarchitecture structure similar to the ENAS microarchitecture search method. </span><span class="koboSpan" id="kobo.1629.2">The macroarchitecture structure is adapted to the size of the dataset, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1630.1">CIFAR-10</span></strong><span class="koboSpan" id="kobo.1631.1">, with</span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.1632.1"> a smaller structure, and ImageNet with a deeper structure. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1633.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.1634.1">.13</span></em><span class="koboSpan" id="kobo.1635.1"> shows </span><span class="No-Break"><span class="koboSpan" id="kobo.1636.1">these structures:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer087">
<span class="koboSpan" id="kobo.1637.1"><img alt="Figure 7.13 – PNAS macroarchitecture structure from the https://arxiv.org/abs/1712.00559v3 paper" src="image/B18187_07_013.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1638.1">Figure 7.13 – PNAS macroarchitecture structure from the https://arxiv.org/abs/1712.00559v3 paper</span></p>
<p><span class="koboSpan" id="kobo.1639.1">The method can be accomplished with the steps defined next, along with an initial predefined max number of </span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.1640.1">blocks in the cell and starting </span><a id="_idIndexMarker564"/><span class="koboSpan" id="kobo.1641.1">with zero blocks in </span><span class="No-Break"><span class="koboSpan" id="kobo.1642.1">the cell:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1643.1">Start with the first block. </span><span class="koboSpan" id="kobo.1643.2">Construct the full CNN with all cell options iteratively and evaluate all of </span><span class="No-Break"><span class="koboSpan" id="kobo.1644.1">the CNN.</span></span></li>
<li><span class="koboSpan" id="kobo.1645.1">Train an RNN surrogate model to predict the metric performance using the </span><span class="No-Break"><span class="koboSpan" id="kobo.1646.1">cell configurations.</span></span></li>
<li><span class="koboSpan" id="kobo.1647.1">Expand to the next block and predict the metric performance of the possible cell option combinations for the next block using all available chosen and evaluated previous </span><span class="No-Break"><span class="koboSpan" id="kobo.1648.1">block variations.</span></span></li>
<li><span class="koboSpan" id="kobo.1649.1">Take the top two best metric performance cell options for the next block and train and evaluate the fully constructed CNN using the two </span><span class="No-Break"><span class="koboSpan" id="kobo.1650.1">cell options.</span></span></li>
<li><span class="koboSpan" id="kobo.1651.1">Fine-tune the RNN surrogate model using the extra two data points obtained in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1652.1">step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1653.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.1654.1">Repeat </span><em class="italic"><span class="koboSpan" id="kobo.1655.1">step 3</span></em><span class="koboSpan" id="kobo.1656.1"> to </span><em class="italic"><span class="koboSpan" id="kobo.1657.1">step 5</span></em><span class="koboSpan" id="kobo.1658.1"> until the total number of blocks reaches the max number of blocks or until the</span><a id="_idIndexMarker565"/><span class="koboSpan" id="kobo.1659.1"> metric performance does not </span><span class="No-Break"><span class="koboSpan" id="kobo.1660.1">improve anymore.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.1661.1">Each block in a cell will have a configuration defined with five variables similar to ENAS; namely, the first input, the second input, the operation to the first input, the operation to the second input, and the</span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.1662.1"> method to combine the outputs of the operation to the first input and operation to the second input. </span><span class="koboSpan" id="kobo.1662.2">The set of possible inputs is all the previous blocks, the output of the previous cell, and the output of the cell before the previous cell. </span><span class="koboSpan" id="kobo.1662.3">This means that the cell can interact with other cells. </span><span class="koboSpan" id="kobo.1662.4">All the possible input combinations, operation types, and combination methods are laid out in each progressive block step and fed to the RNN model to predict the </span><span class="No-Break"><span class="koboSpan" id="kobo.1663.1">metric performance.</span></span></p>
<p><span class="koboSpan" id="kobo.1664.1">PNAS managed to achieve an 84.2 top-1 accuracy on ImageNet but utilized a whopping 225 GPU days using an NVIDIA GTX </span><span class="No-Break"><span class="koboSpan" id="kobo.1665.1">1080 GPU.</span></span></p>
<p><span class="koboSpan" id="kobo.1666.1">The progressive growth-based line of NAS methods has since progressed to the stage where it is possible to achieve an accuracy of 84 top-1 accuracy with only 5 days of searching with</span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.1667.1"> a method called </span><strong class="bold"><span class="koboSpan" id="kobo.1668.1">efficient forward architecture search</span></strong><span class="koboSpan" id="kobo.1669.1">, but this is beyond the scope of </span><span class="No-Break"><span class="koboSpan" id="kobo.1670.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.1671.1">To end this chapter, </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1672.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.1673.1">.14</span></em><span class="koboSpan" id="kobo.1674.1"> shows a summary performance comparison among the methods introduced for the image domain, excluding general hyperparameter </span><span class="No-Break"><span class="koboSpan" id="kobo.1675.1">search methods:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1676.1">Method</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.1677.1">Number of </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1678.1">params (million)</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.1679.1">Search </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1680.1">time (days)</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.1681.1">CIFAR-10 </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1682.1">test error</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.1683.1">ImageNet </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1684.1">test error</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.1685.1">Vanilla </span><span class="No-Break"><span class="koboSpan" id="kobo.1686.1">RL NAS</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1687.1">4.2</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1688.1">1680</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1689.1">4.47</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1690.1">N/A</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1691.1">ENAS macro</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1692.1">21.3</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1693.1">0.32</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1694.1">4.23</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1695.1">N/A</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1696.1">ENAS micro</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1697.1">4.6</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1698.1">0.45</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1699.1">2.89</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1700.1">N/A</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1701.1">DARTS</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1702.1">3.4</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.1703.1">4</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1704.1">2.83</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1705.1">26.9</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1706.1">Proxyless NAS</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1707.1">7.1</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1708.1">8.3</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1709.1">N/A</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1710.1">24.9</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1711.1">PNAS</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1712.1">5.1</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1713.1">225</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1714.1">3.41</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1715.1">25.8</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1716.1">Figure 7.14 – Performance comparison of all the introduced NAS methods, excluding general hyperparameter search methods</span></p>
<p><span class="koboSpan" id="kobo.1717.1">This table includes the number of parameters, search time, and test error rates for </span><strong class="source-inline"><span class="koboSpan" id="kobo.1718.1">CIFAR-10</span></strong><span class="koboSpan" id="kobo.1719.1"> and ImageNet datasets for each NAS method introduced. </span><span class="koboSpan" id="kobo.1719.2">Each NAS method has its own strengths and </span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.1720.1">weaknesses in terms of latency, complexity, and accuracy. </span><span class="koboSpan" id="kobo.1720.2">The ENAS micro method, in particular, stands out with a relatively low number of parameters, a short search time, and a low test error rate for </span><strong class="source-inline"><span class="koboSpan" id="kobo.1721.1">CIFAR-10</span></strong><span class="koboSpan" id="kobo.1722.1">. </span><span class="koboSpan" id="kobo.1722.2">It could be a recommended choice for neural architecture search in the image domain. </span><span class="koboSpan" id="kobo.1722.3">However, the specific choice depends on the requirements and constraints of the project, such as available</span><a id="_idTextAnchor123"/><span class="koboSpan" id="kobo.1723.1"> compute resources and </span><span class="No-Break"><span class="koboSpan" id="kobo.1724.1">desired accuracy.</span></span></p>
<h1 id="_idParaDest-122"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.1725.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1726.1">NAS is a method that is generalized to any NN type, allowing for the automation of creating new and advanced NNs without the need for manual neural architecture design. </span><span class="koboSpan" id="kobo.1726.2">As you may have guessed, NAS dominates the image-based field of NNs. </span><span class="koboSpan" id="kobo.1726.3">The EfficientNet model family exemplifies the impact NAS provides to the image-based NN field. </span><span class="koboSpan" id="kobo.1726.4">This is due to the inherent availability of a wide variety of CNN components that make it more complicated to design when compared to a simple MLP. </span><span class="koboSpan" id="kobo.1726.5">For sequential or time-series data handling, there are not many variations of RNN cells, and thus the bulk of work in NAS for RNNs is focused on designing a custom recurrent cell. </span><span class="koboSpan" id="kobo.1726.6">More work could have been done to accommodate transformers as it is the current state of the art, capable of being adapted to a variety of </span><span class="No-Break"><span class="koboSpan" id="kobo.1727.1">data modalities.</span></span></p>
<p><span class="koboSpan" id="kobo.1728.1">NAS is mainly adopted by researchers or practitioners in larger institutions. </span><span class="koboSpan" id="kobo.1728.2">One of the key traits practitioners want when trying to train better models for their use cases is the speed to the final result. </span><span class="koboSpan" id="kobo.1728.3">NAS by itself is still a process that takes days to accomplish, and if applied to a large dataset, it can take up to months. </span><span class="koboSpan" id="kobo.1728.4">This deters most practitioners’ usage of NAS directly. </span><span class="koboSpan" id="kobo.1728.5">Instead, they mostly use the existing architectures from published open source implementations. </span><span class="koboSpan" id="kobo.1728.6">Using the existing architectures makes no difference in speed when compared to using manually defined architecture and thus gives practitioners the motivation they need to use it instead. </span><span class="koboSpan" id="kobo.1728.7">It is also widely known that pre-training helps to improve the performance of the model, thus using NAS directly means you’d have to also pre-train the resulting architecture yourself on a large generalized dataset, which further extends the time needed to complete the NAS process. </span><span class="koboSpan" id="kobo.1728.8">Use cases in ML often require a lot of time to explore the problem setup and figure out the potential performance that is achievable from the available dataset. </span><span class="koboSpan" id="kobo.1728.9">Thus, quick iteration between model experimentations is crucial to the success of the project. </span><span class="koboSpan" id="kobo.1728.10">Slow experimentations dampen the time to identify success. </span><span class="koboSpan" id="kobo.1728.11">These reasons are why NAS is mainly adopted by practitioners in bigger institutions or researchers who are willing to spend time designing generalized custom neural architectures that can be amortized across different domains instead of building custom architectures for a specific </span><span class="No-Break"><span class="koboSpan" id="kobo.1729.1">use case.</span></span></p>
<p><span class="koboSpan" id="kobo.1730.1">However, NAS still undoubtedly provides a unique way to find unique custom architectures for your use cases as long as time is not of concern and the goal is either to maximize the performance you can get with a target latency or to generally get the best-performing model without </span><span class="No-Break"><span class="koboSpan" id="kobo.1731.1">latency considerations.</span></span></p>
<p><span class="koboSpan" id="kobo.1732.1">In the next chapter, we will go into the details of different problem types in SL, along with general tips and tricks for </span><strong class="bold"><span class="koboSpan" id="kobo.1733.1">supervised </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1734.1">DL</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1735.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1736.1">SDL</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1737.1">).</span></span></p>
</div>
</body></html>