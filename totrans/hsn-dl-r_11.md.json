["```py\nlibrary(OpenImageR)\n\nclock <- readImage(\"Alarms_&_Clock_icon.png\")\n\nclock[1:10,46:56,4]\n```", "```py\nlibrary(keras)\ngenerator_in <- layer_input(shape = c(100))  \n```", "```py\ngenerator_out <- generator_in %>%\n   layer_dense(units = 128 * 25 * 25) %>%\n   layer_reshape(target_shape = c(25, 25, 128))\n```", "```py\ngenerator_out <- generator_in %>%\n   layer_dense(units = 128 * 25 * 25) %>%\n   layer_reshape(target_shape = c(25, 25, 128)) %>%\n   layer_conv_2d(filters = 512, kernel_size = 5,\n                 padding = \"same\")\n```", "```py\ngenerator_out <- generator_in %>%\n   layer_dense(units = 128 * 25 * 25) %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_reshape(target_shape = c(25, 25, 128)) %>%\n   layer_conv_2d(filters = 512, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() \n```", "```py\ngenerator_out <- generator_in %>%\n   layer_dense(units = 128 * 25 * 25) %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_reshape(target_shape = c(25, 25, 128)) %>%\n   layer_conv_2d(filters = 512, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d_transpose(filters = 256, kernel_size = 4,\n                           strides = 2, padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 256, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 128, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 64, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu()\n```", "```py\ngenerator_out <- generator_in %>%\n   layer_dense(units = 128 * 25 * 25) %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_reshape(target_shape = c(25, 25, 128)) %>%\n   layer_conv_2d(filters = 512, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d_transpose(filters = 256, kernel_size = 4,\n                           strides = 2, padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 256, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 128, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 64, kernel_size = 5,\n                 padding = \"same\") %>%\n   layer_batch_normalization(momentum = 0.5) %>%\n   layer_activation_relu() %>%\n   layer_conv_2d(filters = 3, kernel_size = 7,\n                 activation = \"tanh\", padding = \"same\")\n```", "```py\ngenerator <- keras_model(generator_in, generator_out)\nsummary(generator)\n```", "```py\ndiscriminator_in <- layer_input(shape = c(50, 50, 3))  \n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3)\n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3) %>%\n   layer_activation_leaky_relu()\n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3) %>%\n   layer_activation_leaky_relu() %>%\n   layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) \n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3) %>%\n   layer_activation_leaky_relu() %>%\n   layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>%   \n   layer_activation_leaky_relu() %>%\n   layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>%\n   layer_activation_leaky_relu() %>%\n   layer_conv_2d(filters = 256, kernel_size = 3, strides = 2) %>%\n   layer_activation_leaky_relu()\n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3) %>%\n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>% \n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>%\n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 3, strides = 2) %>%\n layer_activation_leaky_relu() %>%\n layer_flatten()\n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3) %>%\n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>% \n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>%\n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 3, strides = 2) %>%\n layer_activation_leaky_relu() %>%\n layer_flatten() %>%\n   layer_dropout(rate = 0.5)\n```", "```py\ndiscriminator_out <- discriminator_in %>%\n   layer_conv_2d(filters = 256, kernel_size = 3) %>%\n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>% \n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 5, strides = 2) %>%\n layer_activation_leaky_relu() %>%\n layer_conv_2d(filters = 256, kernel_size = 3, strides = 2) %>%\n layer_activation_leaky_relu() %>%\n layer_flatten() %>%\n   layer_dropout(rate = 0.5) %>%     \n   layer_dense(units = 1, activation = \"sigmoid\")\n```", "```py\ndiscriminator <- keras_model(discriminator_in, discriminator_out)\nsummary(discriminator)\n```", "```py\ndiscriminator_optimizer <- optimizer_adam(\n   lr = 0.0008\n )\n discriminator %>% compile(\n   optimizer = discriminator_optimizer,\n   loss = \"binary_crossentropy\"\n )\n```", "```py\n library(jpeg)\n library(purrr)\n library(abind)\n library(OpenImageR)\n```", "```py\n setwd('data/faces')\n filename_vector = list.files(pattern=\"*.jpg\")\n image_list <- purrr::map(filename_vector, jpeg::readJPEG)\n```", "```py\nimage_list <- purrr::map(image_list, ~OpenImageR::resizeImage(., width=50, height=50, method = \"nearest\"))\n```", "```py\nimage_array <- abind::abind( image_list, along = 0)\ndim(image_array)\n```", "```py\nrm(image_list,filename_vector)\n\nsetwd('../..')\n```", "```py\nfreeze_weights(discriminator)\n```", "```py\ngan_in <- layer_input(shape = c(100))\ngan_out <- discriminator(generator(gan_in))\ngan <- keras_model(gan_in, gan_out)\n```", "```py\ngan_optimizer <- optimizer_adam(\n   lr = 0.0004\n )\n gan %>% compile(\n   optimizer = gan_optimizer,\n   loss = \"binary_crossentropy\"\n )\n```", "```py\nimage_directory <- \"gan_images\"\n dir.create(image_directory)\n```", "```py\nfirst_row <- 1\n```", "```py\nrandom_value_matrix <- matrix(rnorm(20 * 100),\n                                   nrow = 20, ncol = 100)\n```", "```py\nfake_images <- generator %>% predict(random_value_matrix)\nfake_images[1,1:5,1:5,1]\n```", "```py\nlast_row <- first_row + 19\n```", "```py\nreal_images <- image_array[first_row:last_row,,,]\n\nattr(real_images, \"dimnames\") <- NULL\nattr(image_array, \"dimnames\") <- NULL\n```", "```py\ncombined_images <- array(0, dim = c(nrow(real_images) * 2, 50,50,3))\n```", "```py\ncombined_images[1:nrow(real_images),,,] <- fake_images\ncombined_images[(nrow(real_images)+1):(nrow(real_images)*2),,,] <- real_images\n```", "```py\nlabels <- rbind(matrix(1, nrow = 20, ncol = 1),\n                matrix(0, nrow = 20, ncol = 1))\n```", "```py\nlabels <- labels + (0.1 * array(runif(prod(dim(labels))),\n                                 dim = dim(labels)))\n```", "```py\nd_loss <- discriminator %>% train_on_batch(combined_images, labels)\n\nd_loss\n```", "```py\n random_value_matrix <- matrix(rnorm(20 * 100),\n                               nrow = 20, ncol = 100)\n```", "```py\nfake_target_array <- array(0, dim = c(20, 1)) \n```", "```py\na_loss <- gan %>% train_on_batch(\n     random_value_matrix,\n     fake_target_array\n   )  \n\na_loss\n```", "```py\n  first_row <- first_row + 20\n   if (first_row  > (nrow(image_array) - 20))\n     first_row <- sample(1:10,1)\n\nfirst_row\n```", "```py\nif (i %% 100 == 0) {\n\n     cat(\"step:\", i, \"\\n\")\n     cat(\"discriminator loss:\", d_loss, \"\\n\")\n     cat(\"adversarial loss:\", a_loss, \"\\n\")  \n\n     image_array_save(\n       fake_images[1,,,] * 255,\n       path = file.path(image_directory, paste0(\"fake_gwb\", i, \".png\"))\n     )\n\n     image_array_save(\n       real_images[1,,,] * 255,\n       path = file.path(image_directory, paste0(\"real_gwb\", i, \".png\"))\n     )\n   }\n```"]