<html><head></head><body>
		<div id="_idContainer035">
			<h1 id="_idParaDest-29"><em class="italic"><a id="_idTextAnchor029"/>Chapter 2</em>: Getting Started with AutoKeras</h1>
			<p>In this chapter, we will go over everything you need to get started with <strong class="bold">AutoKeras</strong> and put it into practice with a foundational, well-explained code example. By the end of this chapter, you'll know how to create a simple classifier for handwritten digits from the well-known <strong class="bold">Modified National Institute of Standards and Technology</strong> (<strong class="bold">MNIST</strong>) dataset, in just a few lines of code. </p>
			<p>As we saw in the previous chapter, <strong class="bold">DL</strong> (<strong class="bold">DL</strong>) automation manages to speed up training time and benefit from allocating human resources (data scientists) in other pipeline processes that are less likely to be automated.</p>
			<p>To carry out this automation, we have chosen AutoKeras. This is a <strong class="bold">ML</strong> (<strong class="bold">ML</strong>) automation framework based on <strong class="bold">Keras</strong>, a widely known neural network library based on <strong class="bold">TensorFlow</strong>, which provides high-level building blocks for developing DL models.</p>
			<p>Next, we will see how to install AutoKeras and put it into action with a practical example, but let's first explain some relevant concepts, answering these questions: </p>
			<ul>
				<li>What is deep learning?</li>
				<li>What is a neural network and how does it learn?</li>
				<li>How do deep learning models learn?</li>
				<li>Why AutoKeras?</li>
				<li>Installing AutoKeras</li>
				<li>Hello MNIST: Implementing our first AutoKeras experiment</li>
			</ul>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor030"/>Technical requirements</h1>
			<p>All coding examples in this book are available as Jupyter Notebook/s that can be downloaded from the following website: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras">https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras</a>.</p>
			<p>Jupyter Notebook provides a Python-based environment where code can be developed as a sequence of steps, which are called cells. The notebook also provides flexibility to install libraries/dependencies on the go by executing Linux-based commands in the cells.</p>
			<p>So, to run the coding examples in this chapter, you only need a computer with Jupyter installed. For instance, in Ubuntu/Linux, you can install it with this line:</p>
			<p class="source-code">$ apt-get install python3-pip jupyter-notebook</p>
			<p>The previous command will install the Jupyter notebook package and all its dependencies.</p>
			<p>You can also take a look at the <em class="italic">Installing AutoKeras on an Ubuntu Linux workstation</em> section for more details.</p>
			<p>Alternatively, you can also run these notebooks using Google Colaboratory, in which case you will only need a web browser. See the <em class="italic">AutoKeras with Google Colaboratory</em> section for more details.</p>
			<h1 id="_idParaDest-31"><a id="_idTextAnchor031"/>What is deep learning?</h1>
			<p>DL is a subcategory <a id="_idIndexMarker079"/>of ML, based on extracting patterns from data by implementing successive layers that are responsible for extracting relevant features. These patterns are learned through ML models called neural networks (inspired by our brain neurons) and structured in layers stacked one on top of the other, but <a id="_idIndexMarker080"/>what is a layer? A layer is a set of nodes called <em class="italic">cells</em> that perform an operation by processing an input and generating an output. This kind of operation can be stateless but it usually has a <a id="_idIndexMarker081"/>state that is stored in an array of float numbers, called <em class="italic">weights</em>.</p>
			<p>Let's look at a multilayer-depth neural network recognizing a single-digit image, as follows:</p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B16953_02_01.jpg" alt="Figure 2.1 – Visual representation of the layers of a neural network for digit classification&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – Visual representation of the layers of a neural network for digit classification</p>
			<p>We can think of the network as<a id="_idIndexMarker082"/> a funnel with several filters, in which each layer is equivalent to a filter that reduces impurities until the desired value is obtained.</p>
			<p>DL has multiple applications in many<a id="_idIndexMarker083"/> fields such as computer vision, <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>), signal processing, and many others, so the techniques explained in this book can be applied to solve problems in multiple disciplines.</p>
			<p>We will now see a brief explanation of neural networks and how learning takes place.</p>
			<h1 id="_idParaDest-32"><a id="_idTextAnchor032"/>What is a neural network and how does it learn? </h1>
			<p>As we said previously, a neural<a id="_idIndexMarker084"/> network is a set of layers connected to each other. Each layer contains a set of nodes and each node has an associated weight. Neural network learning <a id="_idIndexMarker085"/>consists of simply modifying these weights in a suitable way so that the model makes good predictions. In the following diagram, we can see a simple two-layer network:</p>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B16953_02_02.jpg" alt="Figure 2.2 – Visual representation of a two-layer neural network"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – Visual representation of a two-layer neural network</p>
			<p>Each circle in the previous diagram is an artificial neuron, which is nothing more than a mathematical function<a id="_idIndexMarker086"/> inspired by the functioning of a biological neuron. These artificial neurons are the basic units in an artificial neural network and their operation consists of receiving one or more inputs (numerical values) and multiplying them by a factor or weight, and then adding the results to generate the output value.</p>
			<p>These models are simple <a id="_idIndexMarker087"/>but really powerful because from a set of data with defined inputs and outputs, they can learn to predict new data whose outputs we do not know. For example, if we train our neural network with house prices based on a series of input variables (square meters, location, and so on), the network could predict the price of new houses based on those variables.</p>
			<p>Having introduced the main concepts of DL models, let's now see how these models learn. </p>
			<h1 id="_idParaDest-33"><a id="_idTextAnchor033"/>How do deep learning models learn?</h1>
			<p>Let's look at a <a id="_idIndexMarker088"/>multilayer-depth neural network recognizing a single-digit image, as follows:</p>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B16953_02_03.jpg" alt="Figure 2.3 – Rendering of the layer content of a neural network for digit classification"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – Rendering of the layer content of a neural network for digit classification</p>
			<p>As you can see in the preceding diagram, the network extracts patterns from the digit image. In each layer, it obtains different representations, so each layer specializes in some specific features of the image, giving the necessary keys to identify the category to which it belongs.</p>
			<p>This is basically DL, a multistage technique of learning patterns from data. It's based on a very simple concept, but by tweaking it and scaling it high enough, you can make amazing predictions.</p>
			<p>Let's now see the reasons why AutoKeras is our <a id="_idIndexMarker089"/>preferred tool for <strong class="bold">automated ML</strong> (<strong class="bold">AutoML</strong>).</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor034"/>Why AutoKeras?</h1>
			<p>As we explained in the<a id="_idIndexMarker090"/> previous chapter, AutoKeras is an open source AutoML framework that allows a non-ML expert to create high-performance models in a simple way. There are similar tools with the same objective, but AutoKeras is specialized in DL. Although it is not the only solution, there are several AutoML services available; most <a id="_idIndexMarker091"/>are cloud computing platforms (Amazon, Google, <strong class="bold">International Business Machines</strong> (<strong class="bold">IBM</strong>)) and have some significant disadvantages, which are outlined here:</p>
			<ul>
				<li>Machine learning cloud platforms are expensive; you usually have a trial period with free credits, but if you want to use them regularly you will have to pay a bill every month. </li>
				<li>Depending on the cloud platform, some of them are not easy to configure and scale, which sometimes requires you to have knowledge of containers and clusters.</li>
				<li>They tend to offer simple to use but less flexible out-of-the-box solutions.</li>
			</ul>
			<p>As AutoKeras is based on an open source model, it solves these problems because you can view the<a id="_idIndexMarker092"/> source code, install it, and run it locally for free. </p>
			<p>AutoKeras is based on the following four main features that make it easy to install and use:</p>
			<ul>
				<li>It has a clear and intuitive <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) based on the Keras API. Users <a id="_idIndexMarker093"/>without programming experience can easily learn how to use it, but it also allows advanced users to adjust lower-level system parameters.</li>
				<li>It can work both locally and in the cloud.</li>
				<li>It is based on a dynamic configuration that adapts the size of the neural architecture in the <a id="_idIndexMarker094"/>function of the <strong class="bold">graphics processing unit</strong> (<strong class="bold">GPU</strong>) memory available on the local system.</li>
				<li>It is actively developed and maintained by the open source community.</li>
			</ul>
			<p>Let's look at a practical example that creates a simple classifier using AutoKeras to predict handwritten digits. But first, we will have to configure a work environment by installing AutoKeras and its necessary dependencies on it.</p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor035"/>How to run the AutoKeras experiments?</h2>
			<p>As the main<a id="_idIndexMarker095"/> tool to implement all the coding examples in this book, we will use Jupyter notebook.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">A <strong class="bold">notebook</strong> is a file generated by Jupyter Notebook (<a href="https://jupyter.org">https://jupyter.org</a>), an open source framework for <a id="_idIndexMarker096"/>creating and sharing documents that incorporates live code, visualizations, and rich text. Both the editing and the execution is done in a web browser, adding snippets (called cells) of code and rich text that show us clearly and visually what is being programmed. Each of these code cells can be run independently, making development interactive and avoiding having to run all your code if there is an error.</p>
			<p>In the following <a id="_idIndexMarker097"/>screenshot, you can see how a Jupyter notebook is running our experiment (notebook file) in a web browser just by clicking the <strong class="bold">Run</strong> button on the toolbar:</p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B16953_02_04.jpg" alt="Figure 2.4 – Jupyter notebook running just the training cell in AutoKeras experiment"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 2.4 – Jupyter notebook running just the training cell in AutoKeras experiment</p>
			<p>Using Jupyter notebooks is a great way to get started with AutoKeras, but not the only one; alternatively, you can also create your experiments in standalone Python scripts and run them from the command <a id="_idIndexMarker098"/>line or from your own <strong class="bold">integrated development environment</strong> (<strong class="bold">IDE</strong>).</p>
			<h1 id="_idParaDest-36"><a id="_idTextAnchor036"/>Installing AutoKeras</h1>
			<p>In the following<a id="_idIndexMarker099"/> sections, we will explain in detail the different options that exist for installing AutoKeras and how to configure each one step by step.</p>
			<p>There are two options to choose when installing AutoKeras: we can install it in a local workstation or we can install it in the cloud. Each of the two options has its pros and cons that we will analyze throughout this chapter.</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor037"/>Installing AutoKeras in the cloud</h2>
			<p>In the cloud, we have <a id="_idIndexMarker100"/>opted for two options: install it on an <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) instance/container, or use <strong class="bold">Google Colaboratory</strong>. In both cases, we <a id="_idIndexMarker101"/>will connect to the cloud instance using Jupyter notebooks from a web browser, as shown in the following screenshot. We just need a computer with an internet connection to run the notebooks:</p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B16953_02_05.jpg" alt="Figure 2.5 – AutoKeras cloud configurations&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – AutoKeras cloud configurations</p>
			<p>Let's look at the <a id="_idIndexMarker102"/>options for the cloud in more detail.</p>
			<h3>AutoKeras with Google Colaboratory</h3>
			<p>Google offers a<a id="_idIndexMarker103"/> Jupyter notebook-hosting service called <strong class="bold">Colaboratory</strong> where you can upload your Jupyter notebooks and run them on Google's cloud servers, leveraging the power of Google hardware (GPU or <strong class="bold">tensor processing unit</strong> (<strong class="bold">TPU</strong>)), regardless<a id="_idIndexMarker104"/> of the power of your workstation. All you need is a web browser. Also, as we said before, notebooks can install their own dependencies, so the AutoKeras installation can be performed while running the notebook (as we are doing with the notebooks in this book).</p>
			<p>You can run our<a id="_idIndexMarker105"/> MNIST notebook by just following these three steps:</p>
			<ol>
				<li>Create an account at <a href="https://colab.research.google.com">https://colab.research.google.com</a>. </li>
				<li>In Colaboratory, open the experiment from GitHub with this link: <a href="https://colab.research.google.com/github/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter02/Chapter2.ipynb">https://colab.research.google.com/github/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter02/Chapter2.ipynb</a>.</li>
				<li>Click the <strong class="bold">Run</strong> button to start the AutoKeras installation and run the experiment.<p>In the following screenshot, you can see Colaboratory running our experiment:</p></li>
			</ol>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B16953_02_06.jpg" alt="Figure 2.6 – AutoKeras running in Google Colaboratory"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – AutoKeras running in Google Colaboratory</p>
			<p>So, Google Colaboratory is a<a id="_idIndexMarker106"/> very good option to explore and run your notebooks quickly and easily, but next, we will also explain in detail how to install Jupyter notebook, plus the necessary dependencies, to run our notebooks in an AWS instance or in your own workstation.</p>
			<h3>AutoKeras in AWS</h3>
			<p>Basically, we have to<a id="_idIndexMarker107"/> make sure we create an Amazon EC2 Ubuntu/ Linux instance with<a id="_idIndexMarker108"/> GPU support and the <strong class="bold">Compute Unified Device Architecture</strong> (<strong class="bold">CUDA</strong>) libraries. Because AutoKeras will be installed when our Jupyter notebook is running, we just have to install the Jupyter framework and run our notebooks there. The following screenshot shows the client and server sides of an AutoKeras installation in an AWS instance: </p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B16953_02_07.jpg" alt="Figure 2.7 – AutoKeras running in AWS instance&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.7 – AutoKeras running in AWS instance</p>
			<p>There are many instances<a id="_idIndexMarker109"/> of AWS, some of them with the CUDA and Jupyter libraries already preinstalled and its ports mapped to access from your browser. The configuration of these is outside the scope of this book, but at <a href="https://docs.aws.amazon.com/dlami/">https://docs.aws.amazon.com/dlami/</a> there is detailed<a id="_idIndexMarker110"/> information on how to set up DL <strong class="bold">Amazon Machine Images</strong> (<strong class="bold">AMIs</strong>) that allow <a id="_idIndexMarker111"/>you to quickly build Amazon <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) instances on Amazon Linux or Ubuntu, preinstalled with the most popular DL frameworks.</p>
			<p>If you prefer containers over instances, you also have the option to run <strong class="bold">AWS DL Containers</strong> (<strong class="bold">AWS DL Containers</strong>) which are Docker images similar to previous AMIs, with<a id="_idIndexMarker112"/> DL software<a id="_idIndexMarker113"/> preinstalled. Find out more at <a href="https://aws.amazon.com/machine-learning/containers/">https://aws.amazon.com/machine-learning/containers/</a>.</p>
			<h3>AutoKeras in the cloud: advantages and disadvantages</h3>
			<p>If you don't have a <a id="_idIndexMarker114"/>powerful GPU, the cloud is a good and inexpensive option to get started without having to buy additional hardware.</p>
			<p>The cloud offering<a id="_idIndexMarker115"/> makes it easy to get started with AutoKeras; you can set it up from scratch on an AWS instance, upload your experiments to cloud services such as Google Colaboratory (<a href="http://colab.research.google.com">colab.research.google.com</a>), or run the training on a remote server using an AutoKeras extension. At the end of the book, we will see an extension called TensorFlow Cloud that allows<a id="_idIndexMarker116"/> you to run your program on <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) just by inserting a few more lines of code, taking easy advantage of the computing power in this cloud platform. </p>
			<p>But for a more intensive use of DL, this configuration is not the most suitable in the long run. Cloud instances or services are expensive, and if you need to train a model for more than a few hours, it is worth investing in a local workstation with one or more GPUs. </p>
			<p>On the other hand, if you need a large-scale on-demand configuration, setting up your own server cluster requires high cost in human and hardware resources and is much more difficult to scale and maintain than the cloud alternative.</p>
			<p>In this screenshot, you can see main differences between cloud and on-premises:</p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B16953_02_08.jpg" alt="Figure 2.8 – AutoKeras in the cloud versus local costs"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.8 – AutoKeras in the cloud versus local costs</p>
			<p>In short, running<a id="_idIndexMarker117"/> AutoKeras in the cloud is a very good way to start. You can follow the code examples in this book and get cutting-edge prediction results using the power of cloud tools such as Google Colaboratory, but if you are planning to run your own experiments for several days or even weeks of training, it's best to get your own GPUs.</p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor038"/>Installing AutoKeras locally</h2>
			<p>If you already have your <a id="_idIndexMarker118"/>own hardware resources, it's time to install the software to run your models there. The options that are outlined next will guide you to achieve that goal.</p>
			<h3>Which operating system to choose</h3>
			<p>When it comes to choosing an operating system for AutoKeras, Linux is undoubtedly the most suitable option for <a id="_idIndexMarker119"/>both your workstation and the cloud.</p>
			<p>Although it is possible to use AutoKeras in Windows, this is not recommended.</p>
			<p>More specifically, the ideal option is an Ubuntu Linux machine due to the number of packages available and because it is the system most used by the ML community. If you use Windows, the simplest and fastest solution to get everything working is to install Ubuntu with a dual boot on your workstation, following the instructions in this link: <a href="https://help.ubuntu.com/community/WindowsDualBoot">https://help.ubuntu.com/community/WindowsDualBoot</a>. </p>
			<p>You can also use an AutoKeras Docker image, but depending on your hardware, this sometimes creates problems in accessing the GPUs.</p>
			<h3>Installing AutoKeras on an Ubuntu Linux workstation</h3>
			<p>Once you have <a id="_idIndexMarker120"/>Ubuntu installed on your workstation, you can follow these steps to install AutoKeras and run the notebook files that come with this book:</p>
			<ol>
				<li value="1">Open a shell and run these commands to install the Jupyter notebook:<p class="source-code">$ apt-get install python3-pip jupyter-notebook</p></li>
				<li>Run this command to start the notebook:<p class="source-code">$ jupyter-notebook</p></li>
				<li>Now, go to <strong class="source-inline">http://127.0.0.1:8888</strong> in your browser and open the notebook file.</li>
				<li>In the top menu, go to <strong class="bold">Runtime</strong> -&gt; <strong class="bold">Run All</strong> to run the experiment. AutoKeras and its dependencies will be installed before running the rest of the code.<p class="callout-heading">Important note</p><p class="callout"><strong class="bold">GPU setup (optional)</strong>: If you have GPUs on your workstation and want AutoKeras to use them to accelerate the training of these, you can follow this tutorial to set this up: </p><p class="callout"><a href="https://www.tensorflow.org/install/gpu">https://www.tensorflow.org/install/gpu</a></p></li>
			</ol>
			<p>Keep in mind that AutoKeras is a work in progress and it evolves very quickly, and there may be changes in the installation process. I therefore recommend taking a look at the latest installation instructions, at <a href="https://autokeras.com/install/">https://autokeras.com/install/</a>.</p>
			<p>Run AutoKeras using a Docker container. The easiest way to get started with TensorFlow and Keras is to run in a Docker container. </p>
			<p><strong class="bold">Docker</strong> is a set of tools that allows<a id="_idIndexMarker121"/> you to install <a id="_idIndexMarker122"/>software in packages called containers, using virtualization at the operating system level. Each of the containers behaves like a single operating system with its own software, libraries, and configuration files, and these are isolated from each other. The process for creating a Docker container involves three steps, as follows:</p>
			<ol>
				<li value="1">First, a Docker container is defined in a file called <strong class="bold">Dockerfile</strong>. </li>
				<li>Then, using the Docker command-line tool, you can build an image from this Dockerfile.</li>
				<li>Finally, you can start a Docker container from this image. </li>
			</ol>
			<p>You can see these three steps in the following diagram:</p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B16953_02_09.jpg" alt="Figure 2.9 – Building a container from a Dockerfile&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.9 – Building a container from a Dockerfile</p>
			<p>There is a public repository for <a id="_idIndexMarker123"/>Docker images called Docker Hub (<a href="https://hub.docker.com/">https://hub.docker.com/</a>). There, you can find thousands of Docker images with preinstalled software packages.</p>
			<p>You can use a Docker image for AutoKeras with the latest version of the framework and get its dependencies already installed using the following steps:</p>
			<ol>
				<li value="1">Download the latest AutoKeras Docker image to your machine, as follows: <p class="source-code">$ docker pull haifengjin/autokeras:latest</p></li>
				<li>Run the AutoKeras Docker container, as follows:<p class="source-code"> $ docker run -it --shm-size 2G  haifengjin /autokeras /bin/bash.</p><p>If you need more memory, just change the <strong class="source-inline">shm-size</strong> value.</p></li>
				<li>Run a local Python script inside the container, as follows: </li>
			</ol>
			<p class="source-code">$ docker run -it -v hostDir:/app --shm-size 2G  haifengjin /autokeras python file.py. </p>
			<p>Notice that we have mounted the <strong class="source-inline">hostDir:/app</strong> host folder where the Python file to execute is located.</p>
			<p>You can also<a id="_idIndexMarker124"/> install the Jupyter notebook and run the AutoKeras installation process from the notebook experiment, as we did in the previous section.</p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor039"/>Hello MNIST: Implementing our first AutoKeras experiment</h1>
			<p>Our first experiment <a id="_idIndexMarker125"/>will be an image classifier using the MNIST dataset. This MINST classification task is like the <em class="italic">"hello world" </em>of DL. It is a classic problem of classifying images of handwritten digits into 10 categories (0 to 9). The images come from the MNIST, the most famous and widely used dataset in ML. It contains 70,000 images (60,000 for training and 10,000 for testing) collected in the 1980s by the NIST. </p>
			<p>In the next screenshot, you can see some samples of every number in the MNIST dataset:</p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B16953_02_10.jpg" alt="Figure 2.10 – MNIST dataset sample images&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10 – MNIST dataset sample images</p>
			<p>AutoKeras is designed to <a id="_idIndexMarker126"/>easily classify all types of data inputs—such as structured data, text, or images—as each of them contains a specific class. </p>
			<p>For this task, we will use <strong class="source-inline">ImageClassifier</strong>. This class generates and tests different models and hyperparameters, returning an optimal classifier to categorize the images of handwritten digits.</p>
			<p>Now, let's have a look at the most relevant cells of the notebook in detail.</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor040"/>Importing the needed packages</h2>
			<p>Load AutoKeras and the required packages, such as matplotlib, as follows:</p>
			<p class="source-code">import autokeras as ak</p>
			<p class="source-code">import matplotlib.pyplot as plt</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import tensorflow as tf</p>
			<p class="source-code">from tensorflow.keras.datasets import mnist</p>
			<p>The preceding <a id="_idIndexMarker127"/>packages include a plotting Python library that we have used to plot some digital representations, and the dataset we used is the MNIST handwritten digits dataset. </p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor041"/>Getting the MNIST dataset</h2>
			<p>We have to first load the<a id="_idIndexMarker128"/> MNIST data in memory and have a quick look at the dataset shape. To do this, we run the following code:</p>
			<p class="source-code">(x_train, y_train), (x_test, y_test) = mnist.load_data()</p>
			<p class="source-code">print(x_train.shape)</p>
			<p class="source-code">print(x_test.shape)</p>
			<p>The following output will be displayed:</p>
			<p class="source-code">Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz</p>
			<p class="source-code">11493376/11490434 [==============================] - 0s 0us/step</p>
			<p class="source-code">(60000, 28, 28)</p>
			<p class="source-code">(10000, 28, 28)</p>
			<p>We can see from the preceding output that each dataset contains images of size <strong class="source-inline">28x28</strong> pixels.</p>
			<p>Now, let's see what a digit looks like by running the following code:</p>
			<p class="source-code">%matplotlib inline</p>
			<p class="source-code">fig = plt.figure()</p>
			<p class="source-code">ax = fig.add_subplot(1, 2, 1)</p>
			<p class="source-code">plt.imshow(x_train[1234])</p>
			<p class="source-code">ax.set_title('Train sample')</p>
			<p class="source-code">ax = fig.add_subplot(1, 2, 2)</p>
			<p class="source-code">plt.imshow(x_test[1234])</p>
			<p class="source-code">ax.set_title('Test sample')</p>
			<p class="source-code">plt.show()</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B16953_02_11.jpg" alt="Figure 2.11 – Training and test samples visualization&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.11 – Training and test samples visualization</p>
			<p>Once we have<a id="_idIndexMarker129"/> looked at some samples of datasets, let's look at their distribution.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor042"/>How are the digits distributed?</h2>
			<p>When we are<a id="_idIndexMarker130"/> working with datasets, it is very important to check that the data is distributed homogeneously. This can be done easily by using <strong class="source-inline">numpy</strong> functions, as shown in the following code block:</p>
			<p class="source-code">train_histogram = np.histogram(y_train)</p>
			<p class="source-code">test_histogram = np.histogram(y_test)</p>
			<p class="source-code">_, axs = plt.subplots(1, 2)</p>
			<p class="source-code">axs[0].set_xticks(range(10))</p>
			<p class="source-code">axs[0].bar(range(10), train_histogram[0])</p>
			<p class="source-code">axs[1].set_xticks(range(10))</p>
			<p class="source-code">axs[1].bar(range(10), test_histogram[0])</p>
			<p class="source-code">plt.show()</p>
			<p>The following <a id="_idIndexMarker131"/>output will be displayed:</p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B16953_02_12.jpg" alt="Figure 2.12 – Training and test dataset histograms&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.12 – Training and test dataset histograms</p>
			<p>It seems homogeneous—each set of digits has similar amounts of samples, so it's now time to create our model.</p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor043"/>Creating an image classifier</h2>
			<p>We will now use the<a id="_idIndexMarker132"/> AutoKeras <strong class="source-inline">ImageClassifier</strong> class to find the best classification model. Just for this little example, we set <strong class="source-inline">max_trials</strong> (the maximum number of different Keras models to try) to 1 and the number of epochs to train each model to 20, but for real use it is recommended to set a large number of trials and not to set the <strong class="source-inline">epochs</strong> parameter, to use an adaptive number of epochs automatically. The code can be seen here:</p>
			<p class="source-code">clf = ak.ImageClassifier(max_trials=1)</p>
			<p>Let's run the training to search for the optimal classifier for the MNIST training dataset, as follows:</p>
			<p class="source-code">clf.fit(x_train, y_train, epochs=10)</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B16953_02_13.jpg" alt="Figure 2.13 – Notebook output of image classifier training &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.13 – Notebook output of image classifier training </p>
			<p>In the previous output, we can see that the model has reached quite good accuracy for the training dataset in just a couple of minutes. We can also see that the best generated model was saved to disk. </p>
			<p>We can also see that the precision increases in each epoch, <a id="_idTextAnchor044"/>so if we increase the number of <em class="italic">epochs</em> we <a id="_idIndexMarker133"/>would have a more precise model, although it would also take longer to finish. It is also important to take into account that after a high number of epochs, the model will usually stop learning.</p>
			<p>Let's test it with the test dataset to know the actual accuracy of the prediction.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor045"/>Evaluating the model with the test set</h2>
			<p>After training, it's time to measure the actual prediction of our<a id="_idIndexMarker134"/> model using the reserved test dataset. In this way, we can rule out that the good results obtained with the training set were due to overfitting. Have a look at the following code snippet:</p>
			<p class="source-code">metrics = clf.evaluate(x_test, y_test)</p>
			<p class="source-code">print(metrics)</p>
			<p>The following output will be displayed:</p>
			<p class="source-code">313/313 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9889</p>
			<p class="source-code">[0.03537507727742195, 0.9889000058174133]</p>
			<p>We can see here that there is really good prediction accuracy using our test dataset (98.8%), considering that we only spent a couple of minutes in the training phase.</p>
			<p>Let's have a look at how it is predicting a single test sample. First, we visualize the number and its true value, as follows:</p>
			<p class="source-code">plt.imshow(x_test[1234])</p>
			<p class="source-code">plt.title('Test sample of number: %s' % y_test[1234])</p>
			<p class="source-code">plt.show()</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B16953_02_14.jpg" alt="Figure 2.14 – Test sample to be predicted"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.14 – Test sample to be predicted</p>
			<p>Now, we print the predicted value using our classifier, as follows:</p>
			<p class="source-code">print(clf.predict(x_test[1234, None]))</p>
			<p>The following output will be displayed:</p>
			<p class="source-code">[['8']]</p>
			<p>We can see that the output matches the true value, so our <a id="_idIndexMarker135"/>classifier has predicted this correctly. Let's now take a look inside the classifier to understand how it is working.</p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor046"/>Visualizing the model</h2>
			<p>We are now<a id="_idIndexMarker136"/> exporting our classifier model to Keras so that we can see a little summary, with the architecture of the best generated model found. Here is the code we need to do this:</p>
			<p class="source-code">model = clf.export_model()</p>
			<p class="source-code">model.summary()</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B16953_02_15.jpg" alt="Figure 2.15 – Image classifier model architecture summary"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.15 – Image classifier model architecture summary</p>
			<p>If you do not have experience in Keras or Tensorflow this output will be a bit confusing, but don't worry—it's not necessary to understand it to use AutoKeras<a id="_idIndexMarker137"/> because the tool does all the work, abstracting us from these details, but it's always good to know how it works. In later chapters, we will see what each layer means in detail, but let's see an overview of what's going on here. </p>
			<p>Each layer performs a transformation operation of the input data, passing the transformed data to the next layer. </p>
			<p>The first layer has a 28x28 input that corresponds to the pixels of the image, as seen in the following code snippet:</p>
			<p class="source-code">input_1 (InputLayer)         [(None, 28, 28)]        0       </p>
			<p>The following tree layers transform and normalize the image to adapt it to the<a id="_idIndexMarker138"/> input of the convolutional operations (Conv2D):</p>
			<p class="source-code">tf_op_layer_Cast (TensorFlow (None, 28, 28)          0      </p>
			<p class="source-code">____________________________________________________________</p>
			<p class="source-code">tf_op_layer_ExpandDims (Tens (None, 28, 28, 1)       0      </p>
			<p class="source-code">_____________________________________________________________</p>
			<p class="source-code">normalization (Normalization (None, 28, 28, 1)       3       </p>
			<p>The convolutional operations layers, widely used for the classification of images, extract characteristics of the image through the use of filters (we will talk about this in later chapters). We can see the process in the following snippet:</p>
			<p class="source-code">conv2d (Conv2D)              (None, 26, 26, 32)      320     </p>
			<p class="source-code">_____________________________________________________________</p>
			<p class="source-code">conv2d_1 (Conv2D)            (None, 24, 24, 64)      18496   </p>
			<p class="source-code">_____________________________________________________________</p>
			<p class="source-code">max_pooling2d (MaxPooling2D) (None, 12, 12, 64)      0       </p>
			<p>Subsequently there are several layers that prevent overfitting by performing dropout (arbitrarily disconnecting part of the neural connections), as follows:</p>
			<p class="source-code">dropout (Dropout)            (None, 12, 12, 64)      0      </p>
			<p class="source-code">____________________________________________________________</p>
			<p class="source-code">flatten (Flatten)            (None, 9216)            0       </p>
			<p class="source-code">____________________________________________________________</p>
			<p class="source-code">dropout_1 (Dropout)          (None, 9216)            0       </p>
			<p>Then, a full connect operation is performed that reduces the dimension of the output of the convolutional operations to 10 elements that correspond to the numbers from 0 to 9, as follows:</p>
			<p class="source-code">dense (Dense)                (None, 10)              92170   </p>
			<p>Finally, the last layer (Softmax) is left with only the highest value of the 10 elements that will correspond to the final predicted number, as follows:</p>
			<p class="source-code">classification_head_1 (Softm (None, 10)              0  </p>
			<p>There is a more graphical way to visualize the model, so let's see it by <a id="_idIndexMarker139"/>running the following code:</p>
			<p class="source-code">from tensorflow.keras.utils import plot_model</p>
			<p class="source-code">plot_model(clf.export_model())</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B16953_02_16.jpg" alt="Figure 2.16 – Image classifier model architecture visualization&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.16 – Image classifier model architecture visualization</p>
			<p>In the preceding<a id="_idIndexMarker140"/> diagram, each block represents a layer and the output of each is connected to the input of the next, except the first block (whose input is the image) and the last block (whose output is the prediction).</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor047"/>Creating an image regressor</h2>
			<p>Now, we will <a id="_idIndexMarker141"/>use a different approach to figure out the digit values from the image: a regression model call regressor.</p>
			<p>The image regressor will try to predict the scalar value of the digit instead, to classify it in a 0-9 category.</p>
			<p>AutoKeras has already a special class ready to use called <strong class="source-inline">ImageRegressor</strong>, which will find the best regression model.</p>
			<p>As we did with the classifier, for this little example we set <strong class="source-inline">max_trials</strong> (the maximum number of different Keras models to try) to 1 and the number of epochs to train each model to 20, but for real use it is recommended to set a large number of trials and not to set the <strong class="source-inline">epochs</strong> parameter to use an adaptive number of epochs automatically.</p>
			<p>First, we initialize the image regressor, as follows:</p>
			<p class="source-code">reg = ak.ImageRegressor(</p>
			<p class="source-code">overwrite=True,</p>
			<p class="source-code">max_trials=1)</p>
			<p>Now, feed the image regressor with the training dataset, as follows.</p>
			<p class="source-code">reg.fit(x_train, y_train, epochs=20)</p>
			<p>Now is the moment of truth—let's evaluate it with our test set.</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor048"/>Evaluating the model with the test set</h2>
			<p>Finally, we evaluate the best model with the testing <a id="_idIndexMarker142"/>dataset, using the following code:</p>
			<p class="source-code">reg.evaluate(x_test, y_test)</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B16953_02_17.jpg" alt="Figure 2.17 – Notebook output of image regressor training&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.17 – Notebook output of image regressor training</p>
			<p>After 20 minutes, the best<a id="_idIndexMarker143"/> model found has a <strong class="bold">mean square error</strong> (<strong class="bold">MSE</strong>) rate of <strong class="source-inline">0.083</strong>, which isn't bad. MSE is a widely used metric for measuring performance in regression models.</p>
			<p>Let's predict the first 10 digits of the<a id="_idIndexMarker144"/> test dataset with the best model found, and print the predicted and true values to compare them. We can do this by running the following code:</p>
			<p class="source-code">predicted_y = reg.predict(x_test[:10])</p>
			<p class="source-code">print(list(y_test[:10]))</p>
			<p class="source-code">print([round(float(i)) for i in predicted_y])</p>
			<p>The following output will be displayed:</p>
			<p class="source-code">[7, 2, 1, 0, 4, 1, 4, 8, 5, 9]</p>
			<p class="source-code">[7, 2, 1, 0, 4, 1, 4, 8, 5, 9]</p>
			<p>As you can see, it's<a id="_idIndexMarker145"/> predicting the true value in every one of the cases. Let's see it in a more graphical way by running the following code:</p>
			<p class="source-code">fig = plt.figure()</p>
			<p class="source-code">for i, v in enumerate(predicted_y):</p>
			<p class="source-code">    ax = fig.add_subplot(2, 5, i+1)</p>
			<p class="source-code">    ax.set_axis_off()</p>
			<p class="source-code">    ax.set_title(round(float(v)))</p>
			<p class="source-code">    plt.imshow(x_test[i])</p>
			<p class="source-code">plt.show()</p>
			<p>The following output will <a id="_idIndexMarker146"/>be displayed:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B16953_02_18.jpg" alt="Figure 2.18 – Image digits labeled with the predicted values"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 2.18 – Image digits labeled with the predicted values</p>
			<p>Notice that we have<a id="_idIndexMarker147"/> rounded up the float values returned by the regressor to compare them to the true values. This is done because regressors always return continuous values that they approximate to the real value, so if we want to predict discrete values (0 to 9 digits), we have to do a rounding to return the predicted value.</p>
			<p>Now, as we did with the classifier, let's take a look at the architecture of the best generated model.</p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor049"/>Visualizing the model</h2>
			<p>We export <a id="_idIndexMarker148"/>the model to a Keras model and then we make a call to the <strong class="source-inline">model.summary</strong> function to see the architecture, as follows:</p>
			<p class="source-code">model = clf.export_model()</p>
			<p class="source-code">model.summary()</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B16953_02_19.jpg" alt="Figure 2.19 – Image regressor model architecture summary&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.19 – Image regressor model architecture summary</p>
			<p>As we did with <a id="_idIndexMarker149"/>the classifier, there is a more visual way to see it, as follows:</p>
			<p class="source-code">from tensorflow.keras.utils import plot_model</p>
			<p class="source-code">plot_model(clf.export_model())</p>
			<p>The following output will be displayed:</p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B16953_02_20.jpg" alt="Figure 2.20 – Image regressor model architecture visualization"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.20 – Image regressor model architecture visualization</p>
			<p>In this example of the classifier, we have given a quick view of each block. We <a id="_idIndexMarker150"/>will not go deeper here, as I think this is enough for a "getting started" chapter. In the following chapters, we will explain in more detail each of the blocks that appear in the screenshots.</p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor050"/>Summary</h1>
			<p>In this chapter, you have learned the main options for getting started with AutoKeras, from installation to running in various environments.</p>
			<p>You have also seen the power of AutoKeras by implementing two different approaches of a high-precision image classifier in just a few lines of code and 2 minutes of training.</p>
			<p>Now that you have learned to implement a DL model from scratch, following these same steps and simply changing the dataset, your model would be able to classify all kinds of images.</p>
			<p>In the following chapters, you will learn how to solve more complicated tasks related to images, structured data, and plaintext as input data sources, but before that, in the next chapter, we will see how to prepare the data to feed to AutoKeras by using some interesting tools to automate this process as much as possible.</p>
		</div>
	</body></html>