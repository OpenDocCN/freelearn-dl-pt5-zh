<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Artificial Neural Networks</h1>
                </header>
            
            <article>
                
<p>In this chapter, you will learn about artificial neural networks, which forms the foundation for all deep learning. We will discuss what makes deep learning different from other forms of machine learning and then spend time diving into some of its specific and special features.</p>
<p>By the end of this chapter, we will have l<span>earned what mak</span><span>es deep learning a special subset of machine learning. We'll have a</span><span>n understanding of neural networks, how they mimic the brain, and t</span><span>he benefits of hidden layers for discrete element detection.</span> <span>We'll create a </span><span>feedforward</span> <span>neural network, noting the role of the activation function in determining variable weights.</span></p>
<p>This chapter will cover the following topics:</p>
<ul>
<li class="mce-root">Contrasting deep learning with machine learning</li>
<li class="mce-root">Comparing neural networks and the human brain</li>
<li class="mce-root">Understanding the role of hidden layers</li>
<li class="mce-root">Creating a feedforward network</li>
<li class="mce-root">Augmenting our neural network with backpropagation</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>For the source code of this chapter, please refer to the GitHub link at <a href="https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R">https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Contrasting deep learning with machine learning</h1>
                </header>
            
            <article>
                
<p>One key strength of deep learning not shared by other forms of ML is its ability to factor the way variables are related. For instance, if we think back to when we were first learning about animals, then we could imagine a simple task where we are given five images of cats and five images of dogs; later, when we were shown a new image, we would be able to determine whether it was a cat or dog using the patterns that we detected from the previous images that we studied. In our example, it was the images that were to be classified as either cats or dogs. We can consider this example as a training set, and will use the same terminology for the classification of images. Mentally, our brain tries to match the images with the patterns that form the features of these two different species so that we can differentiate between them. This is what happens in deep learning as well.</p>
<p>Today, we would find the preceding example task to be quite simple; however, think of how a computer would have to learn this:</p>
<ul>
<li>It needs to account for the ways that features are related for dogs compared with cats and it needs to do this wherever an animal appears in a photo, however much of the image is taken up by the animal.</li>
<li>For this, we cannot use the standard machine-learning approach where all input is used without consideration for how it is related. The placement and proximity of pixels in two-dimensional space must be considered, so we can already see how a simple task for humans is already more complex for a machine.</li>
<li>Furthermore, just evaluating the input data in the form of two-dimensional arrays is not enough. The machine also needs the multiple hidden layer architecture present in deep learning to identify multiple different patterns among the data arrays. That is to say, the pure signal won't be as helpful as the relationship between given signals that are near each other.</li>
<li>Each layer will identify the presence of a different aspect of the image from basic shape detection to the length and steepness of color gradients.</li>
</ul>
<p>When performing a simple regression or classification task, we apply a weight to each variable and then use this to predict an outcome. With deep learning, there is a middle step where artificial neurons or units are created using all the variables. This step creates new features that are a combination of all variables with varying weights applied. This activity happens in what is known as a hidden layer. After this, the signal is passed on to another hidden layer and the same process happens again.</p>
<p>Each layer will learn a different aspect from the input. Let's look at an example of this:</p>
<ul>
<li>The first layer creates neurons based on the overall size of the object in the image by applying different weights to the negative and positive space.</li>
<li>In the second layer, the neurons may be created based on the shape and size of the ears and nose.</li>
<li>In this way, the different characteristics of cats and dogs are captured among the entirety of the hidden layers.</li>
</ul>
<p>The weights are assigned randomly at first. This is then checked against the actual answers. After several attempts, the model learns that adjusting weights in a given direction produces better results, and so it will continue to adjust the weights in the same direction until the chosen error rate is minimized.</p>
<p>Once this is complete and the weights are learned, a new input can be introduced. The model will multiply all variables by the learned weights at every neuron and each neuron will use an activation function that determines whether to activate or fire and send the signal forward to the next layer. We will go into more detail on the various activation functions later in the chapter. For now, let's just say that a calculation occurs at each neuron, after which a final value is produced at the output node. In this case, the probability is that the image is either a dog or a cat.</p>
<p>In this illustration, we may begin to see the power of neural networks and deep learning. The model is not evaluating the variables in isolation but rather in concert. By contrast, regression models calculate weights for each individual variable separately. Regression models can use interaction terms to calculate weights for combinations of variables; however, even this doesn't consider all variables in the same way as neural networks that evaluate all variables at all neurons. The neurons created from all the variables are then used to define the next set of neurons in the next layer. In this way, the entirety of the feature space is considered and is then partitioned based on themes that emerge after evaluating all variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparing neural networks and the human brain</h1>
                </header>
            
            <article>
                
<p>Let's consider how a human brain learns in order to see the ways in which a neural network is similar and the ways in which it is different.</p>
<p>Our brain contains a large number of neurons, and each neuron is connected to thousands of nearby neurons. As these neurons receive signals, they fire if the input contains a certain amount of a given color or a certain amount of a given texture. After millions of these interconnected neurons fire, the brain interprets the incoming signal as a certain class.</p>
<p>Of course, these connections are not set permanently but rather change dynamically as we continue to have experiences, notice patterns, and discover relationships. If we try a new fruit for the first time and discover that it is really sour, then all the attributes that help us recognize this fruit are connected with things that we know are sour. In the future, whether we will want to experience eating this fruit again or not will depend on how much we want to experience this sour taste.</p>
<p>Another example that shows how the neural network in our brain constantly evolves focuses on the types of activities that we find enjoyable. For instance, have you ever wondered why babies find shaking a simple toy enjoyable while we do not? In our brains, novelty is rewarded by the release of opioids; however, as a given piece of stimulus becomes less surprising, a smaller number of neurons are needed to interpret this experience, resulting in a less intense response as fewer neurons are firing. In this way, we see the dynamic nature of the neural connections in our brains, which are in constant flux.</p>
<p><span>When we discuss the connections between neurons, we are specifically speaking of the synapses between neurons.</span><span> </span>Artificial neural networks seek to mimic the type of learning done by the human brain by creating a massive web of connections between constructed neurons and an output node or nodes, in a crude approximation of the brain's neurons. Just as the synapses that connect neurons in our brain can get stronger or weaker, the weights between neurons can change during the training process.</p>
<p>However, unlike the human brain, simple artificial neural networks like those that we are studying in this chapter do not start with any inherited weights and connections. They begin with a random assignment of weights and connections. Also, while the weights can change during the training process, this does not continue during the application of the model. At this phase, the weights that were derived during the training process are applied and there isn't a continual adjustment. This can be contrasted with the human brain. The neural networks in our brains do behave similarly to artificial neural networks; however, the adjustments to how neurons are connected update constantly. Lastly, the human brain has billions of neurons and trillions of connections, while artificial neural networks like those we will build shortly have much fewer.</p>
<p>While there are some significant differences between the way a brain learns and the way an artificial neural network learns, by sharing a similar design structure, the artificial neural network is capable of solving some extremely complex tasks. This idea has continued to develop and improve, and throughout the course of this book, we will see just how powerful this idea has been for data science.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Utilizing bias and activation functions within hidden layers</h1>
                </header>
            
            <article>
                
<p>When we described deep learning earlier, we noted that the defining characteristic is the presence of hidden layers comprised of neurons that contain the weighted sum of all predictor variables in a dataset. We just addressed how this array of interconnected neurons is modeled after the human brain. Now let's take a deeper dive into what is happening in these hidden layers where neurons are created.</p>
<p>At this point, we can deduce the following:</p>
<ul>
<li>We understand that all variables receive a coefficient at random for each neuron based on how many units we want to create in each layer.</li>
<li>The algorithm then continues to make changes to these coefficients until it minimizes the error rate.</li>
<li>However, there is one additional coefficient present during this process of passing weighted values to the neurons, and that is known as the bias function.</li>
</ul>
<p>The bias function can simply be thought of as a means of adjusting the shape of the line separating the data laterally. For now, let's simply imagine that a straight diagonal line is drawn to separate data points in two-dimensional space. In the following example, no matter how we adjust the slope of the line, we cannot find a line that bisects the triangles and circles:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="assets/eea521fc-8c58-4542-9f70-9559a02b977c.png" style="width:31.50em;height:32.25em;"/></p>
<p>However, if we adjust the line slightly so that it intercepts the <em>y</em>-axis above the center of the plot, then we can fit a line between the two classes of points. This is what the bias function does. It adjusts the intercept point to allow for a better fitting line:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/af4a5ff3-c637-4eaa-a04a-5f431a2b36cf.png" style="width:31.42em;height:32.17em;"/></p>
<p>The bias function is a coefficient that adjusts the line along the <em>x</em>-axis in this way to account for situations where the data requires the line to intersect the point where <strong>y</strong> is equal to <strong>0</strong> and <strong>x</strong> perhaps equals <strong>5</strong>.</p>
<p>All the weighted units and the bias function value are summed within the neuron and plotted along a linearly divided space. Calculating where a point is located relative to this line determines whether the neuron activates or switches on and continues to send a signal forward or if it switches off. Neural networks that use this type of function as a threshold to determine what happens with an incoming signal are referred to as perceptrons and are the earliest form of artificial neural network created.</p>
<p class="mce-root">However, as neural networks have evolved, it has become clearer that using a linear model to separate data would not work in all circumstances. As a result, there are now a number of available functions that can take place within the neuron to determine whether the signal should continue or stop as it passes through. These gate functions are referred to as activation functions, as they simulate the process of a neuron within the brain being triggered to fire or activate and send a signal to a connected neuron or not. At this point, let's explore the variety of activation functions available.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Surveying activation functions</h1>
                </header>
            
            <article>
                
<p>The activation functions are the last piece of the neural network that we have not covered in depth yet. To review what we know so far, in a neural network, we start with an input, as we would with any machine-learning modeling exercise. This data consists of a dependent target variable that we would like to predict and any number of independent predictor variables that are to be used for this prediction task.</p>
<p>During the training process, the independent variables are weighted and combined in simulated neurons. A bias function is also applied during this step and this constant value is combined with the weighted independent variable values. At this point, an activation function evaluates an aggregation of the values and if it is above a set threshold limit, then the neuron fires and the signal is passed forward to additional hidden layers, if they exist, or to the output node.</p>
<p>Let's consider the simplest activation function, which is a Heaviside or binary step function. <span>This can be imagined visually as two horizontal lines that act as the threshold limits on either side of a vertical line splitting the data so that the shape is like that of a step. </span><span>If the value is on the horizontal line at 1, then the signal progresses; otherwise, the neuron doesn't fire. We also previously mentioned how a diagonal line could be used at this step to linearly separate points. When points cannot be separated by either of these simple activation functions, then we can use nonlinear alternatives, which we will look at next.<br/></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the sigmoid function</h1>
                </header>
            
            <article>
                
<p>The sigmoid function is the classic S-shaped function. This function works especially well for logistic regression tasks. While most of the results will be classified by the tails on either side of the curve, there is an area in the middle for capturing uncertainty about some of the data. The drawback of this shape is that the gradient is almost zero at the extremes, so the model may not be able to continue to learn as the points get towards either side.</p>
<p>The sigmoid function also contains a derivative value, which means that we can use this function along with backpropagation to update the weights after the variables pass through additional layers. We will explore backpropagation more in the final parts of this chapter.</p>
<p>Another advantage of the sigmoid function is that it confines values between 0 and 1 so that the values are conveniently bound.</p>
<p>The <kbd>sigmoid</kbd> function can be defined simply using R code:</p>
<pre>sigmoid = function(x) {<br/>  1 / (1 + exp(-x))<br/>}</pre>
<p>In this function, we can see that the dynamic value is the exponent of negative <kbd>x</kbd>.</p>
<p>Let's use this sigmoid function on a sequence of values between <kbd>-10</kbd> and <kbd>10</kbd>:</p>
<ol>
<li>To start, we will create a <kbd>tibble</kbd> containing two columns. One column will contain the sequence of numbers and the other will use the results of passing this sequence of values as arguments through the <kbd>sigmoid</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">vals &lt;- tibble(x = seq(-10, 10, 1), sigmoid_x = sigmoid(seq(-10, 10, 1)))</pre>
<ol start="2">
<li>Next, we set up the base of our plot by using the <kbd>ggplot()</kbd> function and passing in the data objects and defining the values that will be used along the <em>x</em>- and <em>y</em>-axes. In this case, we use the sequence of values between <kbd>-10</kbd> and <kbd>10</kbd> along the <em>x</em>-axis and the results of passing these values through the sigmoid function along the <em>y</em>-axis:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- ggplot(vals, aes(x, sigmoid_x))</pre>
<ol start="3">
<li>We will now add the points and use the <kbd>stat_function</kbd> feature to connect the points and display the sigmoid shape:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- p + geom_point()<br/>p + stat_function(fun = sigmoid, n = 1000)</pre>
<p>If we now look at this shape, we can see why this type of activation function works so well for logistic regression. Using the <kbd>sigmoid</kbd> function to transform our values has pushed most of the values close to the extremes of <kbd>0</kbd> or <kbd>1</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5dce8270-9c4f-4561-a97f-ffcbbd5c8e4e.png" style="width:40.50em;height:38.33em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Investigating the hyperbolic tangent function</h1>
                </header>
            
            <article>
                
<p>The hyperbolic tangent function, which is also known as <strong>tanh</strong>, is very similar to the sigmoid function; however, the lower bound of the curve is in negative space to better handle data containing negative values.</p>
<p>Aside from this one difference, everything else about the hyperbolic tangent function is the same as the sigmoid function, and like the sigmoid function, the hyperbolic tangent contains a derivative element and can be used with backpropagation.</p>
<p>Since tanh is bounded between <kbd>-1</kbd> and <kbd>1</kbd>, the gradient is larger and the derivative is more pronounced. Being bounded means that tanh is centered around <kbd>0</kbd>, which can be advantageous in a model with a large number of hidden layers as the results from a layer are easier for the next layer to use.</p>
<p class="mce-root">Let's use the same sequence of values and plot the values after passing all of these values through the hyperbolic tangent function, which is included with base R and can be called using <kbd>tanh()</kbd>:</p>
<ol>
<li>As we did in the preceding sigmoid example, we will create a <kbd>tibble</kbd> with the values in our sequence and the transformed values:</li>
</ol>
<pre style="padding-left: 60px">vals &lt;- tibble(x = seq(-10, 10, 1), tanh_x = tanh(seq(-10, 10, 1)))</pre>
<ol start="2">
<li>We then set up the base of our plot by passing the dataset along with the values to use for the <em>x</em>-axis and the <em>y</em>-axis to the <kbd>ggplot()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- ggplot(vals, aes(x, tanh_x))</pre>
<ol start="3">
<li>Lastly, we again add our points and use the <kbd>stat_function</kbd> feature to connect the dots and display our shape:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- p + geom_point()<br/>p + stat_function(fun = tanh, n = 1000)</pre>
<p>As we look at this shape, we can see that it is a very similar shape to the sigmoid shape that we just plotted; however, note that the <em>y</em>-axis now has a range from <kbd>-1</kbd> to <kbd>1</kbd> rather than <kbd>0</kbd> to <kbd>1</kbd>, as was the case with the sigmoid shape. As a result, the values are pushed even further to the extremes and negative values remain negative after transformation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2497a31e-f420-4e7a-aba6-b4859d42df7d.png" style="width:43.58em;height:41.25em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Plotting the rectified linear units activation function</h1>
                </header>
            
            <article>
                
<p><strong>Rectified Linear Units</strong> (<strong>ReLU</strong>) is a hybrid function that fits a line for positive values of <em>x</em> while assigning any negative values of <em>x</em> with a value of 0. Even though one half of this function is linear, the shape is nonlinear and carries with it all the advantages of nonlinearity, such as being able to use the derivative for backpropagation.</p>
<p>Unlike the previous two activation functions, it has no upper bound. This lack of a constraint can be helpful to avoid the issue with the sigmoid or tanh function, where the gradient becomes very gradual near the extremes and provides little information to help the model continue to learn. Another major advantage of ReLU is how it leads to sparsity in the neural network because of the drop off at the center point. Using signoid or tanh, very few output values from the function will be zero, which means that the activation functions will fire, leading to a dense network. By contrast, ReLU results in far more output values of zero, leading to fewer neurons firing and a much sparser network.</p>
<p>ReLU will learn faster than sigmoid and tanh because of its simplicity. The ReLU function results in more zero values than sigmoid or tanh, which will improve the speed of the training process; however, since we no longer know the unaltered value for these points, they cannot be updated during backpropagation later. This can be an issue if weights would otherwise be adjusted to pass along relevant information during backpropagation; however, it is no longer possible once the derivative is set to zero.</p>
<p>Let's write some code to visualize the ReLU function:</p>
<ol>
<li>First, we will define the function. It is simply defined so that if a value for <em>x</em> is greater than 0, then it sets <em>x</em> equal to <em>y</em>, and creates a line with a slope of <kbd>1</kbd>; otherwise, it sets <em>y</em> to <em>x</em> and creates a horizontal line on the <em>x</em>-axis. This can be coded like this:</li>
</ol>
<pre style="padding-left: 60px">relu &lt;- function(x){dplyr::if_else(x &gt; 0, x, 0)}</pre>
<ol start="2">
<li>Next, let's create our dataset again using the same sequence of numbers as before and the transformed values after passing this sequence through our ReLU function:</li>
</ol>
<pre style="padding-left: 60px">vals &lt;- tibble(x = seq(-10, 10, 1), relu_x = relu(seq(-10, 10, 1)))</pre>
<ol start="3">
<li>Lastly, let's plot these points and connect them to display the shape of this activation function:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- ggplot(vals, aes(x, relu_x))<br/>p &lt;- p + geom_point()<br/>p + geom_line() </pre>
<p>Now, as we look at this shape, we can see its strengths. Having no upper bounds provides the model with more information than sigmoid, where the gradient becomes very minimal near the extremes. In addition, converting all negative values to <kbd>0</kbd> results in a much more sparse neural network and faster training time:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/04d3f782-4dd1-46e9-9255-e68dcf7e19a6.png" style="width:40.58em;height:38.42em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Calculating the Leaky ReLU activation function</h1>
                </header>
            
            <article>
                
<p>One potential problem with ReLU is known as <strong>dying ReLU</strong>, where, since the function assigns a zero value for all negative values, signals can get dropped completely before reaching the output node. One way to try to solve this issue is to use Leaky ReLU, which assigns a small alpha value when numbers are negative so that the signal is not completely lost. Once this constant is applied, the values that would otherwise <span>have</span><span> </span><span>been zero now have a small slope. This keeps the neuron from being fully deactivated so that information can still be passed on to improve the model.</span></p>
<p>Let's create a simple example of the Leaky ReLU activation function:</p>
<ol>
<li>We start by defining the function. We will do this in the exact same way as the ReLU function, except that instead of assigning a <kbd>0</kbd> to all negative values, we will instead multiply by a constant to provide a small slope:</li>
</ol>
<pre style="padding-left: 60px">leaky_relu &lt;- function(x,a){dplyr::if_else(x &gt; 0, x, x*a)}</pre>
<ol start="2">
<li>After this, we create the dataset with the sequence of values that we have been using in these examples, along with the transformed values:</li>
</ol>
<pre style="padding-left: 60px">vals &lt;- tibble(x = seq(-10, 10, 1), leaky_relu_x = leaky_relu(seq(-10, 10, 1),0.01))</pre>
<ol start="3">
<li>Lastly, we plot these points to display the shape of this activation function:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- ggplot(vals, aes(x, leaky_relu_x))<br/>p &lt;- p + geom_point()<br/>p + geom_line() </pre>
<p>When we look at this shape, we can see why this alternative to ReLU is preferable sometimes. Having the slight slope for negative values of <strong>x</strong> combats the dying ReLU problem where the neural network becomes too sparse and doesn't have the data needed to converge around a prediction:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7009590a-75de-4684-9efe-096c48732791.png" style="width:41.58em;height:39.33em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the swish activation function</h1>
                </header>
            
            <article>
                
<p>Swish is a more recently developed activation function that aims to leverage the strengths of ReLU while also addressing some of its shortcomings. Swish, like ReLU, has a lower bound and no upper bound, which is a strength as it can still deactivate neurons while preventing values from being forced to converge around an upper bound. However, unlike ReLU, the lower bound is still curved, and what's more notable is that the line is nonmonotonic, which means that as values for <kbd>x</kbd> decrease, the value for <kbd>y</kbd> can increase. This is an important feature that prevents the dying neuron problem as the derivative can continue to be modified across iterations.</p>
<p>Let's investigate the shape of this activation function:</p>
<ol>
<li>Let's start by defining the function, as we did in other examples. The formula simply takes a value and multiplies it by the result of passing the exact same value through the sigmoid function:</li>
</ol>
<pre style="padding-left: 60px">swish &lt;- function(x){x * sigmoid(x)}</pre>
<ol start="2">
<li>After this, we will create our dataset again with the same sequence of values that we have used previously and a corresponding set of transformed values:</li>
</ol>
<pre style="padding-left: 60px">vals &lt;- tibble(x = seq(-10, 10, 1), swish_x = swish(seq(-10, 10, 1)))</pre>
<ol start="3">
<li>Finally, we can plot these points to display the shape of this function:</li>
</ol>
<pre style="padding-left: 60px">p &lt;- ggplot(vals, aes(x, swish_x))<br/>p &lt;- p + geom_point()<br/>p + geom_line()</pre>
<p>As we look at this shape, we will see that, like ReLU, it has a lower bound and no upper bound; however, unlike ReLU and all other activation functions, it is nonmonotonic—that is, we can see that the values for <em>y</em> when <em>x</em> is negative first decrease and then increase. This feature has been shown to be especially beneficial as neural networks get progressively deeper:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c46491be-188a-43eb-9303-b59485b73200.png" style="width:43.58em;height:41.25em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predicting class likelihood with softmax</h1>
                </header>
            
            <article>
                
<p>The <kbd>softmax()</kbd> function is needed when there is more than one target variable. Softmax will create probabilities that a particular set of input variables belongs to each class. After these results are calculated, they can be used to assign input rows to one of the possible target classes. Let's explore this activation function with a slightly different example:</p>
<ol>
<li>We will start by defining the function:</li>
</ol>
<pre style="padding-left: 60px">softmax &lt;- function(x) {exp(x) / sum(exp(x))}</pre>
<ol start="2">
<li>Next, let's pass a vector of values to the function:</li>
</ol>
<pre style="padding-left: 60px">results &lt;- softmax(c(2,3,6,9))<br/>results<br/><br/><strong>[1] 0.0008658387 0.0023535935 0.0472731888 0.9495073791</strong></pre>
<ol start="3">
<li>Let's confirm that the sum of these transformed values equals <kbd>1</kbd>:</li>
</ol>
<pre style="padding-left: 60px">sum(results)<br/><br/><strong>[1] 1</strong></pre>
<p>We can see that this function will take a set of values and calculate a probability that each is a value we are trying to predict so that the sum of all probabilities is <kbd>1</kbd>. This can be used to select the most likely value among a set of more than two values for a given target.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a feedforward network</h1>
                </header>
            
            <article>
                
<p>With an understanding of neural networks, we will now build some simple examples. First, we will create the functions needed to create a very simple neural network ourselves to better understand what is happening during the modeling process. Afterward, we will use the <kbd>neuralnet</kbd> package to build a neural network that solves a task using a simple dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Writing a neural network with Base R</h1>
                </header>
            
            <article>
                
<p>For this example, we will use Base R to create a very simple neural network from scratch to better understand exactly what is happening at each step. In order to complete this task we will do the following:</p>
<ul>
<li>Define the activation function for the neurons in our model</li>
<li>Create a function that shows the line after every iteration of learning the weights</li>
<li>Make some test data and plot these data values</li>
<li>Update weights using the results of the previous attempt</li>
</ul>
<p>We will use the following steps to do so:</p>
<ol>
<li>First, we code the Heaviside (binary) step activation function to start. We will recall that this function evaluates the input and if this value is greater than zero, then the output value of the function is <kbd>1</kbd>; otherwise, the value is <kbd>0</kbd>. We can express this logic in code using the following lines of code:</li>
</ol>
<pre style="padding-left: 60px">artificial_neuron &lt;- function(input) {  as.vector(ifelse(input %*% weights &gt; 0, 1, 0)) <br/>}</pre>
<ol start="2">
<li>Next, we can create the function for drawing the line using random weights at first and then the learned weight as we iterate over and update the values passed to the expression portion of the curve function, as shown here:</li>
</ol>
<pre style="padding-left: 60px">linear_fits &lt;- function(w, to_add = TRUE, line_type = 1) {curve(-w[1] / w[2] * x - w[3] / w[2], xlim = c(-1, 2), ylim = c(-1, 2), col = "black",lty = line_type, lwd = 2, xlab = "Input Value A", ylab = "Input Value B", add = to_add)}</pre>
<p style="padding-left: 60px">In the expression equation, we can see that everything is relative to <kbd>x</kbd>. In this case, if we just ran <kbd>curve((x))</kbd>, then we would get a line at exactly 45 degrees so that the <kbd>x</kbd> and <kbd>y</kbd> were always equal and the slope of the line was <kbd>1</kbd>. In the preceding code, we use the weights to change the slope of the line relative to <kbd>x</kbd>. The remainder just defines the plot and the line and the <kbd>add</kbd> argument is used to declare whether the new line produced by the curve function should be added to the plot in addition to the line or lines already there.</p>
<ol start="3">
<li>With these functions defined, we can now assign some initial values for the input, output, learning rate, and weights. The input values are a set of <em>x</em> and <em>y</em> coordinates along with a constant value. The output values are just binary flags, in this case, denoting whether the input variable is or is not a member of the target class. Lastly, some random weights are included to initialize the model, along with a learning rate that will be used for updating weights at every iteration:</li>
</ol>
<pre style="padding-left: 60px">input &lt;- matrix(c(1, 0,<br/>                 0, 0,<br/>                  1, 1,<br/>                  0, 1), ncol = 2, byrow = TRUE)  <br/>input &lt;- cbind(input, 1) <br/>output &lt;- c(0, 1, 0, 1)<br/>weights &lt;- c(0.12, 0.18, 0.24)<br/>learning_rate &lt;- 0.2</pre>
<ol start="4">
<li>Next, we can add our first line, which is the guess using the random weights along with our output points. We would like to arrive at a line that completely bisects the two points that belong to the target class from the two points that do not. To start, we apply our initial random weights to the expression equation within the <kbd>linear_fits()</kbd> function to create an initial slope. The <kbd>points()</kbd> function adds our points with squares <span>to </span>the two points that are part of the target class and circles for the points that are not part of this class:</li>
</ol>
<pre style="padding-left: 60px">linear_fits(weights, to_add = FALSE)<br/>points(input[ , 1:2], pch = (output + 21))</pre>
<p style="padding-left: 60px">As we can tell from the following plot that is generated by the preceding code, this first line is extremely far from bisecting the <span>two classes:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-936 image-border" src="assets/0069b1d5-2df1-4760-bda8-77c6244fa22f.png" style="width:32.33em;height:27.42em;"/></p>
<ol start="4">
<li>Now, we will begin to update the weights by using the values from the corresponding input and output values. First, the weights are updated by the learning rate. The smaller this number is, the more gradual the changes will be. This is multiplied by the target class value minus the product of the result of the artificial neuron function, which again is either <kbd>0</kbd> or <kbd>1</kbd> since we are using the binary step activation function and the first input values. The <kbd>linear_fits()</kbd> function is then used again to draw one more line:</li>
</ol>
<pre style="padding-left: 60px">weights &lt;- weights + learning_rate * (output[1] - artificial_neuron(input[1, ])) * input[1, ]<br/>linear_fits(weights)</pre>
<p style="padding-left: 60px">Using the <kbd>linear_fits()</kbd> function, we have created a new line that is closer to bisecting the classes, and yet it is not yet completely dividing the points as we would like:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-937 image-border" src="assets/c91f7a32-4b3e-4c47-bad1-c8c3940700d4.png" style="width:30.75em;height:26.25em;"/></p>
<ol start="5">
<li>This same operation is repeated for the remainder of the input and output values. A different line type is used for the last plot because, as we will see, this line solves the problem and finds a slope that separates the two classes. The third line is drawn next:</li>
</ol>
<pre style="padding-left: 60px">weights &lt;- weights + learning_rate * (output[2] - artificial_neuron(input[2, ])) * input[2, ]<br/>linear_fits(weights)</pre>
<p class="mce-root" style="padding-left: 60px">Here, the third line completely overlaps the second line:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-938 image-border" src="assets/8a627969-1766-4e7f-a96c-943d88aa4127.png" style="width:33.17em;height:28.50em;"/></p>
<ol start="6">
<li class="mce-root">The next code is used to draw the fourth line:</li>
</ol>
<pre style="padding-left: 60px">weights &lt;- weights + learning_rate * (output[3] - artificial_neuron(input[3, ])) * input[3, ]<br/>linear_fits(weights)</pre>
<p class="mce-root" style="padding-left: 60px">The fourth line deviates further away from bisecting the points than the second or the third line:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-939 image-border" src="assets/3e80384b-d17b-4481-b876-950f7bc24a7e.png" style="width:34.50em;height:29.42em;"/></p>
<ol start="7">
<li class="mce-root">The final line is created using the following line of code:</li>
</ol>
<pre style="padding-left: 60px">weights &lt;- weights + learning_rate * (output[4] - artificial_neuron(input[4, ])) * input[4, ]<br/>linear_fits(weights, line_type = 2)</pre>
<p class="mce-root" style="padding-left: 30px">We see here that the dotted line successfully bisects the square points and separates them from the circular points:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-940 image-border" src="assets/7fb3f623-6478-46fa-a72a-93b6b038ac48.png" style="width:31.83em;height:27.17em;"/></p>
<p>In this minimal example, we can see what is happening when we fit a neural network. The model attempts to separate different classes of variables just like in other machine-learning models. In this case, during every iteration, the weights are updated depending on whether the neuron fires along with the constant change introduced by the learning rate value. Through this process, the goal is to reduce the error rate. In this case, we did not define a formal error rate as we could clearly see when the line successfully divided the classes. In the next example, we will step away from the underlying math and focus on optimizing a slightly more complex neural network using an open source dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a model with Wisconsin cancer data</h1>
                </header>
            
            <article>
                
<p>For this example, we will use the breast cancer dataset from the University of Wisconsin. Details on this dataset can be found at the UCI Machine Learning Repository at <a href="http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29">http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29</a>.</p>
<ol>
<li>The dataset can be loaded using the following lines of code:</li>
</ol>
<pre style="padding-left: 60px">library(tidyverse)<br/><br/>wbdc &lt;- readr::read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", col_names = FALSE)</pre>
<ol start="2">
<li>After loading the data, we will encode the target variable by converting the column from a character column with two character values that indicate whether or not there were signs of malignancy to a numeric data type holding binary values. For this type of neural network, we will need all values to be numeric, including the target variable:</li>
</ol>
<pre style="padding-left: 60px">wbdc &lt;- wbdc %&gt;%<br/>  dplyr::mutate(target = dplyr::if_else(X2 == "M", 1, 0)) %&gt;%<br/>  dplyr::select(-X2)</pre>
<ol start="3">
<li>Next, we will scale and standardize all of our predictor values. As we mentioned, all data needs to be numeric for the neural network, and by scaling and standardizing the data, we will increase performance by giving the activation functions a set of values that are all constrained within the same boundaries:</li>
</ol>
<pre style="padding-left: 60px">wbdc &lt;- wbdc %&gt;% dplyr::mutate_at(vars(-X1, -target), funs((. - min(.))/(max(.) - min(.)) ))</pre>
<ol start="4">
<li>Next, we will partition to train and test, just like in our machine learning example. We will use the ID column <span>in </span><kbd>X1</kbd> for splitting the data in this step; however, afterward, we can drop this column. Here, we will use a <kbd>tidyverse</kbd> approach to simplify the process:</li>
</ol>
<pre style="padding-left: 60px">train &lt;- wbdc %&gt;% dplyr::sample_frac(.8)<br/>test  &lt;- dplyr::anti_join(wbdc, train, by = 'X1')<br/><br/>test &lt;- test %&gt;% dplyr::select(-X1)<br/>train &lt;- train  %&gt;% dplyr::select(-X1)</pre>
<ol start="5">
<li>Our last data preparation step is to extract all the actual correct responses from the test data and then remove this column from the test dataset. This vector of values will be used to calculate performance after modeling:</li>
</ol>
<pre style="padding-left: 60px">actual &lt;- test$target<br/>test &lt;- test %&gt;% dplyr::select(-target)</pre>
<p style="padding-left: 60px">The data is now completely prepared and ready for modeling with a neural network.</p>
<ol start="6">
<li>Next, we need to create the formula syntax for the <kbd>neuralnet</kbd> package, which is a dependent variable <kbd>~</kbd>. This is similar to the syntax for fitting a linear model with R. All independent variables can be connected with the <kbd>+</kbd> sign between each one; however, when there are many independent variables, then it would be very tedious to write the name for every column, even in this example, where the column names are just X followed by a number. Fortunately, there is a way to expedite this process, which we will use in the following steps. First, we will get the names for all of the columns in our train set and then, using paste and collapse, we will create the string of independent variables to go on the other side of our formula from the dependent variable:</li>
</ol>
<pre style="padding-left: 60px">n &lt;- names(train)<br/>formula &lt;- as.formula(paste("target ~", paste(n[!n == "target"], collapse = " + ", sep = "")))</pre>
<ol start="7">
<li>With this set, we can now fit our model. In this case, we will keep the model fairly simple, only using a few of the arguments available for this function. Specifically, we include the formula that we just created, defining the dependent and independent variables. Next, we indicate that the model will be fit to the train data. Choosing the correct number of layers and units per layer involves trying a few combinations and comparing performance. In this case, we start with two layers containing about half as many units as there are variables. Lastly, we note that the activation function should be logistic, which is the sigmoid function, and that we are not performing a linear operation:</li>
</ol>
<pre style="padding-left: 60px">net &lt;- neuralnet::neuralnet(formula,<br/>                 data = train,<br/>                 hidden = c(15,15),<br/>                 linear.output = FALSE,<br/>                 act.fct = "logistic"<br/>                 )</pre>
<ol start="8">
<li>With the modeling process complete, we can now use our model to make predictions. With the <kbd>neuralnet</kbd> package, we use the <kbd>compute()</kbd> function to generate these prediction values:</li>
</ol>
<pre style="padding-left: 60px">prediction_list &lt;- neuralnet::compute(net, test)</pre>
<ol start="9">
<li>When we pass the model and the test dataset through the <kbd>compute()</kbd> function, we are given a list. The list contains details about the neurons within the model, along with the predicted values. In this case, we just want the predicted values, so we will pull these from the list. In addition, we will create a set of binary predictions. The binary predictions are created by changing values to <kbd>1</kbd>, if the predicted probability is greater than <kbd>0.5</kbd>; otherwise, the value is changed to a <kbd>0</kbd>. We will use each set of predictions for two different model evaluation methods:</li>
</ol>
<pre style="padding-left: 60px">predictions &lt;- as.vector(prediction_list$net.result)<br/>binary_predictions &lt;- dplyr::if_else(predictions &gt; 0.5, 1, 0)</pre>
<ol start="10">
<li>Using our binary predictions, we can easily calculate basic model accuracy—that is, we will sum the number of cases where the binary predicted value matches the actual value and divide that number by the total number of actual values:</li>
</ol>
<pre style="padding-left: 60px">sum(binary_predictions == actual)/length(actual)</pre>
<p style="padding-left: 60px">Here, we see that the accuracy is 92.98%, so our basic neural net has performed quite well on this data.</p>
<ol start="11">
<li>We can also look at the breakdown for this accuracy value by using a confusion matrix. The simplest way to produce a confusion matrix is to use the <kbd>confusionMatrix()</kbd> function, which is part of the <kbd>caret</kbd> package. This function requires a table containing the predicted valued and the actual values as an argument. In this case, we need to use our binary predictions as the results need to fit into one of four categories, and as such, levels of granularity are not permitted:</li>
</ol>
<pre style="padding-left: 60px">results_table &lt;- table(binary_predictions, actual)<br/>library(caret) <br/>caret::confusionMatrix(results_table)<br/><br/># Confusion Matrix and Statistics<br/># <br/># actual<br/># binary_predictions  0  1<br/># 0 67  2<br/># 1  1 44<br/># <br/># Accuracy : 0.9737         <br/># 95% CI : (0.925, 0.9945)<br/># No Information Rate : 0.5965         <br/># P-Value [Acc &gt; NIR] : &lt;2e-16         <br/># <br/># Kappa : 0.9451         <br/># Mcnemar's Test P-Value : 1              <br/># <br/># Sensitivity : 0.9853         <br/># Specificity : 0.9565         <br/># Pos Pred Value : 0.9710         <br/># Neg Pred Value : 0.9778         <br/># Prevalence : 0.5965         <br/># Detection Rate : 0.5877         <br/># Detection Prevalence : 0.6053         <br/># Balanced Accuracy : 0.9709         <br/># <br/># 'Positive' Class : 0        </pre>
<ol start="12">
<li>After calling this function, we see that we are provided with a two by two grid containing the results. The confusion matrix has categorized our predictions into the following four outcomes:</li>
</ol>
<ul>
<li style="padding-left: 30px"><strong>True positives</strong>: Values of <kbd>1</kbd> correctly predicted to be <kbd>1</kbd>. The actual test target variable contains the value we are predicting and we correctly predicted it.</li>
<li style="padding-left: 30px"><strong>Type I errors</strong>: Values of <kbd>0</kbd> incorrectly predicted to be values of <kbd>1</kbd>. The actual test target variable does not have the value we are predicting; however, we predicted that it will. Also referred to as a false positive.</li>
<li style="padding-left: 30px"><strong>Type II errors</strong>: Values of <kbd>1</kbd> incorrectly predicted to be values of <kbd>0</kbd>. The actual test target variable does have the value we are predicting; however, we predicted that it will not. Also referred to as a false negative.</li>
<li style="padding-left: 30px"><strong>True negatives</strong><span>: Values of <kbd>0</kbd> correctly predicted to be <kbd>0</kbd>. The actual test target variable does not contain the value we are predicting and we correctly predicted that it would not have it.</span></li>
</ul>
<p style="padding-left: 60px">It also includes a number of other statistical measures that are outside the scope of this chapter; however, we can note that the accuracy is included and the value matches the value that we just calculated ourselves.</p>
<p style="padding-left: 60px">In addition to using our binary prediction to calculate accuracy, we can also use our probabilities so that we take into account the level of certainty for each outcome. In order to measure performance using these values, we will use the AUC, or area under the curve, score. This compares the probabilities for true positive cases with the probabilities for false positive cases. The final result is a measure of the confidence that positive values are positive and that negative values are negative, or in this case, that negative values are not incorrectly labeled positive with high confidence.</p>
<ol start="13">
<li>To calculate the AUC score, we can use the <kbd>auc()</kbd> function, which is part of the <kbd>Metrics</kbd> package. The function takes two arguments—a vector of actual values and a vector of predicted probabilities that a record should be classified as the target variable based on the model's interpretation of the independent variable for that row:</li>
</ol>
<pre style="padding-left: 60px">library(Metrics)<br/>Metrics::auc(actual, predictions)</pre>
<p>The AUC score of 0.987 is even stronger than the accuracy score calculated previously.</p>
<p>This model is already working very well at solving the prediction task using this dataset; however, we will now try to add a backpropagation step and see if we can improve performance further.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Augmenting our neural network with backpropagation</h1>
                </header>
            
            <article>
                
<p>At this point, we have a working neural network. For this simple example, we will add one additional feature of neural networks that can improve performance, which is backpropagation. A neural network can learn to solve a task by multiplying the variable by values so that the variables are weighted as they pass through hidden layers. The backpropagation step allows the model to traverse back through layers and adjust the weights that were learned during previous steps:</p>
<ol>
<li>In practical terms, this step is quite straightforward to implement. We simply declare that we will use the backpropagation algorithm and indicate the learning rate, which controls how much the weights are adjusted. In general, this learning rate value should be very low.</li>
</ol>
<p style="padding-left: 60px">In the following example, we have to do the following:</p>
<ul>
<li style="padding-left: 60px">The <kbd>threshold</kbd> value and <kbd>stepmax</kbd> value have to be changed as the model failed to converge using the default values.</li>
<li style="padding-left: 60px">The <kbd>threshold</kbd> argument defines the value that the error rate must reach before the model stops and the <kbd>stepmax</kbd> <span>argument </span>defines the number of iterations the model will run before stopping.</li>
</ul>
<p style="padding-left: 60px">By changing these values, you can program the model to run longer and stop sooner, both of which will help if you run into an error when converging:</p>
<pre style="padding-left: 60px">bp_net &lt;- neuralnet::neuralnet(formula,<br/>                    data = train,<br/>                    hidden = c(15,15),<br/>                    linear.output = FALSE,<br/>                    act.fct = "logistic",<br/>                    algorithm = "backprop",<br/>                    learningrate = 0.00001,<br/>                    threshold = 0.3,<br/>                    stepmax = 1e6<br/>)</pre>
<ol start="2">
<li>After running this new version of the model, we can run the same steps again to assess performance. First, we will run <kbd>compute</kbd> on the new model to get new predictions. We will once again create a vector of probabilities and binary predictions, and as a first step, we will create the table of binary prediction values and actual values and pass this to the <kbd>confusionMatrix()</kbd> function. We will skip calculating the accuracy this time around as it is included in the output from the call to the <kbd>confusionMatrix()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">prediction_list &lt;- neuralnet::compute(bp_net, test)<br/>predictions &lt;- as.vector(prediction_list$net.result)<br/>binary_predictions &lt;- dplyr::if_else(predictions &gt; 0.5, 1, 0)<br/>results_table &lt;- table(binary_predictions, actual)<br/>caret::confusionMatrix(results_table)</pre>
<ol start="3">
<li>Our accuracy has improved, increasing from 92.98% to 94.74%. Let's now check our AUC score. Again, we simply pass the actual values and predicted probabilities to the <kbd>auc()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">Metrics::auc(actual, predictions)</pre>
<p style="padding-left: 60px">Our AUC score has improved, increasing from 0.987 to 0.993, so we can see that backpropagation does improve model performance.</p>
<p style="padding-left: 60px">That being said, what exactly is happening during this step?</p>
<ul>
<li style="padding-left: 30px">The backpropagation step takes the derivative of the error rate and uses this to update weights based on results.</li>
<li style="padding-left: 30px">The derivative is just the rate at which the current weights impact the error rate. So if the derivative rate is <kbd>7</kbd>, then changing the weights by a single unit will result in a change to the error rate that is 7 times larger.</li>
<li style="padding-left: 30px">Using just a feedforward neural network, we can update the initial weights based on the final derivative value; however, using backpropagation, we can update the weights at every neuron.</li>
<li style="padding-left: 30px">Using information about how previous changes have impacted the derivative, this step either increases or decreases the weights.</li>
<li style="padding-left: 30px">The learning rate is applied so that changes are never dramatic but rather smooth and gradual. This process can continue until the error rate is minimized.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned that deep learning is differentiated from other machine-learning algorithms because of the use of multiple hidden layers. This network of hidden layers, which are composed of artificial neurons, was designed to mimic the way our brain processes input signals to interpret our environment. The units within the hidden layers take in all the independent variables and apply some weights to these variables. In this way, each neuron classifies the combination of input values in different ways.</p>
<p>From understanding the architecture of this type of machine learning from a high level, we then took a deeper dive into the actual process of converting the input to predictions using this approach. We discussed the various activation functions that act as the gate for every neuron, determining whether a signal should be passed to the next layer. We then built two feedforward neural networks—one using base R for a better understanding of what is happening and another using the <kbd>neuralnet</kbd> package on a larger dataset. Lastly, we applied the backpropagation step to further improve our model.</p>
<p>As stated, the artificial neural network is the fundamental building block for more complex deep learning, and now that we have this understanding, we will move on to creating convolutional neural networks for image recognition in the next chapter.</p>


            </article>

            
        </section>
    </body></html>