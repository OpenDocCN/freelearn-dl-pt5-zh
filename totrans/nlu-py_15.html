<html><head></head><body>
		<div id="_idContainer135">
			<h1 id="_idParaDest-237" class="chapter-number"><a id="_idTextAnchor262"/>15</h1>
			<h1 id="_idParaDest-238"><a id="_idTextAnchor263"/>Summary and Looking to the Future</h1>
			<p><a id="_idTextAnchor264"/><a id="_idTextAnchor265"/>In this chapter, we will get an overview of the book and a look into the future. We will discuss where there is potential for improvement in performance as well as faster training, more challenging applications, and future directions for practical systems <span class="No-Break">and research.</span></p>
			<p>We will cover the following topics in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Overview of <span class="No-Break">the book</span></li>
				<li>Potential for better accuracy and <span class="No-Break">faster training</span></li>
				<li>Other areas <span class="No-Break">for improvement</span></li>
				<li>Applications that are beyond the current state of <span class="No-Break">the art</span></li>
				<li><span class="No-Break">Future directions</span></li>
			</ul>
			<p>The first section of this chapter is an overall summary of the topics covered in <span class="No-Break">this book.</span></p>
			<h1 id="_idParaDest-239"><a id="_idTextAnchor266"/>Overview of the book</h1>
			<p>This book has covered the <a id="_idIndexMarker1191"/>basics of <strong class="bold">natural language understanding</strong> (<strong class="bold">NLU</strong>), the technology that enables computers to process natural language and apply the results to a wide variety of <span class="No-Break">practical applications.</span></p>
			<p>The goal of this book has been to provide a solid grounding in NLU using the Python programming language. This grounding will enable you not only to select the right tools and software libraries for developing your own applications but will also provide you with the background you need to independently make use of the many resources available on the internet. You can use these resources to expand your knowledge and skills as you take on more advanced projects and to keep up with the many new tools that are becoming available as this rapidly advancing technology continues <span class="No-Break">to improve.</span></p>
			<p>In this book, we’ve discussed three <span class="No-Break">major topics:</span></p>
			<ul>
				<li>In <em class="italic">Part 1</em>, we covered background information and how to <span class="No-Break">get started</span></li>
				<li>In <em class="italic">Part 2</em>, we went over Python tools and techniques for accomplishing <span class="No-Break">NLU tasks</span></li>
				<li>In <em class="italic">Part 3</em>, we discussed some practical considerations having to do with managing <span class="No-Break">deployed applications</span></li>
			</ul>
			<p>Throughout this book, we have taken a step-by-step approach through the typical stages of an NLU<a id="_idIndexMarker1192"/> project, starting from initial ideas through development, testing, and finally, to fine-tuning a deployed application. We can see these steps graphically in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/B19005_15_01.jpg" alt="Figure 15.1 – The NLU project life cycle as covered in this book"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.1 – The NLU project life cycle as covered in this book</p>
			<p>In <em class="italic">Part 1</em>, you were introduced to the general topic of NLU and the kinds of tasks to which it can <span class="No-Break">be applied.</span></p>
			<p>In <em class="italic">Part 2</em>, we started by covering foundational topics that support the most successful NLU applications, such as software development tools, data, visualization, and approaches to representing NLU data. The second general topic that we covered in <em class="italic">Part 2</em> was a set of five different approaches to processing language, including rules, traditional machine learning techniques, neural networks, transformers, and unsupervised learning. These topics are covered in the five chapters from <a href="B19005_08.xhtml#_idTextAnchor159"><span class="No-Break"><em class="italic">Chapter 8</em></span></a> through <a href="B19005_12.xhtml#_idTextAnchor217"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, which covered the basics of <a id="_idIndexMarker1193"/>NLU algorithms. Mastering this material will give you the background that you need to continue exploring NLU algorithms beyond the topics covered in this book. The final topic in <em class="italic">Part 2</em> was the very important subject of evaluation. Evaluation is critically important both for practical NLU deployments and for successful academic research. Our review of evaluation in <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, covers a variety of the most important NLU evaluation tools. With this background, you should now be prepared to evaluate your own <span class="No-Break">NLU projects.</span></p>
			<p>Finally, in <em class="italic">Part 3</em>, we turned to the topic of systems in action and focused (particularly in <a href="B19005_14.xhtml#_idTextAnchor248"><span class="No-Break"><em class="italic">Chapter 14</em></span></a> on approaches to improving the performance of systems both before and <span class="No-Break">after deployment.</span></p>
			<p>If you continue to work in the field of NLU, you will find that there are still many challenges, despite the fact that recent advances <a id="_idIndexMarker1194"/>in <strong class="bold">large language models</strong> (<strong class="bold">LLMs</strong>) have dramatically improved the performance of NLU systems on <span class="No-Break">many tasks.</span></p>
			<p>We will look at some of these challenges in the next two sections, starting with the most important areas of improvement – better accuracy and faster training – followed by a section on other areas <span class="No-Break">of improvement.</span></p>
			<h1 id="_idParaDest-240"><a id="_idTextAnchor267"/>Potential for improvement – better accuracy and faster training</h1>
			<p>At the beginning of <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, we listed several criteria that can be used to evaluate NLU systems. The <a id="_idIndexMarker1195"/>one that we usually think of first is accuracy – that is, given a specific input, did the system provide the right answer? Although in a particular application, we eventually may decide to give another criterion priority over accuracy, accuracy <span class="No-Break">is essential.</span></p>
			<h2 id="_idParaDest-241"><a id="_idTextAnchor268"/>Better accuracy</h2>
			<p>As we saw in <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, even our best-performing<a id="_idIndexMarker1196"/> system, the large <strong class="bold">Bidirectional Encoder Representations from Transformers</strong> (<strong class="bold">BERT</strong>) model, only achieved an F<span class="subscript">1</span> score of <em class="italic">0.85</em> on the movie review dataset, meaning that 15% of its classifications were incorrect. State-of-the-art LLM-based research systems<a id="_idIndexMarker1197"/> currently report an accuracy of <em class="italic">0.93</em> on this dataset, which still means that the system makes many errors (SiYu Ding, Junyuan Shang, Shuohuan Wang, Yu Sun, Hao Tian, Hua Wu, and Haifeng Wang. 2021. <em class="italic">ERNIE-Doc: A Retrospective Long-Document Modeling Transformer</em>), so we can see that there is still much room for <span class="No-Break">accuracy improvements.</span></p>
			<p>LLMs <a id="_idIndexMarker1198"/>represent the state of the art in NLU. However, there have been few formal studies of the accuracy of the most recent LLMs, so it is difficult to quantify how good they are. One study of a fairly challenging medical information task where physicians evaluated the accuracy of ChatGPT’s answers found that ChatGPT answers were considered to be largely accurate overall, receiving a mean score of <em class="italic">4.6</em> out of <em class="italic">6</em> (Johnson, D., et al. (2023). <em class="italic">Assessing the Accuracy and Reliability of AI-Generated Medical Responses: An Evaluation of the Chat-GPT Model</em>. Research Square, rs.3.rs-2566942. <a href="https://doi.org/10.21203/rs.3.rs-2566942/v1">https://doi.org/10.21203/rs.3.rs-2566942/v1</a>). However, the system still made many errors, and the authors cautioned that it was important for physicians to review medical advice supplied by ChatGPT or, in general, any LLMs at the current state of <span class="No-Break">the art.</span></p>
			<p>Better accuracy will always be a goal in NLU. Achieving better accuracy in future systems will include developing larger pretrained models as well as developing more effective fine-tuning techniques. In addition, there is a significant amount of work to be done in extending the current high performance of LLMs for the most widely studied languages to less <span class="No-Break">well-studied languages.</span></p>
			<h2 id="_idParaDest-242"><a id="_idTextAnchor269"/>Faster training</h2>
			<p>By working through some of the<a id="_idIndexMarker1199"/> exercises in earlier chapters, you have found that training NLU models from scratch or fine-tuning an LLM did not take more than a few hours of computer time. For the purposes of this book, we intentionally selected smaller datasets so that you could get feedback from the training process more quickly. However, even larger problems that you may want to address in a practical setting should not take more than a few days of training time. On the other hand, training pretrained LLMs can take a very long time. One estimate for the training time for GPT-3 was that it took 355 GPU years to train on the 300 billion token training dataset. In practice, the calendar time required was reduced by running the training on multiple<a id="_idIndexMarker1200"/> GPUs in parallel (<a href="https://lambdalabs.com/blog/demystifying-gpt-3">https://lambdalabs.com/blog/demystifying-gpt-3</a>). Still, this training does involve tremendous amounts of computing power, along with the <span class="No-Break">associated costs.</span></p>
			<p>Since most pretrained models are trained by large organizations with extensive computing resources rather than by smaller organizations or researchers, long training times for large models don’t directly affect most of us because we will be using the pretrained models developed by large organizations. However, these long training times do affect us indirectly because long training times mean that it will take longer for new and improved <a id="_idIndexMarker1201"/>models to be released for <span class="No-Break">general use.</span></p>
			<p>In addition to better accuracy and faster training times, there are other areas where NLU technology can be improved. We will review some of these in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor270"/>Other areas for improvement</h2>
			<p>The areas for improvement that we’ll review in this section are primarily related to making NLU technology more practical in various ways, such as speeding up development and decreasing the number of computer resources needed during development and at runtime. These topics include smaller models, more explainability, and smaller amounts of <span class="No-Break">fine-tuning data.</span></p>
			<h3>Smaller models</h3>
			<p>The BERT models we <a id="_idIndexMarker1202"/>looked at in <a href="B19005_11.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> and <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, were relatively small. The reason for choosing these models was so that they could be downloaded and fine-tuned in a relatively short amount of time. However, as a rule of thumb, large models will be more accurate than smaller models. But we can’t always take advantage of large models because some models are too large to be fine-tuned on a single GPU, as pointed out on the TensorFlow site (<a href="https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb#scrollTo=dX8FtlpGJRE6">https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb#scrollTo=dX8FtlpGJRE6</a>). Because the larger models have better accuracy, it would be very helpful if high-accuracy performance could be obtained with smaller models. In addition, there are many situations where large models will not fit on resource-constrained devices such as mobile phones or even smartwatches. For those <a id="_idIndexMarker1203"/>reasons, decreasing the size of models is an important goal in <span class="No-Break">NLU research.</span></p>
			<h3>Less data required for fine-tuning</h3>
			<p>For most NLU applications that use pretrained <a id="_idIndexMarker1204"/>models, the pretrained model needs to be fine-tuned with application-specific data. We covered this process in <a href="B19005_11.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> and <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>. Clearly, reducing the amount of data required to fine-tune the system results in a reduction in the development time for the fine-tuned system. For example, in its discussion of the process of fine-tuning GPT-3, OpenAI states, “<em class="italic">The more training examples you have, the better. We recommend having at least a couple hundred examples. In general, we’ve found that each doubling of the dataset size leads to a linear increase in model quality</em>” (<a href="https://platform.openai.com/docs/guides/fine-tuning">https://platform.openai.com/docs/guides/fine-tuning</a>). As we learned in <a href="B19005_05.xhtml#_idTextAnchor107"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, the process of finding and annotating data can be time-consuming and expensive, and it is clearly desirable to minimize <span class="No-Break">this effort.</span></p>
			<h3>Explainability</h3>
			<p>For the most part, a result from an <a id="_idIndexMarker1205"/>NLU system based on machine learning will simply be a number, such as a probability that a text falls into one of the categories on which the model was trained. We don’t have an easy way to understand how the system came up with that answer, whether the answer is correct or incorrect. If the answer is incorrect, we can try to improve the model by adding more data, adjusting the hyperparameters, or using some of the other techniques that we reviewed in <a href="B19005_14.xhtml#_idTextAnchor248"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, but it's hard to understand exactly why the system came up with the <span class="No-Break">wrong answer.</span></p>
			<p>In contrast, if a rule-based system such as those we went over in <a href="B19005_08.xhtml#_idTextAnchor159"><span class="No-Break"><em class="italic">Chapter 8</em></span></a> makes an error, it can normally be traced back to an incorrect rule, which can be fixed. However, since nearly all current systems are based on machine learning approaches rather than rules, it is very difficult to understand how they arrive at the answers that they do. Nevertheless, it is often important for users to understand how a system came up with a result. If the users don’t understand how the system came up with an answer, they might not trust the system. If a system gives a wrong answer or even a correct answer that the user doesn’t understand, it can undermine user confidence in the system. For that reason, explainability in <a id="_idIndexMarker1206"/>NLU and in AI, in general, is an<a id="_idIndexMarker1207"/> important research topic. You can read more about this topic <span class="No-Break">at </span><a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"><span class="No-Break">https://en.wikipedia.org/wiki/Explainable_artificial_intelligence</span></a><span class="No-Break">.</span></p>
			<h3>Timeliness of information</h3>
			<p>In <a href="B19005_14.xhtml#_idTextAnchor248"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, we discussed how changes in the deployment context can result in system errors. The introduction of new product names, new movies, or even <a id="_idIndexMarker1208"/>significant news events can lead to the system not knowing the answer to a user’s question or even giving the wrong answer. Because LLMs take so long to train, they are especially vulnerable to making errors due to a change in the <span class="No-Break">deployment context.</span></p>
			<p>For example, the ChatGPT system has a knowledge cutoff date of September 2021, which means that it doesn’t have any knowledge of events that occurred after that. Because of this, it can make mistakes like the one shown in <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.2</em>, which states that the current monarch of the United Kingdom is Elizabeth II. This was true in September 2021, but it is no <span class="No-Break">longer true.</span></p>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/B19005_15_02.jpg" alt="Figure 15.2 – ChatGPT answer to “who is the current monarch of the united kingdom”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.2 – ChatGPT answer to “who is the current monarch of the united kingdom”</p>
			<p>Although the <a id="_idIndexMarker1209"/>ChatGPT system acknowledges that its information may be out of date, this lack of timeliness can lead to errors if something changes in the deployment context. If you are developing your own application and something changes in the deployment context, you can either retrain the system from scratch with the new data or add new data to your existing model. However, if you are using a cloud-based LLM, you should be aware that the information it provides can be out of date. Note that this cutoff period can vary between different LLMs. For example, the Google Bard system was able to correctly answer the question in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
			<p>If your application uses an LLM and requires access to accurate time-dependent information, you should verify that the system you’re using is being kept up to date by <span class="No-Break">its developers.</span></p>
			<p>The next section talks about a few blue sky applications that may be possible in <span class="No-Break">the future.</span></p>
			<h1 id="_idParaDest-244"><a id="_idTextAnchor271"/>Applications that are beyond the current state of the art</h1>
			<p>This section talks about several applications that are not yet possible, but that are theoretically feasible. In some cases, they could probably be achieved if the right training data and computing resources were available. In other cases, they might require some new algorithmic insights. In all of these examples, it is very interesting to think about how these and other futuristic applications might <span class="No-Break">be accomplished.</span></p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor272"/>Processing very long documents</h2>
			<p>Current LLMs have relatively small<a id="_idIndexMarker1210"/> limits on the length of documents (or prompts) they can process. For example, GPT-4 <a id="_idIndexMarker1211"/>can only handle texts of up to 8,192 tokens (<a href="https://platform.openai.com/docs/models/gpt-4">https://platform.openai.com/docs/models/gpt-4</a>), which is around 16 single-spaced pages. Clearly, this means that many existing documents can’t be fully analyzed with these cloud<a id="_idIndexMarker1212"/> systems. If you are doing a typical classification task, you can train your own model, for example, with a <strong class="bold">Term frequency-inverse document frequency</strong> (<strong class="bold">TF-IDF</strong>) representation, but this is not possible with a <span class="No-Break">pretrained model.</span></p>
			<p>In that case, the documents can be as long as you like, but you will lose the advantages of LLMs. Research systems such as Longformer have been able to process much longer documents through more efficient use of computational resources. If you have a use case for processing long documents, it would be worth looking into some of these <span class="No-Break">research systems.</span></p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor273"/>Understanding and creating videos</h2>
			<p>To understand videos, a system would need to be able to interpret both the video and audio streams and<a id="_idIndexMarker1213"/> relate them to each other. If the system learns someone’s name in the early part of the video and that character appears in a later part of the video, it should be able to name the person based on recognizing the image of the character. It could then do tasks such as transcribing the script of a movie by simply watching it, complete with notations like “Character X smiles”. This is not a very difficult task for humans, who are quite good at recognizing a person that they’ve seen before, but it would be very difficult for automated systems. While they are quite good at identifying people in images, they are less capable of identifying people in videos. In contrast to understanding videos, generating videos seems to be an easier task. For example, there are currently systems available that generate videos from text, such as a system developed by Meta (<a href="https://ai.facebook.com/blog/generative-ai-text-to-video/">https://ai.facebook.com/blog/generative-ai-text-to-video/</a>), although the videos don’t yet look <span class="No-Break">very good.</span></p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor274"/>Interpreting and generating sign languages</h2>
			<p>One application of <a id="_idIndexMarker1214"/>understanding videos would be to understand sign languages such as American Sign Language and translate them into spoken languages. Combined with the reverse process of translating spoken language into sign language, this kind of technology could greatly simplify communication between signers and speakers of spoken languages. There have been some exploratory studies of interpreting and generating <span class="No-Break">sign languages.</span></p>
			<p>For example, the work on <a href="https://abdulhaim.github.io/6.S198-Assignments/final_project.html">https://abdulhaim.github.io/6.S198-Assignments/final_project.html</a> describes an approach to interpreting Argentinian Sign Language using <strong class="bold">Convolutional Neural Networks</strong> (<strong class="bold">CNNs</strong>). Although this is an interesting proof of concept, it only works <a id="_idIndexMarker1215"/>with 64 signs from Argentinian Sign Language. In fact, there are thousands of signs used in actual sign languages, so handling 64 signs is only a small demonstration of the possibility of automatically interpreting <span class="No-Break">sign languages.</span></p>
			<p>In addition, this research only used hand positions to recognize signs, while, in fact, signs are also distinguished by other body positions. More work needs to be done to demonstrate practical automatic sign language interpretation. This would be greatly aided by the availability of more sign <span class="No-Break">language datasets.</span></p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor275"/>Writing compelling fiction</h2>
			<p>If you have experimented with<a id="_idIndexMarker1216"/> ChatGPT or other LLMs, you may have noticed that the writing style is rather bland and boring. This is because it’s based on text from the internet and other existing sources and there is no way for it to be creative beyond the data that it is trained on. On the other hand, compelling fiction is unique and often contains insights and verbal images that have never appeared in <span class="No-Break">writing before.</span></p>
			<p>As an example, let’s look at an excerpt from one of the great poems of the English language, To a Skylark, by Percy Bysshe Shelley, which can be seen in <span class="No-Break"><em class="italic">Figure 15</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer133" class="IMG---Figure">
					<img src="image/B19005_15_03.jpg" alt="Figure 15.3 – An excerpt from “To a Skylark”, a poem by Percy Bysshe Shelley (1820)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.3 – An excerpt from “To a Skylark”, a poem by Percy Bysshe Shelley (1820)</p>
			<p>This poem includes novel figures of speech such as the simile that compares a bird to <em class="italic">a cloud of fire</em> and uses the metaphor <em class="italic">the blue deep</em> for the sky, which are probably unique <span class="No-Break">in literature.</span></p>
			<p>Compare this to the <a id="_idIndexMarker1217"/>poem generated by ChatGPT in <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.4</em>. When prompted to write a poem about a skylark flying in the sky, the result seems flat and unoriginal compared to the Shelley poem and includes cliches such as <em class="italic">boundless sky</em> and <em class="italic">ascends </em><span class="No-Break"><em class="italic">on high</em></span><span class="No-Break">.</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer134" class="IMG---Figure">
					<img src="image/B19005_15_04.jpg" alt="Figure 15.4 – ChatGPT poem about a skylark"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.4 – ChatGPT poem about a skylark</p>
			<p>Let’s think about how we might train an LLM to learn how to generate good poetry or interesting fiction. If we follow the standard NLU development paradigm of learning a model from training data, for an NLU system to write compelling fiction, we would need a dataset consisting of text examples of compelling and engaging writing and other examples of writing that are not compelling or engaging. Alternatively, we might be able to identify other features of compelling writing (use verbs, avoid passive voice, etc.) that could be used to train systems to evaluate writing or to produce good writing. You can understand how far we are from this<a id="_idIndexMarker1218"/> kind of application by thinking about what an NLU system would need to be able to do to write insightful book reviews. It would have to be familiar with the author’s other books, other books in a similar genre, any relevant historical events mentioned in the book, and even the author’s biography. Then it would have to be able to pull all this knowledge together into a concise analysis of the book. All of this seems <span class="No-Break">quite difficult.</span></p>
			<p>The next section will look at applications that are targets of current research and are much closer to realization than the ones we’ve just reviewed. We are likely to see advances in these kinds of applications in the next couple <span class="No-Break">of years.</span></p>
			<h1 id="_idParaDest-249"><a id="_idTextAnchor276"/>Future directions in NLU technology and research</h1>
			<p>While the<a id="_idIndexMarker1219"/> recent improvements in NLU technology based on transformers and LLMs, which we reviewed in <a href="B19005_11.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, have resulted in very impressive capabilities, it is important to point out that there are many topics in NLU that are far from solved. In this section, we will look at some of the most active research areas – extending NLU to new languages, speech-to-speech translation, multimodal interaction, and <span class="No-Break">avoiding bias.</span></p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor277"/>Quickly extending NLU technologies to new languages</h2>
			<p>A <a id="_idIndexMarker1220"/>precise count of the number of currently spoken languages is difficult to obtain. However, according to <em class="italic">WorldData.info</em>, there are currently about 6,500 languages spoken throughout the world (<a href="https://www.worlddata.info/languages/index.php#:~:text=There%20are%20currently%20around%206%2C500,of%20Asia%2C%20Australia%20and%20Oceania">https://www.worlddata.info/languages/index.php#:~:text=There%20are%20currently%20around%206%2C500,of%20Asia%2C%20Australia%20and%20Oceania</a>). Some languages, such as Mandarin, English, Spanish, and Hindi, are spoken by many millions of people, while other languages are spoken by very few people and these languages are even in danger of dying out (for example, you can see a list of the endangered languages of North America<a id="_idIndexMarker1221"/> alone <span class="No-Break">at </span><a href="https://en.wikipedia.org/wiki/List_of_endangered_languages_in_North_America"><span class="No-Break">https://en.wikipedia.org/wiki/List_of_endangered_languages_in_North_America</span></a><span class="No-Break">).</span></p>
			<p>Languages with many millions of speakers tend to be more economically important than languages with few speakers, and as a consequence, NLU technology for those languages is generally much more advanced than that for languages with few speakers. If you recall from our discussion of LLMs in <a href="B19005_11.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, training an LLM such as BERT or GPT-3 for one language is a very expensive and time-consuming process that requires enormous amounts of text data. It would be impractical for this training process to be carried out for thousands of languages. For that reason, researchers have looked into adapting LLMs used for widely spoken languages to less widely <span class="No-Break">spoken languages.</span></p>
			<p>This is a very <a id="_idIndexMarker1222"/>active research area that presents many challenges to NLU technology. One challenge, for example, is how to keep the original language from being forgotten when its language model is adapted to a new language – a process called <span class="No-Break"><strong class="bold">catastrophic forgetting</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Citation</p>
			<p class="callout">This is an example of a recent research paper on this topic that you can read for more insight into the problem of adapting LLMs to <span class="No-Break">new languages:</span></p>
			<p class="callout">Cahyawijaya, S., Lovenia, H., Yu, T., Chung, W., &amp; Fung, P. (2023). <em class="italic">Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction</em>. arXiv preprint <span class="No-Break">arXiv:2305.13627. </span><a href="https://arxiv.org/abs/2305.13627"><span class="No-Break">https://arxiv.org/abs/2305.13627</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor278"/>Real-time speech-to-speech translation</h2>
			<p>Anyone <a id="_idIndexMarker1223"/>who has traveled to a foreign country whose language they do not know, or whose language they do not know well, has probably found communication very frustrating. Looking up words or even phrases in handheld apps or paper dictionaries is slow and can be inaccurate. A much better solution would be speech-to-speech translation. Speech-to-speech translation technology listens to speech in one language, translates it to another language, and the system speaks the output in a second language, which would be much faster than typing words into a <span class="No-Break">mobile app.</span></p>
			<p>The base technologies underlying <strong class="bold">speech-to-speech translation</strong> are<a id="_idIndexMarker1224"/> actually fairly advanced. For example, Microsoft Cognitive Services offers a<a id="_idIndexMarker1225"/> speech-to-speech translation service (<a href="https://azure.microsoft.com/en-us/products/cognitive-services/speech-translation/">https://azure.microsoft.com/en-us/products/cognitive-services/speech-translation/</a>) with support for over 30 languages. The number of available language pairs continues to increase – for example, Speechmatics<a id="_idIndexMarker1226"/> offers a translation service for 69 language <span class="No-Break">pairs (</span><a href="https://www.speechmatics.com/product/translation"><span class="No-Break">https://www.speechmatics.com/product/translation</span></a><span class="No-Break">).</span></p>
			<p>However, most of these services do their processing in the cloud. Because one of the most important use cases for speech-to-speech translation is for travel, users may not want to use a service that requires access to the cloud. They may not have a good internet connection, or they may not want to pay for data while traveling. It is much more difficult to translate speech offline, without sending it to the cloud, as mobile devices have far fewer computing resources than the cloud. The results are less accurate and not nearly as many languages are supported. For example, the<a id="_idIndexMarker1227"/> Apple Translate app (<a href="https://apps.apple.com/app/translate/id1514844618">https://apps.apple.com/app/translate/id1514844618</a>) claims to support 30 languages but the reviews are very low, especially for offline use. There is significant room for improvement in the technology for offline <span class="No-Break">speech-to-speech translation.</span></p>
			<h2 id="_idParaDest-252"><a id="_idTextAnchor279"/>Multimodal interaction</h2>
			<p><strong class="bold">Multimodal interaction</strong> is a type <a id="_idIndexMarker1228"/>of user-system interaction where the user interacts with a computer system in multiple ways (<em class="italic">modalities</em>) in addition to language. For example, multimodal interaction<a id="_idIndexMarker1229"/> could include camera input that allows the system to interpret facial expressions in addition to speech input. This would let the system read the user’s body language to detect emotions such as happiness or confusion in addition to interpreting what the user says. As well as understanding multimodal user inputs, a multimodal system can also produce images, animations, videos, and graphics in addition to language in order to respond to <span class="No-Break">users’ questions.</span></p>
			<p class="callout-heading">Citation</p>
			<p class="callout">Multimodal interaction has been used extensively in research projects such as <span class="No-Break">the following:</span></p>
			<p class="callout">António Teixeira, Annika Hämäläinen, Jairo Avelar, Nuno Almeida, Géza Németh, Tibor Fegyó, Csaba Zainkó, Tamás Csapó, Bálint Tóth, André Oliveira, Miguel Sales Dias, <em class="italic">Speech-centric Multimodal Interaction for Easy-to-access Online Services – A Personal Life Assistant for the Elderly</em>, Procedia Computer Science, Volume 27, 2014, Pages 389-397, ISSN <span class="No-Break">1877-0509, </span><a href="https://doi.org/10.1016/j.procs.2014.02.043"><span class="No-Break">https://doi.org/10.1016/j.procs.2014.02.043</span></a><span class="No-Break">.</span></p>
			<p>However, multimodal interaction is far from widespread in practical applications. This may be due in part to the relative scarcity of training data for multimodal systems since training multimodal systems requires data for all the modalities being used in the system, not just language data. For example, if we wanted to develop an application that used a combination of facial expression recognition and NLU to understand users’ emotions, we would need a video dataset annotated with both facial expressions and NLU categories. There are a few existing datasets with this kind of information – for example, the datasets listed at <a href="https://www.datatang.ai/news/60">https://www.datatang.ai/news/60</a> – but they are not nearly as abundant as the text datasets that we’ve been working with throughout this book. Multimodal interaction is a very interesting topic, and the availability of additional data will certainly stimulate some future <span class="No-Break">groundbreaking work.</span></p>
			<h2 id="_idParaDest-253"><a id="_idTextAnchor280"/>Detecting and correcting bias</h2>
			<p>The <a id="_idIndexMarker1230"/>training data for LLMs is based on existing text, primarily from the web. This text, in many cases, reflects cultural biases that we would not like to perpetuate in our NLU systems. It is easy to find this bias in current LLMs. For example, the article <em class="italic">ChatGPT insists that doctors are male and nurses female</em>, by Suzanne Wertheim, shows many examples of ChatGPT assuming that people in certain professions are male or female (<a href="https://www.worthwhileconsulting.com/read-watch-listen/chatgpt-insists-that-doctors-are-male-and-nurses-female">https://www.worthwhileconsulting.com/read-watch-listen/chatgpt-insists-that-doctors-are-male-and-nurses-female</a>). This problem has been the topic of considerable research and is far <span class="No-Break">from solved.</span></p>
			<p class="callout-heading">Citation</p>
			<p class="callout">You can find out more about how bias has been addressed in the following <span class="No-Break">survey article:</span></p>
			<p class="callout">Alfonso, L. (2021). <em class="italic">A Survey on Bias in Deep NLP</em>. Applied Sciences, 11(7), <span class="No-Break">3184. </span><a href="https://doi.org/10.3390/app11073184"><span class="No-Break">https://doi.org/10.3390/app11073184</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-254"><a id="_idTextAnchor281"/>Summary</h1>
			<p>In this chapter, we have summarized the previous chapters in the book, reviewed some areas where NLU technology still faces challenges, and talked about some directions where it could improve in the future. NLU is an extremely dynamic and fast-moving field, and it will clearly continue to develop in many exciting directions. With this book, you have received foundational information about NLU that will enable you to decide not only how to build NLU systems for your current applications but also to take advantage of technological advances as NLU continues to evolve. I hope you will be able to build on the information in this book to create innovative and useful applications that use NLU to solve future practical as well as <span class="No-Break">scientific problems.</span></p>
			<h1 id="_idParaDest-255"><a id="_idTextAnchor282"/>Further reading</h1>
			<p>SiYu Ding, Junyuan Shang, Shuohuan Wang, Yu Sun, Hao Tian, Hua Wu, and Haifeng Wang. 2021. <em class="italic">ERNIE-Doc: A Retrospective Long-Document Modeling Transformer</em>. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2914–2927, Online. Association for <span class="No-Break">Computational Linguistics</span></p>
			<p>Beltagy, I., Peters, M.E., &amp; Cohan, A. (2020). <em class="italic">Longformer: The Long-Document Transformer</em>. <span class="No-Break">arXiv, abs/2004.05150</span></p>
		</div>
	</body></html>