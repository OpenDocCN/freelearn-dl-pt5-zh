<html><head></head><body>
		<div id="_idContainer077">
			<h1 id="_idParaDest-56"><em class="italic"><a id="_idTextAnchor057"/>Chapter 2</em>: Exploring and Cleaning Up Data with fastai</h1>
			<p>In the previous chapter, we got started with the fastai framework by setting up its coding environment, working through a concrete application example (MNIST), and investigating two frameworks with different relationships to fastai: PyTorch and Keras. In this chapter, we are going to dive deeper into an important aspect of fastai: <strong class="bold">ingesting</strong>, <strong class="bold">exploring</strong>, and <strong class="bold">cleaning up data</strong>. In particular, we are going to explore a selection of the datasets that are curated by fastai.</p>
			<p>By the end of this chapter, you will be able to describe the complete set of curated datasets that fastai supports, use the facilities of fastai to examine these datasets, and clean up a dataset to eliminate missing and non-numeric values.</p>
			<p>Here are the recipes that will be covered in this chapter:</p>
			<ul>
				<li>Getting the complete set of <em class="italic">oven-ready</em> fastai datasets</li>
				<li>Examining tabular datasets with fastai</li>
				<li>Examining text datasets with fastai</li>
				<li>Examining image datasets with fastai </li>
				<li>Cleaning up raw datasets with fastai</li>
			</ul>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor058"/>Technical requirements</h1>
			<p>Ensure that you have completed the setup sections in <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, and that you have a working Gradient instance or Colab setup. Ensure that you have cloned the repository for this book (<a href="https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook">https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook</a>) and have access to the <strong class="source-inline">ch2</strong> folder. This folder contains the code samples that will be described in this chapter.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor059"/>Getting the complete set of oven-ready fastai datasets</h1>
			<p>In <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, you encountered the MNIST dataset and saw how easy it was to make this dataset available to train a fastai deep learning model. You were able to train the<a id="_idIndexMarker102"/> model without needing to worry about the location of the dataset or its structure (apart from the names of the folders containing the training and validation datasets). You were able to examine elements of the dataset conveniently. </p>
			<p>In this section, we'll take a closer look at the complete set of datasets that fastai curates and explain how you can get additional information about these datasets.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor060"/>Getting ready</h2>
			<p>Ensure you have followed the steps in <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, so that you have a fastai environment set up. Confirm that you can open the <strong class="source-inline">fastai_dataset_walkthrough.ipynb</strong> notebook in the <strong class="source-inline">ch2</strong> directory of your cloned repository.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor061"/>How to do it…</h2>
			<p>In this section, you will be running through the <strong class="source-inline">fastai_dataset_walkthrough.ipynb</strong> notebook, as well as the fastai dataset documentation, so that you understand the datasets that fastai curates. Once you have the notebook open in your fastai environment, complete the following steps:</p>
			<ol>
				<li>Run the first three cells of the notebook to load the required libraries, set up the notebook for fastai, and define the MNIST dataset:<div id="_idContainer054" class="IMG---Figure"><img src="image/B16216_02_01.jpg" alt="Figure 2.1 – Cells to load the libraries, set up the notebook, and define the MNIST dataset&#13;&#10;"/></div><p class="figure-caption">Figure 2.1 – Cells to load the libraries, set up the notebook, and define the MNIST dataset</p></li>
				<li>Consider the <a id="_idIndexMarker103"/>argument to <strong class="source-inline">untar_data</strong>: <strong class="source-inline">URLs.MINST</strong>. What is this? Let's try the <strong class="source-inline">??</strong>  shortcut to examine the source code for a <strong class="source-inline">URLs</strong> object:<div id="_idContainer055" class="IMG---Figure"><img src="image/B16216_02_02.jpg" alt="Figure 2.2 – Source for URLs&#13;&#10;"/></div><p class="figure-caption">Figure 2.2 – Source for URLs</p></li>
				<li>By looking at the <strong class="source-inline">image classification datasets</strong> section of the source code for <strong class="source-inline">URLs</strong>, we can find the definition of <strong class="source-inline">URLs.MNIST</strong>:<p class="source-code">MNIST           = f'{S3_IMAGE}mnist_png.tgz'</p></li>
				<li>Working <a id="_idIndexMarker104"/>backward through the source code for the <strong class="source-inline">URLs</strong> class, we can get the whole URL for MNIST:<p class="source-code">S3_IMAGE     = f'{S3}imageclas/'</p><p class="source-code">S3  = 'https://s3.amazonaws.com/fast-ai-'</p></li>
				<li>Putting it all together, we get the URL for <strong class="source-inline">URLs.MNIST</strong>: <p class="source-code">https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz</p></li>
				<li>You can<a id="_idIndexMarker105"/> download this file for yourself and untar it. You will see that the directory structure of the untarred package looks like this: <p class="source-code">mnist_png</p><p class="source-code">├── testing</p><p class="source-code">│   ├── 0</p><p class="source-code">│   ├── 1</p><p class="source-code">│   ├── 2</p><p class="source-code">│   ├── 3</p><p class="source-code">│   ├── 4</p><p class="source-code">│   ├── 5</p><p class="source-code">│   ├── 6</p><p class="source-code">│   ├── 7</p><p class="source-code">│   ├── 8</p><p class="source-code">│   └── 9</p><p class="source-code">└── training</p><p class="source-code">     ├── 0</p><p class="source-code">     ├── 1</p><p class="source-code">     ├── 2</p><p class="source-code">     ├── 3</p><p class="source-code">     ├── 4</p><p class="source-code">     ├── 5</p><p class="source-code">     ├── 6</p><p class="source-code">     ├── 7</p><p class="source-code">     ├── 8</p><p class="source-code">     └── 9</p></li>
				<li>In the untarred directory structure, each of the testing and training directories contain subdirectories for each digit. These digit directories contain image files for that digit. This means that the label of the dataset – the value that we want the model to predict – is encoded in the directory that the image file resides in.</li>
				<li>Is there a way to get the<a id="_idIndexMarker106"/> directory structure of one of the curated datasets without having to determine its URL from the definition of <strong class="source-inline">URLs</strong>, download the dataset, and unpack it? There is – using <strong class="source-inline">path.ls()</strong>:<div id="_idContainer056" class="IMG---Figure"><img src="image/B16216_02_03.jpg" alt="Figure 2.3 – Using path.ls() to get the dataset's directory structure&#13;&#10;"/></div><p class="figure-caption">Figure 2.3 – Using path.ls() to get the dataset's directory structure</p></li>
				<li>This tells us that there are two subdirectories in the dataset: <strong class="source-inline">training</strong> and <strong class="source-inline">testing</strong>. You can call <strong class="source-inline">ls()</strong> to get the structure of the <strong class="source-inline">training</strong> subdirectory:<div id="_idContainer057" class="IMG---Figure"><img src="image/B16216_02_04.jpg" alt="Figure 2.4 – The structure of the training subdirectory&#13;&#10;"/></div><p class="figure-caption">Figure 2.4 – The structure of the training subdirectory</p></li>
				<li>Now that we have learned how to get the directory structure of the MNIST dataset using the <strong class="source-inline">ls()</strong> function, what else can we learn from the output of <strong class="source-inline">??URLs</strong>?</li>
				<li>First, let's<a id="_idIndexMarker107"/> look at the other datasets listed in the output of <strong class="source-inline">??URLs</strong> by group. First, let's look at the datasets listed under <strong class="source-inline">main datasets</strong>. This list includes tabular datasets (<strong class="source-inline">ADULT_SAMPLE</strong>), text datasets (<strong class="source-inline">IMDB_SAMPLE</strong>), recommender system datasets (<strong class="source-inline">ML_SAMPLE</strong>), and a variety of image datasets (<strong class="source-inline">CIFAR, IMAGENETTE, COCO_SAMPLE</strong>):<p class="source-code">     ADULT_SAMPLE           = f'{URL}adult_sample.tgz'</p><p class="source-code">     BIWI_SAMPLE            = f'{URL}biwi_sample.tgz'</p><p class="source-code">     CIFAR                     = f'{URL}cifar10.tgz'</p><p class="source-code">     COCO_SAMPLE            = f'{S3_COCO}coco_sample.tgz'</p><p class="source-code">     COCO_TINY               = f'{S3_COCO}coco_tiny.tgz'</p><p class="source-code">     HUMAN_NUMBERS         = f'{URL}human_numbers.tgz'</p><p class="source-code">     IMDB                       = f'{S3_NLP}imdb.tgz'</p><p class="source-code">     IMDB_SAMPLE            = f'{URL}imdb_sample.tgz'</p><p class="source-code">     ML_SAMPLE               = f'{URL}movie_lens_sample.tgz'</p><p class="source-code">     ML_100k                  = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'</p><p class="source-code">     MNIST_SAMPLE           = f'{URL}mnist_sample.tgz'</p><p class="source-code">     MNIST_TINY              = f'{URL}mnist_tiny.tgz'</p><p class="source-code">     MNIST_VAR_SIZE_TINY = f'{S3_IMAGE}mnist_var_size_tiny.tgz'</p><p class="source-code">     PLANET_SAMPLE         = f'{URL}planet_sample.tgz'</p><p class="source-code">     PLANET_TINY            = f'{URL}planet_tiny.tgz'</p><p class="source-code">     IMAGENETTE              = f'{S3_IMAGE}imagenette2.tgz'</p><p class="source-code">     IMAGENETTE_160        = f'{S3_IMAGE}imagenette2-160.tgz'</p><p class="source-code">     IMAGENETTE_320        = f'{S3_IMAGE}imagenette2-320.tgz'</p><p class="source-code">     IMAGEWOOF               = f'{S3_IMAGE}imagewoof2.tgz'</p><p class="source-code">     IMAGEWOOF_160         = f'{S3_IMAGE}imagewoof2-160.tgz'</p><p class="source-code">     IMAGEWOOF_320         = f'{S3_IMAGE}imagewoof2-320.tgz'</p><p class="source-code">     IMAGEWANG               = f'{S3_IMAGE}imagewang.tgz'</p><p class="source-code">     IMAGEWANG_160         = f'{S3_IMAGE}imagewang-160.tgz'</p><p class="source-code">     IMAGEWANG_320         = f'{S3_IMAGE}imagewang-320.tgz'</p></li>
				<li>Next, let's look at the datasets in the other categories: image classification datasets, NLP datasets, image <a id="_idIndexMarker108"/>localization datasets, audio classification datasets, and medical image classification datasets. Note that the list of curated datasets includes datasets that aren't directly associated with any of the four main application areas supported by fastai. The audio datasets, for example, apply to a use case outside the four main application areas:<p class="source-code">     # image classification datasets</p><p class="source-code">     CALTECH_101  = f'{S3_IMAGE}caltech_101.tgz'</p><p class="source-code">     CARS            = f'{S3_IMAGE}stanford-cars.tgz'</p><p class="source-code">     CIFAR_100     = f'{S3_IMAGE}cifar100.tgz'</p><p class="source-code">     CUB_200_2011 = f'{S3_IMAGE}CUB_200_2011.tgz'</p><p class="source-code">     FLOWERS        = f'{S3_IMAGE}oxford-102-flowers.tgz'</p><p class="source-code">     FOOD            = f'{S3_IMAGE}food-101.tgz'</p><p class="source-code">     MNIST           = f'{S3_IMAGE}mnist_png.tgz'</p><p class="source-code">     PETS            = f'{S3_IMAGE}oxford-iiit-pet.tgz'</p><p class="source-code">     # NLP datasets</p><p class="source-code">     AG_NEWS                        = f'{S3_NLP}ag_news_csv.tgz'</p><p class="source-code">     AMAZON_REVIEWS              = f'{S3_NLP}amazon_review_full_csv.tgz'</p><p class="source-code">     AMAZON_REVIEWS_POLARITY = f'{S3_NLP}amazon_review_polarity_csv.tgz'</p><p class="source-code">     DBPEDIA                        = f'{S3_NLP}dbpedia_csv.tgz'</p><p class="source-code">     MT_ENG_FRA                    = f'{S3_NLP}giga-fren.tgz'</p><p class="source-code">     SOGOU_NEWS                    = f'{S3_NLP}sogou_news_csv.tgz'</p><p class="source-code">     WIKITEXT                       = f'{S3_NLP}wikitext-103.tgz'</p><p class="source-code">     WIKITEXT_TINY               = f'{S3_NLP}wikitext-2.tgz'</p><p class="source-code">     YAHOO_ANSWERS               = f'{S3_NLP}yahoo_answers_csv.tgz'</p><p class="source-code">     YELP_REVIEWS                 = f'{S3_NLP}yelp_review_full_csv.tgz'</p><p class="source-code">     YELP_REVIEWS_POLARITY   = f'{S3_NLP}yelp_review_polarity_csv.tgz'</p><p class="source-code">     # Image localization datasets</p><p class="source-code">     BIWI_HEAD_POSE      = f"{S3_IMAGELOC}biwi_head_pose.tgz"</p><p class="source-code">     CAMVID                  = f'{S3_IMAGELOC}camvid.tgz'</p><p class="source-code">     CAMVID_TINY           = f'{URL}camvid_tiny.tgz'</p><p class="source-code">     LSUN_BEDROOMS        = f'{S3_IMAGE}bedroom.tgz'</p><p class="source-code">     PASCAL_2007           = f'{S3_IMAGELOC}pascal_2007.tgz'</p><p class="source-code">     PASCAL_2012           = f'{S3_IMAGELOC}pascal_2012.tgz'</p><p class="source-code">     # Audio classification datasets</p><p class="source-code">     MACAQUES               = 'https://storage.googleapis.com/ml-animal-sounds-datasets/macaques.zip'</p><p class="source-code">     ZEBRA_FINCH           = 'https://storage.googleapis.com/ml-animal-sounds-datasets/zebra_finch.zip'</p><p class="source-code">     # Medical Imaging datasets</p><p class="source-code">     SIIM_SMALL            = f'{S3_IMAGELOC}siim_small.tgz'</p></li>
				<li>Now that we have listed all the datasets defined in <strong class="source-inline">URLs</strong>, how can we find out more information about them?<p>a) The fastai documentation (<a href="https://course.fast.ai/datasets">https://course.fast.ai/datasets</a>) documents some of the datasets listed in <strong class="source-inline">URLs</strong>. Note that this documentation is not consistent with what's listed in the source of <strong class="source-inline">URLs</strong>. For example, the naming of the datasets is not consistent and the documentation page does not cover all the datasets. When<a id="_idIndexMarker109"/> in doubt, treat the source of <strong class="source-inline">URLs</strong> as your single source of truth about fastai curated datasets.</p><p>b) Use the <strong class="source-inline">path.ls()</strong> function to examine the directory structure, as shown in the following example, which lists the directories under the <strong class="source-inline">training</strong> subdirectory of the MNIST dataset:</p><div id="_idContainer058" class="IMG---Figure"><img src="image/B16216_02_05.jpg" alt="Figure 2.5 – Structure of the training subdirectory&#13;&#10;"/></div><p class="figure-caption">Figure 2.5 – Structure of the training subdirectory</p><p>c) Check out the file structure that gets installed when you run <strong class="source-inline">untar_data</strong>. For example, in Gradient, the datasets get installed in <strong class="source-inline">storage/data</strong>, so you can go into that directory in Gradient to inspect the directories for the curated dataset you're interested in.</p><p>d) For example, let's say <strong class="source-inline">untar_data</strong> is run with <strong class="source-inline">URLs.PETS</strong> as the argument:</p><p class="source-code">path = untar_data(URLs.PETS)</p><p>e) Here, you can find the dataset in <strong class="source-inline">storage/data/oxford-iiit-pet</strong>, and you can see the directory's structure:</p><p class="source-code">oxford-iiit-pet</p><p class="source-code">├── annotations</p><p class="source-code">│   ├── trimaps</p><p class="source-code">│   └── xmls</p><p class="source-code">└── images</p></li>
				<li>If you want to see the definition of a function in a notebook, you can run a cell with <strong class="source-inline">??</strong>, followed by the<a id="_idIndexMarker110"/> name of the function. For example, to see the definition of the <strong class="source-inline">ls()</strong> function, you can use <strong class="source-inline">??Path.ls</strong>:<div id="_idContainer059" class="IMG---Figure"><img src="image/B16216_02_06.jpg" alt="Figure 2.6 – Source for Path.ls()&#13;&#10;"/></div><p class="figure-caption">Figure 2.6 – Source for Path.ls()</p></li>
				<li>To see the documentation for any function, you can use the <strong class="source-inline">doc()</strong> function. For example, the output of <strong class="source-inline">doc(Path.ls)</strong> shows the signature of the function, along with links to the source code (<a href="https://github.com/fastai/fastcore/blob/master/fastcore/xtras.py#L111">https://github.com/fastai/fastcore/blob/master/fastcore/xtras.py#L111</a>) and the documentation (<a href="https://fastcore.fast.ai/xtras#Path.ls">https://fastcore.fast.ai/xtras#Path.ls</a>) for this function: </li>
			</ol>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/B16216_02_07.jpg" alt="Figure 2.7 – Output of doc(Path.ls)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.7 – Output of doc(Path.ls)</p>
			<p>You have now <a id="_idIndexMarker111"/>explored the list of oven-ready datasets curated by fastai. You have also learned how to get the directory structure of these datasets, as well as how to examine the source and documentation of a function from within a notebook.</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor062"/>How it works…</h2>
			<p>As you saw in this section, fastai defines URLs for each of the curated datasets in the <strong class="source-inline">URLs</strong> class. When you call <strong class="source-inline">untar_data</strong> with one of the curated datasets as the argument, if the files for the dataset have not already been copied, these files get downloaded to your filesystem (<strong class="source-inline">storage/data</strong> in a Gradient instance). The object you get back from <strong class="source-inline">untar_data</strong> allows you to examine the directory structure of the dataset, and then pass it along to the next stage in the process of creating a fastai deep learning model. By wrapping a large sampling of interesting datasets in such a convenient way, fastai makes it easy for you to create deep learning models with these datasets, and also lets you focus your efforts on creating and improving the deep learning model rather than fiddling with the details of ingesting the datasets.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor063"/>There's more…</h2>
			<p>You might be asking yourself why we went to the trouble of examining the source code for the <strong class="source-inline">URLs</strong> class to get details about the curated datasets. After all, these datasets are documented in <a href="https://course.fast.ai/datasets">https://course.fast.ai/datasets</a>. The <a id="_idIndexMarker112"/>problem is that this documentation page doesn't give a complete list of all the curated datasets, and it doesn't clearly explain what you need to know to make the correct <strong class="source-inline">untar_data</strong> calls for a particular curated dataset. The incomplete documentation for the curated datasets demonstrates one of the weaknesses of fastai – <em class="italic">inconsistent documentation</em>. Sometimes, the documentation is complete, but sometimes, it is lacking details, so you will need to look at the source code directly to figure out what's going on, like we had to do in this section for the curated datasets. This<a id="_idIndexMarker113"/> problem is compounded by Google search returning hits for documentation for earlier versions of fastai. If you are searching for some <a id="_idIndexMarker114"/>details about fastai, avoid hits for fastai version 1 (<a href="https://fastai1.fast.ai/">https://fastai1.fast.ai/</a>) and keep to the documentation for the current version of fastai: <a href="https://docs.fast.ai/">https://docs.fast.ai/</a>.</p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor064"/>Examining tabular datasets with fastai</h1>
			<p>In the previous section, we looked at <a id="_idIndexMarker115"/>the whole set of datasets curated by fastai. In this section, we are going to dig into a tabular dataset from the <a id="_idIndexMarker116"/>curated list. We will ingest the dataset, look at some example records, and then explore characteristics of the dataset, including the number of records and the number of unique values in each column.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor065"/>Getting ready</h2>
			<p>Ensure you have followed the steps in <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, to get a fastai environment set up. Confirm that you can open the <strong class="source-inline">examining_tabular_datasets.ipynb</strong> notebook in the <strong class="source-inline">ch2</strong> directory of your repository.</p>
			<p>I am grateful for the opportunity to include the ADULT_SAMPLE dataset featured in this section.</p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout">Ron Kohavi. (1996) <em class="italic">Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid</em>  (<a href="http://robotics.stanford.edu/~ronnyk/nbtree.pdf">http://robotics.stanford.edu/~ronnyk/nbtree.pdf</a>). </p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor066"/>How to do it…</h2>
			<p>In this section, you will be running through the <strong class="source-inline">examining_tabular_datasets.ipynb</strong> notebook to examine the <strong class="source-inline">ADULT_SAMPLE</strong> dataset. </p>
			<p>Once you have the notebook open in your fastai environment, complete the following steps:</p>
			<ol>
				<li value="1">Run the first two cells to import the necessary libraries and set up the notebook for fastai.</li>
				<li>Run the following cell to copy the dataset into your filesystem (if it's not already there) and to define the path for the dataset:<p class="source-code">path = untar_data(URLs.ADULT_SAMPLE)</p></li>
				<li>Run the following <a id="_idIndexMarker117"/>cell to get the output of <strong class="source-inline">path.ls()</strong> so that<a id="_idIndexMarker118"/> you can examine the directory structure of the dataset:<div id="_idContainer061" class="IMG---Figure"><img src="image/B16216_02_08.jpg" alt="Figure 2.8 – Output of path.ls()&#13;&#10;"/></div><p class="figure-caption">Figure 2.8 – Output of path.ls()</p></li>
				<li>The dataset is in the <strong class="source-inline">adult.csv</strong> file. Run the following cell to ingest this CSV file into a pandas DataFrame:<p class="source-code">df = pd.read_csv(path/'adult.csv')</p></li>
				<li>Run the <strong class="source-inline">head()</strong> command to get a sample of records from the beginning of the dataset:<div id="_idContainer062" class="IMG---Figure"><img src="image/B16216_02_09.jpg" alt="Figure 2.9 – Sample of records from the beginning of the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 2.9 – Sample of records from the beginning of the dataset</p></li>
				<li>Run the following command to get the number of records (rows) and fields (columns) in the dataset:<p class="source-code">df.shape</p></li>
				<li>Run the following <a id="_idIndexMarker119"/>command to get the number of unique <a id="_idIndexMarker120"/>values in each column of the dataset. Can you tell from the output which columns are categorical?<p class="source-code">df.nunique()</p></li>
				<li>Run the following command to get the count of missing values in each column of the dataset. Which columns have missing values?<p class="source-code">df.isnull().sum()</p></li>
				<li>Run the following command to display some sample records from the subset of the dataset for people whose age is less than or equal to 40:<p class="source-code">df_young = df[df.age &lt;= 40]</p><p class="source-code">df_young.head()</p></li>
			</ol>
			<p>Congratulations! You have ingested a tabular dataset curated by fastai and done a basic examination of the dataset.</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor067"/>How it works…</h2>
			<p>The dataset that you <a id="_idIndexMarker121"/>explored in this section, <strong class="source-inline">ADULT_SAMPLE</strong>, is one of the datasets you would have seen in the source for <strong class="source-inline">URLs</strong> in the previous section. Note that while the source for <strong class="source-inline">URLs</strong> identifies which datasets are related to image<a id="_idIndexMarker122"/> or NLP (text) applications, it does not explicitly identify the tabular or recommender system datasets. <strong class="source-inline">ADULT_SAMPLE</strong> is one of the datasets listed under <strong class="source-inline">main datasets</strong>:</p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B16216_02_10.jpg" alt="Figure 2.10 – Main datasets from the source for URLs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10 – Main datasets from the source for URLs</p>
			<p>How did I determine that <strong class="source-inline">ADULT_SAMPLE</strong> was a tabular dataset? First, the paper by Howard and Gugger (<a href="https://arxiv.org/pdf/2002.04688.pdf">https://arxiv.org/pdf/2002.04688.pdf</a>) identifies <strong class="source-inline">ADULT_SAMPLE</strong> as a tabular dataset. Second, I just had to ingest it and try it out to confirm it <a id="_idIndexMarker123"/>could be ingested into a<a id="_idIndexMarker124"/> pandas DataFrame.</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor068"/>There's more…</h2>
			<p>What about the other curated datasets that aren't explicitly categorized in the source for <strong class="source-inline">URLs</strong>? Here's a summary of the datasets listed in the source for <strong class="source-inline">URLs</strong> under <strong class="source-inline">main datasets</strong>:</p>
			<ul>
				<li>Tabular:<p>a) <strong class="source-inline">ADULT_SAMPLE</strong></p></li>
				<li>NLP (text):<p>a) <strong class="source-inline">HUMAN_NUMBERS  </strong></p><p>b) <strong class="source-inline">IMDB</strong></p><p>c) <strong class="source-inline">IMDB_SAMPLE      </strong></p></li>
				<li>Collaborative filtering:<p>a) <strong class="source-inline">ML_SAMPLE               </strong></p><p>b) <strong class="source-inline">ML_100k                              </strong></p></li>
				<li>Image data:  <p>a) All of the other datasets listed in <strong class="source-inline">URLs</strong> under <strong class="source-inline">main datasets</strong>.</p></li>
			</ul>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor069"/>Examining text datasets with fastai</h1>
			<p>In the previous section, we <a id="_idIndexMarker125"/>looked at how a curated tabular <a id="_idIndexMarker126"/>dataset could be ingested. In this section, we are going to dig into a text dataset from the curated list. </p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor070"/>Getting ready</h2>
			<p>Ensure you have followed the steps in <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, to get a fastai environment set up. Confirm that you can open the <strong class="source-inline">examining_text_datasets.ipynb</strong> notebook in the <strong class="source-inline">ch2</strong> directory of your repository.</p>
			<p>I am grateful for the opportunity to use the WIKITEXT_TINY dataset (<a href="https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/">https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/</a>) featured in this section.</p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout">Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher. (2016). <em class="italic">Pointer Sentinel Mixture Models</em> (<a href="https://arxiv.org/pdf/1609.07843.pdf">https://arxiv.org/pdf/1609.07843.pdf</a>). </p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor071"/>How to do it…</h2>
			<p>In this section, you will be running through the <strong class="source-inline">examining_text_datasets.ipynb</strong> notebook to examine the <strong class="source-inline">WIKITEXT_TINY</strong> dataset. As its name suggests, this is a small set of text that's been gleaned from good and featured Wikipedia articles.</p>
			<p>Once you have the notebook open in your fastai environment, complete the following steps:</p>
			<ol>
				<li value="1">Run the first two cells to import the necessary libraries and set up the notebook for fastai.</li>
				<li>Run the following cell to copy the dataset into your filesystem (if it's not already there) and to define the path for the dataset:<p class="source-code">path = untar_data(URLs.WIKITEXT_TINY)</p></li>
				<li>Run the following cell to get the output of <strong class="source-inline">path.ls()</strong> so that you can examine the directory structure of the dataset:<div id="_idContainer064" class="IMG---Figure"><img src="image/B16216_02_11.jpg" alt="Figure 2.11 – Output of path.ls()&#13;&#10;"/></div><p class="figure-caption">Figure 2.11 – Output of path.ls()</p></li>
				<li>There are two CSV files that make up this dataset. Let's ingest each of them into a pandas DataFrame, starting with <strong class="source-inline">train.csv</strong>:<p class="source-code">df_train = pd.read_csv(path/'train.csv')</p></li>
				<li>When you use <strong class="source-inline">head()</strong> to check the DataFrame, you'll notice that something's wrong – the CSV file has no header with column names, but by default, <strong class="source-inline">read_csv</strong> assumes the<a id="_idIndexMarker127"/> first row is the header, so the first row gets misinterpreted as a header. As shown in the following screenshot, the first<a id="_idIndexMarker128"/> row of output is in bold, which indicates that the first row is being interpreted as a header, even though it contains a regular data row:<div id="_idContainer065" class="IMG---Figure"><img src="image/B16216_02_12.jpg" alt="Figure 2.12 – First record in df_train&#13;&#10;"/></div><p class="figure-caption">Figure 2.12 – First record in df_train</p></li>
				<li>To fix this problem, rerun the <strong class="source-inline">read_csv</strong> function, but this time with the <strong class="source-inline">header=None</strong> parameter, to specify that the CSV file doesn't have a header:<p class="source-code">df_train = pd.read_csv(path/'train.csv',header=None)</p></li>
				<li>Check <strong class="source-inline">head()</strong> again to confirm that the problem has been resolved:<div id="_idContainer066" class="IMG---Figure"><img src="image/B16216_02_13.jpg" alt="Figure 2.13 – Revising the first record in df_train&#13;&#10;"/></div><p class="figure-caption">Figure 2.13 – Revising the first record in df_train</p></li>
				<li>Ingest <strong class="source-inline">test.csv</strong> into a DataFrame using the <strong class="source-inline">header=None</strong> parameter:<p class="source-code">df_test = pd.read_csv(path/'test.csv',header=None)</p></li>
				<li>We want to <a id="_idIndexMarker129"/>tokenize the dataset and transform it into a list <a id="_idIndexMarker130"/>of words. Since we want a common set of tokens for the entire dataset, we will begin by combining the test and train DataFrames:<p class="source-code">df_combined = pd.concat([df_train,df_test])</p></li>
				<li>Confirm the shape of the train, test, and combined dataframes – the number of rows in the combined DataFrame should be the sum of the number of rows in the train and test DataFrames:<p class="source-code">print("df_train: ",df_train.shape)</p><p class="source-code">print("df_test: ",df_test.shape)</p><p class="source-code">print("df_combined: ",df_combined.shape)</p></li>
				<li>Now, we're ready to tokenize the DataFrame. The <strong class="source-inline">tokenize_df()</strong> function takes the list of columns containing the text we want to tokenize as a parameter. Since the columns of the DataFrame are not labeled, we need to refer to the column we want to tokenize using its position rather than its name:<p class="source-code">df_tok, count = tokenize_df(df_combined,[df_combined.columns[0]])</p></li>
				<li>Check the <a id="_idIndexMarker131"/>contents of the first few records of <strong class="source-inline">df_tok</strong>, which is<a id="_idIndexMarker132"/> the new DataFrame containing the tokenized contents of the combined DataFrame:<div id="_idContainer067" class="IMG---Figure"><img src="image/B16216_02_14.jpg" alt="Figure 2.14 – The first few records of df_tok&#13;&#10;"/></div><p class="figure-caption">Figure 2.14 – The first few records of df_tok</p></li>
				<li>Check the count for a few sample words to ensure they are roughly what you expected. Pick a very common word, a moderately common word, and a rare word:<p class="source-code">print("very common word (count['the']):", count['the'])</p><p class="source-code">print("moderately common word (count['prepared']):", count['prepared'])</p><p class="source-code">print("rare word (count['gaga']):", count['gaga'])</p></li>
			</ol>
			<p>Congratulations! You have successfully ingested, explored, and tokenized a curated text dataset.</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor072"/>How it works…</h2>
			<p>The dataset that you<a id="_idIndexMarker133"/> explored in this section, <strong class="source-inline">WIKITEXT_TINY</strong>, is one<a id="_idIndexMarker134"/> of the datasets you would have seen in the source for <strong class="source-inline">URLs</strong> in the <em class="italic">Getting the complete set of oven-ready fastai datasets</em> section. Here, you can see that <strong class="source-inline">WIKITEXT_TINY</strong> is in the NLP datasets section of the source for <strong class="source-inline">URLs</strong>:</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B16216_02_15.jpg" alt="Figure 2.15 – WIKITEXT_TINY in the NLP datasets list in the source for URLs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.15 – WIKITEXT_TINY in the NLP datasets list in the source for URLs</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor073"/>Examining image datasets with fastai</h1>
			<p>In the past two<a id="_idIndexMarker135"/> sections, we examined tabular and text datasets and got a taste of the facilities that fastai provides for accessing and exploring these <a id="_idIndexMarker136"/>datasets. In this section, we are going to look at image data. We are going to look at two datasets: the <strong class="source-inline">FLOWERS</strong> image classification dataset and the <strong class="source-inline">BIWI_HEAD_POSE</strong> image localization dataset.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor074"/>Getting ready</h2>
			<p>Ensure you have followed the steps in <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, to get a fastai environment set up. Confirm that you can open the <strong class="source-inline">examining_image_datasets.ipynb</strong> notebook in the <strong class="source-inline">ch2</strong> directory of your repository.</p>
			<p>I am grateful for the opportunity to use the FLOWERS dataset featured in this section.</p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout">Maria-Elena Nilsback, Andrew Zisserman. (2008). <em class="italic">Automated flower classification over a large number of classes</em> (<a href="https://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf">https://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf</a>).  </p>
			<p>I am grateful for the opportunity to use the BIWI_HEAD_POSE dataset featured in this section.</p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout">Gabriele Fanelli, Thibaut Weise, Juergen Gall, Luc Van Gool. (2011). R<em class="italic">eal Time Head Pose Estimation from Consumer Depth Cameras</em> (<a href="https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11">https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11</a>). Lecture Notes in Computer Science, vol 6835. Springer, Berlin, Heidelberg  <a href="https://doi.org/10.1007/978-3-642-23123-0_11">https://doi.org/10.1007/978-3-642-23123-0_11</a>.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor075"/>How to do it…</h2>
			<p>In this section, you will be running through the <strong class="source-inline">examining_image_datasets.ipynb</strong> notebook to examine the <strong class="source-inline">FLOWERS</strong> and <strong class="source-inline">BIWI_HEAD_POSE</strong> datasets. </p>
			<p>Once you have the notebook open in your fastai environment, complete the following steps:</p>
			<ol>
				<li value="1">Run the first two cells to import the necessary libraries and set up the notebook for fastai.</li>
				<li>Run the following cell to copy the <strong class="source-inline">FLOWERS</strong> dataset into your filesystem (if it's not already there) and to define the path for the dataset:<p class="source-code">path = untar_data(URLs.FLOWERS)</p></li>
				<li>Run the following cell to get the output of <strong class="source-inline">path.ls()</strong> so that you can examine the directory structure of the dataset:<div id="_idContainer069" class="IMG---Figure"><img src="image/B16216_2_16.jpg" alt="Figure 2.16 – Output of path.ls()&#13;&#10;"/></div><p class="figure-caption">Figure 2.16 – Output of path.ls()</p></li>
				<li>Look at the <a id="_idIndexMarker137"/>contents of the <strong class="source-inline">valid.txt</strong> file. This<a id="_idIndexMarker138"/> indicates that <strong class="source-inline">train.txt</strong>, <strong class="source-inline">valid.txt</strong>, and <strong class="source-inline">test.txt</strong> contain lists of the image files that belong to each of these datasets:<div id="_idContainer070" class="IMG---Figure"><img src="image/B16216_2_17.jpg" alt="Figure 2.17 – The first few records of valid.txt&#13;&#10;"/></div><p class="figure-caption">Figure 2.17 – The first few records of valid.txt</p></li>
				<li>Examine the <strong class="source-inline">jgp</strong> subdirectory:<p class="source-code">(path/'jpg').ls()</p></li>
				<li>Take a look at one of the image files. Note that the <strong class="source-inline">get_image_files()</strong> function doesn't need to be pointed to a particular subdirectory – it recursively collects all the image files in a directory and its subdirectories:<p class="source-code">img_files = get_image_files(path)</p><p class="source-code">img = PILImage.create(img_files[100])</p><p class="source-code">img</p></li>
				<li>You should have <a id="_idIndexMarker139"/>noticed that the image displayed in the <a id="_idIndexMarker140"/>previous step was the native size of the image, which makes it rather big for the notebook. To get the image at a more appropriate size, apply the <strong class="source-inline">to_thumb</strong> function with the image dimension specified as an argument. Note that you might see a different image when you run this cell:<div id="_idContainer071" class="IMG---Figure"><img src="image/B16216_2_18.jpg" alt="Figure 2.18 – Applying to_thumb to an image&#13;&#10;"/></div><p class="figure-caption">Figure 2.18 – Applying to_thumb to an image</p></li>
				<li>Now, ingest the <strong class="source-inline">BIWI_HEAD_POSE</strong> dataset:<p class="source-code">path = untar_data(URLs.BIWI_HEAD_POSE)</p></li>
				<li>Examine the path for this dataset:<p class="source-code">path.ls()</p></li>
				<li>Examine the <strong class="source-inline">05</strong> subdirectory:<p class="source-code">(path/"05").ls()</p></li>
				<li>Examine one<a id="_idIndexMarker141"/> of the images. Note that you may see a different<a id="_idIndexMarker142"/> image:<div id="_idContainer072" class="IMG---Figure"><img src="image/B16216_2_19.jpg" alt="Figure 2.19 – One of the images in the BIWI_HEAD_POSE dataset&#13;&#10;"/></div><p class="figure-caption">Figure 2.19 – One of the images in the BIWI_HEAD_POSE dataset</p></li>
				<li>In addition to the image files, this dataset also includes text files that encode the pose depicted<a id="_idIndexMarker143"/> in the image. Ingest one of these text <a id="_idIndexMarker144"/>files into a pandas DataFrame and display it:</li>
			</ol>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B16216_02_20.jpg" alt="Figure 2.20 – The first few records of one of the position text files&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.20 – The first few records of one of the position text files</p>
			<p>In this section, you learned how to ingest two different kinds of image datasets, explore their directory structure, and examine images from the datasets.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor076"/>How it works…</h2>
			<p>You used the same <strong class="source-inline">untar_data()</strong> function to ingest the curated tabular, text, and image datasets, and the same <strong class="source-inline">ls()</strong> function to examine the directory structures for all the different kinds of datasets. On top of these common facilities, fastai provides additional convenience functions for examining image data: <strong class="source-inline">get_image_files()</strong> to collect all the image files in a directory tree starting at a given directory, and <strong class="source-inline">to_thumb()</strong> to render the image at a size that is suitable for a notebook. </p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor077"/>There's more…</h2>
			<p>In addition to image classification datasets (where the goal of the trained model is to predict the category of what's displayed in the image) and image localization datasets (where the goal is to predict the location in the image of a given feature), the fastai curated datasets also include image segmentation datasets where the goal is to identify the subsets of an image that contain a <a id="_idIndexMarker145"/>particular object, including the <strong class="source-inline">CAMVID</strong> and <strong class="source-inline">CAMVID_TINY</strong> datasets.</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor078"/>Cleaning up raw datasets with fastai</h1>
			<p>Now that we have <a id="_idIndexMarker146"/>explored a variety of datasets that are curated by fastai, there is one more topic left to cover in this chapter: how to clean up datasets<a id="_idIndexMarker147"/> with fastai. Cleaning up datasets includes dealing with missing values and converting categorical values into numeric identifiers. We need to apply these cleanup steps to datasets because deep learning models can only be trained with numeric data. If we try to train the model with datasets that contain non-numeric data, including missing values and alphanumeric identifiers in categorical columns, the training process will fail. In this section, we are going to review the facilities provided by fastai to make it easy to clean up datasets, and thus make the datasets ready to train deep learning models.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor079"/>Getting ready</h2>
			<p>Ensure you have followed the steps in <a href="B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019"><em class="italic">Chapter 1</em></a>, <em class="italic">Getting Started with fastai</em>, to get a fastai environment set up. Confirm that you can open the <strong class="source-inline">cleaning_up_datasets.ipynb</strong> notebook in the <strong class="source-inline">ch2</strong> directory of your repository.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor080"/>How to do it…</h2>
			<p>In this section, you will be running through the <strong class="source-inline">cleaning_up_datasets.ipynb</strong> notebook to address missing values in the <strong class="source-inline">ADULT_SAMPLE</strong> dataset and replace categorical values with numeric identifiers.</p>
			<p>Once you have the notebook open in your fastai environment, complete the following steps:</p>
			<ol>
				<li value="1">Run the first two cells to import the necessary libraries and set up the notebook for fastai.</li>
				<li>Recall the <em class="italic">Examining tabular datasets with fastai</em> section of this chapter. When you checked to see which columns in the <strong class="source-inline">ADULT_SAMPLE</strong> dataset had missing values, you <a id="_idIndexMarker148"/>found that some columns did indeed have missing values. We are going to identify the columns in <strong class="source-inline">ADULT_SAMPLE</strong> that have missing values, and use the facilities of fastai to apply transformations<a id="_idIndexMarker149"/> to the dataset that deal with the missing values in those columns, and then replace those categorical values with numeric identifiers.</li>
				<li>First, let's ingest the <strong class="source-inline">ADULT_SAMPLE</strong> curated dataset again:<p class="source-code">path = untar_data(URLs.ADULT_SAMPLE)</p></li>
				<li>Now, create a pandas DataFrame for the dataset and check for the number of missing values in each column. Note which columns have missing values:<p class="source-code">df = pd.read_csv(path/'adult.csv')</p><p class="source-code">df.isnull().sum()</p></li>
				<li>To deal with these missing values (and prepare categorical columns), we will use the fastai <strong class="source-inline">TabularPandas</strong> class (<a href="https://docs.fast.ai/tabular.core.html#TabularPandas">https://docs.fast.ai/tabular.core.html#TabularPandas</a>). To use this class, we need to prepare the following parameters: <p>a) <strong class="bold">procs</strong> is the list of transformations that will <a id="_idIndexMarker150"/>be applied to <strong class="source-inline">TabularPandas</strong>. Here, we will specify that we want missing values to be filled (<strong class="source-inline">FillMissing</strong>) and that we will replace values in categorical columns with numeric identifiers (<strong class="source-inline">Categorify</strong>).</p><p>b) <strong class="bold">dep_var</strong> specifies which column is the<a id="_idIndexMarker151"/> dependent variable; that is, the target that we want to ultimately predict with the model. In the case of <strong class="source-inline">ADULT_SAMPLE</strong>, the dependent variable is <strong class="source-inline">salary</strong>.</p><p>c) <strong class="bold">cont</strong> and <strong class="bold">cat</strong> are lists of the columns <a id="_idIndexMarker152"/>in the dataset. They are continuous and categorical, respectively. Continuous<a id="_idIndexMarker153"/> columns contain <a id="_idIndexMarker154"/>numeric values, such as integers or floating-point values. Categorical values contain category<a id="_idIndexMarker155"/> identifiers, such as names of US states, days of the week, or colors. We use the <strong class="source-inline">cont_cat_split()</strong> (<a href="https://docs.fast.ai/tabular.core.html#cont_cat_split">https://docs.fast.ai/tabular.core.html#cont_cat_split</a>) function to automatically identify the<a id="_idIndexMarker156"/> continuous and categorical columns:</p><p class="source-code">procs = [FillMissing,Categorify]</p><p class="source-code">dep_var = 'salary'</p><p class="source-code">cont,cat = cont_cat_split(df, 1, dep_var=dep_var)</p></li>
				<li>Now, create a <strong class="source-inline">TabularPandas</strong> object called <strong class="source-inline">df_no_missing</strong> using these parameters. This object will contain the dataset with missing values replaced and the values in the categorical columns replaced with numeric identifiers:<p class="source-code">df_no_missing = TabularPandas(df, procs, cat, cont, y_names = dep_var)</p></li>
				<li>Apply the <strong class="source-inline">show</strong> API to <strong class="source-inline">df_no_missing</strong> to display samples of its contents. Note that the values in the categorical columns are maintained when the object is displayed using <strong class="source-inline">show()</strong>. What about replacing the categorical values with numeric identifiers? Don't worry – we'll see that result in the next step:<div id="_idContainer074" class="IMG---Figure"><img src="image/B16216_02_21.jpg" alt="Figure 2.21 – The first few records of df_no_missing&#13;&#10;"/></div><p class="figure-caption">Figure 2.21 – The first few records of df_no_missing</p></li>
				<li>Now, display some sample contents of <strong class="source-inline">df_no_missing</strong> using the <strong class="source-inline">items.head()</strong> API. This time, the categorical columns contain the numeric identifiers rather than the original values. This is an example of a benefit provided by fastai: the <a id="_idIndexMarker157"/>switch between the original categorical <a id="_idIndexMarker158"/>values and the numeric identifiers is handled elegantly. If you need to see the original values, you can use the <strong class="source-inline">show()</strong> API, which transforms the numeric values in categorical columns back into their original values, while the <strong class="source-inline">items.head()</strong> API shows the actual numeric identifiers in the categorical columns:<div id="_idContainer075" class="IMG---Figure"><img src="image/B16216_02_22.jpg" alt="Figure 2.22 – The first few records of df_no_missing with numeric identifiers in categorical columns&#13;&#10;"/></div><p class="figure-caption">Figure 2.22 – The first few records of df_no_missing with numeric identifiers in categorical columns</p></li>
				<li>Finally, let's confirm that the <a id="_idIndexMarker159"/>missing values were handled <a id="_idIndexMarker160"/>correctly. As you can see, the two columns that originally had missing values no longer have missing values in <strong class="source-inline">df_no_missing</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B16216_02_23.jpg" alt="Figure 2.23 – Missing values in df_no_missing&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.23 – Missing values in df_no_missing</p>
			<p>By following these steps, you have seen how fastai makes it easy to prepare a dataset to train a deep learning<a id="_idIndexMarker161"/> model. It does this by replacing missing <a id="_idIndexMarker162"/>values and converting the values in the categorical columns into numeric identifiers.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor081"/>How it works…</h2>
			<p>In this section, you saw several ways that fastai makes it easy to perform common data preparation steps. The <strong class="source-inline">TabularPandas</strong> class provides a lot of value by making it easy to execute common steps to prepare a tabular dataset (including replacing missing values and dealing with categorical columns). The <strong class="source-inline">cont_cat_split()</strong> function automatically identifies continuous and categorical columns in your dataset. In conclusion, fastai makes the cleanup process easy and less error prone than it would be if you had to hand code all the functions required t<a id="_idTextAnchor082"/>o accomplish these dataset cleanup steps.</p>
		</div>
	</body></html>