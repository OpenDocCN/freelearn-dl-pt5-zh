<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Making Magenta Interact with Music Applications</h1>
                </header>
            
            <article>
                
<p>In this chapter, we'll see how Magenta fits into a broader picture by showing how to make it interact with other music applications such as <strong>Digital Audio Workstations</strong> (<strong>DAWs</strong>) and synthesizers. We'll explain how to send MIDI sequences from Magenta to FluidSynth and DAWs using the MIDI interface. By doing so, we'll learn how to handle MIDI ports on all platforms and how to loop MIDI sequences in Magenta. We'll show how to synchronize multiple applications using MIDI clocks and transport information. Finally, we'll cover Magenta Studio, a standalone packaging of Magenta based on Magenta.js that can also integrate into Ableton Live as a plugin.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li class="mce-root">Sending MIDI to a DAW or synthesizer</li>
<li>Looping the generated MIDI</li>
<li>Using Magenta as a standalone application with Magenta Studio</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>In this chapter, we'll use the following tools:</p>
<ul>
<li>The <strong>command line</strong> or <strong>Bash</strong> to launch Magenta from the Terminal</li>
<li><strong>Python</strong> and its libraries to write music generation code using Magenta</li>
<li><strong>Magenta</strong> to generate music in MIDI and synchronize with other applications</li>
<li><strong>Mido</strong> and other MIDI tools to send MIDI notes and clock</li>
<li><strong>FluidSynth</strong> to receive MIDI from Magenta</li>
<li>A <strong>DAW</strong> of your choice (Ableton Live, Bitwig, and so on) to receive MIDI from Magenta</li>
<li><strong>Magenta Studio</strong> as a standalone application or Ableton Live plugin</li>
</ul>
<p class="mce-root"/>
<p>In Magenta, we'll make the use of the <strong>MIDI interface</strong> to send MIDI sequences and MIDI clock to other music applications. We'll cover its usage in depth, but if you feel like you need more information, the Magenta MIDI interface, <kbd>README.md</kbd>, in the Magenta source code (<a href="https://github.com/tensorflow/magenta/tree/master/magenta/interfaces/midi">github.com/tensorflow/magenta/tree/master/magenta/interfaces/midi</a>) is a good place to start. You can also take a look at Magenta's code, which is well documented. We also provide additional content in the <em>Further reading</em> section at the end of this chapter.</p>
<p>We'll also make the use of the <strong>Magenta Studio</strong> project on which you can find more information on its GitHub page at <a href="https://github.com/tensorflow/magenta-studio">github.com/tensorflow/magenta-studio</a>.</p>
<p>The code for this chapter is in this book's GitHub repository in <span><kbd>Chapter09</kbd> </span>folder, located at <a href="https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter09">github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter09</a>. The examples and code snippets will assume you are located in this chapter's folder. For this chapter, you should <span><span>go to </span></span><kbd>cd Chapter09</kbd> before you start. Check out the following video to see the Code in Action: <a href="http://bit.ly/2RGkEaG">http://bit.ly/2RGkEaG</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending MIDI to a DAW or synthesizer</h1>
                </header>
            
            <article>
                
<p>Since the start of this book, we've been generating MIDI as physical files and then listening to them using either MuseScore or FluidSynth. This is a good way of composing music, generating new sequences, keeping the ones we like, and generating more based on them. But what if we'd like the MIDI notes to play continuously as the model generates them? This is a good way of making an autonomous music generation system, where Magenta is the composer, and an external program is a player, as it plays the notes it receives using instruments.</p>
<p>In this section, we'll be looking at how to send MIDI from Magenta to synthesizers or DAWs. We'll also show how to loop the sequences that are generated in Magenta and how to synchronize our Magenta program with the application it is sending the sequences to.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing some DAWs</h1>
                </header>
            
            <article>
                
<p>Producing music using a DAW has many advantages over simple synthesizers such as FluidSynth:</p>
<ul>
<li>Recording and <strong>editing MIDI</strong> sequences</li>
<li>Recording and <strong>editing audio</strong>, either for the master track or single (instrument) track</li>
<li>Creating our own <strong>synthesizers</strong> using oscillators, envelopes, filters, and so on</li>
<li>Using <strong>effects</strong> such as reverb, delay, saturation, <span>and so on</span></li>
<li>Applying <strong>EQ</strong> and <strong>mastering</strong> to the audio tracks</li>
<li>Cutting, merging, and mixing <strong>audio clips</strong> to produce a whole track</li>
</ul>
<p>There are many DAWs on the market, but unfortunately, not many of them are open source or free to use. We'll give a small tour (which is not extensive by any means) of some DAWs that we think are interesting to use with Magenta:</p>
<ul>
<li><strong>Ableton Live</strong> (<a href="https://www.ableton.com">www.ableton.com</a> – <em>not free</em>) is a well known product in the music industry and has been around for a long time. Ableton Live is one of the most complete DAWs on the market but is sold at a hefty price for all of the features. It works only on Windows and macOS.</li>
<li><strong>Bitwig</strong> (<a href="https://www.bitwig.com">www.bitwig.com</a> <span>–</span> <em>not free</em>) is also a very complete product, similar to Ableton Live, and is a bit less pricey than its counterpart. It is a good DAW with many features and is available on all platforms, Windows, macOS, and Linux.</li>
<li><strong>Reason</strong> (<a href="https://www.reasonstudios.com/">www.reasonstudios.com/</a> <span>–</span> <em>not free</em>) is a DAW that focuses on instruments and effects rather than composition. It works really well when integrated with another software for the MIDI sequencing, such as Ableton Live or Magenta. It works only on Windows and macOS.</li>
<li><strong>Cubase</strong> (<a href="https://new.steinberg.net/cubase/">new.steinberg.net/cubase/</a> <span>–</span> <em>not free</em>), from Steinberg, a renowned company making all sorts of audio software and hardware, is one of the oldest DAWs out there. It works only on Windows and macOS.</li>
<li><strong>Cakewalk</strong> (<a href="https://www.bandlab.com/products/cakewalk">www.bandlab.com/products/cakewalk</a> <span>–</span> <em>free</em>) by Bandlab is a complete and easy-to-use DAW. This is the only non-open source DAW that is free to use. It works only on Windows, unfortunately.</li>
<li><strong>SuperCollider</strong> (<a href="https://supercollider.github.io/">supercollider.github.io/</a> <span>–</span> <em>free and open source</em>) is a platform for audio synthesis and algorithmic composition, enabling the development of synthesizers and effects using code, with a language called <kbd>sclang</kbd>. It works on all platforms and is open source.</li>
<li><strong>VCV Rack</strong> (<a href="https://vcvrack.com/">vcvrack.com/</a> <span>–</span> <em>free and open source</em>) is a DAW that reproduces the joys of modular synthesis in software form. It works on all platforms and is open source.</li>
</ul>
<p class="mce-root">We'll be giving our examples using Ableton Live, but all DAWs have similar features when it comes to receiving MIDI, so the examples should work well for all software. We'll highlight caveats when possible, such as handling MIDI routing on Linux.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Looking at MIDI ports using Mido</h1>
                </header>
            
            <article>
                
<p>First things first, we need to find what MIDI ports are available on the machine, if any, to send MIDI messages between applications, such as Magenta to FluidSynth or a DAW. There is a great library called Mido, MIDI Objects for Python (<a href="https://mido.readthedocs.io">mido.readthedocs.io</a>), that is really useful in finding MIDI ports, creating new ones, and sending data over.</p>
<p>Since Magenta has a dependency on Mido, it is already installed in our Magenta environment.</p>
<div class="packt_tip">You can follow this example in the <kbd>chapter_09_example_01.py</kbd> file in the source code of this chapter. There are more comments and content in the source code, so you should go check it out.</div>
<p>Let's look at the MIDI ports that are available on our machine:</p>
<pre><span>import </span>mido<span><br/>print</span>(<span>f"Input ports: </span><span>{</span>mido.get_input_names()<span>}</span><span>"</span>)<br/><span>print</span>(<span>f"Output ports: </span><span>{</span>mido.get_output_names()<span>}</span><span>"</span>)</pre>
<p>This should produce an output similar to the following:</p>
<pre>Input ports: ['Midi Through:Midi Through Port-0 14:0']<br/>Output ports: ['Midi Through:Midi Through Port-0 14:0']</pre>
<p>On Linux and macOS, one input port and one output port should already be present, as in the preceding output. On Windows, the list is either empty, because the OS doesn't create any virtual MIDI ports automatically, or contains only <kbd>Microsoft GS Wavetable Synth</kbd>, a MIDI synthesizer like FluidSynth.</p>
<p>Let's have a look at how to create new ports for our applications to communicate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a virtual MIDI port on macOS and Linux</h1>
                </header>
            
            <article>
                
<p>What is nice about FluidSynth is that it opens a Virtual MIDI port automatically at launch. Unfortunately, it doesn't work on Windows, so we'll be looking at how to create Virtual MIDI ports works first.</p>
<p>A Virtual MIDI port is a MIDI port that can be created for <strong>applications to send MIDI messages between them</strong>. This is essential for all music production applications. For Magenta to send MIDI data to another program such as a DAW, we'll need to open a virtual port for them to communicate.</p>
<div class="packt_infobox">Like we saw in the previous example, Virtual MIDI ports are either <strong>input</strong> ports or <strong>output</strong> ports. That means we can create an input port named <kbd>magenta</kbd> and an output port named <kbd>magenta</kbd>. More often then not, it is clearer to use two different names when doing this, for example, <kbd>magenta_out</kbd> for the output port, and <kbd>magenta_in</kbd> for the input port. It is also simpler when mapping the ports in a DAW.<br/>
<br/>
We'll be choosing the port names from Magenta's perspective, meaning <kbd>magenta_out</kbd> is named as such because Magenta is sending information.</div>
<p>On macOS and Linux, creating new virtual ports is easy, since Mido supports the RtMidi backend that can create them. Using <kbd>MidiHub</kbd> in Magenta, we can provide a string for each of the input and output, for the virtual port names we want to create:</p>
<pre>from magenta.interfaces.midi.midi_hub import MidiHub<br/><br/># Doesn't work on Windows if the ports do not exist<br/>midi_hub = MidiHub(<strong><span>input_midi_ports</span>="magenta_in"</strong>,<br/>                   <strong><span>output_midi_ports</span>="magenta_out"</strong>,<br/>                   <span>texture_type</span>=<span>None</span>)</pre>
<p class="mce-root"/>
<p>This will create two virtual ports, <kbd>magenta_in</kbd> and <kbd>magenta_out</kbd>, if they don't exist, or use the existing ones if they do. Using only Mido, we can use the following:</p>
<pre><span class="gp">import mido<br/><br/># Doesn't work on Windows if the ports do not exist<br/>inport = mido.<strong>open_input</strong>("magenta_in")<br/></span><span class="n">outport</span> <span class="o">=</span> <span class="n">mido</span><span class="o">.</span><strong><span class="n">open_output</span></strong><span class="p">("</span><span class="s1">magenta_out"</span><span class="p">)</span></pre>
<p>Note that an input port has a <kbd>receive</kbd> method and an output port has a <kbd>send</kbd> method. When printing the ports, we should see this:</p>
<pre>Input ports: ['Midi Through:Midi Through Port-0 14:0', '<strong>RtMidiOut Client:magenta_out 128:0</strong>']<br/>Output ports: ['Midi Through:Midi Through Port-0 14:0', '<strong>RtMidiIn Client:magenta_in 128:0</strong>']</pre>
<p>The named virtual ports are now available, until restart, for applications to use.</p>
<p>However, depending on the DAW, this might or might not work. For example, Bitwig in Linux doesn't work well with ALSA virtual ports, so opening one with RtMidi is not sufficient; you'll have to look at the documentation for a workaround using <strong>JACK Audio Connection Kit</strong> (<strong>JACK</strong>). Other DAWs on Linux, such as VCV Rack, will work properly and show the virtual ports.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a virtual MIDI port on Windows using loopMIDI</h1>
                </header>
            
            <article>
                
<p>On Windows, we can't create virtual ports using the code provided earlier. Fortunately, we have the <strong>loopMIDI</strong> software (<a href="https://www.tobias-erichsen.de/software/loopmidi.html">www.tobias-erichsen.de/software/loopmidi.html</a>), a small and rather old program that is a godsend when using MIDI on Windows. The only thing it does is that it creates named virtual MIDI ports on the machine.</p>
<p class="mce-root"/>
<p>Once installed, launch the software and create two new ports named <kbd>magenta_in</kbd> and <kbd>magenta_out</kbd> using the name field at the bottom and the plus button:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d7c81c12-7fb1-405f-8035-9690b479f7d4.png" style="width:29.17em;height:19.83em;"/></p>
<p>The virtual ports named <kbd>magenta_in</kbd> and <kbd>magenta_out</kbd> should now be available both for Ableton Live and Magenta to communicate. When creating a new port, <strong>loopMIDI</strong> always creates both the input port and the output port, meaning we can both send and receive MIDI from the <kbd>magenta_in</kbd> port. We'll be keeping both ports separate for simplicity.</p>
<p>On Windows, if you have to the following error when launching the Magenta <kbd>MidiHub</kbd>, this is because you haven't properly created or named your virtual ports:</p>
<pre>INFO:tensorflow:Opening '['<strong>magenta_out 2</strong>']' as a virtual MIDI port for output.<br/>I1218 15:05:52.208604  6012 midi_hub.py:932] Opening '['<strong>magenta_out 2</strong>']' as a virtual MIDI port for output.<br/>Traceback (most recent call last):<br/>  ...<br/><strong>NotImplementedError: Virtual ports are not supported by the Windows MultiMedia API.</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>Notice the port name, <kbd>magenta_out 2</kbd>, also contains the port index, <kbd>2</kbd>. This is important when referring to ports in Windows, as they are named using the format: name index. This is kind of a pain because the port index might change if you create new ports (or plugin new MIDI devices) that shift the indexes.</p>
<p>To fix that issue, we make sure we filter the ports using string contains and not exact matching (all of our provided examples work properly in this matter).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding a virtual MIDI port on macOS</h1>
                </header>
            
            <article>
                
<p>On macOS, we can either use the previous method described in the <em><span>Looking at virtual MIDI ports</span></em> section or use the built-in macOS interface to create a new virtual port. Using the built-in interface is easy:</p>
<ol>
<li>Launch the <strong>Audio MIDI Setup</strong>.</li>
<li>Open the <strong>Window</strong> menu and click on <strong>Show MIDI Studio</strong>.</li>
<li>Choose the <strong>IAC Driver</strong> icon.</li>
<li>Activate the <strong>Device is online</strong> checkbox.</li>
</ol>
<p>We can then create named virtual ports using the <strong>+</strong> button.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending generated MIDI to FluidSynth</h1>
                </header>
            
            <article>
                
<p>To send generated MIDI from Magenta to FluidSynth, we'll take one of the first examples we wrote in <a href="b60deee5-c58f-45eb-88a2-23718802e580.xhtml"/><a href="b60deee5-c58f-45eb-88a2-23718802e580.xhtml">Chapter 2</a>, <em>Generating Drum Sequences with the DrumsRNN</em>, and add some code to send the MIDI messages directly to the software synthesizer. </p>
<div class="packt_tip">You can follow this example in the <kbd>chapter_09_example_02.py</kbd> file <span>in the source code of this chapter. There are more comments and content in the source code, so you should go check it out.</span></div>
<p><span>This is similar to what we did in the previous chapter when we used the Web MIDI API to send MIDI notes to FluidSynth from the browser:</span></p>
<ol>
<li>First, we'll start FluidSynth using one of the following:
<ul>
<li>Linux: <kbd>fluidsynth -a pulseaudio -g 1 PATH_TO_SF2</kbd></li>
<li>macOS: <kbd>fluidsynth -a coreaudio -g 1 PATH_TO_SF2</kbd></li>
<li>Windows: <kbd>fluidsynth -g 1 -o midi.winmidi.device=magenta_out PATH_TO_SF2</kbd></li>
</ul>
</li>
</ol>
<p class="mce-root"/>
<p style="padding-left: 60px">Note the <kbd>-o</kbd> flag in the Windows command, which tells FluidSynth to listen to this MIDI port because, on Windows, it doesn't open up a port automatically.</p>
<p style="padding-left: 60px">Also, notice how we aren't using the <kbd>-n</kbd> and <kbd>-i</kbd> flags this time since we want to keep incoming MIDI messages and use the synth command line. The program should stop in the command-line interface and should have created a new input MIDI port automatically (or will use the provided one).</p>
<div class="packt_infobox">On Windows, if you see the following error message upon starting FluidSynth: <strong>fluidsynth: error: no MIDI in devices found</strong> or <strong>Failed to create the MIDI thread</strong>, this means you either misspelled the MIDI port or didn't open <strong>loopMIDI</strong>.</div>
<p style="padding-left: 60px">On macOS and Linux, you can run the previous example code again, you should see an output similar to this:</p>
<pre style="padding-left: 90px">Input ports: ['Midi Through:Midi Through Port-0 14:0', 'RtMidiOut Client:magenta_out 128:0']<br/>Output ports: ['<strong>FLUID Synth (7171):Synth input port (7171:0) 129:0</strong>', 'Midi Through:Midi Through Port-0 14:0', 'RtMidiIn Client:magenta_in 128:0']</pre>
<p style="padding-left: 60px">Here, the <kbd>FLUID Synth (7171): Synth input port (7171:0) 129:0</kbd> port is the FluidSynth port. We also have the <kbd>magenta_out</kbd> and <kbd>magenta_in</kbd> ports from the previous example.</p>
<p style="padding-left: 60px">On Windows, running the previous example code again should give you this:</p>
<pre style="padding-left: 90px">Input ports: ['magenta_in 0', 'magenta_out 1']<br/>Output ports: ['Microsoft GS Wavetable Synth 1', 'magenta_in 2', <strong>'magenta_out 3'</strong>]</pre>
<p style="padding-left: 60px">The FluidSynth input port that we'll use is the <kbd>magenta_out 3</kbd> port, which should match the <kbd>-o midi.winmidi.device=magenta_out</kbd> flag provided to FluidSynth.</p>
<ol start="2">
<li>Then, we'll copy the <kbd>chapter_02_example_01.py</kbd> example:</li>
</ol>
<pre style="padding-left: 60px"><span>import argparse<br/><br/>parser = argparse.ArgumentParser()<br/>parser.add_argument("<strong>--midi_port</strong>", type=str, default="FLUID Synth")<br/>args = parser.parse_args()<br/><br/>def </span>generate(<span>unused_argv</span>):<br/><strong>  # The previous example is here</strong><br/><strong>  ...</strong><br/><br/><span>  # Write the resulting plot file to the output directory<br/>  plot_file = os.path.join("output", "out.html")<br/>  pretty_midi = mm.midi_io.note_sequence_to_pretty_midi(sequence)<br/>  plotter = Plotter()<br/>  plotter.show(pretty_midi, plot_file)<br/>  print(f"Generated plot file: {os.path.abspath(plot_file)}")<br/><br/><strong>  # Write the code to send the generated "sequence" to FluidSynth</strong><br/>  pass<br/><br/>  return 0</span><span><br/></span><span><br/></span><span>if </span>__name__ == <span>"__main__"</span>:<br/>  tf.app.run(generate)</pre>
<p style="padding-left: 60px">We add a <kbd>--midi_port</kbd> flag to change the MIDI output port (remember the input and output terminology is from Magenta's perspective) easily for our examples. We'll be writing the code to send the MIDI content (which is in the <kbd>sequence</kbd> variable) at the end of the <kbd>generate</kbd> method.</p>
<ol start="3">
<li>We find the provided output port and initialize <kbd>MidiHub</kbd> using the port:</li>
</ol>
<pre style="padding-left: 60px"><span>import mido<br/>from magenta.interfaces.midi.midi_hub import MidiHub<br/><br/></span><span># We find the proper input port for the software synth<br/></span><span># (which is the output port for Magenta)<br/></span>output_ports = [<strong>name <span>for </span>name <span>in </span>mido.get_output_names()</strong><br/><strong>               <span>if </span><span>args.midi_port </span><span>in </span>name</strong>]<br/><br/><span># Start a new MIDI hub on that port (output only)<br/></span><strong>midi_hub = MidiHub(<span>input_midi_ports</span>=[], </strong><br/><strong>                   <span>output_midi_ports</span>=output_ports, </strong><br/><strong>                   <span>texture_type</span>=<span>None</span>)</strong></pre>
<p style="padding-left: 60px">We then start a new MIDI hub on that port; it will serve as a communication interface between our app and the synth. It is useful because it enables us to use <kbd>NoteSequence</kbd> objects directly without the need of converting them by hand.</p>
<div class="packt_tip">The <kbd>midi_hub</kbd> module is located in Magenta in the <kbd>magenta.interfaces.midi</kbd> module and contains useful utilities for handling MIDI.</div>
<p class="mce-root"/>
<ol start="4">
<li>Next, we'll get a player instance from the hub and set the playback channel to <kbd>9</kbd>:</li>
</ol>
<pre style="padding-left: 60px">import music_pb2<br/><br/>empty_sequence = music_pb2.NoteSequence()<br/><strong>player = midi_hub.start_playback(empty_sequence, <span>allow_updates</span>=<span>True</span>)</strong><br/>player._channel = <span>9</span></pre>
<p style="padding-left: 60px">Remember that GM 1 compatible synthesizers will play the drums sound bank if the MIDI channel is <kbd>10</kbd> (but the channel is zero-indexed in Magenta MIDI hub so we have to use <kbd>9</kbd>). We'll be starting the playback on an empty sequence, allowing the update of the sequence later.</p>
<ol start="5">
<li>Now we can play our <kbd>sequence</kbd>, but we need to adjust it first so that the player knows when it starts:</li>
</ol>
<pre style="padding-left: 60px"><span>import time<br/></span><span>from </span>magenta.interfaces.midi.midi_interaction <span>import </span>adjust_sequence_times<span><br/><br/><strong>wall_start_time = time.time()</strong><br/>sequence_adjusted = music_pb2.NoteSequence()<br/>sequence_adjusted.CopyFrom(sequence)<br/><strong>sequence_adjusted = adjust_sequence_times(sequence_adjusted, </strong><br/><strong>                                          wall_start_time)</strong></span></pre>
<p style="padding-left: 60px">The MIDI player will play <kbd>sequence</kbd> according to wall time, but our sequence starts at <kbd>0</kbd> (the wall time is the time since epoch). For example, if the wall time (which is given by <kbd>time.time()</kbd>) is <kbd>1564950205</kbd>, then we need to update the start of the sequence forward by that amount. We do that by keeping our current sequence intact and making a copy that will be given to the player. We use the <kbd>adjust_sequence_times</kbd> function from Magenta to do that.</p>
<div class="packt_infobox"><span>Notice here the usage of the <kbd>CopyFrom</kbd></span> method<span>, which is present on Protobuf message objects. You can always go check the methods on the</span> <kbd>google.protobuf.message.Message</kbd> <span>class to find useful methods for</span> <kbd>NoteSequence</kbd><span>.</span></div>
<ol start="6">
<li>Now that we adjusted our sequence to the proper time, let's play it! We use the <kbd>update_sequence</kbd> method on the player to do this, which is the equivalent of <kbd>play</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>player.update_sequence(sequence_adjusted, start_time=wall_start_time)</strong><br/>try:<br/>  player.<strong>join</strong>(generation_end_time)<br/>except KeyboardInterrupt:<br/>  return 0<br/>finally:<br/>  return 0</pre>
<p style="padding-left: 60px">We also give the <kbd>start_time</kbd> argument to the player <kbd>instance</kbd>, which is equal to the start of our adjusted (shifted forward) sequence.</p>
<p style="padding-left: 60px">Since <kbd>player</kbd> is a thread, we need to wait for it to finish before exiting or the program will exit before the sequence has played. We do that by using the <kbd>join</kbd> method on the player instance, which is present on any thread class. That method will block until the thread finishes, but because the player thread never stops, this call will block indefinitely. By adding a timeout of <kbd>generation_end_time</kbd>, which is the length of the generated sequence, the call will return after the end of the sequence being played. A blocked join call can always be interrupted by pressing <em>Ctrl </em>+ <em>C</em>, which can be caught using the <kbd>KeyboardInterrupt</kbd> exception class.</p>
<ol start="7">
<li>We can now launch the program by using the following on Linux and macOS:</li>
</ol>
<pre style="padding-left: 60px"><strong>&gt; python chapter_09_example_02.py</strong></pre>
<p style="padding-left: 60px">By keeping the default <kbd>--midi_port</kbd> flag, it will use the port started by FluidSynth.</p>
<p style="padding-left: 60px">Or we can use the <kbd>magenta_out</kbd> MIDI port on Windows:</p>
<pre style="padding-left: 60px"><strong>&gt; python chapter_09_example_02.py --midi_port=magenta_out</strong></pre>
<p>You should now hear your music play from FluidSynth! When executing the code, you might see the following warning:</p>
<pre><strong>WARNING:tensorflow:No input port specified. Capture disabled.</strong></pre>
<p>This is because the MIDI hub can also receive a MIDI message, but we haven't provided any MIDI port to do so. This is only a warning and shouldn't be an issue.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending generated MIDI to a DAW</h1>
                </header>
            
            <article>
                
<p>Sending MIDI to FluidSynth is nice, but you probably want to use another software for producing music. We won't be looking at every DAW, but we'll show examples that can be applied for most music production software.</p>
<p class="mce-root"/>
<p>Now that we have Virtual MIDI ports opened for transferring MIDI from our Magenta application, let's try it out in Ableton Live. You can also try this in any other DAW that has MIDI functionalities.</p>
<div class="packt_tip">You can find the Ableton Live set (with the <kbd>.als</kbd> file extension) in the <kbd>chapter_09_example_02.als</kbd> file in the source code of this chapter.<br/>
<br/>
You can use this Ableton set along with the Python code we've shown in the previous example, <kbd>chapter_09_example_02.py</kbd>.</div>
<p>Let's configure the <kbd>magenta_out</kbd> port in Ableton Live that will be also used by the Magenta app:</p>
<ol>
<li>First, in Ableton, go to <strong>File</strong> &gt; <strong>Options</strong> &gt; <strong>Preferences...</strong> &gt; <strong>Link</strong> <strong>MIDI</strong> and find the <kbd>magenta_out</kbd> input:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9ae7cc95-2305-4537-b10f-8c7b4f93b034.png" style="width:29.50em;height:35.42em;"/></p>
<p style="padding-left: 60px">We need to activate both <strong>Track</strong> and <strong>Remote</strong> to <strong>On</strong> to receive the MIDI notes.</p>
<ol start="2">
<li>Now that the MIDI input is activated, we can create a new MIDI track by right-clicking in the <strong>Drop Files and Devices Here</strong> section and choosing <strong>Insert MIDI track</strong>.</li>
<li>In the new track, we see the following <strong>MIDI from</strong> section:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d15f36d7-c478-42ea-8091-00dc5864132e.png" style="width:54.42em;height:42.83em;"/></p>
<p class="mce-root"/>
<p style="padding-left: 60px">In the screenshot, we highlighted three parts:</p>
<ul>
<li style="padding-left: 60px">The <strong>MIDI From</strong> section, which is available for a MIDI track, where we can now select the <kbd>magenta_out</kbd> MIDI port. We also selected <strong>Ch. 10</strong> for the drum channel 10 and <strong>Monitor</strong> to <strong>In</strong>.</li>
<li style="padding-left: 60px">The <strong>third octave</strong> on the 8-octave strip that represents all of the 127 possible MIDI values, where the <strong>808 Core Kit</strong> is defined. This corresponds to MIDI notes 36 to 52 and you can see note 38 is currently playing.</li>
<li style="padding-left: 60px">The currently playing note, the <strong>Snare 808</strong>, in the <strong>808 Core Kit</strong> instrument.</li>
</ul>
<p style="padding-left: 60px">On the top-right corner, a yellow indicator shows whether there is incoming MIDI or not, which is useful for debugging.</p>
<ol start="4">
<li>Now that we have our Ableton Live setup, we can launch our application by using this:</li>
</ol>
<pre style="padding-left: 60px"><strong>&gt; python chapter_09_example_02.py --midi_port="magenta_out"</strong></pre>
<p>You should receive MIDI in Ableton Live and hear the <strong>808 Core Kit</strong> play the percussion.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using NSynth generated samples as instruments</h1>
                </header>
            
            <article>
                
<p>In the previous <a href="feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml">Chapter 5</a>, <em>Audio Generation with NSynth and GANSynth</em>, we talked about using our generated samples by sequencing them using the generated MIDI from Magenta. Since we can now dynamically send the generated MIDI to a DAW, now is a good time to test this out.</p>
<p>In Ableton Live, in the <strong>808 Core Kit</strong> section, we can drag and drop a generated sample to replace an existing drum kit sample. For example, we could change the <strong>Cowbell 808</strong> instrument with one of our samples, for example, <kbd>160045_412017</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/fffb1961-7ba1-4d2e-8d16-7cfb417bc7f0.png"/></p>
<p class="mce-root"/>
<p>When double-clicking on the new sound, the sampler interface will open, which lets you modify the start and the end of the loop, as well as the volume. We choose that sample because it has a strong attack (the sound envelope goes up fast), which is perfect for a percussive sample. Go ahead and experiment with your own samples.</p>
<p>When mapping drum sounds on channel 10, remember the percussion instrument is chosen according to the MIDI pitch note. In the previous figure, the 16 instruments in the grid are mapped to the MIDI pitches as follows:</p>
<table border="1" style="border-collapse: collapse;width: 100%;border-color: #000000;height: 200px">
<tbody>
<tr style="height: 49px">
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>48</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>49</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>50</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>51</strong></td>
</tr>
<tr style="height: 48px">
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 48px"><strong>44</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 48px"><strong>45</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 48px"><strong>46</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 48px"><strong>47</strong></td>
</tr>
<tr style="height: 49px">
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>40</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>41</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>42</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 49px"><strong>43</strong></td>
</tr>
<tr style="height: 47.2334px">
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 47.2334px"><strong>36</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 47.2334px"><strong>37</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 47.2334px"><strong>38</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 10%;height: 47.2334px"><strong>39</strong></td>
</tr>
</tbody>
</table>
<p> </p>
<p>Here, pitch 36 corresponds to <strong>Kick 808</strong>, pitch 37 to <strong>Rim 808</strong>, pitch 51 to our <kbd>160045_412017</kbd><span> </span><span>sample</span><span>, and so on. You can compare that grid with the MIDI plot that is outputted by our program (in</span> <kbd>output/out.html</kbd><span>).</span></p>
<p>This works well for drum elements. But if you are sending a melody to your DAW, you will want to use a sampler, which will change the pitch of the sound, depending on the incoming note. To do that, in Ableton Live, follow these steps:</p>
<ol>
<li>Create a new MIDI track by right-clicking in the <strong>Drop Files and Devices Here</strong> section and choosing <strong>Insert MIDI track</strong>.</li>
<li>Find the <strong>Sampler</strong> instrument by choosing <strong>Instruments</strong> &gt; <strong>Sampler</strong>.</li>
<li>Drag and drop the <strong>Sampler</strong> in the <strong>Drop Audio Effects Here</strong> at the bottom (in the new MIDI track).</li>
<li>Drag and drop the <kbd>412017_83249</kbd> generated sample (or another of your choice) in the <strong>Drop Sample Here</strong> at the bottom (in the <strong>Sampler</strong>).</li>
</ol>
<p class="mce-root"/>
<p>We've chosen the <kbd>412017_83249</kbd> generated sample since the cat sound makes a good (and funny) note when played as a melody. You should have the following interface:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/96079478-eace-493b-8250-ca73b5c224e6.png"/></p>
<p>Now when you send a melody from your Magenta program, you will hear the sample, <kbd>412017_83249</kbd>, getting played and pitched up and down, following the melody notes pitch.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Looping the generated MIDI</h1>
                </header>
            
            <article>
                
<p>Now that we can send generated MIDI to a DAW, let's have a look at how to loop the generated MIDI. This opens up many different use cases, such as building a system that <strong>generates music continuously</strong>. We'll first have a look at how to loop <kbd>NoteSequence</kbd>. We'll also cover how to synchronize Magenta with a DAW using a MIDI clock, which is important in long-running live music systems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the MIDI player to loop a sequence</h1>
                </header>
            
            <article>
                
<p>In this example, we'll be using the <kbd>player</kbd> instance from Magenta to loop a generated <kbd>NoteSequence</kbd>, by copying the sequence and playing it at a later time, before the player ends its playback.</p>
<div class="packt_tip">You can follow this example in the <kbd>chapter_09_example_03.py</kbd> file <span>in the source code of this chapter. There are more comments and content in the source code, so you should go check it out.</span></div>
<p class="mce-root"/>
<p>Let's take our previous example and make the sequence loop indefinitely:</p>
<ol>
<li>First, let's find the period, which is equivalent to the loop time in seconds:</li>
</ol>
<pre style="padding-left: 60px"><span>from </span>decimal <span>import </span>Decimal<br/><span>from magenta.common import concurrency<br/><br/></span>period = <strong>Decimal(<span>240</span>) / qpm</strong><br/>period = <strong>period * (num_bars + <span>1</span>)</strong><br/><strong>sleeper = concurrency.Sleeper()</strong></pre>
<p style="padding-left: 60px">Here, we want a period (in seconds) of 4 bars, which is the loop length. Using 240/QPM, we get the period for 1 bar (for example, 2 seconds at 120 QPM). We then multiply that by 4 bars (<kbd>num_bars + 1</kbd>), which is our loop length. Also, we are using the <kbd>Decimal</kbd> class, which doesn't have rounding errors like the built-in <kbd>float</kbd>, for increased accuracy for the timing.</p>
<p style="padding-left: 60px">We make use of the <kbd>Sleeper</kbd> class from Magenta, which implements a more precise version of <kbd>sleep</kbd> than the one present in the <kbd>time</kbd> module, so it should wake up more consistently with proper timing.</p>
<ol start="2">
<li>Let's now define the main loop, which will copy the current sequence, adjust it in time, and play it using the player:</li>
</ol>
<pre style="padding-left: 60px"><span>while True</span>:<br/>  <span>try</span>:<br/>    <span># We get the next tick time by using the period<br/></span><span>    # to find the absolute tick number (since epoch)</span><span><br/></span><span>    </span>now = Decimal(time.time())<br/><strong>    tick_number = int(now // period)</strong><br/>    tick_number_next = tick_number + 1<br/><strong>    tick_time = tick_number * period</strong><br/>    tick_time_next = tick_number_next * period<br/><br/>    <span># Update the player time to the current tick time<br/></span><span>    </span>sequence_adjusted = music_pb2.NoteSequence()<br/>    sequence_adjusted.CopyFrom(sequence)<br/><strong>    sequence_adjusted = adjust_sequence_times(sequence_adjusted,</strong><br/><strong>                                              <span>float</span>(tick_time))</strong><br/><strong>    player.update_sequence(sequence_adjusted,</strong><br/><strong>                           <span>start_time</span>=<span>float</span>(tick_time))</strong><br/><br/>    <span># Sleep until the next tick time<br/></span><strong><span>    </span>sleeper.sleep_until(<span>float</span>(tick_time_next))</strong><br/>  <span>except </span><span>KeyboardInterrupt</span>:<br/>    <span>print</span>(<span>f"Stopping"</span>)<br/>    <span>return </span><span>0</span></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px">Let's break the code down a bit:</p>
<ul>
<li style="padding-left: 60px">On each loop start, we get the current time since epoch (in <kbd>now</kbd>).</li>
<li style="padding-left: 60px">We get the current tick number, by dividing the current time by the period (in <kbd>tick_number</kbd><span>). The tick number corresponds to the current index in a separation of the time from epoch to now in intervals of</span> <kbd>period</kbd><span>.</span></li>
<li style="padding-left: 60px">We get the current tick time by multiplying the period with the tick number (in <kbd>tick_time</kbd><span>).</span></li>
</ul>
<p style="padding-left: 60px">For example, if the start time is <kbd>1577021349</kbd>, we have a ticking time of <kbd>1577021344</kbd> and a next tick time of <kbd>1577021352</kbd> (for a period of 8 seconds). In this case, we are on the first iteration of the loop, which is why there is such a big difference between the start time and the ticking time. On the second loop, the start time will be <kbd>1577021352</kbd> (approximately) because the thread will wake up with proper timing.</p>
<p style="padding-left: 60px">Because of the start time difference on the first loop, this means that when the player starts, it might start in the middle of the generated sequence. If we want to make it start at the beginning of the sequence, we need to subtract the start time when calculating the tick number. See the <kbd>Metronome</kbd> class in the <kbd>magenta.interfaces.midi.midi_hub</kbd> module for a more complete implementation.</p>
<p style="padding-left: 60px">Finally, we update the sequence and the player using <kbd>tick_time</kbd> and we sleep until <kbd>tick_time_next</kbd>.</p>
<ol start="3">
<li>We can now launch the program by using this:</li>
</ol>
<pre style="padding-left: 60px"><strong>&gt; python chapter_09_example_03.py --midi_port="magenta_out"</strong></pre>
<p>You should now hear a 4-bar loop of 8 seconds at 120 QPM playing in the DAW you are using.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Synchronizing Magenta with a DAW</h1>
                </header>
            
            <article>
                
<p>Synchronizing devices when playing instruments is important. Two instruments that are in sync will have the <strong>same QPM</strong> (<strong>tempo</strong>) and start on the <strong>same beat</strong> (<strong>phase</strong>). Addressing those problems is simple on the surface, but good sync is hard to achieve because precise timing is difficult.</p>
<p>Syncing our Magenta application with a DAW has many usages, such as recording the MIDI sequences in a DAW with proper timing (tempo and phase), or playing multiple sequences at the same time, some coming from Magenta and the others coming from the DAW.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending MIDI clock and transport</h1>
                </header>
            
            <article>
                
<p>In this example, we'll synchronize Magenta with a DAW using a MIDI clock and transport (start, stop, and reset) information. The MIDI clock is one of the oldest and more popular ways of synchronizing devices, which is available for pretty much every instrument and music software.</p>
<p>We'll be giving the example in Ableton Live, but you can also try this in any DAW that has MIDI clock functionality.</p>
<div class="packt_tip">You can follow this example in the <kbd>chapter_09_example_04.py</kbd> file <span>in the source code of this chapter. There are more comments and content in the source code, so you should go check it out.</span></div>
<p>To sync our Magenta program to Ableton Live, we'll launch a metronome thread that wakes up on every beat and sends a clock message:</p>
<ol>
<li>First, let's declare the <kbd>Metronome</kbd> class that extends the <kbd>Thread</kbd> class:</li>
</ol>
<pre style="padding-left: 60px"><span>import mido<br/>from decimal import Decimal<br/>from threading import Thread<br/><br/>class </span>Metronome(Thread):<br/><br/>  <span>def </span><span>__init__</span>(<span>self</span>, outport, qpm):<br/>    <span>super</span>(Metronome, <span>self</span>).<span>__init__</span>()<br/><strong>    <span>self</span>._message_clock = mido.Message(<span>type</span>=<span>'clock'</span>)</strong><br/><strong>    <span>self</span>._message_start = mido.Message(<span>type</span>=<span>'start'</span>)</strong><br/><strong>    <span>self</span>._message_stop = mido.Message(<span>type</span>=<span>'stop'</span>)</strong><br/><strong>    <span>self</span>._message_reset = mido.Message(<span>type</span>=<span>'reset'</span>)</strong><br/>    <span>self</span>._outport = outport<span><br/></span><strong><span>    </span><span>self</span>._period = Decimal(<span>2.5</span>) / qpm</strong><br/>    <span>self</span>._stop_signal = <span>False<br/></span><span><br/>  def stop(self):<br/>    self._stop_signal = True<br/><br/></span><span>  def </span>run(<span>self</span>):<br/><strong>    # Run code</strong><br/><strong>    pass</strong><span><br/></span></pre>
<p style="padding-left: 60px">At instantiation, we use Mido to define the following messages (see the last section, <em>Further reading</em>, for more documentation on the messages supported by Mido and to what they correspond in the MIDI specification):</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><span>The </span><kbd>clock</kbd><span> message, which is sent every beat</span></li>
<li>The <kbd>start</kbd> message, which is sent when the sequence starts</li>
<li>The <kbd>stop</kbd> message, which is sent when the sequence ends, or when the program exits</li>
<li>The <kbd>reset</kbd> message, which is sent before the start message, making sure that the synced device restarts from the beginning in terms of beat count</li>
<li>The <kbd>continue</kbd> message, which we won't use, but can be used to restart the playback without resetting the beat count</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">We also define the period, which is the exact time between each thread wake up. The thread needs to wake up at each beat, so in 4/4 time at 120 QPM, it needs to wake up every 0.5 seconds, which is the period.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<div class="packt_infobox">Here, we choose to synchronize both applications using one message (or pulse) per beat, which is our period, since it is easy to do. In the MIDI specification (<a href="https://www.midi.org/specifications/item/table-1-summary-of-midi-message">www.midi.org/specifications/item/table-1-summary-of-midi-message</a>), another synchronization period is described, which is called <strong>24</strong> <strong>Pulses Per Quarter Note</strong> (<strong>24</strong> <strong>PPQN</strong>), which is more precise than what we are implementing here.<br/>
<br/>
One pulse per beat and 24 PPQN are both used in many DAWs and instruments. There are other synchronization pulses, however, such as 48 PPQN for Korg instruments. There are also other ways of synchronizing instruments, such as the <strong>MIDI Time Code</strong> (<strong>MTC</strong>), which we won't see here.<br/>
<br/>
Depending on the software or hardware you are trying to sync, make sure to check what type of synchronization pulse they are configured to handle. If this doesn't work, it is probably because you are sending an unexpected pulse rate.</div>
<ol start="2">
<li>Let's now implement the <kbd>run</kbd> method in the <kbd># Run code</kbd> comment:</li>
</ol>
<pre style="padding-left: 60px"><span>import time<br/>from magenta.common.concurrency import Sleeper<br/><br/>def </span>run(<span>self</span>):<br/>  sleeper = Sleeper()<br/><br/>  <span># Sends reset and the start, we could also<br/></span><span>  # use the "continue" message<br/></span><strong><span>  </span><span>self</span>._outport.send(<span>self</span>._message_reset)</strong><br/><strong>  <span>self</span>._outport.send(<span>self</span>._message_start)</strong><br/><br/>  <span># Loops until the stop signal is True<br/></span><span>  </span><span>while not </span><span>self</span>._stop_signal:<br/>    <span># Calculates the next tick for current time<br/></span><span>    </span>now = Decimal(time.time())<br/>    tick_number = <span>max</span>(<span>0</span>, <span>int</span>(now // <span>self</span>._period) + <span>1</span>)<br/><strong>    tick_time = tick_number * <span>self</span>._period</strong><br/><strong>    sleeper.sleep_until(<span>float</span>(tick_time))</strong><br/><br/>    <span># Sends the clock message as soon it wakeup<br/></span><strong><span>    </span><span>self</span>._outport.send(<span>self</span>._message_clock)</strong><br/><br/>  <span># Sends a stop message when finished<br/></span><strong><span>  </span><span>self</span>._outport.send(<span>self</span>._message_stop)</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px">The following list further explains the code:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li>When<span> </span><span>the thread first starts, it sends a </span><kbd>reset</kbd><span> message followed by a </span><kbd>start</kbd><span> message, meaning Ableton Live will reset its beat count to 0, and then start the playback.</span></li>
<li>Then, we calculate the next tick time and make the thread sleep to that time (see the previous section explanation on the ticking time). At wake up, we send the <kbd>clock</kbd> message, which will happen at every beat.</li>
<li>Finally, if the <kbd>stop</kbd> method is called, <kbd>self._stop_signal</kbd> is set to <kbd>True</kbd>, which will exit the loop, sending the <kbd>stop</kbd> message.</li>
</ul>
</li>
</ul>
<ol start="3">
<li>Let's initialize the thread and launch it:</li>
</ol>
<pre style="padding-left: 60px"><span>import argparse<br/><br/>parser = argparse.ArgumentParser()<br/>parser.add_argument("--midi_port", type=str, default="magenta_out")<br/>args = parser.parse_args()<br/><br/>def </span>send_clock():<span><br/></span><span>  </span>output_ports = [name <span>for </span>name <span>in </span>mido.get_output_names()<br/>                  <span>if </span>args.midi_port <span>in </span>name]<span><br/>  </span>midi_hub = MidiHub(<span>input_midi_ports</span>=[],<br/>                     <span>output_midi_ports</span>=output_ports,<br/>                     <span>texture_type</span>=<span>None</span>)<br/><strong>  outport = midi_hub._outport</strong><br/><br/>  <span># Starts the metronome at 120 QPM<br/></span><strong><span>  </span>metronome = Metronome(outport, <span>120</span>)</strong><br/><strong>  metronome.start()</strong><br/><br/>  <span># Waits for 16 seconds and send the stop command<br/></span><strong><span>  </span>metronome.join(<span>timeout</span>=<span>16</span>)</strong><br/><strong>  metronome.stop()</strong><br/><br/>  <span>return </span><span>0<br/></span><span><br/></span><span><br/></span><span>if </span>__name__ == <span>"__main__"</span>:<br/>  send_clock()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The following list explains it further:</p>
<ul>
<li style="padding-left: 60px"><span>The code is similar to our previous example. The first thing we change is that we keep a reference to the </span><kbd>midi_hub._outport</kbd><span> port so that we can send the MIDI clock to it.</span></li>
<li style="padding-left: 60px">Then, we initialize the <kbd>Metronome</kbd> <span>class using </span><kbd>outport</kbd> <span>and start it using</span> <kbd>start</kbd><span>. This will execute the</span> <kbd>run</kbd> <span>method in the thread.</span></li>
<li style="padding-left: 60px">We then <kbd>join</kbd> <span>on the thread with a timeout of 16 (seconds), meaning we'll play 8 bars before exiting and calling the</span> <kbd>stop</kbd> <span>method. We do this solely to show the stop usage and its impact on Ableton Live.</span></li>
</ul>
<ol start="4">
<li>In Ableton Live, we need to make sure that the <strong>Sync</strong> button is <strong>On</strong> for the <kbd>magenta_out</kbd> port:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5d0955ca-b0c0-416c-9548-9204dc051d27.png" style="width:26.33em;height:10.00em;"/></p>
<ol start="5">
<li>Once we've done that, we need to make sure that the <strong>Ext</strong> button on the top-left of the screen is activated:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8de26762-ee96-4ef3-b1d7-f2c8aaf269ae.png" style="width:65.75em;height:4.17em;"/></p>
<p style="padding-left: 60px">The <strong>Ext</strong> button, short for <strong>External</strong>, means that Ableton won't use its internal clock, but rather rely on an external source for the clock.</p>
<div class="packt_infobox">Most DAWs and hardware synths have a similar <strong>External</strong> option but this is often deactivated by default. Make sure to check how to activate that for the software or hardware you are trying to sync.</div>
<p style="padding-left: 60px">On the right of the <strong>Ext</strong> button, two indicators show incoming and outgoing MIDI clock messages, which is useful for debugging. We've also highlighted the following:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><span>The </span><strong>QPM indicator</strong><span>, which will get updated to 120 during playback (currently at 110 QPM for testing purpose)</span></li>
<li>The <strong>Arrangement position</strong> section, that shows <strong>9.1.1</strong>, which is the value the beat count will be at when our Python program exists and sends the <kbd>stop</kbd> message (because we stop after 8 bars)</li>
<li>The <strong>Transport section</strong> with the start, stop and record buttons, which will update when we start and stop the program</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">We can now send the MIDI clock to Ableton Live.</p>
<ol start="6">
<li>Finally, let's launch our Magenta application:</li>
</ol>
<pre style="padding-left: 60px"><strong>&gt; python chapter_09_example_04.py --midi_port="magenta_out"</strong></pre>
<p>In Ableton Live, you should see the BPM change to 120 QPM. It might take time to get there, and it might oscillate up and down while it stabilizes, but it should converge to 120 QPM. After 16 seconds, Ableton Live should stop, with a final beat count of 8 full beats (shown as <strong>9.1.1</strong>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using MIDI control message</h1>
                </header>
            
            <article>
                
<p>Sending the MIDI clock is the most common way of synchronizing devices because all devices support the MIDI clock. Another way of synchronizing Magenta with a DAW would be to use <strong>MIDI control messages</strong>.</p>
<p>A MIDI control message is a message that sends <kbd>control</kbd> and <kbd>value</kbd>. For example, we could be using the following Mido message to send MIDI control: <kbd>mido.Message(type="control_change", control="...", value"...")</kbd>. Let's define some control message for the actions we want to make:</p>
<ul>
<li><strong>Start/stop</strong>: This is to start and stop the transport, which will be used to synchronize the phase (using <kbd>control="1"</kbd> and <kbd>control="2"</kbd>, respectively).</li>
<li><strong>QPM</strong>: This is to set the tempo before the transport starts (using <kbd>control="3"</kbd>).</li>
</ul>
<p>This is just an example of control values; you can use whatever value you want, as long as it is properly mapped on the DAW side. In most DAWs, mapping a control message to input is easy. Often, a <kbd>learn</kbd> function is provided, which, once activated, will map the selected input in the DAW to whatever MIDI message comes next.</p>
<p>Let's try this in Ableton Live:</p>
<ol>
<li>Activate the MIDI mapping mode using the <strong>MIDI</strong> button in the upper-right corner (all of the mappable inputs in Ableton will turn to purple).</li>
<li>Select the input you want to map (<strong>QPM</strong>, for example) and then send the corresponding MIDI control message (see the previous code snippet), which will map the input to the control message.</li>
<li>After the MIDI control message is received, the input in Ableton will be mapped to it.</li>
<li>Exit the MIDI mapping mode, then send the same MIDI control message. The mapped input should activate.</li>
</ol>
<p>Once all of our inputs are mapped, we can send the corresponding messages from our Magenta application, to start, stop, and change the QPM when needed. For example, the Magenta application can send the QPM before starting, and then when sending the first MIDI note, send the MIDI control message <strong>start</strong> at the same time.</p>
<p>The downside of this approach is that if any of the two applications become desynced, there isn't any way of syncing the applications back together without stopping and restarting the playback. MIDI clock, on the other hand, is constantly syncing the devices together.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Ableton Link to sync devices</h1>
                </header>
            
            <article>
                
<p class="mce-root">Ableton Link (<a href="https://github.com/Ableton/link">github.com/Ableton/link</a>) is an open source standard aimed at synchronizing software devices. It enables auto-discovery across a local network and is easy to use. A lot of DAWs now support Ableton Link, which is yet another way of syncing our Magenta application to a DAW but necessitates implementing the specification.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending MIDI to a hardware synthesizer</h1>
                </header>
            
            <article>
                
<p>Sending MIDI to a hardware synthesizer is very similar to what we've been doing in the previous sections, with the exception that the hardware synthesizer should open a new MIDI port by itself (just like FluidSynth) so we don't need to create a virtual port for it.</p>
<p>We'll be using an Arturia BeatStep Pro for our example, but this should work with any MIDI-enabled device:</p>
<ol>
<li>First, we need to install the drivers for the synthesizer, which might or might not be necessary, depending on the synth and the platform.</li>
</ol>
<ol start="2">
<li>Then, we connect the synthesizer using USB to the computer and run the first example to find what are the declared MIDI ports. For the Arturia BeatStep Pro on Windows, we have the output port, <kbd>MIDIIN2 (Arturia BeatStep Pro) 1</kbd>.</li>
<li>Now, we can run our previous example, by changing the Magenta output port with the synthesizer input port:</li>
</ol>
<pre style="padding-left: 60px"><strong>&gt; python chapter_09_example_03.py --midi_port="MIDIIN2 (Arturia BeatStep Pro) 1"</strong></pre>
<p>This should send the MIDI directly to the hardware synthesizer.</p>
<p>This example sends MIDI using USB MIDI, which is not available on all synthesizers. Some synthesizers only support MIDI using a MIDI cable, not a USB cable, which means you'll need a sound card or a USB to MIDI converter. The procedure is still the same, but you'll have to go through the sound card or the converter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Magenta as a standalone application with Magenta Studio</h1>
                </header>
            
            <article>
                
<p>Magenta Studio is the closest you can get to a Magenta standalone application, in the sense that it doesn't require any installation and any knowledge of technologies to make it work. This is especially important, because Magenta and the technology that powers it is complex, but in the end, it is <strong>important that everybody can use it</strong>.</p>
<p>We'll be looking at how Magenta Studio works and find many elements we've already covered in the previous chapters. Magenta Studio comes in two packagings:</p>
<ul>
<li>As <strong>Ableton Live Plugins</strong> (<a href="https://magenta.tensorflow.org/studio/ableton-live">magenta.tensorflow.org/studio/ableton-live</a>), which integrates Magenta into Ableton Live using the Max for Live integration and Magenta.js applications (supported on Windows and macOS)</li>
<li>As <strong>Standalone Applications</strong> (<a href="https://magenta.tensorflow.org/studio/standalone">magenta.tensorflow.org/studio/standalone</a>), which are Electron applications (supported on all platforms)</li>
</ul>
<p>We won't be talking about the standalone applications too much because we've already covered everything we need to know about them. Indeed, an Electron application is a Node.js application packaged with its runtime and a Chromium browser, so we've already covered that content in the previous <a href="cafc52b5-bd8c-41ba-a6f0-eb002405ffca.xhtml">Chapter 8</a>, <em>Magenta in the Browser with Magenta.js</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Looking at Magenta Studio's content</h1>
                </header>
            
            <article>
                
<p>Since both packagings are based on Magenta.js, they both contain the same features:</p>
<ul>
<li><strong>CONTINUE</strong> makes use of MusicRNN (LSTM based), either the DrumsRNN model or the MelodyRNN model depending on the usage, to continue a sequence from a primer.</li>
<li><strong>GENERATE</strong> makes use of the MusicVAE model, using a 4 bar model for the drums or the melody generation.</li>
<li><strong>INTERPOLATE</strong> also makes use of the MusicVAE model.</li>
<li><strong>GROOVE</strong> makes the use of the GrooVAE model to add groove to a quantized sequence.</li>
<li><strong>DRUMIFY</strong> uses the GrooVAE tap model to convert a <strong>tap sequence</strong> into a <strong>drum sequence</strong>.</li>
</ul>
<p>When downloading the standalone version, you'll be able to install (using <kbd>.exe</kbd> or <kbd>.dmg</kbd> depending on the platform) any of the five applications. When installed and launched, the applications are shown as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bf8f39f5-7eb5-489b-9845-343216c956b9.png"/></p>
<p>You can find many parameters we already talked about: temperature, length, variations (number of generated sequences), steps (number of interpolations), and so on. The difference between the standalone and the Ableton packaging is how they integrate with our music tool: the standalone application can work with files on disk (as shown in the previous screenshot, with the <strong>Choose file...</strong> button) and the Ableton Live plugin can directly read and write clips in the <strong>Session View</strong>.</p>
<p class="mce-root">Let's have a look at the Ableton Live Plugins integration.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Integrating Magenta Studio in Ableton Live</h1>
                </header>
            
            <article>
                
<p>The Magenta Studio plugin integration in Ableton Live is nice because it corresponds to the idea of a <strong>machine learning augmented</strong> music production environment. In general, the integration of Magenta in existing tools is important, and Magenta Studio is a good example of that.</p>
<p>It is interesting to understand how the Ableton Live plugins are designed since it is quite clever. In Ableton Live, you can integrate a Max MSP application as a plugin or device. Max MSP (<a href="https://cycling74.com/products/max-features/">cycling74.com/products/max-features/</a>) is a powerful visual programming language for music. The Ableton Live Plugins works as follows:</p>
<ol>
<li>Ableton Live launches the <kbd>magenta.amxd</kbd> patch, which is a Max MSP program.</li>
<li>The Max MSP program shows a UI in Ableton Live, in which we can choose any of the <strong>Continue</strong>, <strong>Generate</strong>, and other programs.</li>
<li>When chosen, the Max MSP program will launch a Node.js process, containing the Magenta.js application (which is the same as the standalone application).</li>
<li>Using the Max MSP API, the Magenta.js application can see the Ableton Live <strong>Session View</strong> content, including clips and tracks, and write content.</li>
</ol>
<p>For now, Magenta Studio integrates only in Ableton Live. Other DAWs might be integrated in the future, as Magenta Studio's implementation has nothing specific to Ableton Live.</p>
<div class="packt_tip packt_infobox">For this example to work, we need Ableton Live 10.1 Suite since the integration of Max For Live (only in the <strong>Suite</strong> version) is necessary for Magenta Studio to work. You can try the demo at <a href="https://www.ableton.com/en/trial/">www.ableton.com/en/trial/</a> if you don't have the program handy.</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Let's go through a complete example using the <strong>Continue</strong> application:</p>
<ol>
<li>From <a href="https://magenta.tensorflow.org/studio/ableton-live">magenta.tensorflow.org/studio/ableton-live</a>, download the Max MSP patch using the <strong>Download</strong> button for your platform, which should download the <kbd>magenta_studio-VERSION-windows.amxd</kbd> file.</li>
<li>Open Ableton Live, create a new MIDI track, and drag and drop the file in the MIDI track devices (it might take a while to load):</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ee302ade-3546-490e-a3c2-65c6c8223659.png"/></p>
<p style="padding-left: 60px">In the previous screenshot, we see that we recorded two MIDI clips from our previous example, <strong>MIDI from Magenta 1</strong> and <strong>MIDI from Magenta 2</strong>, which we'll use to generate new content using the <strong>Continue</strong> plugin. We can see the Magenta Studio patch in the <strong>Magenta Studio Plugin</strong> track, which shows at the bottom.</p>
<ol start="3">
<li>Now, let's click on <strong>CONTINUE</strong> in the Magenta Studio Plugin. You should see the <strong>Continue</strong> Node.js application start:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/dbd326a8-92fc-48b8-a9eb-bdb0f6310ccd.png" style="width:21.83em;height:34.50em;"/></p>
<p>In the <strong>Input Clip</strong> section, we've added from the <strong>MIDI from Magenta</strong> track the <strong>MIDI from Magenta 2</strong> MIDI clip, which will be used by the DrumsRNN model for its primer. The four variations will be added automatically to Ableton Live after the primer clip, with the name <kbd>x/4 [MIDI from Magenta 2]</kbd>, with <em>x</em> being the index of the generated clip.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we've covered the interaction of Magenta with established music production software.</p>
<p>First, we have shown how to send MIDI from Magenta to DAWs or synthesizers. We started by looking at MIDI ports using Mido, a powerful Python library to handle MIDI operations. We've shown examples of how to loop MIDI in Magenta, which requires proper timing and threading tools. We also looked at synchronization between Magenta and a DAW using various methods, most notably using the MIDI clock messages and transport messages. We finished the MIDI section by showing how Magenta could send MIDI directly to hardware synthesizers, such as keyboards.</p>
<p>Finally, we introduced Magenta Studio, both as a standalone application and as an Ableton Live plugin. We looked at its integration in Ableton Live and the importance of integrating Magenta in existing music tools.</p>
<p>Looking at Magenta's integration in a music production ecosystem is the perfect closing chapter. It reminds us that Magenta is not an end by itself, but rather a tool that needs to be used in conjunction with other music production tools to be truly useful. Magenta is becoming more usable by a broader, non-technical audience, by developing projects such as Magenta.js and Magenta Studio.</p>
<p>There is still a lot that can be done for Magenta to grow in terms of usability for everybody. This is, however, the start of a great music production tool.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>What is the difference between a software synthesizer, such as FluidSynth, and a DAW, such as Ableton Live?</li>
<li>Why is opening MIDI virtual ports required to make music software interact with each other?</li>
<li>Write the code based on <kbd>chapter_09_example_03.py</kbd> that, instead of looping the four bars sequence, generates a new sequence every four bars.</li>
<li>Why is syncing based on the MIDI control message not robust?</li>
<li>Why is Magenta Studio such an important project in the music composition ecosystem?</li>
<li>What are the technologies behind Magenta Studio Plugins and Magenta Studio Standalone?</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further Reading</h1>
                </header>
            
            <article>
                
<ul>
<li><strong>Learn Live</strong> (<strong>Ableton Live</strong>): Amazing tutorials on Ableton Live, which are far the best tutorials available on music production in general, with advanced content on many topics that can be used in many DAWs (<a href="https://www.ableton.com/en/live/learn-live/">www.ableton.com/en/live/learn-live/</a>)</li>
<li><strong>Session View</strong> (<strong>Ableton Live</strong>): More information on Ableton Live's <strong>Session View</strong> which is a useful view for using Magenta Studio (<a href="https://www.ableton.com/en/manual/session-view/">www.ableton.com/en/manual/session-view/</a>)</li>
<li><strong>Community Learning</strong> (<strong>Bitwig</strong>): Good tutorials for Bitwig (<a href="https://www.bitwig.com/en/community/learning.html">www.bitwig.com/en/community/learning.html</a>)</li>
<li><strong>Tutorials</strong> (<strong>Reason</strong>): Tutorials for Reason in the form of blog posts (<a href="https://www.reasonstudios.com/blog/category/tutorials">www.reasonstudios.com/blog/category/tutorials</a>)</li>
<li><strong>Getting Started With SC</strong> (<strong>SuperCollider</strong>): The best way to get into SuperCollider and its programming language, <kbd>sclang</kbd>—the examples are also bundled with the software when downloaded (<a href="http://doc.sccode.org/Tutorials/Getting-Started/00-Getting-Started-With-SC.html">doc.sccode.org/Tutorials/Getting-Started/00-Getting-Started-With-SC.html</a>)</li>
<li><strong>VCV Rack Manual</strong> (<strong>VCV Rack</strong>): VCV documentation along with the developer API if you want to write code for the software (<a href="https://vcvrack.com/manual/">vcvrack.com/manual/</a>)</li>
<li><strong>Ports</strong>: Mido documentation on Virtual MIDI ports differences between platforms (<a href="https://mido.readthedocs.io/en/latest/ports.html">mido.readthedocs.io/en/latest/ports.html</a>)</li>
<li><strong>Summary of MIDI Messages</strong>: List of MIDI messages, including the MIDI clock and transport message we're using (<a href="https://www.midi.org/specifications/item/table-1-summary-of-midi-message">www.midi.org/specifications/item/table-1-summary-of-midi-message</a>)</li>
<li><strong>Message Types</strong>: Supported message types in Mido from the MIDI spec (<a href="https://mido.readthedocs.io/en/latest/message_types.html">mido.readthedocs.io/en/latest/message_types.html</a>)</li>
<li><strong>Magenta Studio</strong>: Blog post from the Magenta team on Magenta Studio (<a href="https://magenta.tensorflow.org/studio-announce">magenta.tensorflow.org/studio-announce</a>)</li>
</ul>


            </article>

            
        </section>
    </body></html>