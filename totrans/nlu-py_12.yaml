- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applying Unsupervised Learning Approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In earlier chapters, such as [*Chapter 5*](B19005_05.xhtml#_idTextAnchor107),
    we discussed the fact that supervised learning requires annotated data, where
    a human annotator makes a decision about how a **natural language processing**
    (**NLP**) system should analyze it – that is, a human has *annotated* it. For
    example, with the movie review data, a human has looked at each review and decided
    whether it is positive or negative. We also pointed out that this annotation process
    can be expensive and time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at techniques that don’t require annotated data,
    thereby saving this time-consuming step in data preparation. Although unsupervised
    learning will not be suitable for every NLP problem, it is very useful to have
    an understanding of the general area so that you can decide how to incorporate
    it into your NLP projects.
  prefs: []
  type: TYPE_NORMAL
- en: At a deeper level, we will discuss applications of unsupervised learning, such
    as topic modeling, including the value of unsupervised learning for exploratory
    applications and maximizing scarce data. We will also cover label generation in
    unsupervised classification and mention some approaches to make the most of limited
    labeled data, with techniques for partial supervision.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is unsupervised learning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Topic modeling using clustering techniques and label derivation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making the most of data with partial supervision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is unsupervised learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The applications that we worked with in earlier chapters were based on data
    that was manually categorized by human annotators. For example, each review in
    the movie review corpus that we have used several times was read by a human annotator
    and assigned a category, *positive* or *negative*, based on the human’s opinion.
    The review-category pairs were then used to train models, using the machine learning
    algorithms that we previously learned about to categorize new reviews. This whole
    process is called **supervised learning** because the training process is, in
    effect, *supervised* by the training data. The training data labeled by humans
    is referred to as the *gold standard* or *ground truth.*
  prefs: []
  type: TYPE_NORMAL
- en: Supervised approaches have some disadvantages, however. The most obvious disadvantage
    is the cost of developing the ground-truth data because of the cost of human annotators.
    Another consideration is the possibility that the manual annotations from different
    annotators, or even the same annotator at different times, will be inconsistent.
    Inconsistent annotation can also occur if the data labels themselves are subjective
    or not clear-cut, which makes it harder for the annotators to agree on the correct
    annotation.
  prefs: []
  type: TYPE_NORMAL
- en: For many applications, supervised approaches are the only option, but there
    are other applications, which we will be exploring in this chapter, where **unsupervised
    techniques** are useful.
  prefs: []
  type: TYPE_NORMAL
- en: These unsupervised applications don’t require labeled training data because
    what we want to learn from the natural language data doesn’t require any human
    judgment. Rather, it can be found by just examining the raw text, which can be
    done by an algorithm. These kinds of applications include grouping documents by
    similarity and computing the similarity of documents. In particular, we will be
    looking at **clustering**, which is the process of putting data, documents in
    particular, into similar groups. Finding similar groups of documents is often
    a first step in the process of developing a classification application, before
    the categories of documents are known. Once the clusters are identified, there
    are additional techniques that can help find human-readable labels for the clusters,
    although in some cases, it is easy to identify how the clusters should be labeled
    by manual inspection of the clusters. We will look at tools to find cluster labels
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to clustering, another important application of unsupervised learning
    is the training process for the **large language models** (**LLMs**) that we covered
    in [*Chapter 11*](B19005_11.xhtml#_idTextAnchor193). Training LLMs doesn’t require
    any supervision because the training process only looks at words in the context
    of other words. However, we will not cover the training process for LLMs in this
    book because this is a very computationally intensive process and requires expensive
    computational resources that are not available to the vast majority of developers.
    In addition, LLM training is not needed for most practical applications, since
    existing LLMs that have already been trained are widely available.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will illustrate in detail a practical NLP problem where
    unsupervised learning can be very useful – *topic modeling*. In topic modeling,
    we start with a collection of text items, such as documents or user inputs in
    chatbot applications, but we don’t have a pre-determined set of categories. Instead,
    we use the words in the texts themselves to find semantic similarities among the
    texts that enable us to group them into categories, or topics.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by reviewing a few general considerations about semantically grouping
    similar texts.
  prefs: []
  type: TYPE_NORMAL
- en: Topic modeling using clustering techniques and label derivation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll start our exploration of topic modeling by looking at some considerations
    relating to grouping semantically similar documents in general, and then we’ll
    look at a specific example.
  prefs: []
  type: TYPE_NORMAL
- en: Grouping semantically similar documents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like most of the machine learning problems we’ve discussed so far, the overall
    task generally breaks down into two sub-problems, representing the data and performing
    a task based on the representations. We’ll look at these two sub-problems next.
  prefs: []
  type: TYPE_NORMAL
- en: Representing the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data representations we’ve looked at so far were reviewed in [*Chapter 7*](B19005_07.xhtml#_idTextAnchor144).
    These approaches included the simple **bag of words** (**BoW**) variants, **term
    frequency - inverse document frequency** (**TF-IDF**), and newer approaches, including
    **Word2Vec**. Word2Vec is based on word vectors, which are vectors that represent
    words in isolation, without taking into account the context in which they occur.
    A newer representation, used in the **BERT** system that we discussed in the previous
    chapter, takes into account the contexts of words in a sentence or document to
    create numerical word representations, or *embeddings*. We will use BERT embeddings
    in this chapter to uncover similarities among documents.
  prefs: []
  type: TYPE_NORMAL
- en: Working with data representations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section will discuss two aspects of processing embeddings. First, we will
    discuss grouping similar texts into clusters, and then we will discuss visualizing
    the clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering – grouping similar items
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Clustering** is the main NLP task we’ll talk about in this chapter. Clustering
    is the name for a wide variety of algorithms that attempt to group data items
    together, based on similarities in the data representation. Clustering can be
    used with any dataset, whether or not the data items are text-based, as long as
    there is a numerical way of representing their similarity. In this chapter, we
    will review a practical set of tools to perform clustering, but you should be
    aware that there are many other options, and undoubtedly, there will be many new
    ones as technology moves forward. Two common approaches to clustering are k-means
    and HDBSCAN:'
  prefs: []
  type: TYPE_NORMAL
- en: '**k-means**: The k-means algorithm, which we reviewed in [*Chapter 6*](B19005_06.xhtml#_idTextAnchor134),
    is a very common clustering approach in which data points are initially randomly
    assigned to one of k clusters, the means of the clusters are computed, and the
    distance of the data points from the centers of the clusters is minimized through
    an iterative process. The value of k, or the number of clusters, is a hyperparameter
    that is selected by the developer. It can be considered to be the most *useful*
    number of clusters for the application. The k-means algorithm is often used because
    it is efficient and easy to implement, but other clustering algorithms – in particular,
    HDBSCAN – can yield better results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HDBSCAN**: HDBSCAN is another popular clustering algorithm and stands for
    **Hierarchical Density-Based Spatial Clustering of Applications with Noise**.
    HDBSCAN takes into account the density of the data points within the clusters.
    Because of this, it is able to find oddly sized and differently sized clusters.
    It can also detect outliers or items that don’t fit well into a cluster, while
    k-means forces every item into a cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing the clusters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Visualization** is very important in unsupervised approaches, such as clustering,
    because it allows us to see what groups of similar data items look like and helps
    us judge whether or not the grouping result is useful. While clusters of similar
    items can be represented in any number of dimensions, we are only able to effectively
    visualize clusters in, at most, three dimensions. Consequently, in practice, dimensionality
    reduction is needed to reduce the number of dimensions. We will use a tool called
    **Uniform Manifold Approximation and Projection** (**UMAP**) for dimensionality
    reduction.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will use clustering and visualization to illustrate
    a specific application of unsupervised learning called topic modeling. The general
    problem that can be solved using topic modeling is that of classifying documents
    into different topics. The unique characteristic of this technique is that, unlike
    the classification examples we saw in earlier chapters, we don’t know what the
    topics are at the outset. Topic modeling can help us identify groups of similar
    documents, even if we don’t know what the eventual categories will be.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will use BERT transformer embeddings to represent the documents
    and HDBSCAN for clustering. Specifically, we will use the BERTopic Python library
    found at [https://maartengr.github.io/BERTopic/index.html](https://maartengr.github.io/BERTopic/index.html).
    The BERTopic library is customizable, but we will stick with the default settings
    for the most part in our example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data we’ll look at is a well-known dataset called `20 newsgroups`, which
    is a collection of 20,000 newsgroup documents from 20 different internet newsgroups.
    This is a popular dataset that is often used in text processing. The data is email
    messages of varying lengths that are posted to newsgroups. Here’s one example
    of a short message from this dataset, with the email headers removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `20 newsgroups` dataset can be imported from the scikit-learn datasets
    or downloaded from the following website: [http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/).'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: 'Ken Lang, *Newsweeder: Learning to filter netnews*, 1995, *Proceedings of the
    Twelfth International Conference on Machine* *Learning*, 331–339'
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will go over topic modeling in detail using the
    `20 newsgroups` dataset and the BERTopic package. We will create embeddings, construct
    the model, generate proposed labels for the topics, and visualize the resulting
    clusters. The last step will be to show the process of finding topics for new
    documents using our model.
  prefs: []
  type: TYPE_NORMAL
- en: Applying BERTopic to 20 newsgroups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step in this application is to install BERTopic and import the necessary
    libraries in a Jupyter notebook, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next step is to prepare the data representations, or embeddings, shown
    in the following code block. Because this is a slow process, it is useful to set
    `show_progress_bar ()` to `True` so that we can ensure that the process is moving
    along, even if it takes a long time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Instead of the earlier BERT word embeddings that we worked with in [*Chapter
    11*](B19005_11.xhtml#_idTextAnchor193) in this exercise, we will work with sentence
    embeddings using **Sentence** **Bert** (**SBERT**).
  prefs: []
  type: TYPE_NORMAL
- en: SBERT produces one embedding per sentence. We will use a package called `SentenceTransformers`,
    available from Hugging Face, and the `all-MiniLM-L6-v2` model, which is recommended
    by BERTopic. However, many other transformer models can be used. These include,
    for example, the `en_core_web_trf` spaCy model, or the `distilbert-base-cased`
    Hugging Face model. BERTopic provides a guide to a wide selection of other models
    that you can use at [https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html](https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see what the actual embeddings look like in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the `corpus_embeddings.view()` method shown here, we can see a summary
    of the embeddings, which are an array of arrays of floating point numbers. Looking
    directly at the embeddings isn’t particularly useful itself, but it gives you
    something of a sense of what the actual data looks like.
  prefs: []
  type: TYPE_NORMAL
- en: Constructing the BERTopic model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once the embeddings have been computed, we can build the BERTopic model. The
    BERTopic model can take a large number of parameters, so we won''t show them all.
    We will show some useful ones, but there are many more, and you can consult the
    BERTopic documentation for additional ideas. The BERTopic model can be constructed
    very simply, with just the documents and the embeddings as parameters, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This simple model has defaults for the parameters that will usually lead to
    a reasonable result. However, to illustrate some of the flexibility that’s possible
    with BERTopic, we’ll show next how the model can be constructed with a richer
    set of parameters, with the code shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we start by defining several useful models. The first
    one is `CountVectorizer`, which we saw in [*Chapter 7*](B19005_07.xhtml#_idTextAnchor144)
    and [*Chapter 10*](B19005_10.xhtml#_idTextAnchor184), where we used it to vectorize
    text documents to formats such as BoW. Here, we will use the vectorizer to remove
    stopwords after dimensionality reduction and clustering so that they don’t end
    up being included in topic labels.
  prefs: []
  type: TYPE_NORMAL
- en: '**Stopwords** should not be removed from documents before preparing embeddings
    because the transformers have been trained on normal text, including stopwords,
    and the models will be less effective without the stopwords.'
  prefs: []
  type: TYPE_NORMAL
- en: The vectorizer model parameters indicate that the model is constructed with
    English stopwords and that only words that occur in fewer than 95% of the documents
    and more than 1% are included. This is to exclude extremely common and extremely
    rare words from the model, which are unlikely to be helpful to distinguish topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second model we will define is the HDBSCAN model, which is used for clustering.
    Some of the parameters include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `min_cluster_size` parameter is the minimum number of documents that we
    want to be in a cluster. Here, we’ve selected '`30'` as the minimum cluster size.
    This parameter can vary, depending on the problem you’re trying to solve, but
    you might want to consider a larger number if the number of documents in the dataset
    is large.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prediction_data` is set to `True` if we want to be able to predict the topics
    of new documents after the model is trained.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next model is the **uniform manifold approximation and projection** (**UMAP**)
    model, which is used for dimensionality reduction. Besides making it easier to
    visualize multidimensional data, UMAP also makes it easier to cluster. Some of
    its parameters include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`n-neighbors`: This constrains the size of the area that UMAP will look at
    when learning the structure of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n-components`: This determines the dimensionality of the reduced dimension
    space we will use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`low_memory`: This determines system memory management behavior. If the parameter
    is `False`, the algorithm will use a faster and more memory-intensive approach.
    If running out of memory is a problem with large datasets, you can set `low_memory`
    to `True`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these preliminary models defined, we can move on to defining the BERTopic
    model itself. The parameters that are set in this example are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The models for the three tools we’ve already defined – the vectorizer model,
    the UMAP model, and the HDBSCAN model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nr_topics`: If we have an idea of how many topics we want to find, this parameter
    can be set to that number. In this case, it is set to `auto`, and HDBSCAN will
    find a good estimate of the number of topics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_n_words`: When generating labels, BERTopic should consider only the *n*
    most frequent words in a cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_topic_size`: The minimum number of documents that should be considered
    to form a topic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`calculate_probabilities`: This calculates the probabilities of all topics
    per document.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the code in this section will create clusters from the original documents.
    The number and size of the clusters will vary, depending on the parameters that
    were set in the generation of the model. You are encouraged to try different settings
    of the parameters and compare the results. As you think about the goals of your
    application, consider whether some of the settings seem to yield more or less
    helpful results.
  prefs: []
  type: TYPE_NORMAL
- en: Up to this point, we have used clusters of similar documents, but they are not
    labeled with any categories. It would be more useful if the clusters had names.
    Let’s see how we can get names or labels for the clusters that relate to what
    they are about. The next section will review ways to label the clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once we have the clusters, there are various approaches to labeling them with
    topics. A manual approach, where you just look at the documents and think about
    what a good label might be, should not necessarily be ruled out. However, there
    are automatic approaches that can suggest topics based on the words that occur
    in the documents in the various clusters.
  prefs: []
  type: TYPE_NORMAL
- en: BERTopic uses a method to suggest topic labels called class-based `tf-idf`,
    or `c-tf-idf`. You will recall that TF-IDF was discussed in earlier chapters as
    a document vectorization approach that identifies the most diagnostic terms for
    a document class. It does this by taking into account the frequency of a term
    in a document, compared to its frequency in the overall document collection. Terms
    that are frequent in one document but not overall in the dataset are likely to
    be indicative that a document should be assigned to a specific category.
  prefs: []
  type: TYPE_NORMAL
- en: Class-based TF-IDF takes this intuition a step further by treating each cluster
    as if it were a single document. It then looks at the terms that occur frequently
    in a cluster, but not overall in the entire dataset, to identify words that are
    useful to label a topic. Using this metric, labels can be generated for the topics
    using the most diagnostic words for each cluster. We can see in *Table 12.1* the
    labels generated for the 10 most frequent topics in a dataset, along with the
    number of documents in each topic.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the first topic in the table, *-1*, is a catchall topic that includes
    the documents that don’t fall into any topic.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Topic** | **Count** | **Name** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | -1 | 6,928 | `-``1_maxaxaxaxaxaxaxaxaxaxaxaxaxaxax_dont_know_like` |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 1,820 | `0_game_team_games_players` |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1 | 1,569 | `1_space_launch_nasa_orbit` |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 2 | 1,313 | `2_car_bike_engine_cars` |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 3 | 1,168 | `3_image_jpeg_window_file` |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 4 | 990 | `4_armenian_armenians_people_turkish` |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 5 | 662 | `5_drive_scsi_drives_ide` |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 6 | 636 | `6_key_encryption_clipper_chip` |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 7 | 633 | `7_god_atheists_believe_atheism` |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 8 | 427 | `8_cheek___` |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 9 | 423 | `9_israel_israeli_jews_arab` |'
  prefs: []
  type: TYPE_TB
- en: Table 12.1 – The top 10 topics and automatically generated labels
  prefs: []
  type: TYPE_NORMAL
- en: Visualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Visualization is extremely useful in unsupervised learning, because deciding
    how to proceed in the development process often depends on intuitions that can
    be assisted by looking at results in different ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways of visualizing the results of topic modeling. One useful
    visualization can be obtained with a BERTopic method, `model.visualize_barchart()`,
    which shows the top topics and their top words, as shown in *Figure 12**.1*. For
    example, looking at the top words in `space_launch_nasa_orbit`:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 12.1\uFEFF – The top seven topics and their most significant words](img/B19005_12_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – The top seven topics and their most significant words
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important visualization technique that is often used in clustering
    is representing each item in a cluster as a dot, representing their similarities
    by the distance between the dots, and assigning different colors or markers to
    the clusters. This clustering can be produced with a BERTopic method, `visualize_documents()`,
    as shown in the following code with the minimal `docs` and `embeddings` parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Additional parameters can be set to configure a cluster plot in various ways,
    as documented in the BERTopic documentation. For example, you can set the display
    to show or hide the cluster labels, or to only show the top topics.
  prefs: []
  type: TYPE_NORMAL
- en: The clustering for the top seven topics in the `20 newsgroups` data can be seen
    in *Figure 12**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 12.2\uFEFF – The clustered documents for the top seven topics in the\
    \ 20 newsgroups dataset with their generated labels](img/B19005_12_02.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – The clustered documents for the top seven topics in the 20 newsgroups
    dataset with their generated labels
  prefs: []
  type: TYPE_NORMAL
- en: There are seven topics displayed in *Figure 12**.2*, corresponding to the seven
    topics in *Figure 12**.1*, each labeled with its automatically generated label.
    In addition, there are documents in *Figure 12**.2* shown in light gray that were
    not assigned to any cluster. These are the documents shown as belonging to topic
    *-1* in *Table 12.1*.
  prefs: []
  type: TYPE_NORMAL
- en: One insight we can gain from the cluster display is the fact that there are
    many unassigned documents, which means that we may want to increase the number
    of topics to look for (by increasing the `nr_topic`s parameter to `model()`).
    Another insight is that some of the topics – for example, `1_space_launch_nasa`
    – seem to be split over several clusters. This means that it might be more meaningful
    for them to be considered as separate topics. As in the case of unclassified documents,
    we can investigate this possibility by increasing the number of topics to look
    for.
  prefs: []
  type: TYPE_NORMAL
- en: We have shown two of the most useful BERTopic visualizations, but there are
    many more. You are encouraged to consult the BERTopic documentation for other
    ideas.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the topic of a new document
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once the clustering is complete, the model can be used to find the topics of
    new documents, similar to a classification application. This can be done with
    the `model.transform()` method, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The predicted topics for the two documents in `new_docs` are `-1` (no topic)
    and `3`, which stands for `3_space_launch_orbit_nasa`.
  prefs: []
  type: TYPE_NORMAL
- en: After clustering and topic labeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recall that the most common application of clustering is to explore the data,
    often in preparation to develop a supervised classification application. We can
    look at the clustering results and decide, for example, that some of the clusters
    are very similar and close to each other. In that case, it might be difficult
    to distinguish documents in those topics from each other, even after supervised
    training, and it would be a good idea to combine those clusters into a single
    topic. Similarly, if we find very small clusters, we would probably get more reliable
    results if the small clusters are combined with similar large clusters.
  prefs: []
  type: TYPE_NORMAL
- en: We can also modify labels to make them more helpful or informative. For example,
    topic *1* in *Table 12.1* is `1_space_launch_nasa_orbit`. You might decide that
    `space` would be a simpler label that is, nevertheless, just as informative as
    the automatically generated label.
  prefs: []
  type: TYPE_NORMAL
- en: After making any adjustments to the clusters and labels that you find helpful,
    the result will be a supervised dataset, just like the supervised datasets we
    worked with, such as the movie reviews. You can use this as you would use any
    supervised dataset in NLP applications.
  prefs: []
  type: TYPE_NORMAL
- en: While unsupervised topic modeling can be a very useful technique, it is also
    possible to take advantage of data that is even partially supervised. We will
    summarize some of the ideas that the NLP research community has explored to use
    partially annotated data in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Making the most of data with weak supervision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In between completely supervised and unsupervised learning are several approaches
    to partial supervision, where only x data is supervised. Like unsupervised approaches,
    the goal of these techniques is to make the most of supervised data, which can
    be expensive to obtain. One advantage of partial supervision over unsupervised
    approaches is that unsupervised results don’t automatically have useful labels.
    The labels have to be supplied, either manually or through some of the techniques
    we saw earlier in this chapter. In general, with weak supervision, the labels
    are supplied based on the subset of the data that is supervised.
  prefs: []
  type: TYPE_NORMAL
- en: This is an active research area, and we will not go into it in detail. However,
    it is useful to know what the general tactics of weak supervision are so that
    you will be able to apply them as they relate to specific tasks, depending on
    the kind of labeled data that is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some tactics for weak supervision include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Incomplete supervision, where only partial data has ground-truth labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inexact supervision, where the data has coarse-grained labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inaccurate supervision, where some of the labels might be incorrect
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning, where some predefined labels are provided to help
    push a model toward known classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These approaches are worth considering in applications where full annotation
    is too expensive or takes too long. In addition, they can also be useful in situations
    where unsupervised learning would be problematic because there are predefined
    labels that are required by other parts of the overall application, such as a
    database.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the basic concepts of unsupervised learning.
    We also worked through a specific application of unsupervised learning, topic
    modeling, using a BERT-based tool called BERTopic. We used the BERTopic package
    to identify clusters of semantically similar documents and propose labels for
    the clusters based on the words they contain, without needing to use any supervised
    annotations of the cluster topics.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [*Chapter 13*](B19005_13.xhtml#_idTextAnchor226), we will
    address the question of measuring how good our results are using quantitative
    techniques. Quantitative evaluation is useful in research applications to compare
    results to those from previous research, and it is useful in practical applications
    to ensure that the techniques being used meet the application’s requirements.
    Although evaluation was briefly discussed in earlier chapters, [*Chapter 13*](B19005_13.xhtml#_idTextAnchor226)
    will discuss it in depth. It will include segmenting data into training, validation,
    and test data, evaluation with cross-validation, evaluation metrics such as precision
    and recall, the area under the curve, ablation studies, statistical significance,
    inter-annotator agreement, and user testing.
  prefs: []
  type: TYPE_NORMAL
