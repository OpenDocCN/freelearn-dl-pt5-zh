["```py\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE score-partwise PUBLIC\n    \"-//Recordare//DTD MusicXML 3.1 Partwise//EN\"\n    \"http://www.musicxml.org/dtds/partwise.dtd\">\n<score-partwise version=\"3.1\">\n <part-list>\n    <score-part id=\"P1\">\n      <part-name>Music</part-name>\n    </score-part>\n  </part-list>\n  <part id=\"P1\">\n    <measure number=\"1\">\n      <attributes>\n...\n      </attributes>\n      <note>\n        <pitch>\n          <step>C</step>\n          <octave>4</octave>\n        </pitch>\n        <duration>4</duration>\n        <type>whole</type>\n      </note>\n    </measure>\n  </part>\n</score-partwise>\n```", "```py\n<score lang=\"ABC\">\nX:1\nT:The Legacy Jig\nM:6/8\nL:1/8\nR:jig\nK:G\nGFG BAB | gfg gab | GFG BAB | d2A AFD |\nGFG BAB | gfg gab | age edB |1 dBA AFD :|2 dBA ABd |:\nefe edB | dBA ABd | efe edB | gdB ABd |\nefe edB | d2d def | gfe edB |1 dBA ABd :|2 dBA AFD |]\n</score>\n```", "```py\nfrom itertools import cycle\nfrom multiprocessing import Manager\nfrom multiprocessing.pool import Pool\n\nwith Pool(4) as pool:\n  # Add elements to process here\n  elements = []\n  manager = Manager()\n  counter = AtomicCounter(manager, len(elements))\n  results = pool.starmap(process, zip(elements, cycle([counter])))\n  results = [result for result in results if result]\n```", "```py\nimport copy\nfrom typing import Optional\n\nfrom pretty_midi import Instrument\nfrom pretty_midi import PrettyMIDI\n\ndef extract_drums(midi_path: str) -> Optional[PrettyMIDI]:\n  pm = PrettyMIDI(midi_path)\n  pm_drums = copy.deepcopy(pm)\n  pm_drums.instruments = [instrument for instrument in pm_drums.instruments\n                          if instrument.is_drum]\n  if len(pm_drums.instruments) > 1:\n    # Some drum tracks are split, we can merge them\n    drums = Instrument(program=0, is_drum=True)\n    for instrument in pm_drums.instruments:\n      for note in instrument.notes:\n        drums.notes.append(note)\n    pm_drums.instruments = [drums]\n  if len(pm_drums.instruments) != 1:\n    raise Exception(f\"Invalid number of drums {midi_path}: \"\n                    f\"{len(pm_drums.instruments)}\")\n  return pm_drums\n```", "```py\nimport math\nfrom pretty_midi import PrettyMIDI\n\ndef get_bass_drums_on_beat(pm_drums: PrettyMIDI) -> float:\n  beats = pm_drums.get_beats()\n  bass_drums = [note.start for note in pm_drums.instruments[0].notes\n                if note.pitch == 35 or note.pitch == 36]\n  bass_drums_on_beat = []\n  for beat in beats:\n    beat_has_bass_drum = False\n    for bass_drum in bass_drums:\n      if math.isclose(beat, bass_drum):\n        beat_has_bass_drum = True\n        break\n    bass_drums_on_beat.append(True if beat_has_bass_drum else False)\n  num_bass_drums_on_beat = len([bd for bd in bass_drums_on_beat if bd])\n  return num_bass_drums_on_beat / len(bass_drums_on_beat)\n```", "```py\n[  0\\.    0.4   0.8   1.2   1.6   2\\.    2.4   2.8   3.2   3.6   4\\.    4.4\n   4.8   5.2   5.6   6\\.    6.4   6.8   7.2   7.6   8\\.    8.4   8.8   9.2\n...\n 201.6 202\\.  202.4 202.8 203.2 203.6 204\\.  204.4 204.8 205.2 205.6 206.\n 206.4 206.8 207.2 207.6]\n```", "```py\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--path_output_dir\", type=str, required=True)\nparser.add_argument(\"--bass_drums_on_beat_threshold\", \n                    type=float, required=True, default=0)\nargs = parser.parse_args()\n```", "```py\nimport os\nfrom typing import Optional\nfrom multiprocessing_utils import AtomicCounter\n\ndef process(midi_path: str, counter: AtomicCounter) -> Optional[dict]:\n  try:\n    os.makedirs(args.path_output_dir, exist_ok=True)\n    pm_drums = extract_drums(midi_path)\n    bass_drums_on_beat = get_bass_drums_on_beat(pm_drums)\n    if bass_drums_on_beat >= args.bass_drums_on_beat_threshold:\n      midi_filename = os.path.basename(midi_path)\n      pm_drums.write(os.path.join(args.path_output_dir, f\"{midi_filename}.mid\"))\n    else:\n      raise Exception(f\"Not on beat {midi_path}: {bass_drums_on_beat}\")\n    return {\"midi_path\": midi_path,\n            \"pm_drums\": pm_drums,\n            \"bass_drums_on_beat\": bass_drums_on_beat}\n  except Exception as e:\n    print(f\"Exception during processing of {midi_path}: {e}\")\n  finally:\n    counter.increment()\n```", "```py\nimport shutil\nfrom itertools import cycle\nfrom multiprocessing import Manager\nfrom multiprocessing.pool import Pool\nfrom typing import List\nfrom multiprocessing_utils import AtomicCounter\n\ndef app(midi_paths: List[str]):\n  shutil.rmtree(args.path_output_dir, ignore_errors=True)\n\n  with Pool(4) as pool:\n    manager = Manager()\n    counter = AtomicCounter(manager, len(midi_paths))\n    results = pool.starmap(process, zip(midi_paths, cycle([counter])))\n    results = [result for result in results if result]\n    results_percentage = len(results) / len(midi_paths) * 100\n    print(f\"Number of tracks: {len(MIDI_PATHS)}, \"\n          f\"number of tracks in sample: {len(midi_paths)}, \"\n          f\"number of results: {len(results)} \"\n          f\"({results_percentage:.2f}%)\")\n```", "```py\nimport matplotlib.pyplot as plt\n\npm_drums = [result[\"pm_drums\"] for result in results]\npm_drums_lengths = [pm.get_end_time() for pm in pm_drums]\nplt.hist(pm_drums_lengths, bins=100)\nplt.title('Drums lengths')\nplt.ylabel('length (sec)')\nplt.show()\n```", "```py\nparser.add_argument(\"--sample_size\", type=int, default=1000)\nparser.add_argument(\"--path_dataset_dir\", type=str, required=True)\n\nMIDI_PATHS = glob.glob(os.path.join(args.path_dataset_dir, \"**\", \"*.mid\"),\n                       recursive=True)\n\nif __name__ == \"__main__\":\n  if args.sample_size:\n    # Process a sample of it\n    MIDI_PATHS_SAMPLE = random.sample(list(MIDI_PATHS), args.sample_size)\n  else:\n    # Process all the dataset\n    MIDI_PATHS_SAMPLE = list(MIDI_PATHS)\n  app(MIDI_PATHS_SAMPLE)\n```", "```py\npython chapter_06_example_00.py --sample_size=1000 --path_dataset_dir=\"PATH_DATASET\" --path_output_dir=\"PATH_OUTPUT\"\n```", "```py\nNumber of tracks: 116189, number of tracks in sample: 116189, number of results: 12634 (10.87%)\nTime:  7197.6346254\n```", "```py\n{\n...\n  \"TRRNARX128F4264AEB\": {\"cd3b9c8bb118575bcd712cffdba85fce\": 0.7040202098544246},\n  \"TRWMHMP128EF34293F\": {\n    \"c3da6699f64da3db8e523cbbaa80f384\": 0.7321245522741104,\n    \"d8392424ea57a0fe6f65447680924d37\": 0.7476196649194942\n  },\n...\n}\n```", "```py\nimport argparse\nimport tables\nfrom typing import List, Optional\nfrom lakh_utils import msd_id_to_h5\nfrom threading_utils import AtomicCounter\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--sample_size\", type=int, default=1000)\nparser.add_argument(\"--path_dataset_dir\", type=str, required=True)\nparser.add_argument(\"--path_match_scores_file\", type=str, required=True)\nargs = parser.parse_args()\n\ndef process(msd_id: str, counter: AtomicCounter) -> Optional[dict]:\n  try:\n    with tables.open_file(msd_id_to_h5(msd_id, args.path_dataset_dir)) as h5:\n      artist = h5.root.metadata.songs.cols.artist_name[0].decode(\"utf-8\")\n      title = h5.root.metadata.songs.cols.title[0].decode(\"utf-8\")\n      return {\"msd_id\": msd_id, \"artist\": artist, \"title\": title}\n  except Exception as e:\n    print(f\"Exception during processing of {msd_id}: {e}\")\n  finally:\n    counter.increment()\n```", "```py\nfrom lakh_utils import get_msd_score_matches\n\nMSD_SCORE_MATCHES = get_msd_score_matches(args.path_match_scores_file)\n\nif __name__ == \"__main__\":\n  if args.sample_size:\n    # Process a sample of it\n    MSD_IDS = random.sample(list(MSD_SCORE_MATCHES), args.sample_size)\n  else:\n    # Process all the dataset\n    MSD_IDS = list(MSD_SCORE_MATCHES)\n  app(MSD_IDS)\n```", "```py\npython chapter_06_example_01.py --sample_size=1000 --path_dataset_dir=\"PATH_DATASET\" --path_match_score=\"PATH_MATCH_SCORES\"\n```", "```py\nNumber of tracks: 31034, number of tracks in sample: 31034, number of results: 31034 (100.00%)\nTime:  21.0088559\n```", "```py\nimport argparse\nfrom typing import List, Optional\nimport requests\nfrom threading_utils import AtomicCounter\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--sample_size\", type=int, default=1000)\nparser.add_argument(\"--path_dataset_dir\", type=str, required=True)\nparser.add_argument(\"--path_match_scores_file\", type=str, required=True)\nparser.add_argument(\"--last_fm_api_key\", type=str, required=True)\nargs = parser.parse_args()\n\ndef get_tags(h5) -> Optional[list]:\n  title = h5.root.metadata.songs.cols.title[0].decode(\"utf-8\")\n  artist = h5.root.metadata.songs.cols.artist_name[0].decode(\"utf-8\")\n  request = (f\"https://ws.audioscrobbler.com/2.0/\"\n             f\"?method=track.gettoptags\"\n             f\"&artist={artist}\"\n             f\"&track={title}\"\n             f\"&api_key={args.last_fm_api_key}\"\n             f\"&format=json\")\n  response = requests.get(request, timeout=10)\n  json = response.json()\n  if \"error\" in json:\n    raise Exception(f\"Error in request for '{artist}' - '{title}': \"\n                    f\"'{json['message']}'\")\n  if \"toptags\" not in json:\n    raise Exception(f\"Error in request for '{artist}' - '{title}': \"\n                    f\"no top tags\")\n  tags = [tag[\"name\"] for tag in json[\"toptags\"][\"tag\"]]\n  tags = [tag.lower().strip() for tag in tags if tag]\n  return tags\n```", "```py\nfrom typing import Optional\nimport tables\nfrom threading_utils import AtomicCounter\nfrom lakh_utils import msd_id_to_h5\n\ndef process(msd_id: str, counter: AtomicCounter) -> Optional[dict]:\n  try:\n    with tables.open_file(msd_id_to_h5(msd_id, args.path_dataset_dir)) as h5:\n      tags = get_tags(h5)\n      return {\"msd_id\": msd_id, \"tags\": tags}\n  except Exception as e:\n    print(f\"Exception during processing of {msd_id}: {e}\")\n  finally:\n    counter.increment()\n```", "```py\nfrom collections import Counter\n\ntags = [result[\"tags\"][0] for result in results if result[\"tags\"]]\nmost_common_tags_20 = Counter(tags).most_common(20)\nplt.bar([tag for tag, _ in most_common_tags_20],\n        [count for _, count in most_common_tags_20])\nplt.title(\"Most common tags (20)\")\nplt.xticks(rotation=30, horizontalalignment=\"right\")\nplt.ylabel(\"count\")\nplt.show()\n```", "```py\nfrom typing import List, Optional\nfrom pretty_midi import PrettyMIDI, program_to_instrument_class\nfrom lakh_utils import get_midi_path\nfrom lakh_utils import get_matched_midi_md5\n\ndef get_instrument_classes(msd_id) -> Optional[list]:\n  midi_md5 = get_matched_midi_md5(msd_id, MSD_SCORE_MATCHES)\n  midi_path = get_midi_path(msd_id, midi_md5, args.path_dataset_dir)\n  pm = PrettyMIDI(midi_path)\n  classes = [program_to_instrument_class(instrument.program)\n             for instrument in pm.instruments\n             if not instrument.is_drum]\n  drums = [\"Drums\" for instrument in pm.instruments if instrument.is_drum]\n  classes = classes + drums\n  if not classes:\n    raise Exception(f\"No program classes for {msd_id}: \"\n                    f\"{len(classes)}\")\n  return classes\n```", "```py\nfrom typing import Optional\nimport tables\nfrom threading_utils import AtomicCounter\nfrom lakh_utils import msd_id_to_h5\n\ndef process(msd_id: str, counter: AtomicCounter) -> Optional[dict]:\n  try:\n    with tables.open_file(msd_id_to_h5(msd_id, args.path_dataset_dir)) as h5:\n      classes = get_instrument_classes(msd_id)\n      return {\"msd_id\": msd_id, \"classes\": classes}\n  except Exception as e:\n    print(f\"Exception during processing of {msd_id}: {e}\")\n  finally:\n    counter.increment()\n```", "```py\nfrom collections import Counter\n\nclasses_list = [result[\"classes\"] for result in results]\nclasses = [c for classes in classes_list for c in classes]\nmost_common_classes = Counter(classes).most_common()\nplt.bar([c for c, _ in most_common_classes],\n        [count for _, count in most_common_classes])\nplt.title('Instrument classes')\nplt.xticks(rotation=30, horizontalalignment=\"right\")\nplt.ylabel('count')\nplt.show()\n```", "```py\nimport argparse\nimport ast\nfrom typing import Optional\nimport tables\nfrom multiprocessing_utils import AtomicCounter\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--tags\", type=str, required=True)\nargs = parser.parse_args()\n\nTAGS = ast.literal_eval(args.tags)\n\ndef process(msd_id: str, counter: AtomicCounter) -> Optional[dict]:\n  try:\n    with tables.open_file(msd_id_to_h5(msd_id, args.path_dataset_dir)) as h5:\n      tags = get_tags(h5)\n      matching_tags = [tag for tag in tags if tag in TAGS]\n      if not matching_tags:\n        return\n      pm_drums = extract_drums(msd_id)\n      pm_drums.write(os.path.join(args.path_output_dir, f\"{msd_id}.mid\"))\n      return {\"msd_id\": msd_id,\n              \"pm_drums\": pm_drums,\n              \"tags\": matching_tags}\n  except Exception as e:\n    print(f\"Exception during processing of {msd_id}: {e}\")\n  finally:\n    counter.increment()\n```", "```py\nfrom typing import List\nfrom pretty_midi import Instrument\nfrom pretty_midi import PrettyMIDI\nfrom lakh_utils import get_matched_midi_md5\nfrom lakh_utils import get_midi_path\n\nPIANO_PROGRAMS = list(range(0, 8))\n\ndef extract_pianos(msd_id: str) -> List[PrettyMIDI]:\n  os.makedirs(args.path_output_dir, exist_ok=True)\n  midi_md5 = get_matched_midi_md5(msd_id, MSD_SCORE_MATCHES)\n  midi_path = get_midi_path(msd_id, midi_md5, args.path_dataset_dir)\n  pm = PrettyMIDI(midi_path)\n  pm.instruments = [instrument for instrument in pm.instruments\n                    if instrument.program in PIANO_PROGRAMS\n and not instrument.is_drum]\n  pm_pianos = []\n  if len(pm.instruments) > 1:\n    for piano_instrument in pm.instruments:\n      pm_piano = copy.deepcopy(pm)\n      pm_piano_instrument = Instrument(program=piano_instrument.program)\n      pm_piano.instruments = [pm_piano_instrument]\n      for note in piano_instrument.notes:\n        pm_piano_instrument.notes.append(note)\n      pm_pianos.append(pm_piano)\n  else:\n    pm_pianos.append(pm)\n  for index, pm_piano in enumerate(pm_pianos):\n    if len(pm_piano.instruments) != 1:\n      raise Exception(f\"Invalid number of piano {msd_id}: \"\n                      f\"{len(pm_piano.instruments)}\")\n    if pm_piano.get_end_time() > 1000:\n      raise Exception(f\"Piano track too long {msd_id}: \"\n                      f\"{pm_piano.get_end_time()}\")\n  return pm_pianos\n```", "```py\nimport argparse\nimport ast\nfrom typing import Optional\nimport tables\nfrom lakh_utils import msd_id_to_h5\nfrom multiprocessing_utils import AtomicCounter\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--tags\", type=str, required=True)\nargs = parser.parse_args()\n\nTAGS = ast.literal_eval(args.tags)\n\ndef process(msd_id: str, counter: AtomicCounter) -> Optional[dict]:\n  try:\n    with tables.open_file(msd_id_to_h5(msd_id, args.path_dataset_dir)) as h5:\n      tags = get_tags(h5)\n      matching_tags = [tag for tag in tags if tag in TAGS]\n      if not matching_tags:\n        return\n      pm_pianos = extract_pianos(msd_id)\n      for index, pm_piano in enumerate(pm_pianos):\n        pm_piano.write(os.path.join(args.path_output_dir,\n                                    f\"{msd_id}_{index}.mid\"))\n      return {\"msd_id\": msd_id,\n              \"pm_pianos\": pm_pianos,\n              \"tags\": matching_tags}\n  except Exception as e:\n    print(f\"Exception during processing of {msd_id}: {e}\")\n  finally:\n    counter.increment()\n```", "```py\nconvert_dir_to_note_sequences --input_dir=\"PATH_OUTPUT_DIR\" --output_file=\"notesequences.tfrecord\"\n```", "```py\nmelody_rnn_create_dataset --config=\"attention_rnn\" --input=\"notesequences.tfrecord\" --output_dir=\"sequence_examples\" --eval_ratio=0.10\n```", "```py\nProcessed 500 inputs total. Produced 122 outputs.\nDAGPipeline_MelodyExtractor_eval_melodies_discarded_too_few_pitches: 7\nDAGPipeline_MelodyExtractor_eval_melodies_discarded_too_long: 0\nDAGPipeline_MelodyExtractor_eval_melodies_discarded_too_short: 42\nDAGPipeline_MelodyExtractor_eval_melodies_truncated: 2\nDAGPipeline_MelodyExtractor_eval_melody_lengths_in_bars:\n  [7,8): 4\n  [8,10): 2\n  [10,20): 2\n  [30,40): 2\nDAGPipeline_MelodyExtractor_eval_polyphonic_tracks_discarded: 113\nDAGPipeline_MelodyExtractor_training_melodies_discarded_too_few_pitches: 45\nDAGPipeline_MelodyExtractor_training_melodies_discarded_too_long: 0\nDAGPipeline_MelodyExtractor_training_melodies_discarded_too_short: 439\nDAGPipeline_MelodyExtractor_training_melodies_truncated: 20\nDAGPipeline_MelodyExtractor_training_melody_lengths_in_bars:\n [7,8): 22\n [8,10): 21\n [10,20): 42\n [20,30): 11\n [30,40): 16\nDAGPipeline_MelodyExtractor_training_polyphonic_tracks_discarded: 982\nDAGPipeline_RandomPartition_eval_melodies_count: 49\nDAGPipeline_RandomPartition_training_melodies_count: 451\nDAGPipeline_TranspositionPipeline_eval_skipped_due_to_range_exceeded: 0\nDAGPipeline_TranspositionPipeline_eval_transpositions_generated: 317\nDAGPipeline_TranspositionPipeline_training_skipped_due_to_range_exceeded: 0\nDAGPipeline_TranspositionPipeline_training_transpositions_generated: 2387\n```", "```py\nfrom magenta.pipelines import pipeline\n\npipeline_instance = get_pipeline(\"attention_rnn\", eval_ratio=0.10)\npipeline.run_pipeline_serial(\n    pipeline_instance,\n    pipeline.tf_record_iterator(INPUT_DIR, pipeline_instance.input_type),\n    OUTPUT_DIR)\n```", "```py\nINFO:tensorflow:Processed 500 inputs total. Produced 115 outputs.\n...\nINFO:tensorflow:DAGPipeline_MelodyExtractor_training_melody_lengths_in_bars:\n [7,8): 31\n [8,10): 9\n [10,20): 34\n [20,30): 11\n [30,40): 17\n [50,100): 2\n...\nINFO:tensorflow:DAGPipeline_TranspositionPipeline_training_transpositions_generated: 2058\n...\n```", "```py\n...\ntransposition_pipeline = note_sequence_pipelines.TranspositionPipeline(\n  (0,12), name='TranspositionPipeline_' + mode)\n...\n```", "```py\n...\nINFO:tensorflow:Processed 500 inputs total. Produced 230 outputs.\n...\nINFO:tensorflow:DAGPipeline_MelodyExtractor_training_melody_lengths_in_bars:\n [7,8): 66\n [8,10): 14\n [10,20): 64\n [20,30): 22\n [30,40): 34\n [50,100): 4\n...\nINFO:tensorflow:DAGPipeline_TranspositionPipeline_training_transpositions_generated: 4297\n...\n```", "```py\n...\nmelody_extractor = melody_pipelines.MelodyExtractor(\n min_bars=15, max_steps=1024, min_unique_pitches=5,\n gap_bars=1.0, ignore_polyphonic_notes=False,\n name='MelodyExtractor_' + mode)\n...\n```", "```py\nfrom magenta.pipelines.note_sequence_pipelines import NoteSequencePipeline\n\nclass MyTransformationClass(NoteSequencePipeline):\n  def transform(self, note_sequence):\n    # My transformation code here\n    pass\n```", "```py\n# Melody\nCONFIG_MAP['cat-mel_2bar_small'] = Config(\n    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n                   lstm_models.CategoricalLstmDecoder()),\n    hparams=merge_hparams(\n        lstm_models.get_default_hparams(),\n        HParams(\n            batch_size=512,\n            max_seq_len=32,  # 2 bars w/ 16 steps per bar\n            z_size=256,\n            enc_rnn_size=[512],\n            dec_rnn_size=[256, 256],\n            free_bits=0,\n            max_beta=0.2,\n            beta_rate=0.99999,\n            sampling_schedule='inverse_sigmoid',\n            sampling_rate=1000,\n        )),\n    note_sequence_augmenter=data.NoteSequenceAugmenter(transpose_range=(-5, 5)),\n    data_converter=data.OneHotMelodyConverter(\n        valid_programs=data.MEL_PROGRAMS,\n        skip_polyphony=False,\n        max_bars=100,  # Truncate long melodies before slicing.\n        slice_bars=2,\n        steps_per_quarter=4),\n    train_examples_path=None,\n    eval_examples_path=None,\n)\n```"]