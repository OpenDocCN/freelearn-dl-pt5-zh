["```py\n    import torch\n    import matplotlib.pyplot as plt\n    ```", "```py\n    from pytorch3d.renderer import (\n    FoVPerspectiveCameras,\n    NDCMultinomialRaysampler,\n    MonteCarloRaysampler,\n    EmissionAbsorptionRaymarcher,\n    ImplicitRenderer,\n    )\n    from utils.helper_functions import (generate_rotating_nerf,\n    huber,\n    sample_images_at_mc_locs)\n    from nerf_model import NeuralRadianceField\n    ```", "```py\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda:0\")\n        torch.cuda.set_device(device)\n    else:\n        device = torch.device(\"cpu\")\n    ```", "```py\n    from utils.plot_image_grid import image_grid\n    from utils.generate_cow_renders import generate_cow_renders\n    ```", "```py\n    target_cameras, target_images, target_silhouettes = generate_cow_renders(num_views=40, azimuth_range=180)\n    print(f'Generated {len(target_images)} images/silhouettes/cameras.')\n    ```", "```py\n    render_size = target_images.shape[1] * 2\n    volume_extent_world = 3.0\n    raysampler_mc = MonteCarloRaysampler(\n        min_x = -1.0,\n        max_x = 1.0,\n        min_y = -1.0,\n        max_y = 1.0,\n        n_rays_per_image=750,\n        n_pts_per_ray=128,\n        min_depth=0.1,\n        max_depth=volume_extent_world,\n    )\n    ```", "```py\n    raymarcher = EmissionAbsorptionRaymarcher()\n    ```", "```py\n    renderer_mc = ImplicitRenderer(raysampler=raysampler_mc, raymarcher=raymarcher)\n    ```", "```py\n    def huber(x, y, scaling=0.1):\n        diff_sq = (x - y) ** 2\n        loss = ((1 + diff_sq / (scaling**2)).clamp(1e-4).sqrt() - 1) * float(scaling)\n        return loss\n    ```", "```py\n    def sample_images_at_mc_locs(target_images, sampled_rays_xy):\n        ba = target_images.shape[0]\n        dim = target_images.shape[-1]\n        spatial_size = sampled_rays_xy.shape[1:-1]\n        images_sampled = torch.nn.functional.grid_sample(\n            target_images.permute(0, 3, 1, 2), \n            -sampled_rays_xy.view(ba, -1, 1, 2),  # note the sign inversion\n            align_corners=True\n        )\n        return images_sampled.permute(0, 2, 3, 1).view(\n            ba, *spatial_size, dim\n        )\n    ```", "```py\n    render_size = target_images.shape[1] * 2\n    volume_extent_world = 3.0\n    raysampler_grid = NDCMultinomialRaysampler(\n        image_height=render_size,\n        image_width=render_size,\n        n_pts_per_ray=128,\n        min_depth=0.1,\n        max_depth=volume_extent_world,\n    )\n    ```", "```py\n    renderer_grid = ImplicitRenderer(\n        raysampler=raysampler_grid, raymarcher=raymarcher,\n    )\n    ```", "```py\n    from utils.helper_function import show_full_render\n    ```", "```py\n    from nerf_model import NeuralRadianceField\n    neural_radiance_field = NeuralRadianceField()\n    ```", "```py\n    torch.manual_seed(1)\n    renderer_grid = renderer_grid.to(device)\n    renderer_mc = renderer_mc.to(device)\n    target_cameras = target_cameras.to(device)\n    target_images = target_images.to(device)\n    target_silhouettes = target_silhouettes.to(device)\n    neural_radiance_field = neural_radiance_field.to(device)\n    ```", "```py\n    lr = 1e-3\n    optimizer = torch.optim.Adam(neural_radiance_field.parameters(), lr=lr)\n    batch_size = 6\n    n_iter = 3000\n    ```", "```py\n    loss_history_color, loss_history_sil = [], []\n    for iteration in range(n_iter):\n        if iteration == round(n_iter * 0.75):\n            print('Decreasing LR 10-fold ...')\n            optimizer = torch.optim.Adam(\n                neural_radiance_field.parameters(), lr=lr * 0.1\n            )\n        optimizer.zero_grad()\n        batch_idx = torch.randperm(len(target_cameras))[:batch_size]\n        batch_cameras = FoVPerspectiveCameras(\n            R = target_cameras.R[batch_idx], \n            T = target_cameras.T[batch_idx], \n            znear = target_cameras.znear[batch_idx],\n            zfar = target_cameras.zfar[batch_idx],\n            aspect_ratio = target_cameras.aspect_ratio[batch_idx],\n            fov = target_cameras.fov[batch_idx],\n            device = device,\n        )\n    ```", "```py\n        rendered_images_silhouettes, sampled_rays = renderer_mc(\n            cameras=batch_cameras, \n            volumetric_function=neural_radiance_field\n        )\n        rendered_images, rendered_silhouettes = (\n            rendered_images_silhouettes.split([3, 1], dim=-1)\n        )\n\n        silhouettes_at_rays = sample_images_at_mc_locs(\n            target_silhouettes[batch_idx, ..., None], \n            sampled_rays.xys\n        )\n        sil_err = huber(\n            rendered_silhouettes, \n            silhouettes_at_rays,\n        ).abs().mean()\n        colors_at_rays = sample_images_at_mc_locs(\n            target_images[batch_idx], \n            sampled_rays.xys\n        )\n        color_err = huber(\n            rendered_images, \n            colors_at_rays,\n        ).abs().mean()\n\n        loss = color_err + sil_err\n        loss_history_color.append(float(color_err))\n        loss_history_sil.append(float(sil_err))\n\n        loss.backward()\n        optimizer.step()\n    ```", "```py\n        if iteration % 100 == 0:\n            show_idx = torch.randperm(len(target_cameras))[:1]\n            fig = show_full_render(\n            neural_radiance_field,\n            FoVPerspectiveCameras(\n                R = target_cameras.R[show_idx], \n                T = target_cameras.T[show_idx], \n                znear = target_cameras.znear[show_idx],\n                zfar = target_cameras.zfar[show_idx],\n                aspect_ratio = target_cameras.aspect_ratio[show_idx],\n                fov = target_cameras.fov[show_idx],\n                device = device), \n            target_images[show_idx][0],\n            target_silhouettes[show_idx][0],\n            renderer_grid,\n            loss_history_color,\n            loss_history_sil)\n        fig.savefig(f'intermediate_{iteration}')\n    ```", "```py\n    from utils import generate_rotating_nerf\n    with torch.no_grad():\n        rotating_nerf_frames = generate_rotating_nerf(neural_radiance_field, n_frames=3*5)\n    image_grid(rotating_nerf_frames.clamp(0., 1.).cpu().numpy(), rows=3, cols=5, rgb=True, fill=True)\n    plt.show()\n    ```", "```py\n    class NeuralRadianceField(torch.nn.Module):\n        def __init__(self, n_harmonic_functions=60, n_hidden_neurons=256):\n            super().__init__()        \n            self.harmonic_embedding = HarmonicEmbedding(n_harmonic_functions)\n    ```", "```py\n            embedding_dim = n_harmonic_functions * 2 * 3\n            self.mlp = torch.nn.Sequential(\n                torch.nn.Linear(embedding_dim, n_hidden_neurons),\n                torch.nn.Softplus(beta=10.0),\n                torch.nn.Linear(n_hidden_neurons, n_hidden_neurons),\n                torch.nn.Softplus(beta=10.0),\n            )        \n    ```", "```py\n            self.color_layer = torch.nn.Sequential(\n                torch.nn.Linear(n_hidden_neurons + embedding_dim, n_hidden_neurons),\n                torch.nn.Softplus(beta=10.0),\n                torch.nn.Linear(n_hidden_neurons, 3),\n                torch.nn.Sigmoid(),\n            )\n    ```", "```py\n            self.density_layer = torch.nn.Sequential(\n                torch.nn.Linear(n_hidden_neurons, 1),\n                torch.nn.Softplus(beta=10.0),\n            self.density_layer[0].bias.data[0] = -1.5        \n    ```", "```py\n        def _get_densities(self, features):\n            raw_densities = self.density_layer(features)\n            return 1 - (-raw_densities).exp()\n    ```", "```py\n        def _get_colors(self, features, rays_directions):\n            spatial_size = features.shape[:-1]        \n            rays_directions_normed = torch.nn.functional.normalize(\n                rays_directions, dim=-1\n            )\n            rays_embedding = self.harmonic_embedding(\n                rays_directions_normed\n            )\n            rays_embedding_expand = rays_embedding[..., None, :].expand(\n                *spatial_size, rays_embedding.shape[-1]\n            )        \n            color_layer_input = torch.cat(\n                (features, rays_embedding_expand),\n                dim=-1\n            )\n            return self.color_layer(color_layer_input)\n\n    ```", "```py\n        def forward(\n            self, \n            ray_bundle: RayBundle,\n            **kwargs,\n        ):\n            rays_points_world = ray_bundle_to_ray_points(ray_bundle)        \n            embeds = self.harmonic_embedding(\n                rays_points_world\n            )\n            features = self.mlp(embeds)        \n            rays_densities = self._get_densities(features)\n            # rays_densities.shape = [minibatch x ... x 1]\n            rays_colors = self._get_colors(features, ray_bundle.directions)        \n            return rays_densities, rays_colors\n    ```", "```py\n        def batched_forward(\n            self, \n            ray_bundle: RayBundle,\n            n_batches: int = 16,\n            **kwargs,        \n        ):\n            n_pts_per_ray = ray_bundle.lengths.shape[-1]  \n            spatial_size = [*ray_bundle.origins.shape[:-1], n_pts_per_ray]\n            # Split the rays to `n_batches` batches.\n            tot_samples = ray_bundle.origins.shape[:-1].numel()\n            batches = torch.chunk(torch.arange(tot_samples), n_batches)\n    ```", "```py\n            batch_outputs = [\n                self.forward(\n                    RayBundle(\n                        origins=ray_bundle.origins.view(-1, 3)[batch_idx],\n                     directions=ray_bundle.directions.view(-1, 3)[batch_idx],\n                        lengths=ray_bundle.lengths.view(-1, n_pts_per_ray)[batch_idx],\n                        xys=None,\n                    )\n                ) for batch_idx in batches\n            ]\n            rays_densities, rays_colors = [\n                torch.cat(\n                    [batch_output[output_i] for batch_output in batch_outputs], dim=0\n                ).view(*spatial_size, -1) for output_i in (0, 1)]\n            return rays_densities, rays_colors\n    ```"]