<html><head></head><body>
<div id="_idContainer147">
<h1 class="chapter-number" id="_idParaDest-238"><a id="_idTextAnchor247"/><span class="koboSpan" id="kobo.1.1">17</span></h1>
<h1 id="_idParaDest-239"><a id="_idTextAnchor248"/><span class="koboSpan" id="kobo.2.1">Managing Drift Effectively in a Dynamic Environment</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Drift is a significant factor in the performance deterioration of deployed deep learning models over time, encompassing concept drift, data drift, and model drift. </span><span class="koboSpan" id="kobo.3.2">Let’s understand the drift of a deployed model through a culinary-based analogy. </span><span class="koboSpan" id="kobo.3.3">Imagine a deployed deep learning model as a skilled chef who aims to create dishes that delight customers but excels in a particular cuisine. </span><span class="koboSpan" id="kobo.3.4">Concept drift occurs when the taste preferences of the diner shift, which alters the relationships between ingredients and popular dishes that can satisfy the diner’s palate. </span><span class="koboSpan" id="kobo.3.5">Data drift, on the other hand, happens when the ingredients themselves change, such as variations in flavor or availability. </span><span class="koboSpan" id="kobo.3.6">Finally, model metric monitoring alerts happen most straightforwardly when the chef loses customers. </span><span class="koboSpan" id="kobo.3.7">In all cases, the chef must adapt their dishes to maintain their success, just as deep learning models need to be updated to account for concept drift, which deals with the changing relationships between input and target variables, and data drift, which tackles adjustments in the input data distribution </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">and characteristics.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Monitoring drift is crucial to ensuring the continued success of deep learning models, just as a chef needs to keep track of their customers’ evolving preferences and the changing nature of ingredients. </span><span class="koboSpan" id="kobo.5.2">As a sneak peek, only some use cases require monitoring. </span><span class="koboSpan" id="kobo.5.3">In this chapter, we will delve into the techniques to measure and detect drift, which will allow us to effectively monitor and send timely alerts when drift is detected, and make necessary model maintenance adjustments. </span><span class="koboSpan" id="kobo.5.4">Drawing parallels with our chef analogy, techniques to monitor drift can be likened to a chef observing the reactions of their customers, reading reviews, or collecting feedback to better understand their preferences and the quality of their ingredients. </span><span class="koboSpan" id="kobo.5.5">By staying alert to any drift, both the chef and the deep learning model can adapt and evolve, maintaining their expertise and delivering exceptional results in a dynamic environment. </span><span class="koboSpan" id="kobo.5.6">Specifically, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.7.1">Exploring the issues </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">of drift</span></span></li>
<li><span class="koboSpan" id="kobo.9.1">Exploring the types </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">of drift</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Exploring strategies to </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">handle drift</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Detecting </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">drift programmatically</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Comparing and contrasting the Evidently and Alibi-Detect libraries for </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">drift detection</span></span></li>
</ul>
<h1 id="_idParaDest-240"><a id="_idTextAnchor249"/><span class="koboSpan" id="kobo.17.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.18.1">This chapter will cover a practical example to test out data drift techniques. </span><span class="koboSpan" id="kobo.18.2">We will be using Python 3.10 and, additionally, we will require the following Python libraries to </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">be installed:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.20.1">evidently</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.21.1">numpy</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.22.1">transformers==4.21.3</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.23.1">torch==1.12.0</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.24.1">syllables</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.25.1">audiomentations</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.26.1">datasets</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.27.1">The code files are available on </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">GitHub: </span></span><a href="https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_17"><span class="No-Break"><span class="koboSpan" id="kobo.29.1">https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_17</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.30.1">.</span></span></p>
<h1 id="_idParaDest-241"><a id="_idTextAnchor250"/><span class="koboSpan" id="kobo.31.1">Exploring the issues of drift</span></h1>
<p><span class="koboSpan" id="kobo.32.1">The most obvious issue </span><a id="_idIndexMarker1244"/><span class="koboSpan" id="kobo.33.1">of drift is the degradation of the accuracy. </span><span class="koboSpan" id="kobo.33.2">However, there are more issues than you might initially notice, which include </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.35.1">Applicability</span></strong><span class="koboSpan" id="kobo.36.1">: The model’s ability to make accurate predictions on new, unseen data may be compromised as data patterns and distributions shift. </span><span class="koboSpan" id="kobo.36.2">This can result in reduced effectiveness in real-world scenarios and diminished value for decision-making, which raises the likelihood of the model becoming less relevant and practical </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">to use.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.38.1">Interpretability</span></strong><span class="koboSpan" id="kobo.39.1">: Understanding and explaining the model’s decisions can become challenging, as the factors influencing its predictions may no longer align with the current data landscape. </span><span class="koboSpan" id="kobo.39.2">This can hinder effective communication with stakeholders and impede trust in the model’s predictions. </span><span class="koboSpan" id="kobo.39.3">Note that an originally explainable model is still explainable as we can still produce accurate information on how it used the input data, but it can become more difficult to interpret with </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">drifted data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.41.1">Fairness</span></strong><span class="koboSpan" id="kobo.42.1">: Biases and disparities could emerge or worsen, raising fairness concerns in the model’s output. </span><span class="koboSpan" id="kobo.42.2">This can lead to the unequal treatment of different groups, perpetuating harmful disparities and posing ethical concerns in the </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">model’s application.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.44.1">Stability</span></strong><span class="koboSpan" id="kobo.45.1">: Sensitivity to changes in input data may result in fluctuating performance, impacting the model’s stability and consistency. </span><span class="koboSpan" id="kobo.45.2">Unstable models can lead to unreliable results, making it difficult for decision-makers to rely on the </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">model’s outputs.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.47.1">These issues comprehensively highlight the challenges that can arise from drift in data. </span><span class="koboSpan" id="kobo.47.2">By now, we know about the three high-level drift groups. </span><span class="koboSpan" id="kobo.47.3">This is useful, but not enough to implement drift</span><a id="_idIndexMarker1245"/><span class="koboSpan" id="kobo.48.1"> detection. </span><span class="koboSpan" id="kobo.48.2">Prior knowledge of the types of drift that can impact your model will enable you to prepare your model for any deployment-related concerns and implement drift monitoring, which brings us to the </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">next topic.</span></span></p>
<h1 id="_idParaDest-242"><a id="_idTextAnchor251"/><span class="koboSpan" id="kobo.50.1">Exploring the types of drift</span></h1>
<p><span class="koboSpan" id="kobo.51.1">Drift is like a shift in</span><a id="_idIndexMarker1246"/><span class="koboSpan" id="kobo.52.1"> the way things work with data. </span><span class="koboSpan" id="kobo.52.2">It happens when the data changes, or the environment it comes from changes. </span><span class="koboSpan" id="kobo.52.3">This can sometimes happen suddenly or quickly, sometimes slowly, or even in a recurring pattern. </span><span class="koboSpan" id="kobo.52.4">When it comes to drift, it’s important to look at the big picture, not just a couple of odd blips. </span><span class="koboSpan" id="kobo.52.5">Drift isn’t about those rare anomalies or one or two odd predictions; it’s about changes that stick around, like a new pattern that stays. </span><span class="koboSpan" id="kobo.52.6">These persistent shifts can mess up your model permanently, making it way less useful. </span><span class="koboSpan" id="kobo.52.7">It’s like if your friend suddenly started speaking a different language occasionally, which could lead to one-off confusion but not really be a problem. </span><span class="koboSpan" id="kobo.52.8">But if they started speaking a different language all the time, it’d be a </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">big problem.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">Furthermore, drift can be categorized into three main types: data drift, concept drift, and model drift. </span><span class="koboSpan" id="kobo.54.2">While concept drift is related to the data and can be argued to be part of data drift, concept and data drift are often considered separate in the field. </span><span class="koboSpan" id="kobo.54.3">Let’s dive into each of the drift </span><a id="_idIndexMarker1247"/><span class="koboSpan" id="kobo.55.1">types sequentially, starting with </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">data drift.</span></span></p>
<h2 id="_idParaDest-243"><a id="_idTextAnchor252"/><span class="koboSpan" id="kobo.57.1">Exploring data drift types</span></h2>
<p><span class="koboSpan" id="kobo.58.1">Data drift occurs</span><a id="_idIndexMarker1248"/><span class="koboSpan" id="kobo.59.1"> when certain features of a current data batch </span><a id="_idIndexMarker1249"/><span class="koboSpan" id="kobo.60.1">differ from those of a historical batch. </span><span class="koboSpan" id="kobo.60.2">It is essential to understand that data drift is not limited to a single type of change. </span><span class="koboSpan" id="kobo.60.3">Many practitioners mistakenly focus only on the most widely known type of characteristic change for data drift, which is the shift in distribution. </span><span class="koboSpan" id="kobo.60.4">Distribution is a fundamental concept in statistics that reveals how frequently various values of a variable appear in a dataset. </span><span class="koboSpan" id="kobo.60.5">It helps us comprehend the nature of the data we are working with, but vaguely. </span><span class="koboSpan" id="kobo.60.6">Some well-known distribution patterns include normal, uniform, skewed, exponential, Poisson, binomial, and multinomial. </span><span class="koboSpan" id="kobo.60.7">Determining whether a change in distribution is beneficial or harmful can be challenging because a change in distribution can sometimes result in good consequences, while no change in distribution doesn’t necessarily imply that performance won’t be degraded. </span><span class="koboSpan" id="kobo.60.8">The relationship between distribution changes and model performance is not always straightforward, making it difficult to assess the impact accurately. </span><em class="italic"><span class="koboSpan" id="kobo.61.1">So, it is advisable to always consider other, more understandable, cross-validation-tested statistical data drift that strongly correlates with performance metrics instead of data </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.62.1">distribution drift.</span></em></span></p>
<p><span class="koboSpan" id="kobo.63.1">Statistical drift refers to changes in statistical characteristics, such as mean, variance, correlation, or skewness, that can have a more direct impact on model performance. </span><span class="koboSpan" id="kobo.63.2">This also means that the relationship between them is more predictable, which allows for more targeted maintenance actions. </span><span class="koboSpan" id="kobo.63.3">Change between statistical values can be measured through difference or ratio. </span><span class="koboSpan" id="kobo.63.4">For example, if a deep learning model is trained to recognize handwritten digits, a statistical drift in the mean intensity of the digits (for example, due to changes in lighting conditions) could have a direct impact on the model’s accuracy. </span><span class="koboSpan" id="kobo.63.5">This approach will enable us to better prepare for any potential negative impacts and maintain the effectiveness of our data analysis. </span><span class="koboSpan" id="kobo.63.6">More broadly, the choice between these two is part</span><a id="_idIndexMarker1250"/><span class="koboSpan" id="kobo.64.1"> of the </span><strong class="bold"><span class="koboSpan" id="kobo.65.1">data </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.66.1">drift techniques</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.68.1">However, the prerequisite of drift being relevantly and reliably handled comes down to the choice of the </span><strong class="bold"><span class="koboSpan" id="kobo.69.1">data types</span></strong><span class="koboSpan" id="kobo.70.1"> to apply distributional or statistical drift methods. </span><span class="koboSpan" id="kobo.70.2">Some examples of the other data types are </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.72.1">Data characteristic drift</span></strong><span class="koboSpan" id="kobo.73.1">: Occurs when there are changes in the underlying properties or</span><a id="_idIndexMarker1251"/><span class="koboSpan" id="kobo.74.1"> attributes of the data. </span><span class="koboSpan" id="kobo.74.2">It’s important to remember that drift doesn’t just cover actual model input or output data changes and can also cover external descriptors or metadata associated with the input or output data. </span><span class="koboSpan" id="kobo.74.3">To make this more concrete, let’s explore some example characteristics that can be monitored and measured </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">for drift:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.76.1">Text</span></strong><span class="koboSpan" id="kobo.77.1">: The usage of certain words, phrases, sentiment, word count, and average length </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">of sentences</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.79.1">Image</span></strong><span class="koboSpan" id="kobo.80.1">: Object orientation, lighting hue, color, size, and </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">any styles</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.82.1">Audio</span></strong><span class="koboSpan" id="kobo.83.1">: Sound or speaker pitch, tempo, timbre, tone, speaker gender, speaker accents, speaker dialects, and </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">speaking styles</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.85.1">Data quality drift</span></strong><span class="koboSpan" id="kobo.86.1">: Occurs when there are distribution changes in the quality of the data being collected, such as missing values, data entry errors, or measurement errors. </span><span class="koboSpan" id="kobo.86.2">These changes can impact the model’s ability to make </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">accurate predictions.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.88.1">Core data drift</span></strong><span class="koboSpan" id="kobo.89.1">: This involves the raw data of image, text, audio, and any embedding data that is extracted from a deep learning model at any level. </span><span class="koboSpan" id="kobo.89.2">This drift data type can be hard to interpret and it can be hard to find a correlation with the metrics you care about. </span><span class="koboSpan" id="kobo.89.3">Drift in the unstructured raw data itself rarely correlates with the metrics you care about. </span><span class="koboSpan" id="kobo.89.4">However, embedding data from the actual deep learning model that was used for the prediction is more likely to show drift values that are relevant to the metric you care about. </span><span class="koboSpan" id="kobo.89.5">As a standard, practitioners usually choose the embeddings from the final </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">layer output.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.91.1">While these data </span><a id="_idIndexMarker1252"/><span class="koboSpan" id="kobo.92.1">type categories cover what characteristics of </span><a id="_idIndexMarker1253"/><span class="koboSpan" id="kobo.93.1">the data drifted, there are two higher-level data drift types that should be known. </span><span class="koboSpan" id="kobo.93.2">The higher-level data drift types govern where the drift is measured, monitored, and detected, which can be labeled as part of the </span><strong class="bold"><span class="koboSpan" id="kobo.94.1">drift scenarios</span></strong><span class="koboSpan" id="kobo.95.1">. </span><span class="koboSpan" id="kobo.95.2">These are </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.97.1">Covariate drift</span></strong><span class="koboSpan" id="kobo.98.1"> or input features drift, which involves shifts in the input features while maintaining the same relationship with the target variable. </span><span class="koboSpan" id="kobo.98.2">This can arise from changes in data collection methods, user behavior, or external factors, challenging the model’s ability to generalize effectively. </span><span class="koboSpan" id="kobo.98.3">It can affect the importance or relevance of certain features in predicting the </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">target variable.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.100.1">Label drift</span></strong><span class="koboSpan" id="kobo.101.1"> or target drift, which pertains to changes in the ground-truth labels of the data. </span><span class="koboSpan" id="kobo.101.2">Occurs when the target changes over time. </span><span class="koboSpan" id="kobo.101.3">This may result from errors in labeling, shifts in labeling criteria, or changing interpretations of the target variable. </span><span class="koboSpan" id="kobo.101.4">Not to be confused with concept drift, let’s explore an example of label drift with a product recommendation system. </span><span class="koboSpan" id="kobo.101.5">Shifts from broad categories such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.102.1">Electronics</span></strong><span class="koboSpan" id="kobo.103.1"> to specific labels such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.104.1">Smartphones</span></strong><span class="koboSpan" id="kobo.105.1"> constitute label drift when underlying user-product relationships </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">remain unchanged.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.107.1">Building upon our understanding of data drift, let’s now delve into the equally important phenomenon of </span><a id="_idIndexMarker1254"/><span class="koboSpan" id="kobo.108.1">concept drift, which focuses on the </span><a id="_idIndexMarker1255"/><span class="koboSpan" id="kobo.109.1">evolving relationships between input data and target variables in various use cases </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">and scenarios.</span></span></p>
<h2 id="_idParaDest-244"><a id="_idTextAnchor253"/><span class="koboSpan" id="kobo.111.1">Exploring concept drift</span></h2>
<p><span class="koboSpan" id="kobo.112.1">Concept drift is</span><a id="_idIndexMarker1256"/><span class="koboSpan" id="kobo.113.1"> intimately tied to the specific use case and </span><a id="_idIndexMarker1257"/><span class="koboSpan" id="kobo.114.1">data characteristics. </span><span class="koboSpan" id="kobo.114.2">Rather than adhering to predefined types, concept drift’s occurrence and impact vary based on factors such as problem context, data attributes, temporal dynamics, external influences, and adaptation strategies. </span><span class="koboSpan" id="kobo.114.3">Acknowledging this context dependency is essential for tailoring effective concept drift detection and adaptation methods that align with the nuances of each individual scenario. </span><span class="koboSpan" id="kobo.114.4">Let’s explore some examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">concept drift:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.116.1">Search engine algorithms</span></strong><span class="koboSpan" id="kobo.117.1">: A search engine’s ranking algorithm learns from user behavior, but the user</span><a id="_idIndexMarker1258"/><span class="koboSpan" id="kobo.118.1"> preferences evolve over time. </span><span class="koboSpan" id="kobo.118.2">What was once considered relevant might not be anymore, causing a shift in the concept of relevance and altering both the input data (queries) and target (</span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">rankings) relationships.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.120.1">Online advertisement campaigns</span></strong><span class="koboSpan" id="kobo.121.1">: In online advertising, users’ click-through behavior changes due to new trends or demographics. </span><span class="koboSpan" id="kobo.121.2">This leads to shifts in user preferences, affecting both the input data (ad impressions) and the target (click-through </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">rates) relationships.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.123.1">Medical diagnostics</span></strong><span class="koboSpan" id="kobo.124.1">: In medical diagnosis, patient profiles change as demographics or health trends shift. </span><span class="koboSpan" id="kobo.124.2">This impacts the concept of “normal” and “abnormal” within the data, altering both the input data (patient characteristics) and the target (</span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">diagnosis) relationships.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.126.1">Finally, it’s</span><a id="_idIndexMarker1259"/><span class="koboSpan" id="kobo.127.1"> time to</span><a id="_idIndexMarker1260"/><span class="koboSpan" id="kobo.128.1"> explore the last drift type, called </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">model drift.</span></span></p>
<h2 id="_idParaDest-245"><a id="_idTextAnchor254"/><span class="koboSpan" id="kobo.130.1">Exploring model drift</span></h2>
<p><span class="koboSpan" id="kobo.131.1">Model drift simply </span><a id="_idIndexMarker1261"/><span class="koboSpan" id="kobo.132.1">deals with the shift in model evaluation metrics, which </span><a id="_idIndexMarker1262"/><span class="koboSpan" id="kobo.133.1">usually require real and natural targets being provided later, system metrics, and business metrics. </span><span class="koboSpan" id="kobo.133.2">This drift is the most straightforward to monitor and capture as it is a drift that can be directly connected to metrics you </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">care about.</span></span></p>
<p><span class="koboSpan" id="kobo.135.1">Now, we are ready to explore strategies to </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">handle drift.</span></span></p>
<h1 id="_idParaDest-246"><a id="_idTextAnchor255"/><span class="koboSpan" id="kobo.137.1">Exploring strategies to handle drift</span></h1>
<p><span class="koboSpan" id="kobo.138.1">Simply setting up</span><a id="_idIndexMarker1263"/><span class="koboSpan" id="kobo.139.1"> drift monitoring for a deployed model isn’t enough to effectively tackle all potential drift-related challenges. </span><span class="koboSpan" id="kobo.139.2">It’s crucial to ask yourself: does the specific drift with the chosen data type impact the model’s performance in the metrics that matter the most? </span><span class="koboSpan" id="kobo.139.3">At what point does drift become intolerable? </span><span class="koboSpan" id="kobo.139.4">To properly address drift, start by pinpointing the drift metric and data type that carries the most significance for your model and the business. </span><span class="koboSpan" id="kobo.139.5">If your model has been developed correctly, it may possess generalizable properties, which is the primary goal for most machine learning practitioners. </span><span class="koboSpan" id="kobo.139.6">This means that a well-developed model should be able to handle drift effectively. </span><span class="koboSpan" id="kobo.139.7">When drift detection and alerts are configured without proper consideration of their effects, it poses the risk that drift alerts can be raised without an actual issue, which can result in wasted time and resources that could have been used more productively elsewhere. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.140.1">Figure 17</span></em></span><em class="italic"><span class="koboSpan" id="kobo.141.1">.1</span></em><span class="koboSpan" id="kobo.142.1"> shows the high-level methodology that encompasses the strategies we </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">will explore:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer144">
<span class="koboSpan" id="kobo.144.1"><img alt="Figure 17.1 – Drift-handling methodology" src="image/B18187_17_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.145.1">Figure 17.1 – Drift-handling methodology</span></p>
<p><span class="koboSpan" id="kobo.146.1">Let’s start with a deep</span><a id="_idIndexMarker1264"/><span class="koboSpan" id="kobo.147.1"> dive into the first strategy, which is to explore drift detection methods </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">and strategies.</span></span></p>
<h2 id="_idParaDest-247"><a id="_idTextAnchor256"/><span class="koboSpan" id="kobo.149.1">Exploring drift detection strategies</span></h2>
<p><span class="koboSpan" id="kobo.150.1">Not every drift type that </span><a id="_idIndexMarker1265"/><span class="koboSpan" id="kobo.151.1">can impact your model and the metrics you care about requires monitoring. </span><span class="koboSpan" id="kobo.151.2">There are two primary ways to detect drift, which are </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.153.1">Estimating future drift events based on manual insights and domain knowledge</span></strong><span class="koboSpan" id="kobo.154.1">: This method doesn’t require any monitoring setup and depends on humans as the alerting mechanism. </span><span class="koboSpan" id="kobo.154.2">Imagine an e-commerce platform that uses a deep learning model to recommend products to its customers, with the goal of increasing product purchases. </span><span class="koboSpan" id="kobo.154.3">Drift in customer preferences consistently happens during different seasons, such as Halloween or Christmas. </span><span class="koboSpan" id="kobo.154.4">For instance, people might search for costumes in October and gifts in December. </span><span class="koboSpan" id="kobo.154.5">Building on this domain knowledge, instead of measuring and detecting drift, before each season arrives, you pre-emptively adjust the model’s recommendations according to the expected season trend. </span><span class="koboSpan" id="kobo.154.6">This prevents the need to measure and detect any change in preferences and ultimately can also prevent any degradation </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">in performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.156.1">Using automated programmatic measurements, monitoring, and detection of specific traits or patterns</span></strong><span class="koboSpan" id="kobo.157.1">: Imagine you trained a deep learning model to identify whether an email is spam and validated with real data. </span><span class="koboSpan" id="kobo.157.2">Through analysis, you find that the average length of an email degrades the model’s performance. </span><span class="koboSpan" id="kobo.157.3">You don’t have sufficient data to train the model to tackle this issue, deploy it, and decide to monitor it if the email length changes. </span><span class="koboSpan" id="kobo.157.4">By tracking and comparing this programmatic measurement of email length, you can effectively detect the drift and take subsequent actions to improve the model’s performance. </span><span class="koboSpan" id="kobo.157.5">Programmatic data distribution drift detection methods include statistical tests, distance metrics, and classification models and will be explored further in the </span><em class="italic"><span class="koboSpan" id="kobo.158.1">Detecting drift </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.159.1">programmatically</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.160.1"> section.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.161.1">Sometimes, both are required, and sometimes, only the first method is needed. </span><span class="koboSpan" id="kobo.161.2">Having planned fixed dates on when you expect concept drift to occur and assigning planned dates to mitigate them </span><a id="_idIndexMarker1266"/><span class="koboSpan" id="kobo.162.1">are more reasonable strategies than trying to detect them. </span><span class="koboSpan" id="kobo.162.2">However, as mentioned, there are cases where you absolutely need to implement drift monitoring </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">and detection.</span></span></p>
<p><span class="koboSpan" id="kobo.164.1">If the choice is to measure, monitor, and detect drift programmatically, it is important to make sure that you set a big enough time interval to how you’re measuring and detecting drift. </span><span class="koboSpan" id="kobo.164.2">You want to catch those shifts that are there to stay, and those are the ones that can make your model struggle. </span><span class="koboSpan" id="kobo.164.3">This ensures we’re not chasing after one-time anomalies but addressing substantial shifts that can impact the reliability of our models. </span><span class="koboSpan" id="kobo.164.4">To that end, drift detection in production should be configured to be run in batch mode and does not need real-time monitoring </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">and detection.</span></span></p>
<p><span class="koboSpan" id="kobo.166.1">For other metrics for monitoring a deployed deep learning model, the recommended route is to use real-time predictions and monitoring and alerting functionalities using NVIDIA Triton Inference Server, the Prometheus server, and Grafana. </span><span class="koboSpan" id="kobo.166.2">However, for batch predictions, the recommended stack would be to use Apache Airflow for scheduling a drift detection task to be executed regularly, a database such as PostgreSQL to store drift measurements from Airflow tasks, and Grafana to connect to PostgreSQL for monitoring batch drift and creating alerts. </span><span class="koboSpan" id="kobo.166.3">Notably, a database is recommended over using Prometheus, being the more efficient choice, as Prometheus requires more services to be set up, which can take up more resources. </span><span class="koboSpan" id="kobo.166.4">This can be wasteful as Prometheus is set up to take up resources for real-time usage when it’s not needed. </span><span class="koboSpan" id="kobo.166.5">Look into </span><a href="https://github.com/evidentlyai/evidently/tree/v0.4.4/examples/integrations/airflow_batch_monitoring"><span class="koboSpan" id="kobo.167.1">https://github.com/evidentlyai/evidently/tree/v0.4.4/examples/integrations/airflow_batch_monitoring</span></a><span class="koboSpan" id="kobo.168.1"> for a tutorial on how to set </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">this up.</span></span></p>
<p><span class="koboSpan" id="kobo.170.1">The prerequisite to setting the recommended batch predictions stack up is that the input data used must be saved somewhere for an Airflow task to pick it up in the future. </span><span class="koboSpan" id="kobo.170.2">The data can live in any format, and most typically for actual business use cases, the input data should already live in a database such as PostgreSQL. </span><span class="koboSpan" id="kobo.170.3">If drift is applied to the predictions, then either the predictions also need to be saved in a database or it can be a task prior to the drift measurement under the same directed acyclic graph in Airflow, which can be </span><a id="_idIndexMarker1267"/><span class="No-Break"><span class="koboSpan" id="kobo.171.1">scheduled regularly.</span></span></p>
<p><span class="koboSpan" id="kobo.172.1">As a follow-up, to ensure reliable drift monitoring and detection programmatically, we need an additional step before setting it up, which is to analyze the impact </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">of drift.</span></span></p>
<h2 id="_idParaDest-248"><a id="_idTextAnchor257"/><span class="koboSpan" id="kobo.174.1">Analyzing the impact of drift</span></h2>
<p><span class="koboSpan" id="kobo.175.1">To mitigate the risk that</span><a id="_idIndexMarker1268"/><span class="koboSpan" id="kobo.176.1"> drift alerts are raised without an actual issue, perform </span><a id="_idIndexMarker1269"/><span class="koboSpan" id="kobo.177.1">a </span><strong class="bold"><span class="koboSpan" id="kobo.178.1">drift impact analysis</span></strong><span class="koboSpan" id="kobo.179.1"> on your chosen model before deployment. </span><span class="koboSpan" id="kobo.179.2">Drift impact analysis is closely related to the adversarial performance analysis methods introduced in </span><a href="B18187_14.xhtml#_idTextAnchor206"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.180.1">Chapter 14</span></em></span></a><span class="koboSpan" id="kobo.181.1">, </span><em class="italic"><span class="koboSpan" id="kobo.182.1">Analyzing Adversarial Performance</span></em><span class="koboSpan" id="kobo.183.1">. </span><span class="koboSpan" id="kobo.183.2">The same strategy of using controllable augmentation or collecting real-world data with the targeted data characteristic drift to perform an evaluation can be adopted. </span><span class="koboSpan" id="kobo.183.3">So, re-explore that chapter and apply the same analysis methods with drift in mind. </span><span class="koboSpan" id="kobo.183.4">The idea is to make sure any variation in the data type or types you choose to monitor for drift correlates with the model performance metrics in some way. </span><span class="koboSpan" id="kobo.183.5">In other words, perform correlation analysis, adversarial performance analysis, or drift impact analysis at once! </span><span class="koboSpan" id="kobo.183.6">But do be aware of the issue where correlation not being causation can lead to </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">misleading conclusions.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.185.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.186.1">When there are cases where you can’t augment the characteristics, it can be crucial to monitor it after deployment and perform impact </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">analysis then.</span></span></p>
<p><span class="koboSpan" id="kobo.188.1">Consequently, as a bonus, findings from adversarial performance analysis should guide the establishment of an appropriate detection threshold, determined by pinpointing the stage at which any additional metric degradation becomes unacceptable. </span><span class="koboSpan" id="kobo.188.2">Just as a binary threshold must be finely calibrated to balance recall and precision trade-offs for a binary classification model. </span><span class="koboSpan" id="kobo.188.3">This is part of the guardrail filter component introduced in the </span><em class="italic"><span class="koboSpan" id="kobo.189.1">Governing deep learning model utilization</span></em><span class="koboSpan" id="kobo.190.1"> section in the previous chapter, </span><a href="B18187_16.xhtml#_idTextAnchor238"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.191.1">Chapter 16</span></em></span></a><span class="koboSpan" id="kobo.192.1">, </span><em class="italic"><span class="koboSpan" id="kobo.193.1">Governing Deep Learning Models</span></em><span class="koboSpan" id="kobo.194.1">. </span><span class="koboSpan" id="kobo.194.2">With guardrail filters implemented through data characteristic thresholding, the risk of data drifting in extreme ways negatively will </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">be decreased.</span></span></p>
<p><span class="koboSpan" id="kobo.196.1">It’s important here to differentiate the two related approaches introduced that help to combat performance degradation, which are guardrail filters with thresholds and drift monitoring. </span><span class="koboSpan" id="kobo.196.2">Guardrail filters operate on a per-prediction request level and drift operates at a higher level working with a batch of predictions made in a specified time frame. </span><span class="koboSpan" id="kobo.196.3">The key mutually beneficial relationship between them is that guardrail filters aid in eliminating extreme examples known to yield inaccurate or unreliable results, thus reducing the likelihood and adverse effects of more extreme drift. </span><span class="koboSpan" id="kobo.196.4">It can still be useful to measure and monitor </span><a id="_idIndexMarker1270"/><span class="koboSpan" id="kobo.197.1">the statistics of the same data types even when extreme values are prevented through </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">guardrail filters.</span></span></p>
<p><span class="koboSpan" id="kobo.199.1">Another important aspect to consider is that deployed models can be vulnerable to various types of drift. </span><span class="koboSpan" id="kobo.199.2">Sometimes, you can reliably analyze the impact of specific characteristics on your desired metric, while in other cases, you might not be able to, even if the characteristics are measurable. </span><span class="koboSpan" id="kobo.199.3">This inability could stem from the lack of viable augmentations to simulate the characteristic or the insufficient availability of natural data examples containing the targeted characteristic. </span><span class="koboSpan" id="kobo.199.4">When you’re unable to reliably analyze the impact, you have two main options </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">to consider:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.201.1">Set up monitoring of the statistics of the chosen data characteristics without a detection component, allowing for future analysis once more data has been gathered over time. </span><span class="koboSpan" id="kobo.201.2">Alternatively, consider implementing soft alerts that prompt post-deployment analysis when extreme or unknown values emerge in the characteristic you suspect could influence </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">the model.</span></span></li>
<li><span class="koboSpan" id="kobo.203.1">Apply data distribution drift-based monitoring and detection. </span><span class="koboSpan" id="kobo.203.2">Although it is hard to predict the metric impact from distribution change, there is value in using it as a more reliable arbitrary soft alert mechanism, similar to as described in the </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">previous point.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.205.1">After crafting a detection strategy and verifying its impact, it’s time to consider how we can tackle the potential </span><a id="_idIndexMarker1271"/><span class="koboSpan" id="kobo.206.1">issues caused by drift and determine the steps to address any drift incidents </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">that arise.</span></span></p>
<h2 id="_idParaDest-249"><a id="_idTextAnchor258"/><span class="koboSpan" id="kobo.208.1">Exploring strategies to mitigate drift</span></h2>
<p><span class="koboSpan" id="kobo.209.1">This falls within the </span><a id="_idIndexMarker1272"/><span class="koboSpan" id="kobo.210.1">domain of model maintenance, where we take action to ensure our model stays on track and remains effective over time. </span><span class="koboSpan" id="kobo.210.2">Here are a few techniques that can be used to tackle </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">drift alerts:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.212.1">Retrain or fine-tune</span></strong><span class="koboSpan" id="kobo.213.1">: Regularly retrain or fine-tune the model with new data, incorporating any changes in patterns or trends. </span><span class="koboSpan" id="kobo.213.2">This will help the model adapt to evolving data dynamics and maintain </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">its accuracy.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.215.1">Prevent predictions of high-risk drift metric score ranges</span></strong><span class="koboSpan" id="kobo.216.1">: Don’t allow data that lies in a high-risk range of characteristics or range of distribution distances to be predicted. </span><span class="koboSpan" id="kobo.216.2">For example, face recognition systems should only predict frontal, unobstructed faces without masks or glasses. </span><span class="koboSpan" id="kobo.216.3">This will result in targeted prevention of drift, as the data you receive will always be in the </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">expected range.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.218.1">Manual human analysis</span></strong><span class="koboSpan" id="kobo.219.1">: This is where a human expert is involved in the decision-making process when drift alerts are triggered. </span><span class="koboSpan" id="kobo.219.2">The expert can review the situation, validate the model’s predictions in aggregate, and provide feedback to improve the model’s performance over time. </span><span class="koboSpan" id="kobo.219.3">This approach helps maintain the model’s accuracy and effectiveness while also providing valuable insights for future improvements. </span><span class="koboSpan" id="kobo.219.4">This can be useful to handle new, unseen, non-numerical data types properly, such as new words for text data or new </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">label categories.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.221.1">With proper drift impact analysis, drift detection strategy, and model maintenance flow setup, you can now ensure that your deep learning model remains robust and accurate even as the underlying data distribution evolves. </span><span class="koboSpan" id="kobo.221.2">By understanding how changes in the data can affect your model’s performance, having a strategy in place to identify and quantify drift, and establishing a clear process for model updates and maintenance, you can proactively address </span><a id="_idIndexMarker1273"/><span class="koboSpan" id="kobo.222.1">issues, maintain model reliability, and provide consistent and trustworthy results </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">over time.</span></span></p>
<p><span class="koboSpan" id="kobo.224.1">We will dive deeper into the topic of programmatic drift detection in the </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">next section.</span></span></p>
<h1 id="_idParaDest-250"><a id="_idTextAnchor259"/><span class="koboSpan" id="kobo.226.1">Detecting drift programmatically</span></h1>
<p><span class="koboSpan" id="kobo.227.1">With a comprehensive</span><a id="_idIndexMarker1274"/><span class="koboSpan" id="kobo.228.1"> understanding of drift types and their effects, we will explore techniques for detecting drift programmatically, diving into the realms of concept drift and data drift. </span><span class="koboSpan" id="kobo.228.2">Armed with these methods, you’ll be well equipped to implement high-risk drift detection components. </span><span class="koboSpan" id="kobo.228.3">Let’s start with </span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">concept drift.</span></span></p>
<h2 id="_idParaDest-251"><a id="_idTextAnchor260"/><span class="koboSpan" id="kobo.230.1">Detecting concept drift programmatically</span></h2>
<p><span class="koboSpan" id="kobo.231.1">Concept drift involves </span><a id="_idIndexMarker1275"/><span class="koboSpan" id="kobo.232.1">both the input data and the target data. </span><span class="koboSpan" id="kobo.232.2">This means that we can effectively detect concept drift for a deployed model only when we can get access to the real target labels in production. </span><span class="koboSpan" id="kobo.232.3">When you do have access to them, you can adopt the following techniques to detect </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">concept drift:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.234.1">Check the similarity of production data to the reference training data</span></strong><span class="koboSpan" id="kobo.235.1">: This should include both input and </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">output data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.237.1">Use model evaluation metrics as a proxy</span></strong><span class="koboSpan" id="kobo.238.1">: Evaluation metrics can signal concept drift or </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">data drift.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.240.1">Use multivariate-based data drift detection and include both input and target data</span></strong><span class="koboSpan" id="kobo.241.1">: This can be unreliable where detection can be data drift instead of concept drift. </span><span class="koboSpan" id="kobo.241.2">But it doesn’t change the fact that something needs to be done, so </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">it’s fine.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.243.1">Next, we will explore programmatic data </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">drift detection.</span></span></p>
<h2 id="_idParaDest-252"><a id="_idTextAnchor261"/><span class="koboSpan" id="kobo.245.1">Detecting data drift programmatically</span></h2>
<p><span class="koboSpan" id="kobo.246.1">Detecting data drift </span><a id="_idIndexMarker1276"/><span class="koboSpan" id="kobo.247.1">programmatically involves two essential steps: quantifying the type of change of data and applying a detection threshold based on reference or training data and the current data. </span><span class="koboSpan" id="kobo.247.2">For statistical-based drift, detection can be implemented with data statistical value thresholds identified during the analysis. </span><span class="koboSpan" id="kobo.247.3">However, for distribution-based data drift, it can be hard and ambiguous to define the threshold properly. </span><span class="koboSpan" id="kobo.247.4">In this section, we will focus on methods to quantify the distribution change. </span><span class="koboSpan" id="kobo.247.5">To do that, one can employ either of the </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">following methods:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.249.1">Statistical tests</span></strong><span class="koboSpan" id="kobo.250.1">: These tests are used to compare the distribution of training/reference data with the distribution of new incoming data. </span><span class="koboSpan" id="kobo.250.2">A significant divergence between the two distributions may indicate data drift. </span><strong class="bold"><span class="koboSpan" id="kobo.251.1">Evidently AI</span></strong><span class="koboSpan" id="kobo.252.1"> provides an open source tool called evidently that provides these metrics out of the box. </span><em class="italic"><span class="koboSpan" id="kobo.253.1">Table 17.1</span></em><span class="koboSpan" id="kobo.254.1"> highlights the different univariate statistical tests that can be used with details of the implementation done in </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1">evidently</span></strong><span class="koboSpan" id="kobo.256.1">, along with its pros </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">and cons:</span></span><table class="No-Table-Style _idGenTablePara-1" id="table001-3"><colgroup><col/><col/><col/><col/></colgroup><tbody><tr class="No-Table-Style"><td class="No-Table-Style"><p><strong class="bold"><span class="koboSpan" id="kobo.258.1">Statistical </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.259.1">test type</span></strong></span></p></td><td class="No-Table-Style"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.260.1">Pros</span></strong></span></p></td><td class="No-Table-Style"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.261.1">Cons</span></strong></span></p></td><td class="No-Table-Style"><p><strong class="bold"><span class="koboSpan" id="kobo.262.1">Evidently </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.263.1">implementation info</span></strong></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.264.1">Kolmogorov-</span></strong></span><strong class="bold"><span class="koboSpan" id="kobo.265.1">
Smirnov</span></strong><span class="koboSpan" id="kobo.266.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.267.1">K-S</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.268.1">) test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.269.1">Non-parametric and distribution-free, making it versatile. </span><span class="koboSpan" id="kobo.269.2">Fast to compute </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">and interpret.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.271.1">Less sensitive to differences in tails of distributions. </span><span class="koboSpan" id="kobo.271.2">Assumes continuous and </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">one-dimensional data.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.273.1">Supports: Numerical </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">data type</span></span></p><p><span class="koboSpan" id="kobo.275.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">0.05</span></span></p><p><span class="koboSpan" id="kobo.277.1">Default: For numerical data, if &lt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">1,000 samples</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.279.1">Chi-squared </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.281.1">Works well for categorical data. </span><span class="koboSpan" id="kobo.281.2">Fast to compute </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">and interpret.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.283.1">Requires data to be binned, which can be subjective. </span><span class="koboSpan" id="kobo.283.2">Assumes that observations </span><span class="No-Break"><span class="koboSpan" id="kobo.284.1">are independent.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.285.1">Supports: Categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">data type</span></span></p><p><span class="koboSpan" id="kobo.287.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">0.05</span></span></p><p><span class="koboSpan" id="kobo.289.1">Default: For categorical with &gt; 2 labels, if &lt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">1,000 samples</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break"><span class="koboSpan" id="kobo.291.1">Z-test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.292.1">Works well for large sample sizes. </span><span class="koboSpan" id="kobo.292.2">Fast to compute </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">and interpret.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.294.1">Assumes normal distribution and known population variance. </span><span class="koboSpan" id="kobo.294.2">Not suitable for small </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">sample sizes.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.296.1">Supports: Categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">data type</span></span></p><p><span class="koboSpan" id="kobo.298.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">0.05</span></span></p><p><span class="koboSpan" id="kobo.300.1">Default: For binary categorical data, if &lt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">1,000 samples</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.302.1">Anderson-Darling </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.304.1">More sensitive to differences in tails of distributions compared to the K-S test. </span><span class="koboSpan" id="kobo.304.2">Can be used for various distributions with </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">proper scaling.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.306.1">Assumes continuous data. </span><span class="koboSpan" id="kobo.306.2">Computationally more complex than the </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">K-S test.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.308.1">Supports: Numerical </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">data type</span></span></p><p><span class="koboSpan" id="kobo.310.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">0.05</span></span></p><p><span class="No-Break"><span class="koboSpan" id="kobo.312.1">Default: N/A</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.313.1">Fisher’s </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">exact test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.315.1">Accurate even with small sample sizes. </span><span class="koboSpan" id="kobo.315.2">Suitable for </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">categorical data.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.317.1">Computationally intensive, especially with large sample sizes. </span><span class="koboSpan" id="kobo.317.2">Limited to 2x2 </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">contingency tables.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.319.1">Supports: Categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">data type</span></span></p><p><span class="koboSpan" id="kobo.321.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">0.05</span></span></p><p><span class="No-Break"><span class="koboSpan" id="kobo.323.1">Default: N/A</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.324.1">Cramér-von Mises </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.326.1">Sensitive to differences in both central and tail regions of distributions. </span><span class="koboSpan" id="kobo.326.2">Non-parametric </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">and distribution-free.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.328.1">Computationally more complex than the K-S test. </span><span class="koboSpan" id="kobo.328.2">Assumes </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">continuous data.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.330.1">Supports: Numerical </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">data type</span></span></p><p><span class="koboSpan" id="kobo.332.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">0.05</span></span></p><p><span class="No-Break"><span class="koboSpan" id="kobo.334.1">Default: N/A</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.335.1">G-test (likelihood </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">ratio test)</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.337.1">Suitable for categorical data. </span><span class="koboSpan" id="kobo.337.2">Asymptotically equivalent to the </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">Chi-squared test.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.339.1">Requires large sample sizes for accurate results. </span><span class="koboSpan" id="kobo.339.2">Assumes </span><span class="No-Break"><span class="koboSpan" id="kobo.340.1">independent observations.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.341.1">Supports: Categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">data type</span></span></p><p><span class="koboSpan" id="kobo.343.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">0.05</span></span></p><p><span class="No-Break"><span class="koboSpan" id="kobo.345.1">Default: N/A</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.346.1">Epps-Singleton </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.348.1">Sensitive to differences in the shape of distributions. </span><span class="koboSpan" id="kobo.348.2">Robust </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">against outliers.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.350.1">Computationally complex. </span><span class="koboSpan" id="kobo.350.2">Assumes </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">continuous data.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.352.1">Supports: Numerical </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">data type</span></span></p><p><span class="koboSpan" id="kobo.354.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">0.05</span></span></p><p><span class="No-Break"><span class="koboSpan" id="kobo.356.1">Default: N/A</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break"><span class="koboSpan" id="kobo.357.1">T-test</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.358.1">Fast to compute and interpret. </span><span class="koboSpan" id="kobo.358.2">Applicable for comparing the means of </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">two groups.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.360.1">Assumes normal distribution and equal variance. </span><span class="koboSpan" id="kobo.360.2">Not suitable for small sample sizes when the normality assumption is </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">not met.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.362.1">Supports: Numerical </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">data type</span></span></p><p><span class="koboSpan" id="kobo.364.1">Threshold: Score &lt; </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">0.05</span></span></p><p><span class="No-Break"><span class="koboSpan" id="kobo.366.1">Default: N/A</span></span></p></td></tr></tbody></table></li>
</ul>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.367.1">Table 17.1 – Statistical tests for distribution change</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.368.1">Distance metrics</span></strong><span class="koboSpan" id="kobo.369.1">: Distance metrics can be computed between distributions. </span><em class="italic"><span class="koboSpan" id="kobo.370.1">Table 17.2</span></em><span class="koboSpan" id="kobo.371.1"> shows the</span><a id="_idIndexMarker1277"/><span class="koboSpan" id="kobo.372.1"> different distance metrics that can be used with details of the implementation done in </span><strong class="source-inline"><span class="koboSpan" id="kobo.373.1">evidently</span></strong><span class="koboSpan" id="kobo.374.1"> along with its pros </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">and cons:</span></span><table class="No-Table-Style _idGenTablePara-1" id="table002-2"><colgroup><col/><col/><col/><col/></colgroup><tbody><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.376.1">Distance metric</span></strong></span></p></td><td class="No-Table-Style"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.377.1">Pros</span></strong></span></p></td><td class="No-Table-Style"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.378.1">Cons</span></strong></span></p></td><td class="No-Table-Style"><p><strong class="bold"><span class="koboSpan" id="kobo.379.1">Evidently </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.380.1">implementation info</span></strong></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.381.1">Wasserstein </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">distance</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.383.1">Captures the geometric differences between two distributions, taking into account both the shape and location. </span><span class="koboSpan" id="kobo.383.2">Provides a natural and interpretable metric for </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">comparing distributions.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.385.1">Computationally expensive, especially for high-dimensional data. </span><span class="koboSpan" id="kobo.385.2">May not work well for discrete distributions or </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">sparse data.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.387.1">Supports: Numerical </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">data type</span></span></p><p><span class="koboSpan" id="kobo.389.1">Threshold: Distance &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">0.1</span></span></p><p><span class="koboSpan" id="kobo.391.1">Default: For numerical data, if &gt; </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">1,000 samples</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><strong class="bold"><span class="koboSpan" id="kobo.393.1">Kullback-Leibler</span></strong><span class="koboSpan" id="kobo.394.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.395.1">KL</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.396.1">) divergence</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.397.1">Quantifies the difference between two probability distributions by measuring the extra number of bits required to encode one distribution using the other. </span><span class="koboSpan" id="kobo.397.2">Works well for continuous distributions and has a strong </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">theoretical foundation.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.399.1">Asymmetric: KL(P || Q) ≠ KL(Q || P), which may affect the interpretation of the measure. </span><span class="koboSpan" id="kobo.399.2">May be infinite if the support of the two distributions does not overlap, making it less suitable for data </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">drift detection.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.401.1">Supports: Numerical and categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">data types</span></span></p><p><span class="koboSpan" id="kobo.403.1">Threshold: Distance &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">0.1</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><strong class="bold"><span class="koboSpan" id="kobo.405.1">Jensen-Shannon</span></strong><span class="koboSpan" id="kobo.406.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.407.1">JS</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">) distance</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.409.1">Symmetric measure: JS(P || Q) = JS(Q || P), making it more suitable for comparison. </span><span class="koboSpan" id="kobo.409.2">Bounded between 0 and 1, making it easier to interpret. </span><span class="koboSpan" id="kobo.409.3">Combines the strengths of KL divergence and </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1">mutual information.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.411.1">In some cases, JS distance might not be sensitive enough to detect small differences </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">between distributions.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.413.1">Supports: Numerical and categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">data type</span></span></p><p><span class="koboSpan" id="kobo.415.1">Threshold: Distance &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">0.1</span></span></p><p><span class="koboSpan" id="kobo.417.1">Default: For categorical, if &gt; </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">1,000 samples</span></span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break"><span class="koboSpan" id="kobo.419.1">Hellinger distance</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.420.1">Bounded: Produces values between 0 and 1, providing </span><span class="No-Break"><span class="koboSpan" id="kobo.421.1">easier interpretation</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.422.1">Might not be sensitive enough to detect small differences </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">between distributions.</span></span></p></td><td class="No-Table-Style"><p><span class="koboSpan" id="kobo.424.1">Supports: Numerical and categorical </span><span class="No-Break"><span class="koboSpan" id="kobo.425.1">data type</span></span></p><p><span class="koboSpan" id="kobo.426.1">Threshold: Distance &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.427.1">0.1</span></span></p></td></tr></tbody></table></li>
</ul>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.428.1">Table 17.2 – Distance metrics for data drift</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.429.1">Classification model to differentiate between the reference and the current data</span></strong><span class="koboSpan" id="kobo.430.1">: A binary threshold needs to be set. </span><span class="koboSpan" id="kobo.430.2">Although this isn’t strictly a distribution change measurement, it can be considered an approximated </span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">distribution change.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.432.1">Fortunately, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.433.1">evidently</span></strong><span class="koboSpan" id="kobo.434.1"> library </span><a id="_idIndexMarker1278"/><span class="koboSpan" id="kobo.435.1">provides all these methods out of the box with default thresholds. </span><span class="koboSpan" id="kobo.435.2">Evidently is an easy-to-use toolkit that provides metrics monitoring, data drift detection, and data drift analysis functionalities for machine </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1">learning models.</span></span></p>
<p><span class="koboSpan" id="kobo.437.1">As a follow-up to the data distribution-based drift detection topic, either of the methods introduced can be executed using either univariate or multivariate approaches. </span><span class="koboSpan" id="kobo.437.2">The choice between these approaches depends on the complexity of the data and the desired level of granularity in drift detection. </span><span class="koboSpan" id="kobo.437.3">Here are some suggestions on when to choose </span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">each method:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.439.1">Use univariate drift detection in the </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">following cases:</span></span><ul><li><span class="koboSpan" id="kobo.441.1">The relationships between individual variables are not significant or not of </span><span class="No-Break"><span class="koboSpan" id="kobo.442.1">primary concern</span></span></li><li><span class="koboSpan" id="kobo.443.1">The goal is to detect drift at a granular level, focusing on each </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">variable separately</span></span></li><li><span class="koboSpan" id="kobo.445.1">The data has a low dimensionality or a small number of variables, making it less challenging to analyze each </span><span class="No-Break"><span class="koboSpan" id="kobo.446.1">variable individually</span></span></li><li><span class="koboSpan" id="kobo.447.1">The computational resources or time available for analysis are limited, as univariate methods are generally less computationally demanding than </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1">multivariate methods</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.449.1">Use multivariate drift detection in the </span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">following cases:</span></span><ul><li><span class="koboSpan" id="kobo.451.1">The relationships between multiple variables are essential, and detecting drift in these relationships is crucial for </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">model performance</span></span></li><li><span class="koboSpan" id="kobo.453.1">The data has </span><a id="_idIndexMarker1279"/><span class="koboSpan" id="kobo.454.1">high dimensionality or many variables, making it challenging to analyze each </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">variable individually</span></span></li><li><span class="koboSpan" id="kobo.456.1">The goal is to capture a holistic view of the data drift, considering the interactions </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">between variables</span></span></li><li><span class="koboSpan" id="kobo.458.1">The computational resources and time available for analysis are sufficient, as multivariate methods can be more computationally intensive than </span><span class="No-Break"><span class="koboSpan" id="kobo.459.1">univariate methods</span></span></li><li><span class="koboSpan" id="kobo.460.1">The meaning of individual variables is not defined, for example, embeddings generated from deep </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">learning models</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.462.1">Evaluate these factors to determine the appropriate method for detecting data drift in machine </span><span class="No-Break"><span class="koboSpan" id="kobo.463.1">learning models.</span></span></p>
<p><span class="koboSpan" id="kobo.464.1">One final step is to identify the detection threshold. </span><span class="koboSpan" id="kobo.464.2">As any distribution change doesn’t necessarily mean a positive impact or negative impact, it’s hard to set a threshold through any cross-validation techniques for your dataset. </span><span class="koboSpan" id="kobo.464.3">The idea here is to set a reasonable large distribution change value that can at least cause a change in impact. </span><span class="koboSpan" id="kobo.464.4">Fortunately, if you use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.465.1">evidently</span></strong><span class="koboSpan" id="kobo.466.1"> library, it provides default thresholds that allow us to truly treat this technique as an arbitrary drift detector when you don’t have the means to analyze the </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">metric impact.</span></span></p>
<p><span class="koboSpan" id="kobo.468.1">Next, we will dive</span><a id="_idIndexMarker1280"/><span class="koboSpan" id="kobo.469.1"> into a short practical implementation of programmatic data distribution drift detection using the Python </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.470.1">evidently</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.471.1"> library.</span></span></p>
<h2 id="_idParaDest-253"><a id="_idTextAnchor262"/><span class="koboSpan" id="kobo.472.1">Implementing programmatic data distribution drift detection using evidently</span></h2>
<p><span class="koboSpan" id="kobo.473.1">One thing you are </span><a id="_idIndexMarker1281"/><span class="koboSpan" id="kobo.474.1">probably</span><a id="_idIndexMarker1282"/><span class="koboSpan" id="kobo.475.1"> curious about is whether the absolute magnitude of distribution matters in distribution drift computation. </span><span class="koboSpan" id="kobo.475.2">In this section, we will explore a short tutorial on using evidently that demonstrates </span><span class="No-Break"><span class="koboSpan" id="kobo.476.1">three things:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.477.1">Absolute magnitude matters as well in distribution drift measurements along with </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">relative magnitude</span></span></li>
<li><span class="koboSpan" id="kobo.479.1">A detected distribution drift or a highly drifted score doesn’t necessarily result in </span><span class="No-Break"><span class="koboSpan" id="kobo.480.1">degraded performance</span></span></li>
<li><span class="koboSpan" id="kobo.481.1">Distribution drift alignment with a drop in </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1">metric performance</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.483.1">The tutorial will be based on the same model, dataset, and dataset characteristic used in the </span><em class="italic"><span class="koboSpan" id="kobo.484.1">Executing adversarial performance analysis for speech recognition models</span></em><span class="koboSpan" id="kobo.485.1"> section in </span><a href="B18187_14.xhtml#_idTextAnchor206"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.486.1">Chapter 14</span></em></span></a><span class="koboSpan" id="kobo.487.1">, </span><em class="italic"><span class="koboSpan" id="kobo.488.1">Analyzing Adversarial Performance</span></em><span class="koboSpan" id="kobo.489.1">, which is about speech recognition. </span><span class="koboSpan" id="kobo.489.2">Let’s dive into it in a </span><span class="No-Break"><span class="koboSpan" id="kobo.490.1">step-by-step manner:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.491.1">First, we will import the </span><span class="No-Break"><span class="koboSpan" id="kobo.492.1">necessary libraries:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.493.1">
import evaluate
import numpy as np
import pandas as pd
import syllables
import torch
from audiomentations import TimeStretch
from datasets import load_dataset
from evidently.metric_preset import DataDriftPreset
from evidently.metrics import ColumnSummaryMetric
from evidently.metrics import DataDriftTable
from evidently.report import Report
from tqdm import tqdm_notebook
from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration</span></pre></li> <li><span class="koboSpan" id="kobo.494.1">Next, we will load the dataset and the speech recognition model in </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">the GPU:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.496.1">
ds = load_dataset("google/fleurs", 'en_us', split="validation")
device = torch.device("cuda")
model = Speech2TextForConditionalGeneration.from_pretrained("facebook/s2t-small-librispeech-asr")
processor = Speech2TextProcessor.from_pretrained("facebook/s2t-small-librispeech-asr")
model.to(device)</span></pre></li> <li><span class="koboSpan" id="kobo.497.1">We will be</span><a id="_idIndexMarker1283"/><span class="koboSpan" id="kobo.498.1"> using</span><a id="_idIndexMarker1284"/><span class="koboSpan" id="kobo.499.1"> the word error rate performance metric here, so let’s use the method from the Hugging Face </span><strong class="source-inline"><span class="koboSpan" id="kobo.500.1">evaluate</span></strong><span class="koboSpan" id="kobo.501.1"> library along with the method to compute and return a list of the </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">metric scores:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.503.1">
wer = evaluate.load("wer")
def get_wer_scores(dataset, transcriptions=None, sampling_rates=None, is_hg_ds=False, verbose=True):
  all_wer_score = []
  for idx, audio_data in tqdm_notebook(enumerate(dataset), total=len(dataset), disable=not verbose):
     inputs = processor(
        audio_data["audio"]["array"] if is_hg_ds else audio_data, sampling_rate=audio_data["audio"]["sampling_rate"] if is_hg_ds else sampling_rates[idx], return_tensors="pt")
     generated_ids = model.generate(
        inputs["input_features"].to(device), attention_mask=inputs["attention_mask"].to(device))
     transcription = processor.batch_decode(
generated_ids, skip_special_tokens=True)
     wer_score = wer.compute(predictions=transcription, references=[audio_data['transcription'] if is_hg_ds else transcriptions[idx]])
     all_wer_score.append(wer_score)
     return np.array(all_wer_score)</span></pre></li> <li><span class="koboSpan" id="kobo.504.1">We will be using a</span><a id="_idIndexMarker1285"/><span class="koboSpan" id="kobo.505.1"> known</span><a id="_idIndexMarker1286"/><span class="koboSpan" id="kobo.506.1"> characteristic that affects the metric performance of the model, can be controlled through augmentation, and can be measured, which is syllables per second. </span><span class="koboSpan" id="kobo.506.2">Let’s define the method that gets the augmented results and calls the method to compute the </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">metric scores:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.508.1">
def get_augmented_samples_wer_results(all_baseline_samples, transcriptions, all_sampling_rates, rates_to_change):
     all_augmented_samples = []
     for idx, audio_sample in enumerate(all_baseline_samples):
        if rates_to_change[idx] != 0:
           augment = TimeStretch(min_rate=rates_to_change[idx], max_rate=rates_to_change[idx], p=1.0)
           augmented_samples = augment(samples=audio_sample, sample_rate=all_sampling_rates[idx])
           all_augmented_samples.append(
augmented_samples)
        else:
           all_augmented_samples.append(audio_sample)
           wer_scores = get_wer_scores( all_augmented_samples, transcriptions, sampling_rates=all_sampling_rates, is_hg_ds=False)
     return wer_scores, all_augmented_samples</span></pre></li> <li><span class="koboSpan" id="kobo.509.1">To properly</span><a id="_idIndexMarker1287"/><span class="koboSpan" id="kobo.510.1"> demonstrate</span><a id="_idIndexMarker1288"/><span class="koboSpan" id="kobo.511.1"> the behavior of performance improvements even when drift is detected, we will use a modified version of the dataset as the reference baseline. </span><span class="koboSpan" id="kobo.511.2">Let’s obtain it by first extracting the original </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">dataset info:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.513.1">
all_syllables_per_second = []
original_dataset = []
all_sampling_rates = []
transcriptions = []
     for audio_data in ds:
     num_syllables = syllables.estimate(audio_data['transcription'])
     syllables_per_second = num_syllables / (audio_data['num_samples'] / audio_data['audio']['sampling_rate'])
     all_syllables_per_second.append(
syllables_per_second)
     original_dataset.append(audio_data['audio']['array'])
     all_sampling_rates.append(audio_data['audio']['sampling_rate'])
     transcriptions.append(
audio_data['transcription'])</span></pre></li> <li><span class="koboSpan" id="kobo.514.1">Next, we obtain the audio dataset that is expanded three times its original duration and </span><a id="_idIndexMarker1289"/><span class="koboSpan" id="kobo.515.1">prepare </span><a id="_idIndexMarker1290"/><span class="koboSpan" id="kobo.516.1">the DataFrame compatible with </span><strong class="source-inline"><span class="koboSpan" id="kobo.517.1">evidently</span></strong><span class="koboSpan" id="kobo.518.1"> library processing, which effectively reduces the syllables per second by </span><span class="No-Break"><span class="koboSpan" id="kobo.519.1">three times:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.520.1">
reference_wer_scores, reference_samples = get_augmented_samples_wer_results(original_dataset, transcriptions, all_sampling_rates, rates_to_change=[3] * len(original_dataset)
)
reference_df = pd.DataFrame({
  "wer_score": reference_wer_scores,
  "syllables_per_second": [sps / 3.0 for sps in all_syllables_per_second]})</span></pre></li> <li><span class="koboSpan" id="kobo.521.1">Now that we have a reference dataset, we need a current dataset that simulates new data that we receive with a deployed model. </span><span class="koboSpan" id="kobo.521.2">We will modify 90% of the reference dataset to 10 syllables per second to show a more extreme case of distribution change from normal to highly </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">skewed distribution:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.523.1">
majority_number = int(len(reference_samples) * 0.9)
minority_number = len(reference_samples) - majority_number
majority_rates = []
for i in range(majority_number):
     majority_rates.append(10.0 / all_syllables_per_second[i])
     current_wer_scores, current_samples = get_augmented_samples_wer_results(reference_samples, transcriptions, all_sampling_rates, rates_to_change=majority_rates + [0] * minority_number)
reference_syllables_per_second = reference_df[
  'syllables_per_second'].values.tolist()
current_df = pd.DataFrame({
  "wer_score": current_wer_scores,
  "syllables_per_second": [10] * majority_number + reference_syllables_per_second[-minority_number:]})</span></pre></li> <li><span class="koboSpan" id="kobo.524.1">Now that we have both </span><a id="_idIndexMarker1291"/><span class="koboSpan" id="kobo.525.1">a </span><a id="_idIndexMarker1292"/><span class="koboSpan" id="kobo.526.1">reference dataset and a current dataset, let’s obtain the data </span><span class="No-Break"><span class="koboSpan" id="kobo.527.1">drift report:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.528.1">
data_drift_dataset_report = Report(metrics=[
  DataDriftTable(columns=["syllables_per_second"]),
  ColumnSummaryMetric(column_name="wer_score")])
data_drift_dataset_report.run(reference_data=reference_df, current_data=current_df)
data_drift_dataset_report.show(mode='inline')</span></pre></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer145">
<span class="koboSpan" id="kobo.529.1"><img alt="Figure 17.2 – Data drift report by evidently" src="image/B18187_17_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.530.1">Figure 17.2 – Data drift report by evidently</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.531.1">Remember that</span><a id="_idIndexMarker1293"/><span class="koboSpan" id="kobo.532.1"> the </span><a id="_idIndexMarker1294"/><span class="koboSpan" id="kobo.533.1">default K-S test is used when the dataset has less than 1,000 columns, which reflects what was used here. </span><span class="koboSpan" id="kobo.533.2">Drift was detected with a 0.05 threshold and the metric performance dropped significantly; this is the </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">ideal situation.</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.535.1">Next, we’ll create a simulation in which the number of syllables pronounced per second is tripled compared to the current data. </span><span class="koboSpan" id="kobo.535.2">We’ll use the original dataset for this and get the </span><strong class="source-inline"><span class="koboSpan" id="kobo.536.1">evidently</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.537.1">drift report:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.538.1">
wer_scores = get_wer_scores(original_dataset, transcriptions, sampling_rates=all_sampling_rates, is_hg_ds=False)
current_df = pd.DataFrame({"wer_score": wer_scores,
  "syllables_per_second":all_syllables_per_second})
data_drift_dataset_report = Report(metrics=[
  DataDriftTable(columns=["syllables_per_second"]),
  ColumnSummaryMetric(column_name="wer_score")])
data_drift_dataset_report.run(reference_data=reference_df, current_data=current_df)
data_drift_dataset_report.show(mode='inline')</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.539.1">This will result in </span><a id="_idIndexMarker1295"/><span class="koboSpan" id="kobo.540.1">the </span><a id="_idIndexMarker1296"/><span class="koboSpan" id="kobo.541.1">report shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.542.1">Figure 17</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.543.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.544.1">:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer146">
<span class="koboSpan" id="kobo.545.1"><img alt="Figure 17.3 – Evidently report with same distribution but different magnitude still detected drift" src="image/B18187_17_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.546.1">Figure 17.3 – Evidently report with same distribution but different magnitude still detected drift</span></p>
<p><span class="koboSpan" id="kobo.547.1">Here, the distribution pattern is visibly the same, but the absolute magnitude of each group of syllables per second is much higher. </span><span class="koboSpan" id="kobo.547.2">The K-S test still managed to detect this as drift as it uses cumulative distribution difference, showcasing the versatility of distribution drift methods. </span><span class="koboSpan" id="kobo.547.3">With that, we have completed the tutorial! </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">evidently</span></strong><span class="koboSpan" id="kobo.549.1"> offers a broader range of metrics for measurement, including data quality statistics and model evaluation metrics. </span><span class="koboSpan" id="kobo.549.2">It also includes built-in support for monitoring data drift and detecting data types such as embeddings and text. </span><span class="koboSpan" id="kobo.549.3">Be sure to explore these features separately. </span><span class="koboSpan" id="kobo.549.4">Additionally, consider diving into each of the methods in detail to discover new behaviors of distribution drift techniques that you never thought </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">were possible.</span></span></p>
<p><span class="koboSpan" id="kobo.551.1">Other than</span><a id="_idIndexMarker1297"/><span class="koboSpan" id="kobo.552.1"> Evidently, there</span><a id="_idIndexMarker1298"/><span class="koboSpan" id="kobo.553.1"> is one more notable open source library that you can use to handle drift programmatically, which is part of what we will </span><span class="No-Break"><span class="koboSpan" id="kobo.554.1">discover next.</span></span></p>
<h2 id="_idParaDest-254"><a id="_idTextAnchor263"/><span class="koboSpan" id="kobo.555.1">Comparing and contrasting the Evidently and Alibi-Detect libraries for drift detection</span></h2>
<p><span class="koboSpan" id="kobo.556.1">In this section, we </span><a id="_idIndexMarker1299"/><span class="koboSpan" id="kobo.557.1">will compare </span><a id="_idIndexMarker1300"/><span class="koboSpan" id="kobo.558.1">and contrast two popular libraries for drift detection in deep </span><a id="_idIndexMarker1301"/><span class="koboSpan" id="kobo.559.1">learning models: Evidently and Alibi-Detect. </span><span class="koboSpan" id="kobo.559.2">Both libraries provide tools for monitoring and detecting drift in data, but they differ in terms of their features. </span><span class="koboSpan" id="kobo.559.3">By understanding the strengths and weaknesses of each library, you can choose the one that best suits your needs and requirements for drift detection in your deep </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1">learning models.</span></span></p>
<p><span class="koboSpan" id="kobo.561.1">Evidently has the </span><span class="No-Break"><span class="koboSpan" id="kobo.562.1">following characteristics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.563.1">Provides an easy-to-use toolkit for monitoring data drift, including built-in support for various data types such as embeddings </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">and text</span></span></li>
<li><span class="koboSpan" id="kobo.565.1">Offers a comprehensive set of metrics for measuring drift, including statistical tests, distance metrics, and </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">classification models</span></span></li>
<li><span class="koboSpan" id="kobo.567.1">Supports both univariate and multivariate drift detection methods, allowing for flexibility in handling different types of data and </span><span class="No-Break"><span class="koboSpan" id="kobo.568.1">use cases</span></span></li>
<li><span class="koboSpan" id="kobo.569.1">Offers a simple and intuitive interface for generating drift detection reports </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">and visualizations</span></span></li>
<li><span class="koboSpan" id="kobo.571.1">Supports general evaluation metrics and data </span><span class="No-Break"><span class="koboSpan" id="kobo.572.1">quality metrics</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.573.1">Alibi-Detect, on the other hand, has the </span><span class="No-Break"><span class="koboSpan" id="kobo.574.1">following characteristics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.575.1">A Python library that includes a wide range of drift detection, outlier detection, and adversarial </span><span class="No-Break"><span class="koboSpan" id="kobo.576.1">detection techniques</span></span></li>
<li><span class="koboSpan" id="kobo.577.1">Supports both online and offline detectors for tabular data, text, images, and </span><span class="No-Break"><span class="koboSpan" id="kobo.578.1">time series</span></span></li>
<li><span class="koboSpan" id="kobo.579.1">Claims to support TensorFlow and PyTorch models out of </span><span class="No-Break"><span class="koboSpan" id="kobo.580.1">the box</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.581.1">Both Evidently and Alibi-Detect are powerful libraries for drift detection in deep learning models. </span><span class="koboSpan" id="kobo.581.2">Depending on your specific needs and requirements, you can choose either Evidently or Alibi-Detect as your preferred library for drift detection in deep learning models. </span><span class="koboSpan" id="kobo.581.3">Under typical</span><a id="_idIndexMarker1302"/><span class="koboSpan" id="kobo.582.1"> conditions, Evidently </span><a id="_idIndexMarker1303"/><span class="koboSpan" id="kobo.583.1">can serve as the de facto library. </span><span class="koboSpan" id="kobo.583.2">However, as </span><a id="_idIndexMarker1304"/><span class="koboSpan" id="kobo.584.1">of the time of writing this book, if you’re dealing with non-tabular data without available embedding models, require outlier detection, or need a statistical test that Evidently doesn’t offer, Alibi-Detect is a more </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">suitable choice.</span></span></p>
<h1 id="_idParaDest-255"><a id="_idTextAnchor264"/><span class="koboSpan" id="kobo.586.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.587.1">In this chapter, we explored the concept of drift, which affects the performance of deployed deep learning models over time. </span><span class="koboSpan" id="kobo.587.2">We covered the three types of drift – concept drift, data drift, and model drift – and discussed strategies to handle them effectively. </span><span class="koboSpan" id="kobo.587.3">This included strategies to approach drift, including automatic programmatic detection and manual domain expert predictions, strategies to quantify drift, and strategies to mitigate drift effectively. </span><span class="koboSpan" id="kobo.587.4">We learned that statistical-based drift should always be opted for over ambiguous data distribution drift. </span><span class="koboSpan" id="kobo.587.5">We also learned that monitoring drift by batch in regular intervals is crucial in ensuring the continued success of deep learning models. </span><span class="koboSpan" id="kobo.587.6">Finally, using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.588.1">evidently</span></strong><span class="koboSpan" id="kobo.589.1"> library, we demonstrated how to implement programmatic data distribution drift detection in a practical tutorial and understood behaviors that can shape how you think of data distribution drift methods. </span><span class="koboSpan" id="kobo.589.2">This knowledge can be applied across various industries and applications, such as healthcare, finance, retail, and manufacturing, where maintaining the accuracy and performance of deep learning models is crucial for efficient decision-making and optimizing </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">business processes.</span></span></p>
<p><span class="koboSpan" id="kobo.591.1">This chapter marks the completion of our deep dive into every component of the deep learning life cycle. </span><span class="koboSpan" id="kobo.591.2">In the next chapter, we will explore how a paid-for platform called DataRobot covers crucial components of the deep learning life cycle in an easy-to-use </span><span class="No-Break"><span class="koboSpan" id="kobo.592.1">user interface.</span></span></p>
</div>
</body></html>