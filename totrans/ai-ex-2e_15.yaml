- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting Up a Cognitive NLP UI/CUI Chatbot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are 300,000+ chatbots on Facebook alone. Adding another brick in that
    wall means next to nothing unless you give your chatbot a purpose and provide
    it with real content. Cognitive content represents the core goal of attracting
    more attention than your hundreds of thousands of competitors and SEO experts.
    We will put RBM-PCA chained algorithms to work in this chapter to bring a chatbot
    to another level. We will use the information provided by the RBM-PCA to design
    our dialog.
  prefs: []
  type: TYPE_NORMAL
- en: As you will discover in this first section, creating an agent with Dialogflow
    and beginning a dialog represents no effort at all. Google Dialogflow provides
    the intuitive features to get a chatbot running in no time. The Dialogflow tutorial
    can guide you to reach this simple goal in a few minutes. Understanding what an agent
    is, teaching it to ask a question, and providing an answer can be done by a 10-year-old
    child. I experimented with this by letting a 5-year-old and a 9-year-old child
    loose on this software. They both did not even realize it was work. They were
    having fun!
  prefs: []
  type: TYPE_NORMAL
- en: On Dialogflow, you don't need to know how to program, and you don't need to
    be a linguist or any other kind of expert. So, what will your market differentiation
    be? *Content*. Your chatbot needs to have a purpose, with well-prepared content
    beyond asking and answering simple questions.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond creating your first dialog, the goal of this chapter will provide you
    with a sense of purpose and content that will help you produce meaningful chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, let's create an agent together and a short dialog to illustrate
    both how to create a chatbot and also to provide meaningful content.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a cognitive agent based on the preparation of *Chapter 14*, *Preparing
    the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal
    Component Analysis (PCA)*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning the basic concepts of Dialogflow and chatbots in general
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the chatbot on your website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start with basic concepts and then create an agent with entities, intents,
    dialogs, and a fulfillment function. We will be using the preparation established
    in the previous chapter. We will test its UI with spelling correction and dialogs.
    Then, we will test the chatbot's **conversational user interface** (**CUI**) capability
    by setting up machine learning speech recognition and speech functions.
  prefs: []
  type: TYPE_NORMAL
- en: Basic concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before creating an agent, we'll want to have an understanding of the basic concepts.
  prefs: []
  type: TYPE_NORMAL
- en: This is not a Dialogflow course, but rather an introductory chapter to get us
    started on making our own NLP CUI chatbot. We'll begin by defining some key terms.
  prefs: []
  type: TYPE_NORMAL
- en: Defining NLU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**NLU** means **natural language understanding**. NLU is a subset of **natural
    language processing** (**NLP**). Natural language refers to the everyday language
    we use without having to force ourselves to learn precise words in order to obtain
    information from a machine.'
  prefs: []
  type: TYPE_NORMAL
- en: If we had to learn a dictionary of the only words that would work with a system,
    it would be easier just to read a text. NLP encompasses all forms of natural language
    processing including NLU. Through AI, NLU has become more involved in trying to understand
    what a given sentence means.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we call chatbots "agents"?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A chatbot entails a chat between at least two parties. In our case, the bot
    is an NLU module. That''s not a very nice marketing way to put it. It sounds like:
    "you are now talking to an NLU module." You cannot pretend a bot is a person.
    The word *agent* conveys the impression of a business agent, a sports agent, or
    a secret agent, which is mysterious! It came to mean a computer system that gathers
    information. Now it''s an NLP agent with NLU capability.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an agent to understand Dialogflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The fastest way to learn Dialogflow is to create a dialog from scratch. Log
    into Dialogflow and go to the console. The following is part of a screenshot of
    Dialogflow''s dashboard. You can see the link to the console on the top right:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.1: Accessing Dialogflow''s console'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you click on **Go to console**, you will be asked to sign in if you haven''t
    signed in yet. A Google account is a prerequisite:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.2: Signing in with a Google account'
  prefs: []
  type: TYPE_NORMAL
- en: Once you have followed the sign in instructions and are signed in, you will
    reach the Dialogflow console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the drop-down list in the top-right corner, irrespective of which
    default agent is displayed. A list of existing or default agents will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.3: The list of agents'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scroll down the list until you reach **Create new agent** (if none, click on
    the **Create agent** option). Click on **Create new agent**, and you will reach
    the following window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.4: Entering the agent''s name'
  prefs: []
  type: TYPE_NORMAL
- en: Call the agent `Agent + <your name or initials>` to make sure you will have
    a unique name. I will call the one for this chapter `cogfilmdr`. The agent in
    the chapter will thus be referred to as `cogfilmdr`. Let Google create a default
    agent structure with English as the main language.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once that is done, click on the settings button in the top left:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.5: The settings button'
  prefs: []
  type: TYPE_NORMAL
- en: You will reach the configuration window of your agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the moment, we just have one important option to check. The version of
    the API must be V2 API. V1 API will shut down on March 2020:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.6: Using the V2 API'
  prefs: []
  type: TYPE_NORMAL
- en: The agent is now created, and we can create entities.
  prefs: []
  type: TYPE_NORMAL
- en: Entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most chatbot tutorials explain intents first. I do not agree. Once you know
    where you're going, in this case, choosing a movie based on *Chapter 14*, *Preparing
    the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal
    Component Analysis (PCA)*, it makes sense to build some bricks before building
    your structure.
  prefs: []
  type: TYPE_NORMAL
- en: Dialogflow (or any chatbot) uses entities to extract useful information in a
    user's utterance (not necessarily a sentence) to understand their motivation.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the entities created in *Chapter 14*. We will first create an entity
    named `movies` that will contain the 10 target movies used in *Chapter 14*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Click on **Entities** on the left-hand side of the window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.7: Dialogflow menu'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on **CREATE ENTITY**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.8: Creating an entity'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be asked to provide an entity name:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.9: Entering the name of entity'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter `movies`. Before saving the entity, we must enter the movies we have
    chosen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.10: Entity list'
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that once you add a movie, a default synonym is filled in automatically.
    You can add other synonyms if you wish.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the titles are entered, click on the **SAVE** button, which is mandatory
    (it is not an auto-save interface):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.11: Saving an entity'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now create the feature entity. The features in the `RBM.py` program
    in *Chapter 14* were as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will name it `features`, follow the same process as for the `movies` entity,
    and then click on **SAVE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.12: Creating a feature entity'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Entities** under your agent, and you will see a list of entities
    for the agent, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.13: List of entities'
  prefs: []
  type: TYPE_NORMAL
- en: If you click an entity, a list of possible choices will appear.
  prefs: []
  type: TYPE_NORMAL
- en: Now that your agent knows the movie and feature entities, creating the intents
    makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: Intents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An intent is a clear formulation intention to do something. I named the agent
    `cogfilmdr`. For the agent, the user's intention may be to ask for a movie to
    watch.
  prefs: []
  type: TYPE_NORMAL
- en: To trigger a response, we must enter training phrases.
  prefs: []
  type: TYPE_NORMAL
- en: '**Training phrases** are groups of words that the user will enter through text
    or speech. The more sentences you enter, the better your chatbot will become.
    This is why starting with a ready-to-use Dialogflow makes sense if an existing
    agent satisfies your needs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create our sample dialog, we will use the dataset results supplied on GitHub
    for *Chapter 14*, *Preparing the Input of Chatbots with Restricted Boltzmann Machines
    (RBMs) and Principal Component Analysis (PCA)*. The main terms have been extracted
    with their features that we displayed with TensorBoard. When we extracted the
    data from the RBM, we sorted the features as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We displayed the feature space in a PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.14: TensorBoard representation of features'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reminder**: This result will naturally change if `RBM_launcher.py` runs again
    since it''s a random viewer-movie choice process.'
  prefs: []
  type: TYPE_NORMAL
- en: When starting a chatbot project, it is best to be very careful with going straight
    to generating dialogs automatically. It is much better to start with a simple,
    well-structured chatbot that works on a limited amount of tasks. I call this a
    "closed chatbot" meaning that we control every aspect of dialog. An "open chatbot"
    means that information flows in automatically to create automatic dialogs. That
    can be a goal after getting the chatbot to run as a "closed chatbot" for some
    time using the information prepared with AI algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The results of the work we did in *Chapter 14* provide interesting information
    on the marketing segment we are targeting for the chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: Violence and action point to action movies. Family=0 points to younger viewers,
    teenagers, for example, more interested in action than creating a family. Discovering
    happiness and love is part of the horizons they are looking for. This is typical
    of superhero series and movies. Superheroes are often solitary individuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now create an intent by entering the **Intents** window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.15: Choosing the Intents option'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Intents** window appears. Click on **CREATE INTENT**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.16: Creating an intent'
  prefs: []
  type: TYPE_NORMAL
- en: 'The intent window will appear to create a question-and-answer dialog in a few
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, enter `choose_movie` as the name of the intent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, in the training phrases section, enter: "I would like to watch one of
    your movies."'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At this point, we have an intent name and a possible user question:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.17: Entering intent information'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to provide a response based on the statistics for this market
    segment we drew from *Chapter 14*. We will use the word *action* to encompass
    a movie that contains violence and a happy ending as in the typical superhero
    movies. To do that, scroll down to the **Text Response** section to add a response
    and enter "Would you like to watch an action movie?", as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.18: Entering the text response'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a basic dialog, let''s save and test it. To do that, go to
    the test console in the top right of the console window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.19: Test console'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use a CUI or text:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Text dialog**: Enter the user phrase: "I would like to watch one of your
    movies."'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user will be surprised to see the agent's answer, which is, "Would you like
    to watch an action movie?"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B15438_15_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.20: Responses'
  prefs: []
  type: TYPE_NORMAL
- en: This suggestion comes as a surprise for the user and might seem strange. This
    is because the RBM-PCA approach we used to prepare the dialog targets a market
    segment.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced machine learning shortens the path of a user request to a satisfactory
    response. It constitutes both a time saving and an energy saving process for the
    user.
  prefs: []
  type: TYPE_NORMAL
- en: '**CUI**: Click on the microphone icon in the test console. Make sure that this
    microphone is authorized, or it will not work:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B15438_15_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.21: Microphone'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you click on the microphone, this will trigger a recording of your request.
    Say, "I would like to watch one of your movies." Then, click on the stop button
    to stop the recording. The response to the request will appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.22: Text responses'
  prefs: []
  type: TYPE_NORMAL
- en: To answer the question, we will need to use the context functionality of Dialogflow.
  prefs: []
  type: TYPE_NORMAL
- en: Context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Context means that Dialogflow is going to remember a dialog and use follow-up
    exchanges without starting from scratch each time.
  prefs: []
  type: TYPE_NORMAL
- en: The user has asked to watch a movie, and the bot suggested an action movie.
    The bot will remember this through context as it continues the dialog.
  prefs: []
  type: TYPE_NORMAL
- en: Click on the agent's **Intent** in the menu and hover over **choose_movie**.
    You will see **Add follow-up intent** appear. This means that all of the variables
    of the main intent can be stored, and a follow-up intent added that would remember
    what was said previously, just like us in a conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Add follow-up intent**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.23: Add follow-up intent button'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the agent has planned two cases, *yes* or *no*. We will explore
    the *yes* answers in this chapter, and the more complex *no* answers in *Chapter
    16*, *Improving the Emotional Intelligence Deficiencies of Chatbots*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Chapter 14*, we created a movie feature matrix with the movie titles and
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We now need to transpose this information in a chart we can use to add content
    depth to the dialog:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **MOVIE/FEATURE** | LOVE | HAPPINESS | FAMILY | HORIZONS | ACTION | VIOLENCE
    |'
  prefs: []
  type: TYPE_TB
- en: '| 24H in Kamba | 1 | 1 | 0 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Lost | 1 | 1 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Cube Adventures | 1 | 0 | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| A Holiday | 1 | 1 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Jonathan Brooks | 1 | 0 | 0 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| The Melbourne File | 1 | 1 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| WNC Detectives | 1 | 0 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Stars | 1 | 1 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Space L | 1 | 1 | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Zone 77 | 1 | 0 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: We have already surprised the user a bit by proposing an action movie directly
    without going through tedious lists. We are using all of the information we obtained through
    inputs, intermediate AI outputs, and final outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are going even further by filtering the movies that fit the action-violence-happiness
    features extracted with the RBM-PCA chained algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Only the following movies in the chart match action-violence-happiness:'
  prefs: []
  type: TYPE_NORMAL
- en: 24H in Kamba
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Holiday
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zone 77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At random, we will choose "Zone 77." Once we have entered many possibilities,
    a random choice can be suggested either in the response area or with scripts.
    This development is beyond the scope of this chapter. For this example, we suppose
    it is probable that the viewer will be satisfied with this suggestion we make.
    We are in a *yes* scenario of the dialog. In *Chapter 16*, *Improving the Emotional
    Intelligence Deficiencies of Chatbots*, we will explore the *no* scenarios of
    this dialog, which requires more cognitive designing to keep the satisfaction
    path short.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the moment, let''s suggest "Zone 77." To do this:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Add follow-up intent**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **yes**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You now have a follow-up intent linked to the dialog:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.24: Follow-up intents'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **choose_movie - yes**. The intent will appear. You will notice that
    Dialogflow has already filled in several forms of *yes* in the **Training phrases**
    section, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.25: Training phrases'
  prefs: []
  type: TYPE_NORMAL
- en: 'All that is left to do in this scenario is to scroll down to the **Responses**
    section and add our answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.26: Text response'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we go back to the intent and add a *yes* follow-up to this follow-up to
    process the viewer''s *yes* answer, just as we did previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.27: Follow-up intents'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we click on **choose_movie - yes - yes**, and we will see the *yes* answers
    that Dialogflow prepared for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.28: Training phrases for a follow-up intent'
  prefs: []
  type: TYPE_NORMAL
- en: However, this time, we would like to answer with a script and not an answer
    we type in.
  prefs: []
  type: TYPE_NORMAL
- en: To do that, we can use fulfillment.
  prefs: []
  type: TYPE_NORMAL
- en: Adding fulfillment functionality to an agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A dialog can quickly become boring in everyday life and even more so in a chatbot.
    When we begin to guess everything that an interlocutor has to say, our mind slowly
    drifts away. We cannot help it. Humans are a curious species. **Fulfillment**
    will change the perspective of dialog. That is what I call *purpose* beyond the
    pragmatic approach that says fulfillment adds business logic to a dialog.
  prefs: []
  type: TYPE_NORMAL
- en: To make the dialog sustainable, even from a practical point of view, it has
    to excite the user enough to want it to come back and discover more about your
    chatbot beyond obtaining business information from it.
  prefs: []
  type: TYPE_NORMAL
- en: If you look **fulfilling** up in a dictionary, you will find that it means providing
    happiness or satisfaction, which is exactly the feeling of purpose you want your
    chatbot to convey.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, there is work to do in order to reach that goal. Dialogflow
    provides a wide array of tools to reach fulfillment for the user, the designer,
    and the developers.
  prefs: []
  type: TYPE_NORMAL
- en: To start with, Dialogflow uses an inbuilt, seamless version of Node.js for fulfilling
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Defining fulfillment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Various fulfillment or additional dialog functions are available:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Webhook**: A webhook is an event transmitted via HTTP. It is sent as a `POST`,
    which contains data posted to a predetermined URL. It works as an HTTP callback.
    The data sent to the URL will be parsed by a script on the server side. Once the
    service has processed the information, it will perform an action and send data
    back as a response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will not use the webhook for this example. However, it is important to note
    that you can use a webhook to create dialogs of your own in another environment.
    You can even generate automatic dialogs and call them from Dialogflow.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you are interested in preparing dialogs and uploading them, you can go to the
    **Training** page of the agent on the left-hand side of the screen and upload
    phrases:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B15438_15_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.29: Training window'
  prefs: []
  type: TYPE_NORMAL
- en: You can also upload an agent or even a prebuilt agent designed by Google Dialogflow.
    For our example, we will use the inline editor.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fulfillment with the inline Node.js editor**: Defining a webhook URL can
    be the simplest approach. However, using the inline editor provides Node.js functionality
    for even more potential.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fulfillment with the inline Node.js editor and Cloud Functions for Firebase**:
    The inline Node.js can call a large variety of Cloud Functions for Firebase in
    a few time-saving lines of code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhancing the cogfilmdr agent with a fulfillment webhook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the user answers *yes* to watch "Zone 77," we can answer with a response
    or a link to a website. To use a response, go to the yes - yes follow-up of our
    dialog in the **Intents** window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.30: Intents and follow-up intents'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **choose_movie - yes - yes** and scroll down to **Text Response**
    and add a response such as "Sure, click on the movie and watch it," as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.31: Text response'
  prefs: []
  type: TYPE_NORMAL
- en: 'We would also decide that this is final and that it is the end of the conversation
    by activating the **Set this intent as end of conversation** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.32: End of conversation option'
  prefs: []
  type: TYPE_NORMAL
- en: 'But we will not do this for the moment; let''s scroll down further to activate
    the inline webhook functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.33: Enabling the webhook functionality'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will go to the **Fulfillment** window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.34: Access to the Fulfillment interface'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, enable the inline editor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.35: Inline editor'
  prefs: []
  type: TYPE_NORMAL
- en: To add some fun to the dialog, let's suppose that chatbot is in a cool start-up
    coffee shop and that watching movies on individual screens is a service to attract
    customers. You can watch the movie with headsets (you, friends, family), for example.
    We add this service to our dialog.
  prefs: []
  type: TYPE_NORMAL
- en: 'We go to the `intentMap` of the script and add a `gotomovie` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The recommended format is `intentMap.set(<Intent>,<function>)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'That done, we now write the function with our own text and website link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: All we have to do now is click on **DEPLOY**, and that's it!
  prefs: []
  type: TYPE_NORMAL
- en: I added a link to Amazon Prime Video to show that you can use IBM Watson, Google,
    Microsoft, Amazon services, and more to enhance your chatbots!
  prefs: []
  type: TYPE_NORMAL
- en: '**Important**: You can customize all the dialogs you wish in this editor and
    use a range of Google Cloud functions. The sky is not even the limit. You can
    go to Mars!'
  prefs: []
  type: TYPE_NORMAL
- en: For our example, once the script has been deployed, we go back to the beginning
    of our dialog until we reach this point, which will take us to the movie we wish
    to watch. In this case, I just displayed a streaming site.
  prefs: []
  type: TYPE_NORMAL
- en: You can obtain the full script of `index.js` in the `dialogflowFulfillment.zip`
    on GitHub in `CH15` and copy it into the editor without importing the whole package.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the bot to work on your website
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's get a bot running on your website in a few clicks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scroll down to **Integrations** for the agent you wish to deploy: either your
    own agent or the coffee shop agent.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Activate the **Web Demo** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An embedded code will appear along the lines of the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Copy the code on the page of the website you wish to implement it on.
  prefs: []
  type: TYPE_NORMAL
- en: To test it first, you can copy the URL in your browser and test it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**: You can use a speech dialog if you activate your microphone for this
    site on your browser. Don''t forget to access the page using `https`, otherwise
    the microphone might be blocked. Also, fulfillment cannot be activated in this
    HTML page without some additional development.'
  prefs: []
  type: TYPE_NORMAL
- en: However, you can also click on Google Assistant in the console and create an
    application in a few clicks, and then deploy it on smartphones and Google Home,
    for example. If you create a nice chatbot, you can have the whole world use it
    in a few clicks!
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An NLP chatbot cannot function without machine learning for text recognition,
    utterances, sentences, speech, entities, intents, and many other aspects of a
    dialog.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will explore the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Speech-to-text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text-to-speech
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spelling correction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see how we can apply machine learning in each of these contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Using machine learning in a chatbot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generally, when we hear of machine learning in a chatbot, we think of a machine
    learning program running during a dialog as a response.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will focus on how machine learning is used to improve a
    chatbot and to make it work.
  prefs: []
  type: TYPE_NORMAL
- en: Speech-to-text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without a speech-to-text function, there is no way you can implement a chatbot
    or any speech application on a smart speaker such as Google Home or Amazon Echo.
    Smart speakers are going to play an increasing part in our lives in the years
    to come.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the settings button next to the name of the agent and then on **Speech**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.36: Speech options'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will focus on the main settings of the speech recognition functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhanced Speech Models**: This is an advanced machine learning option that
    comes with the Enterprise Edition. It shows how far speech recognition has come.
    In the standard version, the system already works fairly well. In the advanced
    version, it uses data logging functionality to enhance speech recognition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto Speech Adaptation**: This is interesting because this function uses
    the intents and entities created to train and adapt to speech recognition of the
    agent''s dialog. It can be activated in the free version as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B15438_15_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.37: Enabling Auto Speech Adaptation'
  prefs: []
  type: TYPE_NORMAL
- en: Save the settings before leaving this interface.
  prefs: []
  type: TYPE_NORMAL
- en: Text-to-speech
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we can go to the **Speech** tab and enable the **Automatic Text to Speech**
    function. I have a cloud account. If you cannot activate this in the lab, we will
    use the free online site to test the possibilities and limits of the machine learning
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**: There is an enhanced speech recognition model option, but you have
    to upgrade to the enterprise version.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the settings button next to the name of the agent and then on **Speech**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.38: Speech options'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first configure the main settings of text-to-speech:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Agent language**: Start with `en(English)` to reach the largest audience.
    However, bear in mind that Dialogflow produces good voice results in several languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Voice**: Start with `Automatic` before trying the different WaveNet model
    variations. WaveNet models build voices from scratch with neural networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speaking rate**: You can leave it at `1`, or accelerate the rate or slow
    it down. For sports commentaries, for example, it could be faster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pitch**: You can make the voice higher or lower in semitones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volume gain**: You can reduce or increase the volume. The best is to leave
    it at `0` to start. Then, while testing the agent, see if it needs to be changed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once these parameters are set, save the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.39: Voice configuration'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, test your configuration or experiment with different settings by entering
    a sentence and clicking on the **PLAY** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.40: Experimenting with different voice settings'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have finished setting up the voice parameters, we need to set up the
    spelling machine learning features.
  prefs: []
  type: TYPE_NORMAL
- en: Spelling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have one step left before we explore the possibilities and limits of the
    machine learning algorithms provided by Google. The machine learning spelling
    feature needs to be activated.
  prefs: []
  type: TYPE_NORMAL
- en: For that, we are going to click on the **ML Settings** tab, activate **AUTOMATIC
    SPELL CORRECTION**, and define an acceptable threshold below which our agent will
    refuse to recognize errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the settings button next to the name of the agent and then on **ML
    Settings**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.41: ML Settings tab'
  prefs: []
  type: TYPE_NORMAL
- en: You will have access to a variety of options to work around a user's spelling
    mistakes. It works like the spelling corrector of a search engine when we mistype
    our request and Google, for example, suggests the correct spelling.
  prefs: []
  type: TYPE_NORMAL
- en: 'The options are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ML CLASSIFICATION THRESHOLD** determines a confidence score below which an
    intent will not be triggered unless there is a fallback intent (a general response).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AUTOMATIC SPELL CORRECTION** uses machine learning to correct user spelling
    mistakes. It should be activated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AUTOMATIC TRAINING** may slow the dialog down, so careful use of this function
    is recommended.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AGENT VALIDATION** automatically validates an agent during the training process.
    Notice that training is triggered every time you save an intent, for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows default values you might want to start with:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_15_42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15.42: ML Settings options'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **TRAIN** button every time you change an option.
  prefs: []
  type: TYPE_NORMAL
- en: Why are these machine learning algorithms important?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If it's just an educational chatbot like the `cogfilmdr` agent example, mistakes
    are acceptable. It's unpleasant, but acceptable. As we are going to see in *Chapter
    16*, *Improving the Emotional Intelligence Deficiencies of Chatbots*, if a chatbot
    is going to be used by a large number of people, this means many days of training,
    tests, and creating workarounds to the machine learning limits of these functions.
    And that's just for one language!
  prefs: []
  type: TYPE_NORMAL
- en: If we are deploying in several languages, this means many days times the number
    of languages! Even with machine learning, it's tough work. Without machine learning,
    it's impossible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning is not merely important; it is vital:'
  prefs: []
  type: TYPE_NORMAL
- en: If the chatbot cannot recognize a written utterance because of a simple spelling
    mistake, we will get complaints, bad comments, and the SEO ship will sink.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the chatbot cannot recognize what you are saying on Google Home or any smart
    speaker, then that means a lot of trouble, maybe even a refund.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the chatbot's answer comes out in a phony voice that sounds like a 20th century
    robot, then nobody will want to use it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning in chatbots is here to stay, but there are improvements to
    make in terms of emotional intelligence, like we must now explore in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Dialogflow provides a complete set of tools on Google Cloud to build
    a chatbot, add services to it, and customize it with your cognitive programs.
  prefs: []
  type: TYPE_NORMAL
- en: A good chatbot fits the requirements. Thinking the architecture through before
    starting development avoids underfitting (not enough functionality) or overfitting
    (functions that will not be used) of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Careful AI preparation, as accomplished in *Chapter 14*, *Preparing the Input
    of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component
    Analysis (PCA)*, provides a solid basis for a chatbot by making the path from
    the start of the dialog to the goal of the dialog much shorter and efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Determining the right intent (what is expected of the chatbot), determining
    the entities to describe the intent (the subsets of phrases and words), and creating
    a proper dialog will take quite some time.
  prefs: []
  type: TYPE_NORMAL
- en: If necessary, adding services and specially customized machine learning functions
    will enhance the quality of the system. CUI with speech recognition, voice dialogs,
    and spelling correction features makes a chatbot frictionless to use.
  prefs: []
  type: TYPE_NORMAL
- en: The dialog we built in this chapter was based on *yes* answers. We supposed
    that the probabilities generated with the RBM and PCA in *Chapter 14* were correct.
    However, humans are not easily confined to stereotypes.
  prefs: []
  type: TYPE_NORMAL
- en: The *Chapter 16*, *Improving the Emotional Intelligence Deficiencies of Chatbots*,
    explores emotional intelligence through basic concepts, Dialogflow functions,
    and a cognitive approach to improve the content of a chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Can a chatbot communicate like a human? (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are chatbots necessarily AI programs? (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chatbots only need words to communicate. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do humans only chat with words? (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Humans only think in words and numbers. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Careful machine learning preparation is necessary to build a cognitive chatbot.
    (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a chatbot to function, a dialog flow needs to be planned. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A chatbot possesses general AI, so no prior development is required. (Yes |
    No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A chatbot translates fine without any function other than a translation API.
    (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chatbots can already chat like humans in most cases. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more on Google Dialogflow, refer to this link: [https://dialogflow.com/](https://dialogflow.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more on chatbots and UI development, refer to this link: [https://www.packtpub.com/application-development/hands-chatbots-and-conversational-ui-development](https://www.packtpub.com/application-development/hands-chatbots-and-conversational-ui-development)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
