<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Autoencoders
                </header>
            
            <article>
                
<p>This chapter introduces the autoencoder model by explaining the relationship between encoding and decoding layers. We will be showcasing a model that belongs to the unsupervised learning family. This chapter also introduces a loss function commonly associated with the autoencoder model, and it also applies it to the dimensionality reduction of MNIST data and its visualization in an autoencoder-induced latent space.</p>
<p>The following topics will be covered in this chapter: </p>
<ul>
<li>Introduction to unsupervised learning</li>
<li>Encoding and decoding layers</li>
<li><span>Applications in dimensionality reduction and visualization</span></li>
<li>Ethical implications of unsupervised learning</li>
</ul>
<h1 id="uuid-6b821113-2574-4121-9dc2-4f33ac16225b"><span>Introduction to unsupervised learning</span></h1>
<p>As machine learning has progressed over the last few years, I have come across many ways to categorize the different types of learning. Recently, at the NeurIPS 2018 conference in Montreal, Canada, Dr. Alex Graves shared information about the different types of learning, shown in <em>Figure 7.1</em>: </p>
<p class="mce-root CDPAlignCenter CDPAlign"><img src="assets/5bee9eca-50c2-4a2f-ad2d-2d7f4dd7de2e.png" style="width:23.50em;height:9.42em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.1 – Different types of learning</div>
<p>Such efforts at categorization are very useful today when there are many learning algorithms being studied and improved. The first row depicts <em>active</em> learning, which means that there is a sense of interaction between the learning algorithm and the data. For example, in reinforcement learning and active learning operating over <em>labeled data</em>, the reward policies can inform what type of data the model will read in the following iterations. However, traditional supervised learning, which is what we have studied so far, involves no interaction with the data source and instead assumes that the dataset is fixed and that its dimensionality and shape will not change; these non-interactive approaches are known as <em>passive</em> learning. </p>
<p>The second column in the table in the <em>Figure 7.1</em> represents a special kind of learning algorithm that requires <em>no labels</em> to learn from data. Other algorithms require you to have a dataset that has data <img class="fm-editor-equation" src="assets/52ff04b1-d1b4-4173-846d-eb4fc6caaa71.png" style="width:0.83em;height:0.92em;"/> that is associated with a label <img class="fm-editor-equation" src="assets/2e108673-48ce-4bf6-886c-961518e1492f.png" style="width:0.58em;height:1.00em;"/>; that is: <img class="fm-editor-equation" src="assets/16a7ebb1-2910-4ea4-be45-11490e9bdd33.png" style="width:7.67em;height:1.50em;"/>. However, unsupervised algorithms have no need for labels to "do things" with data. </p>
<div class="packt_tip">You can think of labels as a <strong>teacher</strong>. A teacher tells the learner that <strong>x</strong> corresponds to <sub><img class="fm-editor-equation" src="assets/35b87990-2cba-4534-a272-8a62f182d1e0.png" style="width:0.67em;height:1.08em;"/></sub> and the learner attempts to learn the relationship between<span> </span><sub><img class="fm-editor-equation" src="assets/af098bbe-7b09-4ffa-a98f-1537109b18f5.png" style="width:0.83em;height:0.92em;"/></sub><span> and </span><sub><img class="fm-editor-equation" src="assets/35b87990-2cba-4534-a272-8a62f182d1e0.png" style="width:0.58em;height:1.00em;"/></sub> iteratively by trial and error, adjusting its <em>beliefs</em> (parameters) until it gets it right. However, if there is no teacher, the learner does not know anything about the label <img class="fm-editor-equation" src="assets/4f8dc03e-cf59-479f-89d9-7e277b089165.png" style="width:0.67em;height:1.08em;"/> and therefore learns <em>something</em> about <img class="fm-editor-equation" src="assets/cd1d240b-75a4-4b5b-b53e-e6f9147a5425.png" style="width:0.75em;height:0.83em;"/> by itself, provided some boundaries, and it forms its own beliefs about<span> </span><img class="fm-editor-equation" src="assets/af098bbe-7b09-4ffa-a98f-1537109b18f5.png" style="width:0.83em;height:0.92em;"/><span> without ever knowing anything about </span><img class="fm-editor-equation" src="assets/35b87990-2cba-4534-a272-8a62f182d1e0.png" style="width:0.58em;height:1.00em;"/>. </div>
<p>In the following chapters, we will study <strong>unsupervised learning</strong>, which is the type of learning that assumes that the data we have will not change in its shape or form and will remain consistent during the learning process and also during its deployment. These algorithms are guided by something other than labels, for example, a unique loss function for data compression. On the other hand, there are other algorithms that have an exploration mechanism or a specific motivation to learn from data in an interactive way, and these algorithms are <strong>active learning</strong> algorithms. We will not discuss these algorithms in this book since this book is intended to be introductory and for absolute beginners. However, we will discuss at length some of the most robust <em>unsupervised </em>deep learning models. </p>
<p>We will begin by learning about <strong>autoencoders</strong>. An autoencoder has the sole purpose of taking input data into a neural network that is composed of two parts: an <strong>encoder</strong> and a <strong>decoder</strong>. The encoder portion has the mission of encoding the input data, usually into a lower-dimensional space, thereby compressing or encoding the input data. The decoder portion of the model is in charge of taking the encoded (or compressed) latent representation of the input data and then reconstructing it back to its original shape and to its original values without losing any data. That is, in an ideal autoencoder, the input is equal to the output. Let's discuss this in more detail in the following sections.</p>
<h1 id="uuid-d5e80d0a-f432-40ce-b7a1-adf060c83d41">Encoding and decoding layers</h1>
<p>The autoencoder can be broken down into two major components that serve specific purposes during an unsupervised learning process. The left side of <em>Figure 7.2</em> shows an autoencoder that is implemented using fully connected (dense) layers. It receives as input some vector <img src="assets/51804466-39c7-495b-a3c7-6b5a0e8462fe.png" style="width:3.92em;height:1.42em;"/> and then it goes into six hidden layers; the first three, with 6, 4, and 2 neurons, respectively, are meant to compress <span>the input data</span> down to two dimensions, since the output of two neurons is two scalar values. This first set of layers is known as the <strong>encoder</strong>:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/f308db9c-1cf1-42e1-b1eb-7c8bfea595b9.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.2 – Two representations of an autoencoder. Left: full and descriptive model. Right: compact and abstracted model representation</div>
<p><span>The second set of neurons is meant to reconstruct the input data back to its original dimensionality and values <img src="assets/9d520487-cfc5-48c1-aa44-2e0a69486ce5.png" style="width:3.00em;height:1.08em;"/> using three layers with 4, 6, and 8 neurons, respectively; this group of layers is known as the </span><strong>decoder</strong><span>.</span></p>
<div class="packt_tip">Note that the last layer of the autoencoder <em>must have</em> the same number of neurons as the number of dimensions of the input vector. Otherwise, the reconstruction would not match the input data.</div>
<p>In this case, the autoencoder shown on the left in <em>Figure 7.2</em> acts as a compression network, in the sense that after training the model to achieve good reconstruction, if we disconnect the decoder, we end up with a neural network that encodes the input data into two dimensions (or any dimensions we choose, for that matter). This presents a unique advantage over supervised models: in a supervised model, we teach a network to look for a pattern that will permit an association with a given target label; however, in unsupervised learning (or in this autoencoder, for example), the network does not look for a specific pattern but rather learns to use the input space in any way that preserves the most representative and most important information of the input data, so as to allow good reconstruction in the decoder. </p>
<p>Think of a neural network and an autoencoder that takes input images of cats and dogs; a traditional neural network can be trained to distinguish between dogs and cats and it is tasked with finding important patterns in the images of dogs and cats so as to tell the difference between them; however, an autoencoder will train to learn the most important patterns, the most representative of all patterns, so as to preserve that information and allow good reconstruction regardless of the label. In a way, the traditional supervised neural network is biased to see the world in terms of cats and dogs, while the autoencoder is free to learn from the world regardless of cats or dogs.</p>
<p>The diagram on the right of <em>Figure 7.2</em> depicts an alternative representation of an autoencoder that is more abstract and compact. This type of representation is useful when describing a relatively deep autoencoder, when the number of layers is large to the point of it being difficult to represent all the neurons and all the layers one by one (as in the left side of the <em>Figure 7.2</em>). We will use those trapezoidal shapes to denote that there is an encoder/decoder; we note also that this abstraction will allow us the freedom to use other types of layers and not only dense (fully connected) layers. The diagram on the right of <em>Figure 7.2</em> depicts an autoencoder that takes an image as input, then encodes the input into a <em>d-</em>dimensional space, and then reconstructs the <em>latent</em> vector back to the input (image) space.</p>
<div class="packt_infobox">A <strong>latent space<em> </em></strong>is a space where the learned lower-dimensional patterns are mapped. It is also known as the <em>learned representation space</em>. Ideally, this latent space is rich in important information about the input data and has fewer dimensions than the input data without any loss of information.</div>
<p>Let's now go ahead and implement each of the autoencoder parts based on the simple model on the left in <em>Figure 7.2</em>.</p>
<h2 id="uuid-e9b7133d-4086-4544-b0d5-f1f7f2149cff" class="mce-root">Encoding layers</h2>
<p>The TensorFlow and Keras libraries that we will be using are <kbd>Input</kbd> and <kbd>Dense</kbd> from <span><kbd>tensorflow.keras.layers</kbd> and <kbd>Model</kbd> from <kbd>tensorflow.keras.models</kbd>. We will be using the <kbd>keras</kbd> functional approach as opposed to <em>sequential</em> modeling. Import the following:</span></p>
<pre>from tensorflow.keras.layers import Input, Dense<br/>from tensorflow.keras.models import Model</pre>
<p><span>The </span><kbd>Input</kbd><span> layer will be used to describe the dimensionality of the input vector, which in our case will be <kbd>8</kbd>:</span></p>
<pre>inpt_dim = 8<br/>ltnt_dim = 2 <br/><br/>inpt_vec = Input(shape=(inpt_dim,))</pre>
<p>Then, considering all of our activation functions as <kbd>sigmoid</kbd> just for the sake of this example, we can define the pipeline of the encoder layers as follows:</p>
<pre>elayer1 = Dense(6, activation='sigmoid')(inpt_vec)<br/>elayer2 = Dense(4, activation='sigmoid') (elayer1)<br/>encoder = Dense(ltnt_dim, activation='sigmoid') (elayer2)</pre>
<p>The <kbd>Dense</kbd> <span>class constructor </span>receives the number of neurons and the activation function as parameters and at the end of the definition (on the right side), we must include what the input to the layer is, and this is assigned a name on the left side. Thus, in the line <kbd>elayer1 = Dense(6, activation='sigmoid')(inpt_vec)</kbd>, the name assigned to the layer is <kbd>elayer1</kbd>, then <kbd>6</kbd> is the number of neurons, <kbd>activation='sigmoid'</kbd> assigns a <kbd>sigmoid</kbd> activation function to the dense layer, and <kbd>inpt_vec</kbd> is the input to this layer in the pipeline.</p>
<p class="mce-root"/>
<p>In the preceding three lines of code, we have defined the layers of the encoder, and the <kbd>encoder</kbd> <span>variable </span>points to the object that can output the latent variable if we make it a model and call <kbd>predict()</kbd> on it:</p>
<pre><span>latent_ncdr = Model</span><span>(</span><span>inpt_vec</span><span>,</span><span> encoder</span><span>)</span></pre>
<p>In this line of code, <kbd>latent_ncdr</kbd> contains the model that can map the input data to the latent space once it is trained. But before we do that, let's go ahead and define the layers of the decoder in a similar way.</p>
<h2 id="uuid-f7815cc2-14f4-4776-859c-09a9a7edfc68">Decoding layers</h2>
<p>We can define the decoder layers as follows:</p>
<pre>dlayer1 = Dense(4, activation='sigmoid')(encoder)<br/>dlayer2 = Dense(6, activation='sigmoid') (dlayer1)<br/>decoder = Dense(inpt_dim, activation='sigmoid') (dlayer2)</pre>
<p>Note that in the preceding code, the number of neurons usually goes in increasing order until the last layer that matches the input dimension. In this case, 4, 6, and 8 are defined as <kbd>inpt_dim</kbd>. Similarly, the<span> </span><kbd>decoder</kbd><span> variable points to the object that can output the reconstructed input if we make it a model and call </span><kbd>predict()</kbd><span> on it.</span></p>
<p>We have separated the encoder and decoder intentionally here, simply to show that we could have the ability to access the different components of the network if we choose to do so. However, we should probably also define the autoencoder as a whole, from input to output, by using the<span> </span><kbd>Model</kbd><span> </span>class as follows:</p>
<pre>autoencoder = Model(inpt_vec, decoder)</pre>
<p>This is exactly what we meant earlier when we said "if we make it a model and call<span> </span><kbd>predict()</kbd><span> </span>on it." This declaration is making a model that takes as input the input vector defined in<span> </span><kbd>inpt_vec</kbd> and retrieves the output from the<span> </span><kbd>decoder</kbd><span> </span>layer. Then, we can use this as a model object that has a few nice functions in Keras that will allow us to pass input, read output, train, and do other things that we will discuss in the upcoming sections. For now, since we have defined our model, and before we can train it, we should define what the objective of the training will be, that is<em>, </em>what our loss function will be.</p>
<p class="mce-root"/>
<h2 id="uuid-501196b4-928d-48f2-aa13-c81e8498c0ff">Loss function</h2>
<p>Our loss function has to be in terms of the goal of the autoencoder. This goal is to reconstruct the input perfectly. That means that our input <img src="assets/5609bfb0-1712-46de-89cc-f6748f485e75.png" style="width:3.17em;height:1.17em;"/> and our reconstruction <img class="fm-editor-equation" src="assets/20073a1c-ab85-4c68-9710-7dc75e3838d9.png" style="width:3.25em;height:1.17em;"/> have to be identical in an ideal autoencoder. This implies that the absolute difference must be zero:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/46e56da7-bf75-4217-8bda-4ebfce996ffa.png" style="width:6.08em;height:1.42em;"/></p>
<p>However, this may not be realistic, and it is not in terms of a function that we can easily differentiate. For this, we can come back to the classic mean squared error function, which is defined as follows:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c7136505-52c9-429a-8d05-5d958e6983f1.png" style="width:9.42em;height:3.17em;"/></p>
<p class="mce-root">We want to make <img class="fm-editor-equation" src="assets/cf4788bf-0dbb-4180-9e74-0c6f8c31b7b0.png" style="width:2.42em;height:0.83em;"/>, ideally, or at best minimize it as much as possible. We interpret this loss function as minimizing the average of the squared differences between the input and its reconstruction. If we use a standard backprop strategy, say, some type of standard gradient descent technique, we can compile<em> </em>the model and prepare it for training as follows:</p>
<div>
<pre><span>autoencoder.</span><span>compile</span><span>(</span><span>loss=</span><span>'mean_squared_error'</span><span>,</span><span> optimizer=</span><span>'sgd'</span><span>)</span></pre></div>
<p>The <kbd>compile()</kbd> method prepares the model for training. The loss function defined previously is given as a parameter, <kbd>loss='mean_squared_error'</kbd>, and the optimization technique chosen here is known as <strong>stochastic gradient descent</strong> (<strong>SGD</strong>)<em>,</em> <kbd>optimizer='sgd'</kbd>. For more information on SGD, please see <span>Amari, S. I. (1993)</span><span>.</span></p>
<h2 id="uuid-12f2ba74-7960-4ed7-877d-56ca333b75c2">Learning and testing</h2>
<p>Since this is an introductory example of a simple autoencoder, we will train only with one data point and begin the learning process. We also want to show the encoded version and the reconstructed version.</p>
<p>We will use the number 39 in binary as eight digits, which corresponds to 00100111. We will declare this as our input vector as follows:</p>
<pre>import numpy as np<br/>x = np.array([[0., 0., 1., 0., 0., 1., 1., 1.]])</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>We can then perform the training as follows:</p>
<pre>hist = autoencoder.fit(x, x, epochs=10000, verbose=0)<br/><br/>encdd = latent_ncdr.predict(x)<br/>x_hat = autoencoder.predict(x)</pre>
<p>The <kbd>fit()</kbd> method performs the training. Its first two arguments are the input data and the desired target output; in the case of the autoencoder, they are both <kbd>x</kbd>. The number of epochs is specified as <kbd>epochs=10000</kbd>, since the model can produce a decent output at this point, and we set the verbosity to zero since we do not need to visualize every epoch, using <kbd>verbose=0</kbd>.</p>
<div class="packt_tip">In Google Colab or Jupyter Notebook, it is not a good idea to visualize more than 1,000 epochs on the screen at a time. The web browser might become unresponsive to the JavaScript code in charge of displaying all these epochs. Beware.</div>
<p>The <kbd>predict()</kbd> method in the latent encoder model, <kbd>latent_ncdr</kbd>, and in the <kbd>autoencoder</kbd> model produce the output at the specified layers. If we retrieve <kbd>encdd</kbd>, we can see the latent representation of the input, and if we retrieve <kbd>x_hat</kbd>, we can see the reconstruction. We can even calculate the mean squared error manually as follows:</p>
<pre>print(encdd)<br/>print(x_hat)<br/>print(np.mean(np.square(x-x_hat)))  # MSE</pre>
<p>This produces the following output:</p>
<pre>[[0.54846555 0.4299447 ]]<br/>[[0.07678119 0.07935049 0.91219556 0.07693048 0.07255505 0.9112366 0.9168126 0.9168152 ]]<br/>0.0066003498745448655</pre>
<div class="packt_infobox">The numbers here will vary due to the unsupervised nature of the learning algorithm. The first output vector can be any real numbers. The second output vector will likely have real numbers close to zero and close to one, resembling the original binary vector, but the exact values will vary every single time.</div>
<p>The first vector of two elements is the latent representation, [0.55, 0.43]; this may not mean much to us at this point, but it will be very important to us in terms of data compression. It means that we are able to represent eight digits using two. </p>
<p>Although this is a toy example and representing a binary number with two digits is not very exciting, the theory behind this is that we could take any eight floating-point digits in the range [0, 1] and compress them down to two digits in the same range. </p>
<p>The second vector displayed shows evidence of a good reconstruction: something that should be a zero is a 0.08 and something that should be a one is a 0.91. The <strong>mean squared error</strong> (<strong>MSE</strong>) as calculated manually yields a 0.007, which, although not zero, is small enough to be good.</p>
<p>We can visualize the decay of the MSE throughout the training phase using the information stored in the <kbd>hist</kbd> object defined during the invocation of <kbd>fit()</kbd>. This object contains the information of the loss function value across epochs and allows us to visualize the process with the following code:</p>
<pre>import matplotlib.pyplot as plt<br/><br/>plt.plot(<strong>hist.history['loss']</strong>)<br/>plt.title('Model reconstruction loss')<br/>plt.ylabel('MSE')<br/>plt.xlabel('Epoch')<br/>plt.show()</pre>
<p>This produces what you see in <em>Figure 7.3</em>:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img src="assets/2207d736-a57d-4b78-b766-5d47cdb5e6b3.png" style="width:35.00em;height:22.00em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 7.3 – Reconstruction loss across epochs of training of an autoencoder as described in terms of the MSE</div>
<p>Okay, once again, this was a toy example with one data point. We would never do this in <em>real life</em>. To show how bad an idea this is, we can take the binary string we used to train the model and invert every single bit, which gives 11011000 (or 216 in decimal). If we gave this to the autoencoder, we would expect a <em>good</em> reconstruction, but let's see what happens if we try to do that:</p>
<pre>x = np.array([[1., 1., 0., 1., 1., 0., 0., 0.]])  #216<br/><br/>encdd = latent_ncdr.predict(x)<br/>x_hat = autoencoder.predict(x)<br/><br/>print(encdd)<br/>print(x_hat)<br/>print(np.mean(np.square(x-x_hat)))</pre>
<p>We get the following output:</p>
<pre>[[0.51493704 0.43615338]]<br/>[[0.07677279 0.07933337 0.9122421 0.07690183 0.07254466 0.9112378 0.9167745 0.91684484]]<br/>0.8444848864148122</pre>
<div class="packt_infobox">Once again, the numbers here will vary due to the unsupervised nature of the learning algorithm. If your results are different from what you see here (I'm sure they are), that is not a problem.</div>
<p>If you compare these results with the ones from before, you will notice that the latent representation is not that different, and the reconstructed output does not at all match the given input. It is evident that the model <strong>memorized</strong> the input on which it was trained. This is evident when we calculate the MSE and we obtain a value of 0.84, which is large compared to the one previously obtained.</p>
<p>The solution to this is, of course, adding more data. But this concludes the toy example of building an autoencoder. What really changes after this is the type and amount of data, the number of layers, and the types of layers. In the next section, we will look at the application of a simple autoencoder in dimensionality reduction problems.</p>
<p class="mce-root"/>
<h1 id="uuid-f147302c-aed7-4207-bfb8-930a920e0e6b">Applications in dimensionality reduction and visualization</h1>
<p>Among some of the most interesting applications of autoencoders is dimensionality reduction [Wang, Y., et al. (2016)]. Given that we live in a time where data storage is easily accessible and affordable, large amounts of data are currently stored everywhere. However, not everything is relevant information. Consider, for example, a database of video recordings of a home security camera that always faces one direction. Chances are that there is a lot of repeated data in every video frame or image and very little of the data gathered will be useful. We would need a strategy to look at what is really important in those images. Images, by their nature, have a lot of redundant information, and there is usually correlation among image regions, which makes autoencoders very useful in compressing the information in images (Petscharnig, S., et al. (2017)).  </p>
<p>To demonstrate the applicability of autoencoders in dimensionality reduction for images, we will use the well-known MNIST <span>dataset</span>. </p>
<h2 id="uuid-767a34b1-e9dd-490f-8029-437cba60a541"><span>MNIST data preparation</span></h2>
<p>For details about MNIST, please go to <a href="8300fba9-620e-4bc3-8d81-3b02c5043a0d.xhtml">Chapter 3</a>, <em>Preparing Data</em>. Here we will only mention that the MNIST data will be scaled to the range [0, 1]. We also need to convert all images into vectors by reshaping the 28 by 28 digit images into a 784-dimensional vector. This can be achieved as follows:</p>
<pre>from tensorflow.keras.datasets import mnist<br/><br/>(x_train, y_train), (x_test, y_test) = mnist.load_data()<br/><br/>x_train = x_train.astype('float32') / 255.<br/>x_test = x_test.astype('float32') / 255.<br/><br/>x_train = x_train.reshape((len(x_train), 28*28))<br/>x_test = x_test.reshape((len(x_test), 28*28))</pre>
<p>We will use <kbd>x_train</kbd> to train the autoencoder and <kbd>x_test</kbd> to test the generalization capability of the autoencoder to both encode and decode MNIST digits. For visualization purposes, we will need <kbd>y_test</kbd>, but <kbd>y_train</kbd> can be ignored since we do not need labels in unsupervised machine learning.</p>
<p class="mce-root"/>
<p><em>Figure 7.4</em> depicts the first eight samples in <kbd>x_test</kbd>. These samples will be used across a few experiments to show the capabilities of different autoencoder models:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/6d1cc115-5ef0-473a-a4a5-f470dc712f1f.png" style="width:15.67em;height:8.08em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.4 – Test MNIST digits to be used for comparison</div>
<h2 id="uuid-6a715b45-e8af-40ed-97d1-6d62ab3d493e">Autoencoders for MNIST </h2>
<p>We can design a few experiments with different numbers of layers to see how the autoencoder changes its performance for MNIST. We can start with an autoencoder with four layers, always using a latent dimension of two. This is done to facilitate visualizing the MNIST digits in a two-dimensional space induced by the autoencoders. </p>
<p>Based on the previously defined autoencoder, we can propose the following four-layer base autoencoder:</p>
<pre>inpt_dim = 28*28<br/>ltnt_dim = 2<br/><br/>inpt_vec = Input(shape=(inpt_dim,))<br/><br/>elayer1 = Dense(392, activation='sigmoid')(inpt_vec)<br/>elayer2 = Dense(28, activation='sigmoid') (elayer1)<br/>elayer3 = Dense(10, activation='sigmoid') (elayer2)<br/>encoder = Dense(ltnt_dim, activation='<strong>tanh</strong>')(elayer3)<br/><br/>dlayer1 = Dense(10, activation='sigmoid')(encoder)<br/>dlayer2 = Dense(28, activation='sigmoid')(dlayer1)<br/>dlayer3 = Dense(392, activation='sigmoid')(dlayer2)<br/>decoder = Dense(inpt_dim, activation='sigmoid')(dlayer3)<br/><br/>latent_ncdr = Model(inpt_vec, encoder)<br/>autoencoder = Model(inpt_vec, decoder)<br/><br/>autoencoder.compile(loss='<strong>binary_crossentropy</strong>', optimizer='<strong>adam</strong>')<br/><br/>hist = autoencoder.fit(x_train, x_train, epochs=100, batch_size=256, <br/>                       <strong>shuffle=True, validation_data=(x_test, x_test)</strong>)</pre>
<p>This will be the base of the subsequent models. There are a few things that are highlighted that are new and need to be introduced properly. The first important thing is a new activation function called the <strong>hyperbolic tangent</strong>. This activation function is defined as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/52343b1b-860d-4414-b38c-dcd47901d881.png" style="width:12.92em;height:2.50em;"/></p>
<p>The corresponding first derivative is relatively simple:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/787eef00-1a67-4308-a579-98b187cf7ab2.png" style="width:21.58em;height:2.50em;"/></p>
<p>Besides having a nice and easily calculable derivative, the hyperbolic tangent activation function has a nice output range of [-1, 1]. This allows a neutral range that is not necessarily constrained to the sigmoid range [0, 1]. For visualization purposes, sometimes it is interesting to visualize in the hyperbolic tangent range, but it is not necessary to do so.</p>
<p>Another new element we have introduced is the loss function called <strong>binary cross-entropy</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b277ace3-8e19-46d5-969d-3c8eb2469cac.png" style="width:23.92em;height:3.17em;"/></p>
<p>In general, binary cross-entropy uses information, which are theoretical ideas to calculate the error between the target data <img class="fm-editor-equation" src="assets/64dc5f89-e650-4e23-a54d-ee7b42d906f2.png" style="width:0.75em;height:0.83em;"/> and the reconstructed (or predicted) data <img class="fm-editor-equation" src="assets/491f7fd1-ce72-4085-a1f5-9de08fee77d6.png" style="width:0.75em;height:1.08em;"/>. In a way, it measures the amount of entropy, or surprise, between the target and the prediction. For example, in an ideal autoencoder, it is not surprising that the target <img class="fm-editor-equation" src="assets/d759bd24-540c-47ec-a39e-533ee26397b9.png" style="width:0.67em;height:0.75em;"/> is equal to its reconstruction <img class="fm-editor-equation" src="assets/1383cd76-dc04-4c7e-8437-9e74de440010.png" style="width:0.67em;height:1.00em;"/>, and the loss should be zero. However, if the target <img class="fm-editor-equation" src="assets/131b4632-5c63-4ab0-856c-21ef58000492.png" style="width:0.67em;height:0.75em;"/> is not equal to <img class="fm-editor-equation" src="assets/c67111eb-15ba-4682-9dae-c6468ad25fe8.png" style="width:0.75em;height:1.08em;"/>, that would be surprising and would yield a high loss. </p>
<p>For a more complete discussion on autoencoders using cross-entropy loss, see (Creswell, A., et. al. (2017)).</p>
<p>A new optimizer called <strong>Adam</strong> has also been introduced (Kingma, D. P., et. al. (2014)). It is an algorithm for stochastic optimization that uses an adaptive learning rate that has proven to be very fast in some deep learning applications. Speed is a nice property when we are dealing with deep learning models and large datasets. Time is of the essence, and Adam provides a nice approach that has become popular.</p>
<p class="mce-root"/>
<p>Finally, the last new thing we added was on the <kbd>fit()</kbd> method. You should have noticed that there are two new parameters: <kbd>shuffle=True</kbd>, which allows the shuffling of data during the training process; and <kbd>validation_data=( , )</kbd>, which specifies a tuple of data that is used to monitor the loss using validation data, or data that the model has never seen, and will never use, for training. </p>
<p>That is all the new things we have introduced. The next step is to explain the autoencoder architectures we will try in our experiments. Please see <em>Figure 7.5</em> for a reference regarding the experiments we will perform:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/9ded95c1-d8fa-45fe-aa65-6c97a457ad43.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.5 – Different autoencoder configurations to demonstrate the difference in the quality of the latent representations</div>
<p>In the figure, you will notice that we are using the abstracted representation of an autoencoder, and on the right side of the <em>Figure 7.5</em> are the different layers that each autoencoder architecture will use. The first architecture shown corresponds to the code shown in this section. That is, the code shows an autoencoder with encoding layers of 392, 28, 10, and 2 neurons, respectively; while the decoding layers contain 10, 28, 392, and 784 neurons, respectively. The next model on the right contains the same layers except for removing the pair of layers corresponding to 392 neurons, and so on.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The last autoencoder model only contains two layers, one encoding (two neurons) and one decoding (784 neurons). At this point, you should be able to modify the Python code to remove the necessary layers and replicate the models depicted in <em>Figure 7.5</em>. The next step is to train the models in <em>Figure 7.5</em> and visualize the quality of the output. </p>
<h2 id="uuid-cec91d51-d615-4c89-b3a2-ed6319540256">Training and visualization</h2>
<p>The execution of <kbd>autoencoder.fit()</kbd> for 100 epochs produces a viable model that can easily encode into two dimensions as specified. Looking closely into the loss function during training, we can observe that it converges properly:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/1eaad2b2-ec72-436a-a4d6-7551d485dc5a.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.6 – Loss function monitoring during the training of a four-layer autoencoder</div>
<p>Once the model has been trained successfully, we can retrieve the encoded representation using the following:</p>
<pre>encdd = latent_ncdr.predict(x_test)</pre>
<p class="mce-root"/>
<p>We are using the test set, <kbd>x_test</kbd>. This encoding will encode into two dimensions, as specified, and will produce a latent representation in the range [-1, 1], as specified. Similarly, we can always take the test set and use the autoencoder to compress it and reconstruct it to see how similar the input is to the reconstruction. We do so with this:</p>
<pre>x_hat = autoencoder.predict(x_test)</pre>
<p>Before we look into the latent representations learned from MNIST, we can look into the reconstruction quality as a way of assessing the quality of the learned model. <em>Figure 7.7</em> shows the reconstruction results (in <kbd>x_hat</kbd>) using <em>Figure 7.4</em> as a reference to the input provided to each model. The figure is broken down into four parts, each part corresponding to the models described in <em>Figure 7.5</em>: a) the model with eight layers, b) <span>the </span><span>model with six </span>layers, c) <span>the </span><span>model with four </span>layers, and d) <span>the </span><span>model with two </span>layers:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/ba164838-ce99-4c8b-9915-f1d7c9312e19.png" style="width:12.25em;height:24.00em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.7 – Autoencoder reconstruction for the models in Figure 7.5: a) <span>the model with eight layers</span>, b) <span>the </span><span>model with six </span><span>layers, c) the </span><span>model with four </span><span>layers, and d) the </span><span>model with two </span><span>layers</span></div>
<p>From <em>Figure 7.7.a</em>, we can see that the model with eight layers (392, 28, 10, 2, 10, 28, 392, 784) is capable of producing generally good reconstructions with the exception of the numbers 4 and 9. It is evident that both digits are closely related (visually) and the autoencoder has some difficulty distinguishing clearly between the two digits. To further explore this observation, we can visualize test data in the latent space (in <kbd>encdd</kbd>), which is depicted in <em>Figure 7.8</em>:</p>
<p class="mce-root"/>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/0d99e2d5-f02f-416d-bd0a-38ec29e7ef4d.png" style="width:32.75em;height:28.17em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.8 – Four-layer encoder using MNIST test data</div>
<p>The overlap between digits four and nine is evident in the latent space produced by the autoencoder. However, most of the other groups of digits have relatively clear separate clusters. <em>Figure 7.8</em> also explains the natural closeness of other numbers that look like each other; for example, one and seven appear to be close to each other, as well as zero and six, and so do three and eight. However, numbers that do not look alike are in opposite sections of the latent space – for example, zero and one.</p>
<p class="mce-root"/>
<p><em>Figure 7.9</em> depicts the three-layer autoencoder that removed the layer with 392 neurons and left a 28, 10, 2 neuron architecture. Clearly, the quality of the latent space is significantly reduced, although some of the major structure is consistent. That is, zero and one are on opposite sides, and other numbers that look alike are closer together; the overlap is greater in comparison to <em>Figure 7.8</em>. The quality of this three-layer autoencoder is consistently lower, as shown in <em>Figure 7.7.b</em>:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/4a3f6fa6-12e8-472d-9309-baa2396e9346.png" style="width:38.17em;height:32.83em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.9 – Three-layer encoder using MNIST test data</div>
<p>In <em>Figure 7.10</em>, we can observe the results of the two-layer autoencoder with 10 and 2 neurons, which again has a greater digit overlap than the previous autoencoders; this is also evident in the poor reconstruction shown in <em>Figure 7.7.c</em>:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/b60d2d57-df05-46f3-ac6a-8fbded4dfb34.png" style="width:41.17em;height:35.33em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.10 – Two-layer encoder using MNIST test data</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Finally, <em>Figure 7.11</em> shows the latent space of the one-layer autoencoder. Clearly, this is a terrible idea. Just consider what we are asking the autoencoder to do: we are asking just two neurons to find a way to look at an entire image of a digit and find a way (learning weights <sub><img class="fm-editor-equation" src="assets/e2c8f2cb-9a89-4d71-9848-c755d1cd2c58.png" style="width:1.08em;height:0.83em;"/></sub>) to map all images to two dimensions. It is just not <span><span>possible </span></span>to do that. Logically, if we only have one layer, we would want at least 10 neurons to adequately model each of the 10 digits in MNIST:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/73bc6359-d02c-4f03-b66e-0f8a11f34068.png" style="width:30.33em;height:25.83em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 7.11 – One-layer encoder using MNIST test data – a bad idea</div>
<p>Close observation of <em>Figure 7.11</em> also makes it clear that the scale of the axes varies just slightly; this can be interpreted as the encoder not being able to separate into different regions of the latent space all the digits of MNIST. In practice, please do not use autoencoders with a few layers with a few neurons, unless the dimensionality of the input space is already very low. Autoencoders might be more successful in deep configurations, as shown in this experiment. Learn more about deep autoencoders in the next chapter.</p>
<p class="mce-root"/>
<h1 id="uuid-a78b991d-dbd9-4609-9a99-bc87871affad">Ethical implications of unsupervised learning</h1>
<p>Unsupervised learning, such as what we see happening in the autoencoder we have been exploring so far, is not magical. It is well established and has very rigorous boundaries that are known and pre-defined. It does not have the capability of learning new things outside the limitations given by the data. Remember, unsupervised learning is <strong>passive</strong> learning as explained in the introductory section of this chapter.</p>
<p>However, even the most robust of unsupervised learning models have ethical risks associated with them. One of the major problems is that they create difficulties when dealing with outliers or data that may contain edge cases. For example, say that there is a large amount of data for IT recruitment, which includes years of experience, current salary, and programming languages that a candidate knows. If the data mostly contains data about candidates with the same programming language experience, and only a few know Python, then those candidates that know the Python language might be placed into a boundary or a region that might be difficult to visualize clearly, because the model has learned that since Python is an infrequent language, it may not be relevant in terms of data compression, dimensionality reduction, or data visualization. Furthermore, consider what would happen if 5 years later, you used that same model despite there being newer programming languages that were not known about during training 5 years ago. The model may or may not map such information properly for visualization or data compression applications.</p>
<p>You must be very careful about what data is used to train an autoencoder, and having a variety of cases is important for the reliability of any model. If there is not enough diversity in the data, the autoencoder will be biased toward learning only from one input space. Imagine that you train an autoencoder on images of the 10 MNIST digits from earlier – you would not expect the autoencoder to perform properly on images of cats; that would be a mistake and would likely produce unwanted results. When using, for example, images of people, you must make sure that there is enough variety and diversity in the training data to produce proper training and a robust model that does not perform incorrectly for images of people that were not considered part of the training data.</p>
<h1 id="uuid-948ee96a-8166-464c-919d-45e3b96227cc">Summary </h1>
<p>This chapter showed that autoencoders are very simple models that can be used to encode and decode data for different purposes, such as data compression, data visualization, and simply finding latent spaces where only important features are preserved. We showed that the number of neurons and the number of layers in the autoencoder are important for the success of the model. Deeper (more layers) and wider (more neurons) traits are often ingredients for good models, even if that leads to slower training times.</p>
<p>At this point, you should know the difference between supervised and unsupervised learning in terms of passive learning. You should also feel comfortable implementing the two basic components of an autoencoder: the encoder and the decoder. Similarly, you should be able to modify the architecture of an autoencoder to fine-tune it to achieve better performance. Taking the example we discussed in this chapter, you should be able to apply an autoencoder to a dimensionality reduction problem or to a data visualization problem. Also, you should be considering the risks and responsibilities associated with unsupervised learning algorithms when it comes to the data used to train them.</p>
<p><a href="6677b8b1-806c-4c39-8c1e-371e83501acf.xhtml">Chapter 8</a>, <em>Deep Autoencoders,</em><span> will continue with deeper and wider autoencoder architectures that go beyond the introduction we covered in this chapter. The next chapter will introduce the idea of deep belief networks and the significance of this type of deep unsupervised learning. It will explain such concepts by introducing deep autoencoders and contrasting them with shallow autoencoders. The chapter will also give important advice on optimizing the number of neurons and layers to maximize performance.</span></p>
<h1 id="uuid-d1f342d2-a625-4bed-891c-20cda902fe03">Questions and answers</h1>
<ol>
<li><strong>Is overfitting a bad thing for an autoencoder? </strong></li>
</ol>
<p style="padding-left: 60px">Actually, no. You want the autoencoder to overfit! That is, you want it to exactly replicate the input data in the output. However, there is a caveat. Your dataset must be really large in comparison to the size of the model; otherwise, the memorization of the data will prevent the model from generalizing to unseen data.</p>
<ol start="2">
<li><strong>Why did we use two neurons in the encoder's last layer?</strong></li>
</ol>
<p style="padding-left: 60px">For visualization purposes only. The two-dimensional latent space produced by the two neurons allows us to easily visualize the data in the latent space. In the next chapter, we will use other configurations that do not necessarily have a two-dimensional latent space.</p>
<p> </p>
<p class="mce-root"/>
<ol start="3">
<li><strong>What is so cool about autoencoders again?</strong></li>
</ol>
<p> </p>
<p style="padding-left: 60px">They are simple neural models that learn without a teacher (unsupervised). They are not biased toward learning specific labels (classes). They learn about the world of data through iterative observations, aiming to learn the most representative and relevant features. They can be used as feature extraction models, but we will discuss more about that in future chapters.</p>
<h1 id="uuid-25e2eace-7e09-4ab7-af6a-91d25f567835">References</h1>
<ul>
<li><span>Amari, S. I. (1993). Backpropagation and stochastic gradient descent method.</span><span> </span><em>Neurocomputing</em><span>, 5(4-5), 185-196.</span></li>
<li>Wang, Y., Yao, H., &amp; Zhao, S. (2016). Auto-encoder based dimensionality reduction. <em>Neurocomputing</em>, 184, 232-242.</li>
<li>Petscharnig, S., Lux, M., &amp; Chatzichristofis, S. (2017). Dimensionality reduction for image features using deep learning and autoencoders. In <em>Proceedings of the 15th International Workshop on Content-Based Multimedia Indexing</em> (p. 23). ACM.</li>
<li>Creswell, A., Arulkumaran, K., &amp; Bharath, A. A. (2017). On denoising autoencoders trained to minimize binary cross-entropy. <em>arXiv preprint</em> arXiv:1708.08487.</li>
<li>Kingma, D. P., &amp; Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.</li>
</ul>


            </article>

            
        </section>
    </body></html>