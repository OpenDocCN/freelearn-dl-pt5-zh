["```py\nvirtualenv rlenv\nsource rlenv/bin/activate\npip install pandas==0.25.3\npip install plotly==4.10.0\npip install cufflinks==0.17.3\npip install jupyter\nipython kernel install --name «rlenv» –user\njupyter notebook\n```", "```py\n    import numpy as np # Class for a single slot machine. Rewards are Gaussian.class GaussianBandit(object):    def __init__(self, mean=0, stdev=1):        self.mean = mean         self.stdev = stdev         def pull_lever(self):        reward = np.random.normal(self.mean, self.stdev)        return np.round(reward, 1)\n    ```", "```py\n    class GaussianBanditGame(object):\n        def __init__(self, bandits):\n            self.bandits = bandits\n            np.random.shuffle(self.bandits)\n            self.reset_game()\n\n        def play(self, choice):\n            reward = self.bandits[choice - 1].pull_lever()\n            self.rewards.append(reward)\n            self.total_reward += reward\n            self.n_played += 1\n            return reward\n\n        def user_play(self):\n            self.reset_game()\n            print(\"Game started. \" + \n                  \"Enter 0 as input to end the game.\")\n            while True:\n                print(f\"\\n -- Round {self.n_played}\")\n                choice = int(input(f\"Choose a machine \" + \n                         f\"from 1 to {len(self.bandits)}: \"))\n                if choice in range(1, len(self.bandits) + 1):\n                    reward = self.play(choice)\n                    print(f\"Machine {choice} gave \" + \n                          f\"a reward of {reward}.\")\n                    avg_rew = self.total_reward/self.n_played\n                    print(f\"Your average reward \" +\n                          f\"so far is {avg_rew}.\")\n                else:\n                    break\n            print(\"Game has ended.\")\n            if self.n_played > 0:\n                print(f\"Total reward is {self.total_reward}\" + \n                      f\" after {self.n_played} round(s).\")\n                avg_rew = self.total_reward/self.n_played\n                print(f\"Average reward is {avg_rew}.\")              \n\n        def reset_game(self):\n            self.rewards = []\n            self.total_reward = 0\n            self.n_played = 0\n    ```", "```py\n    slotA = GaussianBandit(5, 3)slotB = GaussianBandit(6, 2)slotC = GaussianBandit(1, 5)game = GaussianBanditGame([slotA, slotB, slotC])\n    ```", "```py\n    game.user_play()\n    ```", "```py\n    Game started. Enter 0 as input to end the game. \n    -- Round 0\n    Choose a machine from 1 to 3:\n    ```", "```py\n    slotB machine, so there is no reason to try something else and lose money! \n    ```", "```py\n    -- Round 1\n    Choose a machine from 1 to 3: 1\n    Machine 1 gave a reward of 4.9.\n    Your average reward so far is 6.65.\n     -- Round 2\n    Choose a machine from 1 to 3: 1\n    Machine 1 gave a reward of -2.8.\n    Your average reward so far is 3.5.\n    ```", "```py\n    class BernoulliBandit(object):\n        def __init__(self, p):\n            self.p = p\n        def display_ad(self):\n            reward = np.random.binomial(n=1, p=self.p)\n            return reward\n    ```", "```py\n    adA = BernoulliBandit(0.004)\n    adB = BernoulliBandit(0.016)\n    adC = BernoulliBandit(0.02)\n    adD = BernoulliBandit(0.028)\n    adE = BernoulliBandit(0.031)\n    ads = [adA, adB, adC, adD, adE]\n    ```", "```py\n    n_test = 10000\n    n_prod = 90000\n    n_ads = len(ads)\n    Q = np.zeros(n_ads)  # Q, action values\n    N = np.zeros(n_ads)  # N, total impressions\n    total_reward = 0\n    avg_rewards = []  # Save average rewards over time\n    ```", "```py\n    for i in range(n_test):\n        ad_chosen = np.random.randint(n_ads)\n        R = ads[ad_chosen].display_ad() # Observe reward\n        N[ad_chosen] += 1\n        Q[ad_chosen] += (1 / N[ad_chosen]) * (R - Q[ad_chosen])\n        total_reward += R\n        avg_reward_so_far = total_reward / (i + 1)\n        avg_rewards.append(avg_reward_so_far)\n    ```", "```py\n    best_ad_index = np.argmax(Q)\n    ```", "```py\n    print(\"The best performing ad is {}\".format(chr(ord('A') + best_ad_index)))\n    ```", "```py\n    The best performing ad is D.\n    ```", "```py\n    ad_chosen = best_ad_index\n    for i in range(n_prod):\n        R = ads[ad_chosen].display_ad()\n        total_reward += R\n        avg_reward_so_far = total_reward / (n_test + i + 1)\n        avg_rewards.append(avg_reward_so_far)\n    ```", "```py\n    import pandas as pd\n    df_reward_comparison = pd.DataFrame(avg_rewards, columns=['A/B/n'])\n    ```", "```py\n    import cufflinks as cf\n    import plotly.offline\n    cf.go_offline()\n    cf.set_config_file(world_readable=True, theme=\"white\")\n    df_reward_comparison['A/B/n'].iplot(title=\"A/B/n Test Avg. Reward: {:.4f}\"\n                                       .format(avg_reward_so_far),\n                                        xTitle='Impressions', \n                                        yTitle='Avg. Reward')\n    ```", "```py\n    eps = 0.1\n    n_prod = 100000\n    n_ads = len(ads)\n    Q = np.zeros(n_ads)\n    N = np.zeros(n_ads)\n    total_reward = 0\n    avg_rewards = []\n    ```", "```py\n    ad_chosen = np.random.randint(n_ads)\n    for i in range(n_prod):\n        R = ads[ad_chosen].display_ad()\n        N[ad_chosen] += 1\n        Q[ad_chosen] += (1 / N[ad_chosen]) * (R - Q[ad_chosen])\n        total_reward += R\n        avg_reward_so_far = total_reward / (i + 1)\n        avg_rewards.append(avg_reward_so_far)\n        # Select the next ad to display\n        if np.random.uniform() <= eps:\n            ad_chosen = np.random.randint(n_ads)\n        else:\n            ad_chosen = np.argmax(Q)\n    df_reward_comparison['e-greedy: {}'.format(eps)] = avg_rewards\n    ```", "```py\n    greedy_list = ['e-greedy: 0.01', 'e-greedy: 0.05', 'e-greedy: 0.1', 'e-greedy: 0.2']\n    df_reward_comparison[greedy_list].iplot(title=\"ε-Greedy Actions\",\n     dash=['solid', 'dash', 'dashdot', 'dot'],\n     xTitle='Impressions', \n     yTitle='Avg. Reward')\n    ```", "```py\n    c = 0.1\n    n_prod = 100000\n    n_ads = len(ads)\n    ad_indices = np.array(range(n_ads))\n    Q = np.zeros(n_ads)\n    N = np.zeros(n_ads)\n    total_reward = 0\n    avg_rewards = []\n    ```", "```py\n    for t in range(1, n_prod + 1):\n        if any(N==0):\n            ad_chosen = np.random.choice(ad_indices[N==0])\n        else:\n            uncertainty = np.sqrt(np.log(t) / N)\n            ad_chosen = np.argmax(Q + c * uncertainty)  \n        R = ads[ad_chosen].display_ad()\n        N[ad_chosen] += 1\n        Q[ad_chosen] += (1 / N[ad_chosen]) * (R - Q[ad_chosen])\n        total_reward += R\n        avg_reward_so_far = total_reward / t\n        avg_rewards.append(avg_reward_so_far)\n    df_reward_comparison['UCB, c={}'.format(c)] = avg_rewards\n    ```", "```py\n    ucb_list = [‹UCB, c=0.1›, ‹UCB, c=1›, ‹UCB, c=10›]\n    best_reward = df_reward_comparison.loc[t-1,ucb_list].max()\n    df_reward_comparison[ucb_list].iplot(title=»Action Selection using UCB. Best avg. reward: {:.4f}»\n                                        .format(best_reward),\n                                        dash = [‹solid›, ‹dash›, ‹dashdot›],\n                                        xTitle=›Impressions›, \n                                        yTitle=›Avg. Reward›)\n    ```", "```py\n    n_prod = 100000\n    n_ads = len(ads)\n    alphas = np.ones(n_ads)\n    betas = np.ones(n_ads)\n    total_reward = 0\n    avg_rewards = []\n    ```", "```py\n    for i in range(n_prod):\n        theta_samples = [np.random.beta(alphas[k], betas[k]) for k in range(n_ads)]\n        ad_chosen = np.argmax(theta_samples)\n        R = ads[ad_chosen].display_ad()\n        alphas[ad_chosen] += R\n        betas[ad_chosen] += 1 - R\n        total_reward += R\n        avg_reward_so_far = total_reward / (i + 1)\n        avg_rewards.append(avg_reward_so_far)\n    df_reward_comparison['Thompson Sampling'] = avg_rewards\n    ```", "```py\n    df_reward_comparison['Thompson Sampling'].iplot(title=\"Thompson Sampling Avg. Reward: {:.4f}\"\n                                       .format(avg_reward_so_far),\n                                        xTitle='Impressions', \n                                        yTitle='Avg. Reward')\n    ```"]