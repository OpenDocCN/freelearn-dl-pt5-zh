<html><head></head><body>
  <div id="_idContainer266">
    <h1 class="chapterNumber">12</h1>
    <h1 id="_idParaDest-238" class="chapterTitle">AI and the Internet of Things (IoT)</h1>
    <p class="normal">Some people say the <strong class="bold">Internet of things</strong> (<strong class="bold">IoT</strong>) will turn out to become the fourth Industrial Revolution. Let's wait a few years until the smoke clears and then let historians figure out what sort of revolution we went through.</p>
    <p class="normal">In any case, <strong class="bold">connected objects</strong> have been changing our lives for at least the past two decades. Given all that we have seen in recent years, we can safely say that IoT has become disruptive.</p>
    <p class="normal">Artificial intelligence has <em class="italics">just</em> begun its long journey through human intellect. New, incredible innovations await us. Understand cutting-edge machine learning and deep learning theory is only the beginning of your adventure. Take everything you see seriously and see how it can be incorporated into your projects.</p>
    <p class="normal">Your mind must remain open to accept the many innovations that are yet to come. For example, conceptual representation learning (see previous chapters) adds the power of human concepts to neural networks.</p>
    <p class="normal">This chapter takes the technology of the previous chapter and applies it to the example of a self-driving car. The previous chapter used a webcam and a program and sent instructions to the conveyor belt. It was in the family of IoT. Let's add a <strong class="bold">support vector machine</strong> (<strong class="bold">SVM</strong>) to the program and take it out on the streets of a city to see what happens.</p>
    <p class="normal">The chapter is divided into three main sections: a public service project, the configuration of the model, and running the model.</p>
    <p class="normal">The following topics will be covered in this chapter:</p>
    <ul>
      <li class="list">A self-driving solution</li>
      <li class="list">Introducing a safe route parameter to trip planners</li>
      <li class="list">Applying CNNs to parking lots</li>
      <li class="list">Applying SVMs to safety on trip planning</li>
      <li class="list">Teaching an MDP to find the safest route (not necessarily the shortest way)</li>
    </ul>
    <p class="normal">Let's get started by outlining the problem and the goal of the project we'll be undertaking.</p>
    <h1 id="_idParaDest-239" class="title">The public service project</h1>
    <p class="normal">The overall <a id="_idIndexMarker574"/>project in this example is to implement a self-driving, home-to-homeless-shelter delivery service:</p>
    <ul>
      <li class="list">Families at homes have clothing and food they would like to give to others that need them.</li>
      <li class="list">The self-driving car can be started at a distance and goes to homes and takes the goods to the shelters.</li>
      <li class="list">The self-driving car does not need to have a base. It can park anywhere, go anywhere, and refuel at service stations with automatic electric recharging.</li>
    </ul>
    <p class="normal">In this chapter, we will focus on the self-driving car when it has finished a delivery and is looking for a parking lot with a parking space. We will need the information to make decisions.</p>
    <p class="normal">Some IoT projects plan to put sensors on every parking space and send the information to control centers. The city council finds that too expensive. Instead, the city council has decided to use a more cost-effective solution. A webcam will be installed on all the possible parking lots in the project's grid. This smart grid is for transporting products from homes to shelters.</p>
    <p class="normal">We'll address this by first setting up an RL-DL-CRLMM model.</p>
    <h1 id="_idParaDest-240" class="title">Setting up the RL-DL-CRLMM model</h1>
    <p class="normal">This section describes <a id="_idIndexMarker575"/>how to set up the previous chapter's model for this project and add a few functions.</p>
    <p class="normal">In <em class="italics">Chapter 11</em>, <em class="italics">Combining Reinforcement Learning and Deep Learning</em>, the RL-DL-CRLMM model analyzed webcam images of pieces of cut cloth to be sewed in real-time on a conveyor belt. The goal was to determine if they contained a gap (not too many pieces to sew) or not (a lot of pieces to sew). Then the model selected the best sewing station. A sewing station with a lot of work to do is best optimized with a small number of pieces to sew. A sewing station with little work to do will be best optimized with a large number of pieces to sew. By doing this, the RL-DL-CRLMM optimized the load on each sewing station, as <a id="_idIndexMarker576"/>shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.1: Apparel production flow</p>
    <p class="normal">This leads to the following circular optimizing model:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_02.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.2: Circular RL-DL-CRLMM</p>
    <p class="normal">This RL-DL-CRLMM model<a id="_idIndexMarker577"/> that we explored in <em class="italics">Chapter 11</em>, <em class="italics">Combining Reinforcement Learning and Deep Learning</em>, contains the following components:</p>
    <ul>
      <li class="list">A CRL-CNN to see if there is a gap in the image. In this chapter, we will use the same model to see if there is a gap in a parking lot that represents an available parking space.</li>
      <li class="list">An optimizer will rely on an SVM to add the concept of safety to the choice of an itinerary. It will then use optimization rules to make decisions, as in <em class="italics">Chapter 11, Combining Reinforcement Learning and Deep Learning</em>.</li>
      <li class="list">An MDP for the itinerary as described in <em class="italics">Chapter 1</em>, <em class="italics">Getting Started with Next-Generation Artificial Intelligence through Reinforcement Learning</em>.</li>
    </ul>
    <p class="normal">The RL-DL-CRLMM model of this chapter, which focuses on finding a parking lot with available parking space and go there will thus become:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_03.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.3: Circular RL-DL-CRLMM</p>
    <p class="normal">The CRL-CNN in this model<a id="_idIndexMarker578"/> looks for spaces in a parking lot instead of gaps on a conveyor belt.</p>
    <p class="normal">The RL-DL-CRLMM model <a id="_idIndexMarker579"/>contains a <strong class="bold">convolutional neural network</strong> (<strong class="bold">CNN</strong>) and a <strong class="bold">Markov decision process</strong> (<strong class="bold">MDP</strong>) linked together by an optimizer. The optimizer <a id="_idIndexMarker580"/>contains an SVM (safety evaluations) and a set of rules.</p>
    <p class="normal">This system will now be referred to as a CRLMM.</p>
    <h2 id="_idParaDest-241" class="title">Applying the model of the CRLMM</h2>
    <p class="normal">In <em class="italics">Chapter 9</em>, <em class="italics">Abstract Image Classification with Convolutional Neural Networks (CNNs)</em>, the CRLMM program, <code class="Code-In-Text--PACKT-">CNN_STRATEGY_MODEL.py</code>, was trained to identify <img src="../Images/B15483_11_028.png" alt=""/> (gamma concept) in outputs on the<a id="_idIndexMarker581"/> conveyor <a id="_idIndexMarker582"/>belt of a food processing factory. The end of the previous chapter brought <img src="../Images/B15438_10_022.png" alt=""/> up to a higher abstraction level.</p>
    <p class="normal">As long as a member of <img src="../Images/B15438_12_003.png" alt=""/> (gamma) of the <img src="../Images/B15438_10_005.png" alt=""/> dataset is in an undetermined state, its generalization encompasses ambivalent but similar concepts. Up to this chapter, these are the concepts <img src="../Images/B15438_12_005.png" alt=""/> (uppercase gamma) has learned (conceptual representation learning).</p>
    <p class="center"><img src="../Images/B15438_12_006.png" alt=""/> = {a gap, no gap, a load, no-load, not enough load, enough load, too much load, a space on a lane for a car, a distance between a high load of products and missing products on a conveyor belt, weights on sewing stations … <em class="italics">n</em>}</p>
    <p class="normal">The next step in the <a id="_idIndexMarker583"/>chapter is to use the CRLMM built in the previous chapters<a id="_idIndexMarker584"/> to recognize a parking space in a parking lot and send a signal to the self-driving vehicle:</p>
    <ul>
      <li class="list"><img src="../Images/B15438_12_006.png" alt=""/> will now perceive gaps as space.</li>
      <li class="list"><img src="../Images/B15438_12_006.png" alt=""/> will now perceive space as a distance (gap) between two objects.</li>
      <li class="list"><img src="../Images/B15438_12_006.png" alt=""/> will need a context to establish whether this space between two objects is a positive or negative distance.</li>
    </ul>
    <p class="normal">Let's take a look at the dataset that we'll use to accomplish our goals.</p>
    <h3 id="_idParaDest-242" class="title">The dataset</h3>
    <p class="normal">The datasets used in <em class="italics">Chapter 9</em>, <em class="italics">Abstract Image Classification with Convolutional Neural Networks (CNNs)</em>, to this chapter are sample datasets. In real-life projects, it will take some work to obtain the right <a id="_idIndexMarker585"/>real-time frames from a webcam. There will be lighting constraints, prerequisites, and more. However, the philosophy remains the same.</p>
    <p class="normal">As in the previous chapters, the <code class="Code-In-Text--PACKT-">dataset</code> directory of this chapter on GitHub contains the following:</p>
    <ul>
      <li class="list">The training set</li>
      <li class="list">The test set</li>
      <li class="list">The model trained by <code class="Code-In-Text--PACKT-">CNN_CONCEPT_STRATEGY.py</code></li>
      <li class="list">The <code class="Code-In-Text--PACKT-">classify</code> directory used by <code class="Code-In-Text--PACKT-">CNN_CONCEPT_STRATEGY.py</code></li>
    </ul>
    <p class="normal">As explained in the previous chapters, a full stream of frames from a well-configured webcam would take weeks, if not months, to prepare. They are projects in themselves.</p>
    <p class="normal">The project would first start by deciding to use a camera webcam or an IP camera that can send images to the CNN that is embedded in the RL-DL-CRLMM program. The CNN will classify each image sent by the video feed either as containing a gap or an available parking space or not.</p>
    <p class="normal">A webcam is usually <a id="_idIndexMarker586"/>connected to a computer, which will, in turn, send information to a distant server. An IP camera can send information directly to distant machines. Both solutions are connected IoT objects. An IP camera can be more expensive. To prove that the solution is a good one, an implementation team might start with a webcam first. Once the project has been accepted, then an IP camera might prove to be better in the long run. In this chapter, we will refer to webcams as in a research project with limited funds to begin with. We will thus consider that the images come from a webcam.</p>
    <p class="normal">In this example, <img src="../Images/B15438_12_006.png" alt=""/> has evolved into space (gap detection between (distance)) cars to find a parking space.</p>
    <p class="normal">The following is a simulated frozen frame with no <img src="../Images/B15438_12_006.png" alt=""/>-space taken by a webcam located on a building, pointing down to a parking lot:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_04.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.4: Simulated frozen frame</p>
    <p class="normal">I transformed the image to simulate some computer vision techniques that could have been used to simplify the image:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_05.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.5: Parking lot with a little to no gaps (not enough available parking spaces)</p>
    <p class="normal">The following <a id="_idIndexMarker587"/>frame represents a small but sufficient parking space on the right of the screen. The images in these examples were designed to explain how the system is built. I created the image for this example to show whether <img src="../Images/B15438_12_006.png" alt=""/>-space is available or not. Once again, I simulated an image after a computer vision process, which is easy to do but beyond the scope of this book. It shows something like several available parking spaces in a higher-level representation of the parking lot:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_06.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.6: Parking lot with a little to no gaps (not enough available parking spaces)</p>
    <h3 id="_idParaDest-243" class="title">Using the trained model</h3>
    <p class="normal">The model was trained <a id="_idIndexMarker588"/>by using the same <code class="Code-In-Text--PACKT-">CNN_STRATEGY_MODEL.py</code> program as in <em class="italics">Chapter 9</em>, <em class="italics">Abstract Image Classification with Convolutional Neural Networks (CNNs)</em>.</p>
    <p class="normal">Just make sure that the directory in the header of the following program is pointing to <code class="Code-In-Text--PACKT-">dataset/</code>, which is scenario number 2:</p>
    <pre class="programlisting"><code class="hljs routeros">A=[<span class="hljs-string">'dataset_O/'</span>,<span class="hljs-string">'dataset_traffic/'</span>,<span class="hljs-string">'dataset/'</span>]
<span class="hljs-attribute">scenario</span>=2 #reference <span class="hljs-keyword">to</span> A
<span class="hljs-attribute">directory</span>=A[scenario] #transfer learning parameter (choice of images)
<span class="hljs-builtin-name">print</span>(<span class="hljs-string">"directory"</span>,directory)
</code></pre>
    <p class="normal">The model is stored in <code class="Code-In-Text--PACKT-">/dataset/model</code>. To test the model, <code class="Code-In-Text--PACKT-">CNN_CONCEPT_STRATEGY.py</code>, improved in the previous chapter, was used. Just change the messages and limit the frame classification loop to <code class="Code-In-Text--PACKT-">2</code>, as shown in the following code snippet:</p>
    <pre class="programlisting"><code class="hljs ini"><span class="hljs-attr">MS1</span>=<span class="hljs-string">'available'</span>
<span class="hljs-attr">MS2</span>=<span class="hljs-string">'space'</span>
<span class="hljs-attr">I</span>=[<span class="hljs-string">'1'</span>,<span class="hljs-string">'2'</span>,<span class="hljs-string">'3'</span>,<span class="hljs-string">'4'</span>,<span class="hljs-string">'5'</span>,<span class="hljs-string">'6'</span>]
</code></pre>
    <p class="normal">The following loaded image was already resized before applying the CNN model:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_07.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.7: Resized image</p>
    <h4 class="title">Classifying the parking lots</h4>
    <p class="normal">We showed that the<a id="_idIndexMarker589"/> model works. However, in the following sections, we will simulate the images that are sent with a random function, not with the actual images.</p>
    <p class="normal">Now that the CRLMM has been trained to distinguish a full parking lot from a parking lot with available space, once an available parking lot has been found, an SVM takes over as an intermediate step, as we'll see in the next section.</p>
    <h1 id="_idParaDest-244" class="title">Adding an SVM function</h1>
    <p class="normal">The self-driving car has <a id="_idIndexMarker590"/>delivered its packages to the shelters. Now it has to find a parking lot and park there. Instead of having a base like many other systems, this saves the city the cost of many useless trips.</p>
    <h2 id="_idParaDest-245" class="title">Motivation – using an SVM to increase safety levels</h2>
    <p class="normal">The support vector<a id="_idIndexMarker591"/> system adds a new function to itinerary calculations—<strong class="bold">safety</strong>.</p>
    <p class="normal">Most systems, such as Google Maps, focus on:</p>
    <ul>
      <li class="list">The shortest trip</li>
      <li class="list">The fastest trip</li>
      <li class="list">Traffic</li>
    </ul>
    <p class="normal">However, self-driving cars have to take extra precautions. Many humans do not feel secure on some roads. Safety comes first, no matter what. Once a suitable parking lot has been found, the SVM has to avoid traffic.</p>
    <p class="normal">The goal is to find a path through traffic, even if the distance is longer. A <em class="italics">p</em> parameter allows for a <em class="italics">p</em>% variance in the distance. For example, 10% allows a 10% longer distance and will provide safe<a id="_idIndexMarker592"/> passage, as shown in the following SVM result:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.8: Traffic path</p>
    <p class="normal">It is important to note that the datapoints are <strong class="bold">not</strong> the actual coordinates but a representation in a higher dimension, as explained in the following section.</p>
    <h2 id="_idParaDest-246" class="title">Definition of a support vector machine</h2>
    <p class="normal">An <a id="_idIndexMarker593"/>SVM classifies data by transforming it into higher dimensions. It will then classify data into two classes, for example.</p>
    <p class="normal">In this section, the SVM will be used to separate risky driving locations from safer driving locations:</p>
    <p class="normal">The example in the<a id="_idIndexMarker594"/> code is random (as in real-life traffic), but the model can be developed much further.</p>
    <p class="normal">Safety is the key to this model, so each driving location (road, crossing) possesses features related to this goal:</p>
    <ul>
      <li class="list">Number of accidents at that location</li>
      <li class="list">Traffic at that location</li>
      <li class="list">Experience of driving through that location (near misses and no problems)</li>
    </ul>
    <p class="normal">All of this data can be fed into an SVM program. The program will transform the data to make it linearly separable (see <em class="italics">Chapter 8, Solving the XOR Problem with a Feedforward Neural Network</em>).</p>
    <p class="normal">The blue dots on the left will be the good locations, and the brown ones on the right will be the risky ones. A function will read the latitude and longitude features of the datapoint in another table to convert them back into GPS format.</p>
    <p class="normal">For example, a blue dot on the left might be:</p>
    <ul>
      <li class="list">Location A</li>
      <li class="list">One accident in the past ten years</li>
      <li class="list">Zero problems driving through that point in 1 year</li>
    </ul>
    <p class="normal">A brown dot<a id="_idIndexMarker595"/> might be:</p>
    <ul>
      <li class="list">Location D (a few blocks from A)</li>
      <li class="list">Seventy-four accidents in 10 years</li>
      <li class="list">Fifteen problems driving through that point in one year</li>
    </ul>
    <p class="normal">The blue dots and brown dots thus have nothing to do with the real location on the preceding graph. The locations<a id="_idIndexMarker596"/> are <strong class="bold">labels</strong>. Their features have been separated as expected.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">To send the data to a GPS guiding system, all that needs to be done is to find the GPS coordinates of the locations that are part of the initial dataset.</p>
    </div>
    <p class="normal">Location A will be chosen, for example, instead of location D. Hence, the program looks into the dataset and finds its GPS location.</p>
    <p class="normal">Let's put some words to the following SVM graph:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_10.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.10: SVM graph</p>
    <ul>
      <li class="list">The space between the dotted<a id="_idIndexMarker597"/> vertical lines is the <strong class="bold">margin</strong>. It's somewhat like the margin between two lines of a rugby or football team. When the players (datapoints) are lined up, an invisible space or margin separates them.</li>
      <li class="list">The dots that touch those margins are critical because they are the ones that decide where the margin will be in the first place. As the rugby or football players line up in clusters, the SVM will calculate this (refer to the following Python function). These<a id="_idIndexMarker598"/> special datapoints are called <strong class="bold">support points</strong>. They are also referred<a id="_idIndexMarker599"/> to as <strong class="bold">support vectors</strong>.</li>
      <li class="list">The vertical line running in the middle of the <a id="_idIndexMarker600"/>margin is the <strong class="bold">decision line</strong>.</li>
      <li class="list">Since a line separates the dots, the dataset is linearly separable. This means that a line can be drawn between the datapoints and can separate them into classes. In this case, the system wants to obtain safe locations (blue dots) and avoid unsafe locations (brown dots).</li>
    </ul>
    <p class="normal">Now that we defined what an SVM is, let's implement it in Python.</p>
    <h2 id="_idParaDest-247" class="title">Python function</h2>
    <p class="normal">The <code class="Code-In-Text--PACKT-">sklearn</code> packages <a id="_idIndexMarker601"/>provide the following <code class="Code-In-Text--PACKT-">svm</code> function:</p>
    <pre class="programlisting"><code class="hljs angelscript"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_blobs
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">make_blobs</code> function generates uniform data for this example in all <a id="_idIndexMarker602"/>directions. It is thus an <strong class="bold">isotropic</strong> distribution (<em class="italics">iso</em> = equal, <em class="italics">tropy</em> = way) of random data. A <strong class="bold">blob</strong> contains points of data. The points of data<a id="_idIndexMarker603"/> represent the concentration of cars in given areas, which were calculated using their longitude and latitude.</p>
    <p class="normal">scikit-learn contains a Gaussian factor for the generation function. A Gaussian kernel applies standard deviations from a mean. Imagine you are playing in a sandbox, and you make a little hill. Then, with your hand, you cut the pile in two. The mean is where you cut the sand pile; the standard deviation is shown by the slopes going down on both sides.</p>
    <p class="normal">It might take days, and sometimes weeks, to put a good dataset together. But with scikit-learn, you can do it in one line, as shown in the following code snippet:</p>
    <pre class="programlisting"><code class="hljs routeros">    #100 cars clusters(concentration of cars) represented   [Line 323]
    X, y = make_blobs(<span class="hljs-attribute">n_samples</span>=100, <span class="hljs-attribute">centers</span>=2, <span class="hljs-attribute">random_state</span>=7)
</code></pre>
    <p class="normal">This function offers many parameters. The ones used are as follows:</p>
    <ul>
      <li class="list"><code class="Code-In-Text--PACKT-">n_samples</code>, which represents the number of points spread out between the clusters. In this example, <code class="Code-In-Text--PACKT-">100</code> already represents sub-clusters of car concentrations in an area.</li>
      <li class="list"><code class="Code-In-Text--PACKT-">Centers</code> is the number of centers from which to generate data. In this example, <code class="Code-In-Text--PACKT-">2</code> represents areas close to the present location of the self-driving car and its future destination.</li>
      <li class="list"><code class="Code-In-Text--PACKT-">random_state</code> is the seed by the random number generator. This is where the sequence of random numbers will start. This is because what we think is random is pseudo-random, so it has a deterministic basis.</li>
    </ul>
    <p class="normal">In this example, a linear kernel is used to fit the model, as shown in the following code:</p>
    <pre class="programlisting"><code class="hljs nix">    <span class="hljs-comment"># the model is directly fitted. The goal is a global estimate    [Line 326]</span>
    <span class="hljs-attr">clf</span> = svm.SVC(<span class="hljs-attr">kernel='linear',</span> <span class="hljs-attr">C=1000)</span>
    clf.fit(X, y)
</code></pre>
    <p class="normal">scikit-learn's SVM contains <a id="_idIndexMarker604"/>a parameter penalty, which explains the <code class="Code-In-Text--PACKT-">C</code> in <code class="Code-In-Text--PACKT-">svm.SVC</code>. There are many more options, but the key option is the kernel. A linear kernel will produce a linear separation, as shown in the preceding screenshot.</p>
    <p class="normal">An RBF kernel would produce a different result. The structure looks more regularized. As shown in the following screenshot, an RBF kernel acts as an efficient structural regularizing function:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_11.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.11: Regularized structure path</p>
    <p class="normal">Bear in mind that the SVM can be used for image recognition on the MNIST and CIFAR datasets, for example. Artificial intelligence provides more than one way to solve a given problem. It is up to you to choose the right tools by having a flexible trial-and-error approach where necessary.</p>
    <p class="normal">The plotting line instructions start at line 300. The main line of code to take into account is the function that will find and use the decision line (refer to the preceding definition) and scatter the <a id="_idIndexMarker605"/>datapoints on both sides of the margin. This is achieved by using the following <code class="Code-In-Text--PACKT-">decision_function</code>:</p>
    <pre class="programlisting"><code class="hljs reasonml">    Z = clf.decision<span class="hljs-constructor">_function(<span class="hljs-params">xy</span>)</span>.reshape(<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">XX</span>.</span></span>shape)
</code></pre>
    <p class="normal">The result will be displayed, as shown previously. The SVM is now a component of the CRLMM in this self-driving car (SDC) model. We are ready the run the CRLMM to find an available parking space for the SDC.</p>
    <h1 id="_idParaDest-248" class="title">Running the CRLMM</h1>
    <p class="normal">The self-driving car's <a id="_idIndexMarker606"/>mission is a circular (no beginning, no end) one like the CRLMM described in the previous chapter:</p>
    <ul>
      <li class="list">If it is in a parking lot, it can be activated by a home or a shelter.</li>
      <li class="list">If it is at a given home, it will go to a shelter.</li>
      <li class="list">If it is at a shelter, it can go to a home or a parking space.</li>
      <li class="list">If it needs recharging, this can be done at a recharging space (or more probably at a parking space), which is already the case in some cities.</li>
    </ul>
    <p class="normal">At one point, the self-driving car has to go from a specific home to a parking space. This part of its itinerary is the subject of the following sections.</p>
    <h2 id="_idParaDest-249" class="title">Finding a parking space</h2>
    <p class="normal"><code class="Code-In-Text--PACKT-">CRL-MM-IoT_SVM.py</code> uses a <a id="_idIndexMarker607"/>fine-tuned version of <code class="Code-In-Text--PACKT-">RL_DL.py</code> described in the previous chapter.</p>
    <p class="normal">A no-<img src="../Images/B15438_12_006.png" alt=""/> (no gamma, no gap, no space) result is not acceptable. The result we are looking for is an image with a gap.</p>
    <p class="normal">If the <code class="Code-In-Text--PACKT-">crlmm</code> function, which classifies parking lot images into full or available space, returns a <code class="Code-In-Text--PACKT-">0</code>, the program detects it and displays a message. The code samples contain the line number of the following code excerpt:</p>
    <pre class="programlisting"><code class="hljs python">            <span class="hljs-keyword">if</span>(crlmm==<span class="hljs-number">0</span>):    <span class="hljs-comment"># [Line 392]</span>
                full = load_img(<span class="hljs-string">"FULL.JPG"</span>)
                plt.subplot(<span class="hljs-number">111</span>)
                plt.imshow(full)
                plt.title(<span class="hljs-string">'PARKING LOT STATUS : This parking lot is full.'</span> + <span class="hljs-string">'\n'</span> + <span class="hljs-string">'Another webcam is consulted'</span>, fontname=<span class="hljs-string">'Arial'</span>, fontsize=<span class="hljs-number">10</span>)
                <span class="hljs-comment">#plt.text(0.1,2, "The frame is the input of a trained CNN")</span>
                plt.show()
                <span class="hljs-string">'''
                plt.show(block=False)
                time.sleep(5)
                plt.close()
                '''</span>
                print(<span class="hljs-string">"This parking lot is full, searching..."</span>)
</code></pre>
    <p class="normal">The program displays the following full sign and closes it after a few seconds:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_12.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.12: Parking lot status</p>
    <p class="normal">The program must find a <a id="_idIndexMarker608"/>parking space. It will thus try searches of good parking lots as shown in this code snippet:</p>
    <pre class="programlisting"><code class="hljs angelscript">        <span class="hljs-keyword">for</span> search <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):    # [Line <span class="hljs-number">391</span>]
            <span class="hljs-keyword">if</span>(crlmm==<span class="hljs-number">0</span>):
</code></pre>
    <p class="normal">A thousand searches looks like a lot, but it isn't difficult for a machine learning program.</p>
    <p class="normal">Furthermore, looking for available parking spaces in a large city can be excruciating. More often than not, it will not be suitable: there will not be sufficient available parking spaces to be certain of finding one in the time it will take to get there.</p>
    <p class="normal">For this prototype, the number <a id="_idIndexMarker609"/>of optimal searches is limited to <code class="Code-In-Text--PACKT-">2</code>. Beyond that value, the following <code class="Code-In-Text--PACKT-">CRLMM</code> function is activated:</p>
    <pre class="programlisting"><code class="hljs gcode">                <span class="hljs-keyword">if</span><span class="hljs-comment">(search&gt;2)</span>:    <span class="hljs-attr"># [Line 405</span>]
                    a=<span class="hljs-number">1</span>
                crlmm=CRLMM<span class="hljs-comment">(Q,lr,e,a)</span>
</code></pre>
    <p class="normal">After two fruitless searches, the program activates <code class="Code-In-Text--PACKT-">a</code>, a flag for the <code class="Code-In-Text--PACKT-">CRLMM</code> function.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">CRLMM</code> function now contains a random search function, which simulates the choice of a parking lot and provides a first-level status:</p>
    <pre class="programlisting"><code class="hljs angelscript">    status=random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>)    # [Line <span class="hljs-number">199</span>]
    <span class="hljs-keyword">if</span>(status&gt;<span class="hljs-number">5</span>):
        status=<span class="hljs-number">1</span>
    <span class="hljs-keyword">if</span>(status&lt;=<span class="hljs-number">5</span>):
        status=<span class="hljs-number">0</span> 
</code></pre>
    <p class="normal">The status represents a probabilistic estimate of the availability of the parking lot. The <code class="Code-In-Text--PACKT-">a</code> flag simulates a program yet to be added that will scan all the parking lots and run this function to find an available space.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">To present a prototype at an initial meeting, you will always need enough to convince, but if you go too far, the cost of doing this becomes a risk if your idea is rejected.</p>
    </div>
    <p class="normal">So, if <code class="Code-In-Text--PACKT-">a</code> is activated, the system simulates a scan (to be developed) and forces the status to <code class="Code-In-Text--PACKT-">1</code>, as shown in the following code snippet:</p>
    <pre class="programlisting"><code class="hljs routeros">    <span class="hljs-keyword">if</span>(a&gt;0 <span class="hljs-keyword">and</span> <span class="hljs-attribute">status</span>==0):    # [Line 204]
        #<span class="hljs-builtin-name">add</span> an available search function here that scans all the
        #webcams of then<span class="hljs-built_in"> network </span>until it finds one that suits the model (<span class="hljs-keyword">not</span> too far parameter <span class="hljs-keyword">and</span> available)
        <span class="hljs-attribute">status</span>=1
</code></pre>
    <p class="normal">The program then continues and runs the CNN trained to identify an available parking lot (refer to the screenshot that follows), as explained in the preceding configuration section:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_13.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.13: Webcam freezes a frame of a parking lot</p>
    <p class="normal">Now that a parking lot with <a id="_idIndexMarker610"/>available space has been found (the empty spaces on the top left of the frame), the search function stops, and the following <code class="Code-In-Text--PACKT-">break</code> instruction is activated:</p>
    <pre class="programlisting"><code class="hljs angelscript">                <span class="hljs-keyword">if</span>(crlmm==<span class="hljs-number">1</span>):    # [Line <span class="hljs-number">408</span>]
                    a=<span class="hljs-number">0</span>
                    <span class="hljs-keyword">break</span>
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">break</code> instruction is reached once a parking space has been found. Once an available parking space has been detected, we can decide how to get to the parking lot.</p>
    <h2 id="_idParaDest-250" class="title">Deciding how to get to the parking lot</h2>
    <p class="normal">The CRLMM program has found a <a id="_idIndexMarker611"/>suitable parking lot, as shown in the following code, when <code class="Code-In-Text--PACKT-">crlmm==1</code>:</p>
    <pre class="programlisting"><code class="hljs python">        <span class="hljs-keyword">if</span>(crlmm==<span class="hljs-number">1</span>):    <span class="hljs-comment"># [Line 412]</span>
            available = load_img(<span class="hljs-string">"AVAILABLE.JPG"</span>)
            plt.subplot(<span class="hljs-number">111</span>)
            plt.imshow(available)
            plt.title(<span class="hljs-string">'PARKING LOT STATUS : This parking lot has available space.'</span> + <span class="hljs-string">'\n'</span> + <span class="hljs-string">'Now an SVM will suggest a safe route '</span>, fontname=<span class="hljs-string">'Arial'</span>, fontsize=<span class="hljs-number">10</span>)
            <span class="hljs-comment">#plt.text(0.1,2, "The frame is the input of a trained CNN"</span>
            plt.show()
            <span class="hljs-string">'''
            plt.show(block=False)
            time.sleep(5)
            plt.close()
            '''</span>
            print(<span class="hljs-string">"This parking lot has available space..."</span>)
</code></pre>
    <p class="normal">It displays the following message and a sign:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_14.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.14: Parking lot status</p>
    <p class="normal">Now that we found an <a id="_idIndexMarker612"/>available parking space, we need to find a safe route for the SDC. This means the SDC will avoid traffic to make it easier for the autonomous machine learning program. Now it is time to activate the function.</p>
    <h3 id="_idParaDest-251" class="title">Support vector machine</h3>
    <p class="normal">The CRLMM now<a id="_idIndexMarker613"/> demands a safe route, even if it means taking longer (time or distance). Self-driving vehicles require a strict safety-comes-first policy.</p>
    <p class="normal">The program reaches the following SVM function:</p>
    <pre class="programlisting"><code class="hljs less">            <span class="hljs-selector-tag">print</span>(<span class="hljs-string">"This parking lot has available space..."</span>)    # <span class="hljs-selector-attr">[Line 424]</span>
            <span class="hljs-selector-tag">SAFE_SVM</span>()
</code></pre>
    <p class="normal">The SVM described in the configuration section provides a safe path through traffic, as shown in this screenshot of the result:</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_15.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.15: Traffic graph</p>
    <p class="normal">For example, in this random case (traffic will be random most of the time), the blue dots on the left represent sparser traffic, and the brown dots represent areas with denser traffic. The goal, in real-life implementation, is to provide information to the MDP in the program so that it will find paths through sparser traffic for safety reasons to limit the errors an SDC can make in denser traffic. The weights of the statistics of past accidents and the car's experience can <a id="_idIndexMarker614"/>also be added to create a deeper vision of this safety model trip planner.</p>
    <p class="normal">Suppose the self-driving car has to go to a point in the brown area. The SVM will:</p>
    <ul>
      <li class="list">Suggest an itinerary that goes through blue dot areas as much as possible and only then in brown areas.</li>
      <li class="list">Send the information to Google Maps. This will require an additional script that will read a dataset that contains GPS coordinates for each datapoint in the SVM.</li>
    </ul>
    <p class="normal">Many drivers feel unsafe on loaded freeways or in dense cities. Adding the safest route function to mapping software would help.</p>
    <p class="normal">The SVM brought the datapoints to a higher level (refer to the explanation in the configuration section of the chapter).</p>
    <div class="note">
      <p class="Information-Box--PACKT-">The points represented in an SVM function are <strong class="bold">not</strong> the actual locations but an abstract representation. The dividing line needs to go through a function that will transform that information into a real location datapoint.</p>
    </div>
    <p class="normal">Once the SVM boundaries have been converted into location datapoints, the itinerary or trip graph is activated.</p>
    <h3 id="_idParaDest-252" class="title">The itinerary graph</h3>
    <p class="normal">The prototype shows a <a id="_idIndexMarker615"/>simulation of an itinerary graph based on the SVM recommendations and its weight vector through the following function call:</p>
    <pre class="programlisting"><code class="hljs less">            <span class="hljs-selector-tag">print</span>(<span class="hljs-string">"SAFE PASSAGE SUGGESTED"</span>)    # <span class="hljs-selector-attr">[Line 426]</span>
            <span class="hljs-selector-tag">MDP_GRAPH</span>(lr,e)
</code></pre>
    <p class="normal">The following graph displays the safest itinerary in red, even if it takes longer (time or distance):</p>
    <figure class="mediaobject"><img src="../Images/B15438_12_16.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.16: The optimizer chose the safest itinerary</p>
    <p class="normal">For the purpose of the prototype, the SVM was not directly connected to the graph, which would require costly hours. </p>
    <p class="normal">Instead, the following <code class="Code-In-Text--PACKT-">random.randint</code> function was inserted, which simulates the random availability of parking space in any case:</p>
    <pre class="programlisting"><code class="hljs maxima">            <span class="hljs-keyword">for</span> wi <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):    [Line <span class="hljs-number">430</span>]
                <span class="hljs-built_in">op</span>=<span class="hljs-built_in">random</span>.randint(<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)
                <span class="hljs-keyword">if</span>(W[<span class="hljs-built_in">op</span>]&gt;maxw):
                    lr=<span class="hljs-built_in">op</span>;maxw=W[<span class="hljs-built_in">op</span>]
</code></pre>
    <p class="normal">Bear in mind that it would be useless to execute further development for a prototype as regards the initial presentation to a prospect or manager.</p>
    <p class="normal">This type of prototype is <a id="_idIndexMarker616"/>more powerful than a slideshow because it proves your legitimacy. Slideshows are static and don't prove your abilities on this particular subject. A prototype will show your expertise. Once we have the safest locations, we can update the weight vector for the MDP, as in the previous chapter.</p>
    <h3 id="_idParaDest-253" class="title">The weight vector</h3>
    <p class="normal">The weight vector is displayed. In this model, the weights represent the locations, just like in the previous chapter. However, in<a id="_idIndexMarker617"/> this chapter, the weights are a rating:</p>
    <ul>
      <li class="list">Each weight has a high safety rank when a few accidents have occurred around that area in the past <em class="italics">n</em> years. This<a id="_idIndexMarker618"/> is a <strong class="bold">safety rank</strong>. This ranking should be part of our itinerary software. We should be informed.</li>
      <li class="list">The self-driving car's experience will customize each weight. It is its own driving record. Near misses because of its faulty software will bring the weight down. Good track records will take the weights up. What seems easy for a human might be difficult for software, and vice versa.</li>
    </ul>
    <p class="normal">The system now displays the weights used with an internal update program to be developed if the prototype is accepted. The following code calls the function that manages the weights of the safest routes for the self-driving vehicle and displays a histogram:</p>
    <pre class="programlisting"><code class="hljs less">            <span class="hljs-selector-tag">print</span>(<span class="hljs-string">"Vertex Weights"</span>,W)    # <span class="hljs-selector-attr">[Line 428]</span>
            <span class="hljs-selector-tag">MDP_CRL_graph</span>(W,lr)
</code></pre>
    <figure class="mediaobject"><img src="../Images/B15438_12_17.png" alt=""/></figure>
    <p class="packt_figref">Figure 12.17: Histogram of the updated weights vertex (safest routes)</p>
    <p class="normal">We detected an available parking space, asked an SVM to provide the safest areas to go through to get to that parking space, updated the weight of each area, and sent the information to the MDP to calculate a safe route.</p>
    <h1 id="_idParaDest-254" class="title">Summary</h1>
    <p class="normal">This chapter, like the previous chapter, described a connected IoT process with no humans involved. This trend will expand into every field in the years to come.</p>
    <p class="normal">This also shows that knowing how to use a tool requires hard work, especially when learning artificial intelligence. Imagining a solution for a given market requires more than hard work. Creativity does not come with work. It develops by freeing your mind from any form of constraint.</p>
    <p class="normal">Once the solution has been imagined, then comes the fine line between developing too much for a presentation and not showing enough. A CRLMM provides the kind of framework that helps build a technical solution (CNN, MDP, SVM, and optimizers) while keeping everyday concepts that others understand in mind.</p>
    <p class="normal">The chapter also shows that an artificial intelligence model can contain an ensemble of algorithms, RL, DL, SVM, and CRL cognitive approaches, and more.</p>
    <p class="normal">The next chapter will take us deeper under the hood of neural networks and TensorFlow 2 by peeking inside the ANN's processes.</p>
    <h1 id="_idParaDest-255" class="title">Questions</h1>
    <ol>
      <li class="list">Driving quickly to a location is better than safety in any situation. (Yes | No)</li>
      <li class="list">Self-driving cars will never really replace human drivers. (Yes | No)</li>
      <li class="list">Will a self-driving fire truck with robots be able to put out a fire one day? (Yes | No)</li>
      <li class="list">Do major cities need to invest in self-driving cars or avoid them? (Invest | Avoid)</li>
      <li class="list">Would you trust a self-driving bus to take children to school and back? (Yes | No)</li>
      <li class="list">Would you be able to sleep in a self-driving car on a highway? (Yes | No)</li>
      <li class="list">Would you like to develop a self-driving program for a project for a city? (Yes | No)</li>
    </ol>
    <h1 id="_idParaDest-256" class="title">Further reading</h1>
    <ul>
      <li class="list">For more information on SVMs, refer these links: <a href="http://scikit-learn.org/stable/modules/svm.html"><span class="url">http://scikit-learn.org/stable/modules/svm.html</span></a>, <a href="http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html#sphx-glr-auto-examp"><span class="url">http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-py</span></a></li>
    </ul>
  </div>
</body></html>