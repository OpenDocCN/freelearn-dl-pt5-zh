["```py\n    entry_points:\n      main:\n        parameters:\n          pipeline_steps: { type: str, default: all }\n        command: \"python main.py –pipeline_steps {pipeline_steps}\"\n    ```", "```py\nparameter_name: {type: data_type, default: value}\n```", "```py\nparameter_name:\n  type: data_type\n  default: value\n```", "```py\nmlflow run . --experiment-name='dl_model_chapter05' -P pipeline_steps='download_data'\n```", "```py\n2022/01/01 19:15:37 INFO mlflow.projects.utils: === Created directory /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmp3qj2kws2 for downloading remote URIs passed to arguments of type 'path' ===\n2022/01/01 19:15:37 INFO mlflow.projects.backend.local: === Running command 'source /Users/yongliu/opt/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-95353930ddb7b60101df80a5d64ef8bf6204a808 1>&2 && python main.py --pipeline_steps download_data' in run with ID 'f7133b916a004c508e227f00d534e136' ===\n```", "```py\nmlflow run . -e main -b local --experiment-name='dl_model_chapter05' -P pipeline_steps='download_data'\n```", "```py\n2022-01-01 19:15:48,249 <Run: data=<RunData: metrics={}, params={'download_url': 'https://pl-flash-data.s3.amazonaws.com/imdb.zip',\n 'local_folder': './data',\n 'mlflow run id': 'f9f74ebd80f246d58a5f7a3bfb3fc635',\n 'pipeline_run_name': 'chapter05'}, tags={'mlflow.gitRepoURL': 'git@github.com:PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow.git',\n 'mlflow.parentRunId': 'f7133b916a004c508e227f00d534e136',\n```", "```py\ndownload_run = mlflow.run(\".\", \"download_data\", parameters={})\n```", "```py\n 'mlflow.project.backend': 'local',\n 'mlflow.project.entryPoint': 'download_data',\n```", "```py\n2022-01-01 19:15:48,269 finished mlflow pipeline run with a run_id = f7133b916a004c508e227f00d534e136\n2022/01/01 19:15:48 INFO mlflow.projects: === Run (ID 'f7133b916a004c508e227f00d534e136') succeeded ===\n```", "```py\nmlflow run https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 -v 26119e984e52dadd04b99e6f7e95f8dda8b59238  --experiment-name='dl_model_chapter05' -P pipeline_steps='download_data'\n```", "```py\n2021/12/30 18:57:32 INFO mlflow.projects.utils: === Fetching project from https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 into /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpdyzaa1ye ===\n```", "```py\nlocal_folder: { type: str, default: ./data }\n```", "```py\n    pip install databricks-cli\n    ```", "```py\n    databricks configure --token\n    ```", "```py\n    Databricks Host (should begin with https://): https://????\n    Token: dapi??????????\n    ```", "```py\n[DEFAULT]\nhost = https://??????\ntoken = dapi???????\njobs-api-version = 2.0 \n```", "```py\n    os.environ[\"MLFLOW_TRACKING_URI\"] = http://localhost\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = http://localhost:9000\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n    ```", "```py\nexport MLFLOW_TRACKING_URI=\"databricks\"\n```", "```py\n    mlflow run . -b databricks --backend-config cluster_spec.json --experiment-name='/Shared/dl_model_chapter05' -P pipeline_steps ='download_data'\n    ```", "```py\n{\n    \"new_cluster\": {\n        \"spark_version\": \"9.1.x-gpu-ml-scala2.12\",\n        \"num_workers\": 1,\n        \"node_type_id\": \"g4dn.xlarge\"\n    }\n}\n```", "```py\n/rootPath/subfolder1/subfolder2/my_experiment_name\n```", "```py\nexport MLFLOW_EXPERIMENT_NAME=/Shared/dl_model_chapter05\n```", "```py\n    INFO: '/Shared/dl_model_chapter05' does not exist. Creating a new experiment\n    2022/01/06 17:35:32 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/427565/projects-code/f1cbec57b21eabfca52f417f8482054bbea22be 9205b5bbde461780d809924c2.tar.gz ===\n    2022/01/06 17:35:32 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/427565/projects-code/f1cbec57b21eabfca52f417f8482054bbea22be 9205b5bbde461780d809924c2.tar.gz ===\n    ```", "```py\n2022/01/06 17:48:31 INFO mlflow.projects.databricks: === Running entry point main of project . on Databricks ===\n2022/01/06 17:48:31 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 279456. Getting run status page URL... ===\n2022/01/06 17:48:31 INFO mlflow.projects.databricks: === Check the run's status at https://???.cloud.databricks.com#job/168339/run/1 ===\n```", "```py\nmlflow run . -b databricks --backend-config cluster_spec.json --experiment-name='/Shared/dl_model_chapter05' -P pipeline_steps='download_data,fine_tuning_model'\n```", "```py\n2022/01/07 15:22:39 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/427565/projects-code/743cadfec82a55b8c76e9f27754cfdd516545b155254e990c2cc62650b8af959.tar.gz ===\n2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/427565/projects-code/743cadfec82a55b8c76e9f27754cfdd516545b155254e990c2cc62650b8af959.tar.gz ===\n2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Running entry point main of project . on Databricks ===\n2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 279540\\. Getting run status page URL... ===\n2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Check the run's status at https://?????.cloud.databricks.com#job/168429/run/1 ===\n```", "```py\nexport MLFLOW_TRACKING_URI=databricks\nexport DATABRICKS_TOKEN=[databricks_token]\nexport DATABRICKS_HOST='https://[your databricks host name/'\n```", "```py\nmlflow run https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 -v 395c33858a53bcd8ac217a962ab81e148d9f1d9a -b databricks --backend-config cluster_spec.json --experiment-name='/Shared/dl_model_chapter05' -P pipeline_steps='all'\n```", "```py\n    2022/01/07 17:36:54 INFO mlflow.projects.utils: === Fetching project from https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 into /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpzcepn5h5 ===\n    ```", "```py\n    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/427565/projects-code/fba3d31e1895b78f40227b5965461faddb 61ec9df906fb09b161f74efaa90aa2.tar.gz ===\n    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/427565/projects-code/fba3d31e1895b78f40227b5965461faddb61ec 9df906fb09b161f74efaa90aa2.tar.gz ===\n    ```", "```py\ndatabricks fs ls -l dbfs:/mlflow-experiments/427565/projects-code/fba3d31e1895b78f40227b5965461faddb61ec 9df906fb09b161f74efaa90aa2.tar.gz\n```", "```py\nfile  3070  fba3d31e1895b78f40227b5965461faddb61ec 9df906fb09b161f74efaa90aa2.tar.gz  1641605818000\n```", "```py\n    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Running entry point main of project https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 on Databricks ===\n    ```", "```py\n    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 279660\\. Getting run status page URL... ===\n    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Check the run's status at https://????.cloud.databricks.com#job/168527/run/1 ===\n    ```"]