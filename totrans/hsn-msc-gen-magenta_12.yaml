- en: Magenta in the Browser with Magenta.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll talk about Magenta.js, a JavaScript implementation of
    Magenta that has gained in popularity for its ease of use, since it runs in the
    browser and can be shared as a web page. We'll introduce TensorFlow.js, the technology
    upon which Magenta.js is built, and show which models are available in Magenta.js,
    including how to convert our previously trained models. Then, we'll create small
    web applications using GANSynth and MusicVAE, for sampling audio and sequences
    respectively. Finally, we'll see how Magenta.js can interact with other applications,
    using the Web MIDI API and Node.js.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Magenta.js and TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Magenta.js web application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making Magenta.js interact with other apps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll use the following tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Command line** or **Bash** to launch Magenta from the terminal'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Python** and **Magenta** to convert trained models for Magenta.js'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TensorFlow.js** and **Magenta.js** to create music generation apps in the
    browser'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JavaScript**, **HTML**, and **CSS** to write Magenta.js web applications'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **recent browser** (Chrome, Firefox, Edge, Safari) for up-to-date web APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Node.js** and **npm** to install Magenta.js and its dependencies server side'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FluidSynth** to listen to generated MIDI from the browser'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Magenta.js, we'll make the use of the **Music RNN** and **MusicVAE** models
    for MIDI sequence generation and **GANSynth** for audio generation. We'll cover
    their usage in depth, but if you feel like you need more information, the Magenta.js
    Music README in the Magenta.js source code ([github.com/tensorflow/magenta-js/tree/master/music](https://github.com/tensorflow/magenta-js/tree/master/music))
    is a good place to start. You can also take a look at the Magenta.js code, which
    is well documented. We also provide additional content in the last section, *Further
    reading*.
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter is in the book's GitHub code repository in the `Chapter08` folder,
    located at [github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter08](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter08).
    The examples and code snippets used assume you are located in the chapter folder.
    For this chapter, you should run `cd Chapter08`, before you start.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: Placeholder link
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Magenta.js and TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we've covered Magenta in Python, its usage, and its
    inner workings. We'll now be looking at Google's Magenta.js, a smaller implementation
    of Magenta in JavaScript. Magenta and Magenta.js both have their advantages and
    disadvantages; let's compare them to see which one we should use, depending on
    the use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Magenta.js application is easy to use and deploy since it executes in the
    browser. **Developing and deploying a web application is easy**: all you need
    is an HTML file and a web server, and your application is available for the whole
    world to see and use. This is a major advantage of making a browser-based application,
    since not only does it enable us to create our own music generation application
    easily, but it also makes it easy to use it collaboratively. See the *Further
    reading* section at the end of the chapter for great examples of popular Magenta.js
    web applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the power of a web browser: everyone has one, and a web page requires
    no installation to run. The downside of a Magenta.js web application is that it
    also runs in a browser: it isn''t the best place to handle quality, real-time
    audio, and making your application interact with traditional music production
    tools, such as **digital audio workstations** (**DAWs**), is harder.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll be looking at the specifics of working in the browser as we go along.
    First, we'll be looking at Tone.js in the *Introducing Tone.js for sound synthesis
    in the browser* section, which describes the usage of the Web Audio API. Then,
    we'll be looking at the Web Workers API in the *Using the Web Workers API to offload
    computations from the UI thread* section, to make real-time audio easier. Finally,
    we'll be looking at making Magenta.js interact with other music applications,
    in the *Making Magenta.js interact with other apps* section.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing TensorFlow.js for machine learning in the browser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let's introduce TensorFlow.js ([www.tensorflow.org/js](https://www.tensorflow.org/js)),
    the project upon which Magenta.js is built. As its name suggests, TensorFlow.js
    is a JavaScript implementation of TensorFlow, making it possible to **use and
    train** **models in the browser**. Importing and running pre-trained models from
    TensorFlow SavedModel or Keras is possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using TensorFlow.js is easy. You can use a `script` tag, as shown in the following
    code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use the `npm` or `yarn` command to run the following
    code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Notice in both code snippets the usage of the `tf` variable, which is imported
    with the script (we'll be seeing more `tf` usage in this chapter's examples).
    We won't be looking at TensorFlow.js specifically, but we are going to use it
    in our Magenta.js code.
  prefs: []
  type: TYPE_NORMAL
- en: Another nice thing about TensorFlow.js is that it uses WebGL ([www.khronos.org/registry/webgl/specs/latest/](https://www.khronos.org/registry/webgl/specs/latest/))
    for its computation, meaning it is **graphics processing unit** (**GPU**) accelerated
    (if you have a GPU), without having to install CUDA libraries. The mathematical
    operations are implemented in WebGL shaders and the tensors are encoded in WebGL
    textures, which is a very clever use of WebGL. We don't have to do anything for
    GPU acceleration since the TensorFlow.js backend will handle it for us. When using
    the Node.js server side, the TensorFlow C API is used for hardware acceleration,
    meaning that the usage of CUDA libraries is possible.
  prefs: []
  type: TYPE_NORMAL
- en: Using WebGL has a few caveats, though, most notably that the computations might
    block the UI thread in some cases and that the memory used by a tensor allocation
    must be reclaimed (disposed) after usage. Regarding computation threading, we'll
    be looking at this in more depth when we look at web workers. Regarding memory
    management, we'll be showing proper usage in the code as we go along. See the
    *Further reading* section for more information on these issues.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Magenta.js for music generation in the browser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand what Tensorflow.js is, let's talk about Magenta.js. First,
    we need to understand what Magenta.js can and cannot do. For now, models cannot
    be trained in Magenta.js (with the exception of the partial training in MidiMe),
    but the models we've trained in the previous chapter can be converted and imported
    easily. Another limitation of Magenta.js is that not all models are present, but
    the most important ones are. While writing Magenta.js code, we'll see that most
    of the concepts we've already covered are there, sometimes with a different syntax.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an overview of some of the pre-trained models present in Magenta.js:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Onsets and Frames** for piano transcription, converting raw audio to MIDI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Music RNN** (**long short-term memory** (**LSTM**)-based networks) for monophonic
    and polyphonic MIDI generation, including the Melody RNN, Drums RNN, Improv RNN
    and Performance RNN models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MusicVAE** for single or trio sampling and interpolation, also including
    GrooVAE'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Piano Genie** that maps an 8-key input to a full 88-key piano'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've already talked about these models in the previous chapters. We can find
    the pre-trained checkpoints list either in the Magenta.js source code, in the
    `music/checkpoints/checkpoints.json` file, or in the hosted version, at [goo.gl/magenta/js-checkpoints](https://goo.gl/magenta/js-checkpoints).
    Most of the checkpoints (or bundles) we've used are present in Magenta.js, plus
    some new additions such as longer 4-bar MusicVAE and GrooVAE models.
  prefs: []
  type: TYPE_NORMAL
- en: Converting trained models for Magenta.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using pre-trained models is great, but we can also import our own trained models,
    such as the ones we trained in the previous chapter—[Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*. We are doing that by using the `checkpoint_converted.py`
    script that dumps the weights from a Magenta checkpoint to a format Magenta.js
    can use.
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_01.html` file in the source
    code of this chapter. There are more comments and content in the source code—you
    should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s convert a simple RNN model for Magenta.js, by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll need the `checkpoint_converter.py` script from Magenta.js. The
    easiest way is to download the script directly from the source code on GitHub,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This should create the `checkpoint_converter.py` file locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we''ll need the TensorFlow.js Python packaging on which the `checkpoint_converter.py`
    script depends. Run the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now run the conversion script using, for example, one of our previously
    trained DrumsRNN models (replacing `PATH_TO_TRAINING_DIR` with a proper value),
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This will create the `checkpoints/drums_rnn_dance_small` directory with a JSON
    metadata file and the checkpoint binary files that will get loaded by TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that when referencing checkpoints in TensorFlow, you need to provide
    the prefix—for example, `model.ckpt-20000`, but not followed by `.data`, `.index`,
    or `.meta`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we need to create a JSON configuration file that describes the model
    configuration. Open the `checkpoints/drums_rnn_dance_small/config.json` file and
    enter this content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is a minimal example for the DrumsRNN model, without any further configuration.
    Note that the `args` key for the `dataConverter` key is necessary, even if no
    arguments are provided. The `type` of `dataConverter` is one of the subclasses
    of `DataConverter`, located in the `data.ts` file in `music/src/core` in the Magenta.js
    source code. Other possible data converters could be `MelodyConverter`, `TrioConverter`,
    or `GrooveConverter`.
  prefs: []
  type: TYPE_NORMAL
- en: Other models and converters will require more configuration. The easiest way
    to find the proper configuration for a specific model is to find a similar Magenta
    pre-trained model and use similar values. To do that, follow the *Downloading
    pre-trained models locally* section, and find the information you want in the
    downloaded `config.json` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our custom model is now converted to a format TensorFlow.js understands. Let''s
    create a small web page that imports and initializes that model to test it, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Don't worry too much about the content of the HTML page, since it will be thoroughly
    explained in the following sections. The important part here is that the MusicRNN
    constructor (`mm.MusicRNN("URL")`) is loading our converted DrumsRNN checkpoint
    in the MusicRNN model.
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that the URL of the checkpoint is local, at `http://0.0.0.0:8000`.
    This is because most browsers implement **Cross-Origin Resource Sharing** (**CORS**)
    restrictions, one of them being that a local file can only fetch resources starting
    with a **Uniform Resource Identifier** (**URI**) scheme of `http` or `https`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way of circumventing that is to start a web server locally, like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This will start a web server serving the current folder at `http://0.0.0.0:8000`,
    meaning the HTML file from the previous snippet will be served at `http://0.0.0.0:8000/example.html`,
    and our checkpoint at `http://0.0.0.0:8000/checkpoints/drums_rnn_dance_small`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the HTML file and check the console. You should see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This means that our model was successfully initialized.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading pre-trained models locally
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Downloading pre-trained models locally is useful if we want to serve them ourselves
    or if we want to check the `config.json` content:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll need the `checkpoint_converter.py` script from Magenta.js. The
    easiest way is to download the script directly from the source code on GitHub,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This should create the `checkpoint_converter.py` file locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then call the script by entering the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This will download the `mel_16bar_small_q2` MusicVAE pre-trained model in the
    `checkpoints` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Tone.js for sound synthesis in the browser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you'll hear generated audio in the browser, which means that
    audio synthesis, analogous to when we used FluidSynth in the previous chapters
    to listen to MIDI files, is happening in the browser, using the Web Audio API.
  prefs: []
  type: TYPE_NORMAL
- en: The **Web Audio API** ([www.w3.org/TR/webaudio/](https://www.w3.org/TR/webaudio/))
    provides fairly low-level concepts to handle sound sources, transformations, and
    routing, through the usage of audio nodes. First, we have a sound source that
    provides an array of sound intensities (see [Chapter 1](c5602f6c-c094-42f2-936f-98746cf04a49.xhtml),
    *Introduction on Magenta and Generative Art*, for a refresher on that), which
    could be a sound file (a sample) or an oscillator. Then, the sound source node
    can be connected to a transformation node such as a gain (to change the volume).
    Finally, the result needs to be connected to a destination (an output) for the
    sound to be heard in the speakers.
  prefs: []
  type: TYPE_NORMAL
- en: The specification is quite mature, listed as *W3C Candidate Recommendation,
    September 18, 2018*, so some implementation details might change, but it can be
    considered stable. In terms of support, all the major browsers support the Web
    Audio API, which is great. See the *Further reading* section for more information.
  prefs: []
  type: TYPE_NORMAL
- en: We won't be using the Web Audio API directly. Rather, we'll be using **Tone.js**
    ([tonejs.github.io](https://tonejs.github.io/)), which is a JavaScript library
    built on top of the Web Audio API, providing higher-level functionalities. Another
    advantage of using Tone.js is that it can be resilient to change, in the event
    of the underlying Web Audio API changing.
  prefs: []
  type: TYPE_NORMAL
- en: Since the Web Audio API implementation changes from browser to browser, the
    quality of the audio might vary. For example, layering multiple audio samples
    from GANSynth resulted in audio clipping in Firefox but worked correctly in Chrome.
    Remember that for professional-grade audio quality, audio synthesis in the browser
    might not be the best choice.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Magenta.js web application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have introduced the concepts surrounding Magenta.js, we'll be creating
    a web application using Magenta.js. Let's create a web application where we generate
    a trio of instruments (the drum kit, the bass, and the lead) using MusicVAE, where
    we can change the lead instrument for a GANSynth-generated instrument.
  prefs: []
  type: TYPE_NORMAL
- en: We'll be building this application step by step. First, we'll make an app that
    generates instruments, using GANSynth. Then, we'll create an app in which we can
    sample a trio sequence. Finally, we'll merge the two apps together.
  prefs: []
  type: TYPE_NORMAL
- en: Generating instruments in the browser using GANSynth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the first part of our example, we'll use GANSynth to sample single instrument
    notes, which are short audio clips of 4 seconds. We'll be able to layer multiple
    audio clips, for interesting effects.
  prefs: []
  type: TYPE_NORMAL
- en: First, we'll create the HTML page and import the required scripts. Then, we'll
    write the GANSynth sampling code and explain each step in detail. We'll finish
    the example by listening to the generated audio.
  prefs: []
  type: TYPE_NORMAL
- en: Writing the page structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll be keeping the page structure and style at a minimum, to focus on the
    Magenta.js code.
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_02.html` file in the source
    code of this chapter. There are more comments and content in the source code—you
    should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s create the page structure and import the required scripts, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The page structure contains only a button that will call the GANSynth generation
    and a container in which we'll draw the generated spectrogram.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways of using Magenta.js in the browser, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We can import the whole Magenta.js music distribution in `dist/magentamusic.min.js`.
    In the Magenta documentation, this is referred to as the **ES5 bundle** method.
    This will include Magenta.js (bound on `mm`) and all its dependencies, including
    TensorFlow.js (bound on `mm.tf`) and Tone.js (bound on `mm.Player.tone`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can import only the Magenta.js elements that we need, under the `es6` folder.
    In the Magenta documentation, this is referred to as the **ES6 bundle** method.
    For example, if we only need the GANSynth model, we will need to import Tone.js
    (bound on `Tone`), Tensorflow.js (bound on `tf`), Magenta.js core (bound on `core`),
    and Magenta.js GANSynth (bound on `gansynth`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We won't talk about the differences between the ES5 and the ES6 bundles here.
    Just remember that the easiest way to go is to use the ES5 bundle method, importing
    one big file with everything. If you want more control over what is sent to the
    client (for performance reasons, for example), you'll want to use the ES6 bundle
    method. Remember that the module bindings are not the same between both methods,
    so you'll have to adapt your code if you change the imports.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the ES6 bundle imports for the GANSynth model only:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This imports only the GANSynth model, which can be instantiated using `new gansynth.GANSynth(...)`.
    When using ES6 modules, we need to import each script individually. For our example,
    these are Tone.js, TensorFlow.js, Magenta.js core, and GANSynth.
  prefs: []
  type: TYPE_NORMAL
- en: We'll stick with ES5 bundles for our example, but feel free to use ES6 bundles
    if you feel like it. We'll be showing where the code differs between each approach
    in our examples.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the ES6 code for this example in the `chapter_08_example_02_es6.html` file,
    in the source code of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's write the GANSynth code (in the `GANSynth code` comment), and explain
    each step.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling audio using GANSynth
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have properly imported Magenta.js, we can write the GANSynth audio
    generation code by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll initialize the DOM elements and initialize GANSynth, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we instantiate GANSynth using `mm.GANSynth(...)`. Remember, the Magenta.js
    context is under the `mm` variable when imported using an ES5 module. The URL
    for the checkpoint is the same that we've used in the previous chapter—[Chapter
    5](feb070b7-92ac-4762-a4ac-7c1a797a47ef.xhtml), *Audio Generation with NSynth
    and GANSynth*. Refer to that chapter if you want more information. We also make
    the reference to `ganSynth` globally so that we can call it later easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the Magenta.js ES6 bundle, we would have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: For the ES6 bundle, the module variable is `gansynth.GANSynth` instead of `mm.GANSynth`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s write an asynchronous function that will insert the generated spectrogram
    in the web page using a `canvas`, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This method creates a spectrogram plot and inserts it in a `canvas` element
    in the `containerPlots` elements we've previously declared. It will keep adding
    spectrograms for each generation.
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed the usage of `tf.tidy` and `dispose` in the example.
    Using those methods is necessary to avoid memory leaks in the TensorFlow.js code.
    This is because TensorFlow.js uses WebGL to make its computations, and **WebGL
    resources need to be explicitly reclaimed** after use. Any `tf.Tensor` needs to
    be disposed of after use by using `dispose`. The `tf.tidy` method can be used
    to dispose of all the tensors that are not returned by a function after executing
    it.
  prefs: []
  type: TYPE_NORMAL
- en: You might wonder what the `async` and `await` keywords are, in the previous
    JavaScript code. Those two keywords mark the usage of **asynchronous methods**.
    When calling a method that is marked with `async`, meaning it is asynchronous,
    the caller needs to mark the calls with `await`, meaning that it will wait (block)
    until a value is returned. The `await` keyword can be used only in `async` methods.
    In our example, the `mm.tf.browser.toPixels` method is marked with `async`, so
    we need to wait for its return using `await`. Calling an `async` method without
    using `await` can be done using the `Promise` syntax—`Promise.all([myAsyncMethod()])`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Promises were introduced in JavaScript to fix a recurring problem when writing
    asynchronous code: the **callback hell**. The callback hell is a problem that
    arises when multiple linked calls are all asynchronous, resulting in nested callbacks
    (from hell).'
  prefs: []
  type: TYPE_NORMAL
- en: Promises are great because they provide a clean mechanism to handle complex
    chains of asynchronous calls, as well as proper error handling. However, they
    are a bit verbose, which is why the `async` and `await` keywords were introduced
    as syntactic sugar, to alleviate some of the common use cases around using promises.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we write an asynchronous function that samples a note from GANSynth,
    plays it, and plots it using our previous method, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We first sample from GANSynth using the `randomSample` method, using a base
    pitch of `60`, which is C4, as an argument. This tells the model to sample a value
    corresponding to that pitch. Then, the returned spectrogram is converted to audio
    using `specgramsToAudio`. Finally, we use a Tone.js audio buffer to play the sample,
    by instantiating a new player using the audio buffer. Since we instantiate a new
    player for each sample, each new audio sample will get layered on top of the others.
  prefs: []
  type: TYPE_NORMAL
- en: The code to instantiate the player, `mm.Player.tone.Player`, is a bit convoluted
    since we first need to find the reference to Tone.js that was already instantiated
    by the Magenta.js object using `mm.Player.tone` (here, the `Player` reference
    is a Magenta.js class).
  prefs: []
  type: TYPE_NORMAL
- en: 'Using ES6 bundles is more straightforward, as can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Since the Magenta.js ES6 bundle doesn't include Tone.js, it is initialized on
    its own and can be referenced directly, using the `Tone` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s wrap up our example by binding the button to an action and
    initializing GANSynth, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: First, we bind our button the `sampleGanNote` method, then we initialize GANSynth,
    using the `startGanSynth` method.
  prefs: []
  type: TYPE_NORMAL
- en: Launching the web application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have our web application ready, we can test our code. Let''s open
    the HTML page we''ve created using a browser. We should see a page similar to
    the one shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4912ffc-37a4-4d40-afe7-9d5f9b1acd48.png)'
  prefs: []
  type: TYPE_IMG
- en: In the previous figure, we've already generated some GANSynth samples. Each
    generation plots two spectrograms and keeps the previous ones on the page. On
    the right side of the preceding screenshot, in the console debugger, you can see
    Tone.js and GANSynth initializing. When that is completed, the **Sample GANSynth
    note** button will get enabled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go ahead and generate sounds: you''ll get pretty interesting effects when layering
    many of them. Congratulations—you''ve completed your first Magenta.js web application!'
  prefs: []
  type: TYPE_NORMAL
- en: Generating a trio using MusicVAE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll now be using the MusicVAE model in Magenta.js to generate some sequences
    and play them directly in the browser, using Tone.js. The checkpoint we''ll be
    using is a `trio` model, meaning we''ll be generating three sequences at the same
    time: the drum kit, the bass, and the lead.'
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_03.html` file in the source
    code of this chapter. There are more comments and content in the source code—you
    should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the code is similar to the last section, we won''t be going through all
    the content, but we''ll explain the major differences:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s define the page structure and script imports, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The page has the same structure as the previous section. We'll be filling in
    the code in the `MusicVAE code` comment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, let''s initialize the MusicVAE model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The URL for the checkpoint is the same as the one we used in the previous chapter—[Chapter
    4](838da33e-26a9-4701-bfd3-5014dfff4146.xhtml), *Latent Space Interpolation with
    MusicVAE*. Refer to this chapter if you want more information on that checkpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now create a new Tone.js player to play the three generated sequences, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This code extends the `mm.BasePlayer` class in Magenta.js, which is useful
    because we only need to implement the `playNote` method to play the sequences.
    First, we define three synths: `bassDrumSynth`, `bassSynth`, and `leadSynth`,
    described here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **bass drum synth** only plays the bass drum, which is represented by the
    `note.isDrum` property and MIDI notes 35 or 36 and always plays a `C2` frequency
    for an 8-note length `8n`, using the `MembraneSynth` from Tone.js. Remember: in
    the MIDI specification for the percussion channel, the instruments (Bass Drum,
    Snare, etc.) are defined by the note''s pitch—for example, pitch 35 is Acoustic
    Bass Drum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **bass synth** only plays the programs from 32 to 39 inclusive, using the
    `Synth` from Tone.js with a triangle waveshape. Remember: from the MIDI specification,
    the program specifies which instrument should be played. For example, program
    1 is Acoustic Grand Piano, and program 33 is Acoustic Bass.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **lead synth** plays the other programs, using the `PolySynth` from Tone.js
    with five voices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One thing to notice for the bass and lead synths is that we first need to convert
    the MIDI note to a Tone.js frequency, using the `Frequency` class.
  prefs: []
  type: TYPE_NORMAL
- en: Another important thing to talk about is the **note envelope**, used on a synth
    in Tone.js with the `triggerAttackRelease` method. An envelope acts as a filter
    that will let the note be heard for a certain amount of time. You can think of
    a synthesizer as *always* *playing*, and the envelope—when closed—does not let
    the sound through. When opened, the envelope lets the sound be heard, using a
    certain **slope**, meaning the sound can come slowly (or fast), and end slowly
    (or fast). This is called, respectively, **the attack** and **the release** of
    the envelope. Each time we call the trigger method, the synth will be heard for
    the given duration, using a certain slope.
  prefs: []
  type: TYPE_NORMAL
- en: You might have already heard the term **Attack Decay Sustain Release** (**ADSR**)
    when talking about envelopes. In Tone.js, we are using a simplified version of
    this, using only the **Attack** and the **Release** of the envelope. With an ADSR
    envelope, we have more control over the resulting shape. For the sake of our example,
    we'll stick with the simplified version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now sample the MusicVAE model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: First, we sample the MusicVAE model using the `sample` method and an argument
    of 1, which is the number of required samples. We then plot the resulting note
    sequence, using an `mm.PianoRollCanvasVisualizer` in the previously declared `canvas`.
    Finally, we start the player with the sample at 120 QPM and loop the 8-second
    sequence, using the Tone.js `Transport` class. Remember that the MusicVAE models
    have fixed length, meaning that by using the 4-bar trio model, we generate 8-second
    samples at 120 QPM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s wrap up our example by binding the button to an action and
    initializing the MusicVAE model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: First, we bind our button the `sampleMusicVaeTrio` method, then we initialize
    the MusicVAE model using the `startMusicVae` method. You can see here that we
    are using the `Promise.all` call that we previously introduced to launch our asynchronous
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our web application ready, we can test our code. Let''s open
    the HTML page we''ve created using a browser. We should see a page similar to
    the one shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/23e2e0b7-42e4-4f8c-86ed-4efcad9bbbf5.png)'
  prefs: []
  type: TYPE_IMG
- en: By pressing the **Sample MusicVAE trio** button, the MusicVAE should sample
    a sequence, plot it, and play it using the synths we've defined. The generated
    plot is rather basic, since it doesn't differentiate the three instruments and
    has no time or pitch marker, but it can be customized using the `PianoRollCanvasVisualizer`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: To generate a new sequence, reload the page to start again.
  prefs: []
  type: TYPE_NORMAL
- en: Using a SoundFont for more realistic-sounding instruments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When listening to the generated sound, you might notice that the music sounds
    a bit *basic* or *simple*. That is because we've used the default synths in Tone.js,
    which have the advantage of being easy to use, with the downside of not sounding
    as good as more complex synths. Remember that the Tone.js synth can be customized
    to sound better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of using a synthesizer, we can also use a SoundFont. SoundFonts are
    recorded notes of various instruments, and we''ve been using them in FluidSynth
    since the beginning of this book. In Magenta.js, we can use the `SoundFontPlayer`
    for that purpose, instead of using the `Player` instance, as shown in the following
    code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The list of the SoundFonts hosted by the Magenta team can be found in the Magenta.js
    music README ([github.com/tensorflow/magenta-js/tree/master/music](https://github.com/tensorflow/magenta-js/tree/master/music)).
  prefs: []
  type: TYPE_NORMAL
- en: Playing generated instruments in a trio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have MusicVAE generating a three-instrument sequence and GANSynth
    generating audio, let's make the two work together.
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_04.html` file in the source
    code of this chapter. There are more comments and content in the source code—you
    should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the code is similar to the last section, we won''t be going through all
    the content, but we''ll explain the major differences:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s define the page structure and script imports, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The page has the same structure as the previous section. We'll be filling in
    the code in the `MusicVAE + GANSynth code` comment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, let''s initialize both the MusicVAE model and the GANSynth model, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, we only enable the **MusicVAE sampling** button. The **GANSynth sampling**
    button will get enabled when MusicVAE has completed its generation.
  prefs: []
  type: TYPE_NORMAL
- en: We keep the same `plotSpectra` method (from the previous example).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We keep the same `Player` class (from the previous example) for the sound synthesis.
    We can set `leadSynth = null` because it will get replaced by the GANSynth generation,
    but it is not necessary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We keep the same `sampleMusicVaeTrio` method (from the previous example), but
    we also set the instantiated player as a global variable using `window.player
    = player`, since GANSynth will need to change the lead synth later.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We rewrite the `sampleGanNote` method (from the previous example) to add a
    sample player, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: First, we sample a random instrument from GANSynth using `randomSample`, as
    in the previous example. Then, we need to play that sample in a Tone.js synth,
    so we use the `Sampler` class, which takes a dictionary containing a sample for
    each key. Because we sampled the model using the MIDI pitch 60, we are using a
    `C4` for the resulting audio buffer. Finally, we put that synth in our player
    using `window.player.leadSynth = instrument`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s wrap up our example by binding the buttons to their corresponding actions
    and initializing the MusicVAE and GANSynth models, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This code will start the models, bind the buttons, and update the button states.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our web application ready, we can test our code. Let''s open
    the HTML page we''ve created using a browser. We should see a page similar to
    the one shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/770e58ed-3a0b-41a1-8d4d-cbd2f754af69.png)'
  prefs: []
  type: TYPE_IMG
- en: By pressing the **Sample MusicVAE trio** button, the MusicVAE should sample
    a sequence, plot it, and play it using the synths we've defined. Then, the **Sample
    GANSynth note for the lead synth** button can be used to generate a new sound
    for the lead synth, which can be used multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: To generate a new sequence, reload the page to start again.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Web Workers API to offload computations from the UI thread
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you might have noticed from the previous example when you use the **Sample
    GANSynth note for the lead synth** button, the audio freezes (you won't hear any
    sound coming from MusicVAE) while GANSynth generates its first sample.
  prefs: []
  type: TYPE_NORMAL
- en: This is because JavaScript's concurrency is built on the event loop pattern,
    meaning that JavaScript is not multithreaded, and everything is executed in a
    single thread called the **UI thread.** This works well because JavaScript uses
    non-blocking I/O, meaning most of its costly operations complete immediately,
    and return their values using events and callbacks**.** Nonetheless, if a long
    computation is synchronous, it will block the UI thread while it executes, which
    is what happens when GANSynth generates its sample (see the previous *Introducing
    TensorFlow.js for machine learning in the browser* section, for more information
    on how Tensorflow handles computations using WebGL).
  prefs: []
  type: TYPE_NORMAL
- en: One solution to this is the **Web Workers API** ([html.spec.whatwg.org/multipage/workers.html](https://html.spec.whatwg.org/multipage/workers.html)),
    specified by the **Web Hypertext Application Technology Working Group** (**WHATWG**),
    which enables offloading computations to another thread that won't affect the
    UI thread. A web worker is basically a JavaScript file that gets started from
    the main thread and executes in its own thread. It can send and receive messages
    from the main thread. The Web Workers API is mature and well supported across
    browsers. You can read more about web workers in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_05.html` and `chapter_09_example_05.js` files
    in the source code of this chapter. There are more comments and content in the
    source code—you should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, at the time of writing, some parts of Magenta do not work well
    with web workers. We''ll be showing an example using the MusicVAE model, but we
    can''t show the same example using GANSynth, for example, because the model won''t
    load in a web worker. We still provide this example, since it can serve as a base
    for later use:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write the main page code. We''ll include only the JavaScript code from
    the full HTML page since we''ve covered the other parts in the previous sections.
    Proceed as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve already covered most of the code shown in the preceding block in the
    previous examples. Let''s break down the new content, covering the web worker
    creation and the message passing between the web worker and the main thread, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to start the worker, which is done by using `new Worker("chapter_09_example_05.js")`.
    This will execute the content of the JavaScript file and return a handle we can
    assign to a variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we bind the `onmessage` attribute on the worker, which will get called
    when the worker uses its `postMessage` function. In the `data` attribute of the
    `event` object, we can pass anything we want (see the worker''s code described
    here next):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the worker sends `initialized` as the first element of the `data` array,
    it means that the worker is initialized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the worker sends `sample` as the first element of the `data` array, it means
    the worker has sampled a MusicVAE sequence and is returning it as the second element
    of the `data` array.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, when the HTML button is clicked, we call the `postMessage` method on
    the worker instance (without arguments, but it needs—at least—an empty array),
    which will start the sampling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember that the web workers have no shared state with the main thread, meaning
    all data sharing needs to happen using the `onmessage` and `postMessage` methods
    or functions exclusively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s write the JavaScript worker''s code (which sits at the same location
    as the HTML file), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The first thing you notice here is that we are using Magenta's ES6 bundle since
    we cannot import everything in a web worker. By importing Tone.js, for example,
    we would get an error such as **This browser does not support Tone.js**. Also,
    remember that Magenta.js is not fully compatible yet with web workers, meaning
    importing GANSynth might result in an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we''ve already covered most of the code shown in the preceding block,
    we''ll just talk about the web worker additions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to send an `initialized` message to the main thread using `postMessage`
    when the model is ready to roll.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we bind on the module `onmessage` attribute, which will get called when
    the main thread sends the worker a message. Upon reception, we sample the MusicVAE
    model and then use `postMessage` to send the result back to the main thread.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This covers the basic usage of creating a web worker and making it exchange
    data with the main thread.
  prefs: []
  type: TYPE_NORMAL
- en: Using other Magenta.js models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As always, we cannot cover all models here, but the usage of other models will
    be similar to the examples we've provided. There are a lot of Magenta.js examples
    and demos on the internet, and some are very impressive music-generation web applications.
  prefs: []
  type: TYPE_NORMAL
- en: We provide resources to find examples and demos in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Making Magenta.js interact with other apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because Magenta.js sits in the browser, it is a bit harder to make it interact
    with other applications such as a DAWthan a Magenta application, but as web standards
    evolve, this will become easier.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Web MIDI API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Web MIDI API ([www.w3.org/TR/webmidi/](https://www.w3.org/TR/webmidi/))
    is a W3C standard with a specification that isn't very mature, with the status
    of *W3C Working Draft March 17, 2015*. It isn't well supported across browsers,
    with Firefox and Edge having no support at all. It works pretty well in Chrome,
    though, so if you require your users to use that browser, your application might
    work. See the last section, *Further reading*, for more information.
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_06.html` file, in the source
    code of this chapter. There are more comments and content in the source code—you
    should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll write a small example using the Web MIDI API, based on the previous
    example on MusicVAE and the trio sampling. You can copy the previous example and
    add the new content:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s add a `select` element to our page, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in the `startMusicVae` method, let''s initialize the list of available
    MIDI outputs, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the Magenta.js `MIDIPlayer` class, which makes usage of the `requestMIDIAccess`
    method easier than directly calling the Web MIDI API. Calling this method will
    return a list of `output` that we add, using the `name` attribute in the selection
    list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in the `sampleMusicVaeTrio` method, we use the player to send the
    MIDI directly to that output, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Here, we only need to set the `outputs` list with the element that was selected
    in the dropdown (if any).
  prefs: []
  type: TYPE_NORMAL
- en: 'To test our code, we can use our trusty FluidSynth, using the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Linux: `fluidsynth -a pulseaudio -g 1 PATH_TO_SF2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'macOS: `fluidsynth -a coreaudio -g 1 PATH_TO_SF2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Windows: `fluidsynth -g 1 PATH_TO_SF2`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: FluidSynth should start and show a terminal (notice we removed the `-n` and
    `-i` flags so that we can receive MIDI notes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s open our web application. Once the model is initialized, we should
    see the FluidSynth MIDI input port in the **Select MIDI output**—select drop-down
    list. It should look like this: **Synth input port (17921:0)**. Choose the option,
    and then click on **Sample MusicVAE trio**. You should hear the sound coming from
    FluidSynth.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll notice that all the notes are played as a piano sequence, even if we
    have three instruments. This is because the `MIDIPlayer` is pretty basic and won't
    send the percussion on the drums channel, as specified in the MIDI specification.
  prefs: []
  type: TYPE_NORMAL
- en: Running Magenta.js server side with Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Magenta.js can also be used server side, using Node.js. Using Node.js is nice
    because you can have the same (or almost the same) code running server side and
    client side. Communication between client and server can be handled using WebSockets.
  prefs: []
  type: TYPE_NORMAL
- en: The WebSocket API ([developer.mozilla.org/en-US/docs/Web/API/WebSockets_API](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API))
    is an API that makes it possible to open **two-way communications** between a
    client and a server. We won't be looking at WebSockets here, but they can be a
    good way of transferring the data back and forth between a server-side Magenta
    process (Magenta.js server side using Node.js, or Magenta in Python) and a client
    application. The easiest way of using WebSockets is to use a framework such as
    Socket.IO ([socket.io/](https://socket.io/)).
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of using Node.js is that our program is running server side,
    which means it isn't dependent on the browser's implementation. A good example
    of this is that we could use a Node.js package to handle sending MIDI to other
    processes, such as `node-midi` ([www.npmjs.com/package/midi](https://www.npmjs.com/package/midi)),
    which alleviates the necessity of using the Web MIDI API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s show a simple example of Magenta.js running with Node.js. The code shown
    here is similar to what we''ve already covered in JavaScript:'
  prefs: []
  type: TYPE_NORMAL
- en: You can find this code in the `chapter_08_example_07.js` file in the source
    code of this chapter. There are more comments and content in the source code—you
    should go and check it out.
  prefs: []
  type: TYPE_NORMAL
- en: First, let's install Node.js ([nodejs.org/en/download/](https://nodejs.org/en/download/))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, let''s install Magenta.js, using the `npm` command, which is the Node.js
    dependency manager, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This will install Magenta.js and its dependencies in the `node_modules` directory.
    When Node.js runs, it looks in this directory to find the script's dependencies,
    for each `require` call.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now create a JavaScript file to sample a sequence, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This code is similar to the previous examples, the only addition being the `require`
    method, which is used in Node.js to import a dependency module.
  prefs: []
  type: TYPE_NORMAL
- en: 'To execute your Node.js application, use the `node` command (replacing `PATH_TO_JAVASCRIPT_FILE`
    by a proper value), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The sample should show on the console because we''ve used `console.log`. You
    will also notice a couple of messages on the console, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: This reminds us that Tone.js cannot be run on Node.js, because the Web Audio
    API is implemented client side. It also reminds us that Node.js can use CUDA libraries
    for better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've looked at Tensorflow.js and Magenta.js, the JavaScript
    implementations of TensorFlow and Magenta. We've learned that TensorFlow.js is
    GPU accelerated using WebGL and that Magenta.js has a limited set of models available
    that can only be used for generation, not training. We've converted a Python-trained
    model from the previous chapter to a format that TensorFlow.js can load. We've
    also introduced Tone.js and the Web Audio API, which is used by Magenta.js to
    synthesize sound in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we've created three music generation web applications. The first application
    used GANSynth to sample short audio notes. By doing so, we've learned how to import
    the required scripts, either using a big ES5 bundle or a smaller, split up, ES6
    bundle. The second application used MusicVAE to sample a trio of instruments,
    with the drum kit, the bass, and the lead, and played the sequence in a loop.
    The third application used both models to generate sequences and audio together
    and introduced the usage of the Web Workers API to offload computations to another
    thread.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we've talked about how to make Magenta.js interact with other applications.
    We've used the Web MIDI API to send the generated sequences to another synthesizer—for
    example, FluidSynth. We've also used Node.js to run a Magenta.js application server
    side.
  prefs: []
  type: TYPE_NORMAL
- en: Magenta.js is a great project because it makes it easy to create and share music-generation
    applications using web technologies. There are other ways of making Magenta fit
    in a broader context, such as using Magenta Studio (which makes Magenta run in
    Ableton Live) and using MIDI, which is a good way of controlling all types of
    devices, such as software and hardware synthesizers. We'll be showing those subjects
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Can a model be trained using Tensorflow.js? Using Magenta.js?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the Web Audio API do, and what is the easiest way of using it?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the generation method in GANSynth? What is the argument that needs to
    be provided?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the generation method in MusicVAE? How many instruments does it generate?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is the Web Workers API useful in JavaScript?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name two ways of sending MIDI from a Magenta.js application to another application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**MagentaMusic.js demos**: A Magenta-maintained list of demos using the various
    models and core classes in Magenta.js ([tensorflow.github.io/magenta-js/music/demos/](https://tensorflow.github.io/magenta-js/music/demos/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web apps built with Magenta.js**: A community-driven list of demos using
    Magenta.js, with lots of cool stuff ([magenta.tensorflow.org/demos/web/](https://magenta.tensorflow.org/demos/web/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monica Dinculescu—Why you should build silly things**: Interesting talk on
    the importance of Magenta.js and sharing music-creation applications ([www.youtube.com/watch?v=DkiFjzQgJtg](https://www.youtube.com/watch?v=DkiFjzQgJtg)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Celebrating Johann Sebastian Bach**: A good example of a popular music-generation
    application ([www.google.com/doodles/celebrating-johann-sebastian-bach](https://www.google.com/doodles/celebrating-johann-sebastian-bach)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**WebGL Specifications**: The WebGL specification ([www.khronos.org/registry/webgl/specs/latest/](https://www.khronos.org/registry/webgl/specs/latest/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform and environment**: An interesting read on memory management and
    GPU computations using WebGL in TensorFlow.js ([www.tensorflow.org/js/guide/platform_environment](https://www.tensorflow.org/js/guide/platform_environment)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web Audio API**: The Web Audio API specification from the W3C ([webaudio.github.io/web-audio-api/](https://webaudio.github.io/web-audio-api/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web Audio API**: An introduction to the Web Audio API ([developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web Workers**: The Web Workers API specification from the WHATWG ([html.spec.whatwg.org/multipage/workers.html](https://html.spec.whatwg.org/multipage/workers.html)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concurrency model and the event loop**: An introduction to the event loop
    pattern in JavaScript ([developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop](https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using Web Workers**: An introduction to the Web Workers API ([developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web MIDI API**: The Web MIDI API specification for the W3C ([webaudio.github.io/web-midi-api/](https://webaudio.github.io/web-midi-api/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web MIDI (MIDI Support in Web Browsers)**: An introduction to the Web MIDI
    API from the MIDI Association, with examples of applications using it ([www.midi.org/17-the-mma/99-web-midi](https://www.midi.org/17-the-mma/99-web-midi)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
