- en: 3D Deep Learning with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Design and develop your computer vision model with 3D data using PyTorch3D and
    more
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Xudong Ma
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Vishakh Hegde
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Lilit Yolyan
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Packt_Logo_SuperSite_2022_Orange.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: BIRMINGHAM—MUMBAI
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 3D Deep Learning with Python
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Copyright © 2022 Packt Publishing
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '*All rights reserved*. No part of this book may be reproduced, stored in a
    retrieval system, or transmitted in any form or by any means, without the prior
    written permission of the publisher, except in the case of brief quotations embedded
    in critical articles or reviews.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Every effort has been made in the preparation of this book to ensure the accuracy
    of the information presented. However, the information contained in this book
    is sold without warranty, either express or implied. Neither the authors, nor
    Packt Publishing or its dealers and distributors, will be held liable for any
    damages caused or alleged to have been caused directly or indirectly by this book.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Packt Publishing has endeavored to provide trademark information about all of
    the companies and products mentioned in this book by the appropriate use of capitals.
    However, Packt Publishing cannot guarantee the accuracy of this information.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**Publishing Product Manager**: Dinesh Chaudhary'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Content Development Editor**: Joseph Sunil'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**Technical Editor**: Rahul Limbachiya'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '**Copy Editor**: Safis Editing'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Project Coordinator**: Farheen Fathima'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '**Proofreader**: Safis Editing'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**Indexer**: Rekha Nair'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '**Production Designer**: Ponraj Dhandapani'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '**Marketing Coordinator**: Shifa Ansari'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'First published: November 2022'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Production reference: 1211022'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Published by Packt Publishing Ltd.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Livery Place
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 35 Livery Street
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Birmingham
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: B3 2PB, UK.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: ISBN 978-1-80324-782-3
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[www.packt.com](http://www.packt.com)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '"To my wife and family, for their support and encouragement at every step".
    - Vishakh Hegde'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '"To my family and friends, whose love and support have been my biggest motivation".
    - Lilit Yolyan'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Contributors
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About the author
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Xudong Ma** is a Staff Machine Learning engineer with Grabango Inc. in Berkeley
    California. He was a Senior Machine Learning Engineer at Facebook (Meta) Oculus
    and worked closely with the 3D PyTorch Team on 3D facial tracking projects. He
    has many years of experience working on computer vision, machine learning, and
    deep learning and holds a Ph.D. in Electrical and Computer Engineering.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '**Vishakh Hegde** is a Machine Learning and Computer Vision researcher. He
    has over 7 years of experience in the field, during which he has authored multiple
    well-cited research papers and published patents. He holds a masters from Stanford
    University specializing in applied mathematics and machine learning, and a BS
    and MS in Physics from IIT Madras. He previously worked at Schlumberger and Matroid.
    He is a Senior Applied Scientist at Ambient.ai, where he helped build their weapon
    detection system which is deployed at several Global Fortune 500 companies. He
    is now leveraging his expertise and passion for solving business challenges to
    build a technology startup in Silicon Valley. You can learn more about him on
    his website.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: I would like to thank the computer vision researchers whose breakthrough research
    I got to write about. I want to thank the reviewers for their feedback and the
    wonderful team at Packt Publishing for giving me the chance to be creative. Finally,
    I want to thank my wife and family for all their support and encouragement when
    I most needed it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Lilit Yolyan** is a machine learning researcher working on her Ph.D. at YSU.
    Her research focuses on building computer vision solutions for smart cities using
    remote sensing data. She has 5 years of experience in the field of computer vision
    and has worked on a complex driver safety solution to be deployed by many well-known
    car manufacturing companies.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: About the reviewer
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Eya Abid** is a Masters of Engineering student specializing in Deep Learning
    and Computer Vision. She holds the position of an AI instructor within NVIDIA
    and quantum machine learning at CERN.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: I would like to dedicate this work first to my family, friends, and whoever
    helped me through this process. A special dedication to Aymen, to whom I am forever
    grateful.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '**Ramesh Sekhar** is the CEO and co-founder of Dapster.ai, a company that builds
    affordable and easily deployable robots that perform the most arduous tasks in
    warehouses. Ramesh has worked at companies like Symbol, Motorola, and Zebra and
    specializes in building products at the intersection of computer vision, AI, and
    Robotics. He has a BS in Electrical Engineering and an MS in Computer Science.
    Ramesh founded Dapster.ai in 2020\. Dapster’s mission is to build robots that
    positively impact human beings by performing dangerous and unhealthy tasks. Their
    vision is to unlock better jobs, fortify supply chains, and better negotiate the
    challenges arising from climate change.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**Utkarsh Srivastava** is an AI/ML professional, trainer, YouTuber, and blogger.
    He loves to tackle and develop ML, NLP, and computer vision algorithms to solve
    complex problems. He started his data science career as a blogger on his blog
    (datamahadev.com) and YouTube channel (datamahadev), followed by working as a
    senior data science trainer at an institute in Gujarat. Additionally, he has trained
    and counseled 1,000+ working professionals and students in AI/ML. Utkarsh has
    completed 40+ freelance training and development work/projects in data science
    and analytics, AI/ML, Python development, and SQL. He hails from Lucknow and is
    currently settled in Bangalore, India, as an analyst at Deloitte USI Consulting.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: I would like to thank my mother, Mrs. Rupam Srivastava, for her continuous guidance
    and support throughout my hardships and struggles. Thanks also to the Supreme
    Para-Brahman.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '**Mason McGough** is a Sr. R&D Engineer and Computer Vision Specialist at Lowe’s
    Innovation Labs. He has a passion for imaging and has spent over a decade solving
    computer vision problems across a broad range of industrial and academic disciplines
    including geology, bio-informatics, game development, and retail. Most recently
    he is exploring the use of Digital Twins and 3D scanning for retail stores.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: I wish to thank Andy Lykos, Joseph Canzano, Alexander Arango, Oleg Alexander,
    Erin Clark, and my family for their support.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Preface](B18217_Preface_eBook.xhtml#_idTextAnchor004)'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PART 1: 3D Data Processing Basics](B18217_Part_1.xhtml#_idTextAnchor014)'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1](B18217_01.xhtml#_idTextAnchor015)'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Introducing 3D Data Processing](B18217_01.xhtml#_idTextAnchor016)'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_01.xhtml#_idTextAnchor017)'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Setting up a development environment](B18217_01.xhtml#_idTextAnchor018)'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[3D data representation](B18217_01.xhtml#_idTextAnchor019)'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding point cloud representation](B18217_01.xhtml#_idTextAnchor020)'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding mesh representation](B18217_01.xhtml#_idTextAnchor021)'
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding voxel representation](B18217_01.xhtml#_idTextAnchor022)'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[3D data file format – Ply files](B18217_01.xhtml#_idTextAnchor023)'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[3D data file format – OBJ files](B18217_01.xhtml#_idTextAnchor025)'
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding 3D coordination systems](B18217_01.xhtml#_idTextAnchor026)'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding camera models](B18217_01.xhtml#_idTextAnchor027)'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Coding for camera models and coordination systems](B18217_01.xhtml#_idTextAnchor028)'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_01.xhtml#_idTextAnchor029)'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[2](B18217_02.xhtml#_idTextAnchor030)'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Introducing 3D Computer Vision and Geometry](B18217_02.xhtml#_idTextAnchor031)'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_02.xhtml#_idTextAnchor032)'
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring the basic concepts of rendering, rasterization, and shading](B18217_02.xhtml#_idTextAnchor033)'
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding barycentric coordinates](B18217_02.xhtml#_idTextAnchor034)'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Light source models](B18217_02.xhtml#_idTextAnchor035)'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding the Lambertian shading model](B18217_02.xhtml#_idTextAnchor036)'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding the Phong lighting model](B18217_02.xhtml#_idTextAnchor037)'
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Coding exercises for 3D rendering](B18217_02.xhtml#_idTextAnchor038)'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Using PyTorch3D heterogeneous batches and PyTorch optimizers](B18217_02.xhtml#_idTextAnchor039)'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A coding exercise for a heterogeneous mini-batch](B18217_02.xhtml#_idTextAnchor040)'
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding transformations and rotations](B18217_02.xhtml#_idTextAnchor042)'
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A coding exercise for transformation and rotation](B18217_02.xhtml#_idTextAnchor043)'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_02.xhtml#_idTextAnchor044)'
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PART 2: 3D Deep Learning Using PyTorch3D](B18217_Part_2.xhtml#_idTextAnchor045)'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[3](B18217_03.xhtml#_idTextAnchor046)'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Fitting Deformable Mesh Models to Raw Point Clouds](B18217_03.xhtml#_idTextAnchor047)'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_03.xhtml#_idTextAnchor048)'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Fitting meshes to point clouds – the problem](B18217_03.xhtml#_idTextAnchor049)'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Formulating a deformable mesh fitting problem into an optimization problem](B18217_03.xhtml#_idTextAnchor050)'
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Loss functions for regularization](B18217_03.xhtml#_idTextAnchor051)'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Mesh Laplacian smoothing loss](B18217_03.xhtml#_idTextAnchor052)'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Mesh normal consistency loss](B18217_03.xhtml#_idTextAnchor053)'
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Mesh edge loss](B18217_03.xhtml#_idTextAnchor054)'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Implementing the mesh fitting with PyTorch3D](B18217_03.xhtml#_idTextAnchor055)'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[The experiment of not using any regularization loss functions](B18217_03.xhtml#_idTextAnchor056)'
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[The experiment of using only the mesh edge loss](B18217_03.xhtml#_idTextAnchor057)'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_03.xhtml#_idTextAnchor058)'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[4](B18217_04.xhtml#_idTextAnchor059)'
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Learning Object Pose Detection and Tracking by Differentiable Rendering](B18217_04.xhtml#_idTextAnchor060)'
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_04.xhtml#_idTextAnchor062)'
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Why we want to have differentiable rendering](B18217_04.xhtml#_idTextAnchor063)'
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How to make rendering differentiable](B18217_04.xhtml#_idTextAnchor064)'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[What problems can be solved by using differentiable rendering](B18217_04.xhtml#_idTextAnchor065)'
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[The object pose estimation problem](B18217_04.xhtml#_idTextAnchor066)'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How it is coded](B18217_04.xhtml#_idTextAnchor067)'
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[An example of object pose estimation for both silhouette fitting and texture
    fitting](B18217_04.xhtml#_idTextAnchor068)'
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_04.xhtml#_idTextAnchor069)'
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5](B18217_05.xhtml#_idTextAnchor070)'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Understanding Differentiable Volumetric Rendering](B18217_05.xhtml#_idTextAnchor071)'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_05.xhtml#_idTextAnchor073)'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Overview of volumetric rendering](B18217_05.xhtml#_idTextAnchor074)'
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding ray sampling](B18217_05.xhtml#_idTextAnchor075)'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Using volume sampling](B18217_05.xhtml#_idTextAnchor076)'
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring the ray marcher](B18217_05.xhtml#_idTextAnchor077)'
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Differentiable volumetric rendering](B18217_05.xhtml#_idTextAnchor078)'
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Reconstructing 3D models from multi-view images](B18217_05.xhtml#_idTextAnchor079)'
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_05.xhtml#_idTextAnchor080)'
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[6](B18217_06.xhtml#_idTextAnchor081)'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Exploring Neural Radiance Fields (NeRF)](B18217_06.xhtml#_idTextAnchor082)'
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_06.xhtml#_idTextAnchor083)'
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding NeRF](B18217_06.xhtml#_idTextAnchor084)'
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[What is a radiance field?](B18217_06.xhtml#_idTextAnchor085)'
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Representing radiance fields with neural networks](B18217_06.xhtml#_idTextAnchor086)'
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Training a NeRF model](B18217_06.xhtml#_idTextAnchor087)'
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding the NeRF model architecture](B18217_06.xhtml#_idTextAnchor088)'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding volume rendering with radiance fields](B18217_06.xhtml#_idTextAnchor089)'
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Projecting rays into the scene](B18217_06.xhtml#_idTextAnchor090)'
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Accumulating the color of a ray](B18217_06.xhtml#_idTextAnchor091)'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_06.xhtml#_idTextAnchor092)'
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PART 3: State-of-the-art 3D Deep Learning Using PyTorch3D](B18217_Part_3.xhtml#_idTextAnchor093)'
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[7](B18217_07.xhtml#_idTextAnchor094)'
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Exploring Controllable Neural Feature Fields](B18217_07.xhtml#_idTextAnchor095)'
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_07.xhtml#_idTextAnchor096)'
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding GAN-based image synthesis](B18217_07.xhtml#_idTextAnchor097)'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introducing compositional 3D-aware image synthesis](B18217_07.xhtml#_idTextAnchor098)'
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Generating feature fields](B18217_07.xhtml#_idTextAnchor099)'
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Mapping feature fields to images](B18217_07.xhtml#_idTextAnchor100)'
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring controllable scene generation](B18217_07.xhtml#_idTextAnchor101)'
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring controllable car generation](B18217_07.xhtml#_idTextAnchor102)'
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring controllable face generation](B18217_07.xhtml#_idTextAnchor103)'
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Training the GIRAFFE model](B18217_07.xhtml#_idTextAnchor104)'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Frechet Inception Distance](B18217_07.xhtml#_idTextAnchor105)'
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Training the model](B18217_07.xhtml#_idTextAnchor106)'
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_07.xhtml#_idTextAnchor107)'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[8](B18217_08.xhtml#_idTextAnchor108)'
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Modeling the Human Body in 3D](B18217_08.xhtml#_idTextAnchor109)'
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_08.xhtml#_idTextAnchor110)'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Formulating the 3D modeling problem](B18217_08.xhtml#_idTextAnchor111)'
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Defining a good representation](B18217_08.xhtml#_idTextAnchor112)'
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding the Linear Blend Skinning technique](B18217_08.xhtml#_idTextAnchor113)'
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding the SMPL model](B18217_08.xhtml#_idTextAnchor114)'
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Defining the SMPL model](B18217_08.xhtml#_idTextAnchor115)'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Using the SMPL model](B18217_08.xhtml#_idTextAnchor116)'
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Estimating 3D human pose and shape using SMPLify](B18217_08.xhtml#_idTextAnchor118)'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Defining the optimization objective function](B18217_08.xhtml#_idTextAnchor119)'
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring SMPLify](B18217_08.xhtml#_idTextAnchor120)'
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Running the code](B18217_08.xhtml#_idTextAnchor121)'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring the code](B18217_08.xhtml#_idTextAnchor122)'
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Summary](B18217_08.xhtml#_idTextAnchor123)'
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[9](B18217_09.xhtml#_idTextAnchor124)'
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Performing End-to-End View Synthesis with SynSin](B18217_09.xhtml#_idTextAnchor125)'
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Technical requirements](B18217_09.xhtml#_idTextAnchor126)'
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Overview of view synthesis](B18217_09.xhtml#_idTextAnchor127)'
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[SynSin network architecture](B18217_09.xhtml#_idTextAnchor128)'
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[SynSin 网络架构](B18217_09.xhtml#_idTextAnchor128)'
- en: '[Spatial feature and depth networks](B18217_09.xhtml#_idTextAnchor129)'
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[空间特征与深度网络](B18217_09.xhtml#_idTextAnchor129)'
- en: '[Neural point cloud renderer](B18217_09.xhtml#_idTextAnchor130)'
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[神经点云渲染器](B18217_09.xhtml#_idTextAnchor130)'
- en: '[Refinement module and discriminator](B18217_09.xhtml#_idTextAnchor131)'
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[细化模块与鉴别器](B18217_09.xhtml#_idTextAnchor131)'
- en: '[Hands-on model training and testing](B18217_09.xhtml#_idTextAnchor132)'
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[实践模型训练与测试](B18217_09.xhtml#_idTextAnchor132)'
- en: '[Summary](B18217_09.xhtml#_idTextAnchor133)'
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_09.xhtml#_idTextAnchor133)'
- en: '[10](B18217_10.xhtml#_idTextAnchor134)'
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[10](B18217_10.xhtml#_idTextAnchor134)'
- en: '[Mesh R-CNN](B18217_10.xhtml#_idTextAnchor135)'
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[Mesh R-CNN](B18217_10.xhtml#_idTextAnchor135)'
- en: '[Technical requirements](B18217_10.xhtml#_idTextAnchor136)'
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[技术要求](B18217_10.xhtml#_idTextAnchor136)'
- en: '[Overview of meshes and voxels](B18217_10.xhtml#_idTextAnchor137)'
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格与体素概述](B18217_10.xhtml#_idTextAnchor137)'
- en: '[Mesh R-CNN architecture](B18217_10.xhtml#_idTextAnchor138)'
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[Mesh R-CNN 架构](B18217_10.xhtml#_idTextAnchor138)'
- en: '[Graph convolutions](B18217_10.xhtml#_idTextAnchor139)'
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[图卷积](B18217_10.xhtml#_idTextAnchor139)'
- en: '[Mesh predictor](B18217_10.xhtml#_idTextAnchor140)'
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[网格预测器](B18217_10.xhtml#_idTextAnchor140)'
- en: '[Demo of Mesh R-CNN with PyTorch](B18217_10.xhtml#_idTextAnchor141)'
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[PyTorch 下的 Mesh R-CNN 演示](B18217_10.xhtml#_idTextAnchor141)'
- en: '[Demo](B18217_10.xhtml#_idTextAnchor142)'
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[演示](B18217_10.xhtml#_idTextAnchor142)'
- en: '[Summary](B18217_10.xhtml#_idTextAnchor143)'
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[总结](B18217_10.xhtml#_idTextAnchor143)'
- en: '[Index](B18217_Index.xhtml#_idTextAnchor144)'
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[索引](B18217_Index.xhtml#_idTextAnchor144)'
- en: '[Other Books You May Enjoy](B18217_BM_eBook.xhtml#_idTextAnchor146)'
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[您可能喜欢的其他书籍](B18217_BM_eBook.xhtml#_idTextAnchor146)'
