<html><head></head><body>
  <div id="_idContainer400">
    <h1 class="chapterNumber">16</h1>
    <h1 id="_idParaDest-312" class="chapterTitle">Improving the Emotional Intelligence Deficiencies of Chatbots</h1>
    <p class="normal">Emotions remain irrational and subjective. AI algorithms never forsake rationality and objectivity. Cognitive dissonance ensues, which complicates the task of producing an efficient chatbot.</p>
    <p class="normal">In <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>, we built a rational chained algorithm process with an RBM and a PCA approach. From there, we extracted critical objective data on a market segment. From that market segment and its features, we then designed a dialog in <em class="italics">Chapter 15</em>, <em class="italics">Setting Up a Cognitive NLP UI/CUI Chatbot</em>. The dialog was rational, and we produced a probable choice of services for the user. We did this out of good faith, to make the path from a request to its outcome as short as possible. It was a <em class="italics">yes</em> path in which everything went smoothly.</p>
    <p class="normal">In this chapter, we will confront human nature with unexpected reactions. A <em class="italics">no</em> path will challenge our dialog. One of the problems we face resides in emotional polysemy, confusing emotional signals from a user.</p>
    <p class="normal">We will address the <em class="italics">no</em> unexpected path with information drawn from <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBM) and Principal Component Analysis (PCA)</em> and <em class="italics">Chapter 15</em>, <em class="italics">Setting up a Cognitive NLP UI/CUI Chatbot</em>, and go into the world of data logging. </p>
    <p class="normal">Data logging will provide critical contextual data to satisfy the user. The goal will be to create emotions, not just react randomly to a user's emotional state.</p>
    <p class="normal">Finally, we will open the door to researching ways to generate text automatically through RNN-LSTM approaches. The idea will be to create automatic dialogs in the future based on data logging.</p>
    <p class="normal">The following topics will be covered in this chapter:</p>
    <ul>
      <li class="list">Emotional polysemy</li>
      <li class="list">Small talk</li>
      <li class="list">Data logging</li>
      <li class="list">Creating emotions</li>
      <li class="list">Exploring RNN-LSTM approaches</li>
    </ul>
    <p class="normal">We will first explore the difference between simply reacting to emotions and creating emotions.</p>
    <h1 id="_idParaDest-313" class="title">From reacting to emotions, to creating emotions</h1>
    <p class="normal">Designing a chatbot that reacts to what a user expresses is one thing. But creating emotions during a dialog like a human does requires deeper understanding of how a chatbot manages emotions. Let's start with emotional polysemy.</p>
    <h2 id="_idParaDest-314" class="title">Solving the problems of emotional polysemy</h2>
    <p class="normal">We will be <a id="_idIndexMarker777"/>enhancing the emotional intelligence of a chatbot starting by addressing the issue of emotional polysemy. We are used to defining polysemy with words, not emotions, in the sense that polysemy is the capacity of a word to have multiple meanings. In <em class="italics">Chapter 6</em>, <em class="italics">How to Use Decision Trees to Enhance K-Means Clustering</em>, we explored the confusion that arose with the word "coach." "Coach" can mean a bus or a sports trainer, which leads to English to French translation issues.</p>
    <p class="normal">Polysemy also applies to the interpretation of emotions by artificial intelligence. We will explore this domain with two examples: greetings and affirmations.</p>
    <p class="normal">Then we will go through the speech recognition and facial analysis as silver bullet solutions fallacies that mislead us into thinking it's easy to read emotions on faces.</p>
    <h3 id="_idParaDest-315" class="title">The greetings problem example</h3>
    <p class="normal">To implement this <a id="_idIndexMarker778"/>chapter, open Dialogflow and go to the agent named <code class="Code-In-Text--PACKT-">cogfilm+&lt;your unique ID&gt;</code> created in <em class="italics">Chapter 15</em>, <em class="italics">Setting Up a Cognitive NLP UI/CUI Chatbot</em>.</p>
    <p class="normal">Suppose somebody types "Hi" to a chatbot agent. Almost everybody will think that this is a good beginning. But is it really?</p>
    <p class="normal">Let's explore some of the many possible interpretations:</p>
    <ul>
      <li class="list"><strong class="bold">"Hi" meaning the person is very tense and irritated</strong>: This could be the case of a top manager who never uses "Hi" to say hello, does not like chatbots, or doubts that the one that is being tested is worth anything at all.<p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">This manager usually says, "Good morning," "Good afternoon," and "Good evening."</p>
      </li>
      <li class="list"><strong class="bold">"Hi" meaning "So what?"</strong>: It is more like, "Yeah, hi." This could be a person, P, who dislikes person Q who just said good morning to P.</li>
      <li class="list"><strong class="bold">"Hi," meaning "I'm in trouble."</strong>: This could be a usually chirpy, happy person who says, "Hello, everyone. How are things going today?" But today, it's just a brief "Hi." This will trigger alert reactions from others, such as "Are you okay?," "Is something wrong?"</li>
      <li class="list"><strong class="bold">"Hi," meaning "I'm trying to be nice."</strong>: This could be a person that is usually grumpy in the morning and just sits down and stares down a laptop until the caffeine in their coffee kicks in. But today, this person comes in totally in shape, wide awake, and says, "Hi." This might trigger alert reactions from others such as, "Somebody had a great evening or night! Am I wrong?", with some laughter from the others.</li>
    </ul>
    <p class="normal">I could go on with<a id="_idIndexMarker779"/> literally hundreds of other situations and uses of "Hi." Why? Because humans have an indefinite number of behaviors that can be reflected in that first "Hi" in an encounter.</p>
    <p class="normal">This could apply to ending a conversation without saying "bye" or saying it in many ways. The way a person says goodbye to another person in the morning can have an incredible number of significations.</p>
    <p class="normal">This is therefore one of our challenges. Before we go further with this, let's look at one more challenge by considering the affirmation example.</p>
    <h3 id="_idParaDest-316" class="title">The affirmation example</h3>
    <p class="normal">Suppose <a id="_idIndexMarker780"/>somebody types or says "Yes" in a chatbot. Does that really mean "Yes"?</p>
    <ul>
      <li class="list"><strong class="bold">"Yes", as in "Yeah, whatever."</strong>: The user hates the chatbot. The dialog is boring. The user is thinking that if they do not say "Yes" and get it over with, this dialog will go on forever.</li>
      <li class="list"><strong class="bold">"Yes", as in "I'm afraid to say no."</strong>: The user does not want to say "Yes." The question could be, "Are you satisfied with your job?" The user could fear the answers are logged and monitored. The user fears sanctions. Although this person hates their job, the answer will be "Yes" or might even be "I sure do!"</li>
      <li class="list"><strong class="bold">"Yes" as a good faith "yes" that a person regrets right after</strong>: A person says "Yes" to a purchase, stimulated by the ad pressure at that moment in the chatbot. But minutes later, the same person thinks, "Why did I say yes and buy that?" Therefore, some platforms allow refunds even before the product or service is delivered.</li>
    </ul>
    <p class="normal">Just as for "Hi," I could<a id="_idIndexMarker781"/> list hundreds of situations of emotional polysemy with "Yes."</p>
    <p class="normal">Now, that we have understood the challenge at hand, let's explore the silver bullet fallacies mentioned previously.</p>
    <h3 id="_idParaDest-317" class="title">The speech recognition fallacy</h3>
    <p class="normal">Many editors and<a id="_idIndexMarker782"/> developers believe that speech recognition will solve the problem of emotional intelligence by detecting the tone of a voice.</p>
    <p class="normal">However, emotional polysemy applies to the tone of voice, as well. Human beings tend to hide their emotions when they feel threatened, and open up when they trust their environment.</p>
    <p class="normal">Let's go back to the "Hi" and "Yes" examples.</p>
    <p class="normal"><strong class="bold">"Hi" in a chirpy tone</strong>: A person, X, comes into an office, for example. Somebody says, "Oh, hi there! Great to see you!" Person Y answers "Hi" in a very happy tone. Google Home or Amazon Alexa, in their research lab, produces 0.9 probability that the conversation is going well.</p>
    <p class="normal">This could be true. Or it could be false.</p>
    <p class="normal">For example, person Y hates person X. Person X knows it and says, "Great to see you!" on purpose. Person Y knows that person X knows that they hate each other but won't give in to bursting out first. So person "Y" answers "Hi" in a super-happy tone.</p>
    <p class="normal">At that point, many turn to facial analysis.</p>
    <h3 id="_idParaDest-318" class="title">The facial analysis fallacy</h3>
    <p class="normal">Emotional polysemy also<a id="_idIndexMarker783"/> applies to facial analysis. Many think that deep learning facial analysis will solve the polysemy problem.</p>
    <p class="normal">I saw a post recently by a developer with a picture of an obviously forced smile with the text stating that happiness could be detected with DL facial analysis!</p>
    <p class="normal">Let's take two basic facial expressions and explore them: a smile and a frown. By now, you know that emotional polysemy will apply to both cases.</p>
    <h4 class="title">A smile</h4>
    <p class="normal">If <a id="_idIndexMarker784"/>somebody smiles and a DL facial analysis algorithm detects that smile, it means the person is happy. Is this true? Maybe. Maybe not.</p>
    <p class="normal">Maybe the person is happy. Maybe the smile is ironic, meaning "Yeah, sure, dream if you want, but I don't agree!" It could mean "Get out of my way," or, "I'm happy because I'm going to hurt you," or, "I'm happy to see you." Who knows?</p>
    <p class="normal">The truth is that nobody knows, and sometimes even the person that smiles doesn't know. Sometimes a person will think, "Why did I smile at her/him? I hate her/him!"</p>
    <h4 class="title">A frown</h4>
    <p class="normal">If somebody <a id="_idIndexMarker785"/>frowns and a DL facial analysis algorithm detects that frown, it means the person is sad or unhappy. Is that true? Maybe. Maybe not.</p>
    <p class="normal">Maybe the person is happy that day. Things are going smoothly, and the person just forgot a book, for example, at home before coming to this location. Maybe the second after the person will smile, thinking, "So what? It's a great day and I don't care!"</p>
    <p class="normal">Maybe the person is unhappy. Maybe the person is having a great time watching some kind of ball game, and their favorite player missed something. The second after, the person thinks "Oh, so what? My team is winning anyway," and smiles. Some people just frown if they're thinking hard, but it doesn't mean they're unhappy.</p>
    <p class="normal">We can now see that there are thousands of cases of emotional polysemy that occur with words, tone of voice, and facial expressions, and therefore there is no magical solution that is going to suddenly overcome the inherent difficulty that AI have when it comes to interpreting people's emotions.</p>
    <p class="normal">We will now explore some realistic solutions to this problem.</p>
    <h2 id="_idParaDest-319" class="title">Small talk</h2>
    <p class="normal">Small talk is not a<a id="_idIndexMarker786"/> silver bullet to solve the emotional intelligence problem of chatbots at all. In fact, even without speaking about chatbots, we all suffer from emotional distress in one situation or another. Small talk adds little unimportant phrases to a dialog such as "wow," "cool," "oops," "great," and more.</p>
    <p class="normal"><em class="italics">We do not need to seek perfection, but show goodwill</em>. Every human knows the difficulty of emotional intelligence and polysemy. A human can accept an error in a dialog if goodwill is shown by the other party to make up for that error.</p>
    <p class="normal">Small talk is a<a id="_idIndexMarker787"/> little step in making amends to show goodwill.</p>
    <p class="normal">To achieve the "making customers happy" purpose, scroll down the main menu to <strong class="screen-text">Small Talk</strong>, click on that option, and enable it, as shown in the following screenshot. We will be focusing on <strong class="screen-text">Courtesy</strong> and <strong class="screen-text">Emotions</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.1: Small Talk in menu</p>
    <h3 id="_idParaDest-320" class="title">Courtesy</h3>
    <p class="normal">Courtesy<a id="_idIndexMarker788"/> will help make a conversation smoother when things go wrong. Emotional intelligence is not answering 100% correctly every time.</p>
    <p class="normal"><em class="italics">Emotional intelligence (EI) is adjusting to an environment, correcting a mistake made, and trying to ease the tension at all times.</em></p>
    <p class="normal">First, click on <strong class="screen-text">Enable</strong>, which will trigger small talk responses during a dialog:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_02.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.2: Enabling Small Talk</p>
    <p class="normal">You will notice that the <strong class="screen-text">Courtesy</strong> progress bar is at 0%. We need to increase EI:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_03.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.3: Small talk themes</p>
    <p class="normal">We will carefully answer the first possible "question" a user can ask or a phrase they might express: <strong class="screen-text">That's bad.</strong></p>
    <p class="normal">We are in <a id="_idIndexMarker789"/>trouble here! This is the worst-case scenario. We are going to have to work hard to make up for this.</p>
    <p class="normal">Emotional polysemy makes the situation extremely difficult to deal with. The one thing we do not want to do is to pretend our bot is intelligent.</p>
    <p class="normal">I would recommend two courses of action:</p>
    <p class="normal">First, answer carefully, saying that we need to investigate this with something like:</p>
    <p class="normal"><em class="italics">I am very sorry about this. Could you please describe why it's bad? We will regularly check our history log and try to improve all the time. You can also send us an email at &lt;your customer service email address&gt;. We will answer as soon as possible.</em></p>
    <p class="normal">You can enter this answer as follows and click on the <strong class="screen-text">SAVE</strong> button:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_04.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.4: Courtesy</p>
    <p class="normal">You will notice the <strong class="screen-text">Courtesy</strong> progress bar has jumped up to 17%. We have covered a critical area of a dialog. Default answers are provided when we don't fill everything in, but they are random, which makes it better to enter your own phrases if you activate this function.</p>
    <p class="normal">Now test the<a id="_idIndexMarker790"/> dialog by entering "That's bad" in the test console at the top right. You will see the response appear:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_05.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.5: Default response</p>
    <p class="normal">If you type "bad" instead of "That's bad," it will work too, thanks to the ML functionality of Dialogflow:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_06.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.6: Default response</p>
    <p class="normal"><strong class="bold">Data logging</strong> will <a id="_idIndexMarker791"/>tremendously help to boost the quality of a chatbot.</p>
    <p class="normal">We will explore data logging in the next section. But let's check our emotions first.</p>
    <h3 id="_idParaDest-321" class="title">Emotions</h3>
    <p class="normal">We will deal with the<a id="_idIndexMarker792"/> first reaction: <strong class="screen-text">Ha ha ha!</strong> If we go back to emotional polysemy issues, knowing the user can say this at any time, we are in trouble again!</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_07.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.7: Managing Emotions</p>
    <p class="normal">Is the user happy, or are they making fun of the chatbot? Who knows? Even with facial analysis and tone analysis, a quick "Ha ha ha!" is very difficult to interpret.</p>
    <p class="normal">I would suggest a careful low-profile answer such as "Well, that's cheerful!", for example.</p>
    <p class="normal">This will get the user to think that the chatbot has a sense of humor. When you click on <strong class="screen-text">SAVE</strong>, the <strong class="screen-text">Emotions</strong> progress bar will jump up.</p>
    <p class="normal">You will notice that beyond the variants Dialogflow detects, you can also enter variants directly in your responses. Also, if the user enters a phrase that is not in the dialog, there is a fallback intent in the intents list.</p>
    <p class="normal">Small talk might make a dialog smoother, but it is only one of the components of emotional intelligence, in a <a id="_idIndexMarker793"/>chatbot or in everyday life.</p>
    <p class="normal">Data logging will take us a step further.</p>
    <h1 id="_idParaDest-322" class="title">Data logging</h1>
    <p class="normal">In <em class="italics">Chapter 15</em>, <em class="italics">Setting Up a Cognitive NLP UI/CUI Chatbot</em>, we took the context of a dialog into account <a id="_idIndexMarker794"/>using follow-up intents. However, even follow-up intents will not provide solutions to unexpected answers on the part of a user.</p>
    <p class="normal">To enhance a dialog, data logging will create a long-term memory for the chatbot by remembering the key aspects of a dialog.</p>
    <p class="normal">A user and a Dialogflow designer have to agree to the terms of the Google Dialogflow data logging features, as described on this page: <a href="https://cloud.google.com/dialogflow/docs/data-logging"><span class="url">https://cloud.google.com/dialogflow/docs/data-logging</span></a>.</p>
    <p class="normal">Privacy is a serious matter. However, you will notice that when you use a search engine for a given product, you end up viewing or receiving ads related to the search. This is data logging.</p>
    <p class="normal">Making this decision depends on your goal and target audience. Suppose the user accepts the terms of the agreement. Now, data logging is activated. Then, data logging will provide the chatbot with long-term memory.</p>
    <p class="normal">The rest of this chapter explores data logging, with the assumption of it having been clearly accepted by the user.</p>
    <p class="normal">Google Cloud, like all chatbot platforms (Amazon, Microsoft, and others), offers logs to improve chatbots. Many functions, interfaces, and services provide great support to boost the quality of dialogs.</p>
    <p class="normal">Data logging can drive cognitive-adaptive dialogs beyond speech recognition tasks.</p>
    <p class="normal">We will explore one way of doing this through the history of a dialog. Go to <strong class="screen-text">History</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.8: Dialog history option in the menu</p>
    <p class="normal">You will see <a id="_idIndexMarker795"/>a list of past conversations:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_09.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.9: Dialog history</p>
    <p class="normal">Notice the <strong class="screen-text">All platforms</strong> list, which contains information for Google Assistant and other platforms. You can deploy your chatbot by clicking on <strong class="screen-text">See how it works on Google Assistant</strong> on the right-hand side of the screen. From there, you can follow the instructions and have it running on smartphones, Google Home, and elsewhere. Also, you will have advanced log data to improve the chatbot.</p>
    <p class="normal">If you tested "That's bad" in the <em class="italics">Courtesy</em> section, the history of the interactions will be present:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_10.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.10: Chatbot interactions</p>
    <p class="normal">One way to know the<a id="_idIndexMarker796"/> username is to ask the user their name when an issue comes up. This can come in handy to customize a dialog. We can thus have a special dialog for this person or this category of persons. We can thus ask the person to state their name in their response with an email address, for example. When we analyze the data logs manually or with scripts in the <strong class="screen-text">Fulfillment</strong> section, we can track the problem down and improve the chatbot on a personal level.</p>
    <p class="normal">Having completed the <strong class="screen-text">Small Talk</strong> sections and then activated the data log authorization for your use of data logging, we can proceed to create emotions. Google will continue to improve our chatbot with our data logging features.</p>
    <p class="normal">If we know which user said what, we can improve the dialog, as we will see in the next section.</p>
    <h1 id="_idParaDest-323" class="title">Creating emotions</h1>
    <p class="normal">When the user enters <a id="_idIndexMarker797"/>ambiguous responses involving emotional polysemy, it is difficult for a chatbot to consider the hundreds of possibilities described in the previous sections.</p>
    <p class="normal">In this section, we will focus on a user trying to obtain a service such as access to a movie on a streaming platform.</p>
    <p class="normal">An efficient chatbot should <em class="italics">create emotions in the user</em>. The most effective method is to:</p>
    <ul>
      <li class="list">Generate <em class="italics">customer satisfaction</em>. Customer satisfaction is the ultimate emotion a chatbot should try to produce in a frictionless and expected dialog. If the customer is not satisfied with an answer, tensions and frustration will build up.</li>
      <li class="list">Use<a id="_idIndexMarker798"/> functions such as the RBM-PCA approach of <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>, to suggest options that shorten the dialog path, thus its duration making the user "happy."</li>
    </ul>
    <p class="normal">We will now explore the <em class="italics">no</em> path of the dialog encountered in <em class="italics">Chapter 15, Setting Up a Cognitive NLP UI/CUI Chatbot</em>.</p>
    <p class="normal">To access the <em class="italics">no</em> path of the dialog, go to <strong class="screen-text">Intents</strong>, click on the <strong class="screen-text">choose_movie</strong> intent and click on <strong class="screen-text">Add follow-up intent</strong>, and click on <strong class="screen-text">no</strong> in the drop-down menu:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_11.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.11: Adding a follow-up intent</p>
    <p class="normal">A <strong class="screen-text">choose_movie - no</strong> option should now appear:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_12.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.12: Follow-up options</p>
    <p class="normal">Click on <strong class="screen-text">choose_movie - no</strong>.</p>
    <p class="normal">Google has entered several default "no" variants, as shown in the following screenshot:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_13.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.13: Dialogflow training phrases</p>
    <p class="normal">This "no" response comes as a surprise to the chatbot. In <em class="italics">Chapter 14</em>, this market segment was explored. Something has gone wrong!</p>
    <p class="normal">The chatbot was working <a id="_idIndexMarker799"/>on a specific market segment, the "action" superhero fan type viewer. The answer being "no" means that we need to examine the other features available.</p>
    <p class="normal">The features in <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>, in the <code class="Code-In-Text--PACKT-">RBM.py</code> program were:</p>
    <pre class="programlisting"><code class="hljs autoit">    <span class="hljs-meta"># Each column is a feature. There are 6 features:</span>
    <span class="hljs-meta"># [<span class="hljs-string">'love'</span>,<span class="hljs-string">'happiness'</span>,<span class="hljs-string">'family'</span>,<span class="hljs-string">'horizons'</span>,<span class="hljs-string">'action'</span>,<span class="hljs-string">'violence'</span>]</span>
</code></pre>
    <p class="normal">The "action" feature predicted so far groups several features:</p>
    <p class="center">Action = {happiness, action, violence}</p>
    <p class="normal">The following features were not taken into account:</p>
    <p class="center">{love, family, horizons}</p>
    <p class="normal">Since we want to keep the path short, we must find a way to ask a question that:</p>
    <ul>
      <li class="list">Covers these three features</li>
      <li class="list">Can use an existing feature matrix for another marketing segment</li>
    </ul>
    <p class="normal">The viewer also may have:</p>
    <ul>
      <li class="list">Recently seen enough action movies</li>
      <li class="list">Progressively grown out of the superhero period of their life and be looking for other types of movies</li>
    </ul>
    <p class="normal">In both cases, the viewer's market segment might overlap with another segment that contains family-love values.</p>
    <p class="normal">As we saw in the <em class="italics">Adding fulfillment functionality to an agent</em> section in <em class="italics">Chapter 15</em>, <em class="italics">Setting up a Cognitive NLP UI/CUI Chatbot</em>, we can use a script to:</p>
    <ul>
      <li class="list">Cover these <a id="_idIndexMarker800"/>three features</li>
      <li class="list">Use an existing feature matrix for another marketing segment</li>
    </ul>
    <p class="normal">Classical marketing segments take age into account. Let's continue in this direction and prepare for the possibility that the viewer, a young superhero fan, is growing a bit older and entering another age-movie-type segment that overlaps with the one used in <code class="Code-In-Text--PACKT-">RBM.py</code> in <em class="italics">Chapter 14</em>:</p>
    <pre class="programlisting"><code class="hljs angelscript">    movies_feature_map = np.<span class="hljs-built_in">array</span>([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
    .../...
</code></pre>
    <p class="normal">We should add some love-family features in the matrix with the corresponding movies. We will then obtain another marketing segment. In the end, the chatbot will manage many marketing segments, which is the standard practice on many streaming platforms.</p>
    <p class="normal">A variant of the chart in <em class="italics">Chapter 15</em>, <em class="italics">Setting Up a Cognitive NLP UI/CUI Chatbot</em>, could be as follows:</p>
    <table id="table001-10" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">MOVIE/FEATURE</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">LOVE</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">HAPPINESS</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">FAMILY</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">HORIZONS</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">ACTION</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">VIOLENCE</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">24H in Kamba</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Lost</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Cube Adventures</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">A Holiday</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Jonathan Brooks</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">The Melbourne File</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">WNC Detectives</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Stars</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Space II </p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Zone 77</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">This feature matrix contains a movie with the missing features from the previous matrix: Space II.</p>
    <p class="normal">A streaming platform contains many marketing segments:</p>
    <p class="center"><em class="italics">M</em> = {<em class="italics">s</em><sub>1</sub>, <em class="italics">s</em><sub>2</sub>, … <em class="italics">s</em><sub style="font-style: italic;">n</sub>}</p>
    <p class="normal">Many of these marketing segments contain variants, merged features, combinations, and more.</p>
    <p class="normal">Since data logging <a id="_idIndexMarker801"/>has been activated, from this point on we now have the following information:</p>
    <ul>
      <li class="list">Whether this viewer has seen one of the several movies available in this marketing segment. This constitutes another tricky issue since some viewers may want to watch a movie again.</li>
      <li class="list">The viewer's new marketing segment.</li>
    </ul>
    <p class="normal">Building a chatbot for a streaming platform will take months of designing with many build possibilities. For this example, we will focus on the age progression scenario, keep the dialog path as short as possible, and provide the following response:</p>
    <p class="normal">"Would you like to watch SPACE II? It's a blockbuster with a family that has an adventure in space. There is some action but it's mostly the story of a family that tries to survive in space."</p>
    <p class="normal">Scroll down to the <strong class="screen-text">Text Response</strong> section and enter the response as follows, then click on <strong class="screen-text">SAVE</strong> to trigger the training process:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_14.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.14: A look at the training process</p>
    <p class="normal">If the viewer answers "yes," then the dialog will lead to the movie's page. To continue in this direction, go back to <em class="italics">Chapter 15</em>, <em class="italics">Setting Up a Cognitive NLP UI/CUI Chatbot</em>, and a "yes" follow-up exchange to this part of the dialog as you wish.</p>
    <p class="normal">We have added<a id="_idIndexMarker802"/> some emotional intelligence to the agent. We will now explore the future of chatbot architecture through text augmentation with <strong class="bold">recurrent neural networks</strong> (<strong class="bold">RNNs</strong>).</p>
    <p class="normal">An RNN can process sequential data such as sequences of words, events, and more.</p>
    <h1 id="_idParaDest-324" class="title">RNN research for future automatic dialog generation</h1>
    <p class="normal">The future <a id="_idIndexMarker803"/>of chatbots lies in producing dialogs automatically, based on data logging dialogs, their cognitive meanings, the personal profile of a user, and more. As RNNs progress, we will get closer to this approach. There are many generative approaches that can produce automatic sequences of sounds and texts. Understanding an RNN is a good place to start.</p>
    <p class="normal">An RNN model is based on sequences, in this case, words. It analyzes anything in a sequence, including images. To speed the mind-dataset process up, data augmentation can be applied here, exactly as it is to images in other models.</p>
    <p class="normal">A first look at its graph data flow structure shows that an RNN is a neural network like the others previously explored. The following diagram shows a conceptual view of an RNN:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_15.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.15: Data flow structure</p>
    <p class="normal">The <em class="italics">y</em> inputs (test data) go to the loss function (<strong class="bold">Loss_Train</strong>). The <em class="italics">x</em> inputs (training data) will be <a id="_idIndexMarker804"/>transformed through weights and biases into logits with a softmax function. </p>
    <p class="normal">Looking at the RNN area of the graph shows the following <strong class="bold">basic_lstm_cell</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_16.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.16: The basic_lstm_cell—the RNN area of the graph</p>
    <p class="normal">The LSTM cell of an RNN contains "forget" gates that will prevent vanishing gradients when the sequences become too long for an RNN unit.</p>
    <h2 id="_idParaDest-325" class="title">RNNs at work</h2>
    <p class="normal">An <a id="_idIndexMarker805"/>RNN contains functions that take the output of a layer and feed it back to the input in sequences simulating time. This feedback process takes information in a sequence, for example:</p>
    <p class="center"><em class="italics">The</em> -&gt; movie -&gt; was -&gt; <strong class="bold">interesting</strong> -&gt; but -&gt; I -&gt; didn't -&gt; like -&gt; <em class="italics">it</em></p>
    <p class="normal">An RNN will unroll a stack of words into a sequence and parse a window of words to the right and the left. For example, in this sentence, an RNN can start with interesting (bold) and then read the words on the right and left (in italic). These are some of the hyperparameters of the RNN.</p>
    <p class="normal">This sequence aspect opens the door to sequence prediction. Instead of recognizing a whole pattern of data at the same time, it is recognizing the sequence of data, as in this example.</p>
    <p class="normal">A network with no RNN will recognize the following vector as a week, a pattern just like any other:</p>
    <p class="center">Monday</p>
    <p class="center">Tuesday</p>
    <p class="center">Wednesday</p>
    <p class="center">Thursday</p>
    <p class="center">Friday</p>
    <p class="center">Saturday</p>
    <p class="center">Sunday</p>
    <p class="normal">An RNN will explore the same data in a sequence by unrolling streams of data:</p>
    <p class="center">Monday -&gt; Tuesday -&gt; Wednesday -&gt; Thursday -&gt; Friday -&gt; Saturday -&gt; Sunday</p>
    <p class="normal">The main difference lies in the fact that once trained, the network will predict the word that follows; if Wednesday is the input, Thursday could be one of the outputs. This is shown in the next section.</p>
    <h3 id="_idParaDest-326" class="title">RNN, LSTM, and vanishing gradients</h3>
    <p class="normal">To simulate sequences and memory, an RNN and an LSTM will use backpropagation algorithms. An LSTM is an improved version of RNN in some cases.</p>
    <p class="normal">An <a id="_idIndexMarker806"/>RNN often has problems with gradients when calculating them over deeper and deeper layers in the network. Sometimes, it vanishes (too close to 0) due to the sequence property, just like us when a memory sequence becomes too long.</p>
    <p class="normal">The backpropagation (just like us with a sequence) becomes less efficient. There are many backpropagation algorithms, such as vanilla backpropagation, which is commonly used. This algorithm performs efficient backpropagation because it updates the weights after every training pattern.</p>
    <p class="normal">One way to force the gradient not to vanish is to use a ReLU activation function, <em class="italics">f</em>(<em class="italics">x</em>) = max(0, <em class="italics">x</em>), forcing values on the model so that it will not get stuck.</p>
    <p class="normal">Another way is to use an LSTM cell containing a forget gate between the input and the output cells, a bit like us when we get stuck in a memory sequence, and we say "whatever" and move on.</p>
    <p class="normal">The LSTM<a id="_idIndexMarker807"/> cell will act as a memory gate with 0 and 1 values, for example. This cell will forget some information to have a fresh view of the information it has unrolled into a sequence. In recent TensorFlow versions (2.0 and above), you can choose to use RNN or LSTM units in a layer. Your choice will depend on several factors. The key factor is the behavior of the gradient. If it vanishes in the RNN units, you might want to improve your model or move to LSTM units.</p>
    <p class="normal">The key idea of an RNN to <a id="_idIndexMarker808"/>bear in mind is that it unrolls information into sequences, remembering the past to predict the future. The main idea of an LSTM relies upon its "forget" gate, avoiding the vanishing gradient. In TensorFlow 2.x, the choice of RNN or LSTM units can be made in a few lines.</p>
    <p class="normal">Let's run an example on Google Colaboratory.</p>
    <h2 id="_idParaDest-327" class="title">Text generation with an RNN</h2>
    <p class="normal">To view the <a id="_idIndexMarker809"/>program, log<a id="_idIndexMarker810"/> into your Dialogflow account, upload <code class="Code-In-Text--PACKT-">text_generation_tf2.ipynb</code> (located in the <code class="Code-In-Text--PACKT-">CH16</code> directory in the GitHub repository of this book) to your Google Colaboratory environment, and save it in your drive, as explained in the <em class="italics">Getting started with Google Colaboratory</em> section in <em class="italics">Chapter 13</em>, <em class="italics">Visualizing Networks with TensorFlow 2.x and TensorBoard</em>.</p>
    <p class="normal">This TensorFlow authors' program has been well designed for educational purposes. The program starts by setting up TensorFlow 2.x and the necessary libraries.</p>
    <p class="normal">In this section, we will thus focus on the main points of the program that you can then explore, run, and modify.</p>
    <h2 id="_idParaDest-328" class="title">Vectorizing the text</h2>
    <p class="normal">The main entry step<a id="_idIndexMarker811"/> to an RNN consists of taking the sequence of words, the strings, and converting them into a <strong class="bold">numerical representation</strong>:</p>
    <pre class="programlisting"><code class="hljs ini"><span class="hljs-comment"># Creating a mapping from unique characters to indices</span>
<span class="hljs-attr">char2idx</span> = {u:i for i, u in enumerate(vocab)}
<span class="hljs-attr">idx2char</span> = np.array(vocab)
<span class="hljs-attr">text_as_int</span> = np.array([char2idx[c] for c in text])
</code></pre>
    <p class="normal">We obtain a numerical value for each character:</p>
    <pre class="programlisting"><code class="hljs ada">{
  '\n':   <span class="hljs-number">0</span>,
  <span class="hljs-string">' '</span> :   1,
  <span class="hljs-string">'!'</span> :   2,
  <span class="hljs-string">'$'</span> :   3,
  <span class="hljs-string">'&amp;'</span> :   4,
  <span class="hljs-string">"'"</span> :   5,
  <span class="hljs-string">','</span> :   6,
  <span class="hljs-string">'-'</span> :   7,
  <span class="hljs-string">'.'</span> :   8,
  <span class="hljs-string">'3'</span> :   9,
  <span class="hljs-string">':'</span> :  10,
  <span class="hljs-string">';'</span> :  11,
  <span class="hljs-string">'?'</span> :  12,
  <span class="hljs-string">'A'</span> :  13,
  <span class="hljs-string">'B'</span> :  14,
  <span class="hljs-string">'C'</span> :  15,
.../...
</code></pre>
    <p class="normal">You will notice that this "dictionary" can be interpreted in two ways:</p>
    <ul>
      <li class="list">character2number</li>
      <li class="list">integer2character</li>
    </ul>
    <p class="normal">The RNN will run its calculations but the predictions will come out in characters.</p>
    <p class="normal">For example, the program can take the first sequence of the loaded text and produce the mapped integers of the text as follows:</p>
    <pre class="programlisting"><code class="hljs livecodeserver"><span class="hljs-comment"># Show how the first 13 characters from the text are mapped to integers</span>
print (<span class="hljs-string">'{} ---- characters mapped to int ---- &gt; {}'</span>.<span class="hljs-built_in">format</span>(
    repr(<span class="hljs-keyword">text</span>[:<span class="hljs-number">13</span>]), text_as_int[:<span class="hljs-number">13</span>]))
</code></pre>
    <p class="normal">In this example, the result is:</p>
    <pre class="programlisting"><code class="hljs angelscript"><span class="hljs-string">'First Citizen'</span> ---- characters mapped to <span class="hljs-built_in">int</span> ---- &gt; [<span class="hljs-number">18</span> <span class="hljs-number">47</span> <span class="hljs-number">56</span> <span class="hljs-number">57</span> <span class="hljs-number">58</span>  <span class="hljs-number">1</span> <span class="hljs-number">15</span> <span class="hljs-number">47</span> <span class="hljs-number">58</span> <span class="hljs-number">47</span> <span class="hljs-number">64</span> <span class="hljs-number">43</span> <span class="hljs-number">52</span>]
</code></pre>
    <p class="normal">The RNN will run through numerical sequences, integer segments, or windows of the text to train and then make predictions. To do this, the program creates examples and targets as for all neural <a id="_idIndexMarker812"/>networks that have training batches.</p>
    <h2 id="_idParaDest-329" class="title">Building the model</h2>
    <p class="normal">Building neural networks with TensorFlow 2 has become so simple to write in a few lines that you can even miss seeing them in the example programs!</p>
    <p class="normal">Let's clarify some basic concepts before getting to those few lines:</p>
    <ul>
      <li class="list">A <strong class="bold">sequential</strong> model<a id="_idIndexMarker813"/> contains a pile or stack of layers.</li>
      <li class="list"><strong class="bold">Embedding</strong> takes the <a id="_idIndexMarker814"/>number of each character and stores it in a vector.</li>
      <li class="list"><strong class="bold">GRU</strong> stands for gated recurrent unit. A GRU<a id="_idIndexMarker815"/> contains gates that manage hidden units, keeping some information and forgetting other information. An RNN GRU can sometimes get confused when the sequences become long and thus mismanage the gradient, which then disappears. The more efficient LSTM units are part of a recurrent network unit as well with feedback connections with a cell, an input gate, an output gate, and a forget gate. But in the end the choice of the types units will always be yours depending on the context of your project. In any case, the key concept to keep in mind is that recurrent networks manage sequences of data, keeping the past in mind while forgetting some information.</li>
      <li class="list">A <strong class="bold">dense</strong> layer, in<a id="_idIndexMarker816"/> this case, is the output layer.</li>
      <li class="list">A <strong class="bold">timestep</strong> is a<a id="_idIndexMarker817"/> predefined sequence length. In another model, it could be actual time if we are working on time-dependent data.</li>
    </ul>
    <p class="normal">A sequential model is built in three layers only:</p>
    <pre class="programlisting"><code class="hljs routeros">def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
    model = tf.keras.<span class="highlight">Sequential</span>([
        tf.keras.layers.<span class="highlight">Embedding</span>(vocab_size, embedding_dim,
                                  batch_input_shape=[batch_size,
                                                     None]),
    tf.keras.layers.<span class="highlight">GRU</span>(rnn_units,
                        <span class="hljs-attribute">return_sequences</span>=<span class="hljs-literal">True</span>,
                        <span class="hljs-attribute">stateful</span>=<span class="hljs-literal">True</span>,
                        <span class="hljs-attribute">recurrent_initializer</span>=<span class="hljs-string">'glorot_uniform'</span>),
    tf.keras.layers.<span class="highlight">Dense</span>(vocab_size)
    ])
    return model
</code></pre>
    <p class="normal">And that's it! You can replace the basic <code class="Code-In-Text--PACKT-">rnn_units</code> with an LSTM layer if the model requires it during the training phase. Once the model is built, the model:</p>
    <ul>
      <li class="list">Looks an embedding up, as in a "dictionary."</li>
      <li class="list">Runs the GRU for a timestep.</li>
      <li class="list">The dense layer will then generate <strong class="bold">logits</strong> (see <em class="italics">Chapter 2</em>, <em class="italics">Building a Reward Matrix – Designing Your Datasets</em>) to produce a prediction using a likelihood function, a probability distribution.</li>
    </ul>
    <p class="normal">The following figure of the TensorFlow author's program sums the process up:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_17.png" alt="A drawing of the data passing through the model"/></figure>
    <p class="packt_figref">Figure 16.17: TensorFlow model</p>
    <h2 id="_idParaDest-330" class="title">Generating text</h2>
    <p class="normal">After trying and training<a id="_idIndexMarker818"/> the model, the program will generate text automatically, for example:</p>
    <pre class="programlisting"><code class="hljs python">print(generate_text(model, start_string=<span class="hljs-string">u"ROMEO: "</span>))
</code></pre>
    <p class="normal">As you'll notice, <code class="Code-In-Text--PACKT-">ROMEO: </code> has been set up as the starting string. It then shows that the following predictions come from the initial text written by Shakespeare and are loaded at the beginning of the program:</p>
    <pre class="programlisting"><code class="hljs properties"><span class="hljs-attr">ROMEO</span>: <span class="hljs-string">Isick a tranch</span>
<span class="hljs-attr">It</span> <span class="hljs-string">wast points for a sisten of resold thee, testement.</span>
<span class="hljs-attr">Petch</span> <span class="hljs-string">doth my sweety beits are so of my sister.</span>
<span class="hljs-attr">KING</span> <span class="hljs-string">RICHARD III:</span>
<span class="hljs-attr">Thou</span> <span class="hljs-string">forget,</span>
<span class="hljs-attr">How</span> <span class="hljs-string">did you burzenty day, 'tis oatly; heaven, for a womanous dear!</span>
<span class="hljs-attr">This</span> <span class="hljs-string">is thy for mercy to the Kanging;</span>
<span class="hljs-attr">He</span> <span class="hljs-string">that from the brothers of Gloucestersherding blame,</span>
<span class="hljs-attr">Thisble</span> <span class="hljs-string">York, se me?</span>
</code></pre>
    <p class="normal">You can go back to the beginning of the program and change the URL. Instead of loading Shakespeare, change it to your own text:</p>
    <pre class="programlisting"><code class="hljs vbnet">path_to_file = tf.keras.utils.get_file(<span class="hljs-comment">'<span class="hljs-doctag">&lt;YOUR FILE NAME&gt;</span>',</span>
    <span class="hljs-comment">'<span class="hljs-doctag">&lt;YOUR URL&gt;</span>')</span>
</code></pre>
    <p class="normal">Before running the program, go to <strong class="screen-text">Runtime</strong> -&gt; <strong class="screen-text">Change runtime type</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_18.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.18: Runtime type</p>
    <p class="normal">Click <a id="_idIndexMarker819"/>on <strong class="screen-text">Change runtime type</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_16_19.png" alt=""/></figure>
    <p class="packt_figref">Figure 16.19: Notebook settings</p>
    <p class="normal">I recommend using the GPU. Also, verify that <strong class="screen-text">Omit code cell output when saving this notebook</strong> is not checked if you<a id="_idIndexMarker820"/> want to save your notebook with the results produced when you run the program.</p>
    <p class="normal">You are now ready to explore and do your own research to contribute to the future of automatic text generation!</p>
    <h1 id="_idParaDest-331" class="title">Summary</h1>
    <p class="normal">Emotional polysemy makes human relationships rich and excitingly unpredictable. However, chatbots remain machines and do not have the ability to manage wide ranges of possible interpretations of a user's phrases.</p>
    <p class="normal">Present-day technology requires hard work to get a cognitive NPL CUI chatbot up and running. Small talk will make the conversation smoother. It goes beyond being a minor feature; courtesy and pleasant emotional reactions are what make a conversation go well.</p>
    <p class="normal">We can reduce the limits of present-day technology by creating emotions in the users through a meaningful dialog that creates a warmer experience. Customer satisfaction constitutes the core of an efficient chatbot. One way to achieve this goal is to implement cognitive functions based on data logging. We saw that when a user answers "no" when we expect "yes," the chatbot needs to adapt, exactly the way we humans do.</p>
    <p class="normal">Cognitive data logging can be achieved through the preparation we explored in <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>, the cognitive dialog of <em class="italics">Chapter 15</em>, <em class="italics">Setting Up a Cognitive NLP UI/CUI Chatbot</em>, and the adaptive dialog built in this chapter. In our example, the viewer changed market segments, and the chatbot logged the new profile. Dialogflow-fulfillment scripts can manage the whole adaptive process, though that is beyond the scope of this book.</p>
    <p class="normal">We looked at the study of sequences of data through RNNs eventually leading to automatic dialogs. Chatbots, using cognitive approaches such as the RBM-PCA and the adaptive data logging inferences of this chapter, will one day build their own dialogs.</p>
    <p class="normal">The following chapters will explore ways to achieve higher levels of artificial intelligence through genes, biological neurons, and qubits. The next chapter explores genetic algorithms and then implements them into a hybrid neural network.</p>
    <h1 id="_idParaDest-332" class="title">Questions</h1>
    <ol>
      <li class="list">When a chatbot fails to provide a correct response, a hotline with actual humans needs to take over the conversation. (Yes | No)</li>
      <li class="list">Small talk serves no purpose in everyday life or with chatbots. It is best to just get to the point. (Yes | No)</li>
      <li class="list">Data logging can be used to improve speech recognition. (Yes | No)</li>
      <li class="list">The history of a chatbot agent's conversations will contain valuable information. (Yes | No)</li>
      <li class="list">Present-day technology cannot make use of the data logging of a user's dialogs. (Yes | No)</li>
      <li class="list">An RNN uses sequences of data to make predictions. (Yes | No)</li>
      <li class="list">An RNN can generate the dialog flow of a chatbot automatically for all applications. (Yes | No)</li>
    </ol>
    <h1 id="_idParaDest-333" class="title">Further reading</h1>
    <ul>
      <li class="list">Information on RNNs: <a href="https://www.tensorflow.org/tutorials/recurrent"><span class="url">https://www.tensorflow.org/tutorials/recurrent</span></a></li>
      <li class="list">More on text generation: <a href="https://www.tensorflow.org/tutorials/text/text_generation"><span class="url">https://www.tensorflow.org/tutorials/text/text_generation</span></a></li>
    </ul>
  </div>
</body></html>