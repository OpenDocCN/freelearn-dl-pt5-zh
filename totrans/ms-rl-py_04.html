<html><head></head><body>
		<div id="_idContainer159">
			<h1 id="_idParaDest-60"><em class="italic"><a id="_idTextAnchor059"/>Chapter 3</em>: Contextual Bandits</h1>
			<p>A more advanced version of the multi-armed bandit is the <strong class="bold">contextual bandit</strong> (<strong class="bold">CB</strong>) problem, where decisions are tailored to the context they are made in. In the previous chapter, we identified the best-performing ad in an online advertising scenario. In doing so, we did not use any information about, for instance, the user persona, age, gender, location, or previous visits, which would have increased the likelihood of a click. CBs allow us to leverage this information, which means, they play a role in central role in commercial personalization and recommendation applications. </p>
			<p>Context is similar to state in a multi-step <strong class="bold">reinforcement</strong> <strong class="bold">learning</strong> (<strong class="bold">RL</strong>) problem, with one key difference. In a multi-step RL problem, the action an agent takes, affects the states it is likely to visit in the subsequent steps. For example, when playing tic-tac-toe, an agent's action in the current state changes the board configuration (state) in a particular way, which then affects what actions the opponent can take, and so on. In CB problems, however, the agent simply observes the context, makes a decision, and observes the reward. The next context the agent will observe does not depend on the current context/action. This setup, although simpler than multi-step RL, occurs in a very broad set of applications. So, you will add a key tool to your arsenal with what we cover in this chapter. </p>
			<p>We will continue to solve different versions of the online advertising problem, using more advanced tools, such as neural networks, together with CB models. Specifically, in this chapter, you will learn about the following:</p>
			<ul>
				<li>Why we need function approximations</li>
				<li>Using function approximations for context</li>
				<li>Using function approximations for actions</li>
				<li>Other applications of multi-armed bandits and CBs</li>
			</ul>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor060"/>Why we need function approximations</h1>
			<p>While <a id="_idIndexMarker146"/>solving (contextual) multi-armed bandit problems, our goal is to learn action values for each arm (action) from our observations, which we have denoted by <img src="image/Formula_03_001.png" alt=""/>. In the online advertising example, it represented our estimate for the probability of a user clicking the ad if we displayed <img src="image/Formula_03_002.png" alt=""/>. Now, assume that we have two pieces of information about the user seeing the ad, namely the following:</p>
			<ul>
				<li>Device type (mobile or desktop) </li>
				<li>Location (domestic/US or international/non-US)</li>
			</ul>
			<p>It is quite likely that ad performances will differ by device type and location, which make up the context in this example. A CB model will therefore leverage this information, estimate the action values for each context, and choose the actions accordingly. </p>
			<p>This would look like filling in a table for each ad similar to the following:</p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/Table_3.1.jpg" alt="Table 3.1 – Sample action values for ad D&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Table 3.1 – Sample action values for ad D</p>
			<p>This means solving four MAB problems, one for each context: </p>
			<ul>
				<li>Mobile – Domestic</li>
				<li>Mobile – International</li>
				<li>Desktop – Domestic</li>
				<li>Desktop – International</li>
			</ul>
			<p>While this could work fine in this simple example, think about what happens when you add additional information to the context, for example, age. This introduces a number of challenges: </p>
			<ul>
				<li>First, we may not have enough observations to (accurately) learn action values for each context (Mobile, International, 57). However, we want to be able to cross-learn and estimate the action values (or improve the estimate) for a 57-year-old user if we have data on users of close ages. </li>
				<li>Second, the number of possible contexts increases by a factor of 100. We could of course mitigate this problem by defining age groups, but then we would have to spend time and data on calibrating the groups, which is not a trivial undertaking. In addition, the growth of the context space would be more limited (growth by a factor of 10 instead of 100), but still exponential. As we add more and more dimensions to the context, which is very likely in any realistic implementation, the problem could easily become intractable. </li>
			</ul>
			<p>Next, we address<a id="_idIndexMarker147"/> this problem using function approximations. This will allow us to work with very complex and high-dimensional contexts. Later, we will also use function approximations for actions, which will enable us to work with changing and/or high-dimensional action spaces.</p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor061"/>Using function approximations for context</h1>
			<p>Function approximations<a id="_idIndexMarker148"/> allow us to model the dynamics of a process from which we have observed data, such as contexts and ad clicks. As in the previous chapter, consider an online advertising scenario with five different ads (A, B, C, D, and E), with the context comprising user device, location, and age. In this section, our agent will learn five different Q functions, one per ad, each receiving a context of <img src="image/Formula_03_004.png" alt=""/>, and return the action value estimate. This is illustrated in <em class="italic">Figure 3.1</em>:</p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/B14160_03_01.jpg" alt="Figure 3.1 – We learn a function for each action that receives the context and returns the action value&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – We learn a function for each action that receives the context and returns the action value</p>
			<p>At this point, we have a supervised machine learning problem to solve for each action. We can use different models to obtain the Q functions, such as logistic regression or a neural network (which actually allows us to use a single network that estimates values for all actions). Once we choose the type of function approximation, we can use the exploration<a id="_idIndexMarker149"/> strategies that we covered in the previous chapter to determine the ad to display given the context. But first, let's create a synthetic process to generate click data mimicking user behavior for our example.</p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor062"/>Case study – contextual online advertising with synthetic user data</h2>
			<p>Assume that<a id="_idIndexMarker150"/> the true user click behavior follows a logistic function: </p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/Formula_03_005.jpg" alt=""/>
				</div>
			</div>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/Formula_03_006.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <img src="image/Formula_03_007.png" alt=""/> is the probability of a user click when the context is <img src="image/Formula_03_008.png" alt=""/> and ad <img src="image/Formula_03_009.png" alt=""/> is shown. Also, let's assume that <em class="italic">device</em> is 1 for mobile and 0 otherwise; and <em class="italic">location</em> is 1 for US and 0 otherwise. There are two important things to note here:</p>
			<ul>
				<li>This behavior, particularly the <img src="image/Formula_03_010.png" alt=""/> parameters, is unknown to the advertiser, which they will try to uncover.</li>
				<li>Note the <img src="image/Formula_03_011.png" alt=""/> superscript in <img src="image/Formula_03_012.png" alt=""/>, which denotes that the impact of these factors on user behavior is potentially different for each ad. </li>
			</ul>
			<p>Let's now implement this in Python, using the following steps:</p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Chapter03/Contextual Bandits.ipynb</p>
			<ol>
				<li>First, let's import <a id="_idIndexMarker151"/>the Python packages we will need:<p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p class="source-code">from scipy.optimize import minimize</p><p class="source-code">from scipy import stats</p><p class="source-code">import plotly.offline</p><p class="source-code">from plotly.subplots import make_subplots</p><p class="source-code">import plotly.graph_objects as go</p><p class="source-code">import cufflinks as cf</p><p class="source-code">cf.go_offline()</p><p class="source-code">cf.set_config_file(world_readable=True, theme='white') </p><p>These include libraries for scientific computation, such as NumPy and SciPy, and Plotly, a powerful visualization tool.</p></li>
				<li>Now, we create a class, <strong class="source-inline">UserGenerator</strong>, to simulate the user dynamics. Set some true <img src="image/Formula_03_013.png" alt=""/> parameters here, which the advertiser (the agent) will try to learn:<p class="source-code">class UserGenerator(object):</p><p class="source-code">    def __init__(self):</p><p class="source-code">        self.beta = {}</p><p class="source-code">        self.beta['A'] = np.array([-4, -0.1, -3, 0.1]) </p><p class="source-code">        self.beta['B'] = np.array([-6, -0.1, 1, 0.1])</p><p class="source-code">        self.beta['C'] = np.array([2, 0.1, 1, -0.1])</p><p class="source-code">        self.beta['D'] = np.array([4, 0.1, -3, -0.2])</p><p class="source-code">        self.beta['E'] = np.array([-0.1, 0, 0.5, -0.01])</p><p class="source-code">        self.context = None    </p></li>
				<li>Let's define the<a id="_idIndexMarker152"/> methods to generate a click or no clicks given the user context:<p class="source-code">    def logistic(self, beta, context):</p><p class="source-code">        f = np.dot(beta, context)</p><p class="source-code">        p = 1 / (1 + np.exp(-f))</p><p class="source-code">        return p</p><p class="source-code">    def display_ad(self, ad):</p><p class="source-code">        if ad in ['A', 'B', 'C', 'D', 'E']:</p><p class="source-code">            p = self.logistic(self.beta[ad], self.context)</p><p class="source-code">            reward = np.random.binomial(n=1, p=p)</p><p class="source-code">            return reward</p><p class="source-code">        else:</p><p class="source-code">            raise Exception('Unknown ad!') </p><p>Note that each ad has a different set of <img src="image/Formula_03_014.png" alt=""/> values. When an ad is displayed to a user, the <strong class="source-inline">logistic</strong> method calculates the probability of a click and the <strong class="source-inline">display_ad</strong> method generates a click with that probability. </p></li>
				<li>We define a <a id="_idIndexMarker153"/>method that will generate users with different contexts randomly:<p class="source-code">    def generate_user_with_context(self):</p><p class="source-code">        # 0: International, 1: U.S.</p><p class="source-code">        location = np.random.binomial(n=1, p=0.6)</p><p class="source-code">        # 0: Desktop, 1: Mobile</p><p class="source-code">        device = np.random.binomial(n=1, p=0.8)</p><p class="source-code">        # User age changes between 10 and 70, </p><p class="source-code">        # with mean age 34</p><p class="source-code">        age = 10 + int(np.random.beta(2, 3) * 60)</p><p class="source-code">        # Add 1 to the concept for the intercept</p><p class="source-code">        self.context = [1, device, location, age]</p><p class="source-code">        return self.context</p><p>As you can see, the <strong class="source-inline">generate_user_with_context</strong> method generates a US user with 60% chance. Also, with 80% chance, the ad is displayed on a mobile device. Finally, the user ages vary between 10 and 70, with a mean age of 34. These are some numbers we set somewhat arbitrarily for the sake of the example. For simplicity, we don't assume any correlations between these user attributes. You can modify these parameters and introduce correlations to create more realistic scenarios.</p></li>
				<li>We can create some functions (outside of the class) to visualize, for our own intuition, the relationship between the context and the probability of a click associated with it. To this end, we need a function to create a scatter plot for a given ad type and data:<p class="source-code">def get_scatter(x, y, name, showlegend):</p><p class="source-code">    dashmap = {'A': 'solid',</p><p class="source-code">               'B': 'dot',</p><p class="source-code">               'C': 'dash',</p><p class="source-code">               'D': 'dashdot',</p><p class="source-code">               'E': 'longdash'}</p><p class="source-code">    s = go.Scatter(x=x, </p><p class="source-code">                   y=y, </p><p class="source-code">                   legendgroup=name, </p><p class="source-code">                   showlegend=showlegend,</p><p class="source-code">                   name=name, </p><p class="source-code">                   line=dict(color='blue', </p><p class="source-code">                             dash=dashmap[name]))</p><p class="source-code">    return s </p></li>
				<li>Now, we <a id="_idIndexMarker154"/>define a function to plot how the click probabilities change with age, shown in different subplots for each device type and location pair:<p class="source-code">def visualize_bandits(ug):</p><p class="source-code">    ad_list = 'ABCDE'</p><p class="source-code">    ages = np.linspace(10, 70)</p><p class="source-code">    fig = make_subplots(rows=2, cols=2, </p><p class="source-code">            subplot_titles=("Desktop, International", </p><p class="source-code">                            "Desktop, U.S.", </p><p class="source-code">                            "Mobile, International", </p><p class="source-code">                            "Mobile, U.S."))</p><p class="source-code">    for device in [0, 1]:</p><p class="source-code">        for loc in [0, 1]:</p><p class="source-code">            showlegend = (device == 0) &amp; (loc == 0)</p><p class="source-code">            for ad in ad_list:</p><p class="source-code">                probs = [ug.logistic(ug.beta[ad], </p><p class="source-code">                          [1, device, loc, age]) </p><p class="source-code">                                 for age in ages]</p><p class="source-code">                fig.add_trace(get_scatter(ages, </p><p class="source-code">                                          probs, </p><p class="source-code">                                          ad, </p><p class="source-code">                                          showlegend), </p><p class="source-code">                           row=device+1, </p><p class="source-code">                           col=loc+1)             </p><p class="source-code">    fig.update_layout(template="presentation")</p><p class="source-code">    fig.show()</p></li>
				<li>Now, let's <a id="_idIndexMarker155"/>create an object instance to generate users and visualize user behavior:<p class="source-code">ug = UserGenerator()</p><p class="source-code">visualize_bandits(ug)</p><p>The output is shown in <em class="italic">Figure 3.2</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer138" class="IMG---Figure">
					<img src="image/B14160_03_02.jpg" alt="Figure 3.2 – Comparison of the true ad click probabilities given the context &#13;&#10;(x axis: age, y axis: click probability)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Comparison of the true ad click probabilities given the context (x axis: age, y axis: click probability)</p>
			<p>Looking at the plots in <em class="italic">Figure 3.2</em>, we should expect our algorithms to figure out, for example, to<a id="_idIndexMarker156"/> display ad E for users aged around 40, who connect from the US on a mobile device. Also, note that these probabilities <a id="_idIndexMarker157"/>are unrealistically high. More realistic <strong class="bold">click-through rates</strong> (<strong class="bold">CTRs</strong>) would be less than 5%. This can be obtained by multiplying the <strong class="source-inline">p</strong> calculation in the <strong class="source-inline">logistic</strong> class by 0.05. We will keep this as it is for now to make the problem easier.</p>
			<p>Now, we have implemented a process to generate user clicks. Here is how the scenario will flow:</p>
			<ol>
				<li value="1">We will generate a user and get the associated context using the <strong class="source-inline">generate_user_with_context</strong> method in the <strong class="source-inline">ug</strong> object.</li>
				<li>A CB model will use the context to display one of the five ads: A, B, C, D, or E.</li>
				<li>The chosen ad will be passed to the <strong class="source-inline">display_ad</strong> method in the <strong class="source-inline">ug</strong> object, giving a reward of 1 (click) or 0 (no click).</li>
				<li>The CB model will be trained based on the reward, and this cycle will go on.</li>
			</ol>
			<p>Before actually <a id="_idIndexMarker158"/>implementing this flow, let's dive into the CB approaches we will use.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor063"/>Function approximation with regularized logistic regression</h2>
			<p>We want our<a id="_idIndexMarker159"/> CB algorithms to <a id="_idIndexMarker160"/>observe the user responses to the ads, update the models that estimate the action values (function approximations), and determine which ad to display given the context, the action value estimates, and the exploration strategy. Note that in most realistic settings where the user traffic is high, the models would be updated not after every observation but after a batch of observations. With that, let's start by discussing what kind of function approximator to use. There are numerous options, including many custom and sophisticated algorithms designed for CBs. Many of these models are based on the following:</p>
			<ul>
				<li>Logistic regression</li>
				<li>Decision trees/random forest</li>
				<li>Neural networks</li>
			</ul>
			<p>In terms of the exploration strategy, we'll continue to focus on the following three fundamental approaches:</p>
			<ul>
				<li>ε-greedy</li>
				<li>Upper confidence bounds </li>
				<li>Thompson/Bayesian sampling</li>
			</ul>
			<p>Now, let's assume that, as subject matter experts, we know that the CTR can be modeled using logistic regression. We also mentioned that it is not practical to update the model after every single observation, so we prefer batch updates to our models. Finally, we would like to have Thompson sampling in our exploration toolbox, therefore we need posterior distributions on the parameters of the logistic regression models. To this end, we use a regularized logistic regression algorithm with batch updates provided by the agent(Chapelle et al., 2011). The algorithm does the following: </p>
			<ul>
				<li>Approximates the posterior distribution on the model weights by a Gaussian distribution. This allows us to use the posterior distribution as the prior in the next batch, and also use Gaussian for the likelihood function, since the Gaussian family is conjugate to itself.</li>
				<li>Uses a diagonal covariance matrix for the weights, meaning we assume the weights are not correlated. </li>
				<li>Uses Laplace approximation to obtain the mean and the variance estimates of the weight distributions, one of the common methods in statistics to estimate the posterior<a id="_idIndexMarker161"/> parameters from <a id="_idIndexMarker162"/>observed data if the posterior is assumed to be Gaussian.<p class="callout-heading">Info</p><p class="callout">You can learn more about Laplace approximation for computing the posterior mean at <a href="https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html">https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html</a>.</p></li>
			</ul>
			<p>Let's see this algorithm in action next.</p>
			<h3>Implementing regularized logistic regression</h3>
			<p>We will follow <a id="_idIndexMarker163"/>these steps to implement the regularized logistic regression, which we will use later:</p>
			<ol>
				<li value="1">First, we create a class and initialize the parameters we will keep track of:<p class="source-code">class RegularizedLR(object):</p><p class="source-code">    def __init__(self, name, alpha, rlambda, n_dim):</p><p class="source-code">        self.name = name</p><p class="source-code">        self.alpha = alpha</p><p class="source-code">        self.rlambda = rlambda</p><p class="source-code">        self.n_dim = n_dim</p><p class="source-code">        self.m = np.zeros(n_dim)</p><p class="source-code">        self.q = np.ones(n_dim) * rlambda</p><p class="source-code">        self.w = self.get_sampled_weights()</p><p>Let's better understand what these parameters are:</p><p>a) <strong class="source-inline">name</strong> is to identify which ad an object instance is estimating the action value of. Again, we have a separate model for each of the ads and they are updated separately based on their own click data.</p><p>b) The <strong class="source-inline">alpha</strong> hyperparameter controls the exploration and exploitation trade-off. Smaller values reduce the variance (for example, 0.25), which therefore encourages exploitation.</p><p>c) This is a regularized regression, meaning that we have a regularization term, λ. This is a hyperparameter to be tuned. We also use it to initialize the <strong class="source-inline">q</strong> array.</p><p>d) <strong class="source-inline">n_dim</strong> is to indicate<a id="_idIndexMarker164"/> the dimension of the <img src="image/Formula_03_015.png" alt=""/> parameter vector, one for each element of the context input and a bias term.</p><p>e) The weights of the logistic function are denoted by the array of <strong class="source-inline">w</strong>, such that <strong class="source-inline">w[i]</strong> corresponds to <img src="image/Formula_03_016.png" alt=""/> in our bandit dynamics model.</p><p>f) The mean estimate of <strong class="source-inline">w[i]</strong> is given by <strong class="source-inline">m[i]</strong>, and the variance estimate is the inverse of <strong class="source-inline">q[i]</strong>.</p></li>
				<li>Then, we define a method to sample the parameters of the logistic regression function:<p class="source-code">    def get_sampled_weights(self): </p><p class="source-code">        w = np.random.normal(self.m, self.alpha * self.q**(-1/2))</p><p class="source-code">        return w</p><p>Note that we need this to use Thompson sampling, which requires sampling the <strong class="source-inline">w</strong> array parameters from the posterior, rather than using the mean values. Again, the posterior is a normal distribution here. </p></li>
				<li>Define the loss <a id="_idIndexMarker165"/>function and a fit function, which will carry out the training:<p class="source-code">    def loss(self, w, *args):</p><p class="source-code">        X, y = args</p><p class="source-code">        n = len(y)</p><p class="source-code">        regularizer = 0.5 * np.dot(self.q, (w - self.m)**2)</p><p class="source-code">        pred_loss = sum([np.log(1 + np.exp(np.dot(w, X[j])))</p><p class="source-code">                                    - y[j] * np.dot(w, X[j]) for j in range(n)])</p><p class="source-code">        return regularizer + pred_loss</p><p class="source-code">    def fit(self, X, y):</p><p class="source-code">        if y:</p><p class="source-code">            X = np.array(X)</p><p class="source-code">            y = np.array(y)</p><p class="source-code">            minimization = minimize(self.loss, </p><p class="source-code">                                    self.w, </p><p class="source-code">                                    args=(X, y), </p><p class="source-code">                                    method="L-BFGS-B", </p><p class="source-code">                                    bounds=[(-10,10)]*3 + [(-1, 1)],</p><p class="source-code">                                    options={'maxiter': 50})</p><p class="source-code">            self.w = minimization.x</p><p class="source-code">            self.m = self.w</p><p class="source-code">            p = (1 + np.exp(-np.matmul(self.w, X.T)))**(-1)</p><p class="source-code">            self.q = self.q + np.matmul(p * (1 - p), X**2)</p><p>Let's elaborate on how the fitting part works:</p><p>a) We update the model using the <strong class="source-inline">fit</strong> method and the <strong class="source-inline">loss</strong> function with a given set of contexts and associated click data (1 for a click, 0 for no click).</p><p>b) We use SciPy's<a id="_idIndexMarker166"/> minimize function for the model training. To prevent numerical overflows in the exponential terms, we impose bounds on <strong class="source-inline">w</strong>. These bounds need to be adjusted depending on the range of the input values. For the binary features of device type and the age input, location [-10, +10] and [-1, +1], respectively, are reasonable ranges for our use case.</p><p>c) In each model update with a new batch of data, the previous <strong class="source-inline">w</strong> values serve as the prior.</p></li>
				<li>Implement the upper confidence bounds on predictions, which is one of the exploration methods we will experiment with:<p class="source-code">    def calc_sigmoid(self, w, context):</p><p class="source-code">        return 1 / (1 + np.exp(-np.dot(w, context)))</p><p class="source-code">    def get_ucb(self, context):</p><p class="source-code">        pred = self.calc_sigmoid(self.m, context)</p><p class="source-code">        confidence = self.alpha * np.sqrt(np.sum(np.divide(np.array(context)**2, self.q)))</p><p class="source-code">        ucb = pred + confidence</p><p class="source-code">        return ucb</p></li>
				<li>Implement two types of prediction methods, one using the mean values parameter estimates and the other using the sampled parameters to be used with Thompson <a id="_idIndexMarker167"/>sampling:<p class="source-code">    def get_prediction(self, context):</p><p class="source-code">        return self.calc_sigmoid(self.m, context)</p><p class="source-code">    def sample_prediction(self, context):</p><p class="source-code">        w = self.get_sampled_weights()</p><p class="source-code">        return self.calc_sigmoid(w, context)</p></li>
			</ol>
			<p>Now, before actually diving into solving the problem, we will define a metric to compare the alternative exploration strategies. </p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor064"/>Objective – regret minimization</h2>
			<p>A common metric<a id="_idIndexMarker168"/> that is used to compare MAB and CB algorithms is called <strong class="bold">regret</strong>. We define the total regret by the time we have observed the <img src="image/Formula_03_017.png" alt=""/> user as follows:</p>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="image/Formula_03_018.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <img src="image/Formula_03_019.png" alt=""/> is the context for the <img src="image/Formula_03_020.png" alt=""/> user, <img src="image/Formula_03_021.png" alt=""/> is the best action (ad) to take that gives the highest expected CTR, and <img src="image/Formula_03_022.png" alt=""/> is the expected CTR for the selected action (ad). Note that we are able to calculate the regret because we have access to the true action values (expected CTRs), which would not be the case in reality (although regret can still be estimated). Note that the minimum possible regret at any step is zero.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">With a good exploration strategy, we should see a decelerating cumulative regret over time as the algorithm discovers the best actions. </p>
			<p>We will use the <a id="_idIndexMarker169"/>following code to calculate the regret given the context and the selected ad:</p>
			<p class="source-code">def calculate_regret(ug, context, ad_options, ad):</p>
			<p class="source-code">    action_values = {a: ug.logistic(ug.beta[a], context) for a in ad_options}</p>
			<p class="source-code">    best_action = max(action_values, key=action_values.get)</p>
			<p class="source-code">    regret = action_values[best_action] - action_values[ad]</p>
			<p class="source-code">    return regret, best_action</p>
			<p>Finally, let's write the code to actually solve the problem using different exploration strategies. </p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor065"/>Solving the online advertising problem</h2>
			<p>As we have already <a id="_idIndexMarker170"/>defined all the auxiliary methods to use the three exploration strategies we mentioned earlier, selecting the actions accordingly will be trivial. Now, let's implement the functions for these strategies:</p>
			<ol>
				<li value="1">We start with writing a function to implement the ε-greedy actions, which selects the best action most of the time and explores a random action otherwise:<p class="source-code">def select_ad_eps_greedy(ad_models, context, eps):</p><p class="source-code">    if np.random.uniform() &lt; eps:</p><p class="source-code">        return np.random.choice(list(ad_models.keys()))</p><p class="source-code">    else:</p><p class="source-code">        predictions = {ad: ad_models[ad].get_prediction(context) </p><p class="source-code">                       for ad in ad_models}</p><p class="source-code">        max_value = max(predictions.values()); </p><p class="source-code">        max_keys = [key for key, value in predictions.items() if value == max_value]</p><p class="source-code">        return np.random.choice(max_keys)</p></li>
				<li>Next, we write a<a id="_idIndexMarker171"/> function to implement action selection using the upper confidence bounds:<p class="source-code">def select_ad_ucb(ad_models, context):</p><p class="source-code">    ucbs = {ad: ad_models[ad].get_ucb(context) </p><p class="source-code">                   for ad in ad_models}</p><p class="source-code">    max_value = max(ucbs.values()); </p><p class="source-code">    max_keys = [key for key, value in ucbs.items() if value == max_value]</p><p class="source-code">    return np.random.choice(max_keys)</p></li>
				<li>Then, we define a function to implement action selection using Thompson sampling:<p class="source-code">def select_ad_thompson(ad_models, context):</p><p class="source-code">    samples = {ad: ad_models[ad].sample_prediction(context) </p><p class="source-code">                   for ad in ad_models}</p><p class="source-code">    max_value = max(samples.values()); </p><p class="source-code">    max_keys = [key for key, value in samples.items() if value == max_value]</p><p class="source-code">    return np.random.choice(max_keys)</p></li>
				<li>Finally, we perform the actual experiment, which will run and compare each strategy sequentially. We start with initializing the ad names, the experiment names, and the<a id="_idIndexMarker172"/> necessary data structures:<p class="source-code">ad_options = ['A', 'B', 'C', 'D', 'E']</p><p class="source-code">exploration_data = {}</p><p class="source-code">data_columns = ['context', </p><p class="source-code">                'ad', </p><p class="source-code">                'click', </p><p class="source-code">                'best_action', </p><p class="source-code">                'regret', </p><p class="source-code">                'total_regret']</p><p class="source-code">exploration_strategies = ['eps-greedy', </p><p class="source-code">                          'ucb', </p><p class="source-code">                          'Thompson']</p></li>
				<li>We need to implement an outer <strong class="source-inline">for</strong> loop to kick off a clean experiment with each of the exploration strategies. We initialize all the algorithm parameters and data structures:<p class="source-code">for strategy in exploration_strategies:</p><p class="source-code">    print("--- Now using", strategy)</p><p class="source-code">    np.random.seed(0)</p><p class="source-code">    # Create the LR models for each ad</p><p class="source-code">    alpha, rlambda, n_dim = 0.5, 0.5, 4</p><p class="source-code">    ad_models = {ad: RegularizedLR(ad, </p><p class="source-code">                                   alpha, </p><p class="source-code">                                   rlambda, </p><p class="source-code">                                   n_dim) </p><p class="source-code">                 for ad in 'ABCDE'}</p><p class="source-code">    # Initialize data structures</p><p class="source-code">    X = {ad: [] for ad in ad_options}</p><p class="source-code">    y = {ad: [] for ad in ad_options}</p><p class="source-code">    results = []</p><p class="source-code">    total_regret = 0</p></li>
				<li>Now, we implement <a id="_idIndexMarker173"/>an inner loop to run the active strategy for 10K user impressions:<p class="source-code">    for i in range(10**4):</p><p class="source-code">        context = ug.generate_user_with_context()</p><p class="source-code">        if strategy == 'eps-greedy':</p><p class="source-code">            eps = 0.1</p><p class="source-code">            ad = select_ad_eps_greedy(ad_models, </p><p class="source-code">                                      context,</p><p class="source-code">                                      eps)</p><p class="source-code">        elif strategy == 'ucb':</p><p class="source-code">            ad = select_ad_ucb(ad_models, context)</p><p class="source-code">        elif strategy == 'Thompson':</p><p class="source-code">            ad = select_ad_thompson(ad_models, context)</p><p class="source-code">        # Display the selected ad</p><p class="source-code">        click = ug.display_ad(ad)</p><p class="source-code">        # Store the outcome</p><p class="source-code">        X[ad].append(context)</p><p class="source-code">        y[ad].append(click)</p><p class="source-code">        regret, best_action = calculate_regret(ug, </p><p class="source-code">                                               context, </p><p class="source-code">                                               ad_options, </p><p class="source-code">                                               ad)</p><p class="source-code">        total_regret += regret</p><p class="source-code">        results.append((context, </p><p class="source-code">                        ad, </p><p class="source-code">                        click, </p><p class="source-code">                        best_action, </p><p class="source-code">                        regret, </p><p class="source-code">                        total_regret))</p><p class="source-code">        # Update the models with the latest batch of data</p><p class="source-code">        if (i + 1) % 500 == 0:</p><p class="source-code">            print("Updating the models at i:", i + 1)</p><p class="source-code">            for ad in ad_options:</p><p class="source-code">                ad_models[ad].fit(X[ad], y[ad])</p><p class="source-code">            X = {ad: [] for ad in ad_options}</p><p class="source-code">            y = {ad: [] for ad in ad_options}</p><p class="source-code">    </p><p class="source-code">    exploration_data[strategy] = {'models': ad_models,</p><p class="source-code">                       'results': pd.DataFrame(results, </p><p class="source-code">                                         columns=data_columns)}</p><p>Let's unpack this:</p><p>a) We generate a user and use the context to decide which ad to display given the exploration strategy in each iteration.</p><p>b) We observe and record the outcome. We also calculate the regret after each impression to be able to compare the strategies.</p><p>c) We update the logistic regression models in batches, namely after every 500 ad impressions.</p></li>
				<li>After executing this <a id="_idIndexMarker174"/>code block, we can visualize the results using the following code:<p class="source-code">df_regret_comparisons = pd.DataFrame({s: exploration_data[s]['results'].total_regret</p><p class="source-code">                                     for s in exploration_strategies})</p><p class="source-code">df_regret_comparisons.iplot(dash=['solid', 'dash','dot'],</p><p class="source-code">                            xTitle='Impressions', </p><p class="source-code">                            yTitle='Total Regret',</p><p class="source-code">                            color='black')</p><p>This gives the plot that is shown in Figure 3.3:</p><div id="_idContainer147" class="IMG---Figure"><img src="image/B14160_03_03.jpg" alt="Figure 3.3 – Comparison of exploration strategies in the online advertising example&#13;&#10;"/></div><p class="figure-caption">Figure 3.3 – Comparison of exploration strategies in the online advertising example</p><p>We clearly see that Thompson sampling is outperforming the ε-greedy and <strong class="bold">upper confidence bound</strong> (<strong class="bold">UCB</strong>) strategies as the total regret decelerates over time faster than <a id="_idIndexMarker175"/>the other two. It writes off the inefficient ads for given contexts pretty early on, while ε-greedy and UCB <a id="_idIndexMarker176"/>continue to explore those alternatives. Also note that we have not tuned the exploration rate for ε-greedy and <strong class="source-inline">alpha</strong> for UCB, which could have led to better performances. But this is exactly the point: Thompson sampling provides a very effective exploration strategy pretty much out of the box. This is what <em class="italic">Chapelle et al., 2011</em> empirically showed and helped the method gain popularity nearly a century after it was introduced.</p><p class="callout-heading">Tip</p><p class="callout">In a real production system, it makes more sense to use well-maintained libraries for the supervised learning portion in CBs rather than a custom implementation as we did here. One such library for probabilistic programming is PyMC3 (<a href="https://docs.pymc.io/">https://docs.pymc.io/</a>). Using PyMC3, you can fit supervised learning models to your data and then sample the model parameters. As an exercise, consider implementing Thompson sampling using a logistic regression model in PyMC3.</p></li>
				<li>Let's close this section by visualizing the parameter estimates of the models. For example, when we used the ε-greedy strategy, the <img src="image/Formula_03_023.png" alt=""/> coefficients for ad A were estimated as<a id="_idIndexMarker177"/> follows:<p class="source-code">lrmodel = exploration_data['eps-greedy']['models']['A']</p><p class="source-code">df_beta_dist = pd.DataFrame([], index=np.arange(-4,1,0.01))</p><p class="source-code">mean = lrmodel.m</p><p class="source-code">std_dev = lrmodel.q ** (-1/2)</p><p class="source-code">for i in range(lrmodel.n_dim):</p><p class="source-code">    df_beta_dist['beta_'+str(i)] = stats.norm(loc=mean[i], </p><p class="source-code">                                              scale=std_dev[i]).pdf(df_beta_dist.index)</p><p class="source-code">    </p><p class="source-code">df_beta_dist.iplot(dash=['dashdot','dot', 'dash', 'solid'],</p><p class="source-code">                   yTitle='p.d.f.',</p><p class="source-code">                   color='black')</p><p>This results in the following output:</p></li>
			</ol>
			<div>
				<div id="_idContainer149" class="IMG---Figure">
					<img src="image/B14160_03_04.jpg" alt="Figure 3.4 – Visualization of the posterior distribution of  for ad A at the end of the experiment with ε-greedy exploration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – Visualization of the posterior distribution of <img src="image/Formula_03_024.png" alt=""/> for ad A at the end of the experiment with ε-greedy exploration</p>
			<p>The logistic regression <a id="_idIndexMarker178"/>model estimates the coefficients as <img src="image/Formula_03_025.png" alt=""/> whereas the actual coefficients are <img src="image/Formula_03_026.png" alt=""/>. The model is especially certain about its estimate for <img src="image/Formula_03_027.png" alt=""/>, which is indicated by a very narrow distribution in the plot.</p>
			<p>Terrific job! This was a rather long exercise, but one that will set you up for success in your real-life implementations. Take a deep breath and a break, and next, we will look at an even more realistic version of online advertising where the ad inventory changes over time.</p>
			<h1 id="_idParaDest-67"><a id="_idTextAnchor066"/>Using function approximations for actions</h1>
			<p>In our online advertising <a id="_idIndexMarker179"/>examples so far, we have assumed that we have a fixed set of ads (actions/arms) to choose from. However, in many applications of CBs, the set of available actions changes over time. Take the example of a modern advertising network that uses an ad server to match ads to websites/apps. This is a very dynamic operation that involves, leaving the pricing aside, three major components:</p>
			<ul>
				<li>Website/app content</li>
				<li>Viewer/user profile</li>
				<li>Ad inventory</li>
			</ul>
			<p>Previously, we considered only the user profile for the context. An ad server needs to take the website/app content into account additionally, but this does not really change the structure of the problem we solved before. However, now, we cannot use a separate model for each ad since the ad inventory is dynamic. We handle this by using a single model to which we feed ad features. This is illustrated in <em class="italic">Figure 3.5</em>:</p>
			<div>
				<div id="_idContainer154" class="IMG---Figure">
					<img src="image/B14160_03_05.jpg" alt="Figure 3.5 – Function approximation of action values with context and action inputs in the ad network example&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5 – Function approximation of action values with context and action inputs in the ad network example</p>
			<p>While making a decision, we take the context as given. So, the decision is about which ad to display from the ad inventory that is available at the time. So, to make this decision, we generate action values for all available ads using this single model.</p>
			<p>Now it is time to talk about what kind of model to use in this situation:</p>
			<ul>
				<li>Remember what the model does: it learns how a given user would react to a given ad that they see on a given website/app and estimates the probability of a click. </li>
				<li>When you think about all possible user and website/app contexts, and all possible ads, this is a very complicated relationship to figure out. </li>
				<li>Such a model needs to be trained on a lot of data and it should be sophisticated enough to be able to come up with a good approximation of the true dynamics of a click. </li>
				<li>When we have<a id="_idIndexMarker180"/> this much complexity, and<a id="_idIndexMarker181"/> hopefully enough data, there is one obvious choice: <strong class="bold">deep neural networks</strong> (<strong class="bold">DNNs</strong>).</li>
			</ul>
			<p>In the previous section, we compared different exploration strategies and showed that Thompson sampling is a very competitive choice. However, Thompson sampling requires us to be able to sample from the posterior of the model parameters; this is often intractable for complex models such as neural networks. To overcome this challenge, we rely on approximate Bayesian methods available in the literature. </p>
			<p class="callout-heading">Info</p>
			<p class="callout">There are many approximation methods and their comparison is beyond the scope here. <em class="italic">Riquelme et al., 2018</em> provide a great comparison along with code in the TensorFlow repository. </p>
			<p>One of these approximations involves using dropout regularization in the DNN and keeping it active during inference time. As a reminder, dropout regularization deactivates each neuron in the DNN with respect to a given probability and increases generalization. Typically, dropout is only used during training. When it is kept active during inference, since neurons are disabled probabilistically, the output varies accordingly. <em class="italic">Gal et al., 2015</em> have shown that this works as an approximate Bayesian inference, which we<a id="_idIndexMarker182"/> need for Thompson sampling.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor067"/>Case study – contextual online advertising with user data from the US Census</h2>
			<p>Now, let's talk <a id="_idIndexMarker183"/>about the example we will use in this section. Previously, we crafted our own examples. This time, we'll use a dataset that is modified from the 1994 US Census and adapt it to an online advertising setting. The dataset is known as the Census Income dataset and is available at <a href="https://archive.ics.uci.edu/ml/datasets/Census+Income">https://archive.ics.uci.edu/ml/datasets/Census+Income</a>.</p>
			<p>In this dataset, we use the following information on the individuals who participated in the census: age, work class, education, marital status, occupation, relationship, race, gender, work hours per week, native country, and income level. </p>
			<p>With that, let's discuss how to turn this data into an online advertising scenario.</p>
			<h3>The scenario</h3>
			<p>Consider an ad server that knows all of the preceding information about a user, except the education level. On the other hand, the ad network is managing ads that address a specific education level. For example, at any given time, the ad server has one ad that is targeting users with a college education and one ad that is targeting users with elementary school education. If the target audience of the ad that is shown to a user matches the user's education level, there is a high probability of a click. If not, the probability of a click decreases gradually as the discrepancy between the target education level and the user's education level grows. In other words, the ad server is implicitly trying to predict users' education levels as close as possible.</p>
			<p>Next, let's prepare the dataset for our scenario.</p>
			<h3>Preparing the data</h3>
			<p>Follow these steps to clean and prepare the data:</p>
			<ol>
				<li value="1">We start with importing the necessary packages to use later:<p class="source-code">from collections import namedtuple</p><p class="source-code">from numpy.random import uniform as U</p><p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import io</p><p class="source-code">import requests</p><p class="source-code">from tensorflow import keras</p><p class="source-code">from tensorflow.keras.layers import Dense, Dropout</p><p class="source-code">import cufflinks as cf</p><p class="source-code">cf.go_offline()</p><p class="source-code">cf.set_config_file(world_readable=True, theme='white')</p></li>
				<li>Next, we need<a id="_idIndexMarker184"/> to download the data and select the columns of interest:<p class="source-code">url="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"</p><p class="source-code">s=requests.get(url).content</p><p class="source-code">names = ['age', </p><p class="source-code">           'workclass', </p><p class="source-code">           'fnlwgt', </p><p class="source-code">           'education',</p><p class="source-code">           'education_num',</p><p class="source-code">           'marital_status',</p><p class="source-code">           'occupation',</p><p class="source-code">           'relationship',</p><p class="source-code">           'race',</p><p class="source-code">           'gender',</p><p class="source-code">           'capital_gain',</p><p class="source-code">           'capital_loss',</p><p class="source-code">           'hours_per_week',</p><p class="source-code">           'native_country',</p><p class="source-code">          'income']</p><p class="source-code">usecols = ['age', </p><p class="source-code">           'workclass', </p><p class="source-code">           'education',</p><p class="source-code">           'marital_status',</p><p class="source-code">           'occupation',</p><p class="source-code">           'relationship',</p><p class="source-code">           'race',</p><p class="source-code">           'gender',</p><p class="source-code">           'hours_per_week',</p><p class="source-code">           'native_country',</p><p class="source-code">           'income']</p><p class="source-code">df_census = pd.read_csv(io.StringIO(s.decode('utf-8')), </p><p class="source-code">                        sep=',',</p><p class="source-code">                        skipinitialspace=True,</p><p class="source-code">                        names=names,</p><p class="source-code">                        header=None,</p><p class="source-code">                        usecols=usecols)</p></li>
				<li>Let's<a id="_idIndexMarker185"/> drop the rows with missing data, marked by <strong class="source-inline">?</strong> entries:<p class="source-code">df_census = df_census.replace('?', np.nan).dropna()</p><p>Normally, a missing entry could itself be a valuable indicator that the model could use. In addition, it is a bit wasteful to drop a whole record just because of a single missing entry. However, data imputation is beyond our scope here, so let's keep focusing on the CB problem. </p></li>
				<li>Let's also collapse <a id="_idIndexMarker186"/>the different education levels to four categories: <strong class="source-inline">Elementary</strong>, <strong class="source-inline">Middle</strong>, <strong class="source-inline">Undergraduate</strong>, and <strong class="source-inline">Graduate</strong>:<p class="source-code">edu_map = {'Preschool': 'Elementary',</p><p class="source-code">           '1st-4th': 'Elementary',</p><p class="source-code">           '5th-6th': 'Elementary',</p><p class="source-code">           '7th-8th': 'Elementary',</p><p class="source-code">           '9th': 'Middle',</p><p class="source-code">           '10th': 'Middle',</p><p class="source-code">           '11th': 'Middle',</p><p class="source-code">           '12th': 'Middle',</p><p class="source-code">           'Some-college': 'Undergraduate',</p><p class="source-code">           'Bachelors': 'Undergraduate',</p><p class="source-code">           'Assoc-acdm': 'Undergraduate',</p><p class="source-code">           'Assoc-voc': 'Undergraduate',</p><p class="source-code">           'Prof-school': 'Graduate',</p><p class="source-code">           'Masters': 'Graduate',</p><p class="source-code">           'Doctorate': 'Graduate'}</p><p class="source-code">for from_level, to_level in edu_map.items():</p><p class="source-code">    df_census.education.replace(from_level, to_level, inplace=True)</p></li>
				<li>Next, we convert categorical data into one-hot vectors to be able to feed into a DNN. We preserve the education column as is, since that is not part of the context: <p class="source-code">context_cols = [c for c in usecols if c != 'education']</p><p class="source-code">df_data = pd.concat([pd.get_dummies(df_census[context_cols]),</p><p class="source-code">           df_census['education']], axis=1)</p><p>By doing this conversion at the beginning, we assume that we know all possible work class categories and native countries.</p></li>
			</ol>
			<p>That's it! We have<a id="_idIndexMarker187"/> the data ready. Next, we implement logic to simulate an ad click based on the actual education level of the user and the education level that the ad displayed targets.</p>
			<h3>Simulating ad clicks</h3>
			<p>In this example, the availability of ads is random and the ad clicks are stochastic. We need to come up with some logic to simulate this behavior:</p>
			<ol>
				<li value="1">Let's start with determining the ad availability probabilities for each education category and implement the sampling of ads:<p class="source-code">def get_ad_inventory():</p><p class="source-code">    ad_inv_prob = {'Elementary': 0.9, </p><p class="source-code">                   'Middle': 0.7, </p><p class="source-code">                   'HS-grad': 0.7, </p><p class="source-code">                   'Undergraduate': 0.9, </p><p class="source-code">                   'Graduate': 0.8}</p><p class="source-code">    ad_inventory = []</p><p class="source-code">    for level, prob in ad_inv_prob.items():</p><p class="source-code">        if U() &lt; prob:</p><p class="source-code">            ad_inventory.append(level)</p><p class="source-code">    # Make sure there are at least one ad</p><p class="source-code">    if not ad_inventory:</p><p class="source-code">        ad_inventory = get_ad_inventory()</p><p class="source-code">    return ad_inventory</p><p>As mentioned, the ad server will have at most one ad for each target group. We also ensure that there is at least one ad in the inventory.</p></li>
				<li>Then, we define a function to generate a click probabilistically, where the likelihood of a click increases to the degree that the user's education level and the ad's target <a id="_idIndexMarker188"/>match:<p class="source-code">def get_ad_click_probs():</p><p class="source-code">    base_prob = 0.8</p><p class="source-code">    delta = 0.3</p><p class="source-code">    ed_levels = {'Elementary': 1, </p><p class="source-code">                 'Middle': 2, </p><p class="source-code">                 'HS-grad': 3, </p><p class="source-code">                 'Undergraduate': 4, </p><p class="source-code">                 'Graduate': 5}</p><p class="source-code">    ad_click_probs = {l1: {l2: max(0, base_prob - delta * abs(ed_levels[l1]- ed_levels[l2])) for l2 in ed_levels}</p><p class="source-code">                           for l1 in ed_levels}</p><p class="source-code">    return ad_click_probs</p><p class="source-code">def display_ad(ad_click_probs, user, ad):</p><p class="source-code">    prob = ad_click_probs[ad][user['education']]</p><p class="source-code">    click = 1 if U() &lt; prob else 0</p><p class="source-code">    return click</p><p>So, when an ad is shown to a user, if the ad's target matches the user's education level, there will be <img src="image/Formula_03_028.png" alt=""/> chance of a click. This probability decreases by <img src="image/Formula_03_029.png" alt=""/> for each level of mismatch. For example, a person with a high school diploma has a <img src="image/Formula_03_030.png" alt=""/> chance of clicking on an ad that targets a user group of elementary school graduates (or college graduates). Note that this information is not known to the CB algorithm. It will be used only to simulate the clicks.</p></li>
			</ol>
			<p>We have the<a id="_idIndexMarker189"/> problem set up. Next, we'll turn to implementing a CB model.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor068"/>Function approximation using a neural network</h2>
			<p>As mentioned, we <a id="_idIndexMarker190"/>use a (not so) DNN, which will<a id="_idIndexMarker191"/> estimate the action value, given the context and the action. The DNN we'll use has two layers, with 256 hidden units in each layer. This model is pretty easy to create using Keras, TensorFlow's high-level API. </p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Note that in our model, we use dropout that we leave active for the inference time as a Bayesian approximation that we need for Thompson sampling. This is configured by setting <strong class="source-inline">training=True</strong> in the dropout layer. </p>
			<p>The network outputs a scalar, which is an estimate for the action value given the context and the action feature (target user group). Using binary cross-entropy suits such an output the best, so we'll use it in our model. Finally, we'll use the popular Adam optimizer.</p>
			<p class="callout-heading">Info</p>
			<p class="callout">Visit <a href="https://www.tensorflow.org/guide/keras">https://www.tensorflow.org/guide/keras</a> if you need to get started with Keras or to refresh your memory. It is very simple to build the standard DNN models with it.</p>
			<p>Now, let's create the functions for model creation and updates:</p>
			<ol>
				<li value="1">We create a function that returns a compiled DNN model with given input dimensions <a id="_idIndexMarker192"/>and <a id="_idIndexMarker193"/>a dropout rate:<p class="source-code">def get_model(n_input, dropout):</p><p class="source-code">    inputs = keras.Input(shape=(n_input,))</p><p class="source-code">    x = Dense(256, activation='relu')(inputs)</p><p class="source-code">    if dropout &gt; 0:</p><p class="source-code">        x = Dropout(dropout)(x, training=True)</p><p class="source-code">    x = Dense(256, activation='relu')(x)</p><p class="source-code">    if dropout &gt; 0:</p><p class="source-code">        x = Dropout(dropout)(x, training=True)</p><p class="source-code">    phat = Dense(1, activation='sigmoid')(x)</p><p class="source-code">    model = keras.Model(inputs, phat)</p><p class="source-code">    model.compile(loss=keras.losses.BinaryCrossentropy(),</p><p class="source-code">                  optimizer=keras.optimizers.Adam(),</p><p class="source-code">                  metrics=[keras.metrics.binary_accuracy])</p><p class="source-code">    return model</p></li>
				<li>We will update this model in batches as data becomes available. Next, write a function to train the model for 10 epochs with each batch:<p class="source-code">def update_model(model, X, y):</p><p class="source-code">    X = np.array(X)</p><p class="source-code">    X = X.reshape((X.shape[0], X.shape[2]))</p><p class="source-code">    y = np.array(y).reshape(-1)</p><p class="source-code">    model.fit(X, y, epochs=10)</p><p class="source-code">    return model</p></li>
				<li>We then define a<a id="_idIndexMarker194"/> function that returns a<a id="_idIndexMarker195"/> one-hot representation for a specified ad based on the education level it targets:<p class="source-code">def ad_to_one_hot(ad):</p><p class="source-code">    ed_levels = ['Elementary', </p><p class="source-code">                 'Middle', </p><p class="source-code">                 'HS-grad', </p><p class="source-code">                 'Undergraduate', </p><p class="source-code">                 'Graduate']</p><p class="source-code">    ad_input = [0] * len(ed_levels)</p><p class="source-code">    if ad in ed_levels:</p><p class="source-code">        ad_input[ed_levels.index(ad)] = 1</p><p class="source-code">    return ad_input</p></li>
				<li>We implement the Thompson sampling to select an ad given the context and the ad inventory at hand:<p class="source-code">def select_ad(model, context, ad_inventory):</p><p class="source-code">    selected_ad = None</p><p class="source-code">    selected_x = None</p><p class="source-code">    max_action_val = 0</p><p class="source-code">    for ad in ad_inventory:</p><p class="source-code">        ad_x = ad_to_one_hot(ad)</p><p class="source-code">        x = np.array(context + ad_x).reshape((1, -1))</p><p class="source-code">        action_val_pred = model.predict(x)[0][0]</p><p class="source-code">        if action_val_pred &gt;= max_action_val:</p><p class="source-code">            selected_ad = ad</p><p class="source-code">            selected_x = x</p><p class="source-code">            max_action_val = action_val_pred</p><p class="source-code">    return selected_ad, selected_x</p><p>The ad to be displayed is chosen based on the largest action value estimate that we obtain from the DNN. We obtain this by trying all available ads in the inventory – and<a id="_idIndexMarker196"/> remember, we have <a id="_idIndexMarker197"/>at most one ad per target user group – with the context of the user. Note that the target user group is equivalent to <strong class="source-inline">action</strong>, which we feed to the DNN in the format of a one-hot vector.</p></li>
				<li>Finally, we write a function to generate users through a random selection from the dataset. The function will return the user data as well as the derived context:<p class="source-code">def generate_user(df_data):</p><p class="source-code">    user = df_data.sample(1)</p><p class="source-code">    context = user.iloc[:, :-1].values.tolist()[0]</p><p class="source-code">    return user.to_dict(orient='records')[0], context</p></li>
			</ol>
			<p>This concludes <a id="_idIndexMarker198"/>what we need to decide on the ad to<a id="_idIndexMarker199"/> display using Thompson sampling.</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor069"/>Calculating the regret</h2>
			<p>We'll continue<a id="_idIndexMarker200"/> to use regret for comparing various versions of the CB algorithm. We calculate it as follows:</p>
			<p class="source-code">def calc_regret(user, ad_inventory, ad_click_probs, ad_selected):</p>
			<p class="source-code">    this_p = 0</p>
			<p class="source-code">    max_p = 0</p>
			<p class="source-code">    for ad in ad_inventory:</p>
			<p class="source-code">        p = ad_click_probs[ad][user['education']]</p>
			<p class="source-code">        if ad == ad_selected:</p>
			<p class="source-code">            this_p = p</p>
			<p class="source-code">        if p &gt; max_p:</p>
			<p class="source-code">            max_p = p</p>
			<p class="source-code">    regret = max_p - this_p</p>
			<p class="source-code">    return regret</p>
			<p>With the regret calculation also in place, let's now actually solve the problem.</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor070"/>Solving the online advertising problem</h2>
			<p>Now we are ready to <a id="_idIndexMarker201"/>put all these components together. We'll try this algorithm with different dropout probabilities over 5,000 impressions. We'll update the DNN parameters after every 500 iterations. Here is the implementation in Python for various dropout rates:</p>
			<p class="source-code">ad_click_probs = get_ad_click_probs()</p>
			<p class="source-code">df_cbandits = pd.DataFrame()</p>
			<p class="source-code">dropout_levels = [0, 0.01, 0.05, 0.1, 0.2, 0.4]</p>
			<p class="source-code">for d in dropout_levels:</p>
			<p class="source-code">    print("Trying with dropout:", d)</p>
			<p class="source-code">    np.random.seed(0)</p>
			<p class="source-code">    context_n = df_data.shape[1] - 1</p>
			<p class="source-code">    ad_input_n = df_data.education.nunique()</p>
			<p class="source-code">    model = get_model(context_n + ad_input_n, 0.01)</p>
			<p class="source-code">    X = []</p>
			<p class="source-code">    y = []</p>
			<p class="source-code">    regret_vec = []</p>
			<p class="source-code">    total_regret = 0</p>
			<p class="source-code">    for i in range(5000):</p>
			<p class="source-code">        if i % 20 == 0:</p>
			<p class="source-code">            print("# of impressions:", i)</p>
			<p class="source-code">        user, context = generate_user(df_data)</p>
			<p class="source-code">        ad_inventory = get_ad_inventory()</p>
			<p class="source-code">        ad, x = select_ad(model, context, ad_inventory)</p>
			<p class="source-code">        click = display_ad(ad_click_probs, user, ad)</p>
			<p class="source-code">        regret = calc_regret(user, ad_inventory,    ad_click_probs, ad)</p>
			<p class="source-code">        total_regret += regret</p>
			<p class="source-code">        regret_vec.append(total_regret)</p>
			<p class="source-code">        X.append(x)</p>
			<p class="source-code">        y.append(click)</p>
			<p class="source-code">        if (i + 1) % 500 == 0:</p>
			<p class="source-code">            print('Updating the model at', i+1)</p>
			<p class="source-code">            model = update_model(model, X, y)</p>
			<p class="source-code">            X = []</p>
			<p class="source-code">            y = []</p>
			<p class="source-code">            </p>
			<p class="source-code">    df_cbandits['dropout: '+str(d)] = regret_vec</p>
			<p>The cumulative regrets over time are stored in the <strong class="source-inline">df_cbandits</strong> <strong class="source-inline">pandas</strong> DataFrame. Let's <a id="_idIndexMarker202"/>visualize how they compare:</p>
			<p class="source-code">df_cbandits.iplot(dash = ['dash', 'solid', 'dashdot', </p>
			<p class="source-code">                          'dot', 'longdash', 'longdashdot'],</p>
			<p class="source-code">                  xTitle='Impressions', </p>
			<p class="source-code">                  yTitle='Cumulative Regret')</p>
			<p>This results in the following output:</p>
			<div>
				<div id="_idContainer158" class="IMG---Figure">
					<img src="image/B14160_03_06.jpg" alt="Figure 3.6 – Comparison of cumulative regret with various dropout rates&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – Comparison of cumulative regret with various dropout rates</p>
			<p>The results in <em class="italic">Figure 3.6</em> show that our bandit models learn after some observation on how to select the ads given the user characteristics. As various dropout rates have led to different algorithm performances, an important question again becomes how to select the dropout rate. One obvious answer is to try different rates over time to identify what works best in similar online advertising problems. This approach usually works if the business has to solve similar problems again and again over a long time period. A better approach, though, is to learn the optimal dropout rate.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout"><strong class="bold">Concrete dropout</strong> is a <a id="_idIndexMarker203"/>variant that tunes the dropout probabilities automatically. (Collier &amp; Llorens, 2018) have successfully used this method on CB problems and reported superior performance over fixed dropout selections. For a TensorFlow implementation of concrete dropout, see <a href="https://github.com/Skydes/Concrete-Dropout">https://github.com/Skydes/Concrete-Dropout</a>.</p>
			<p>With this, we conclude <a id="_idIndexMarker204"/>our discussion on CBs. Note that we focused on two components while formulating the CB problem: </p>
			<ul>
				<li>Function approximation </li>
				<li>Exploration strategy</li>
			</ul>
			<p>You can often mix and match different function approximations with various exploration techniques. While Thompson sampling with DNNs is probably the most common choice, we encourage you to take a look at the literature for other approaches.</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor071"/>Other applications of multi-armed bandits and CBs</h1>
			<p>So far, we have<a id="_idIndexMarker205"/> focused on online advertising as our running <a id="_idIndexMarker206"/>example. If you are wondering how common bandit algorithms are in practice in this field, they are actually quite common. For example, Microsoft has a service, called Personalizer, based on bandit algorithms (disclaimer: the author is a Microsoft employee at the time of writing this book). The example here is itself inspired by the work at HubSpot – a marketing solutions company (Collier &amp; Llorens, 2018). Moreover, bandit problems have a vast array of practical<a id="_idIndexMarker207"/> applications other than advertising. In this <a id="_idIndexMarker208"/>section, we'll briefly go over some of those applications.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor072"/>Recommender systems</h2>
			<p>The bandit<a id="_idIndexMarker209"/> problems we formulated and solved in this chapter are a type of recommender system: they recommend which ad to display, potentially leveraging information available about users. There are many other recommender systems that use bandits in a similar way, such as the following:</p>
			<ul>
				<li>Artwork selection for movie titles, as Netflix famously implements (Chandrashekar, Amat, Basilico, &amp; Jebara, 2017)</li>
				<li>Article recommendations on a news portal</li>
				<li>Post recommendations on a social media platform</li>
				<li>Product/service recommendations on an online retail platform</li>
				<li>Tailoring search results to the user on a search engine</li>
			</ul>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor073"/>Web page/app feature design</h2>
			<p>Most famous <a id="_idIndexMarker210"/>websites and apps that we visit every day decide which design to use for different features after extensive tests. For example, they create different designs of the "buy" button on the shopping cart and observe which design generates the most sales. These experiments are conducted nonstop for hundreds of features. An efficient way of conducting these experiments is to use multi-armed bandits. This way, bad feature designs could be identified early on and eliminated to minimize the user disturbance throughout these experiments (Lomas et al., 2016).</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor074"/>Healthcare</h2>
			<p>Bandit problems<a id="_idIndexMarker211"/> have important applications in healthcare. Especially with the increasing availability of patient data, through well-maintained patient databases and data collection via mobile devices, many treatments can now be personalized to individuals. CBs are therefore an important tool to use when deciding which treatment to apply to a patient in randomized controlled trials. Another application in which CBs have successfully been used is for deciding the treatment dose of drugs, such as Warfarin, which regulates blood coagulation (Bastani and Bayati, 2015). One more application is related to the optimal allocation of data sampling to various animal models to assess the effectiveness of a treatment. CBs<a id="_idIndexMarker212"/> have proven to increase the efficiency of this process by identifying promising treatments better than conventional methods (Durand et al., 2018).</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor075"/>Dynamic pricing</h2>
			<p>An important <a id="_idIndexMarker213"/>challenge for online retailers is to dynamically adjust their prices on millions of products. This can be modeled as a CB problem where the context could include product demand forecasts, inventory levels, product cost, and location.</p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor076"/>Finance</h2>
			<p>CBs are used in<a id="_idIndexMarker214"/> literature for optimal portfolio construction through mixing passive and active investments to achieve a balance between the risk and expected return.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor077"/>Control systems tuning</h2>
			<p>Many mechanical <a id="_idIndexMarker215"/>systems use variants of <strong class="bold">proportional-integral-derivative</strong> (<strong class="bold">PID</strong>) controllers to control the <a id="_idIndexMarker216"/>system. PID controllers require tuning, which is often done by subject matter experts for each system separately. This is because optimal gains for the controller depend on the specifics of the equipment, such as the material, temperature, and wear and tear. This manual process can be automated using a CB model that assesses system characteristics and tunes the controller accordingly.</p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor078"/>Summary</h1>
			<p>In this chapter, we concluded our discussion on bandit problems with CBs. As we mentioned, bandit problems have many practical applications. So, it would not be a surprise if you already had a problem in your business or research that can be modeled as a bandit problem. Now that you know how to formulate and solve one, go out and apply what you have learned! Bandit problems are also important to develop an intuition on how to solve an exploration-exploitation dilemma, which will exist in almost every RL setting.</p>
			<p>Now that you have a solid understanding of how to solve one-step RL, it is time to move on to full-blown multi-step RL. In the next chapter, we will go into the theory behind multi-step RL with Markov decision processes, and build the foundation for modern deep RL methods, which we will cover in the subsequent chapters.</p>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor079"/>References</h1>
			<ul>
				<li>Bouneffouf, D., &amp; Rish, I. (2019). <em class="italic">A Survey on Practical Applications of Multi-Armed and Contextual Bandits</em>. Retrieved from arXiv: <a href="https://arxiv.org/abs/1904.10040">https://arxiv.org/abs/1904.10040</a></li>
				<li>Chandrashekar, A., Amat, F., Basilico, J., &amp; Jebara, T. (2017, December 7). Netflix Technology Blog. Retrieved from Artwork Personalization at Netflix: <a href="https://netflixtechblog.com/artwork-personalization-c589f074ad76">https://netflixtechblog.com/artwork-personalization-c589f074ad76</a></li>
				<li>Chapelle, O., &amp; Li, L. (2011). <em class="italic">An Empirical Evaluation of Thompson Sampling. Advances in Neural Information Processing Systems</em>, 24, (pp. 2249-2257)</li>
				<li>Collier, M., &amp; Llorens, H. U. (2018). <em class="italic">Deep Contextual Multi-armed Bandits</em>. Retrieved from arXiv: <a href="https://arxiv.org/abs/1807.09809">https://arxiv.org/abs/1807.09809</a></li>
				<li>Gal, Y., Hron, J., &amp; Kendall, A. (2017). <em class="italic">Concrete Dropout. Advances in Neural Information Processing Systems</em>, 30, (pp. 3581-3590)</li>
				<li>Marmerola, G. D. (2017, November 28). <em class="italic">Thompson Sampling for Contextual bandits</em>. Retrieved from Guilherme's blog: <a href="https://gdmarmerola.github.io/ts-for-contextual-bandits">https://gdmarmerola.github.io/ts-for-contextual-bandits</a></li>
				<li>Riquelme, C., Tucker, G., &amp; Snoek, J. (2018). <em class="italic">Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling</em>. International Conference on Learning Representations (ICLR) </li>
				<li>Russo, D., Van Roy, B., Kazerouni, A., Osband, I., &amp; Wen, Z. (2018). <em class="italic">A Tutorial on Thompson Sampling. Foundations and Trends in Machine Learning</em>, (pp. 1-96)</li>
				<li>Lomas, D., Forlizzi, J., Poonawala, N., Patel, N., Shodhan, S., Patel, K., Koedinger, K., &amp; Brunskill, E. (2016). <em class="italic">Interface Design Optimization as a Multi-Armed Bandit Problem</em>. (pp. 4142-4153). 10.1145/2858036.2858425</li>
				<li>Durand, A., Achilleos, C., Iacovides, D., Strati, K., Mitsis, G.D., &amp; Pineau, J. (2018). <em class="italic">Contextual Bandits for Adapting Treatment in a Mouse Model of de Novo Carcinogenesis</em>. Proceedings of the 3rd Machine Learning for Healthcare Conference, in PMLR 85:67-82</li>
				<li>Bastani, H. &amp; Bayati, M. (2015). <em class="italic">Online decision-making with high-dimensional covariates</em>. Available at SSRN 2661896</li>
			</ul>
		</div>
	</body></html>