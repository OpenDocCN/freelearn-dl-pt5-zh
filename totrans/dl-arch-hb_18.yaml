- en: '18'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring the DataRobot AI Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will turn our focus to the DataRobot AI platform, a paid
    software platform that provides a powerful toolkit for deep learning use cases.
    DataRobot allows its users to streamline the complex stages of the machine learning
    life cycle. It presents an intuitive interface for data scientists, engineers,
    and researchers who wish to harness the power of machine learning for their projects
    and businesses. As we delve into the workings of DataRobot, you will learn how
    it simplifies and accelerates the creation, training, deployment, and government
    of intricate deep learning models. Thanks to features designed for automation
    and ease of use, it empowers users to focus on what truly matters—extracting significant
    value from their machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: Our exploration will highlight the key functionalities of DataRobot, underlining
    its potential as a catalyst in the evolution of deep learning solutions. DataRobot
    aspires to offer a combination of automation, collaboration, and scalability for
    machine learning use cases, making it also a noteworthy tool in the deep learning
    domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A high-level look into what the DataRobot AI platform provides
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing data with DataRobot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing modeling experiments with DataRobot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a deep learning blueprint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Governing a deployed deep learning blueprint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will have a practical topic in this chapter to make predictions using a
    DataRobot deployed model. We will be using Python 3.10 and we will require the
    following Python libraries to be installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`datarobotx==0.1.17`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas==2.0.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code files are available on GitHub at [https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_18](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_18),
    and the dataset can be downloaded from [https://www.kaggle.com/datasets/dicksonchin93/datarobot-compatible-house-pricing-dataset](https://www.kaggle.com/datasets/dicksonchin93/datarobot-compatible-house-pricing-dataset).
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, a paid or free trial account is needed to access DataRobot. To
    subscribe for a trial account, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visit the DataRobot website at [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill up your credentials under the **Start For Free** interface on the right
    side of the web page and click on the **Submit** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A high-level look into what the DataRobot AI platform provides
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The DataRobot AI platform provides data ingestion, data preparation, data insights,
    model development, model evaluation, model insights and analysis, model deployment,
    and model governance through model monitoring and model maintenance tools that
    work seamlessly with each other. While DataRobot streamlines the deep learning
    life cycle, it is important to note that the planning stage still requires human
    input to define the goals and scope of the project. Additionally, you are still
    required to consume the insights, reports, and results made easy for you to obtain.
    Ultimately, this means that such a platform is a tool that can assist any machine
    learning practitioner instead of being a replacement for data scientists, machine
    learning engineers, machine learning researchers, or data analysts. Think of AI
    platforms such as DataRobot as being powerful calculators that can help you solve
    complex math problems quickly and accurately. But just like a calculator can’t
    think for you, DataRobot can’t replace the expertise and creativity of a data
    scientist, engineer, analyst, or researcher.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the tools DataRobot offers are built to be extensible, composable, and
    flexible to add your own code or components, and they don’t tie you into the only
    things that the platform provides. Additionally, some components cover a wide
    range of methods, so you don’t need to worry about doing any customization. Effectively,
    this means you get the benefit of executing projects reliably fast while still
    holding customization power.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dive into the components DataRobot offers, there’s more key information
    that can help you understand what the platform is capable of:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Platform hosting options**: The DataRobot AI platform offers a cloud-hosted
    application. If your business has data privacy and security concerns, DataRobot
    also offers the option to host the AI platform as a privately hosted instance
    in the confines of your own infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability and collaborative nature**: Whether you’re a single user or a
    team, DataRobot is designed to scale with your needs. Most of the tool components
    provided by DataRobot can be shared with multiple users, which enables collaboration
    between different users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`datarobot`, which is installable through `PyPI`. Almost everything you see
    in the web UI is available in the API interface and the Python API client. Additionally,
    the Notebooks feature provides a flexible and interactive environment where data
    scientists can manually perform complex data analysis, create machine learning
    models, and prototype data manipulations alongside the other DataRobot features
    through the Python API client easily. It enhances the user experience by allowing
    the flexibility of defaulting to using traditional Python code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The transition to a use case-focused asset management**: The ML or DL life
    cycle introduced in [*Chapter 1*](B18187_01.xhtml#_idTextAnchor015), *Deep Learning
    Life Cycle*, is an iterative process. This means a DL use case will involve a
    lot of data, data versions, model development experimentations, applications that
    utilize a deployed model, and notebooks being created. The **Workbench** feature
    in DataRobot is meant to support this process by managing many use case-related
    assets mentioned in a single interface, making it easier to realize value through
    the use case. However, at the time of writing this book, Workbench does not comprehensively
    support all the features provided by the traditional, separately managed DataRobot
    projects. It will be updated to support the full suite of features in time. You
    can manage projects separately with DataRobot Classic features. *Figure 18**.1*
    shows an example flow of how a typical machine learning practitioner would navigate
    the platform:![](img/B18187_18_01.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To PD: This image has been sent for redraw.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 18.1 – Example Workbench workflow
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to dive into the relevant supported features for deep learning
    use cases, starting with the data preparation component.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing data with DataRobot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first part of what the platform offers is the data preparation component.
    DataRobot simplifies the data preparation process by offering a range of features
    to streamline data ingest, cleaning, transformation, and integration. Let’s dive
    into these features in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Ingesting data for deep learning model development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The development of deep learning models in DataRobot begins with the pivotal
    step of data ingestion. This process allows you to directly import your data from
    various sources, including cloud storage (such as AWS S3), Google Cloud Storage,
    local files, or databases such as PostgreSQL, Oracle, and SQL Server. The platform
    accepts diverse file formats, including CSV, XLSX, and ZIP files. Additionally,
    the platform supports image, text, document, geospatial, numerical, categorical,
    and summarized categorical data through secondary datasets as input data types.
    For the target data types, the platform supports numerical, categorical, and multilabel
    data types along with data with no targets for unsupervised learning. This sets
    the stage for regression, binary classification, multiclass classification, multilabel
    classification, unsupervised anomaly detection, and unsupervised clustering.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, image data type, text data type, and document data type are the core
    unstructured input data types for building deep learning use cases in DataRobot.
    Image data and document data are supported by being encoded as a base64 string
    under the hood. However, the dataset to be ingested itself can be structured to
    be zipped folders with images or documents, where the folder names are the classes
    or target names. Text data can naturally exist under tabular data in a column,
    encoded in formats such as CSV. Additionally, DataRobot automatically creates
    useful features if there are secondary datasets or datetime feature columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two paths you can take to ingest data:'
  prefs: []
  type: TYPE_NORMAL
- en: Through project creation, tied closely to the model development process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Through the **AI Catalog** feature, which allows you to share the dataset independently.
    This can be subsequently used to create an experiment in a use case or a project
    independently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s explore the second approach, as it is a more responsible and reliable
    way of managing data used for model development.
  prefs: []
  type: TYPE_NORMAL
- en: Using DataRobot to ingest an image and text dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will be tackling the use case of predicting housing prices with multimodal
    data that consists of image data, text data, date data, categorical data, and
    numerical data. Let’s start the step-by-step tutorial:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by creating a use case by clicking on the **+ Create a new Use Case**
    button shown in *Figure 18**.2*. The page shown in *Figure 18**.2* will also be
    the landing page after you enter the DataRobot web app and log in through [app.datarobot.com](http://app.datarobot.com):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.2 – Creating a use case screen in Workbench](img/B18187_18_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.2 – Creating a use case screen in Workbench
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, click on **DataRobot Classic** in the top-right and then on the **AI Catalog**
    tab in the top-left of the interface. Then, click on the **Add to catalog** button
    in the top-left of the interface and then **Local File**, as depicted in *Figure
    18**.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.3 – Adding the dataset to the catalog interface in DataRobot](img/B18187_18_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.3 – Adding the dataset to the catalog interface in DataRobot
  prefs: []
  type: TYPE_NORMAL
- en: Upload the `trulia_pricing_dataset.zip` file provided in the code repo. This
    dataset is a ZIP file that consists of a single CSV file, which contains the raw
    data, and additionally, raw image files that are mapped to one of the columns
    in the CSV through its relative path in the zipped file. From here, an uploaded
    dataset in the AI Catalog can be managed independently and shared separately.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once it is created, go into Workbench in the top-right again, go into the use
    case we created, and rename the use case to a suitable name, such as `Pricing
    Prediction`. Then, click on the **Add new** button dropdown in the top-right of
    the interface and click on **Add datasets**, as depicted in *Figure 18**.4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.4 – Pricing prediction use case in the Workbench interface](img/B18187_18_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.4 – Pricing prediction use case in the Workbench interface
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose `trulia_pricing_dataset` from the **Data Registry** page and click on
    **Add to Use case**, as depicted in *Figure 18**.5*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.5 – Adding the dataset to the use case](img/B18187_18_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.5 – Adding the dataset to the use case
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to move into the EDA part of DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory analysis of the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DataRobot provides a two-step experience in performing **exploratory data analysis**
    (**EDA**) on an at most 500MB subset of the dataset. The first step is EDA, which
    is executed before a project or experiment type is determined, and the second
    step is done after. Standard EDA techniques are provided. These include histograms
    for numerical and categorical data, frequency distribution for the top 50 items
    for categorical data, duplicate counts, missing value counts, disguised missing
    value detection, excessive zero value detection, target leakage, numerical value
    aggregates, outlier rows, univariate feature correlation to the target, and a
    feature association matrix that measures mutual information. For images and text
    data specifically, DataRobot Classic shows a general sample of the data in *step
    1* and sorted by the target values or value ranges group in *step 2*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 18**.6* shows the EDA 2 visualizations from the house pricing prediction
    dataset in DataRobot Classic, where the left image shows the image samples by
    binned targets and the right image shows the duplicate feature interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.6 – EDA 1 and EDA 2 of images](img/B18187_18_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.6 – EDA 1 and EDA 2 of images
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s continue the tutorial with the EDA of the house pricing dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Practically performing EDA in DataRobot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will continue the EDA tutorial in a step-by-step manner:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the `trulia_pricing_dataset` entity under the **Data** tab in the
    use case and you will be presented with the view in *Figure 18**.7*, which can
    be scrolled horizontally and vertically:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![￼Figure 18.7 – Sample data preview EDA interface of the housing dataset in
    Workbench](img/B18187_18_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.7 – Sample data preview EDA interface of the housing dataset in Workbench
  prefs: []
  type: TYPE_NORMAL
- en: If you scroll through the entire table, you will find that the dataset consists
    of 68 features, where 52 features are identified to be informative. This most
    notably consists of an image column that is valid, along with 23 other columns
    that are supposed to be images too but are just links that are not included properly.
    It also has five useful text columns that consist of facts, short and full addresses,
    features of the houses, and general descriptions of the houses.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the **Features** button in the top-left, you will see the interface
    in *Figure 18**.8*, which shows simple statistics of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.8 – Features of the housing dataset](img/B18187_18_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.8 – Features of the housing dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to set the prediction target. The use case is to predict the price
    of a house here, so click on the `Price` in the **Target Feature** box. You will
    then see the interface shown in *Figure 18**.9*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.9 – Choosing a target in Workbench](img/B18187_18_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.9 – Choosing a target in Workbench
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on the **Start modeling** button to start the quick modeling process.
    If you navigate to the **Data** tab from the DataRobot Classic interface, you
    will be able to see the univariate importance computed under the hood. This ranks
    features by their univariate informativeness with regard to the chosen target.
    This is depicted by the green bars in *Figure 18**.10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.10 – DataRobot Classic Data tab showing univariate importance](img/B18187_18_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.10 – DataRobot Classic Data tab showing univariate importance
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will discover how DataRobot allows data wrangling after connecting
    to a dataset source and performing EDA.
  prefs: []
  type: TYPE_NORMAL
- en: Wrangling data for deep learning model development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DataRobot allows you to transform your data with its **Wrangle** feature. It
    is supported for the case where the dataset is added through a data connection
    to a source, such as Snowflake. You can craft a set of data transformations you
    intend to apply to the entire dataset, which are called **recipes**. These transformations
    are initially tested on the live sample to ensure accuracy. Once your recipe is
    finalized, it’s sent to the data source and executed to create the final output
    dataset. The feature allows you to optionally save the transformed dataset right
    into the source of the data and get the output under the data registry, the AI
    Catalog.
  prefs: []
  type: TYPE_NORMAL
- en: 'DataRobot supports a wide range of transformation operations, including the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Joining datasets from the same connection instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying mathematical aggregations to dataset features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing new features using scalar subqueries, scalar functions, or window
    functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering rows based on specified values and conditions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: De-duplicating rows to remove duplicates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding and replacing specific feature values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Renaming features within the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing selected features from the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot doesn’t provide data labeling tools to create labels from scratch
    and depends on the idea that raw business data is all already recorded and saved
    somewhere. Use external labeling tools such as LabelBox to label data collaboratively
    and reliably for deep learning use cases.
  prefs: []
  type: TYPE_NORMAL
- en: As the dataset we are using leverages a local dataset, we won’t be practically
    exploring the data wrangling component here. Dive into [https://docs.datarobot.com/en/docs/workbench/wb-dataprep/wb-wrangle-data/wb-add-operation.html](https://docs.datarobot.com/en/docs/workbench/wb-dataprep/wb-wrangle-data/wb-add-operation.html)
    to explore more on this topic.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will explore how DataRobot executes modeling experiments or projects.
  prefs: []
  type: TYPE_NORMAL
- en: Executing modeling experiments with DataRobot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DataRobot currently provides two ways to execute modeling experiments: DataRobot
    Classic and Workbench. Workbench is where an experiment will be managed under
    a use case, focusing on extracting value from a use case more seamlessly, and
    DataRobot Classic is the original AutoML experience where a modeling experiment
    is called a project. A project, or a modeling experiment here, encompasses the
    same components, which include modeling machine learning, gathering model insights
    and prediction insights, and making one-off batch predictions. We will dive deeper
    into these three components.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'DataRobot provides modeling configurations and tasks in the form of **directed
    acyclic graphs** (**DAG**) called **blueprints**. The individual nodes in the
    graph are grouped up into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input data**: The input nodes can be any of the supported input data types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data preprocessing tasks**: They consist of data regularization, normalization,
    missing value filling, and just any data preprocessing logic. You can also have
    tasks that choose the exact column to operate on. Additionally, techniques to
    perform predictions post-processing are also grouped here. Pre-trained networks
    that serve as feature transforms are also grouped here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modeling tasks**: They consist of any model that produces predictions in
    all formats. You can also make a model task part of an intermediate node, where
    the predictions from the model can then be used in subsequent modeling tasks through
    the stacking method. The stacking method outputs the combined out-of-fold features
    from the *k*-fold cross-validation strategy introduced in the *Partitioning the
    data for deep learning training* section in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125),
    *Exploring Supervised Deep Learning*. This can be useful for training a neural
    network and using it to provide new features in the inferencing stage in a non-overfitting
    manner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Comprehensively, the supported types of deep learning-specific tasks grouped
    by data type are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image tasks**: The Visual AI feature, which is the product feature name that
    encapsulates everything related to images in DataRobot, supports both pre-trained
    featurizers, fine-tuning featurizers, and predictors with the following networks:
    Darknet, EfficientNet-B0, EfficientNet-B4, Preresnet10, Resnet50, Squeezenet,
    mobilenet-v3-small, and EfficientNetV2-S. For pre-trained featurizers specifically,
    pruned variants of the networks mentioned are offered, which offer no accuracy
    degradation with improved inference speeds. For featurizers, DataRobot provides
    an out-of-the-box way to extract low-, medium-, high-, and highest-level features
    from the pre-trained network, which can be tuned according to the use case. Additionally,image
    augmentation tasks are supported, which can be configured before an experiment
    has been executed and after a blueprint has been trained through the **advanced
    tuning** feature, where a trained blueprint can be retrained with new parameters.
    During the configuration of image augmentation, insights into how the augmented
    images will appear are provided, which will be demonstrated in the coming practical
    section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Types of models for text and document**: DataRobot supports various models
    for text and document processing, including lemmatizer, pre-trained part of speech
    tagger, Stemmer, FastText embeddings, TFIDF with stopwords, pre-trained TinyBERT
    featurizer for the English language, pre-trained Roberta featurizer for the English
    language, and pre-trained MiniLM for multiple languages. Note that the strategy
    DataRobot made for text is that the stopwords and pre-trained model used will
    depend on the language detected in the EDA sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**General models**: DataRobot offers various general models, such as MLP with
    and without residuals, **Automatic Feature Interaction Learning** (**AutoInt**),
    Neural Architecture Search with Hyperband for MLP, Self-Normalizing Residual MLP
    with Training Schedule, and Adaptive Training Schedule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataRobot automatically determines the blueprints that will be included in an
    experiment based on the dataset characteristics based on the modeling strategy
    of autopilot, quick, manual, or comprehensive mode. Manual mode doesn’t run any
    blueprints and leaves it to you to decide which blueprint to run. Quick, autopilot,
    and comprehensive modes can be viewed as modes that will take the fastest, medium
    fast, and slowest to complete. The comprehensive mode that is slowest to complete
    will run either different blueprints or additional blueprints that can be long-running,
    such as large deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot uses a modeling strategy that gradually eliminates models to find
    the best balance between exploration and runtime required to build the best model.
    This involves creating a set of blueprints with smaller sample sizes and removing
    weaker models. The top blueprints are then trained with a higher sample size in
    succession. The process continues by identifying a second reduced feature list
    with only the most informative features. Finally, the best model is trained with
    this feature list. For images, a pre-trained CNN model is used as the base model
    across all blueprints. When the final blueprints are built with the final sample
    size and reduced feature list, the best model is retrained with a larger and more
    time-consuming pre-trained network. This approach helps identify the most effective
    features and ensures the final model is optimized for accuracy and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Another key modeling functionality is DataRobot’s bias and fairness functionality.
    It enables users to build and evaluate fair AI models by defining protected attributes,
    assessing various fairness metrics, and comparing model performance across different
    subpopulations. The protected attributes have to be categorical values at the
    time of writing this book. If enabled through the **Show Advanced Options** option,
    the platform automatically detects potential biases, offers mitigation strategies,
    and allows users to monitor fairness throughout the model development process.
    By incorporating these features, DataRobot promotes responsible AI deployment,
    ensuring models comply with ethical guidelines and deliver equitable results for
    all users and subgroups.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to try out tasks that are not part of the out-of-the-box deep learning
    tasks, you can leverage **custom tasks** that you can share and use in a modeling
    experiment or project. Custom tasks allow you to define custom logic to either
    preprocess data or do modeling logic. On top of this feature, the Composable ML
    feature allows you to restructure and rearrange the blueprint DAGs flexibly. These
    features allow you to leverage more commonly used methods out-of-the-box and leverage
    any custom model that you might want to try out in your experiments.
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot executes any tasks, such as training a blueprint, computing model
    insights, and computing predictions, through an on-demand worker queue. Each user
    will get their own assigned number of workers. Training and predicting with deep
    learning models can take a long time. Fortunately, DataRobot has both CPU and
    GPU workers, and deep learning models can be run on GPU workers to speed up runtime.
  prefs: []
  type: TYPE_NORMAL
- en: On the topic of evaluation, DataRobot uses nested cross-validation and never
    uses test data for in-training validation. The evaluation metrics supported by
    DataRobot are comprehensive and can be referred to at [https://docs.datarobot.com/en/docs/modeling/reference/model-detail/opt-metric.html](https://docs.datarobot.com/en/docs/modeling/reference/model-detail/opt-metric.html).
    The metrics and trained blueprints will then be presented in a leaderboard interface
    where blueprints are ranked by the chosen metric.
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons between blueprints, however, are much broader than comparing blueprints
    trained on the same dataset. Datasets can be different, experiment settings can
    be different, and associated insights can also be different. This is where the
    **Model Comparison** feature helps to bridge this gap and allows the comparison
    of many blueprint setups managed under a single use case.
  prefs: []
  type: TYPE_NORMAL
- en: As a final note here, most modeling-related settings, such as the weights column,
    partitioning strategy, and metric to optimize against, can be configured under
    the **Advanced Options** feature. We will now continue the tutorial to execute
    a model experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Practically executing modeling experiments in DataRobot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s dive into practical modeling with DataRobot through a step-by-step process,
    continuing on from the previous tutorial:'
  prefs: []
  type: TYPE_NORMAL
- en: 'After you start the modeling process, in Workbench, you will see the following
    interface, where DataRobot shows you what the platform is doing while waiting
    for blueprints to start populating:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.11 – Waiting for blueprints to populate in Workbench](img/B18187_18_11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.11 – Waiting for blueprints to populate in Workbench
  prefs: []
  type: TYPE_NORMAL
- en: 'After waiting for the blueprints to be generated and complete their training,
    in Workbench, you will be able to see the sorted trained blueprints on the left,
    as shown in *Figure 18**.12 (a)*, where we can **star** two models to compare
    them more comprehensively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.12 – (a) Showing the ranked blueprints with scores and (b) showing
    the dataset Comparison feature](img/B18187_18_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.12 – (a) Showing the ranked blueprints with scores and (b) showing
    the dataset Comparison feature
  prefs: []
  type: TYPE_NORMAL
- en: By clicking on the **Comparison** tab, you will be able to compare the two starred
    models in terms of evaluation metrics, datasets, blueprint type, and many more
    insights across different experiments, as depicted in *Figure* *18**.12 (b)*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By clicking on the best-performing model in the **Gamma Deviance** metric, we
    can investigate the blueprint structure of the model under the **Blueprint** dropdown
    depicted in *Figure 18**.13*. The blueprint is a multimodal blueprint with an
    XGBoost final modeler that takes in transformed input from categorical, geospatial,
    numerical, image, and text variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.13 – Best model blueprint diagram](img/B18187_18_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.13 – Best model blueprint diagram
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see if we can make manual improvements to the metric score, which
    you can get for the **Validation**, **Cross Validation**, or **Holdout** partitions.
    As the default experiment modeling mode is a quick pilot and you can’t rerun another
    modeling mode in Workbench as of writing, let’s manually select blueprints available
    in the repository by clicking on **View experiment info** in the top-left of the
    experiment interface, which will bring you to the interface in *Figure 18**.14*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.14 – The Blueprint repository tab in Experiment information](img/B18187_18_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.14 – The Blueprint repository tab in Experiment information
  prefs: []
  type: TYPE_NORMAL
- en: Now, search for all Keras models and fine-tuned image models, check the checkbox,
    and click on the **Train model** button on the right to train more blueprints
    that can take much longer to execute.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As an additional modeling step, let’s add image augmentation to the existing
    best model starred earlier. We can do that by navigating into the **DataRobot
    Classic Models** tab and clicking on the starred best model on the Validation
    partition. Click on the **Advanced Tuning** sub-tab under the **Evaluate** tab
    under the blueprint. This will bring you to the interface shown in *Figure 18**.15*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.15 – The Advanced Tuning interface under the best model’s Evaluate
    tab](img/B18187_18_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.15 – The Advanced Tuning interface under the best model’s Evaluate
    tab
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, scroll down to the **Image Augmentation List** tab and click on **Create
    new list**, as shown in *Figure 18**.16 (a)*. Configure **Blur**, **Cutout**,
    **Horizontal flip**, **Vertical flip**, **New images per original**, **Probability**,
    **Shift**, **Scale**, and **Rotate** to the default settings. Click on the **Preview
    augmentation** button and you will see image previews like in *Figure 18**.16
    (b)*. Now click on **Save as new list**, set your name, and click on **Create
    Augmentation List**. Finally, click on **Begin Tuning**, which is also shown in
    *Figure* *18**.16 (a)*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.16 – Image augmentation configuration in Advanced Tuning](img/B18187_18_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.16 – Image augmentation configuration in Advanced Tuning
  prefs: []
  type: TYPE_NORMAL
- en: Wait until the newly tuned blueprint completes its training, and you will be
    blessed with a better-performing blueprint!
  prefs: []
  type: TYPE_NORMAL
- en: The steps done here only cover a small part of the modeling process that DataRobot
    supports. Be sure to explore features such as bias, fairness mitigation and evaluation,
    Composable ML, custom tasks, advanced tuning of many other parameters, and time-series
    modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that up to this stage, we were using the evaluation metric as the only
    form of model comparison feedback. Comparing blueprints by only using the metric
    is not enough in most critical use cases. In the next section, we will discover
    how we can gather model and prediction insights to compare blueprints comprehensively.
  prefs: []
  type: TYPE_NORMAL
- en: Gathering model and prediction insights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Notably, DataRobot provides the following insights, which are relevant to blueprints
    that have deep learning model tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature impact**: This is a multivariate analysis that helps determine the
    importance of different features within a dataset, revealing which variables have
    the strongest influence on model predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature Effects**: This is a tool that helps you understand how each feature
    in your dataset affects the model’s predictions. It provides you with a clear
    and easy-to-interpret visual representation of the relationship between each feature
    and the model’s output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Activation maps**: These are visualizations that display the regions in an
    input image that are most responsible for making the final blueprint predictions.
    It covers neural networks as predictors, intermediate featurizers, and even intermediate
    modelers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prediction explanations**: These are techniques used to explain the output
    of a model, highlighting the contribution of each input feature to a particular
    prediction. **SHAP** (**SHapley Additive exPlanations**) and **XEMP** (**eXtended
    Example-based Model explanations through Perturbations**) are two popular methods
    that are supported. For images, image activation maps are used. For text explanations,
    a model-agnostic method is used to provide word-based importance scores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Word cloud**: This is a visualization technique that represents the frequency
    of words or phrases within a text dataset, where the size of the word indicates
    its importance or frequency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image embeddings**: This is a visualization of images in a lower-dimensional
    space that captures essential features. It is derived from the output of the supported
    CNN models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ROC curve**: This is a plot that illustrates the diagnostic ability of a
    binary classifier, showing the true positive rate against the false positive rate
    at various threshold settings, which helps in selecting an optimal threshold.
    Along with the curve, the confusion matrix and an optional profit curve feature
    are added. The profit curve is a tool that helps optimize the threshold for classification
    models by plotting the profit (or other performance metrics) against different
    threshold values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural network visualizer**: This is a tool that allows users to visualize
    the architecture of a neural network, displaying the layers, neurons, and connections
    between them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training dashboard**: This is a tool that provides you with an easy-to-use
    interface that shows you important loss curves and any metric by epochs or iterations
    for a neural network model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blueprint visualizer**: This is a feature that provides a comprehensive view
    of the overall blueprint, displaying the data processing, feature engineering,
    and modeling steps involved in creating a machine learning model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s explore some of these functionalities by continuing the earlier tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: Practically gathering insights in DataRobot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Under each blueprint in the DataRobot Classic experience, you can explore all
    the insight functionalities. In Workbench, work is being done to add the comprehensive
    insights experience, and so far, feature impact, lift charts, and residuals insights
    are available. Let’s dive into the insights part of the tutorial in a step-by-step
    manner:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by clicking on the `Image 4` column being used, even when it’s just URLs.
    The next thing is the `Home Id` column, which should’ve been removed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![ Figure 18.17 – Feature impact on the best model](img/B18187_18_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.17 – Feature impact on the best model
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will explore the feature effects of the best blueprint by clicking
    on the `Bath`. The effect graph shows that with increasing bath numbers, the price
    generally increases, which makes sense:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.18 – Feature effects for the best blueprint](img/B18187_18_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.18 – Feature effects for the best blueprint
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on the `Description` is also one of the top contributing features.
    Clicking on the symbol under the **Value** column open a pop-up modal window will
    allow you to check the text explanations for the feature, as shown in *Figure
    18**.19*. Both the explanations look good and make good sense here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.19 – Prediction explanations for the best blueprint](img/B18187_18_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.19 – Prediction explanations for the best blueprint
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s click on the `nice` being attributed negatively. However, `cozy`
    makes sense to be negatively attributed, as it usually refers to small units.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.20 – Word cloud importance attribution of the best blueprint](img/B18187_18_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.20 – Word cloud importance attribution of the best blueprint
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on the **Activation Maps** sub-tab to see the interface shown in
    *Figure 18**.21*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.21 – Activation maps of the best-performing blueprint](img/B18187_18_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.21 – Activation maps of the best-performing blueprint
  prefs: []
  type: TYPE_NORMAL
- en: For image activation maps, you want to look out for areas that don’t make sense
    logically. Ask questions such as, “Why is the model looking at the sky?” or “Why
    is the model looking at the grass?” Also, ask follow-up questions such as “Is
    a well-trimmed lawn connected to price?” For this use case, there are a lot of
    visual components at play that make it hard to say what doesn’t make sense. Focusing
    on grass can still be meaningful, but It’s a relief that the model is at least
    not looking at the sky, which contributes to nothing. Additionally, the predicted
    and actual filter can allow you to pinpoint the successful example’s behavior
    vs the failed example’s behavior, which can be useful to form a mental picture
    of what patterns the model is identifying. Another issue is that the image column
    isn’t standardized with regard to which part of the house it is representing.
    Standardizing can help you achieve a better prediction performance.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you can export the insights individually, and better yet, download
    the compliance report documentation that provides an offline one-stop document
    with all the insights. You can do this by clicking on the **Compliance** tab and
    clicking on the **Create Report** button shown in *Figure 18**.22*. There is a
    default structure of the document, but you can craft the exact structure that
    you want to have in your report. An example document is provided in the code repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 18.22 – The Model Compliance Documentation interface under the blueprint](img/B18187_18_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.22 – The Model Compliance Documentation interface under the blueprint
  prefs: []
  type: TYPE_NORMAL
- en: With that, we are done with the tutorial on gathering insights. However, note
    that this is not a comprehensive take on gathering insights for this use case.
    So, be sure to test out more insight types such as lift charts and image embeddings
    and iterate through more model improvements that you identify through gathering
    insights.
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on to the DLOps side of things, to deploy and govern a deep learning
    model, let’s explore how batch predictions can be made without deploying a model.
  prefs: []
  type: TYPE_NORMAL
- en: Making batch predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are use cases where a deployment is not needed, as predictions can be
    made asynchronously in a regular cadence via a custom trigger or a one-time event.
    This is where the **batch predictions** feature from DataRobot comes in. Batch
    predictions simply allow you to upload your data, compute predictions optionally
    with prediction explanations, and, once this is done, download the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'This step can be done in both DataRobot Classic and Workbench. For the DataRobot
    Classic graphical UI experience, navigate to the **Make Predictions** sub-tab
    under the **Predict** tab of a leaderboard model. You will then be able to upload
    the dataset you want to generate one-off predictions with. This interface is shown
    in *Figure 18**.23*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.23 – Batch predictions functionality interface](img/B18187_18_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.23 – Batch predictions functionality interface
  prefs: []
  type: TYPE_NORMAL
- en: There will still be use cases where real-time predictions are needed by single
    samples. This brings us to the next section—discussing how DataRobot manages the
    deployment of a blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a deep learning blueprint
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DataRobot allows the deployment of a model directly through a trained blueprint
    in an experiment or a project, which we will explore in the next practical section.
    However, for more advanced users, the platform also allows the deployment of custom
    models through the `requirements.txt` file. Once uploaded, users can create, test,
    and deploy custom inference models to DataRobot’s centralized deployment hub.
    These custom models support different model types, which include regression, classification,
    and unstructured types where the input and output can be of various types.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure the reliability and compatibility of your custom models, DataRobot
    provides a comprehensive testing suite in the Custom Model Workshop. The custom
    model testing suite encompasses a comprehensive range of evaluations, including
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Startup check**: This ensures that the custom model can be built and the
    custom model service can be launched without errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Null imputation check**: This validates the handling of missing values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Side effects check**: This makes sure that a row of data predicted as part
    of a batch of data produces the same predictions as the same row of data predicted
    with a single row of data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'P**rediction verification**: This confirms the correctness of predictions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance check**: This gauges the efficiency and speed of the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stability check**: This evaluates the model’s consistency and reliability'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Duration check**: This measures the time taken for various tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By running these tests, you can verify the performance, stability, and prediction
    accuracy of your custom models before deployment. A bonus here with a supervised
    custom model is that it can be linked to training data, which will allow prediction
    explanations to be computed and data drift to be measured and monitored. Once
    your custom model is assembled and tested, you can deploy it alongside other blueprints
    in DataRobot, making it a versatile and powerful tool for advanced users. To deploy
    a model, either a custom or a local DataRobot model, a prerequisite is that you’d
    need to choose the reliability of the deployment that you want. Levels of reliability
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Low**: This is suitable for non-critical, experimental, or low-priority use
    cases where occasional downtime or reduced performance is acceptable. This option
    provides minimal resources and infrastructure redundancy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Medium**: This is ideal for moderately important use cases that require a
    balance between cost and performance. This level offers better resources and redundancy
    than the low option, but you may still experience some downtime or reduced performance
    during peak loads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High**: This is recommended for important use cases that demand high availability
    and performance. This level provides increased resources, infrastructure redundancy,
    and faster response times to ensure consistent performance, even during heavy
    loads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Critical**: This is designed for mission-critical applications where maximum
    availability and performance are essential. This option offers the highest level
    of resources, redundancy, and response times to ensure near-zero downtime and
    optimal performance under any conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing an appropriate reliability level allows DataRobot to configure an appropriate
    server machine type and infrastructure to host your model according to your requirements.
    As there are limitations to the deployment your organization signed up with, choosing
    an appropriate reliability level will make sure you don’t overpay after passing
    the organization deployment limits, or it just makes sure you stay under the deployment
    limits. In other words, you must manage costs incurred when it comes to deployment.
    Let’s continue through the previous tutorial and deploy the best-performing blueprint
    that wasn’t trained into the validation or holdout partition.
  prefs: []
  type: TYPE_NORMAL
- en: Practically deploying a blueprint in DataRobot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deploying a blueprint is as simple as going to the **Deploy** sub-tab under
    the **Predict** tab under a blueprint and then clicking the **Deploy model** button.
    You then need to choose the deployment reliabilitythe default is low. Then, click
    on the **Deploy model** button again in the same location. The interface for the
    first **Deploy model** button is shown in *Figure 18**.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.24 – Deploying a blueprint](img/B18187_18_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.24 – Deploying a blueprint
  prefs: []
  type: TYPE_NORMAL
- en: And that’s it! We have successfully deployed a model in DataRobot with the click
    of two buttons. Next, we will discuss how DataRobot governs its deployed blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: Governing a deployed deep learning blueprint
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss how DataRobot enables users to govern their
    deep-learning models effectively by providing comprehensive tools for model utilization,
    monitoring, and maintenance. With a focus on seamless integration, DataRobot allows
    users to deploy AI applications on cloud-based or on-premises infrastructure,
    manage prediction outputs, and monitor model performance using custom metrics
    and alerts. Furthermore, the platform supports data drift detection and offers
    retraining capabilities for continuous model improvement. We will explore these
    features in detail, demonstrating how DataRobot empowers users to efficiently
    manage their deep learning models and ensure optimal performance throughout their
    life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Governing through model utilization in DataRobot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Users can access their models through various means, such as API calls, Python
    interfaces, or DataRobot-made applications called `base64` format. DataRobot also
    facilitates the direct storage of predictions into databases, streamlining the
    process of incorporating model outputs into existing workflows or applications.
    Additionally, DataRobot allows for the scheduling of batch predictions with a
    deployed model to be executed regularly to the specified frequency and time.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the model utilization component in DataRobot simplifies the process
    of leveraging deep learning models and machine learning models in general, making
    it more accessible and efficient for users across various domains.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s continue on from the previous tutorial to get predictions using the
    DataRobot HTTP client library.
  prefs: []
  type: TYPE_NORMAL
- en: Practically consuming predictions from a deployed blueprint in DataRobot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will continue on from the previous tutorial and use the
    `datarobotx` Python client library to generate predictions with the deployed model.
    Under each deployment, DataRobot includes low-level example code to make real-time
    `prediction-api` requests to a deployment. However, in this tutorial, we will
    utilize an easy-to-use, high-level library called `datarobotx` that simplifies
    making `prediction-api` requests. Let’s start the step-by-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by importing the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will initialize the deployment instance based on the deployment ID.
    You’d have to replace `deployment_id` with your own deployment ID here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will set the API token and the endpoint URL in a DataRobot context
    class. You’d have to set your own token here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will load the `trulia_one_row.csv` house pricing DataFrame provided
    in the code repository and make a prediction using the initialized deployment
    instance. Finally, we display the predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will produce the following results:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: And that concludes the tutorial. We will now dive into how DataRobot implements
    model monitoring for a deployed model.
  prefs: []
  type: TYPE_NORMAL
- en: Governing through model monitoring in DataRobot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Model monitoring in DataRobot is an essential component that allows users to
    track the performance and health of their deployed deep learning models. The platform
    provides several features to ensure models maintain optimal performance over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data drift detection**: DataRobot continuously monitors changes in the distribution
    of input data, identifying any deviations from the original training data. This
    feature helps users understand when their models might be at risk of becoming
    less accurate due to shifts in the underlying data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model performance monitoring**: Users can track the performance of their
    models over time. This includes the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accuracy**: This can be monitored by comparing the actual target values with
    the predicted values. Actual target values can be sent to the deployment any time
    after a prediction has been made with the prerequisite that an association ID
    has to be set and returned to connect the actual targets to the historical prediction
    requests.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fairness**: This ensures that AI models continue to provide fair and unbiased
    predictions in a production environment. An association ID is similarly required
    here, as it is tied to the accuracy-related performance metric. Key aspects of
    the fairness functionality for deployed models include the following:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fairness metrics tracking**: The platform tracks various fairness metrics,
    such as disparate impact, demographic parity, and equal opportunity, enabling
    users to assess the fairness of their models across different subgroups within
    the protected attributes.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alerts and notifications**: DataRobot can be configured to send alerts and
    notifications if biases or disparities are detected, ensuring that users are promptly
    informed about any fairness issues that may arise during the model’s life cycle.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Humility rules**: Users can set actions to execute based on undesirable conditions.
    Supported conditions are defined as uncertainties in predictions, outlier input
    values or ranges, and low observation regions. Supported actions are recording
    the trigger, overriding the prediction with a defined prediction, and throwing
    an error. This enhances the user’s overall confidence in the model’s predictions
    and mitigates the risk of it making incorrect decisions based on low-confidence
    predictions, out-of-distribution data, or low observation data points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment service health monitoring**: This includes total predictions made,
    total requests made, requests made over a defined time interval, aggregated response
    time (such as median), aggregated execution time (median), median peak load at
    calls per minute, data error rate, system error rate, number of consumers, and
    cache hit rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment notifications**: Be notified about changes in the deployment,
    either for all changes or just critical changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom metrics tracking and alerting**: DataRobot enables users to define
    and monitor custom performance metrics specific to their use cases. Users can
    set up alerts to notify them when certain thresholds are reached, ensuring prompt
    response to any performance-related issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s practically explore the interface that DataRobot provides for model
    monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Practically monitoring a deployed blueprint in DataRobot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By clicking on the **Service Health** tab of the deployed model, you will be
    able to see the general service health monitoring. This is shown in *Figure 18**.25*.
    Additionally, you can check out the dashboards for data drift, accuracy, humility,
    fairness, and custom metrics each in their own tab under the deployed model. Notifications,
    on the other hand, are by default configured to be sent to all deployment activities
    and can be configured based on preferences.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 18.25 –The service health of the deployed model](img/B18187_18_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 18.25 –The service health of the deployed model
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will discuss how a user can maintain the performance of the deployed
    model and ensure that the model can continuously deliver value.
  prefs: []
  type: TYPE_NORMAL
- en: Governing through model maintenance in DataRobot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Model maintenance in DataRobot is a crucial aspect of managing deep learning
    models, ensuring that they continue to deliver accurate and reliable results throughout
    their life cycle. The platform provides several features to facilitate effective
    model maintenance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Challenger models and model replacement**: DataRobot allows users to create
    and compare alternative models, known as challengers, against the currently deployed
    model. By evaluating the performance of these challenger models, users can identify
    potential improvements and decide if it’s necessary to replace the existing model
    with a better-performing alternative. Once a better model has been identified,
    it is referred to as the **Champion model**. It will then replace the previous
    model for the existing deployment. This maintains the same deployment ID and ensures
    a seamless transition to a better model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model versioning**: DataRobot tracks and manages different versions of a
    model, allowing users to easily revert to previous versions if needed. This feature
    ensures that users can maintain a history of their models and compare their performance
    across different versions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retraining and retraining policies**: Users can register data received by
    the deployed model, including input data and delayed target values, into the AI
    Catalog. This enables the models to be retrained with the most recent data. Additionally,
    DataRobot’s retraining policies provide a way to manage and automate the model
    updating process, ensuring that deployed models stay relevant and maintain optimal
    performance. Key aspects of retraining policies include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customizable triggers**: Users can define specific triggers for retraining,
    such as data drift, performance degradation, or scheduled intervals, to initiate
    the retraining process automatically when certain conditions are met.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data integration**: Retraining policies facilitate the seamless integration
    of new data into the model updating process, ensuring that models are trained
    on the most recent and relevant information.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated retraining and deployment workflow**: DataRobot automates the entire
    retraining process, from data ingestion and preprocessing to model building and
    validation, streamlining the model update workflow and reducing manual effort.
    You can choose to either maintain the same model with the same parameters, maintain
    the same model with hyperparameter optimization, or just choose the best model
    from autopilot. Retrained models are automatically evaluated against the new data
    using performance metrics, enabling users to assess the updated model’s performance
    and determine if it’s ready for redeployment. Once a retrained model meets the
    desired performance criteria you‘d wish to achieve, DataRobot facilitates its
    seamless deployment, replacing the existing model with minimal interruption. By
    employing retraining policies, DataRobot simplifies and automates the model updating
    process, helping users ensure that their deployed AI models remain accurate, relevant,
    and high-performing as new data and insights become available.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By delving into the features supported by DataRobot and going through hands-on
    tutorials, we’ve gained significant insights into how DataRobot employs deep learning
    methods to process and analyze data, including unstructured and structured data.
    Now, let’s examine some real-world examples that demonstrate the capabilities
    of this technology, as shared by customers who were enthusiastic about their experiences
    with DataRobot.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring some customer success stories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DataRobot has empowered numerous organizations to achieve remarkable success
    through the implementation of deep learning solutions, particularly in handling
    unstructured data such as text and images. While most of these success stories
    remain confidential, we are fortunate to have a few customers who have enthusiastically
    shared their inspiring experiences, showcasing the transformative potential of
    deep learning in various industries. Some of these notable successes include the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Lenovo, a leading technology company, successfully implemented DataRobot’s Visual
    AI in its Brazilian laptop manufacturing facility to improve quality control and
    increase productivity. The Visual AI system helped increase label verification
    accuracy from 93% to 98% by automating the comparison of identification labels
    on laptops with their respective bill of materials. This implementation not only
    reduced errors in the manual labeling process but also had a positive impact on
    delivery times, customer satisfaction, and legal risk reduction for the manufacturer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OYAK Cement, a leading Turkish cement maker, successfully utilized DataRobot’s
    AI solutions to optimize their manufacturing processes, resulting in reduced costs
    and CO2 emissions. By implementing AI-assisted process control, OYAK increased
    alternative fuel usage by seven times, cutting almost 2% of total CO2 emissions
    and reducing costs by approximately $39 million. The company was also able to
    predict and prevent mechanical failures more efficiently, improving overall operational
    efficiency and environmental sustainability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AUTOproff successfully implemented the DataRobot AI Platform, which included
    visual AI capabilities for processing image data of vehicles, to develop their
    Pricing Robot to make automated car value estimations. The AI-driven solution
    automated 55–60% of all estimates, leading to improved pricing accuracy and a
    significant reduction in the time required to generate quotes. As a result, the
    estimators could focus on rarer vehicles, enhancing their efficiency. The Pricing
    Robot’s success has played a pivotal role in AUTOproff’s European expansion, enabling
    the company to swiftly adapt to new markets. This has ultimately led to increased
    customer satisfaction and streamlined business operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on the latest success stories, check out [https://www.datarobot.com/customers/](https://www.datarobot.com/customers/).
  prefs: []
  type: TYPE_NORMAL
- en: As we reach the end of this chapter, if you are interested in trying out the
    DataRobot AI Platform for yourself and don’t already have access, you can subscribe
    for a free trial. And that’s it! This will allow you to experience first-hand
    the powerful tools and automation features that DataRobot offers for 30 days (as
    of 28 September 2023), enabling you to focus on extracting significant value from
    your deep learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explored the DataRobot AI Platform and showcased the benefits an
    AI platform can provide to you in general. DataRobot streamlines the complex stages
    of the machine learning life cycle, providing an intuitive interface for data
    scientists, engineers, and researchers. By harnessing the potential of AI platforms
    such as DataRobot, users can accelerate the creation, training, deployment, and
    governance of intricate deep learning models, focusing on extracting significant
    value from their machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot offers automation, collaboration, and scalability for machine learning
    use cases. DataRobot provides support for various data types and advanced features
    such as bias and fairness mitigation, Composable ML, custom tasks, advanced tuning,
    and time-series modeling. DataRobot also enables users to deploy AI applications
    on cloud-based or on-premises infrastructure, manage prediction outputs, monitor
    model performance, and maintain models implemented in features such as **Challenger
    Models**, **Model Versioning**, **Retraining**, and **Retraining policies**.
  prefs: []
  type: TYPE_NORMAL
- en: While this chapter showcased the various features and capabilities of the DataRobot
    AI platform, it is not a comprehensive coverage of what the platform provides.
    Additionally, the company constantly evolves to attend to real-world data science
    needs, so any unsupported features may be added in the future. For a more detailed
    understanding, you can refer to the official documentation at [https://docs.datarobot.com/](https://docs.datarobot.com/).
  prefs: []
  type: TYPE_NORMAL
- en: In summary, AI platforms such as DataRobot offer a powerful solution for deep
    learning applications, streamlining and accelerating the deep learning life cycle.
    However, they are not a replacement for the expertise and creativity of data scientists,
    engineers, analysts, or researchers; instead, they serve as tools to assist practitioners
    in solving complex problems quickly and accurately.
  prefs: []
  type: TYPE_NORMAL
- en: As we move forward to the next chapter, we will delve deeper into the world
    of large language models, exploring their potential, challenges, and ways to create
    effective solutions. Building upon the foundation from all the previous chapters,
    we’ll uncover how to harness the power of LLMs to tackle complex language-related
    tasks and create advanced, contextually-aware applications.
  prefs: []
  type: TYPE_NORMAL
