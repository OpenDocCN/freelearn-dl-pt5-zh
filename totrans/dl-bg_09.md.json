["```py\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\n```", "```py\ninpt_dim = 8\nltnt_dim = 2 \n\ninpt_vec = Input(shape=(inpt_dim,))\n```", "```py\nelayer1 = Dense(6, activation='sigmoid')(inpt_vec)\nelayer2 = Dense(4, activation='sigmoid') (elayer1)\nencoder = Dense(ltnt_dim, activation='sigmoid') (elayer2)\n```", "```py\nlatent_ncdr = Model(inpt_vec, encoder)\n```", "```py\ndlayer1 = Dense(4, activation='sigmoid')(encoder)\ndlayer2 = Dense(6, activation='sigmoid') (dlayer1)\ndecoder = Dense(inpt_dim, activation='sigmoid') (dlayer2)\n```", "```py\nautoencoder = Model(inpt_vec, decoder)\n```", "```py\nautoencoder.compile(loss='mean_squared_error', optimizer='sgd')\n```", "```py\nimport numpy as np\nx = np.array([[0., 0., 1., 0., 0., 1., 1., 1.]])\n```", "```py\nhist = autoencoder.fit(x, x, epochs=10000, verbose=0)\n\nencdd = latent_ncdr.predict(x)\nx_hat = autoencoder.predict(x)\n```", "```py\nprint(encdd)\nprint(x_hat)\nprint(np.mean(np.square(x-x_hat)))  # MSE\n```", "```py\n[[0.54846555 0.4299447 ]]\n[[0.07678119 0.07935049 0.91219556 0.07693048 0.07255505 0.9112366 0.9168126 0.9168152 ]]\n0.0066003498745448655\n```", "```py\nimport matplotlib.pyplot as plt\n\nplt.plot(hist.history['loss'])\nplt.title('Model reconstruction loss')\nplt.ylabel('MSE')\nplt.xlabel('Epoch')\nplt.show()\n```", "```py\nx = np.array([[1., 1., 0., 1., 1., 0., 0., 0.]])  #216\n\nencdd = latent_ncdr.predict(x)\nx_hat = autoencoder.predict(x)\n\nprint(encdd)\nprint(x_hat)\nprint(np.mean(np.square(x-x_hat)))\n```", "```py\n[[0.51493704 0.43615338]]\n[[0.07677279 0.07933337 0.9122421 0.07690183 0.07254466 0.9112378 0.9167745 0.91684484]]\n0.8444848864148122\n```", "```py\nfrom tensorflow.keras.datasets import mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = x_train.reshape((len(x_train), 28*28))\nx_test = x_test.reshape((len(x_test), 28*28))\n```", "```py\ninpt_dim = 28*28\nltnt_dim = 2\n\ninpt_vec = Input(shape=(inpt_dim,))\n\nelayer1 = Dense(392, activation='sigmoid')(inpt_vec)\nelayer2 = Dense(28, activation='sigmoid') (elayer1)\nelayer3 = Dense(10, activation='sigmoid') (elayer2)\nencoder = Dense(ltnt_dim, activation='tanh')(elayer3)\n\ndlayer1 = Dense(10, activation='sigmoid')(encoder)\ndlayer2 = Dense(28, activation='sigmoid')(dlayer1)\ndlayer3 = Dense(392, activation='sigmoid')(dlayer2)\ndecoder = Dense(inpt_dim, activation='sigmoid')(dlayer3)\n\nlatent_ncdr = Model(inpt_vec, encoder)\nautoencoder = Model(inpt_vec, decoder)\n\nautoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n\nhist = autoencoder.fit(x_train, x_train, epochs=100, batch_size=256, \n                       shuffle=True, validation_data=(x_test, x_test))\n```", "```py\nencdd = latent_ncdr.predict(x_test)\n```", "```py\nx_hat = autoencoder.predict(x_test)\n```"]