- en: 4\. Neural Network Training
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 神经网络训练
- en: This chapter describes neural network training. When we talk about "training"
    in this context, we mean obtaining the optimal weight parameters automatically
    from training data. In this chapter, we will introduce a criterion called a loss
    function; this enables a neural network to learn. The purpose of training is to
    discover the weight parameters that lead to the smallest value of the loss function.
    In this chapter, we will be introduced to the method of using the gradient of
    a function, called a gradient method, to discover the smallest loss function value.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍神经网络的训练。当我们在这个语境中谈论“训练”时，我们指的是从训练数据中自动获取最佳权重参数。在本章中，我们将介绍一种称为损失函数的标准，它使得神经网络能够学习。训练的目的是发现能够使损失函数值最小的权重参数。本章还将介绍一种通过函数梯度发现最小损失函数值的方法，这种方法被称为梯度法。
- en: Learning from Data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从数据中学习
- en: The essential characteristic of a neural network is its ability to learn from
    data. Training from data means that weight parameter values can be automatically
    determined. If you have to determine all the parameters manually, it is quite
    hard work. For example, for a sample perceptron, as shown in *Chapter 2*, *Perceptrons*,
    we determined the parameter values manually while looking at the truth table.
    There are as few as three parameters. However, in an actual neural network, the
    number of parameters can range between thousands and tens of thousands. For deep
    learning with more layers, the number of parameters may reach hundreds of millions.
    It is almost impossible to determine them manually. This chapter describes neural
    network training, or how to determine parameter values from data, and implements
    a model that learns handwritten digits from the MNIST dataset with Python.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的核心特性是其从数据中学习的能力。从数据中学习意味着权重参数的值可以自动确定。如果你需要手动确定所有参数，这将是一项非常艰巨的任务。例如，对于一个样本感知机，如*第二章*所示的*感知机*，我们在查看真值表时手动确定了参数值。这里只有三个参数。然而，在实际的神经网络中，参数的数量可以从几千到几万不等。对于具有更多层次的深度学习，参数数量可能达到数亿。手动确定这些参数几乎是不可能的。本章描述了神经网络的训练，或者说如何从数据中确定参数值，并实现了一个使用Python从MNIST数据集学习手写数字的模型。
- en: Note
  id: totrans-4
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For a linearly separable problem, a perceptron can learn automatically from
    data. That training, when completed a finite number of times, can solve a linearly
    separable problem, which is known as "the perceptron convergence theorem." On
    the other hand, a nonlinear separation problem cannot be solved (automatically).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性可分问题，感知机可以通过数据自动学习。当训练完成一定次数时，它能够解决线性可分问题，这就是所谓的“感知机收敛定理”。另一方面，非线性分离问题是无法解决的（自动化）。
- en: Data-Driven
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据驱动
- en: Data is critical in machine learning. Machine learning looks for an answer in
    the data, finds a pattern in the data, and tells a story based on it. It can do
    nothing without data. Therefore, "data" exists at the center of machine learning.
    We can say that this data-driven approach is a departure from a "man"-centered
    approach.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在机器学习中至关重要。机器学习在数据中寻找答案，发现数据中的模式，并基于此讲述一个故事。没有数据，它什么也做不了。因此，“数据”处于机器学习的核心。我们可以说，这种数据驱动的方法是对以“人”为中心方法的偏离。
- en: Usually, when we solve a problem—especially when we need to find a pattern—we
    must consider various things to find an answer. "This problem seems to have this
    pattern." "No, there may be a cause somewhere else." Based on our experience and
    intuition, we advance this task through trial and error. Machine learning avoids
    human intervention as much as possible. It tries to find an answer (pattern) from
    the collected data. Moreover, a neural network and deep learning have an important
    characteristic in common in that they can avoid human intervention more than traditional
    machine learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们解决一个问题时——尤其是当我们需要找出一个模式时——我们必须考虑各种因素来找到答案。“这个问题似乎有这样的模式。”“不，可能在别的地方有原因。”基于我们的经验和直觉，我们通过反复试验推进这一任务。机器学习尽量避免人为干预。它试图从收集到的数据中找到答案（模式）。此外，神经网络和深度学习有一个共同的重要特性，那就是它们能够比传统的机器学习更好地避免人为干预。
- en: Let's look at a specific problem here. Suppose that we want to implement a program
    that recognizes the number "5", for example. Let's suppose that our goal is implementing
    the program that determines whether handwritten images, as shown in *Figure 4.1*,
    are "5" or not "5". This problem seems relatively simple. What algorithm can we
    use?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个具体的问题。假设我们想实现一个识别数字"5"的程序。假设我们的目标是实现一个程序，判断手写图像（如*图4.1*所示）是"5"还是不是"5"。这个问题看起来相对简单。我们可以使用什么算法呢？
- en: '![Figure 4.1: Sample handwritten digits – how "5" is written varies from person
    to person'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.1：手写数字示例——"5"的书写方式因人而异'
- en: '](img/fig04_1.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/fig04_1.jpg)'
- en: 'Figure 4.1: Sample handwritten digits – how "5" is written varies from person
    to person'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.1：手写数字示例——"5"的书写方式因人而异
- en: When you try to design a program that can classify "5" correctly, you will find
    that it is a more difficult problem than expected. We can easily recognize "5",
    but it is difficult to clarify the rule for recognizing an image as "5". As shown
    in *Figure 4.1*, how it is written differs from person to person. This tells us
    that finding the rule for recognizing "5" will be hard work and that it may take
    a lot of time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当你尝试设计一个能正确分类"5"的程序时，你会发现这比预期的要难得多。我们可以轻松识别"5"，但很难明确识别图像为"5"的规则。如*图4.1*所示，书写方式因人而异。这告诉我们，找到识别"5"的规则将是艰苦的工作，并且可能需要大量的时间。
- en: Now, instead of "working out" the algorithm that recognizes "5" from scratch,
    we want to use data effectively to solve the problem. One of the methods we can
    use is to extract features from an image and use machine learning technology to
    learn the pattern of the features. A feature indicates a converter that is designed
    to extract essential data (important data) from input data (input image) accurately.
    The feature of an image is usually described as a vector. Famous features in the
    field of computer vision include SIFT, SURF, and HOG. You can use these features
    to convert image data into vectors and use a classifier in machine learning, such
    as SVM and KNN, to learn the converted vectors.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不再是从零开始"推导"出识别"5"的算法，而是希望有效利用数据来解决问题。我们可以使用的方法之一是从图像中提取特征，并使用机器学习技术来学习这些特征的模式。特征指的是一个转换器，它被设计用来准确地从输入数据（输入图像）中提取重要数据（关键数据）。图像的特征通常被描述为一个向量。在计算机视觉领域，著名的特征包括SIFT、SURF和HOG。你可以使用这些特征将图像数据转换为向量，并使用机器学习中的分类器，如SVM和KNN，来学习转换后的向量。
- en: In this machine learning approach, a "machine" discovers a pattern from the
    collected data. This can solve a problem more efficiently and reduce the burden
    on a "person" compared to when we invent an algorithm from scratch. However, we
    must note that the features that are used when images are converted into vectors
    are designed by a "man." This is because good results cannot be obtained without
    using features that are suitable for the problem (or without designing the features).
    For example, to recognize the face of a dog, a person may need to select the features
    that are different from those for recognizing "5". After all, even the approach
    of using features and machine learning may need suitable features to be selected
    by a "man," depending on the problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种机器学习方法中，"机器"从收集到的数据中发现一个模式。与我们从头开始发明算法相比，这可以更高效地解决问题，并减少对"人"的负担。然而，我们必须注意，当图像被转换成向量时，所使用的特征是由"人"设计的。因为没有使用适合问题的特征（或者没有设计特征），是无法获得良好结果的。例如，要识别狗的面部，可能需要选择与识别"5"不同的特征。毕竟，即使是使用特征和机器学习的方法，也可能需要根据问题选择合适的特征，这些特征仍然由"人"来选择。
- en: So far, we have discussed two approaches to machine learning problems. These
    two approaches are shown in the upper rows in *Figure 4.2*. Meanwhile, the approach
    to using a neural network (deep learning) is shown in the lower row of *Figure
    4.2*. It is represented by a block without human intervention.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了两种机器学习方法。这两种方法如*图4.2*中的上排所示。同时，使用神经网络（深度学习）的方法则显示在*图4.2*的下排。它通过一个没有人工干预的模块来表示。
- en: 'As shown in *Figure 4.2*, a neural network learns images "as they are." In
    the second approach, an example that uses features and machine learning, called
    human-designed features, are used, while in a neural network, a "machine" learns
    important features from images:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图4.2*所示，神经网络学习的是图像"原样"。在第二种方法中，使用特征和机器学习的示例，称为人工设计的特征，而在神经网络中，"机器"从图像中学习重要的特征：
- en: '![Figure 4.2: A paradigm shift from man-made rules to a "machine" learning
    from data –'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: a block without human intervention is shown in gray
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_2.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.2: A paradigm shift from man-made rules to a "machine" learning from
    data – a block without human intervention is shown in gray'
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Deep learning is sometimes called "end-to-end machine learning." "**End-to-end**"
    means "from one end to the other end," that is, the acquisition of the desired
    result (output) from raw data (input).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of a neural network is that it can solve all the problems in the
    same flow; for example, whether trying to recognize "5", a dog, or a human face,
    a neural network learns the provided data patiently, trying to discover a pattern
    in the given problem. A neural network can learn data as it is "end-to-end," regardless
    of the problem to solve.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Training Data and Test Data
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we will cover neural network training, beginning with some
    best practices when handling data in machine learning.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning problems, we usually use **training data** and **test data**
    according to the purpose. First, we use only training data to find optimal parameters.
    Then, we use test data to evaluate the ability of the trained model. Why should
    we divide training data and test data? Because we want the generalization capability
    of the model. We must separate the training data and test data because we want
    to evaluate this **generalization** correctly.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Generalization means the ability of unknown data (data that is not contained
    in the training data), and the ultimate goal of machine learning is to obtain
    this generalization. For example, handwritten digit recognition may be used in
    a system for reading postal codes on postcards automatically. In that case, handwritten
    digit recognition must be able to recognize the characters written by "someone."
    That "someone" is not "a specific character written by a specific person," but
    "an arbitrary character is written by an arbitrary person." Even if the model
    can distinguish only your training data well, it may have learned only specific
    characters of the person's handwriting contained in the data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if you use only one dataset to learn parameters and evaluate them,
    the correct evaluation will not be provided. This results in a model that can
    handle a certain dataset well but cannot handle another one. When a model has
    become too adapted to only one dataset, **overfitting** occurs. Avoiding overfitting
    is an important challenge in machine learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Loss Function
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How do you answer when you are asked, "How happy are you now?". We may usually
    answer vaguely: "I am moderately happy" or "I am not very happy." You may be surprised
    if someone answers, "My current happiness score is 10.23" because the person can
    only quantify their happiness with one score. If such a person exists, the person
    may lead their life only based on their "happiness score."'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: This "happiness score" is an allegory used to illustrate some similar things
    which occur in neural network training. In neural network training, one "score"
    is used to indicate the current status. Based on the score, optimal weight parameters
    are searched for. As this person looks for an "optimal life" based on the "happiness
    score," a neural network searches for optimal parameters using "one score" as
    a guide. The score that's used in neural network training is called a **loss function**.
    Although any function can be used as the loss function, the sum of squared errors
    or a cross-entropy error is usually used.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A loss function is an index that indicates the "poorness" of a neural network's
    ability. It indicates how unfit the current neural network is for labeled data
    and how it deviates from labeled data. You may feel that it's unnatural for the
    "poorness of ability" to be the score, but you can interpret the loss function
    multiplied by a negative value as the score of the opposite of "how poor the ability
    is" (that is, the score of "how good the ability is"). "To minimize poorness of
    ability" is the same as "to maximize the goodness of ability." Therefore, the
    index of the "poorness" of ability is essentially the same as that of the "goodness"
    of ability.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Sum of Squared Errors
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a few functions that are used as loss functions. Probably the most
    famous one is the **sum of squared errors**. It is expressed by the following
    equation:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '| ![18](img/Figure_4.2a.png) | (4.1) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: 'Here, *y*k is the output of the neural network, *t*k is labeled data, and *k*
    is the number of dimensions of the data. For example, in the section, *Handwritten
    Digit Recognition*, of *Chapter 3*, *Neural networks*, *y*k, and *t*k are data
    items that consist of 10 elements:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The elements of these arrays correspond to numbers "0," "1," "2," ... in order
    from the first index. Here, the output of the neural network, y, is the output
    of a softmax function. The output of the softmax function can be interpreted as
    a probability. In this example, the probability of "0" is 0.1, that of "1" is
    0.05, that of "2" is 0.6, and so on. Meanwhile, t is labeled data. In the labeled
    data, the correct label is 1 and the other labels are 0\. Here, label "2" is 1,
    which indicates that the correct answer is "2." Setting 1 for the correct label
    and 0 for other labels is called **one-hot representation**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in equation (4.1), the sum of squared errors is the sum of the squares
    of the differences between the outputs of the neural network and the corresponding
    elements of the correct teacher data. Now, let''s implement the sum of squared
    errors in Python. You can implement it as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, the `y` and `t` arguments are NumPy arrays. Because this simply implements
    equation (4.1), we won''t explain this here. Now, we will use this function to
    perform a calculation:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: There are two examples here. In the first one, the correct answer is "2", and
    the output of the neural network is the largest at "2." Meanwhile, in the second
    one, the correct answer is "2," but the output of the neural network is the largest
    at "7." As the result of this experiment shows, the loss function of the first
    example is smaller, which indicates that the difference in the labeled data is
    smaller. In other words, the sum of squared errors indicates that the output in
    the first example fits the labeled data better.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Entropy Error
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Other than the sum of squared errors, a **cross-entropy error** is also often
    used as a loss function. It is expressed by the following equation:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '| ![19](img/Figure_4.2b.png) | (4.2) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: 'Here, log indicates the natural logarithm, that is, the logarithm to the base
    of *e (log*e*)*. yk is the output of the neural network and tk is the correct
    label. In tk, only the index for the correct label is 1; the other indices are
    0 (one-hot representation). Therefore, equation (4.2) only calculates the logarithm
    of the output that corresponds to the correct label, 1\. For example, if "2" is
    the index of the correct label, and the corresponding output from the neural network
    is 0.6, a cross-entropy error is `-log 0.6 = 0.51`. If the output for "2" is 0.1,
    the error is `-log 0.1 = 2.30`. A cross-entropy error depends on the output result
    from the correct label. *Figure 4.3* shows the graph of this natural logarithm:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3: Graph of the natural logarithm y = log x'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_3.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.3: Graph of the natural logarithm y = log x'
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As shown in *Figure 4.3*, *y* is 0 when *x* is 1, and the value of *y* is getting
    smaller as *x* approaches 0\. Therefore, since the output corresponding to the
    correct label is larger, equation (4.2) approaches 0\. When the output is 1, the
    cross-entropy error becomes 0\. When the output corresponding to the correct label
    is smaller, the value of equation (4.2) is larger.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s implement a cross-entropy error:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, the y and t arguments are NumPy arrays. When `np.log` is calculated,
    a very small value, delta, is added. If `np.log(0)` is calculated, `-inf`, which
    indicates minus infinity, is returned. At this point, the calculation cannot be
    advanced further. To avoid this, a very small value is added so that minus infinity
    does not occur. Now, let''s use `cross_entropy_error(y, t)` for ease of calculation:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the first example, the output of the correct label is 0.6 and the cross-entropy
    error is 0.51\. In the next example, the output of the correct label is as small
    as 0.1 and the cross-entropy error is 2.3\. These results are consistent with
    what we've discussed so far.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Mini-Batch Learning
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a machine learning problem, training data is used for training. To be precise,
    it means finding the loss function for the training data and finding the parameters
    that make that value as small as possible. Therefore, all the training data must
    be used to obtain the loss function. If there are 100 pieces of training data,
    the sum of their 100 loss functions must be used as the index.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example of the loss function we described earlier, the loss function
    for one piece of data was used. For a cross-entropy error, equation (4.3) can
    calculate the sum of the loss functions for all training data:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '| ![20](img/Figure_4.3a.png) | (4.3) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: Suppose that the number of data elements is N. tnk means the k-th value of the
    n-th data (ynk is the output of the neural network, and tnk is labeled data).
    Although this equation seems a little complicated, it is only an extension of
    equation (4.2), which expresses the loss function for one piece of data for N
    items of data. In the end, it is divided by `N` for normalization. Division by
    N calculates the "average loss function" per data. The average can be used as
    a consistent index, regardless of the amount of training data. For example, even
    when the number of training data elements is 1,000 or 10,000, you can calculate
    the average loss function per data element.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: The MNIST dataset contains 60,000 items of training data. Calculating the sum
    of the loss functions for all this data takes a while. Big data sometimes contains
    millions or tens of millions of pieces of data. In that case, calculating the
    loss functions for all the data is not practical. Therefore, some data is extracted
    to approximate all the data. Also, in neural network training, some training data
    is selected, and training is conducted for each group of data, which is called
    a mini-batch (small collection). For example, 100 pieces of data are selected
    at random from 60,000 items of training data to be used for training. This training
    method is called **mini-batch training**.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s write some code that selects the specified amount of data from
    the training data at random for mini-batch training. Before that, the following
    is the code for loading the MNIST dataset:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As described in *Chapter 3*, *Neural Networks*, the `load_mnist` function loads
    the MNIST dataset. It is located in the `dataset/mnist.py` file provided with
    this book. This function loads the training and test data. By specifying the `one_hot_label=True`
    argument, you can use one-hot representation, where the correct label is 1 and
    the other labels are 0.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: When you load the preceding MNIST data, you will find that the number of training
    data is 60,000 and that the input data contains 784 rows of image data (originally
    28x28). Labeled data is data with 10 rows. Therefore, the shapes of `x_train`
    and `t_train` are (60000, 784) and (60000, 10), respectively.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, how can we extract 10 pieces of data at random from the training data?
    We can write the following code by using NumPy''s `np.random.choice()` function:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'By using `np.random.choice()`, you can select the desired number of numerals
    at random from the specified numerals. For example, `np.random.choice(60000, 10)`
    selects 10 numerals at random from the numerals between 0 and less than 60,000\.
    In the actual code, as shown here, you can obtain the indices as an array for
    selecting mini-batches:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, you can specify the randomly selected indices to extract mini-batches.
    We will use these mini-batches to calculate loss functions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To measure television viewership, not all households, but selected ones, are
    targeted. For example, by measuring viewership among 1,000 households randomly
    selected from Tokyo, you can approximate the viewership throughout Tokyo. The
    viewership among these 1,000 households is not exactly the same as the whole viewership,
    but it can be used as an approximate value. Like the viewership described here,
    the loss function of a mini-batch is measured by using sample data to approximate
    the whole data. In short, a small group of randomly selected data (mini-batch)
    is used as the approximation of the whole training data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Cross-Entropy Error (Using Batches)
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'How can we use batch data such as mini-batches to implement a cross-entropy
    error? By improving the cross-entropy error we implemented earlier, which targets
    only one piece of data, we can implement it easily. Here, we will support both
    the input of a single piece of data and the input of data as batches:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, `y` is the output of the neural network, and `t` is labeled data. If `y`
    is one-dimensional (that is, to calculate the cross-entropy error for one piece
    of data), the shape of the data is changed. The average cross-entropy error per
    data is calculated by normalization based on the amount of data in a batch.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'If labeled data is provided as labels (not in one-hot representation format
    but as labels such as "2" and "7"), we can implement a cross-entropy error as
    follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Please note that if `t` of an element is 0 in one-hot representation, its cross-entropy
    error is also `0`, and you can ignore this calculation. In other words, if you
    can obtain the output of the neural network for a correct label, you can calculate
    the cross-entropy error. Therefore, for `t` as the one-hot representation, `t
    * np.log(y)` is used, while for `t` as labels, `np.log( y[np.arange(batch_size),
    t] )` is used for the same processing (here, the description of "a very small
    value, `1e-7`" has been omitted for visibility).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: For reference, we can cover `np.log( y[np.arange(batch_size), t] )` briefly.
    `np.arange(batch_size)` generates an array from 0 to `batch_size-1`. When `batch_size`
    is 5, `np.arange(batch_size)` generates a NumPy array, [0, 1, 2, 3, 4]. `t` contains
    labels, as in [2, 7, 0, 9, 4] and `y[np.arange(batch_size), t]` extracts the output
    of the neural network corresponding to the correct label for each piece of data
    (in this example, `y[np.arange(batch_size), t]` generates a NumPy array, `[y[0,2],
    y[1,7], y[2,0], y[3,9], y[4,4]]`).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作为参考，我们可以简要介绍一下`np.log( y[np.arange(batch_size), t] )`。`np.arange(batch_size)`会生成一个从0到`batch_size-1`的数组。当`batch_size`为5时，`np.arange(batch_size)`生成一个NumPy数组，[0,
    1, 2, 3, 4]。`t`包含标签，如[2, 7, 0, 9, 4]，而`y[np.arange(batch_size), t]`则提取每个数据的正确标签对应的神经网络输出（在这个例子中，`y[np.arange(batch_size),
    t]`生成的NumPy数组为`[y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]`）。
- en: Why Do We Configure a Loss Function?
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么我们要配置损失函数？
- en: Some people may wonder why we introduce a loss function. For example, in the
    case of number recognition, we want parameters to improve recognition accuracy.
    Isn't it extra work to introduce a loss function? Our goal is to achieve a neural
    network that maximizes recognition accuracy. So, surely, we should use "recognition
    accuracy" as a score?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人可能会想，为什么我们要引入损失函数？例如，在数字识别的情况下，我们希望参数提高识别准确率。引入损失函数难道不是多余的工作吗？我们的目标是实现一个最大化识别准确率的神经网络。那么，难道我们不应该使用“识别准确率”作为评分标准吗？
- en: You can find the answer to this question by paying attention to the role of
    the "derivative" in neural network training. This will be explained in detail
    in the next section. Neural network training looks for optimal parameters (weights
    and biases) so that the value of the loss function is the smallest. To look for
    the position of the smallest loss function, the derivative (gradient, to be precise)
    of a parameter is calculated, and the parameter value is updated gradually, based
    on the value of the derivative.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过关注“导数”在神经网络训练中的作用，来找到这个问题的答案。下一节将详细解释这一点。神经网络训练的目标是寻找最优的参数（权重和偏置），使损失函数的值最小。为了寻找损失函数最小的值，需要计算某个参数的导数（准确来说是梯度），并根据导数的值逐步更新参数值。
- en: For example, suppose that a virtual neural network exists here. We will pay
    attention to one weight parameter in the neural network. Here, the derivative
    of the loss function of the weight parameter indicates how the loss function changes
    when the value of the weight parameter is changed a little. If the derivative
    becomes a negative value, you can reduce the loss function by changing the weight
    parameter in a positive direction. On the other hand, if the derivative is a positive
    value, you can reduce the loss function by changing the weight parameter in the
    negative direction. However, when the value of the derivative becomes 0, the value
    of the loss function does not change, no matter how the weight parameter is moved.
    Updating the weight parameter is stopped there.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设这里存在一个虚拟的神经网络。我们将关注神经网络中的一个权重参数。在这里，权重参数的损失函数的导数表示当权重参数的值稍微改变时，损失函数的变化情况。如果导数变为负值，则可以通过将权重参数沿正方向调整来减少损失函数。另一方面，如果导数是正值，则可以通过将权重参数沿负方向调整来减少损失函数。然而，当导数值为0时，不管如何移动权重参数，损失函数的值都不会改变。此时，权重参数的更新将停止。
- en: We cannot use recognition accuracy as the score because the derivative becomes
    0 at almost all positions, preventing parameters from being updated. Now, let's
    neatly summarize this.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能使用识别准确率作为评分标准，因为在几乎所有位置，导数都会变为0，导致参数无法更新。现在，让我们简洁地总结一下这一点。
- en: Note
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: When training a neural network, we should not use recognition accuracy as the
    score. The reason is that if you use recognition accuracy as the score, the derivative
    of the parameters will be zero in most places.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练神经网络时，我们不应使用识别准确率作为评分标准。原因是，如果使用识别准确率作为评分标准，大多数地方的参数导数将为零。
- en: So why does recognition accuracy as the score lead the derivative of the parameter
    to 0 at almost all positions? Well, to explain this, let's consider another example.
    Say that a neural network can recognize 32 out of 100 items of training data.
    This means that the recognition accuracy is 32%. If we use the recognition accuracy
    as the score, slightly changing the weight parameter will leave it at 32% and
    cause no change. Slightly adjusting the parameters does not improve recognition
    accuracy. Even if the recognition accuracy is improved, the change will not be
    continuous, such as 32.0123…%, but discontinuous, such as 33% and 34%. On the
    other hand, if the loss function is used as the score, the current value of the
    loss function is represented as a value, such as 0.92543… Slightly changing the
    parameter value also changes the loss function continuously, such as 0.93432…
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Slightly adjusting the parameter only changes the recognition accuracy a bit,
    and any change is discontinuous and sudden. This is also true of the "step function"
    of an activation function. If you use a step function for an activation function,
    a neural network cannot learn appropriately for the same reason. The reason for
    this is that the derivative of a step function is 0 almost anywhere (positions
    other than 0), as shown in *Figure 4.4*. When you use a step function, a slight
    change to the parameter is erased by the step function, and the value of the loss
    function shows no changes, even if you use it as the score.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'A step function changes only at some moments, like a shishi-odoshi or scarecrow.
    On the other hand, for the derivative (tangent) of a sigmoid function, the output
    (value of the vertical axis) changes continuously and the gradient of the curve
    also changes continuously, as shown in *Figure 4.4*. In short, the derivative
    of a sigmoid function is not 0 at any position. This is important for "training"
    in a neural network. Because the gradient is never 0, a neural network can learn
    correctly:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4: Step function and sigmoid function – the gradient of a step function
    is 0 at almost all positions, while the gradient of a sigmoid function (tangent)
    is never 0'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_4.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.4: Step function and sigmoid function – the gradient of a step function
    is 0 at almost all positions, while the gradient of a sigmoid function (tangent)
    is never 0'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Numerical Differentiation
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The gradient method uses information from the gradient to determine which direction
    to follow. This section describes what a gradient is and its characteristics,
    beginning with a "derivative."
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Derivative
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For example, let's assume that you ran 2 km in 10 minutes from the start of
    a full marathon. You can calculate the speed as *2 / 10 = 0.2* [km/minute]. You
    ran at a speed of 0.2 km per minute.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we calculated how much the "running distance" changed over
    "time." Strictly speaking, this calculation indicates the "average speed" for
    10 minutes because you ran 2 km in 10 minutes. A derivative indicates the amount
    of change at "a certain moment." Therefore, by minimizing the time of 10 minutes
    (the distance in the last 1 minute, the distance in the last 1 second, the distance
    in the last 0.1 seconds, and so on), you can obtain the amount of change at a
    certain moment (instantaneous speed).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, a derivative indicates the amount of change at a certain moment. This
    is defined by the following equation:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '| ![21](img/Figure_4.4a.png) | (4.4) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: Equation (4.4) indicates the derivative of a function. The left-hand side ![22](img/Figure_4.4b.png)
    indicates the derivative of *f(x)* with respect to *x* – the degree of changes
    of f(x) with respect to *x*. The derivative expressed by equation (4.4) indicates
    how the value of the function, *f(x)*, changes because of a "slight change" in
    *x*. Here, the slight change, *h*, is brought close to 0 infinitely, which is
    indicated as ![23](img/Figure_4.4c.png).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a program to obtain the derivative of a function based on equation
    (4.4). To implement equation (4.4) directly, you can assign a small value to h
    for calculation purposes:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The function is named `numerical_diff(f, x)`, after **numerical differentiation**.
    It takes two arguments: the function, f, and the argument, x, of the function,
    f. This implementation seems correct, but two improvements can be made.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding implementation uses a small value of `10e-50` ("0.00...1" containing
    50 0s) as h because we want to use the smallest possible value as h (we want to
    bring h infinitely close to 0 if possible). But the problem of a **rounding error**
    occurs here. A rounding error occurs in the final calculation result by omitting
    a numeric value in the small range of a decimal (for example, by omitting eight
    or more places of decimals). The following example shows a rounding error in Python:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When you represent `1e-50` in the float32 type (a 32-bit floating-point number),
    the value becomes 0.0\. You cannot express it correctly. Using too small value
    causes a problem in computer calculation. Now, here is the first improvement.
    You can use 10−4 as the small value, h. It is known that a value of around 10−4
    brings about good results.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'The second improvement is in terms of the difference in the function, f. The
    preceding implementation calculates the difference in the function f between x
    + h and x. You should observe that this calculation causes an error in the first
    place. As shown in *Figure 4.5*, the "true derivative " corresponds to the gradient
    of the function at the position of *x* (called a tangent), while the derivative
    in this implementation corresponds to the gradient between (*x* + *h*) and x.
    Therefore, the true derivative (true tangent) is not strictly identical to the
    value of this implementation. This difference occurs because you cannot bring
    *h* close to 0 infinitely:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5: True derivative (true tangent) and numerical differentiation
    (tangent'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: by approximation) are different in value
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_5.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.5: True derivative (true tangent) and numerical differentiation (tangent
    by approximation) are different in value'
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As shown in *Figure 4.5*, a numerical differential contains an error. To reduce
    this error, you can calculate the difference of the function, (*f*), between (*x
    + h*) and (*x - h*). This difference is called a **central difference** because
    it is calculated around *x* (on the other hand, the difference between (*x + h*)
    and *x* is called a **forward difference**). Now, let''s implement a numerical
    differentiation (numerical gradient) based on these two improvements:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As the preceding code shows, calculating a derivative by using a very small
    value difference is called **numerical differentiation**. On the other hand, obtaining
    a derivative with the expansion is called an "analytical solution" or "analytically
    obtaining a derivative," for example, by using the word "analytic." You can obtain
    the derivative of *y* = *x*2 analytically as ![24](img/Figure_4.5a.png). Therefore,
    you can calculate the derivative of *y* as *x* = 2, and this is 4\. An analytic
    derivative is the "true derivative" without errors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Numerical Differentiation
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s differentiate an easy function by using numerical differentiation. The
    first example is the quadratic function expressed by the following equation:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '| ![25](img/Figure_4.5b.png) | (4.5) |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: 'Implement equation (4.5) in Python as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Draw the graph of this function. The following shows the code for drawing a
    graph and the resulting graph (*Figure 4.6*):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now calculate the differentials of the function when x=5 and x=10:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The differential calculated here is the amount of change of *f(x)* for *x*,
    which corresponds to the gradient of the function. By the way, the analytical
    solution of *f (x) = 0.01x*2 *+ 0.1x* is ![26](img/Figure_4.6c.png) *= 0.02x +
    0.1*. The true derivative when *x=5* and 10 are 0.2 and 0.3, respectively. They
    are not strictly identical to the results from numerical differentiation, but
    the error is very small. Actually, the error is so small that they can be regarded
    as almost identical values:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6: Graph of f (x) = 0.01x2 + 0.1x'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_6.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.6: Graph of *f* (*x*) = 0.01*x*2 + 0.1*x*'
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We will use the preceding results of our numerical differentiation to plot
    graphs of lines whose gradients are the values of the numerical differentiation.
    The results are shown in *Figure 4.7*. Here, you can see that the derivatives
    correspond to the tangents of the function (the source code is located at `ch04/gradient_1d.py`):'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7: Tangents when x = 5 and x = 10 – using the values from numerical
    differentiation as the ](img/fig04_7.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.7: Tangents when *x* = 5 and *x* = 10 – using the values from numerical
    differentiation as the gradients of lines'
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Partial Derivative
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next, let''s look at the function expressed by equation (4.6). This simple
    equation calculates the square sum of the arguments. Note that it has two variables,
    unlike the previous example:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '| ![27](img/Figure_4.7a.png) | (4.6) |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
- en: 'You can implement it in Python as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here, it is assumed that NumPy arrays are passed as arguments. The function
    simply squares each element of the NumPy arrays and sums it up (`np.sum(x**2)`
    can implement the same processing). Now, let''s draw the graph of this function.
    This three-dimensional graph appears as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8: Graph of'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_8.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.8: Graph of ![28](img/Figure_4.8a.png)'
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, we want to calculate the derivative of equation (4.6). Here, please note
    that equation (4.6) has two variables. Therefore, you must specify for which of
    the two variables, *x*0 and *x*1, the differentials are calculated. The derivative
    of a function that consists of multiple variables is called a **partial derivative**.
    They are expressed as ![29](img/Figure_4.8b.png).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this, consider the following two partial derivative problems
    and their solutions:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '`x0` when `x0 = 3` and `x1 = 4`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`x1` when `x0 = 3` and `x1 = 4`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: To solve these problems, a function with one variable is defined, and the derivative
    for the function is calculated. For example, in `x1=4` is defined, and the function,
    which has only one variable, `x0`, is passed to the function to calculate a numerical
    differentiation. Based on the results, the answer to `6.00000000000378`, and the
    answer to `7.999999999999119`. They are mostly the same as the solutions from
    analytical differentiation.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: In this way, the partial derivative calculates the gradient at a certain position,
    such as the differentiation for one variable. However, for the partial derivative,
    one of the variables is targeted, and the other variables are fixed at a certain
    value. In the preceding implementation, a new function was defined to hold the
    other variables at a specific value. The newly defined function was passed to
    the previous numerical differential function to calculate the partial derivative.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Gradient
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous example, the partial derivatives of *x*0 and *x*1 were calculated
    for each variable. Now, we want to calculate the partial derivatives of *x*0 and
    *x*1 collectively. For example, let''s calculate the partial derivatives of (*x*0,
    *x*1) when `x0 = 3` and `x1 = 4` as (![31](img/Figure_4.8b1.png))The vector that
    collectively indicates the partial differentials of all the variables, such as
    (![32](img/Figure_4.8b2.png)) is called a **gradient**. You can implement a gradient
    as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Implementing the `numerical_gradient(f, x)` function seems a little complicated,
    but the processes are almost the same as those in numerical differentiation for
    one variable. Note that `np.zeros_like(x)` generates an array that has the same
    shape as `x` and whose elements are all zero.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'The `numerical_gradient(f, x)` function takes the `f (function)` and `x (NumPy
    array)` arguments and obtains numerical differentiations for each element of the
    NumPy array, `x`. Now, let''s use this function to calculate a gradient. Here,
    we will obtain the gradients at points (3, 4), (0, 2), and (3, 0):'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The actual result is [6.0000000000037801, 7.9999999999991189], but [6., 8.]
    is returned. This is because a returned NumPy array is formatted to enhance the
    visibility of the values.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we can calculate the gradient at each point of (*x*0, *x*1). The preceding
    example shows that the gradient for point (3, 4) is (6, 8), that for point (0,
    2) is (0, 4), and that for point (3, 0) is (6, 0). What do these gradients mean?
    To understand this, let's look at the gradients of ![33](img/Figure_4.8g.png).
    Here, we will make the gradients negative and draw the vectors (the source code
    is located at `ch04/gradient_2d.py`).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'The gradients of ![34](img/Figure_4.8g1.png) are shown as the vectors (arrows)
    that have the direction toward the lowest point, as shown in *Figure 4\. 9*. In
    *Figure 4.9*, the gradients seem to point at "the lowest position (smallest value)"
    of the function, *f*(*x*0, *x*1). Just like a compass, the arrows point to one
    point. The more distant they are from "the lowest position," the larger the size
    of the arrow:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9: Gradients of'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_9.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.9: Gradients of ![35](img/Figure_4.9a.png)'
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the example shown in *Figure 4.9*, the gradients point at the lowest position,
    but this is not always the case. In fact, gradient points in the lower direction
    at each position. To be more precise, the direction of a gradient is **the direction
    that reduces the value of the function most at each position**. This is an important
    point, so please keep this in mind.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Method
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many machine learning problems look for optimal parameters during training.
    A neural network also needs to find optimal parameters (weights and biases) during
    training. The optimal parameter here is the parameter value when the loss function
    takes the minimum value. However, a loss function can be complicated. The parameter
    space is vast, and we cannot guess where it takes the minimum value. A gradient
    method makes good use of gradients to find the minimum value (or the smallest
    possible value) of the function.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: A gradient shows the direction that reduces the value of the function most at
    each position. Therefore, whether the position that a gradient points in is really
    the minimum value of the function, in other words, whether the direction is really
    the one to take, cannot be guaranteed. Actually, in a complicated function, the
    direction that a gradient points to is not the minimum value in most cases.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The gradient is 0 at the local minimum, the minimum, and at a point called the
    saddle point of a function. A local minimum is locally the smallest value, which
    is the minimum value in a limited range. A saddle point is a position of the local
    maximum in one direction and of the local minimum in another direction. A gradient
    method looks for the position where a gradient is 0, but where the position is
    not always the global minimum (it can be the local minimum or a saddle point).
    When a function has a complicated and distorted shape, learning enters an (almost)
    flat land and a stagnant period called a "plateau" might occur, leading to stagnation
    in training.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Even if the direction of a gradient does not always point at the global minimum
    value, moving in that direction can reduce the value of the function the most.
    Therefore, to look for the position of the minimum value or to look for the position
    where the function has the smallest possible value, you should determine the direction
    of movement based on the information about gradients.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's look at the gradient method. In the gradient method, you move a fixed
    distance from the current position in the gradient direction. By doing this, you
    obtain a gradient at the new position and move in the gradient direction again.
    Thus, you move in the gradient direction repeatedly. Reducing the value of a function
    gradually by going in the gradient direction repeatedly is known as the **gradient
    method**. This method is often used in optimization problems for machine learning.
    It is typically used when training neural networks.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-174
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A gradient method is called by another name if it looks for the minimum or the
    maximum value. To be precise, the method for the minimum value is called the **gradient
    descent method**, while the method for the maximum value is called the **gradient
    ascent method**. However, reversing the sign of a loss function can change this
    from a problem for the minimum value into a problem for the maximum value. So,
    the difference between "descent" and "ascent" is not especially important. Generally,
    a "gradient descent" method is often used in neural networks (deep learning).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s express a gradient method with an equation. Equation (4.7) shows
    a gradient method:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '| ![36](img/Figure_4.9b.png) | (4.7) |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
- en: In equation (4.7), η adjusts the amount to be updated. This is called a **learning
    rate** in neural network. A learning rate determines how much needs to be learned
    and how much to update the parameters.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Equation (4.7) shows an update equation for one training instance, and the step
    is repeated. Each step updates the variable values, as shown in equation (4.7),
    and the step is repeated several times to reduce the value of the function gradually.
    This example has two variables, but even when the number of variables is increased,
    a similar equation—a partial differential value for each variable—is used for
    updating.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: You must specify the value of the learning rate, such as 0.01 and 0.001, in
    advance. Generally, if this value is too large or too small, you cannot reach
    a "good place." In neural network training, we usually check whether training
    is successful by changing the value of the learning rate.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s implement a gradient descent method in Python. This can be done
    as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `f` argument is a function to optimize, the `init_x` argument is an initial
    value, the `lr` argument is a learning rate, and the `step_num` argument is the
    number of repetitions in a gradient method. The gradient of the function is obtained
    by `numerical_gradient(f, x)` and the gradient updated by multiplying it by the
    learning rate, which is repeated the number of times specified by `step_num`.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: You can use this function to obtain the local minimum of the function and even
    the minimum value if you are lucky. Now, let's try solving a problem.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Obtain the minimum value of ![37](img/Figure_4.9d.png) with a
    gradient method:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, specify (-3.0, 4.0) as the initial value and start looking for the minimum
    value by using a gradient method. The final result is (-6.1e-10, 8.1e-10), which
    is almost near (0, 0). Actually, the true minimum value is (0, 0). You successfully
    obtained almost correct results by using a gradient method. *Figure 4.10* shows
    the process of updating with a gradient method. The origin is the lowest position,
    and you can see that the result is approaching it gradually. The source code to
    draw this graph is located at `ch04/gradient_method.py` (`ch04/gradient_method.py`
    does not display dashed lines, which show the contour lines in the graph):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10: Updating  with a gradient method – the dashed lines show'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: the contour lines of the function
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_10.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.10: Updating ![38](img/Figure_4.10a.png) with a gradient method –
    the dashed lines show the contour lines of the function'
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As mentioned earlier, an overly large or small learning rate does not achieve
    good results. Let''s do some experiments regarding both cases here:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As this experiment shows, the result diverges to a large value if the learning
    rate is too large. On the other hand, almost no updates occur if the learning
    rate is too small. Setting an appropriate learning rate is important.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A parameter such as a learning rate is called a **hyperparameter**. It is different
    from the parameters (weights and biases) of a neural network in terms of its characteristics.
    Weight parameters in a neural network can be obtained automatically with training
    data and a training algorithm, while a hyperparameter must be specified manually.
    Generally, you must change this hyperparameter to various values to find a value
    that enables good training.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Gradients for a Neural Network
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You must also calculate gradients in neural network training. The gradients
    here are those of a loss function for weight parameters. For example, let''s assume
    that a neural network has the weight W (2x3 array) only, and the loss function
    is L. In this case, we can express the gradient as ![39](img/Figure_4.10b.png).
    The following equation shows this:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '| ![40](img/Figure_4.10c.png) | (4.8) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
- en: Each element of ![41](img/Figure_4.10e.png) is the partial derivative for each
    element. For example, the element at the first row and column, ![42](img/Figure_4.10f.png),
    indicates how a slight change in w11 changes the loss function, L. What is important
    here is that the shape of ![43](img/Figure_4.10g.png) is the same as that of W.
    Actually, in equation (4.8), both W and ![44](img/Figure_4.10h.png) are the same
    (2x3) in shape.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s implement a program that calculates a gradient by taking an easy
    neural network as an example. To do that, we will implement a class named `simpleNet`
    (the source code is located at `ch04/gradient_simplenet.py`):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here, the `softmax` and `cross_entropy_error` methods in `common/functions.py`
    are being used. The `numerical_gradient` method in `common/gradient.py` is also
    being used. The `simpleNet` class has only one instance variable, which is the
    weight parameters with a shape of 2x3\. It has two methods: one is `predict(x)`
    for prediction, and the other is `loss(x, t)` for obtaining the value of the loss
    function. Here, the `x` argument is the input data and the `t` argument is a correct
    label. Now, let''s try using `simpleNet`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, let''s obtain the gradients,using `numerical_gradient(f, x)`. The `f(W)`
    function defined here takes a dummy argument, `W`. Because the `f(x)` function
    is executed inside `numerical_gradient(f, x)`, `f(W)` is defined for consistency:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `f` argument of `numerical_gradient(f, x)` is a function and the `x` argument
    is the argument to the function, `f`. Therefore, a new function, `f`, is defined
    here. It takes `net.W` as an argument and calculates the loss function. The newly
    defined function is passed to `numerical_gradient(f, x)`.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '`numerical_gradient(f, net.W)` returns `dW`, which is a two-dimensional 2x3
    array. `dW` shows that ![45](img/Figure_4.10i.png) for ![46](img/Figure_4.10j.png)
    is around `0.2`, for example. This indicates that when w11 is increased by h,
    the value of the loss function increases by 0.2h. ![47](img/Figure_4.10k.png)
    is about `-0.5`, which indicates that when w23 is increased by h, the value of
    the loss function decreases by 0.5h. Therefore, to reduce the loss function, you
    should update w23 in a positive direction and w11 in a negative direction. You
    can also see that updating w23 contributes to the reduction more than updating
    w11.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding implementation, the new function is written as `def f(x):…`
    In Python, you can use a `lambda` notation to write and implement a simple function,
    as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: After obtaining the gradients for a neural network, all you have to do is use
    a gradient method to update the weight parameters. In the next section, we will
    implement all these training processes for a two-layer neural network.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `numerical_gradient()` function we used here is slightly different from
    the previous implementation for handling multi-dimensional arrays such as the
    weight parameter, `W`. However, these changes are simple and are only for handling
    multidimensional arrays. For further details, please refer to the source code
    (`common/gradient.py`).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a Training Algorithm
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have learned about the basics of neural network training. Important
    keywords such as "loss function", "mini-batch", "gradient", and "gradient descent
    method" have appeared in succession. Here, we will look at the procedure of neural
    network training for review purposes. Let's go over the neural network training
    procedure.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Presupposition
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: A neural network has adaptable weights and biases. Adjusting them so that they
    fit the training data is called "training." Neural network training consists of
    four steps.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 (mini-batch)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Select some data at random from the training data. The selected data is called
    a mini-batch. The purpose here is to reduce the value of the loss function for
    the mini-batch.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 (calculating gradients)
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: To reduce the loss function for the mini-batch, calculate the gradient for each
    weight parameter. The gradient shows the direction that reduces the value of the
    loss function the most.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 (updating parameters)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Update the weight parameters slightly in the gradient direction.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 (repeating)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Repeat *steps* *1*, *2*, and *3*.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: The preceding four steps are used for neural network training. This method uses
    a gradient descent method to update parameters. Because the data used here is
    selected at random as a mini-batch, it is referred to as **stochastic gradient
    descent**. "Stochastic" means "selecting data at random stochastically." Therefore,
    stochastic gradient descent means "the gradient descent method for randomly selected
    data." In many deep learning frameworks, stochastic gradient descent is usually
    implemented as the **SGD** function, which is named after its initials.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's implement the neural network that actually learns handwritten digits.
    Here, a two-layer neural network (with one hidden layer) will use the MNIST dataset
    for training.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: A Two-Layer Neural Network as a Class
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, let''s implement a two-layer neural network as a class. This class is
    named `TwoLayerNet` and is implemented as follows (implementing `TwoLayerNet`
    is based on the Python source code provided by the CS231n (*Convolutional Neural
    Networks for Visual Recognition* ([http://cs231n.github.io/](http://cs231n.github.io/))
    course at Stanford University). The source code is located at `ch04/two_layer_net.py`:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The implementation of this class is a little long, but nothing that new appears.
    It has many things in common with the implementation of forward processing a neural
    network covered in the previous chapter. First, let''s look at the variables and
    methods that were used in this class. *Table 4.1* shows the important variables,
    while *Table 4.2* shows all the methods:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 4\. 1: Variables used in the TwoLayerNet class'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4_Table01.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4\. 1: Variables used in the TwoLayerNet class'
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Table 4.2: Methods used in the TwoLayerNet class'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_4_Table02.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4.2: Methods used in the TwoLayerNet class'
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The `TwoLayerNet` class has two dictionary variables, `params` and `grads`,
    as instance variables. The `params` variable contains the weight parameters. For
    example, the weight parameters for layer 1 are stored in `params[''W1'']` as a
    NumPy array. You can access the bias for layer 1 using `params[''b1'']`. Here
    is an example:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'As shown here, the `params` variable contains all the parameters required for
    this network. The weight parameters contained in the `params` variable are used
    for predicting (forward processing). You can make a prediction as follows:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `grads` variable contains the gradient for each parameter so that it corresponds
    to the `params` variable. When you calculate gradients by using the `numerical_gradient()`
    method, gradient information is stored in the `grads` variable, as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now, let's look at the implementation of the methods in `TwoLayerNet`. The `__init__`
    (`self`, `input_size`, `hidden_size`, `output_size`) method is the initialization
    method of the class ( called when `TwoLayerNet` is generated). The arguments are
    the numbers of neurons in the input layer, in the hidden layer, and the output
    layer in order from left to right. For handwritten digit recognition, a total
    of 784 input images that are 28x28 in size are provided and 10 classes are returned.
    Therefore, we specify the `input_size=784` and `output_size=10` arguments and
    set an appropriate value for `hidden_size` as the number of hidden layers.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: This initialization method also initializes the weight parameters. Determining
    what values to set as the initial weight parameters is important for successful
    neural network training. We will discuss the initialization of weight parameters
    in detail later. Here, the weights are initialized by using the random numbers
    based on Gaussian distribution, and the biases are initialized by 0\. `predict(self,
    x)`, and `accuracy(self, x, t)` are almost the same as in the implementation of
    predicting in relation to the neural network, which we looked at in the previous
    chapter. If you have any questions, please refer to the previous chapter. The
    `loss(self, x, t)` method calculates the value of the loss function. It obtains
    a cross-entropy error based on the result of `predict()` and the correct label.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The remaining `numerical_gradient(self, x, t)` method calculates the gradient
    of each parameter. It uses numerical differentiation to calculate the gradient
    for the loss function of each parameter. The `gradient(self, x, t)` method will
    be implemented in the next chapter.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`numerical_gradient(self, x, t)` uses numerical differentiation to calculate
    the gradients of the parameters. In the next chapter, we will look at how to calculate
    gradients quickly using backpropagation, which returns almost the same result
    as using numerical differentiation, but with faster processing. The method for
    obtaining a gradient through backpropagation will be implemented as `gradient(self,
    x, t)` in the next chapter. If you want to save time, you can use `gradient(self,
    x, t)` instead of `numerical_gradient(self, x, t)` because neural network training
    takes time.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Mini-Batch Training
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here, we will use mini-batch training to implement neural network training.
    In mini-batch training, we extract some data randomly from training data (called
    a mini-batch) and use it to update the parameters using a gradient method. Let''s
    conduct training for the `TwoLayerNet` class by using the MNIST dataset (the source
    code is located at `ch04/train_neuralnet.py`):'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here, the size of a mini-batch is 100\. Each time, 100 pieces of data (image
    data and correct label data) are extracted randomly from 60,000 pieces of training
    data. Then, gradients are obtained for the mini-batch, and the parameters are
    updated using **stochastic gradient descent** (**SGD**). Here, the number of updates
    made by a gradient method;that is, the number of iterations is 10,000\. At each
    update, the loss function for the training data is calculated, and the value is
    added to the array. *Figure 4.11* shows the graph of how the value of this loss
    function changes.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4.11* shows that, as the number of training increases, the value of
    the loss function decreases. It indicates that training is successful. The weight
    parameters of the neural network are adapting to the data gradually. The neural
    network is indeed learning. By being exposed to data repeatedly, it is approaching
    the optimal weight parameters:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11: Transition of the loss function – the image on the left shows
    the transition up to 10,000 iterations, while the image on the right shows the
    transition up to 1,000 iterations'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_11.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.11: Transition of the loss function – the image on the left shows
    the transition up to 10,000 iterations, while the image on the right shows the
    transition up to 1,000 iterations'
  id: totrans-256
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Using Test Data for Evaluation
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The result of *Figure 4.11* shows that repeatedly training the data reduces
    the value of the loss function gradually. However, the value of the loss function
    is the value of "the loss function for the mini-batch of training data." The reduction
    in the value of the loss function for the training data indicates that the neural
    network is learning well. However, this result does not prove that it can handle
    a different dataset as well as this one.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: In neural network training, we must check whether data other than training data
    can be recognized correctly. We must check whether "overfitting" does not occur.
    Overfitting means that only the number of images contained in the training data
    can be recognized correctly, and those that are not contained there cannot be
    recognized, for example.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The goal of neural network training is to obtain generalization capability.
    To do that, we must use data that is not contained in the training data to evaluate
    the generalization capability of the neural network. In the next implementation,
    we will record the recognition accuracy for the test data and the training data
    periodically during training. We will record the recognition accuracy for the
    test data and the training data for each epoch.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An epoch is a unit. One epoch indicates the number of iterations when all the
    training data has been used for training. For example, let's assume that 100 mini-batches
    are used to learn 10,000 pieces of training data. After a stochastic gradient
    descent method is repeated 100 times, all the training data has been seen. In
    this case, `100 iterations = 1 epoch`.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will change the previous implementation slightly to gain a correct
    evaluation. Here, the differences from the previous implementation are shown in
    bold:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In the preceding example, the recognition accuracy is calculated for all the
    training and test data and the results are recorded for each epoch. The recognition
    accuracy is calculated for each epoch because it takes time if it is calculated
    repeatedly in a `for` statement. Also, we do not need to record recognition accuracy
    frequently (all we need is the approximate transition of recognition accuracy).
    Therefore, the transition of recognition accuracy is recorded for each epoch of
    training data.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s show the results of the preceding code in a graph:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12: Transition of recognition accuracy for training data and test
    data. The horizontal'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: axis shows the epochs
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '](img/fig04_12.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.12: Transition of recognition accuracy for training data and test
    data. The horizontal axis shows the epochs'
  id: totrans-270
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In *Figure 4.12*, the solid line shows the recognition accuracy of the training
    data, while the dashed line shows that of the test data. As you can see, as the
    number of epochs increases (training advances), the recognition accuracies for
    both the training data and the test data improve. Here, we can see that the two
    recognition accuracies are almost the same as the two lines mostly overlap. This
    indicates that overfitting did not occur here.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This chapter described neural network training. First, we introduced a `score`
    called a loss function so that a neural network can learn. The goal of neural
    network training is to discover the weight parameters that lead to the smallest
    value of the loss function. Then, we learned how to use the gradient of a function,
    called the gradient method, to discover the smallest loss function value. This
    chapter covered the following points:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, we use training data and test data.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training data is used for training, while test data is used to evaluate the
    generalization capability of the trained model.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A loss function is used as a score in neural network training. Weight parameters
    are updated so that the value of the loss function will decrease.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To update the weight parameters, their gradients are used to update their values
    in the gradient direction repeatedly.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating a derivative based on the difference when very small values are
    provided is called numerical differentiation.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use numerical differentiation to obtain the gradients for the weight parameters.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numerical differentiation takes time to calculate, but its implementation is
    easy. On the other hand, backpropagation, which will be described in the next
    chapter, is slightly complicated, but it can calculate gradients quickly.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
