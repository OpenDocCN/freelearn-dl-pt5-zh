["```py\nfrom sagemaker.pytorch import PyTorch\npytorch_estimator = PyTorch(\n                        session=session,\n                        entry_point=f'path/to/train.py',\n                        role=role,\n                        instance_type=\"ml.m4.xlarge\",\n  volume_size=100,\n                        instance_count=4,\n                        framework_version=\"1.9.0\",\n                        )\n```", "```py\n    from sagemaker.huggingface.estimator import HuggingFace\n    from sagemaker.debugger import TensorBoardOutputConfig\n    from sagemaker import get_execution_role\n    role=get_execution_role()\n    estimator = HuggingFace(\n        py_version=\"py36\",\n        entry_point=\"train.py\",\n        pytorch_version=\"1.7.1\",\n        transformers_version=\"4.6.1\",\n        instance_type=\"ml.p2.xlarge\",\n        instance_count=2,\n        role=role,\n        model_uri=\"s3://unique/path/models/pretrained-bert/\",\n        checkpoint_s3_uri=\"s3://unique/path/training/checkpoints\",\n        output_path=\"s3://unique/path/training/output\",\n        tensorboard_output_config = TensorBoardOutputConfig(\n            s3_output_path='s3://unique/path/tensorboard/ ',\n            container_local_output_path='/local/path/'\n            ),\n    )\n    ```", "```py\nestimator.fit({\n    \"train\":\"s3://unique/path/train_files/\",\n    \"test\":\"s3://unique/path/test_files\"}\n    )\n```", "```py\nfrom sagemaker.tensorflow.estimator import TensorFlow\nfrom sagemaker.inputs import FileSystemInput\nfrom sagemaker import get_execution_role\nrole=get_execution_role()\nestimator = TensorFlow(entry_point='train.py',\n                       role=role,\n                       image_uri=\"image/uri\",\n                       instance_count=4,\n                       instance_type='ml.c4.xlarge')\nfile_system_input = FileSystemInput(file_system_id='fs-1',\n                                    file_system_type='EFS',\n                                    directory_path='/tensorflow',\n                                    file_system_access_mode='ro')\nestimator.fit(file_system_input)\n```", "```py\nfrom sagemaker.inputs import FileSystemInput\nfrom sagemaker import get_execution_role\nrole=get_execution_role()\nestimator = TensorFlow(entry_point='train.py',\n                       role=role,\n                       image_uri=\"image/uri\",\n                       instance_count=4,\n                       instance_type='ml.c4.xlarge')\nfile_system_input = FileSystemInput(\n                       file_system_id='fs-XYZ', \n                       file_system_type='FSxLustre',\n                       directory_path='/tensorflow',\n                       file_system_access_mode='ro')\nestimator.fit(file_system_input)\n```", "```py\n    from datasets import load_dataset\n    dataset = load_dataset(\"imdb\")\n    ```", "```py\n    import pandas as pd\n    import time\n    dataset_df = dataset['train'].to_pandas()\n    current_time_sec = int(round(time.time()))\n    dataset_df[\"EventTime\"] = pd.Series([current_time_sec]*len(dataset_df), dtype=\"float64\")\n    dataset_df[\"ID\"] = dataset_df.index\n    dataset_df[\"text\"] = dataset_df[\"text\"].astype('string')\n    dataset_df[\"text\"] = dataset_df[\"text\"].str.encode(\"utf8\")\n    dataset_df[\"text\"] = dataset_df[\"text\"].astype('string')\n    ```", "```py\n    from transformers import DistilBertTokenizerFast\n    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n    dataset_df[\"tokenized-text\"] = tokenizer(dataset_df[\"text\"].tolist(), truncation=True, padding=True)[\"input_ids\"]\n    dataset_df[\"tokenized-text\"] = dataset_df[\"tokenized-text\"].astype('string')\n    ```", "```py\n    from sagemaker.feature_store.feature_group import FeatureGroup\n    imdb_feature_group_name = \"imdb-reviews-tokenized\"\n    imdb_feature_group = FeatureGroup(name=imdb_feature_group_name, sagemaker_session=sagemaker_session)\n    imdb_feature_group.load_feature_definitions(data_frame=dataset_df)\n    ```", "```py\n    imdb_feature_group.create(    \n    s3_uri=f\"s3://{s3_bucket_name}/{imdb_feature_group_name}\",\n        record_identifier_name=\"ID\",\n        event_time_feature_name=\"EventTime\",\n        role_arn=role,\n        enable_online_store=True\n    )\n    # Waiter for FeatureGroup creation\n    def wait_for_feature_group_creation_complete(feature_group):\n        status = feature_group.describe().get('FeatureGroupStatus')\n        print(f'Initial status: {status}')\n        while status == 'Creating':\n            print(f'Waiting for feature group: {feature_group.name} to be created ...')\n            time.sleep(5)\n            status = feature_group.describe().get('FeatureGroupStatus')\n        if status != 'Created':\n            raise SystemExit(f'Failed to create feature group {feature_group.name}: {status}')\n        print(f'FeatureGroup {feature_group.name} was successfully created.')\n    wait_for_feature_group_creation_complete(imdb_feature_group)\n    ```", "```py\n    imdb_feature_group.ingest(data_frame=dataset_df, max_processes=16, wait=True)\n    ```", "```py\n    athena_query = imdb_feature_group.athena_query()\n    imdb_table_name = athena_query.table_name\n    result = athena_query.run(f'SELECT \"label\", COUNT(\"label\") as \"Count\" FROM \"sagemaker_featurestore\".\"{imdb_table_name}\" group by \"label\";', output_location=f\"s3://{s3_bucket_name}/athena_output\")\n    athena_query.wait()\n    print(f\"Counting labels in dataset: \\n {athena_query.as_dataframe()}\")\n    ```", "```py\n    df = pd.read_parquet(args.training_dir)\n    df[\"input_ids\"] = df[\"tokenized-text\"].astype(\"string\")\n    train_dataset = Dataset.from_pandas(df[[\"input_ids\", \"label\"]])\n```", "```py\n    def string_to_list(example):\n        list_of_str = example[\"input_ids\"].strip(\"][\").split(\", \")\n        example[\"input_ids\"] = [int(el) for el in list_of_str]\n        return example\n    train_dataset = train_dataset.map(string_to_list)\n```", "```py\n    train_dataset_uri = imdb_feature_group.describe()['OfflineStoreConfig'][\"S3StorageConfig\"][\"ResolvedOutputS3Uri\"]\n    ```", "```py\n    from sagemaker.huggingface.estimator import HuggingFace\n    estimator = HuggingFace(\n        py_version=\"py36\",\n        entry_point=\"train.py\",\n        source_dir=\"1_sources\",\n        pytorch_version=\"1.7.1\",\n        transformers_version=\"4.6.1\",\n        hyperparameters={\n            \"model_name\":\"distilbert-base-uncased\",\n            \"train_batch_size\": 16,\n            \"epochs\": 3\n            # \"max_steps\": 100 # to shorten training cycle, remove in real scenario\n        },\n        instance_type=\"ml.p2.xlarge\",\n        debugger_hook_config=False,\n        disable_profiler=True,\n        instance_count=1,\n        role=role\n    )\n    estimator.fit(train_dataset_uri)\n    ```", "```py\nimport boto3\nclient = boto3.client('sagemaker-featurestore-runtime')\n```", "```py\nresponse = client.batch_get_record(\n    Identifiers=[\n        {\n            'FeatureGroupName':imdb_feature_group.name,\n            'RecordIdentifiersValueAsString': [\"0\", \"1\", \"2\"], # picking several records to run inference.\n            'FeatureNames': [\n                'tokenized-text', \"label\", 'text'\n            ]\n        },\n    ]\n)\n# preparing the inference payload\nlabels = []\ninput_ids = []\ntexts = []\nfor record in response[\"Records\"]:\n    for feature in record[\"Record\"]:\n        if feature[\"FeatureName\"]==\"label\":\n            labels.append(feature[\"ValueAsString\"])\n        if feature[\"FeatureName\"]==\"tokenized-text\":\n            list_of_str = feature[\"ValueAsString\"].strip(\"][\").split(\", \")\n            input_ids.append([int(el) for el in list_of_str])\n        if feature[\"FeatureName\"]==\"text\":\n            texts.append(feature[\"ValueAsString\"])    \n```", "```py\n    FROM python:3.7-slim-buster\n    ########### Installing packages ##########\n    RUN pip3 install pandas numpy tensorflow numpy scipy\n    RUN pip install Pillow\n    ENV PYTHONUNBUFFERED=TRUE\n    ########### Configure processing scripts ##########\n    ARG code_dir=/opt/ml/code\n    RUN mkdir -p $code_dir\n    COPY 2_sources $code_dir\n    WORKDIR $code_dir\n    ENTRYPOINT [\"python3\",\"processing.py\"]\n    ```", "```py\n        dataset = keras.utils.image_dataset_from_directory(\n            args.data_location,\n            labels=\"inferred\",\n            label_mode=\"int\",\n            class_names=None,\n            color_mode=\"rgb\",\n            batch_size=args.batch_size,\n            image_size=(WIDTH, HEIGHT),\n            shuffle=True,\n            seed=None,\n            validation_split=None,\n            subset=None,\n            interpolation=\"bilinear\",\n            follow_links=False,\n            crop_to_aspect_ratio=False,\n        )\n        datagen = ImageDataGenerator(\n            rotation_range=40,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            fill_mode=\"nearest\",\n        )\n    ```", "```py\n        for batch_data, batch_labels in dataset.as_numpy_iterator():\n            print(f\"Processing batch with index {i} out from {len(dataset)}\")\n            for image, label in zip(batch_data, batch_labels):\n                label_name = class_lookup.iloc[label][\"class\"]\n                image_save_dir = os.path.join(augmented_root_dir, label_name)\n                os.makedirs(image_save_dir, exist_ok=True)\n                j = 0\n                image = np.expand_dims(image, axis=0)\n                # generate 5 new augmented images\n                for batch in datagen.flow(\n                    image,\n                    batch_size=1,\n                    save_to_dir=image_save_dir,\n                    save_prefix=\"augmented\",\n                    save_format=\"jpeg\",\n                ):\n                    j += 1\n                    if j > max_augmentations:\n                        break\n            i += 1\n            if args.max_samples is not None:\n                if i > args.max_samples:\n                    break\n    ```", "```py\n    from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n    lookup_location = \"/opt/ml/processing/lookup\"\n    data_location = \"/opt/ml/processing/input\"\n    output_location = '/opt/ml/processing/output'\n    sklearn_processor = Processor(\n                          image_uri=image_uri,\n                          role=role,\n                          instance_count=2,\n                          base_job_name=\"augmentation\",\n                          sagemaker_session=sess, \n                          instance_type=\"ml.m5.xlarge\")\n    ```", "```py\nsklearn_processor.run(\n    inputs=[\n      ProcessingInput(\n          source=dataset_uri,\n          destination=data_location,\n          s3_data_distribution_type=\"ShardedByS3Key\"),\n      ProcessingInput(\n          source=class_dict_uri,\n          destination=lookup_location),],\n    outputs=[\n      ProcessingOutput(\n          source=output_location)],\n          arguments = [\n               \"--data_location\", data_location, \n               \"--lookup_location\", lookup_location,\n               \"--output_location\", output_location,\n               \"--batch_size\", \"32\",\n               \"--max_samples\", \"10\",\n               \"--max_augmentations\", \"5\"\n               ])                     \n```", "```py\n    def convert_to_tfrecord(input_files, output_file):\n        \"\"\"Converts a file to TFRecords.\"\"\"\n        print(\"Generating %s\" % output_file)\n        with tf.io.TFRecordWriter(output_file) as record_writer:\n            for input_file in input_files:\n                data_dict = read_pickle_from_file(input_file)\n                data = data_dict[b\"data\"]\n                labels = data_dict[b\"fine_labels\"]\n                num_entries_in_batch = len(labels)\n                for i in range(num_entries_in_batch):\n                    example = tf.train.Example(\n                        features=tf.train.Features(\n                            feature={\n                                \"image\": _bytes_feature(data[i].tobytes()),\n                                \"label\": _int64_feature(labels[i]),\n                            }\n                        )\n                    )\n                    record_writer.write(example.SerializeToString())\n    ```", "```py\n    def _input(epochs, batch_size, channel, channel_name):\n        mode = args.data_config[channel_name][\"TrainingInputMode\"]\n        dataset = PipeModeDataset(channel=channel_name, record_format=\"TFRecord\")\n        dataset = dataset.repeat()\n        dataset = dataset.prefetch(10)\n        dataset = dataset.map(_dataset_parser, num_parallel_calls=10)\n        if channel_name == \"train\":\n            buffer_size = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * batch_size\n            dataset = dataset.shuffle(buffer_size=buffer_size)\n        dataset = dataset.batch(batch_size, drop_remainder=True)\n        iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n        image_batch, label_batch = iterator.get_next()\n        return {INPUT_TENSOR_NAME: image_batch}, label_batch\n    ```", "```py\n    from sagemaker.tensorflow import TensorFlow\n    hyperparameters = {\"epochs\": 10, \"batch-size\": 256}\n    estimator = TensorFlow(\n        entry_point=\"train.py\",\n        source_dir=\"3_sources\",\n        metric_definitions=metric_definitions,\n        hyperparameters=hyperparameters,\n        role=role,\n        framework_version=\"1.15.2\",\n        py_version=\"py3\",\n        train_instance_count=1,\n        input_mode=\"Pipe\",\n        train_instance_type=\"ml.p2.xlarge\",\n        base_job_name=\"cifar100-tf\",\n    )\n    ```", "```py\n    from awsio.python.lib.io.s3.s3dataset import S3Dataset\n    from torch.utils.data import DataLoader\n    from torchvision import transforms\n    from PIL import Image\n    import io\n    class S3ImageSet(S3Dataset):\n        def __init__(self, urls, transform=None):\n            super().__init__(urls)\n            self.transform = transform\n        def __getitem__(self, idx):\n            img_name, img = super(S3ImageSet, self).__getitem__(idx)\n            # Convert bytes object to image\n            img = Image.open(io.BytesIO(img)).convert('RGB')\n\n            # Apply preprocessing functions on data\n            if self.transform is not None:\n                img = self.transform(img)\n            return img\n    batch_size = 32\n    preproc = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        transforms.Resize((100, 100))\n    ])\n    ```", "```py\n    # urls can be S3 prefix containing images or list of all individual S3 images\n    urls = 's3://path/to/s3_prefix/'\n    dataset = S3ImageSet(urls, transform=preproc)\n    dataloader = DataLoader(dataset,\n            batch_size=batch_size,\n            num_workers=64)\n    ```", "```py\n    from torch.utils.data import IterableDataset\n    from awsio.python.lib.io.s3.s3dataset import S3IterableDataset\n    from PIL import Image\n    import io\n    import numpy as np\n    from torchvision import transforms\n    class ImageS3(IterableDataset):\n        def __init__(self, urls, shuffle_urls=False, transform=None):\n            self.s3_iter_dataset = S3IterableDataset(urls,\n                                       shuffle_urls)\n            self.transform = transform\n        def data_generator(self):\n            try:\n                while True:\n                    label_fname, label_fobj =       next(self.s3_iter_dataset_iterator)\n                    image_fname, image_fobj = next(self.s3_iter_dataset_iterator)\n                    label = int(label_fobj)\n                    image_np = Image.open(io.BytesIO(image_fobj)).convert('RGB')                \n                    # Apply torch vision transforms if provided\n                    if self.transform is not None:\n                        image_np = self.transform(image_np)\n                    yield image_np, label\n            except StopIteration:\n                return\n        def __iter__(self):\n            self.s3_iter_dataset_iterator = iter(self.s3_iter_dataset)\n            return self.data_generator()        \n        def set_epoch(self, epoch):\n            self.s3_iter_dataset.set_epoch(epoch)\n    ```", "```py\n    # urls can be a S3 prefix containing all the shards or a list of S3 paths for all the shards \n     urls = [\"s3://path/to/file1.tar\", \"s3://path/to/file2.tar\"]\n    # Example Torchvision transforms to apply on data    \n    preproc = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        transforms.Resize((100, 100))\n    ])\n    dataset = ImageS3(urls, transform=preproc)\n    ```", "```py\nfrom sagemaker.tensorflow import TensorFlow\nestimator = TensorFlow(\n    entry_point=\"train.py\",\n    source_dir=\"3_sources\",\n    metric_definitions=metric_definitions,\n    hyperparameters=hyperparameters,\n    role=role,\n    framework_version=\"1.15.2\",\n    py_version=\"py3\",\n    train_instance_count=1,\n    input_mode=\"FastFile\",\n    train_instance_type=\"ml.p2.xlarge\",\n)\n```"]