["```py\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models \n```", "```py\nclassifier = models.Sequential() \n```", "```py\nclassifier.add(layers.Conv2D(32, (3, 3),input_shape = (64, 64, 3), activation = 'relu')) \n```", "```py\nclassifier.add(layers.Conv2D(32, (3, 3)... \n```", "```py\n#I.An edge detection kernel\nkernel_edge_detection = np.array([[0.,1.,0.],\n[1.,-4.,1.],\n[0.,1.,0.]]) \n```", "```py\n#II.Load image and convolution\nimage=mpimg.imread('img.bmp')[:,:,0]\nshape = image.shape \n```", "```py\n#III.Convolution\nimage_after_kernel = filter.convolve(image,kernel_edge_detection,mode='constant', cval=0) \n```", "```py\n#II.Load image\nimage=mpimg.imread('img.bmp')[:,:,0]\nshape = image.shape\nprint(\"image shape\",shape) \n```", "```py\nimage shape (100, 100)\nimage before convolution\n[[255 255 255 ..., 255 255 255]\n [255 255 255 ..., 255 255 255]\n [255 255 255 ..., 255 255 255]\n ..., \n```", "```py\nclassifier.add(...input_shape = (64, 64, 3)...) \n```", "```py\nclassifier.add(..., activation = 'relu')) \n```", "```py\nimport numpy as np\nnx=-3\npx=5 \n```", "```py\ndef relu(x):\n    if(x<=0):ReLU=0\n    if(x>0):ReLU=x\n    return ReLU \n```", "```py\nnegative x= -3 positive x= 5\nReLU nx= 0\nReLU px= 5 \n```", "```py\ndef f(x):\n    vfx=np.maximum(0.1,x)\n    return vfx \n```", "```py\ndef lrelu(x):\n    if(x<0):lReLU=0.01\n    if(x>0):lReLU=x\n    return lReLU \n```", "```py\nprint(\"negative x=\",nx,\"positive x=\",px)\nprint(\"ReLU nx=\",relu(nx))\nprint(\"ReLU px=\",relu(px))\nprint(\"Leaky ReLU nx=\",lrelu(nx))\nprint(\"f(nx) ReLu=\",f(nx))\nprint(\"f(px) ReLu=\",f(px))\nprint(\"f(0):\",f(0)) \n```", "```py\nnegative x= -3 positive x= 5\nReLU nx= 0\nReLU px= 5\nLeaky ReLU nx= 0.01 \n```", "```py\nclassifier.add(layers.MaxPooling2D(pool_size = (2, 2))) \n```", "```py\n# Step 3 Adding a second convolutional layer and pooling layer\nprint(\"Step 3a Convolution\")\nclassifier.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\nprint(\"Step 3b Pooling\")\nclassifier.add(layers.MaxPooling2D(pool_size = (2, 2))) \n```", "```py\n# Step 4 â€“ Flattening\nprint(\"Step 4 Flattening\")\nclassifier.add(layers.Flatten()) \n```", "```py\nprint(\"Step 5 Dense\")\nclassifier.add(layers.Dense(units = 128, activation = 'relu'))\nclassifier.add(layers.Dense(units = 1, activation = 'sigmoid')) \n```", "```py\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n```", "```py\n...metrics = ['accuracy']) \n```", "```py\ntrain_datagen =\ntf.compat.v2.keras.preprocessing.image.ImageDataGenerator(\nrescale = 1./255,shear_range = 0.2,zoom_range = 0.2,\nhorizontal_flip = True) \n```", "```py\nprint(\"Step 7b training set\")\ntraining_set = train_datagen.flow_from_directory(directory+'training_set',\ntarget_size = (64, 64),\nbatch_size = batchs,\nclass_mode = 'binary') \n```", "```py\nprint(\"Step 8a test\")\ntest_datagen = tf.compat.v2.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255) \n```", "```py\nprint(\"Step 8b testing set\")\ntest_set = test_datagen.flow_from_directory(directory+'test_set',\ntarget_size = (64, 64),\nbatch_size = batchs,\nclass_mode = 'binary') \n```", "```py\nprint(\"Step 9 training\")\nprint(\"Classifier\",classifier.fit_generator(training_set,\nsteps_per_epoch = estep,\nepochs = ep,\nvalidation_data = test_set,\nvalidation_steps = vs,verbose=2)) \n```", "```py\n    estep=100 #10000\n    vs=1000 #8000->100\n    ep=3 #25->2 \n    ```", "```py\nEpoch 1/2\n - 23s - loss: 0.1437 - acc: 0.9400 - val_loss: 0.4083 - val_acc: 0.5000\nEpoch 2/2\n - 21s - loss: 1.9443e-06 - acc: 1.0000 - val_loss: 0.3464 - val_acc: 0.5500 \n```", "```py\nprint(\"Step 10: Saving the model\")\nclassifier.save(directory+\"model/model3.h5\") \n```"]