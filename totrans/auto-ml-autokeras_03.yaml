- en: '*Chapter 2*: Getting Started with AutoKeras'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will go over everything you need to get started with **AutoKeras**
    and put it into practice with a foundational, well-explained code example. By
    the end of this chapter, you'll know how to create a simple classifier for handwritten
    digits from the well-known **Modified National Institute of Standards and Technology**
    (**MNIST**) dataset, in just a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in the previous chapter, **DL** (**DL**) automation manages to speed
    up training time and benefit from allocating human resources (data scientists)
    in other pipeline processes that are less likely to be automated.
  prefs: []
  type: TYPE_NORMAL
- en: To carry out this automation, we have chosen AutoKeras. This is a **ML** (**ML**)
    automation framework based on **Keras**, a widely known neural network library
    based on **TensorFlow**, which provides high-level building blocks for developing
    DL models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will see how to install AutoKeras and put it into action with a practical
    example, but let''s first explain some relevant concepts, answering these questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What is deep learning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a neural network and how does it learn?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do deep learning models learn?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why AutoKeras?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing AutoKeras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hello MNIST: Implementing our first AutoKeras experiment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All coding examples in this book are available as Jupyter Notebook/s that can
    be downloaded from the following website: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras).'
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter Notebook provides a Python-based environment where code can be developed
    as a sequence of steps, which are called cells. The notebook also provides flexibility
    to install libraries/dependencies on the go by executing Linux-based commands
    in the cells.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to run the coding examples in this chapter, you only need a computer with
    Jupyter installed. For instance, in Ubuntu/Linux, you can install it with this
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The previous command will install the Jupyter notebook package and all its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: You can also take a look at the *Installing AutoKeras on an Ubuntu Linux workstation*
    section for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you can also run these notebooks using Google Colaboratory, in
    which case you will only need a web browser. See the *AutoKeras with Google Colaboratory*
    section for more details.
  prefs: []
  type: TYPE_NORMAL
- en: What is deep learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DL is a subcategory of ML, based on extracting patterns from data by implementing
    successive layers that are responsible for extracting relevant features. These
    patterns are learned through ML models called neural networks (inspired by our
    brain neurons) and structured in layers stacked one on top of the other, but what
    is a layer? A layer is a set of nodes called *cells* that perform an operation
    by processing an input and generating an output. This kind of operation can be
    stateless but it usually has a state that is stored in an array of float numbers,
    called *weights*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a multilayer-depth neural network recognizing a single-digit
    image, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Visual representation of the layers of a neural network for
    digit classification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – Visual representation of the layers of a neural network for digit
    classification
  prefs: []
  type: TYPE_NORMAL
- en: We can think of the network as a funnel with several filters, in which each
    layer is equivalent to a filter that reduces impurities until the desired value
    is obtained.
  prefs: []
  type: TYPE_NORMAL
- en: DL has multiple applications in many fields such as computer vision, **natural
    language processing** (**NLP**), signal processing, and many others, so the techniques
    explained in this book can be applied to solve problems in multiple disciplines.
  prefs: []
  type: TYPE_NORMAL
- en: We will now see a brief explanation of neural networks and how learning takes
    place.
  prefs: []
  type: TYPE_NORMAL
- en: What is a neural network and how does it learn?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we said previously, a neural network is a set of layers connected to each
    other. Each layer contains a set of nodes and each node has an associated weight.
    Neural network learning consists of simply modifying these weights in a suitable
    way so that the model makes good predictions. In the following diagram, we can
    see a simple two-layer network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Visual representation of a two-layer neural network](img/B16953_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – Visual representation of a two-layer neural network
  prefs: []
  type: TYPE_NORMAL
- en: Each circle in the previous diagram is an artificial neuron, which is nothing
    more than a mathematical function inspired by the functioning of a biological
    neuron. These artificial neurons are the basic units in an artificial neural network
    and their operation consists of receiving one or more inputs (numerical values)
    and multiplying them by a factor or weight, and then adding the results to generate
    the output value.
  prefs: []
  type: TYPE_NORMAL
- en: These models are simple but really powerful because from a set of data with
    defined inputs and outputs, they can learn to predict new data whose outputs we
    do not know. For example, if we train our neural network with house prices based
    on a series of input variables (square meters, location, and so on), the network
    could predict the price of new houses based on those variables.
  prefs: []
  type: TYPE_NORMAL
- en: Having introduced the main concepts of DL models, let's now see how these models
    learn.
  prefs: []
  type: TYPE_NORMAL
- en: How do deep learning models learn?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at a multilayer-depth neural network recognizing a single-digit
    image, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Rendering of the layer content of a neural network for digit
    classification](img/B16953_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – Rendering of the layer content of a neural network for digit classification
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding diagram, the network extracts patterns from
    the digit image. In each layer, it obtains different representations, so each
    layer specializes in some specific features of the image, giving the necessary
    keys to identify the category to which it belongs.
  prefs: []
  type: TYPE_NORMAL
- en: This is basically DL, a multistage technique of learning patterns from data.
    It's based on a very simple concept, but by tweaking it and scaling it high enough,
    you can make amazing predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now see the reasons why AutoKeras is our preferred tool for **automated
    ML** (**AutoML**).
  prefs: []
  type: TYPE_NORMAL
- en: Why AutoKeras?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we explained in the previous chapter, AutoKeras is an open source AutoML
    framework that allows a non-ML expert to create high-performance models in a simple
    way. There are similar tools with the same objective, but AutoKeras is specialized
    in DL. Although it is not the only solution, there are several AutoML services
    available; most are cloud computing platforms (Amazon, Google, **International
    Business Machines** (**IBM**)) and have some significant disadvantages, which
    are outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning cloud platforms are expensive; you usually have a trial period
    with free credits, but if you want to use them regularly you will have to pay
    a bill every month.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the cloud platform, some of them are not easy to configure and
    scale, which sometimes requires you to have knowledge of containers and clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They tend to offer simple to use but less flexible out-of-the-box solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As AutoKeras is based on an open source model, it solves these problems because
    you can view the source code, install it, and run it locally for free.
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoKeras is based on the following four main features that make it easy to
    install and use:'
  prefs: []
  type: TYPE_NORMAL
- en: It has a clear and intuitive **application programming interface** (**API**)
    based on the Keras API. Users without programming experience can easily learn
    how to use it, but it also allows advanced users to adjust lower-level system
    parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can work both locally and in the cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is based on a dynamic configuration that adapts the size of the neural architecture
    in the function of the **graphics processing unit** (**GPU**) memory available
    on the local system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is actively developed and maintained by the open source community.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's look at a practical example that creates a simple classifier using AutoKeras
    to predict handwritten digits. But first, we will have to configure a work environment
    by installing AutoKeras and its necessary dependencies on it.
  prefs: []
  type: TYPE_NORMAL
- en: How to run the AutoKeras experiments?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the main tool to implement all the coding examples in this book, we will
    use Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: A **notebook** is a file generated by Jupyter Notebook ([https://jupyter.org](https://jupyter.org)),
    an open source framework for creating and sharing documents that incorporates
    live code, visualizations, and rich text. Both the editing and the execution is
    done in a web browser, adding snippets (called cells) of code and rich text that
    show us clearly and visually what is being programmed. Each of these code cells
    can be run independently, making development interactive and avoiding having to
    run all your code if there is an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can see how a Jupyter notebook is running
    our experiment (notebook file) in a web browser just by clicking the **Run** button
    on the toolbar:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Jupyter notebook running just the training cell in AutoKeras
    experiment](img/B16953_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – Jupyter notebook running just the training cell in AutoKeras experiment
  prefs: []
  type: TYPE_NORMAL
- en: Using Jupyter notebooks is a great way to get started with AutoKeras, but not
    the only one; alternatively, you can also create your experiments in standalone
    Python scripts and run them from the command line or from your own **integrated
    development environment** (**IDE**).
  prefs: []
  type: TYPE_NORMAL
- en: Installing AutoKeras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following sections, we will explain in detail the different options that
    exist for installing AutoKeras and how to configure each one step by step.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options to choose when installing AutoKeras: we can install it
    in a local workstation or we can install it in the cloud. Each of the two options
    has its pros and cons that we will analyze throughout this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing AutoKeras in the cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the cloud, we have opted for two options: install it on an **Amazon Web
    Services** (**AWS**) instance/container, or use **Google Colaboratory**. In both
    cases, we will connect to the cloud instance using Jupyter notebooks from a web
    browser, as shown in the following screenshot. We just need a computer with an
    internet connection to run the notebooks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – AutoKeras cloud configurations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – AutoKeras cloud configurations
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at the options for the cloud in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: AutoKeras with Google Colaboratory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Google offers a Jupyter notebook-hosting service called **Colaboratory** where
    you can upload your Jupyter notebooks and run them on Google's cloud servers,
    leveraging the power of Google hardware (GPU or **tensor processing unit** (**TPU**)),
    regardless of the power of your workstation. All you need is a web browser. Also,
    as we said before, notebooks can install their own dependencies, so the AutoKeras
    installation can be performed while running the notebook (as we are doing with
    the notebooks in this book).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can run our MNIST notebook by just following these three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create an account at [https://colab.research.google.com](https://colab.research.google.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In Colaboratory, open the experiment from GitHub with this link: [https://colab.research.google.com/github/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter02/Chapter2.ipynb](https://colab.research.google.com/github/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter02/Chapter2.ipynb).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Run** button to start the AutoKeras installation and run the experiment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can see Colaboratory running our experiment:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.6 – AutoKeras running in Google Colaboratory](img/B16953_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – AutoKeras running in Google Colaboratory
  prefs: []
  type: TYPE_NORMAL
- en: So, Google Colaboratory is a very good option to explore and run your notebooks
    quickly and easily, but next, we will also explain in detail how to install Jupyter
    notebook, plus the necessary dependencies, to run our notebooks in an AWS instance
    or in your own workstation.
  prefs: []
  type: TYPE_NORMAL
- en: AutoKeras in AWS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Basically, we have to make sure we create an Amazon EC2 Ubuntu/ Linux instance
    with GPU support and the **Compute Unified Device Architecture** (**CUDA**) libraries.
    Because AutoKeras will be installed when our Jupyter notebook is running, we just
    have to install the Jupyter framework and run our notebooks there. The following
    screenshot shows the client and server sides of an AutoKeras installation in an
    AWS instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – AutoKeras running in AWS instance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – AutoKeras running in AWS instance
  prefs: []
  type: TYPE_NORMAL
- en: There are many instances of AWS, some of them with the CUDA and Jupyter libraries
    already preinstalled and its ports mapped to access from your browser. The configuration
    of these is outside the scope of this book, but at [https://docs.aws.amazon.com/dlami/](https://docs.aws.amazon.com/dlami/)
    there is detailed information on how to set up DL **Amazon Machine Images** (**AMIs**)
    that allow you to quickly build Amazon **Elastic Compute Cloud** (**EC2**) instances
    on Amazon Linux or Ubuntu, preinstalled with the most popular DL frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer containers over instances, you also have the option to run **AWS
    DL Containers** (**AWS DL Containers**) which are Docker images similar to previous
    AMIs, with DL software preinstalled. Find out more at [https://aws.amazon.com/machine-learning/containers/](https://aws.amazon.com/machine-learning/containers/).
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoKeras in the cloud: advantages and disadvantages'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you don't have a powerful GPU, the cloud is a good and inexpensive option
    to get started without having to buy additional hardware.
  prefs: []
  type: TYPE_NORMAL
- en: The cloud offering makes it easy to get started with AutoKeras; you can set
    it up from scratch on an AWS instance, upload your experiments to cloud services
    such as Google Colaboratory ([colab.research.google.com](http://colab.research.google.com)),
    or run the training on a remote server using an AutoKeras extension. At the end
    of the book, we will see an extension called TensorFlow Cloud that allows you
    to run your program on **Google Cloud Platform** (**GCP**) just by inserting a
    few more lines of code, taking easy advantage of the computing power in this cloud
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: But for a more intensive use of DL, this configuration is not the most suitable
    in the long run. Cloud instances or services are expensive, and if you need to
    train a model for more than a few hours, it is worth investing in a local workstation
    with one or more GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you need a large-scale on-demand configuration, setting
    up your own server cluster requires high cost in human and hardware resources
    and is much more difficult to scale and maintain than the cloud alternative.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this screenshot, you can see main differences between cloud and on-premises:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – AutoKeras in the cloud versus local costs](img/B16953_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – AutoKeras in the cloud versus local costs
  prefs: []
  type: TYPE_NORMAL
- en: In short, running AutoKeras in the cloud is a very good way to start. You can
    follow the code examples in this book and get cutting-edge prediction results
    using the power of cloud tools such as Google Colaboratory, but if you are planning
    to run your own experiments for several days or even weeks of training, it's best
    to get your own GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Installing AutoKeras locally
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you already have your own hardware resources, it's time to install the software
    to run your models there. The options that are outlined next will guide you to
    achieve that goal.
  prefs: []
  type: TYPE_NORMAL
- en: Which operating system to choose
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When it comes to choosing an operating system for AutoKeras, Linux is undoubtedly
    the most suitable option for both your workstation and the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Although it is possible to use AutoKeras in Windows, this is not recommended.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, the ideal option is an Ubuntu Linux machine due to the number
    of packages available and because it is the system most used by the ML community.
    If you use Windows, the simplest and fastest solution to get everything working
    is to install Ubuntu with a dual boot on your workstation, following the instructions
    in this link: [https://help.ubuntu.com/community/WindowsDualBoot](https://help.ubuntu.com/community/WindowsDualBoot).'
  prefs: []
  type: TYPE_NORMAL
- en: You can also use an AutoKeras Docker image, but depending on your hardware,
    this sometimes creates problems in accessing the GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Installing AutoKeras on an Ubuntu Linux workstation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once you have Ubuntu installed on your workstation, you can follow these steps
    to install AutoKeras and run the notebook files that come with this book:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a shell and run these commands to install the Jupyter notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run this command to start the notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, go to `http://127.0.0.1:8888` in your browser and open the notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the top menu, go to **Runtime** -> **Run All** to run the experiment. AutoKeras
    and its dependencies will be installed before running the rest of the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**GPU setup (optional)**: If you have GPUs on your workstation and want AutoKeras
    to use them to accelerate the training of these, you can follow this tutorial
    to set this up:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Keep in mind that AutoKeras is a work in progress and it evolves very quickly,
    and there may be changes in the installation process. I therefore recommend taking
    a look at the latest installation instructions, at [https://autokeras.com/install/](https://autokeras.com/install/).
  prefs: []
  type: TYPE_NORMAL
- en: Run AutoKeras using a Docker container. The easiest way to get started with
    TensorFlow and Keras is to run in a Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker** is a set of tools that allows you to install software in packages
    called containers, using virtualization at the operating system level. Each of
    the containers behaves like a single operating system with its own software, libraries,
    and configuration files, and these are isolated from each other. The process for
    creating a Docker container involves three steps, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, a Docker container is defined in a file called **Dockerfile**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, using the Docker command-line tool, you can build an image from this Dockerfile.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, you can start a Docker container from this image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can see these three steps in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Building a container from a Dockerfile'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – Building a container from a Dockerfile
  prefs: []
  type: TYPE_NORMAL
- en: There is a public repository for Docker images called Docker Hub ([https://hub.docker.com/](https://hub.docker.com/)).
    There, you can find thousands of Docker images with preinstalled software packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use a Docker image for AutoKeras with the latest version of the framework
    and get its dependencies already installed using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the latest AutoKeras Docker image to your machine, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the AutoKeras Docker container, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you need more memory, just change the `shm-size` value.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run a local Python script inside the container, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we have mounted the `hostDir:/app` host folder where the Python
    file to execute is located.
  prefs: []
  type: TYPE_NORMAL
- en: You can also install the Jupyter notebook and run the AutoKeras installation
    process from the notebook experiment, as we did in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hello MNIST: Implementing our first AutoKeras experiment'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our first experiment will be an image classifier using the MNIST dataset. This
    MINST classification task is like the *"hello world"* of DL. It is a classic problem
    of classifying images of handwritten digits into 10 categories (0 to 9). The images
    come from the MNIST, the most famous and widely used dataset in ML. It contains
    70,000 images (60,000 for training and 10,000 for testing) collected in the 1980s
    by the NIST.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next screenshot, you can see some samples of every number in the MNIST
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – MNIST dataset sample images'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – MNIST dataset sample images
  prefs: []
  type: TYPE_NORMAL
- en: AutoKeras is designed to easily classify all types of data inputs—such as structured
    data, text, or images—as each of them contains a specific class.
  prefs: []
  type: TYPE_NORMAL
- en: For this task, we will use `ImageClassifier`. This class generates and tests
    different models and hyperparameters, returning an optimal classifier to categorize
    the images of handwritten digits.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's have a look at the most relevant cells of the notebook in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the needed packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Load AutoKeras and the required packages, such as matplotlib, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding packages include a plotting Python library that we have used to
    plot some digital representations, and the dataset we used is the MNIST handwritten
    digits dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the MNIST dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have to first load the MNIST data in memory and have a quick look at the
    dataset shape. To do this, we run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We can see from the preceding output that each dataset contains images of size
    `28x28` pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see what a digit looks like by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Training and test samples visualization'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Training and test samples visualization
  prefs: []
  type: TYPE_NORMAL
- en: Once we have looked at some samples of datasets, let's look at their distribution.
  prefs: []
  type: TYPE_NORMAL
- en: How are the digits distributed?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When we are working with datasets, it is very important to check that the data
    is distributed homogeneously. This can be done easily by using `numpy` functions,
    as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Training and test dataset histograms'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Training and test dataset histograms
  prefs: []
  type: TYPE_NORMAL
- en: It seems homogeneous—each set of digits has similar amounts of samples, so it's
    now time to create our model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an image classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now use the AutoKeras `ImageClassifier` class to find the best classification
    model. Just for this little example, we set `max_trials` (the maximum number of
    different Keras models to try) to 1 and the number of epochs to train each model
    to 20, but for real use it is recommended to set a large number of trials and
    not to set the `epochs` parameter, to use an adaptive number of epochs automatically.
    The code can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run the training to search for the optimal classifier for the MNIST
    training dataset, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Notebook output of image classifier training'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Notebook output of image classifier training
  prefs: []
  type: TYPE_NORMAL
- en: In the previous output, we can see that the model has reached quite good accuracy
    for the training dataset in just a couple of minutes. We can also see that the
    best generated model was saved to disk.
  prefs: []
  type: TYPE_NORMAL
- en: We can also see that the precision increases in each epoch, so if we increase
    the number of *epochs* we would have a more precise model, although it would also
    take longer to finish. It is also important to take into account that after a
    high number of epochs, the model will usually stop learning.
  prefs: []
  type: TYPE_NORMAL
- en: Let's test it with the test dataset to know the actual accuracy of the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model with the test set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After training, it''s time to measure the actual prediction of our model using
    the reserved test dataset. In this way, we can rule out that the good results
    obtained with the training set were due to overfitting. Have a look at the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We can see here that there is really good prediction accuracy using our test
    dataset (98.8%), considering that we only spent a couple of minutes in the training
    phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s have a look at how it is predicting a single test sample. First, we
    visualize the number and its true value, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Test sample to be predicted](img/B16953_02_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 – Test sample to be predicted
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we print the predicted value using our classifier, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the output matches the true value, so our classifier has predicted
    this correctly. Let's now take a look inside the classifier to understand how
    it is working.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are now exporting our classifier model to Keras so that we can see a little
    summary, with the architecture of the best generated model found. Here is the
    code we need to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – Image classifier model architecture summary](img/B16953_02_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.15 – Image classifier model architecture summary
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have experience in Keras or Tensorflow this output will be a bit
    confusing, but don't worry—it's not necessary to understand it to use AutoKeras
    because the tool does all the work, abstracting us from these details, but it's
    always good to know how it works. In later chapters, we will see what each layer
    means in detail, but let's see an overview of what's going on here.
  prefs: []
  type: TYPE_NORMAL
- en: Each layer performs a transformation operation of the input data, passing the
    transformed data to the next layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first layer has a 28x28 input that corresponds to the pixels of the image,
    as seen in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following tree layers transform and normalize the image to adapt it to
    the input of the convolutional operations (Conv2D):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The convolutional operations layers, widely used for the classification of
    images, extract characteristics of the image through the use of filters (we will
    talk about this in later chapters). We can see the process in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Subsequently there are several layers that prevent overfitting by performing
    dropout (arbitrarily disconnecting part of the neural connections), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, a full connect operation is performed that reduces the dimension of the
    output of the convolutional operations to 10 elements that correspond to the numbers
    from 0 to 9, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the last layer (Softmax) is left with only the highest value of the
    10 elements that will correspond to the final predicted number, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a more graphical way to visualize the model, so let''s see it by running
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Image classifier model architecture visualization'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – Image classifier model architecture visualization
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, each block represents a layer and the output of each
    is connected to the input of the next, except the first block (whose input is
    the image) and the last block (whose output is the prediction).
  prefs: []
  type: TYPE_NORMAL
- en: Creating an image regressor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we will use a different approach to figure out the digit values from the
    image: a regression model call regressor.'
  prefs: []
  type: TYPE_NORMAL
- en: The image regressor will try to predict the scalar value of the digit instead,
    to classify it in a 0-9 category.
  prefs: []
  type: TYPE_NORMAL
- en: AutoKeras has already a special class ready to use called `ImageRegressor`,
    which will find the best regression model.
  prefs: []
  type: TYPE_NORMAL
- en: As we did with the classifier, for this little example we set `max_trials` (the
    maximum number of different Keras models to try) to 1 and the number of epochs
    to train each model to 20, but for real use it is recommended to set a large number
    of trials and not to set the `epochs` parameter to use an adaptive number of epochs
    automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we initialize the image regressor, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now, feed the image regressor with the training dataset, as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now is the moment of truth—let's evaluate it with our test set.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model with the test set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we evaluate the best model with the testing dataset, using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Notebook output of image regressor training'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Notebook output of image regressor training
  prefs: []
  type: TYPE_NORMAL
- en: After 20 minutes, the best model found has a `0.083`, which isn't bad. MSE is
    a widely used metric for measuring performance in regression models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s predict the first 10 digits of the test dataset with the best model
    found, and print the predicted and true values to compare them. We can do this
    by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, it''s predicting the true value in every one of the cases.
    Let''s see it in a more graphical way by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18 – Image digits labeled with the predicted values](img/B16953_02_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.18 – Image digits labeled with the predicted values
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we have rounded up the float values returned by the regressor to
    compare them to the true values. This is done because regressors always return
    continuous values that they approximate to the real value, so if we want to predict
    discrete values (0 to 9 digits), we have to do a rounding to return the predicted
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Now, as we did with the classifier, let's take a look at the architecture of
    the best generated model.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We export the model to a Keras model and then we make a call to the `model.summary`
    function to see the architecture, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – Image regressor model architecture summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_02_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.19 – Image regressor model architecture summary
  prefs: []
  type: TYPE_NORMAL
- en: 'As we did with the classifier, there is a more visual way to see it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Image regressor model architecture visualization](img/B16953_02_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.20 – Image regressor model architecture visualization
  prefs: []
  type: TYPE_NORMAL
- en: In this example of the classifier, we have given a quick view of each block.
    We will not go deeper here, as I think this is enough for a "getting started"
    chapter. In the following chapters, we will explain in more detail each of the
    blocks that appear in the screenshots.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned the main options for getting started with
    AutoKeras, from installation to running in various environments.
  prefs: []
  type: TYPE_NORMAL
- en: You have also seen the power of AutoKeras by implementing two different approaches
    of a high-precision image classifier in just a few lines of code and 2 minutes
    of training.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned to implement a DL model from scratch, following these
    same steps and simply changing the dataset, your model would be able to classify
    all kinds of images.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, you will learn how to solve more complicated tasks
    related to images, structured data, and plaintext as input data sources, but before
    that, in the next chapter, we will see how to prepare the data to feed to AutoKeras
    by using some interesting tools to automate this process as much as possible.
  prefs: []
  type: TYPE_NORMAL
