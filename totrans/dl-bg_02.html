<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Introduction to Machine Learning
                </header>
            
            <article>
                
<p>You have probably heard the term <strong>Machine Learning</strong> (<strong>ML</strong>) or <strong>Artificial Intelligence</strong> (<strong>AI</strong>) frequently in recent years, especially <strong>Deep Learning</strong> (<strong>DL</strong>). It may be the reason you decided to invest in this book and get to know more. Given some new, exciting developments in the area of neural networks, <span>DL has come to be a hot area in ML</span>. Today, it is difficult to imagine a world without quick text translation between languages, or without fast song identification. These, and many other things, are just the tip of the iceberg when it comes to the potential of DL to change your world.<span><span> </span></span><span>When you finish this book, we hope you will join the bus and ride along with amazing new applications and projects based on DL. </span></p>
<p class="mce-root">This chapter briefly introduces the field of ML and how it is used to solve common problems. Throughout this chapter, you will be driven to understand the basic concepts of ML, the research questions addressed, and their significance. </p>
<p>The following topics will be covered in this chapter: </p>
<ul>
<li>Diving into the ML ecosystem</li>
<li>Training ML algorithms from data</li>
<li>Introducing deep learning</li>
<li>Why is deep learning important today?</li>
</ul>
<h1 id="uuid-d9219901-bd67-41e4-9282-f3393225853a">Diving into the ML ecosystem</h1>
<p class="mce-root">From the typical ML application process depicted in <em>Figure 1.1</em>, you can see that ML has a broad range of applications. However, ML algorithms are only a small part of a bigger ecosystem with a lot of moving parts, and yet ML is transforming lives around the world today:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/238398f2-bdc7-42c4-a046-5fb6057cf064.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 1.1 - ML ecosystem. ML interacts with the world through several stages of data manipulation and interpretation to achieve an overall system integration</div>
<p>Deployed ML applications usually start with a process of data collection that uses sensors of different types, such as cameras, lasers, spectroscopes, or other types of direct access to data, including local and remote databases, big or small. In the simplest of cases, input can be gathered through a computer keyboard or smartphone screen taps. At this stage, the data collected or sensed is considered to be raw data.</p>
<p>Raw data is usually preprocessed before presenting it to an ML model. Raw data is rarely the actual input to ML algorithms, unless the ML model is meant to find a rich representation of the raw data, and later be used as input to another ML algorithm. In other words, there are some ML algorithms that are specifically used as preprocessing agents and they are not at all related to a main ML model that will classify or regress on the preprocessed data. In a general sense, this data preprocessing stage aims to convert raw data into arrays or matrices with specific data types. Some popular preprocessing strategies include the following:</p>
<ul>
<li>Word-to-vector conversions, for example, using GloVe or Word2Vec</li>
<li>Sequence-to-vector or sequence-to-matrix strategies</li>
<li>Value range normalization, for <span>example</span>, (0, 255) to (0.0, 1.0)</li>
<li>Statistical value normalization, for <span>example</span>, to have zero mean and unit variance</li>
</ul>
<p>Once these preprocessing measures take place, most ML algorithms can use the data. However, it must be noted that the preprocessing stage is not trivial, it requires advanced knowledge and skills with respect to operating systems and sometimes even electronics. In a general sense, a real ML application has a long pipeline touching different aspects of computer science and engineering.</p>
<div class="packt_infobox">The processed data is what you will usually see in books like the one you are reading right now. The reason is that we need to focus on deep learning instead of data processing. If you wish to be more knowledgeable in this area, you could read data science materials such as Ojeda, T. <em>et.al.</em> 2014 or Kane, F. 2017.</div>
<p class="mce-root"><span>Mathematically speaking, the processed data as a whole is referred to using the uppercase, bold font, letter <strong><em>X</em></strong>,</span><span> which has </span><strong><em>N</em></strong><span> rows (or data points). If we want to refer to the specific</span> <em>i</em><span>-th element (or row) of the dataset, we would do that by writing: <em><strong>X<sub>i</sub></strong></em></span><span>.</span> <span>The dataset will have </span><em>d</em><span> columns and they are usually called</span> features<em>.</em> <span>One way to think about the features is as </span>dimensions<span>. For example, if the dataset has two features, height and weight, then you could represent the entire dataset using a two-dimensional plot. The first dimension,</span> <strong><em>x<sub>1</sub></em></strong><span>, (height) can be the horizontal axis, while the second dimension, <strong><em>x<sub>2</sub></em></strong></span><span>, (weight) can be the vertical axis, as depicted in <em>Figure 1.2</em>:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c6a8a698-ba57-462e-9c70-0d97094963cd.png" style="width:30.17em;height:21.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 1.2 - Sample two-dimensional data</div>
<p>During production, when the data is presented to an ML algorithm, a series of tensor products and additions will be executed. Such vectorial operations are usually transformed or normalized using non-linear functions. This is then followed by more products and additions, more non-linear transformations, temporary storage of intermediate values, and finally producing the desired output that corresponds to the input. For now, you can think of this process as an ML black box that will be revealed as you continue reading. </p>
<p>The output that the ML produces in correspondence to the input usually requires some type of interpretation, for example, if the output is a vector of probabilities of objects being classified to belong to a group or to another, then that may need to be interpreted. You may need to know how low the probabilities are in order to account for uncertainty, or you may need to know how different are the probabilities to account for even more uncertainty. The output processing serves as the connecting factor between ML and the decision-making world through the use of business rules. These rules can be, for example, <em>if-then</em> rules such as, "If the predicted probability of the maximum is twice as large as the second maximum, then issue a prediction; otherwise, do not proceed to make a decision." Or they can be formula-based rules or more complex systems of equations.</p>
<p>Finally, in the decision-making stage, the ML algorithm is ready to interact with the world by turning on a light bulb through an actuator, or to buy stock if the prediction is not uncertain, by alerting a manager that the company will run out of inventory in three days and they need to buy more items, or by sending an audio message to a smartphone speaker saying, "Here is the route to the movie theater" and opening a maps application through an <strong>application programming interface</strong> (<strong>API</strong>) call or <strong>operating system</strong> (<strong>OS</strong>) commands.</p>
<p>This is a broad overview of the world of ML systems when they are in production. However, this assumes that the ML algorithm is properly trained and tested, which is the easy part, trust me. At the end of the book, you will be skilled in training highly complex, deep learning algorithms but, for now, let us introduce the generic training process.</p>
<h1 id="uuid-61027c5f-3a95-4458-8bc0-f8425cdd2fbf">Training ML algorithms from data</h1>
<p class="mce-root CDPAlignLeft CDPAlign">A typical preprocessed dataset is formally defined as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/92150313-7b8e-4825-ace3-647ebae682c9.png" style="width:8.08em;height:1.58em;"/></p>
<p>Where <em>y</em> is the desired output corresponding to the input vector <strong>x</strong>. So, the motivation of ML is to use the data to find linear and non-linear transformations over <strong>x</strong> using highly complex tensor (vector) multiplications and additions, or to simply find ways to measure similarities or distances among data points, with the ultimate purpose of predicting <strong><em>y</em></strong> given <strong>x</strong>.</p>
<p>A common way of thinking about this is that we want to approximate some unknown function over <strong>x</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8cc3eeec-c6d9-4f63-84e3-00b63c6dfad2.png" style="width:9.25em;height:1.42em;"/></p>
<p>Where <em><strong>w</strong></em> is an unknown vector that facilitates the transformation of <strong>x</strong> along with <strong><em>b</em></strong>. This formulation is very basic, linear, and is simply an illustration of what a simple learning model would look like. In this simple case, the ML algorithms revolve around finding the best <em><strong>w</strong></em> and <strong><em>b</em></strong> that yields the closest (if not perfect) approximation to <em><strong>y</strong></em>, the desired output. Very simple algorithms such as the perceptron (<span>Rosenblatt, F. 1958</span>) try different values for <em><strong>w</strong></em> and <em>b</em> using past mistakes in the choices of<span> </span><strong>w</strong><span> and </span><strong><em>b</em></strong><span> to make the next selection in proportion to the mistakes made. </span></p>
<p>A combination of perceptron-like models that look at the same input, intuitively, turned out to be better than single ones. Later, people realized that having them stacked may be the next logical step leading to multilayer perceptrons, but the problem was that the learning process was rather complicated for people in the 1970s. These kinds of multilayered systems were analog to brain neurons, which is the reason we call them neural networks today. With some interesting discoveries in ML, new specific kinds of neural networks and algorithms were created known as deep learning.</p>
<h1 id="uuid-d6671f30-a255-44a0-9746-634dd962be5f">Introducing deep learning</h1>
<p><span>While a more detailed discussion of learning algorithms will be addressed in <a href="7f55e68e-2e9f-486f-9337-5b2ea7bdb504.xhtml">Chapter 4</a>, <em>Learning from Data</em>, in this section, we will deal with the fundamental concept of a neural network and the developments that led to deep learning.</span></p>
<h2 id="uuid-eb921f03-6970-4b21-9026-1477056a4fcb">The model of a neuron</h2>
<p>The human brain has input connections from other neurons (synapses) that receive stimuli in the form of electric charges, and then has a nucleus that depends on how the input stimulates the neuron that can trigger the neuron's activation<strong>. </strong>At the end of the neuron, the output signal is propagated to other neurons through dendrites, thus forming a network of neurons. </p>
<p>The analogy of the human neuron is depicted in <em>Figure 1.3</em>, where the input is represented with the vector <em><strong>x</strong></em>, the activation of the neuron is given by some function <strong>z(.)</strong>, and the output is <strong><em>y</em></strong>. The parameters of the neuron are <strong>w</strong> and <strong><em>b</em></strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f17064ac-8bd1-46e3-832f-ecdc2b9dad6b.png" style="width:25.42em;height:15.00em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 1.3 - The basic model of a neuron</div>
<p>The trainable parameters of a neuron are <em><strong>w</strong></em> and <strong><em>b</em></strong>, and they are unknown. Thus, we can use training data <img src="assets/c380f821-4bbe-426d-9996-1819f9a61000.png" style="width:0.92em;height:0.92em;"/> to determine these parameters using some learning strategy. From the picture, <strong>x</strong><sub><strong>1</strong> </sub>multiplies <em><strong>w<sub>1</sub></strong></em>, then <strong><em>x</em></strong><sub><strong>2</strong> </sub>multiplies <em><strong>w<sub>2</sub></strong></em>, and <em><strong>b</strong></em><sub> </sub>is multiplied by 1; all these products are added, which can be simplified as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a57b2bc2-0ad9-44cd-bbc2-42618a80eb84.png" style="width:11.58em;height:1.17em;"/></p>
<p class="CDPAlignLeft CDPAlign">The activation function operates as a way to ensure the output is within the desired output range. Let's say that we want a simple linear activation, then the function <strong>z</strong><span><strong>(.)</strong> is non-existing or can be bypassed, as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6182f132-99da-4278-9242-57133e23fb53.png" style="width:8.67em;height:1.17em;"/></p>
<p>This is usually the case when we want to solve a regression problem and the output data can have a range from -∞ to +<span>∞. However, we may want to train the neuron to determine whether a vector <em><strong>x</strong></em> belongs to one of two classes, say -1 and +1. Then we would be better suited using a function called a sign activation:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1a254e0a-49c7-42fb-aeb6-0fe282bd0c34.png" style="width:10.92em;height:1.17em;"/></p>
<p>Where the <em>sign</em>(.) function is denoted as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d0c512a7-95b3-40f9-b4cc-d3e4fdb35a88.png" style="width:16.17em;height:2.33em;"/></p>
<p>There are many other activation functions, but we will introduce those later on. For now, we will briefly show one of the simplest learning algorithms, the <span><strong>perceptron learning algorithm</strong> (<strong>PLA</strong>).</span></p>
<h2 id="uuid-0913f4bd-d508-4c63-881b-1a9872c73c67">The perceptron learning algorithm</h2>
<p>The PLA begins from the assumption that you want to classify data, <strong>X</strong>, into two different groups, the positive group (+) and the negative group (-). It will find <em>some </em><strong>w </strong>and <em>b</em> by training to predict the corresponding correct labels <em><strong>y</strong>.</em> The PLA uses the <em>sign</em>( . ) function as the activation. Here are the steps that the PLA follows:</p>
<ol>
<li>Initialize <strong>w</strong> to zeros, and iteration counter <em>t</em> = 0</li>
<li>While there are any incorrectly classified examples:</li>
</ol>
<ul>
<li style="padding-left: 60px"><span>Pick an incorrectly classified example, call it <strong>x</strong><sup>*</sup>, whose true label is <em>y</em><sup>*</sup></span></li>
<li style="padding-left: 60px">Update <strong>w</strong> as follows: <strong>w</strong><em><sub>t+1</sub></em> = <strong>w</strong><em><sub>t</sub></em> + <em>y</em><sup>*</sup><strong>x</strong><sup>*</sup></li>
<li style="padding-left: 60px">Increase iteration counter <em>t</em>++ and repeat</li>
</ul>
<p>Notice that, for the PLA to work as we want, we have to make an adjustment. What we want is for<span> <img src="assets/851a5760-3a74-45bb-81b2-14bf338e8848.png" style="width:5.25em;height:1.42em;"/></span> to be implied in the expression <img src="assets/d1ac8002-3b39-47be-945c-fdff2b35ae12.png" style="width:2.42em;height:1.17em;"/>. The only way this could work is if we set <img class="fm-editor-equation" src="assets/7f9e85b0-b9bf-441d-a0ca-5d17632a508a.png" style="width:12.75em;height:1.58em;"/> and <img class="fm-editor-equation" src="assets/34e97ef0-ae8a-4fb4-9692-c9dfe8d0e8dc.png" style="width:12.00em;height:1.58em;"/>. The previous rule seeks <strong>w</strong>, which implies the search for <em>b.</em></p>
<p>To illustrate the PLA, consider the case of the following linearly separable dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/05cdb81d-1ef5-4004-a9fd-786de7689fa1.png" style="width:28.92em;height:20.83em;"/></p>
<div class="packt_infobox"><span>A </span>linearly<span> separable dataset is one whose data points are sufficiently apart such that at least one hypothetical line exists that can be used to separate the data groups into two. Having a linearly separable dataset is the dream of all ML scientists, but it is seldom the case that we will find such datasets naturally. In further chapters, we will see that neural networks transform the data into a new feature space where such a line may exist.</span></div>
<p>This two-dimensional dataset was produced at random using Python tools that we will discuss later on. For now, it should be self-evident that you can draw a line between the two groups and divide them. </p>
<p>Following the steps outlined previously, the PLA can find <strong><em>a</em></strong> solution, that is, a separating line that satisfies the training data target outputs completely in only four iterations in this particular case. The plots after each update are depicted in the following plots with the corresponding line found at every update:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a4fa4db2-1cc1-46e1-a1b1-7d60035a1cf0.png" style="width:24.33em;height:17.50em;"/></p>
<p>At iteration zero, all 100 points are misclassified, but after randomly choosing one misclassified point to make the first update, the new line only misses four points:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e868771c-3d6d-407b-9930-cc09476afb8e.png" style="width:24.50em;height:17.67em;"/></p>
<p>After the second update, the line only misses one data point:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/310f03fc-6726-48f1-a2ad-8e43469e6987.png" style="width:24.92em;height:17.92em;"/></p>
<p>Finally, after update number three, all data points are correctly classified. This is just to show that a simple learning algorithm can successfully learn from data. Also, the perceptron model led to much more complicated models such as a neural network. W<span>e will now introduce the concept of a shallow network and its basic complexities.</span></p>
<h2 id="uuid-b27ece67-3f69-4f27-b0c1-71c3847e47eb">Shallow networks</h2>
<p><span>A neural network consists of multiple networks connected in different layers. In contrast, a perceptron has only one neuron and its architecture consists of an input layer and an output layer. In neural networks, there are additional layers between the input and output layer, as shown in <em>Figure 1.4</em>, and they are known as</span><strong> </strong>hidden layers:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/eaa06b01-7c6d-491f-9dae-45554fc092b1.png" style="width:31.67em;height:24.50em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 1.4 - Example of a shallow neural network</div>
<p>The example in the figure shows a neural network that has a hidden layer with eight neurons in it. The input size is 10-dimensional, and the output layer has four dimensions (four neurons). This intermediate layer can have as many neurons as your system can handle during training, but it is usually a good idea to keep things to a reasonable number of neurons.</p>
<div class="packt_tip">If this is your first time using neural networks, it is recommended that your hidden layer size, that is, the number of neurons, is greater than or equal to the input layer, and less than or equal to the output size. However, although this is good advice for absolute beginners, this is not an absolute scientific fact since finding the optimal number of neurons in neural networks is an art, rather than a science, and it is usually determined through a great deal of experimentation.</div>
<p>Neural networks can solve more difficult problems than without a network, for example<em>,</em> with a single neural unit such as the perceptron. This must feel intuitive and must be easy to conceive. A neural network can solve problems including and beyond those that are linearly separable. For linearly separable problems, we can use both the perceptron model and a neural network. However, for more complex and non-linearly separable problems, the perceptron cannot offer a high-quality solution, while a neural network does.</p>
<p>For example, if we consider the sample two-class dataset and we bring the data groups closer together, the perceptron will fail to terminate with a solution and some other strategy can be used to stop it from going forever. Or, we can switch to a neural network and train it to find the best solution it can possibly find. <em>Figure 1.5</em> shows an example of training a neural network with 100 neurons in the hidden layer over a two-class dataset that is not linearly separable:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/23682c14-ee9e-4535-a5a0-4a37007f3993.png" style="width:25.08em;height:17.67em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 1.5 - Non-separable data and a non-linear solution using a neural network with 100 neurons in the hidden layer</div>
<p>This neural network has 100 neurons in the hidden layer. This was a choice done by experimentation and you will learn strategies on how to find such instances in further chapters. However, before we go any further, t<span>here are two new terms introduced that require further explanation: </span><span>non-separable data and non-linear models, which are defined as follows:</span></p>
<ul>
<li>Non-separable data is such that there is no line that can separate groups of data (or classes) into two groups.</li>
<li>Non-linear models, or solutions, are those that naturally and commonly occur when the best solution to a classification problem is not a line. For example, it can be some curve described by some polynomial of any degree greater than one. For an example, see <em>Figure 1.5</em>.</li>
</ul>
<p>A non-linear model is usually what we will be working with throughout this book, and the reason is that this is most likely what you will encounter out there in the real world. Also, it is non-linear, in a way, because the problem is non-separable. To achieve this non-linear solution, the neural network model goes through the following mathematical operations.</p>
<h3 id="uuid-a7bafa86-b97d-4cbe-8ac8-6c649eedd2ca">The input-to-hidden layer</h3>
<p>In a neural network, the input vector <em><strong>x</strong></em> is connected to a number of neurons through weights <em><strong>w</strong></em> for each neuron, which can be now thought of as a number of weight vectors forming a matrix <em><strong>W</strong></em>. The matrix <strong><em>W</em> </strong>has as many columns as neurons as the layer has, and as many rows as the number of features (or dimensions) <em><strong>x</strong></em> has. Thus, the output of the hidden layer can be thought of as the following vector:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/515143a9-56db-43e7-99fd-56f26ae62c95.png" style="width:8.50em;height:1.67em;"/></p>
<p>Where <strong>b</strong> is a vector of biases, whose elements correspond to one neural unit, and the size of <strong>h</strong> is proportional to the number of hidden units. For example, eight neurons in <em>Figure 1.4</em>, and 100 neurons in <em>Figure 1.5</em>. However, the activation function z(.) does not have to be the <em>sign</em>(.)<em> </em>function, in fact, it usually never is. Instead, most people use functions that are easily differentiable<em>.</em> </p>
<div class="packt_infobox">A differentiable activation function is one that has a mathematical derivative that can be computed with traditional numerical methods or that is clearly defined. The opposite would be a function that does not have a defined derivative, it does not exist, or is nearly impossible to calculate.</div>
<h3 id="uuid-7b69f0b2-b315-41ce-8be4-e3f481eeac50">The hidden-to-hidden layer</h3>
<p>In a neural network, we could have more than one single hidden layer, and we will work with this kind a lot in this book. In such case, the matrix <em><strong>W</strong></em> can be expressed as a three-dimensional matrix that will have as many elements in the third dimension and as many hidden layers as the network has. In the case of the <em>i</em>-th layer, we will refer to that matrix as <strong>W<sub><em>i</em></sub></strong> for convenience. </p>
<p>Therefore, we can refer to the output of the <em>i</em><span>-th </span>hidden layer as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dd6555c4-470b-422b-852e-773f99cadef2.png" style="width:11.75em;height:1.67em;"/></p>
<p>For <em>i</em> = 2, 3, ..., <em>k</em>-1, where <strong><em>k</em></strong> is the total number of layers, and the case of <em><strong>h<sub>1</sub></strong></em> is computed with the equation given for the first layer (see previous section), which uses <em><strong>x</strong></em> directly, and does not go all the way to the last layer, <em><strong>h<sub>k</sub></strong></em>, because that is computed as discussed next.</p>
<h3 id="uuid-f16f89cd-563a-4b82-82fc-4e4c1399cef8">The hidden-to-output layer</h3>
<p>The overall output of the network is the output at the last layer:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/995792ee-3b1c-4cf6-b1e8-2058af172a6c.png" style="width:12.17em;height:1.67em;"/></p>
<p>Here, the last activation function is usually different from the hidden layer activations. The activation function in the last layer (output) traditionally depends on the type of problem we are trying to solve. For example, if we want to solve a regression problem, we would use a linear function, or sigmoid activations for classification problems. We will discuss those later on. For now, it should be evident that the perceptron algorithm will no longer work in the training phase. </p>
<p>While the learning still has to be in terms of the mistakes the neural network makes, the adjustments cannot be in direct proportion to the data point that is incorrectly classified or predicted. The reason is that the neurons in the last layer are responsible for making the predictions, but they depend on a previous layer, and those may depend on more previous layers, and when making adjustments to <em><strong>W</strong></em> and <em><strong>b</strong></em>, the adjustment has to be made differently for each neuron. </p>
<p>One approach to do this is to apply gradient descent techniques on the neural network. There are many of these techniques and we will discuss the most popular of these in further chapters. In general, a gradient descent algorithm is one that uses the notion that, if you take the derivative of a function and that reaches a value of zero, then you have found the maximum (or minimum) value you can get for the set of parameters on which you are taking the derivatives. For the case of scalars, we call them derivatives, but for vectors or matrices (<strong>W</strong>, <strong>b</strong>), we call them gradients. </p>
<p>The function we can use is called a loss function.</p>
<div class="packt_infobox">A loss function is usually one that is differentiable so that we can calculate its gradient using some gradient descent algorithm. </div>
<p>We can define a loss function, for example, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/54f2b837-debb-482a-8c0f-18e7002c1435.png" style="width:10.25em;height:3.25em;"/></p>
<p>This loss is known as the <strong>mean squared error</strong> (<strong>MSE</strong>); it is meant to measure how different the target output <em><strong>y</strong></em> is from the predicted output in the output layer <em><strong>h</strong></em><sub><em><strong>k</strong></em></sub><sub><em> </em></sub>in terms of the square of its elements, and averaged. This is a good loss because it is differentiable and it is easy to compute.  </p>
<p>A neural network such as this <span>introduced</span> a great number of possibilities, but relied heavily on a gradient descent technique for learning them called backpropagation (<span>Hecht</span><span>-Nielsen, R. 1992)</span>. Rather than explaining backpropagation here (we will reserve that for later), we rather have to remark that it changed the world of ML, but did not make much progress for a number of years because it had some practical limitations and the solutions to these paved the way for deep learning.</p>
<h2 id="uuid-f1acaeda-d6cc-4d4c-90cb-705775e53efd">Deep networks</h2>
<p><span>On March 27, 2019, an announcement was published by the ACM saying that three computer scientists were awarded the Nobel Prize in computing, that is, the ACM Turing Award, for their achievements in deep learning. Their names are Yoshua Bengio, Yann LeCun, and Geoffrey Hinton; all are very accomplished scientists. One of their major contributions was in the learning algorithm known as backpropagation. </span></p>
<p>In <a href="https://www.acm.org/media-center/2019/march/turing-award-2018">the official communication</a>, the ACM wrote the following about Dr. Hinton and one of his seminal papers (Rumelhart, D. E. 1985):</p>
<div class="packt_quote">In a 1986 paper, “Learning Internal Representations by Error Propagation,” co-authored with David Rumelhart and Ronald Williams, Hinton demonstrated that the backpropagation algorithm allowed neural nets to discover their own internal representations of data, making it possible to use neural nets to solve problems that had previously been thought to be beyond their reach. The backpropagation algorithm is standard in most neural networks today.</div>
<p>Similarly, they wrote the following about Dr. LeCun's paper (<span>LeCun, Y., <em>et.al.,</em> 1998</span>):</p>
<div class="packt_quote">LeCun proposed an early version of the backpropagation algorithm (backprop), and gave a clean derivation of it based on variational principles. His work to speed up backpropagation algorithms included describing two simple methods to accelerate learning time.</div>
<p>Dr. Hinton was able to show that there was a way to minimize a loss function in neural networks using biologically inspired algorithms such as the backward and forward adjustment of connections by modifying its importance for particular neurons. Usually, backpropagation is related to feed-forward neural networks, while backward-forward propagation is related to Restricted Boltzmann Machines<strong> </strong>(covered in <a href="6ec46669-c8d3-4003-ba28-47114f1515df.xhtml">Chapter 10</a>, <em>Restricted Boltzmann Machines</em>). </p>
<p>A feed-forward neural network is one whose input is pipelined directly toward the output layer through intermediate layers that have no backward connections, as shown in <em>Figure 1.4</em>, and we will talk about these all the time in this book. </p>
<div class="packt_tip">It is usually safe to assume that, unless you are told otherwise, all neural networks have a feed-forward architecture. Most of this book will talk about deep neural networks and the great majority are feed-forward-like, with the exception of Restricted Boltzmann Machines or recurrent neural networks, for example.</div>
<p>Backpropagation enabled people to train neural networks in a way that was never seen before; however, people had problems training neural networks on large datasets, and on larger (deeper) architectures. If you go ahead and look at neural network papers in the late '80s and early '90s, you will notice that architectures were small in size; networks usually had no more than two or three layers, and the number of neurons usually did not exceed the order of hundreds. These are (today) known as shallow neural networks. </p>
<p>The major problems were with convergence time for larger datasets, and convergence time for deeper architectures. Dr. LeCun's contributions were precisely in this area as he envisioned different ways to speed up the training process. Other advances such as vector (tensor) computations over <strong>graphics processing units</strong> (<strong>GPUs</strong>) increased training speeds dramatically.</p>
<p>Thus, over the last few years, we have seen the rise of deep learning, that is, the ability to train deeper neural networks, with more than three or four layers, in fact with tens and hundreds of layers. Further, we have a wide variety of architectures that can accomplish things that we were not able in the last decade.</p>
<p>The deep network shown in <em>Figure 1.6</em> would have been impossible to train 30 years ago, and it is not that deep anyway:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e261302a-8ab2-44f4-a52c-e856ad8bc42e.png" style="width:45.00em;height:33.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 1.6 - A deep and fully connected feed-forward neural network with eight layers</div>
<div class="packt_infobox">In this book, we will consider a deep neural network any network that has more than three or four layers overall. However, there is no standard definition as to exactly how deep is considered deep out there. Also, you need to consider that what we consider deep today, at the time of writing this book in 2020, will probably not be considered deep in 20 or 30 years from now.</div>
<p>Regardless of the future of DL, let us now discuss what makes DL so important today.</p>
<h1 id="uuid-36fe50cf-e47c-4784-a3ce-378690629308">Why is deep learning important today?</h1>
<p><span>Today, we enjoy the benefits of algorithms and strategies that we did not have 20 or 30 years ago, which enable us to have amazing applications that are changing lives. Allow me to summarize some of the great and important things about deep learning today:</span></p>
<ul>
<li><strong>Training in mini-batches</strong>: This strategy allows us today to have very large datasets and train a deep learning model little by little. In the past, we would have to load the entire dataset into memory, making it computationally impossible for some large datasets. Today, yes, it may take a little longer, but we at least can actually perform training on finite time. </li>
<li><strong>Novel activation functions</strong>: <strong>Rectified linear units</strong> (<strong>ReLUs</strong>), for example, are a relatively new kind of activation that solved many of the problems with large-scale training with backpropagation strategies. These new activations enable training algorithms to converge on deep architectures when, in the past, we would get stuck on non-converging training sessions that would end up having exploding or vanishing gradients.</li>
<li><strong>Novel neural network architectures</strong>: Convolutional or recurrent networks, for example, have been transforming the world by opening the possibilities of things we can do with neural networks. Convolutional networks are widely applied in computer vision applications or other areas in which the convolution operation is a natural thing to do, for example, multi-dimensional signal or audio analysis. Recurrent neural networks with memory are widely used to analyze sequences of text, thus enabling us to have networks that understand words, sentences, and paragraphs, and we can use them to translate between languages, and many more things.</li>
<li><strong>Interesting loss functions</strong>: These losses play an interesting role in deep learning because, in the past, we only used the same standard losses over and over again; losses such as the MSE. Today, we can minimize the MSE and, at the same time, minimize the norm of the weights or the output of some neurons, which leads to sparser weights and solutions that, in turn, make the produced model much more efficient when it is deployed into production.</li>
</ul>
<ul>
<li><strong>Novel strategies resembling biology</strong>: Things such as missing or dropping connections between neurons, rather than having them fully connected all the time, is more realistic, or comparable to biological neural network design. Also, dropping or removing neurons altogether is a new strategy that can push some neurons to excel when others are removed, learning richer representations, while at the same time reducing the computations during training and when deployed. The sharing of parameters between different and specialized neural networks also has proven to be interesting and effective today.</li>
<li><strong>Adversarial training</strong>: Making a neural network compete against another network whose sole purpose is to generate fraudulent, noisy, and confusing data points trying to make the network fail has proven to be an excellent strategy for networks to learn better from the data and be robust against noisy environments when deployed into production. </li>
</ul>
<p>There are many other interesting facts and points that make deep learning an exciting area and justify the writing of this book. I hope you are as excited as we all are and begin reading this book knowing that we are going to code some of the most exciting and incredible neural networks of our time. Our ultimate purpose will be to make deep neural networks that can generalize.</p>
<div class="packt_infobox">Generalization is the ability of a neural network to correctly make predictions on data that has never been seen before. This is the ultimate purpose of all machine and deep learning practitioners, and requires a great deal of skill and knowledge of the data.</div>
<h1 id="uuid-17b312e9-d8ad-4525-9920-8c1520a34ad0">Summary </h1>
<p>This introductory chapter presented an overview of ML. It introduced the motivation behind ML and the terminology that is commonly used in the field. It also introduced deep learning and how it fits in the realm of artificial intelligence. At this point, you should feel confident that you know enough about what a neural network is to be curious about how big it can be. You should also feel very intrigued about the area of deep learning and all the new things that are coming out every week. </p>
<p>At this point, you must be a bit anxious to begin your deep learning coding journey; for that reason, the next logical step is to go to <a href="0b6e1f9c-280c-4107-aa1b-862b99f991c8.xhtml"/><a href="0b6e1f9c-280c-4107-aa1b-862b99f991c8.xhtml">Chapter 2</a>, <em>Setup and Introduction to Deep Learning Frameworks.</em> In this chapter, you will get ready for the action by setting up your system and making sure you have access to the resources you will need to be a successful deep learning practitioner. But before you go there, please try to quiz yourself with the following questions. </p>
<h1 id="uuid-b92cfb31-2cfa-4420-b44d-656e32a10557">Questions and answers</h1>
<ol>
<li><strong>Can a perceptron and/or a neural network solve the problem of classifying data that is linearly separable?</strong></li>
</ol>
<p style="padding-left: 60px">Yes, both can.</p>
<ol start="2">
<li><strong>Can a perceptron and/or a neural network solve the problem of classifying data that is non-separable? </strong></li>
</ol>
<p style="padding-left: 60px">Yes, both can. However, the perceptron will go on forever unless we specify a stopping condition such as a maximum number of iterations (updates), or stopping if the number of misclassified points does not decrease after a number of iterations.</p>
<ol start="3">
<li><strong>What are the changes in the ML filed that have enabled us to have deep learning today?</strong></li>
</ol>
<p style="padding-left: 60px">(A) backpropagation algorithms, batch training, ReLUs, and so on;</p>
<p style="padding-left: 60px">(B) computing power, GPUs, cloud, and so on.</p>
<ol start="4">
<li><strong>Why is generalization a good thing?</strong></li>
</ol>
<p style="padding-left: 60px">Because deep neural networks are most useful when they can function as expected when they are given data that they have not seen before, that is, data on which they have not been trained.</p>
<h1 id="uuid-2a81cdea-d4e4-4b8d-b27a-876b5bb088ca">References</h1>
<ul>
<li><span>Hecht-Nielsen, R. (1992). <em>Theory of the backpropagation neural network</em>. In </span><em>Neural networks for perception</em><span> (pp. 65-93). <em>Academic Press</em>.</span></li>
<li>Kane, F. (2017). <em>Hands-On Data Science and Python ML</em><span>. <em>Packt Publishing Ltd</em>.</span></li>
<li>LeCun, Y., Bottou, L., Orr, G., and Muller, K. (1998). <em>Efficient backprop in neural networks: Tricks of the trade</em> (Orr, G. and Müller, K., eds.). <em>Lecture Notes in Computer Science</em><span>, </span><span>1524</span><span>(98), 111.</span></li>
<li>Ojeda, T., Murphy, S. P., Bengfort, B., and Dasgupta, A. (2014). <em>Practical Data Science Cookbook</em><span>. <em>Packt</em> <em>Publishing Ltd</em>.</span></li>
</ul>
<ul>
<li><span>Rosenblatt, F. (1958). <em>The perceptron: a probabilistic model for information storage and organization in</em> the <em>brain</em>. </span><em>Psychological Review</em><span>, </span>65<span>(6), 386.</span></li>
<li><span>Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1985). </span><em>Learning internal representations by error</em> <em>propagation</em><span> (No. ICS-8506). <em>California Univ San Diego La Jolla Inst for Cognitive Science</em>.</span></li>
</ul>


            </article>

            
        </section>
    </body></html>