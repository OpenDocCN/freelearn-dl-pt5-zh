- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring Advanced Use Cases of Jina
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we discuss more advanced applications of the Jina neural search
    framework. Building on the concepts we have learned in the previous chapters,
    we will now look at what else we can achieve with Jina. We will examine multi-level
    granularity matches, querying while indexing, and a cross-modal example. These
    are challenging concepts in neural search and are required to achieve complex
    real-life applications. In particular, we will be covering these topics in this
    chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing multi-level granularity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-modal search with images with text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent querying and indexing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These cover a wide variety of real-life requirements of neural search applications.
    Using these examples, together with the basic examples in [*Chapter 6*](B17488_06.xhtml#_idTextAnchor085),
    *Basic Practical Examples with Jina*, you can expand and improve your Jina applications
    to cover even more advanced usage patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will build and execute the advanced examples provided in
    the GitHub repository. The code is available at [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina/tree/main/src/Chapter07](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina/tree/main/src/Chapter07).
    Make sure to download this and navigate to each of the examples’ respective folders
    when following the instructions for how to reproduce the use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this code, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: macOS, Linux, or Windows with WSL2 installed. Jina does not run on native Windows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.7 or 3.8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally, a clean new virtual environment for each of the examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing multi-level granularity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss how Jina can capture and leverage the hierarchical
    structure of real-life data. In order to follow along with the existing code,
    check the chapter’s code for a folder named `multires-lyrics-search`. This is
    the example we will be referring to in this section.
  prefs: []
  type: TYPE_NORMAL
- en: This example relies on the `Document` type’s capacity to hold chunks (child
    documents) and refer to a specific parent. Using this structure, you can compose
    advanced arbitrary level hierarchies of documents within documents. This mimics
    various real-life data-related problems. Examples could be patches of images,
    sentences of a paragraph, video clips of a longer movie, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'See the following code for how to perform this with Jina’s `Document` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This can then be chained, with multiple levels of granularity, with each chunk
    having its own chunks. This becomes helpful when dealing with hierarchical data
    structures. For more information on the `Document` data type, you can check the
    *Understanding Jina components* section in [*Chapter 4*](B17488_04.xhtml#_idTextAnchor054),
    *Learning Jina’s Basics*.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the dataset will be composed of lyrics from various popular
    songs. In this case, the granularity is based on linguistic concepts. The top
    level will be the entire contents of the body of a song’s lyrics. The level under
    that will be individual sentences extracted from the top-level body. This splitting
    is done using the `Sentencizer` Executor, which splits the long piece of text
    by looking for specific separator text tokens, such as `.` or `,`.
  prefs: []
  type: TYPE_NORMAL
- en: This application helps showcase the concept of **chunking** and its importance
    in search systems. This is important because, in order to get the best results
    in a neural search system, it is best to search with text inputs of the same length.
    Otherwise, the context-to-content ratio will be different between the data you
    are searching with and the data you have trained your model on. Once we have built
    the example, we can visualize how the system is matching input to output via a
    custom frontend.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating through the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s now go through the logic of the app and the functions of each component.
    You can follow along with the code in the repository, at [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina/tree/main/src/Chapter07/multires-lyrics-search](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina/tree/main/src/Chapter07/multires-lyrics-search).
    I will explain the purpose and design of the main files in the folder.
  prefs: []
  type: TYPE_NORMAL
- en: app.py
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the main entry point of the example. The user can use this script to
    either index (add) new data or search with their desired queries. For indexing
    data, this is done from the command line as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Instead of providing the `index` argument, you can also provide `query` or `query_text`
    as arguments. `query` starts the Flow to be used by an external REST API. You
    can then use the custom frontend provided in the repository to connect to this.
    `query_text` allows the user to search directly from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: When indexing, the data is sequentially read from a `CSV` file. We also attach
    relevant tag information, such as author, song name, album name, and language,
    for displaying metadata in the interface. Tags can also be used by the user in
    whatever way they need. They were discussed in the *Accessing nested attributes
    from tags* subsection in the *Understanding Jina components* section in [*Chapter
    4*](B17488_04.xhtml#_idTextAnchor054), *Learning Jina’s Basics*.
  prefs: []
  type: TYPE_NORMAL
- en: index.yml
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This file defines the structure of the Flow used when indexing data (adding
    data). Following are the different configuration options provided in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '`jtype` informs the YAML parser about the class type of this object. In this
    case, it’s the `Flow` class. The YAML parser will then instantiate the class with
    the respective configuration parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`workspace` defines the default location where each Executor might want to
    store its data. Not all Executors require a workspace. This can be overridden
    by each Executor’s `workspace` parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`executors` is a list that defines the processing steps in this Flow. These
    steps are defined by specific classes, all of which are subclasses of the `Executor`
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The indexing Flow is represented by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 7.1 – Index Flow showing document chunking ](img/Figure_7.1_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Index Flow showing document chunking
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the data Flow is split at the gateway. The original document is stored
    as is in `root_indexer`, for future retrieval. On the other path, the document
    gets processed in order to extract its chunks, encode them, and then store them
    in the indexer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following are the different Executors used in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: The first one is `segmenter`, which uses the `Sentencizer` class, from Jina
    Hub. We use the default configuration. This splits the body of the lyrics into
    sentences using a set of punctuation markers that usually delimit sentences, such
    as `.`, `,`, `;`, `!`. This is where the chunks are being created and assigned
    to their parent document, based on where these tokens are found in the text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next is `encoder`. This is the component in the Flow that transforms the
    sentence from text into a numeric format. The component uses the `TransformerTorchEncoder`
    class. It downloads the `distilbert-base-cased` model from the `Huggingface` API
    and uses it to encode the text itself into vectors, which can then be used for
    vector similarity computation. We will also define some configuration options
    here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pooling_strategy: ''cls''`: This is the pooling strategy that is used by the
    encoder.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pretrained_model_name_or_path: distilbert-base-cased`: This is the deep learning
    model that is used. It is pre-trained and downloaded at the start time by the
    Executor.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_length: 96`: This indicates the maximum number of characters to encode
    from the sentence. Sentences longer than this limit get trimmed (the extra characters
    are removed).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device: ''cpu''`: This configuration instructs the Executor to run on the
    CPU. The Executor can also be run on the GPU (with `''gpu''`).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`default_traversal_paths: [''c'']`: This computes the embeddings on the chunk
    level. This represents the hierarchy level of the sentences extracted by `segmenter`.
    We only encode these, as we will perform the search matching at this level only.
    Matching the entire body of a song’s lyrics will not perform well, due to the
    amount of data a model needs to encode.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will now deep-dive into the actual storage engine, `indexer`. For this,
    we use the Executor called `SimpleIndexer`, again from Jina Hub. This uses the
    `DocumentArrayMemmap` class from Jina, to store the data on disk, but at the same
    time, load it into memory for reading and writing as needed, without consuming
    too much memory. We define the following configuration options for it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`default_traversal_paths: [''c'']`: These options configure the component to
    store the chunks of the documents. This has the same purpose as the previous usage
    of `default_traversal_paths`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next is another indexer, `root_indexer`. This is part of the specific requirements
    of this example. Before, at `indexer`, we stored only the chunks of the document.
    But, at search time, we need to also retrieve the parent document itself, in order
    to obtain the tags associated with it (artist name, song name, and much more).
    As such, we need to store these documents somewhere. That is why we need this
    additional Executor. Usually, this will not be required, depending on your use
    case in your application. We define the following configuration options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`default_traversal_paths: [''r'']`: We define that we will index the root level
    of the document (i.e., not chunk-level)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`needs: [gateway]`: This tells the Flow to send requests in parallel, to two
    separate paths: one is sent to the `segmenter` and `encoder` path, and the other
    is sent directly to `root_indexer`, since this one does not depend on any Executor
    in the other path'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You will have noticed an additional argument that is repeated across some of
    the Executors, `volumes`. This conforms to the Docker syntax for mounting a local
    directory in the Docker container, in order to mount the workspace in the running
    Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: query.yml
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This file defines the structure of the Flow used when querying data (searching
    data). This is different from the Flow configuration used at index time because
    the order of operations is different. Looking at the following diagram, we notice
    the main change is that the operations at query time are strictly sequential:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Query Flow showing document chunking ](img/Figure_7.2_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Query Flow showing document chunking
  prefs: []
  type: TYPE_NORMAL
- en: The matches are retrieved from `indexer`, which operates at the chunk level,
    as we previously defined. `ranker` then creates one single match for each parent
    ID present in the chunks. Finally, the original metadata of this parent match
    document is retrieved from `root_indexer` based on its ID. This is required in
    order to get the full context of the chunk (the parent’s full text contents and
    the name of the artist and song).
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like the `index.yml` file, the `query.yml` file also defines a Flow with
    Executors. We will discuss their configuration choices, but we will only cover
    the differences from their equivalent in the `index.yml` file. If a parameter
    is not covered in this section, check the previous section. The following are
    the Executors defined in the query Flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '`segmenter` is the same.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoder` is also the same.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`indexer` is also the same.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first new Executor is `ranker`. This performs a custom ranking and sorting
    of the results from the search. We use `SimpleRanker`, from Jina Hub. The only
    parameter here is `metric: ''cosine''`. This configures the class to use the `cosine`
    metric to base its ranking on. It works by aggregating the scores of a parent
    document’s chunks (children documents) into an overall score for the parent document.
    This is required to ensure that the matches are sorted in a meaningful way for
    the client (the frontend, REST API client, or command-line interface).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The last hop is `root_indexer`. Here, we change `default_traversal_paths` to
    `['m']`. This means that we want to retrieve the metadata of the matches of the
    document, not of the request document itself. This takes the document’s ID and
    performs a lookup for the metadata. As mentioned previously, `indexer` only stores
    the chunks of the document. We need to retrieve the full metadata of the chunks’
    parent Document.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installing and running the example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I will now guide you through installing and running this example application:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure the requirements defined at the beginning of this chapter are fulfilled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clone the Git repository from [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina)
    and open a terminal in the example’s folder, at `src/Chapter07/multires-lyrics-search`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install the requirements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the full dataset. This step is optional; you can skip this step and
    use the sample data provided:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Begin by installing the Kaggle library if you haven’t already done so. You
    will also need to set up your API keys as explained here: [https://github.com/Kaggle/kaggle-api#api-credentials:](https://github.com/Kaggle/kaggle-api#api-credentials%0D)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to index the data. This step processes your data and stores
    it in the workspace of the Flow’s Executors:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Search your data. Here you have two options:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`python app.py -t query_text`: This option starts a command-line application.
    At some point, it will ask for a phrase as input. The phrase will be processed
    and then used as a search query. The results will be displayed in the terminal.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`python app.py -t query`: This starts the application in server mode. It listens
    for incoming requests on the REST API and responds to the client with the best
    matches.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the second mode, you can use the custom frontend we have built to explore
    the results. You can start the frontend by running the following commands in a
    terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now you can open [http://127.0.0.1:8000/](http://127.0.0.1:8000/) in your browser
    and you should see a web interface. In this interface, you can type your text
    in the left-side box. You will then get results on the right side. The matching
    chunks will be highlighted in the body of the lyrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is a screenshot of the interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Lyrics search engine example showing matching songs ](img/Figure_7.3_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Lyrics search engine example showing matching songs
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you add the sentence `I am very happy today`, you should see
    a similar result. Each of these boxes you see on the right-hand side is a song
    in your dataset. Each highlighted sentence is a *match*. A match is a similar
    sentence, determined by how close two vectors are in embedding space.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity can be adjusted using the breakdown slider on the left-hand side.
    As you move the slider to the right, you will see more matches appear. This is
    because we are increasing our radius in the vector space to find similar matches.
  prefs: []
  type: TYPE_NORMAL
- en: The relevance score you see at the bottom of the song box summarizes all the
    matches in a song. Each match has a numeric value between 0 and 1, determining
    how close it is to the original input in the vector space. The average of these
    match values is the relevance score. This means that a song with only good matches
    will be ranked as highly relevant.
  prefs: []
  type: TYPE_NORMAL
- en: The example also allows for more complex, multi-sentence queries. If you input
    two or three sentences when querying, the query Flow will break down the total
    input into individual “chunks.” These chunks in this example are sentences, but
    you can determine what a chunk is for your own data when building Jina.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have covered how you can model the hierarchical structure
    of real-life data in the Jina framework. We use the `Document` class and its ability
    to hold chunks as our representation of this data. We have then built an example
    application that we can use to search through song lyrics, on the sentence level.
    This approach can be generalized to any text (or other modality) data application.
    In the next section, we will see how we can leverage a document’s modality in
    order to search for images with text.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-modal search with images with text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will cover an advanced example showcasing **cross-modal
    search**. Cross-modal search is a subtype of neural search, where the data we
    index and the data we search with belong to different modalities. This is something
    that is unique to neural search, as none of the traditional search technologies
    could easily achieve this. This is possible due to the central neural search technology:
    all deep learning models fundamentally transform all data types to the same shared
    numeric representation of a vector (the embedding extracted from a specific layer
    of the network).'
  prefs: []
  type: TYPE_NORMAL
- en: 'These modalities can be represented by different data types: audio, text, video,
    and images. At the same time, they can also be of the same type, but of different
    distributions. An example of this could be searching with a paper summary and
    wanting to get the paper title. They are both texts, but the underlying data distribution
    is different. The distribution is thus a modality as well in this case.'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of the example in this section is to show how the Jina framework
    helps us to easily perform this sort of search. We highlight how the Flow can
    be used to split the data processing, depending on modalities, into two pipelines
    of Executors. This is done with the `needs` field, which defines the previously
    required step of an Executor. Chaining these `needs`, we can obtain separate paths.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now go through the logic of the app and what each file’s purpose is. The
    code can be found at [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina)
    in the folder `src/Chapter07/cross-modal-search`.
  prefs: []
  type: TYPE_NORMAL
- en: app.py
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the main entry point of the example. The user can call it to either
    **index** or **search**. It then creates the Flows and either indexes data or
    searches with the query from the user.
  prefs: []
  type: TYPE_NORMAL
- en: flow-index.yml
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This file defines the structure of the Flow used when indexing data (adding
    data). I will explain the different steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Flow itself has the following arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`prefetch` defines the number of documents to prefetch from the client’s request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`workspace` defines the default location where data will be stored. This can
    be overridden by each Executor’s `workspace` parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, the `executors` list defines the Executors used in this Flow. Each item
    in this list is an Executor and its configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is a diagram representing the indexing Flow. Notice how the path
    bifurcates from the gateway, depending on whether the data is image or text:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Index Flow showing cross-modal features ](img/Figure_7.4_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Index Flow showing cross-modal features
  prefs: []
  type: TYPE_NORMAL
- en: 'We will describe the purpose of each of the Executors, grouped by paths. The
    first path is the path for image data:'
  prefs: []
  type: TYPE_NORMAL
- en: The first Executor is `image_loader`. This uses the `ImageReader` class, defined
    locally in the `flows/executors.py` file. This will load the image files from
    a specific folder and pass them down further into the Flow for processing. When
    a document is created, we can assign it a `mime` type. This can then be used in
    specific Executors to perform custom logic. Here, we are using it to restrict
    which documents go to which Executors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The parameters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`py_modules`: This tells the Python process where to find extra classes that
    can then be used in the `uses` parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`needs`: This creates a direct connection from the gateway (which is always
    the first and last hop of the Flow) to this Executor. It makes this component
    wait for requests from the gateway. This is required here because we want two
    separate paths for text and images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next one is `image_encoder`. This is where the brunt of the work is done.
    Encoders are the Executors that transform data into a numeric representation.
    It uses `CLIPImageEncoder`, version 0.1\. The parameters are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`needs`: This defines the path of the data on the image path'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image_indexer` is the storage for the embeddings and metadata of the documents
    that contain images. It uses `SimpleIndexer`. The parameters are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`index_file_name`: This defines the folder where the data is stored'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`needs`: This makes the Executor part of the image processing path, by explicitly
    making it depend on `image_encoder`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next elements will be part of the text path. `text_filter` is similar to
    `image_filter`. It reads data, but only text-based documents. The parameters used
    here are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`py_modules`: This parameter again defines the files where the `TextFilterExecutor`
    is defined.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`needs: gateway` defines the path of dependencies between the Executors. In
    this case, this Executor is at the beginning of the path and thus depends on `gateway`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, similar to the image path, we have the encoder `text_encoder`. This processes
    the text and encodes it using `CLIPTextEncoder`. The parameters used here are
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`needs: text_filter`: This parameter specifies that this Executor is part of
    the text pat.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_indexer` stores the embeddings of the Executor.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we join the two paths. `join_all` joins the results from the two paths
    into one. The `needs` parameter here is given a list of Executor names.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will have noticed an argument that is repeated across some of the Executors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`volumes`: This is the Docker syntax for mounting a local directory into the
    Docker container.'
  prefs: []
  type: TYPE_NORMAL
- en: query.yml
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will cover the query (search) Flow. This designates the
    process for searching the data you have indexed (stored) with the aforementioned
    index Flow. The configuration of the Executors is the same, at an individual level.
  prefs: []
  type: TYPE_NORMAL
- en: 'As can be seen from the following diagram, the Flow path is also similar. It
    also bifurcates at the start, depending on the data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Query Flow showing cross-modal features ](img/Figure_7.5_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Query Flow showing cross-modal features
  prefs: []
  type: TYPE_NORMAL
- en: The difference is that now we are searching with documents across the two modalities.
    Thus, `text_loader` sends the documents with text to be encoded by `text_encoder`,
    but the actual similarity matching is done with image documents that have been
    stored in `image_indexer`, from the index Flow. This is the central aspect that
    allows us to achieve cross-modality searching in this example.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and running the example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run the example, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure the requirements defined at the beginning of this chapter are fulfilled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clone the code from the repository at [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina)
    and open a terminal in the `src/Chapter07/cross-modal-search` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note that this example only includes two images as a sample dataset. In order
    to download the entire dataset and explore the results, you will need to download
    it from Kaggle. You can do so by registering for a free Kaggle account. Then,
    set up your API token. Finally, to download the `flickr 8k` dataset, run the following
    command in a terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To index the full dataset, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Starting the index Flow and indexing the sample data is done from the command
    line, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This creates the index Flow, processes the data in the specific folder, and
    stores it in a local folder, `workspace`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, in order to start the searching Flow and allow the user to perform a
    search query, you can run this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let’s begin by running a small test query. This test query actually contains
    both an image and a text document. The text is the sentence `a black dog and a
    spotted dog are fighting.` The image is `toy-data/images/1000268201_693b08cb0e.jpg`.
    The system then searches with both the image and the text, in a cross-modal manner.
    This means the image is used to search across the text data and the text is used
    to search across the image data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The text results from searching with the image will be printed in your terminal
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Cross-modal search terminal output ](img/Figure_7.6_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Cross-modal search terminal output
  prefs: []
  type: TYPE_NORMAL
- en: 'The image results will be shown in a `matplotlib` figure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – Cross-modal search plot output ](img/Figure_7.7_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – Cross-modal search plot output
  prefs: []
  type: TYPE_NORMAL
- en: In this case, a lower score is better, as it measures the distance between the
    vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can pass your own image queries with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `path_to_your_image` variable can be provided as either an absolute or relative
    path, from the terminal’s current working directory path.
  prefs: []
  type: TYPE_NORMAL
- en: 'Or, for text, you can do it like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we have covered how the Jina framework allows us to easily
    build a cross-modal search application. This is possible due to Jina’s universal
    and generalizable data types, mainly the document, and flexible pipeline construction
    process. We see that the `needs` parameter allows us to split the processing pipeline
    into two paths, depending on the *mime* type. In the following section, we will
    see how we can serve data while modifying it.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent querying and indexing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will present the methodology for how to continuously serve
    your client’s requests while still being able to update, delete, or add new data
    to your database. This is a common requirement in the industry, but it is not
    trivial to achieve. The challenges here are around maintaining the vector index
    actualized with the most recent data, while also being able to update that data
    in an atomic manner, but also doing all these operations in a scalable, containerized
    environment. With the Jina framework, all of these challenges can be easily met
    and overcome.
  prefs: []
  type: TYPE_NORMAL
- en: By default, in a Jina Flow, you cannot both index data and search at the same
    time. This is due to the nature of the network protocol. In essence, each Executor
    is a single-threaded application. You can use sharding to extend the number of
    copies of an Executor that form an Executor group. However, this is only safe
    for purely parallel operations, such as encoding data. These sorts of operations
    do not affect the state of the Executor. On the other hand, **CRUD** (**Create/Read/Update/Delete**)
    are operations that affect the state. Generally, these are harder to parallelize
    in scalable systems. Thus, if you send a lot of data to index (to add) to your
    application, this will block all searching requests from your clients. This is,
    of course, highly limiting. In this solution, I will show how this can be tackled
    within Jina.
  prefs: []
  type: TYPE_NORMAL
- en: The key component of the solution is the **HNSWPostgresIndexer** Executor. This
    is an Executor for the Jina framework. It combines an in-memory HNSW vector database
    with a connection to a PostgreSQL database. The metadata of your documents is
    stored in the SQL database, while the embeddings are stored in RAM. Unlike the
    applications in the previous examples, it does not require two distinct Flows.
    All the CRUD operations are performed within one Flow life cycle. This is possible
    due to the Executor’s capacity to synchronize the states between the SQL database
    and its in-memory vector database. This can be configured to be done automatically
    or can be triggered manually at the desired time.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now delve into what each component of this example is doing. The code
    can be found at [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina)
    in the folder `/src/Chapter07/wikipedia-sentences-query-while-indexing`.
  prefs: []
  type: TYPE_NORMAL
- en: app.py
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the main entry point of the example. The user can call it to start
    the index and search Flows or to search documents. In order to start the Flows,
    you run `app.py` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This will initialize the Flow of the Jina application, with its Executors.
    It will then add new data to the **HNSWPostgreSQL** Executor, in batches of five
    documents at a time. This data is at first only inserted into the SQL database.
    This is because the SQL database is considered the primary source of data. The
    **HNSW** vector index will be gradually updated based on the data in the SQL database.
    Once there is data present, the Executor will automatically synchronize it into
    the HNSW vector index. This process continues until the data is fully inserted.
    Once one round has been completed, there will be data available for searching
    for the user. The user can then query the data with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Then the user will be prompted for text input for a query. This text will then
    be encoded and compared with the existing dataset to get the best matches. These
    will be printed back to the terminal.
  prefs: []
  type: TYPE_NORMAL
- en: flow.yml
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This file defines the structure of the Flow used both when indexing data (adding
    data) and searching. I will explain the different options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is the diagram of the index Flow. Notice that it is quite simple:
    we are just encoding and storing the encoded data. The complexity of this example
    application arises from the internal behavior of the **HNSWPostgreSQL** Executor.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8 – Query Flow showing concurrency ](img/Figure_7.8_B17488.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – Query Flow showing concurrency
  prefs: []
  type: TYPE_NORMAL
- en: 'The Flow itself has the following arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`protocol`: Defines that the Flow should open its HTTP protocol to the exterior'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`port_expose`: Defines the port for listening on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, the Executors define the steps in the Flow:'
  prefs: []
  type: TYPE_NORMAL
- en: The first one is `storage_encoder`. This uses `FlairTextEncoder` from Jina Hub.
    This encodes the text into a vector, for the linear algebra operations required
    in machine learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second one is `indexer`. This uses `HNSWPostgresIndexer`, also from Jina
    Hub. The parameters used here are the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`install_requirements`: Setting this to `True` will install the libraries required
    for this Executor'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sync_interval`: How many seconds to wait between automatically synchronizing
    the data from the SQL database into the vector database'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dim`: The dimensionality of the embeddings'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You will have noticed an additional argument that is repeated across some of
    the Executors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`timeout_ready`: This defines the number of seconds to wait for an Executor
    to become available before it’s canceled. We set it to `–1` so we wait as long
    as it’s required. Depending on your scenario, this should be adjusted. For example,
    if you want to safely terminate a long-running downloading request, you can set
    it to whatever amount of seconds you want to wait for the Executor to start.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and running the example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before running this example, make sure you understand the basic text search
    from the previous chapter, the chatbot example. Also, you will need to install
    Docker on your computer:'
  prefs: []
  type: TYPE_NORMAL
- en: Clone the Git repository from [https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina/tree/main/src/Chapter07/wikipedia-sentences-query-while-indexing](https://github.com/PacktPublishing/Neural-Search-From-Prototype-to-Production-with-Jina/tree/main/src/Chapter07/wikipedia-sentences-query-while-indexing)
    and open a terminal in the example’s folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Python 3.7 environment. Although it is not required, it is strongly
    recommended.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install the requirements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The repository includes a small subset of the Wikipedia dataset, for quick testing.
    You can just use that. If you want to use the entire dataset, run `bash` `get_data.sh`
    and then modify the `DATA_FILE` constant (in `app.py`) to point to that file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then start the Flow with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This creates the Flow and establishes the data synchronizing loop, as described
    in `app.py` previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to query the data, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will then be prompted for some text input. Enter whatever query you wish.
    You will then get back the best matches for your query.
  prefs: []
  type: TYPE_NORMAL
- en: Since the Flows expose an HTTP protocol, you can query the REST API with the
    Jina Client, cURL, Postman, or the custom Swagger UI built within Jina. The Swagger
    UI can be reached at the URL informed by the Flow, in the terminal. Usually, it’s
    `http://localhost:45678/docs`, but it depends on your configured system.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have learned how we can use the `HNSWPostgreSQLIndexer`
    Executor to concurrently index and search data in our live system. In the previous
    examples, the Flow needed to be redefined and restarted in order to switch between
    the two modes. Since this Executor combines both the metadata store (via a connection
    to a SQL database) and the embeddings index (via an in-memory HNSW index), it
    is possible to perform all CRUD operations within one Flow life cycle. Using these
    techniques, we can have a real client-facing application that is not blocked by
    the need to update the underlying database in the index.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have analyzed and practiced how you can use Jina’s advanced
    features, such as chunking, modality, and the advanced `HNSWPostgreSQL` Executor,
    in order to tackle the most difficult goals of neural search. We implemented solutions
    for arbitrary hierarchical depth data representation, cross-modality searching,
    and non-blocking data updates. Chunking allowed us to reflect on some data’s properties
    of having multiple levels of semantic meaning, such as sentences in a paragraph
    or video clips in longer films. Cross-modal searching opens up one of the main
    advantages of neural search – its data universality. This means that you can search
    with any data for any type of data, as long as you use the correct model for the
    data type. Finally, the `HNSWPostgreSQL` Executor allows us to build a live system
    where users can both search and index at the same time, with the data being kept
    in sync.
  prefs: []
  type: TYPE_NORMAL
