<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Multilayer Perceptron for Signal Detection</h1>
                </header>
            
            <article>
                
<p>This chapter will show you how to build a multilayer perceptron neural network for signal detection. We will first discuss the architecture of multilayer perceptron neural networks. Then we will cover how to prepare the data, how to decide on hidden layers and neurons, and how to train and evaluate the model.</p>
<p>The section on preparing the data will be important going forward as these deep learning models require data to be in particular formats in order to pass the data to the models. The hidden layer is the part of the neural network that separates it from other machine learning algorithms, and in this chapter, we will show you how to search for the optimal number of nodes in a hidden layer. In addition, over the course of this chapter, you will become much more familiar with the MXNet syntax, including the model training and evaluation steps.</p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>Understanding multilayer perceptrons</li>
<li>Preparing and processing the data</li>
<li class="mce-root">Deciding on the hidden layers and neurons</li>
<li class="mce-root">Training and evaluating the model</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p><span>You can find the code files of this chapter at the corresponding </span>GitHub link at <a href="https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R">https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding multilayer perceptrons</h1>
                </header>
            
            <article>
                
<p>A multilayer perceptron is an instance of a feedforward neural network that only uses fully connected layers consisting of perceptrons. A perceptron is a node that takes input values and multiplies them by weights, and then passes this aggregate value to an activation function that returns a value that indicates how much this set of inputs and weights matches the pattern we are trying to find.</p>
<p>The multilayer perceptron can be thought of as the most basic neural network implementation. As we mentioned, all layers are fully connected, which means that there are no convolution or pooling layers. It is also a feedforward model, which means that information from backpropagation is not looped back at every step, as it is in a recurrent neural network.</p>
<p>Simplicity can be an asset in terms of the ease of the <span>interpretability of the </span><span>network and its initial setup;</span><span> however, the main drawback is that with so many fully connected layers, the count of weights will grow to such a level that the model will take a long time to train for large datasets. It also has a vanishing gradient problem, which means that the model will reach a point where the value that is passed back to correct the model is so small that it no longer significantly impacts the results.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing and preprocessing data</h1>
                </header>
            
            <article>
                
<p>For this example, we will use the Adult dataset. We will walk through the steps to get this dataset in the proper form so that we can train a multilayer perceptron on it:</p>
<ol>
<li>We will first load the libraries that we need. We will use the <kbd>mxnet</kbd> package to train the MLP model, the <kbd>tidyverse</kbd> family of packages for our data cleaning and manipulation, and <kbd>caret</kbd> to evaluate our model. We load the libraries using the following code:</li>
</ol>
<pre style="padding-left: 60px">library(mxnet)<br/>library(tidyverse)<br/>library(caret)</pre>
<p style="padding-left: 60px">This code will not produce any output to the console; however, you will see a checkmark next to these libraries in the <span class="packt_screen">Packages</span> pane, indicating that the packages are now ready to use. Your <span class="packt_screen">Packages</span> pane should look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1010 image-border" src="assets/989aa574-bd75-4019-a461-f2c865aeba62.png" style="width:49.92em;height:25.75em;"/></p>
<ol start="2">
<li>Next, we will load our training and test data. In addition, we will add a column called <kbd>dataset</kbd> that we will populate with the <kbd>train</kbd> and <kbd>test</kbd> values to label our data. We will do this so that we can combine our data and perform some manipulation on the full data to save ourselves from repeating steps, and then be able to split the data again afterward. We then load the data and add the label with the following code:</li>
</ol>
<pre style="padding-left: 60px">train &lt;- read.csv("adult_processed_train.csv")<br/>train &lt;- train %&gt;% mutate(dataset = "train")<br/>test &lt;- read.csv("adult_processed_test.csv")<br/>test &lt;- test %&gt;% mutate(dataset = "test")</pre>
<p style="padding-left: 60px">The preceding code will place two data objects in your <span class="packt_screen">Environment</span> pane. This will be the train and test data that we will use for this modeling exercise. Your <span class="packt_screen">Environment</span> pane will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1011 image-border" src="assets/5528f5aa-b276-40ec-b87f-0c5476e831c1.png" style="width:38.83em;height:9.83em;"/></p>
<ol start="3">
<li>In this step, we will combine our data with a row bind and then remove any rows with NA values. Removing rows with missing values is not always the most appropriate course of action; at times, other tactics should be used to handle missing values. These tactics include <strong>imputation</strong> and <strong>replacement</strong>. In this case, we would just like to remove these rows for ease of use, since we are just using this data for example purposes. We combine the data and remove rows with missing values using the following code:</li>
</ol>
<pre style="padding-left: 60px">all &lt;- rbind(train,test)<br/><br/>all &lt;- all[complete.cases(all),]</pre>
<p style="padding-left: 60px">The preceding code will add one more data object to our <span class="packt_screen">Environment</span> pane. Your <span class="packt_screen">Environment</span> pane will now look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1012 image-border" src="assets/427aa6d5-af4b-4b3e-a1be-f66395687c9e.png" style="width:36.92em;height:9.17em;"/></p>
<p style="padding-left: 60px">You can see that the data object <kbd>all</kbd> contains rows from <kbd>test</kbd> and <kbd>train</kbd>. We can now modify both <kbd>train</kbd> and <kbd>test</kbd> at the same time.</p>
<ol start="4">
<li>In the next step, we take any factor value and trim the whitespace. We do this because there are multiple values that should mean the same thing but are showing up as distinct values because of whitespace, such as <kbd>Male</kbd> and <kbd> Male</kbd>. We will demonstrate that whitespace is causing an issue when accurately defining categories and then correct the issue with the following code:</li>
</ol>
<pre style="padding-left: 60px">unique(all$sex)<br/><br/>all &lt;- all %&gt;%<br/>  mutate_if(~is.factor(.),~trimws(.))</pre>
<p style="padding-left: 60px">When we run the first line of the preceding code, we will print the distinct factor levels to the console. Your console will look similar to the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-620 image-border" src="assets/5e7c5839-7c1a-4d51-bcf8-a17cbb8456cb.png" style="width:16.58em;height:4.08em;"/></p>
<p style="padding-left: 60px">However, after running the second line and removing the whitespace, we will see that this has been corrected, and the output will look different. If you run the <kbd>unique()</kbd> function again, the output in your console will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-621 image-border" src="assets/0ea849c2-c230-40ee-a6f6-edd8bec4b1ce.png" style="width:12.58em;height:3.92em;"/></p>
<p style="padding-left: 60px">Correcting this issue will help the algorithm to use the proper number of categories when creating the model.</p>
<ol start="5">
<li>Next, we filter just our training data. We will extract the target variable to a vector and convert the values to numeric. Afterward, we can remove the target variable from the dataset, as well as the dataset variable. We extract the train data, create the target variable vector, and remove the unneeded columns using the following code:</li>
</ol>
<pre style="padding-left: 60px">train &lt;- all %&gt;% filter(dataset == "train")<br/>train_target &lt;- as.numeric(factor(train$target))<br/>train &lt;- train %&gt;% select(-target, -dataset)</pre>
<p style="padding-left: 60px">After we run this code, we will see that the <kbd>train</kbd> data has been updated in our <kbd>Environment</kbd> pane and the <kbd>train_target</kbd> vector has been added. Your <kbd>Environment</kbd> pane will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1013 image-border" src="assets/cceeb682-871e-4583-b29e-2363fc2e411f.png" style="width:40.75em;height:14.08em;"/></p>
<p style="padding-left: 60px">We can see that the train data has two fewer variables now that we have removed the target and the dataset. The <kbd>target</kbd> column is now extracted to its own vector and we have the dependent variable and independent variables in separate data objects so that they are in the proper format and ready to be passed to the modeling function.</p>
<ol start="6">
<li>The next step is to separate the data column-wise so that one subset contains only columns containing numeric values while the other contains only columns containing string values. As stated earlier, all values will need to be numeric, so we will be using one-hot encoding on the string values, which is also known as creating dummy variables. This will create a column for every possible field name–value pair and populate this column with either a <kbd>1</kbd> or <kbd>0</kbd>, representing whether the value is present for the given field name per row. We split our data column-wise in the way described here using the following code:</li>
</ol>
<pre style="padding-left: 60px">train_chars &lt;- train %&gt;%<br/>  select_if(is.character)<br/><br/>train_ints &lt;- train %&gt;%<br/> select_if(is.integer)</pre>
<p style="padding-left: 60px">After we run the preceding code, we will see two new data objects—one with the 6 numeric columns among the 14 total and the other with the remaining 8 columns, which contain string values. Your <span class="packt_screen">Environment</span> pane will now look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1014 image-border" src="assets/b77bc154-3b9b-4e8e-80ea-bbd5dfa878f2.png" style="width:46.83em;height:19.08em;"/></p>
<p style="padding-left: 60px">Now that our data is in this format, we can one-hot encode the columns that contain only strings.</p>
<ol start="7">
<li>In this step, we will actually create our dummy variables. We use the <kbd>dummyVars()</kbd> function from the caret package. This takes two steps. In the first, we define the columns that we would like converted to dummy variables. Since we would like all columns to be converted, we just include a dot after the tilde. Next, we use the <kbd>predict()</kbd> function to actually create the new variables using the formula. We create our new dummy variable columns using the following code:</li>
</ol>
<pre style="padding-left: 60px">ohe &lt;- caret::dummyVars(" ~ .", data = train_chars)<br/>train_ohe &lt;- data.frame(predict(ohe, newdata = train_chars))</pre>
<p style="padding-left: 60px">After running the preceding code, we will have two new data objects in our <span class="packt_screen">Environment</span> pane. One is the <kbd>ohe</kbd> object, which is a list with all the details that we need to convert our string columns to dummy variables, and the other is the <kbd>train_ohe</kbd> object, which contains the dummy variables. Your <span class="packt_screen">Environment</span> pane will now look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1015 image-border" src="assets/24d01370-cffd-45fa-8dd4-8d9aefdf3c0d.png" style="width:42.92em;height:20.67em;"/></p>
<p style="padding-left: 60px">We can see that creating dummy variables results in a dataset with many more columns than our original data. As stated, we take every column name and value pair and create a new column, which results in the growth of columns.</p>
<ol start="8">
<li>After the columns containing string values have been converted to columns with numeric values, then we can column-bind both subsets back together again. We combine the data that was already numeric and the data that was converted to a numeric format using the following line of code:</li>
</ol>
<pre style="padding-left: 60px">train &lt;- cbind(train_ints,train_ohe)</pre>
<p style="padding-left: 60px">We can see that the <kbd>train</kbd> object in our <span class="packt_screen">Environment</span> pane has changed. Your <span class="packt_screen">Environment</span> pane will now look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1016 image-border" src="assets/02f29f52-6162-4468-bb11-5b3183ef0f51.png" style="width:43.08em;height:20.42em;"/></p>
<p style="padding-left: 60px">The train data now contains all numeric columns and is in the proper format to be used with a neural network.</p>
<ol start="9">
<li>Lastly, for the columns that originally held numeric values, we will rescale the values so that all values are in a range between <kbd>0</kbd> and <kbd>1</kbd>, and as such are on the same scale as our one-hot encoded columns. We get all of our data on the same scale using the following code:</li>
</ol>
<pre style="padding-left: 60px">train &lt;- train %&gt;% mutate_all(funs(scales::rescale(.) %&gt;% as.vector))</pre>
<p style="padding-left: 60px">Before we run the preceding code, let's first see what the train data columns look like in our <span class="packt_screen">Environment</span> pane. Yours will look like the following screenshot before running the code:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1017 image-border" src="assets/cd3cc60c-0bfc-4778-aaa0-a9c37cbd6a09.png" style="width:51.58em;height:20.17em;"/></p>
<p style="padding-left: 60px">Your <span class="packt_screen">Environment</span> pane will look like the following screenshot after running the code:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1018 image-border" src="assets/c752c279-20c6-473c-8f59-667ce1ce0966.png" style="width:41.58em;height:21.33em;"/></p>
<p style="padding-left: 60px">We can see that all the values that were on different scales in the first image are now all rescaled so that all values are between <kbd>0</kbd> and <kbd>1</kbd>. Having all values on the same scale will help to make training the model more efficient.</p>
<ol start="10">
<li>We can now repeat the same steps for the test dataset. We prepare our test data for modeling using the same steps as the training data by running the following lines of code:</li>
</ol>
<pre style="padding-left: 60px">test &lt;- all %&gt;% filter(dataset == "test")<br/>test_target &lt;- as.numeric(factor(test$target))<br/>test &lt;- test %&gt;% select(-target, -dataset)<br/><br/>test_chars &lt;- test %&gt;%<br/>  select_if(is.character)<br/><br/>test_ints &lt;- test %&gt;%<br/>  select_if(is.integer)<br/><br/>ohe &lt;- caret::dummyVars(" ~ .", data = test_chars)<br/>test_ohe &lt;- data.frame(predict(ohe, newdata = test_chars))<br/><br/>test &lt;- cbind(test_ints,test_ohe)<br/><br/>test &lt;- test %&gt;% mutate_all(funs(scales::rescale(.) %&gt;% as.vector))</pre>
<p style="padding-left: 60px">As a result of running this code, you will see test data objects that have been modified in the same way as the training data objects. Your <span class="packt_screen">Environment</span> pane will now look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1019 image-border" src="assets/db7590e8-e1ac-4168-b993-6534fce3a247.png" style="width:33.33em;height:20.92em;"/></p>
<p style="padding-left: 60px">All of our data is now in the proper format and ready to be used for training our neural network model.</p>
<ol start="11">
<li>There is one last cleanup step. If we look at our column count, we can see that the <kbd>train</kbd> dataframe has one more column than the test dataframe. We can use the <kbd>setdiff</kbd> function to see which column exists in the <kbd>train</kbd> and not in the <kbd>test</kbd> set. Once that has been identified, we can just remove that column from the <kbd>train</kbd> set. We need our data to have the same number of columns for modeling. We find the column that doesn't exist in both datasets and remove it using the following two lines of code:</li>
</ol>
<pre style="padding-left: 60px">setdiff(names(train), names(test))<br/><br/>train &lt;- train %&gt;% select(-native.countryHoland.Netherlands)</pre>
<p style="padding-left: 60px">When we run the first line of code, we will print the value of the output to our console. Your console output will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-631 image-border" src="assets/9b94150a-edb4-4a3c-bc8e-a2de1c69d51d.png" style="width:19.33em;height:3.33em;"/></p>
<p style="padding-left: 60px">We now know that the <kbd>train</kbd> has the column <kbd>native.countryHoland.Netherlands</kbd> while <kbd>test</kbd> does not. We use the second line of code to remove this column from the <kbd>train</kbd>. After we run the second line of code, we will notice a difference in our <span class="packt_screen">Environment</span> pane. Your <span class="packt_screen">Environment</span> pane will now look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1020 image-border" src="assets/f8d30171-6ba2-47ab-9ec8-0872b958a569.png" style="width:36.83em;height:22.58em;"/></p>
<p style="padding-left: 60px">When we look at <kbd>train</kbd> and <kbd>test</kbd> now, we can see that both data objects have the same number of columns, which is required for using the two data objects to train and test our model.</p>
<ol start="12">
<li>The last data preparation step is to take our target variable vectors and <span>subtract </span><kbd>1</kbd> from all values. When we first cast these to numeric format, we took their factor level values so that we got vectors coded with values of either <kbd>1</kbd> or <kbd>2</kbd>; however, we want these to be coded as either <kbd>0</kbd> or <kbd>1</kbd> so that they are at the same scale as our independent variables. We get our target variables on the same scale as our independent variables by running the following code:</li>
</ol>
<pre style="padding-left: 60px">train_target &lt;- train_target-1<br/>test_target &lt;- test_target-1</pre>
<p style="padding-left: 60px">After running the following code, you will notice one last change to your <span class="packt_screen">Environment</span> pane. Your <span class="packt_screen">Environment</span> pane will now look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1021 image-border" src="assets/59e1b6ed-2c81-4007-b77f-a5df543d743c.png" style="width:40.17em;height:23.42em;"/></p>
<p style="padding-left: 60px">All of our data is now numeric and on the same scale, so the data is completely prepared for modeling at this point.</p>
<p>We started with data in the state that it was originally stored in and took some steps to get the data into the proper format so that we could use it to train a neural network. Neural networks, especially deep-learning implementations, offer the convenience of not needing to perform feature engineering like you might have to do with other machine-learning techniques. That being the case, some data preparation is still often required as neural networks require all data to be stored as numeric values, and your model will perform better if all numeric value data is on the same scale. The data manipulation and transformation steps that we just performed are representative of the type of data preparation work that will need to be completed for other data that you will use for training neural networks. With our data in the proper format, we can now devise a system to search for the optimal number of nodes for the hidden layer in our model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deciding on the hidden layers and neurons</h1>
                </header>
            
            <article>
                
<p>Multilayer perceptrons provide only a few choices during the model design process: the activation function used in the hidden layers, the number of hidden layers, and the number of nodes or artificial neurons in each layer. The topic of selecting the optimal number of layers and nodes will be covered in this section. We can begin with a single layer and use a set of heuristics to guide our starting point for selecting the number of nodes to include in this hidden layer.</p>
<p>When beginning this process, a good starting point is 66% of the length of the input or the number of independent variable columns. This value, in general, will fall within a range between the size of the output to two times the size of the input; however, 66% of the length of the input is a good starting point within this range.</p>
<p>This does not mean that this starting point will always be the optimal number of nodes to use. To discover the optimal number, we can write a function that will train our model using a different number of nodes right around our starting point in order to see trends and attempt to find the optimal value. In this case, we will train with a larger learning rate using only a few rounds for fast run-time. If you are working with a large dataset, then it may be necessary to use a subset of the data when using this strategy so that long run times per iteration do not create an issue.</p>
<p>We will now walk through the creation of a function to test the performance of the model given a number of different nodes in the hidden layer:</p>
<ol>
<li>To start, let's look at the number of independent variable columns and then get 66% of this value to arrive at our starting point. We decide on the starting point for the number of nodes to include in our hidden layer by running the following code:</li>
</ol>
<pre style="padding-left: 60px">length(train)*.66</pre>
<p style="padding-left: 60px">The preceding code will print the following output to your console:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-635 image-border" src="assets/7531e213-13f8-491c-9efc-96204c5e25a7.png" style="width:10.92em;height:3.67em;"/></p>
<p style="padding-left: 60px">The precise value is <kbd>67.98</kbd>, but we will round this up to <kbd>70</kbd> as our starting value. Keep in mind that you can use any value you like, as this is just a heuristic—working with round numbers is convenient, and you can always drill down to the exact optimal number of neurons at a later time—however, the performance difference when making small changes will be minimal and may not be present when generalizing with this model later.</p>
<ol start="2">
<li>Next, let's choose two values that are larger than this starting point as well as two that are smaller and store these in a vector. These will be the options that we will pass through as arguments to our function. In this case, we started with <kbd>70</kbd>, so we will also include <kbd>50</kbd>, <kbd>60</kbd>, <kbd>80</kbd>, and <kbd>90</kbd>. We create the vector of possible nodes for our hidden layer by running the following code:</li>
</ol>
<pre style="padding-left: 60px">possible_node_values &lt;- c(50,60,70,80,90)</pre>
<p style="padding-left: 60px">After running the preceding code, we will see that this data object is now in our <span class="packt_screen">Environment</span> pane. Your <span class="packt_screen">Environment</span> pane will now look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1022 image-border" src="assets/3babbfa2-371d-43bf-9fa7-e06d5470bcef.png" style="width:37.42em;height:24.42em;"/></p>
<p style="padding-left: 60px">We will use the values from this vector later to loop through these choices and see which performs best.</p>
<ol start="3">
<li>We will set our seed at this point to ensure reproducibility. This is always important, and should always be done when working with any type of model that introduces quasirandom numbers. In our case, it is important for this demonstration to show that the function we create produces the same result as running the code alone. We set the seed specifically for use with our MXNet model by running the following line of code:</li>
</ol>
<pre style="padding-left: 60px">mx.set.seed(0)</pre>
<p style="padding-left: 60px">After running this code, no output is printed to the console and there are no noticeable changes in RStudio; however, using this method, we ensure consistent model results.</p>
<ol start="4">
<li>Before writing our function, we will first define and run our model and look at the syntax and options for training a multilayer perceptron using the <kbd>mxnet</kbd> package. We define and run our multilayer perceptron model using the following code:</li>
</ol>
<pre style="padding-left: 60px">model &lt;- mx.mlp(data.matrix(train), train_target, hidden_node=70,out_node=2, out_activation="softmax",num.round=10, array.batch.size=32, learning.rate=0.1, momentum=0.8, eval.metric=mx.metric.accuracy)</pre>
<p style="padding-left: 60px">After running the preceding code, we will see model details printed to our console for every run. The output to your console will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-637 image-border" src="assets/fc49ba07-9139-4554-9c98-dbb9f22d7795.png" style="width:17.00em;height:10.08em;"/></p>
<p style="padding-left: 60px">The output to the console lists all the accuracy values using a holdout set from the <kbd>train</kbd> data. We will cover all the options for modeling with MXNet after this code to cover each argument in more detail. Simply put, we are using values to make the model run quickly at this point, while we are preparing to test for the optimal number of nodes to include.</p>
<ol start="5">
<li>In addition to training this model, we would also like a data object to hold performance results so that we can compare the performance after trying the different hidden layer sizes. Here, we can make a prediction using our model and then select the class with the highest likelihood. Lastly, we calculate the accuracy by summing up the cases where the prediction is correct over the length of the test target variables. We can also see how we can now store these two values in a table. We do this here to demonstrate the entire inside of our function, which will hold all the different node size choices along with the accuracy of using that given number of nodes. We make predictions and calculate the accuracy using the following code:</li>
</ol>
<pre style="padding-left: 60px"> preds = predict(model, data.matrix(test))<br/> <br/> pred.label = max.col(t(preds))-1<br/> <br/> acc = sum(pred.label == test_target)/length(test_target)<br/><br/> vals &lt;- tibble(<br/> nodes = 70,<br/> accuracy = acc<br/> )<br/><br/>vals</pre>
<p style="padding-left: 60px">After running the preceding code, we will have four new data objects in our <span class="packt_screen">Environment</span> pane. Your <span class="packt_screen">Environment</span> pane will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1023 image-border" src="assets/ee70f05b-0c90-4498-85cf-f6b13c457734.png" style="width:52.33em;height:33.00em;"/></p>
<p style="padding-left: 60px">The <kbd>preds</kbd> object holds the results from making predictions with our model. MXNet stores these prediction results in a matrix with the probabilities for each class. If we transpose this matrix or rotate it 90 degrees and select the maximum value for every column, then we will get the highest row number that corresponds with the most likely class; however, this will be using values <kbd>1</kbd> and <kbd>2</kbd> for the rows, so we subtract 1 from all values to get our prediction values on the same scale as our true test classes, which are <kbd>0</kbd> or <kbd>1</kbd>. For the accuracy value, we sum all the cases where the predicted values and true values are the same over the total number of true cases. Finally, we can put the node count and accuracy score in a table. This will be useful for comparing results when we try different node counts.</p>
<ol start="6">
<li>Now that we have everything coded for an individual case, we can create our function by replacing the value assigned to the argument that we would like to test with a variable. We then move that variable to be the argument for our new function. We can see that everything in the code is the exact same as it was previously, except that the <kbd>70</kbd> that we had as a value for the <kbd>hidden_node</kbd> argument, and that we had later as a value to add under the <kbd>nodes</kbd> column in the new table we will create, are now replaced with <kbd>x</kbd>. The <kbd>x</kbd> is then moved outside and added as an argument for our new function. In this way, we can now pass any value to our new <kbd>mlp_loop()</kbd> function and have it replace the two instances of <kbd>x</kbd> in our code. We write our custom function to try different values for the <kbd>hidden_node</kbd> argument using the following code:</li>
</ol>
<pre style="padding-left: 60px">mlp_loop &lt;- function(x) {<br/>  model &lt;- mx.mlp(data.matrix(train), train_target, hidden_node=x, out_node=2, out_activation="softmax",<br/>num.round=10, array.batch.size=32, learning.rate=0.1, momentum=0.8,eval.metric=mx.metric.accuracy)<br/>  <br/>  preds = predict(model, data.matrix(test))<br/>  <br/>  pred.label = max.col(t(preds))-1<br/>  <br/>  acc = sum(pred.label == test_target)/length(test_target)<br/>  <br/>  vals &lt;- tibble(<br/>    nodes = x,<br/>    accuracy = acc<br/>  )<br/>}</pre>
<p style="padding-left: 60px">After we run the preceding code, we will see the change in our <span class="packt_screen">Environment</span> pane. Your <span class="packt_screen">Environment</span> pane will now look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1024 image-border" src="assets/4b33b27f-1380-4193-a2eb-ce826e38f194.png" style="width:45.58em;height:31.50em;"/></p>
<p style="padding-left: 60px">We can see that we <span>now</span><span> </span><span>have a custom function defined and stored in our environment.</span></p>
<ol start="7">
<li>Now we can first test our function with the value from the previous run. We test our function by supplying the value <kbd>70</kbd> to the function that we just made using the following lines of code:</li>
</ol>
<pre style="padding-left: 60px">results &lt;- mlp_loop(70)<br/><br/>results<br/><br/>all.equal(results$accuracy,acc)</pre>
<p style="padding-left: 60px">After we run the following code, we will get a printout on our console with the accuracy value and the number of nodes that we included in the hidden layer, as well as the results of testing for equality. Your console will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-641 image-border" src="assets/7700478a-3334-4134-922a-cfe0332d5964.png" style="width:18.00em;height:11.17em;"/></p>
<p style="padding-left: 60px">Based on the results of the code that we just ran, we can see that our function produces the same results that it would produce by just passing the values to the modeling code directly. This makes sense, as we are just swapping in <kbd>70</kbd> for all places where <kbd>x</kbd> is in the model function.</p>
<ol start="8">
<li>Now that it is confirmed that our new function is working (as we get the same result when passing the value <kbd>70</kbd> through the function that we get by just having it in the code), we can now pass our entire vector of values through the function. In order to do so, we will use the <kbd>map()</kbd> function from the <kbd>purrr</kbd> package, which makes iterating very simple and straightforward. In this case, we will use the <kbd>map_df()</kbd> function in order to get a dataframe, after looping all values through the function call. We loop through our function, passing in all values from the vector we created earlier by using the following code:</li>
</ol>
<pre style="padding-left: 60px">results &lt;- map_df(possible_node_values, mlp_loop)<br/><br/>results</pre>
<p style="padding-left: 60px">When we run the <span><span>preceding </span></span>code, we will see a printout to the console just like in <em>step 4</em> for all five model runs. After this, we will get the <kbd>results</kbd> dataframe, which now has all the accuracy scores for all the node count attempts. In your console, you may notice some rounding, which prevents an immediate determination of which model performed best. Let's click on the results from our <span class="packt_screen">Environment</span> pane instead and view the data that way. After clicking on <kbd>results</kbd>, you should see a table similar to the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1025 image-border" src="assets/d23427e0-cf3d-4a59-ad58-20f362e8ac02.png" style="width:15.25em;height:13.17em;"/></p>
<ol start="9">
<li>While we were able to create a loop to pass different node count values to the <kbd>mlp()</kbd> function to determine the optimal count, we will see in the next step that using a similar loop technique for finding the optimal layers is not as straightforward. To add layers, we must abandon the convenience of the <kbd>mlp()</kbd> function and create our multilayer perceptron one layer at a time. We can create an MLP one layer at a time using the following code:</li>
</ol>
<pre style="padding-left: 60px">data &lt;- mx.symbol.Variable("data")<br/>fc1 &lt;- mx.symbol.FullyConnected(data, num_hidden=90)<br/>fc2 &lt;- mx.symbol.FullyConnected(fc1, num_hidden=50)<br/>smx &lt;- mx.symbol.SoftmaxOutput(fc2)<br/><br/>model &lt;- mx.model.FeedForward.create(smx, data.matrix(train), train_target,num.round=10, array.batch.size=32,<br/>learning.rate=0.1, momentum=0.8, eval.metric=mx.metric.accuracy)<br/><br/><br/>preds = predict(model, data.matrix(test))<br/><br/>pred.label = max.col(t(preds))-1<br/><br/>acc = sum(pred.label == test_target)/length(test_target)<br/><br/>acc</pre>
<p style="padding-left: 60px">After running the <span>preceding </span>code, we will have a number of new data objects in our <span class="packt_screen">Environment</span> pane and an accuracy score printed to our console. Your console will look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-643 image-border" src="assets/a223a863-7dc1-4156-94e1-19c920739a33.png" style="width:8.08em;height:3.83em;"/></p>
<p>From this output, we can see that using the two highest-scoring values from our test of node counts in two separate layers did not improve our score. Adding more layers will not always lead to a better performing model, though you can continue to experiment with different layers using the <span>preceding </span>code as a guide to try to see if you can improve the score. Let's review what the preceding code is doing and how it differs from the model we created using the <kbd>mlp()</kbd> function.</p>
<p>In this case, we initiate our model by creating a symbolic variable. We then create two fully connected layers with 90 and 50 nodes respectively. We then define an output layer using the softmax activation function. We then use the <kbd>FeedForward()</kbd> function to define the other options that we used previously. In doing this, we can see that most of the arguments can be passed to <kbd>FeedForward</kbd> while the <kbd>hidden_node</kbd> argument moves to the <kbd>FullyConnected()</kbd> function for as many layers as you want and the <kbd>out_node</kbd> and <kbd>out_activation</kbd> arguments move to an output function, which in this case is <kbd>SoftmaxOutput</kbd>.</p>
<p>Using our prepared data, we looked at how to test for the optimal number of nodes for a hidden layer. We also looked at how we need to change our code to add additional layers. With MLPs, there are fewer options than other neural network implementations, so we have focused on making changes to the hidden layers to try to optimize our model using the main strength of neural network models. In the next step, we will take everything we have learned while tuning parameters to run a model that will maximize performance while giving a more in-depth explanation of our model options using MXNet.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training and evaluating the model</h1>
                </header>
            
            <article>
                
<p>After parameter tuning, we can now run the model for maximum performance. In order to do so, we will make a few important changes to the model options. Ahead of making the changes, let's have a more in-depth review of the model options:</p>
<ul>
<li><kbd>hidden_node</kbd>: These are the number of nodes in the hidden layer. We used a looping function to find the optimal number of nodes.</li>
<li><kbd>out_node</kbd>: These are the number of nodes in the output layer and must be set equal to the number of target classes. In this case, that number is <kbd>2</kbd>.</li>
<li><kbd>out_activation</kbd>: This is the activation function to use for the output layer.</li>
<li><kbd>num.round</kbd>: This is the number of iterations we take to train our model. In the parameter tuning stage, we set this number low so that we could quickly loop through a number of options; to get maximum accuracy, we would allow the model to run for more rounds while at the same time dropping the learning rate, which we will cover soon.</li>
<li><kbd>array.batch.size</kbd>: This sets the batch size, which is the number of rows that are trained at the same time during each round. The higher this is set, the more memory will be required.</li>
<li><kbd>learning.rate</kbd>: This is the constant value applied to the gradient from the loss function that is used to adjust weights. For parameter tuning, we set this to a large number to move quickly along the cost surface in a small number of rounds. To achieve the best performance, we will set this to a lower number to make more subtle adjustments while learning new weights so we don't constantly overadjust the values.</li>
<li><kbd>momentum</kbd>: This uses the decaying values from previous gradients to avoid sudden shifts in movement along the cost surface. As a heuristic, a good starting value for <kbd>momentum</kbd> is between <kbd>0.5</kbd> and <kbd>0.8</kbd>.</li>
<li><kbd>eval.metric</kbd>: This is the metric that you will use to evaluate performance. In our case, we are using <kbd>accuracy</kbd>.</li>
</ul>
<p>Now, that we have covered the options included in our model using the <kbd>mlp()</kbd> function, we will make adjustments to improve accuracy. In order to improve accuracy, we will increase the number of rounds while simultaneously dropping the learning rate. We will keep the other values constant and use the node count that led to the best performance from our loop earlier. You can set the model for better performance using what we learned when parameter tuning using the following code:</p>
<pre>model &lt;- mx.mlp(data.matrix(train), train_target, hidden_node=90, out_node=2, out_activation="softmax",num.round=200, array.batch.size=32, learning.rate=0.005, momentum=0.8,eval.metric=mx.metric.accuracy)<br/><br/>preds = predict(model, data.matrix(test))<br/><br/>pred.label = max.col(t(preds))-1<br/><br/>acc = sum(pred.label == test_target)/length(test_target)<br/><br/>acc</pre>
<p>After running this code, you will see a printout in your console with the accuracy score after running the model with the adjustments to the parameters. Your console output will look like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-644 image-border" src="assets/2d45fe33-d287-4bb3-a3ae-0a911f7975de.png" style="width:8.17em;height:5.00em;"/></p>
<p>We can see that our accuracy has improved from our adjustments. Before, when we were testing parameters, the best accuracy we could achieve was 84.28%, and we can see that we now have an accuracy score of 85.01%.</p>
<p>After preparing our data so that it is in the proper format to model with MXNet, and then parameter tuning to find the best values for our model, we then made adjustments to further improve performance using what we learned earlier. All of these steps together describe a complete cycle of manipulating and transforming data, optimizing parameters, and then running our final model. We saw how to use MXNet, which offers a convenience function for simple MLPs and also offers the functionality to build MLPs with additional hidden layers using the activation, output, and feedforward functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Multilayer perceptrons are the simplest form of neural networks. They are feedforward without the feedback loops of recurrent neural networks, and all hidden layers are dense, fully connected layers, unlike convolutional neural networks, which feature convolutional layers and pooling layers. Given their simplicity, there are fewer options to adjust; however, in this chapter, we focused on adjusting the nodes in the hidden layer and looked at adding additional layers, as this aspect is the main element that separates neural network models, and as such, all deep learning methods from other machine learning algorithms. Using all the code in this chapter, you have learned how to process data so that it was ready to model, how to select the optimal number of nodes and layers, and how to train and evaluate a model using the <kbd>mxnet</kbd> library for R.</p>
<p>In the next chapter, you will learn how to code deep autoencoders. This model is a form of unsupervised learning that is used to automatically categorize our input data. We will use this clustering process to code a recommender system using collaborative filtering.</p>


            </article>

            
        </section>
    </body></html>