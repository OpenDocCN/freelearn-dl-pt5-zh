["```py\n    import numpy as np\n    from onnx import TensorProto, numpy_helper\n    from onnx.helper import make_tensor_value_info\n    X = make_tensor_value_info(\n        name='X',\n        elem_type=TensorProto.FLOAT,\n        shape=[None, None])\n    Y = make_tensor_value_info(\n        'Y', TensorProto.FLOAT, [None])\n    A = numpy_helper.from_array(\n        np.array([0.5, -0.6], dtype=np.float32),\n        name='A')\n    B = numpy_helper.from_array(\n        np.array([0.4], dtype=np.float32),\n        name='B')\n    ```", "```py\n    from onnx.helper import make_node\n    mat_mul = make_node(\n        op_type='MatMul',\n        inputs=['X', 'A'],\n        outputs=['XA'])\n    addition = make_node('Add', ['XA', 'B'], ['Y'])\n    ```", "```py\n    from onnx.helper import make_graph\n    graph = make_graph(\n        nodes=[mat_mul, addition],\n        name='Linear regression',\n        inputs=[X],\n        outputs=[Y],\n        initializer=[A, B])\n    ```", "```py\n    from onnx.helper import make_model\n    onnx_model = make_model(graph)\n    onnx_model.doc_string = 'Test model'\n    onnx_model.model_version = 1\n    ```", "```py\n    from onnx.checker import check_model\n    check_model(onnx_model)\n    print(onnx_model)\n    ```", "```py\n    from onnx.reference import ReferenceEvaluator\n    sess = ReferenceEvaluator(onnx_model)\n    print(sess.run(\n        output_names=None,\n        feed_inputs={'X': np.random.randn(2, 2).astype(np.float32)}))\n    ```", "```py\n    [array([-0.7511951,  1.0294889], dtype=float32)]\n    ```", "```py\n    with open('model.onnx', 'wb') as f:\n        f.write(onnx_model.SerializeToString())\n    from onnx import load\n    with open('model.onnx', 'rb') as f:\n        onnx_model = load(f)\n    ```", "```py\n    import torch\n    from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n    torch_model = mobilenet_v3_small(\n      weights=MobileNet_V3_Small_Weights.DEFAULT)\n    ```", "```py\n    torch.onnx.export(\n        model=torch_model,\n        args=torch.randn(1, 3, 224, 224),\n        f=\"torch_model.onnx\",\n        export_params=True)\n    ```", "```py\n    import onnx\n    torch_model_onnx = onnx.load('torch_model.onnx')\n    onnx.checker.check_model(torch_model_onnx)\n    ```", "```py\n    import tensorflow as tf\n    tf_model = tf.keras.applications.MobileNetV3Small(\n      weights='imagenet',\n      input_shape=(224, 224, 3),\n    )\n    ```", "```py\n    import tf2onnx\n    tf_model_onnx, _ = tf2onnx.convert.from_keras(\n      model=tf_model,\n      input_signature=[tf.TensorSpec([1, 224, 224, 3])])\n    onnx.save(tf_model_onnx, 'tf_model.onnx')\n    ```", "```py\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(\n            learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy'])\n    ```", "```py\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n        log_dir='logs/tb/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S'),\n        update_freq='epoch',\n        histogram_freq=1,\n        write_graph=True,\n        write_images=True,\n        write_steps_per_second=True,\n        profile_batch=0,\n        embeddings_freq=0)\n    ```", "```py\n    steps_per_epoch=metadata.splits['train'].num_examples // BATCH_SIZE\n    validation_steps=metadata.splits['test'].num_examples // BATCH_SIZE\n    model.fit(\n        train_batches,\n        epochs=epochs,\n        validation_data=test_batches,\n        callbacks=[tensorboard_callback],\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps)\n    ```", "```py\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(\nlog_dir='logs/tb/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n```", "```py\nfrom torchvision.models import (\n    MobileNet_V3_Small_Weights, mobilenet_v3_small)\nmodel = mobilenet_v3_small(\n    weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n```", "```py\nfor i, (inputs, labels) in enumerate(data_loader):\n    # Training loop goes here\n```", "```py\nwriter.add_graph(model, inputs)\n```", "```py\nwriter.add_scalar(\n    tag='train/accuracy',\n    scalar_value=total_acc,\n    global_step=epoch)\nwriter.add_scalar(\n    tag='train/loss',\n    scalar_value=total_loss,\n    global_step=epoch)\n```", "```py\n    from mediapipe_model_maker import image_classifier\n    dataset = image_classifier.Dataset.from_folder(dataset_path)\n    train_data, validation_data = dataset.split(0.9)\n    ```", "```py\n    hparams = image_classifier.HParams(\n        export_dir='tflite_model',\n        epochs=3,\n        batch_size=16)\n    ```", "```py\n    options = image_classifier.ImageClassifierOptions(    supported_model=image_classifier.SupportedModels.EFFICIENTNET_LITE4,\n        hparams=hparams)\n    ```", "```py\n    model = image_classifier.ImageClassifier.create(\n        train_data=train_data,\n        validation_data=validation_data,\n        options=options,\n    )\n    ```", "```py\n    model.export_model('model.tflite')\n    ```", "```py\n    import mediapipe as mp\n    from mediapipe.tasks import python\n    from mediapipe.tasks.python import vision\n    generic_options = python.BaseOptions(\n        model_asset_path='/content/tflite_model/model.tflite')\n    cls_options = vision.ImageClassifierOptions(\n        base_options=generic_options)\n    classifier = vision.ImageClassifier.create_from_options(cls_options)\n    ```", "```py\n    for image_path, label in zip(image_paths, labels):\n      image = mp.Image.create_from_file(image_path)\n      result = classifier.classify(image)\n      top_1 = result.classifications[0].categories[0]\n      print(f'Label: {label}; Prediction: {top_1.category_name}')\n    ```", "```py\ndef train_model(model, loss_fn, optimizer, data_loader):\n    scaler = torch.cuda.amp.GradScaler()\n    for i, (inputs, labels) in enumerate(data_loader):\n        optimizer.zero_grad()\n        with torch.autocast(\n            device_type=device,\n            dtype=torch.float16):\n            # send the input/labels to the GPU\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            # forward\n            outputs = model(inputs)\n            loss = loss_fn(outputs, labels)\n        # backward with scaler\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n```", "```py\n    import torch\n    from diffusers import StableDiffusionPipeline\n    sd_pipe = StableDiffusionPipeline.from_pretrained(\n        \"stabilityai/stable-diffusion-2-1\",\n        torch_dtype=torch.float16)\n    sd_pipe.to('cuda')\n    ```", "```py\n    from flask import Flask\n    from flask_ngrok import run_with_ngrok\n    app = Flask(__name__)\n    run_with_ngrok(app)\n    ```", "```py\n    import io\n    from flask import Flask, request, send_file, abort\n    @app.route('/text-to-image', methods=['POST', 'GET'])\n    def predict():\n        if request.method in ('POST', 'GET'):\n            prompt = request.get_json().get('prompt')\n            if prompt and prompt.strip():\n                image = sd_pipe(\n                    prompt,\n                    num_inference_steps=100).images[0]\n                image_io = io.BytesIO()\n                image.save(image_io, format='PNG')\n                image_io.seek(0)\n                return send_file(\n                    image_io,\n                    as_attachment=False,\n                    mimetype='image/png'\n                )\n            else:\n                abort(500, description='Invalid prompt')\n    ```", "```py\n    import requests\n    response = requests.post(\n        url='http://RANDOM-SEQUENCE.ngrok.io/text-to-image',\n        json={'prompt': 'High quality photo of a racing car on a track'})\n    ```", "```py\n    from PIL import Image\n    import io\n    image = Image.open(io.BytesIO(response.content))\n    image.show()\n    ```", "```py\n    def generate_image(\n            prompt: str,\n            inf_steps: int = 100):\n        return sd_pipe(\n            prompt=prompt,\n            num_inference_steps=inf_steps).images[0]\n    ```", "```py\n    import gradio as gr\n    interface = gr.Interface(\n        fn=generate_image,\n        inputs=[\n            gr.components.Textbox(label='Prompt'),\n            gr.components.Slider(\n                minimum=0,\n                maximum=100,\n                label='Inference Steps')],\n        outputs=gr.components.Image(),\n        title='Stable Diffusion',\n    )\n    ```"]