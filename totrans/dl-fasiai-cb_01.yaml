- en: '*Chapter 1*: Getting Started with fastai'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the last decade, deep learning has revolutionized swathes of technology,
    from image recognition to machine translation. Until recently, only those with
    extensive training and access to specialized hardware have been able to unlock
    the benefits of deep learning. The fastai framework is an effort to democratize
    deep learning by making it accessible to non-specialists. One of the key ways
    that fastai opens up deep learning to the masses is by making it easy to get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will show you what you need to get started with fastai,
    starting with how to set up an environment for fastai. By the end of this chapter,
    you will be able to do the following: set up a cloud environment in which to run
    `fastai` examples; exercise a basic fastai example; explain the relationship between
    fastai and PyTorch (the underlying deep learning library for fastai); and contrast
    fastai with Keras, the other high-level library for deep learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the recipes that will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a fastai environment in Paperspace Gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a fastai environment in Google Colaboratory (Google Colab)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up JupyterLab environment in Paperspace Gradient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"Hello world" for fastai—creating a model for the **Modified National Institute
    of Science and Technology** (**MNIST) dataset**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding the world in four applications: tables, text, recommender systems,
    and images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with PyTorch tensors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrasting fastai with Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test your knowledge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will be using the following technologies:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Paperspace Gradient: [https://gradient.paperspace.com/](https://gradient.paperspace.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Colab: [https://colab.research.google.com/notebooks/intro.ipynb](https://colab.research.google.com/notebooks/intro.ipynb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Drive: [https://drive.google.com](https://drive.google.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keras: [https://keras.io/](https://keras.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the code referred to in this chapter at the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook/tree/main/ch1](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook/tree/main/ch1)'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a fastai environment in Paperspace Gradient
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two free cloud environments that you can use to explore fastai: **Paperspace
    Gradient** and **Google Colab**. In this section, we''ll go through the steps
    to set up Paperspace Gradient with a fastai notebook environment, and in the next
    section, we''ll go through the setup steps for Colab. It''s your choice, so pick
    the environment that works best for you.'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient is simpler to use because you have access to a standard filesystem
    for storage. With Colab, you need to use Google Drive for storage and, unlike
    Gradient, you don't have convenient access to the terminal for command-line interactions.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, Colab gives you direct access to a wider set of libraries
    beyond those needed for fastai—for example, you can run the Keras MNIST example
    in Colab but it won't work off the shelf in a Gradient fastai instance. To get
    the most out of the examples in the book, it's best to set up both environments
    so that you can choose which one works best for you as you go along. We'll start
    with Gradient, since it is the simplest to get started with.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prior to setting up Gradient for fastai, you need to create a Paperspace account.
    You can do this by going to [https://console.paperspace.com/signup?gradient=true](https://console.paperspace.com/signup?gradient=true).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have a Paperspace account, you can create a free fastai notebook in
    Gradient by following these steps to create a fastai notebook instance in Gradient.
    Once created, this will be a complete Jupyter Notebook environment with all the
    libraries that you need (including fastai, PyTorch, and related libraries).
  prefs: []
  type: TYPE_NORMAL
- en: Go to the Paperspace site and sign in using the account you created in the *Getting
    ready* section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the pulldown at the top of the page, select **Gradient**:![Figure 1.1\.
    – Selecting gradient from the pulldown
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.1\. – Selecting gradient from the pulldown
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the **Notebooks** tab:![Figure 1.2 – Selecting the Notebooks tab
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.2 – Select the Notebooks tab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the **CREATE** button.![Figure 1.3 – CREATE button
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.3 – CREATE button
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter a name for your notebook in the **Name** field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Select a runtime** section, select **fastai**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Select a machine** section, select **Free-GPU** or **Free-P5000**.
    Note that you may receive a message indicating out of capacity for the machine
    type you selected. If this happens, you can either choose another GPU-enabled
    machine type or wait a few minutes and try again with your original machine type.
    Also note that after your notebook is created, you can change the machine type—for
    example, if you find that the free instance is not meeting your needs, you can
    switch your notebook to a paid machine. You can also define multiple notebooks
    for different applications and configure auto-shutdown (how many hours your instance
    will run before shutting itself down) if you opt for a paid subscription. For
    details, see [https://console.paperspace.com/teim6pi2i/upgrade](https://console.paperspace.com/teim6pi2i/upgrade).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **START NOTEBOOK** button to launch the process of creating a new
    fastai instance for you in Gradient.![Figure 1.4 – START NOTEBOOK button
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.4 – START NOTEBOOK button
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your notebook will take a minute or so to be created. When it is ready, you
    will see a **Running** message at the bottom of the screen:![Figure 1.5 – Running
    message
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.5 – Running message
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, you should see a Jupyter button appear in the navigation panel on the
    left, as highlighted in *Figure 1.6*:![Figure 1.6 – Jupyter icon in the navigation
    panel
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.6 – Jupyter icon in the navigation panel
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select the Jupyter button to start your new notebook environment. You should
    now see a Jupyter files view, as shown in *Figure 1.7*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.7 – Jupyter file view in Gradient'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.7 – Jupyter file view in Gradient
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that your notebook has started, you need to validate that it was set up
    correctly by running a short notebook that checks the fastai version available
    to your notebook and confirms that your notebook has access to **graphics processing
    units** (**GPUs**), the specialized hardware required to efficiently run subsequent
    examples in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a terminal in the root directory of your Gradient notebook environment:![Figure
    1.8– Pulldown to open a terminal in Jupyter notebook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.8– Pulldown to open a terminal in Jupyter notebook
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the terminal, create a new directory, `fastai_cookbook`, in the root level
    of your notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the terminal, make this new directory your current directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize `git` in this new directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Clone the repository for the book:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the repository has been cloned, go to the `ch1` directory and open the
    `validate_gradient_setup.ipynb` notebook:![Figure 1.9 – validate_gradient_setup.ipynb
    notebook in the Files view
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.9 – validate_gradient_setup.ipynb notebook in the Files view
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the entire notebook (**Cell -> Run all**) and check the output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the first code cell, you should see something like the following if your
    notebook has access to the `fastai` library. Don't worry about the exact level
    of fastai—the key point is that you are able to import the library and get back
    a valid version without errors:![Figure 1.10 – Getting the fastai version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.10 – Getting the fastai version
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For the second code cell, you should see something like the table shown next
    if your notebook has access to a GPU. A GPU is specialized hardware for deep learning
    that you will need in order to efficiently run subsequent examples. Don''t worry
    about the specific type of GPU listed; just confirm that you get a table like
    this as output of this cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.11 – Output of the nvidia-smi command'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.11 – Output of the nvidia-smi command
  prefs: []
  type: TYPE_NORMAL
- en: 'If you get the following kind of output from this cell, then your notebook
    was not set up correctly with access to a GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.12 – Error from the nvidia-smi command'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.12 – Error from the nvidia-smi command
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have set up a Gradient environment that is ready to explore
    fastai.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you have a working Gradient instance, you will be able to run fastai
    examples. Gradient includes PyTorch, fastai, and other libraries that you need
    to run the examples in this book, along with access to the GPU hardware that you
    need to run these examples efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the aspects of Gradient notebooks that you need to be aware of are
    listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: By default, your free instance will run for 6 hours and then shut itself down.
    If you want to have longer, uninterrupted sessions, you will need to change to
    a paid subscription.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally speaking, restarting a Gradient instance takes between 3 and 10 minutes,
    so it's a good idea to go to the **Notebook** section of the Paperspace console
    and click on **START** for your notebook a few minutes before you're ready to
    actually get working. I am in the habit of starting my notebook and then completing
    some other task (such as sending an email or making a cup of tea) so that I'm
    not waiting too long for the notebook to start.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are a bit rusty about how to use Jupyter notebooks, the tutorial available
    at [https://www.dataquest.io/blog/jupyter-notebook-tutorial/](https://www.dataquest.io/blog/jupyter-notebook-tutorial/)
    gives a good review of the key points.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have completed all the steps in this section and have a working Gradient
    environment, the next section is not strictly required. I recommend that you set
    up both Gradient and Colab, but it's not mandatory to have both environments in
    order to complete most of the examples in this book. However, if you want the
    best of both worlds, you can also set up Colab for fastai—it's also free, and
    it offers some advantages over Gradient, such as supporting Keras applications.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a fastai environment in Google Colab
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are already familiar with the **Google Colab** environment or want to
    take advantage of Google's overall machine learning ecosystem, Colab may be the
    right environment for you to use to explore fastai. In this section, we'll go
    through the steps to get set up with Colab and validate that it's ready for you
    to use with fastai.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use Colab, you will need a Google ID and access to Google Drive. If you
    don''t already have a Google ID, follow the instructions here to create one: [https://support.google.com/accounts/answer/27441?hl=en](https://support.google.com/accounts/answer/27441?hl=en).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have a Google ID, you need to confirm that you have access to Google
    Drive. You need access to Drive because it acts as the storage system for Colab.
    You save your notebooks and data in Drive when you are working in Colab. Follow
    the instructions here to get access to Drive: [https://support.google.com/drive/answer/2424384?co=GENIE.Platform%3DDesktop&hl=en](https://support.google.com/drive/answer/2424384?co=GENIE.Platform%3DDesktop&hl=en).'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have a Google ID with access to Drive, you can set up Colab to work
    with fastai by completing the following steps. First, we'll get access to Drive
    from within a Colab notebook, then clone the repository for this book, and finally
    run the validation notebook to confirm the setup worked.
  prefs: []
  type: TYPE_NORMAL
- en: Open Colab ([https://colab.research.google.com/](https://colab.research.google.com/)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new, blank notebook by selecting **File -> New notebook**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the new notebook, paste the following statement into an empty cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, select the **Run** button:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.13 – Colab run button'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_01_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.13 – Colab run button
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Confirm that you get the expected output:![Figure 1.14 – Expected output of
    "hello world" in Colab
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.14 – Expected output of "hello world" in Colab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go to Drive and create a new folder called `fastai_cookbook` in your root folder
    in Drive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go into this new folder and right-click, and select **Google Colaboratory**:![Figure
    1.15 – Selecting Google Colaboratory in your new directory in Drive
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.15 – Selecting Google Colaboratory in your new directory in Drive
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Colab will open a new notebook. In this notebook, select **Connect** -> **Connect
    to hosted runtime**:![Figure 1.16 – Selecting Connect to hosted runtime
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.16 – Selecting Connect to hosted runtime
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In a new cell in this notebook, paste the following code and run the cell (for
    example, by clicking the arrow):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the response that comes back, click on the link that is provided:![Figure
    1.17 – Prompt to mount Google Drive in your notebook
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.17 – Prompt to mount Google Drive in your notebook
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select an account:![Figure 1.18 – Dialog to select your Google account
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.18 – Dialog to select your Google account
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the screen for **Google Drive File Stream** access, select on **Allow**:![Figure
    1.19 – Google Drive File Stream dialog
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.19 – Google Drive File Stream dialog
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the **Sign in** screen, select the **copy** icon to copy your access code:![Figure
    1.20 – Dialog to get access code
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.20 – Dialog to get access code
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, return to the notebook in Colab and paste the access code in the authorization
    code field, and then press *Enter*:![Figure 1.21 – Access code entered to mount
    Google Drive
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.21 – Access code entered to mount Google Drive
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The cell will run and produce the following mounted message to confirm that
    your Google Drive has been mounted and is available for your Colab notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.22 – Message confirming that Google Drive has been mounted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.22 – Message confirming that Google Drive has been mounted
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that Drive is mounted in Colab, the next step is to clone the book''s repository:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make the `fastai_cookbook` new directory folder in Drive your current directory
    by running a cell in the notebook with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following command in a new cell to list the contents of this directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following code in a new cell in your notebook to clone the book''s
    repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the cell to list the directory contents again, and you should see the directory
    created now for the repository. You can confirm in Drive that the repository has
    been cloned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that you have cloned the repository, you can run the validation notebook
    to confirm that you have access to the `fastai` library and GPUs:'
  prefs: []
  type: TYPE_NORMAL
- en: In Drive, navigate to the `fastai_cookbook/Deep-Learning-with-fastai-Cookbook/ch1`
    folder, right-click on the `validate_gradient_setup.ipynb` notebook, and select
    **Open With** | **Google Colaboratory**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The notebook opens up in Colab. Select **Runtime** | **Change Runtime Type**.
    In the **Notebook settings** dialog that comes up, select **GPU** in the **Hardware
    accelerator** field, and select **SAVE**:![Figure 1.23 – Selecting GPU as the
    hardware accelerator in the Notebook settings dialog
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.23 – Selecting GPU as the hardware accelerator in the Notebook settings
    dialog
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the notebook by selecting **Runtime** | **Run all**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Confirm that you get output like the following, with no errors, for the first
    code cell in the notebook:![Figure 1.24 – Confirmation of the fastai version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.24 – Confirmation of the fastai version
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Confirm that you get output like the following for the second code cell in
    the notebook. Don''t worry about the specific GPU type listed—this will vary depending
    on what''s available. If you did not specify **GPU** as the hardware accelerator
    in *Step 2*, then you won''t get this output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.25 – Output of nvidia-smi confirming access to a GPU'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.25 – Output of nvidia-smi confirming access to a GPU
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have set up a Colab environment that is ready to explore
    fastai.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you have a working Colab environment, you will be able to run fastai
    examples in it. Colab incorporates PyTorch, fastai, and other libraries that you
    need to run the examples in this book. Note that, unlike Gradient, every time
    you start up a new Colab session, you will need to follow the steps to mount Drive
    and will also need to specify that you want a GPU. By default, Drive is not mounted
    and your Colab notebooks don't have access to GPUs until you explicitly change
    the hardware accelerator type.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have set up both Gradient and Colab environments, I recommend that you
    use Gradient to exercise the examples in this book by default. Gradient gives
    you direct access to a terminal, which is handy for entering command-line commands,
    and does not require you to mount a filesystem or request a GPU every time you
    start a new session. Colab does have some advantages, including not shutting down
    after 6 hours, but overall you will have a smoother experience with Gradient.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up JupyterLab environment in Gradient
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier in this chapter, we went through the steps to set up Gradient as an
    environment to explore fastai. With this set up, you get the standard Jupyter
    notebook environment that features a filesystem view and the ability to update
    notebooks, launch terminal windows, and perform basic operations such as uploading
    and downloading files from your local system. If you want a richer development
    environment, you can set up Gradient to use JupyterLab.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to allowing you to maintain multiple views (for example, a terminal
    view along with several notebooks) within the same browser tab, JupyterLab also
    lets you take advantage of visual debuggers in the context of a notebook. In this
    section, we will go through the steps to set up Gradient so that you can use JupyterLab.
    Note that this recipe is optional—any example in this book that you can run in
    Gradient with JupyterLab will also work in vanilla Jupyter.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you attempt to set up Gradient with JupyterLab, ensure that you have
    successfully completed the steps in the *Setting up a fastai environment in Paperspace
    Gradient* section. Once you have set up JupyterLab Gradient, you will be able
    to switch back and forth between the vanilla Jupyter view and JupyterLab at any
    time.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To get JupyterLab set up, you begin by starting up your Gradient instance,
    run a command to install JupyterLab, and then restart the instance to see the
    result. Here are the steps to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: Start your Gradient fastai instance to bring up the vanilla Jupyter **Files**
    view:![Figure 1.29 – Vanilla Jupyter Files view
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.26 – Vanilla Jupyter Files view
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once you are in the filesystem view for your instance, select **New** | **Terminal**:![Figure
    1.27 – Pulldown to open up a terminal in Jupyter
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.27 – Pulldown to open up a terminal in Jupyter
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This will open a terminal window:![Figure 1.28 – Jupyter terminal window
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.28 – Jupyter terminal window
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the terminal window, enter this command to install JupyterLab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the install has completed, exit Jupyter, stop your Gradient instance in
    the Paperspace console, and restart it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When you get to the vanilla Jupyter `tree` at the end of the URL with `lab`,
    and hit *Enter*. You should now see the JupyterLab view instead of the vanilla
    Jupyter view:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.29 – JupyterLab environment in Gradient'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.29 – JupyterLab environment in Gradient
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have set up Gradient so that you can use the JupyterLab
    view.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can go back and forth between the vanilla Jupyter view and JupyterLab any
    time you like by simply modifying the URL so that the end is `tree` (for Jupyter)
    or `lab` (for JupyterLab).
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you want more details on the benefits of JupyterLab, this tutorial explains
    the features and how to use them: [https://dzone.com/articles/getting-started-with-jupyterlab](https://dzone.com/articles/getting-started-with-jupyterlab).'
  prefs: []
  type: TYPE_NORMAL
- en: I mentioned earlier that one of the benefits of JupyterLab is that it supports
    a visual Python debugger you can use in notebooks. For more details on this debugger
    and how to set it up, see `https://medium.com/@cristiansaavedra/visual-jupyter-debugger-for-python-e96fdd4f6f68`
    and [https://blog.jupyter.org/a-visual-debugger-for-jupyter-914e61716559](https://blog.jupyter.org/a-visual-debugger-for-jupyter-914e61716559).
  prefs: []
  type: TYPE_NORMAL
- en: '"Hello world" for fastai – creating a model for MNIST'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have set up your environment for fastai, it''s time to run through
    an example. In this section, you will go through the process of creating a simple
    deep learning model trained on the MNIST dataset. This dataset consists of images
    of handwritten digits. The goal of the trained model is to predict the digit given
    an image. For example, we want the trained model to predict that the following
    digits are `6,` `3,` `9,` and `6`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.30 – Sample handwritten digits from the MNIST dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.30 – Sample handwritten digits from the MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: We won't be covering every detail of the fastai solution for MNIST in this section,
    but we will be running a complete example that demonstrates one of the key values
    of fastai—getting a powerful deep learning result with only a few lines of code.
    This example should also whet your appetite for the more advanced fastai examples
    that are coming in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensure that you have followed the steps to set up fastai in Gradient and confirm
    that you can open the `MNIST` `hello_world` notebook (`mnist_hello_world.ipynb`)
    in the `ch1` directory. If you choose to use Colab, ensure that you have selected
    **Runtime** | **Change runtime type** and have selected **GPU** as the hardware
    accelerator.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used in this section is the classic dataset of deep learning, MNIST
    ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)). I gratefully
    acknowledge the opportunity to use this dataset to provide an initial illustration
    of the capabilities of fastai.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: Y. LeCun, L. Bottou, Y. Bengio and P. Haffner.(1998) Gradient-Based Learning
    Applied to Document Recognition (http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf).
    Proceedings of the IEEE, 86(11):2278-2324, November 1998
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You will begin by running the notebook all the way through. By running all the
    cells in this notebook you will be executing code that trains an image classification
    deep learning model that predicts the class (that is, which digit from 0 to 9)
    a given image of a hand-written digit belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: First, you will make the MNIST dataset, which consists of a set of images of
    handwritten digits organized into directories (one for each digit from 0 to 9),
    available to the Python code in the notebook. Next, you will define a `dataloaders`
    object that specifies the training subset of the dataset (that is, the images
    that will be used to train the model) and the validation subset of the dataset
    (that is, the images that will be used to assess the performance of the model
    as it is trained). Next, you will define the deep learning model itself using
    a pre-defined architecture (that is, an organization of layers that make up the
    model) made available by fastai.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you will train the model, that is iteratively apply the training set
    to update the weights in the model to optimize the performance of the model for
    the specified metric (in the case of this model, accuracy). Next, you will examine
    batches of images in the training and validation sets. You will then look at images
    where the model does the worst job of classification. Finally, you will apply
    the trained deep learning model to example hand-written images to see whether
    the model predicts the correct digit for these images. In the following steps
    you will run the code in the entire notebook and then go through the cells in
    the notebook one-by-one to review what the code is doing:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the MNIST `hello_world` notebook `mnist_hello_world.ipynb` in the `ch1`
    directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the entire notebook by selecting the appropriate choice for your environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) **Cell**|**Run all** (Jupyter)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) **Run**|**Run all** (JupyterLab)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) **Runtime**|**Run all** (Colab)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Confirm that the notebook runs correctly to the end. You should see the following
    output from the last cell. Don''t worry if you see a different digit output, as
    long as you get output with no errors in this cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.31 – Example MNIST digit prediction'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.31 – Example MNIST digit prediction
  prefs: []
  type: TYPE_NORMAL
- en: 'Congratulations! You have just successfully trained your first deep learning
    model with fastai and used the trained model to predict the digits depicted in
    a set of handwritten digits from the MNIST dataset. Now, let''s go through the
    notebook cell by cell to review what this example tells us about fastai:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first code cell imports the libraries that the notebook needs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The second cell calls the `fastai` function to prepare a notebook to run a
    fastai application. In Colab, for example, this function triggers the steps to
    mount Drive so that it''s accessible within the notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The third cell defines the location of the dataset that will be used to train
    the model. fastai provides a set of oven-ready datasets (including several varieties
    of the MNIST dataset) that you can ingest into your notebook with a single call
    using the `untar_data()` function. We''ll dig into more details about these datasets
    in [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)*, Exploring and
    Cleaning Up Data with fastai*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The fifth cell is the heart of the notebook and demonstrates the power of fastai.
    Here are three lines of code that completely define and train a deep learning
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) The first line creates a `dataloaders` object from the `path` object created
    in the previous cell and identifies the subdirectories that contain the training
    and validation datasets. See the fastai documentation ([https://docs.fast.ai/vision.data.html#ImageDataLoaders](https://docs.fast.ai/vision.data.html#ImageDataLoaders))
    for more details on `ImageDataLoaders`, the specific kind of `dataloaders` object
    used for image problems:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) The second line defines the structure of the deep learning model, including
    its architecture (based on the famous `1` epoch (that is, one iteration through
    the entire training set) and the learning rate will be `0.1`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output of this cell shows the results of the training process, including
    the training and validation loss, the validation accuracy, and the time taken
    to complete the training. Note that the accuracy is very high:![Figure 1.32 –
    Output of training the MNIST model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.32 – Output of training the MNIST model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next two cells display examples of the training and validation **test**
    datasets:![Figure 1.33 – Examples from the MNIST train and test datasets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.33 – Examples from the MNIST train and test datasets
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The next cell shows examples of digits that the model got the most wrong. Note
    how these digits are not easy for us humans to identify, so it's not surprising
    that the model got them wrong:![Figure 1.34 – Digits for which the MNIST model
    made the worst predictions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.34 – Digits for which the MNIST model made the worst predictions
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next cell displays a summary of information about the model, including
    the layers that make it up, how many parameters it has, and the optimizer and
    loss function used:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we have a set of cells at the end of the notebook that display digit
    images from the validation set, and then apply the trained model to get a prediction
    of which digit is shown in the image. In the following example, the model correctly
    identifies from the validation set an image of a zero as a zero:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.35 – Example prediction by the MNIST model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.35 – Example prediction by the MNIST model
  prefs: []
  type: TYPE_NORMAL
- en: That's it—a complete, self-contained deep learning model that solves a famous
    computer vision problem (predicting a digit in a handwritten image) with remarkable
    accuracy. With fastai, you can accomplish this with just a few lines of code.
    This notebook contains some additional code to validate the model and investigate
    the dataset, but all you really need are the first five cells, which together
    contain barely 10 lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may be asking yourself about the details of the code that we just went through.
    How exactly does the data ingestion work? What's a dataloader? How does the model
    know to include all the layers that are shown by the `summary()` function? We'll
    be answering these questions in subsequent chapters. In [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)*,
    Exploring and Cleaning Up Data with fastai*, we'll dig into the data ingestion
    story for fastai, and in subsequent chapters we'll take a detailed tour through
    fastai's solutions for a set of common deep learning applications, including tabular
    data, text data, recommender systems, and computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: One of the beauties of fastai is that you can abstract away much of the complexity
    of deep learning (if you want), and get a working and useful model with just a
    few lines of code, as with the MNIST model we just saw. However, fastai doesn't
    keep the details hidden or limit your flexibility. In addition to providing an
    elegant way to create deep learning models with very little code, fastai incorporates
    a set of layers, each of which reveals more flexibility and detail. This means
    that as you learn more about fastai, you can continue to dig deeper and customize
    your solution to meet your exact needs.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section makes use of some standard machine learning terminology, including
    **loss function**, **optimizer**, **accuracy**, and **multi-class classification**.
    If you need a refresher on these and other fundamental machine learning concepts,
    I recommend the series of tutorials here: [https://machinelearningmastery.com/](https://machinelearningmastery.com/).
    This site includes clear descriptions of the major concepts of machine learning,
    along with Python code samples that illustrate how to apply the concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding the world in four applications: tables, text, recommender systems,
    and images'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In their seminal paper describing fastai, Howard and Gugger ([https://arxiv.org/pdf/2002.04688.pdf](https://arxiv.org/pdf/2002.04688.pdf))
    describe the four application areas that fastai supports *out of the box*. In
    this section, we will go through these four applications of deep learning that
    fastai directly supports: tabular data, text data, recommender systems, and computer
    vision. The MNIST example that you saw in the previous section is an example of
    a computer vision application. The MNIST example included the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Curated dataset: MNIST. You can find an overall list of curated datasets here:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://course.fast.ai/datasets](https://course.fast.ai/datasets)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Easy ingestion of the curated dataset via `untar_data()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image-specific handling of the dataset via a data loader object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Definition of an image-specific model structure via a `Learner` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilities to examine the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Similarly, fastai also provides components specifically aimed at the other
    three application areas: tabular data, text data, and recommender systems. In
    this section, we''ll examine each of these application areas and learn about how
    fastai provides support for them.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Have the MNIST example that you went through in the last section open because
    we will be referring to is as we go through the four application areas. Before
    we get into the description of the four application areas, it''s important to
    get some definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`DataLoader`: A structure that allows you to access batches of *x* (independent)
    and *y* (dependent) values. The *x* values are the data you use to train the model,
    and the *y* values are what you are trying to predict with the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DataLoaders`: A structure that contains training and validation `DataLoader`
    objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Learner`: An object that combines `DataLoaders`, architecture, and other characteristics
    (including loss function and optimizer) to define a model. To contrast `Learner`
    objects with models in Keras, `Learner` objects fully incorporate the data used
    to train the model, whereas with Keras models, the various facets of the dataset
    (such as training independent values, training dependent values, and much more)
    are arguments to the model that need to be addressed separately from the model
    itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's go through each of the four application areas and examine the support
    that fastai provides for them.
  prefs: []
  type: TYPE_NORMAL
- en: '`AG_NEWS` (~ 0.5 M categorized news articles), and `DBPedia` (training/testing
    samples from a knowledge base ([https://wiki.dbpedia.org/about](https://wiki.dbpedia.org/about))
    containing structured content from Wikimedia projects), `YELP_REVIEWS` (~1.5 M
    Yelp reviews along with corresponding star scores)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'b) Text-specific `DataLoaders` object: `TextDataLoaders` [https://docs.fast.ai/text.data.html#TextDataLoaders](https://docs.fast.ai/text.data.html#TextDataLoaders)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) Text-specific learner object: `TextLearner` [https://docs.fast.ai/text.learner.html#TextLearner](https://docs.fast.ai/text.learner.html#TextLearner)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`DataLoaders` object: `TabularDataLoaders` [https://docs.fast.ai/tabular.data.html#TabularDataLoaders](https://docs.fast.ai/tabular.data.html#TabularDataLoaders)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'b) Tabular data-specific `Learner` object: `TabularDataLearner` [https://docs.fast.ai/tabular.learner.html#TabularLearner](https://docs.fast.ai/tabular.learner.html#TabularLearner)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) Utilities to examine the dataset: `TabularPandas` [https://docs.fast.ai/tabular.core.html#TabularPandas](https://docs.fast.ai/tabular.core.html#TabularPandas)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`ML_SAMPLE` and `ML_100k` (rankings of thousands of movies by thousands of
    users)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'b) Recommender system-specific `DataLoaders` object: `CollabDataLoaders` [https://docs.fast.ai/collab.html#CollabDataLoaders](https://docs.fast.ai/collab.html#CollabDataLoaders)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) Recommender system-specific `Learner` object: `collab_learner` [https://docs.fast.ai/collab.html#Create-a-Learner](https://docs.fast.ai/collab.html#Create-a-Learner)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`BIWI_HEAD_POSE` (images of people, along with descriptions of their positions),
    `PASCAL_2007`, and `PASCAL_2012` (images, along with corresponding segmentation
    maps for each image) image localization datasets'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'b) Image-specific `DataLoaders` object: `ImageDataLoaders` [https://docs.fast.ai/vision.data.html#ImageDataLoaders](https://docs.fast.ai/vision.data.html#ImageDataLoaders)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) Image-specific `Learner` object: `cnn_learner` [https://docs.fast.ai/vision.learner.html#cnn_learner](https://docs.fast.ai/vision.learner.html#cnn_learner)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) Utilities to examine the dataset: many convenient functions that make it
    easy to render individual images and categories of images'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a lot to digest in this section, but don''t worry. Each application-specific
    aspect of fastai gets its own dedicated chapter in which we''ll cover the details
    of the application-specific features (datasets, `DataLoaders`, `Learners`, and
    others) and show you how to harness these features to create deep learning solutions
    for each application area. The important thing to note is that fastai provides
    these application-specific features to make it easy for you to create applications
    across all four of the areas: **tabular data**, **text data**, **recommender systems**,
    and **computer vision**.'
  prefs: []
  type: TYPE_NORMAL
- en: Working with PyTorch tensors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout most of this book, the focus will be on the features provided by
    the fastai framework. However, some of the solutions that we'll review also exploit
    general Python libraries (such as the `pandas` library for deep learning applications
    with tabular data) as well as aspects of PyTorch, the low-level deep learning
    framework upon which fastai is built. To give you a small taste of PyTorch, in
    this section we'll go through some basic examples of using tensors, the PyTorch
    structure for multidimensional matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are already familiar with NumPy arrays, then you will have a good basis
    for examining PyTorch tensors because tensors play much the same role for PyTorch
    as NumPy arrays do for general-purpose Python applications. If you are not familiar
    with NumPy arrays or it''s been a while since you have had a chance to use them,
    take a bit of time to review them—for example, by going through this tutorial:
    [https://numpy.org/doc/stable/user/quickstart.html](https://numpy.org/doc/stable/user/quickstart.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Once you have completed your NumPy array review, ensure that you have followed
    the steps to set up fastai in Gradient and confirm that you can open the PyTorch
    tensor walkthrough notebook (`pytorch_tensor_walkthrough.ipynb`) in the `ch1`
    directory. If you choose to use Colab, ensure that you have selected **Runtime**
    | **Change runtime type** and have selected **GPU** as the hardware accelerator.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we''ll go through some basic operations with PyTorch tensors:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `pytorch_tensor_walkthrough.ipynb` PyTorch tensor walkthrough notebook
    in the `ch1` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the first four cells of the notebook to import the necessary libraries and
    define three tensors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) Note that since this notebook only makes use of PyTorch and doesn''t need
    any fastai libraries, we only need one `import` statement:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) Define `a`: a two-dimensional 5x7 tensor with value `1` in every position:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.36 – Defining a 5x7 tensor'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_01_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.36 – Defining a 5x7 tensor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) Define `b`: a two-dimensional 5x7 tensor with `0`s in every position except
    a diagonal of `1`s:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.37 – Defining a 5x7 tensor with 1s on the diagonal'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_01_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.37 – Defining a 5x7 tensor with 1s on the diagonal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) Define `c`: a two-dimensional 5x5 identity tensor:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.38 – Defining a 5x5 identity tensor'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_01_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.38 – Defining a 5x5 identity tensor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, run the cells in the `0`th row of tensor `b`:![Figure 1.39 – The 0th row
    of tensor b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_01_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.39 – The 0th row of tensor b
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) Get the `0`th element of the `0`th row:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.40 – Element [0,0] of tensor b'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_01_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.40 – Element [0,0] of tensor b
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) Get rows starting at row 2 to the end:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.41 – Rows of tensor b from row to the end'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_01_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.41 – Rows of tensor b from row to the end
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the cells in the `a` and `b`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.42 – Adding two tensors'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_42.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.42 – Adding two tensors
  prefs: []
  type: TYPE_NORMAL
- en: 'b) Attempt to multiply tensors `a` and `c`—note that you get an error because
    the tensors do not have compatible dimensions. To multiply two two-dimensional
    tensors, the second dimension of the first tensor has to be identical to the first
    dimension of the second vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.43 – Attempt to multiply two incompatible tensors generates an error'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_43.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.43 – Attempt to multiply two incompatible tensors generates an error
  prefs: []
  type: TYPE_NORMAL
- en: 'c) Define a 7x7 identity tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.44 – Defining a 7x7 identity tensor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_44.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.44 – Defining a 7x7 identity tensor
  prefs: []
  type: TYPE_NORMAL
- en: 'd) Now, multiply tensors `a` and `d`—this time, there is no error because the
    tensors'' dimensions are compatible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.45 – Multiplying two compatible tensors'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_45.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.45 – Multiplying two compatible tensors
  prefs: []
  type: TYPE_NORMAL
- en: 'e) Create a new tensor that is the transpose of tensor `a` (that is, the columns
    of tensor `a` become the rows of the new tensor):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.46 – Transposing a tensor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_46.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.46 – Transposing a tensor
  prefs: []
  type: TYPE_NORMAL
- en: 'f) Multiply the transpose of tensor `a` with tensor `c` — while tensor `a`
    multiplied by tensor `c` caused an error, there will be no error this time because
    the tensors'' dimensions are compatible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.47 – Multiplying two compatible tensors'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_47.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.47 – Multiplying two compatible tensors
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have had your first direct taste of PyTorch, the framework
    that underlies fastai.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section you got a taste of tensors, one of the building blocks of PyTorch.
    If you are familiar with the relationship between Keras and TensorFlow, you can
    think of the relationship between fastai and PyTorch being similar. Similar to
    the way that Keras is a high-level **application programming interface** (**API**)
    for TensorFlow, fastai is built on top of PyTorch and abstracts away some of the
    complexity of PyTorch (for example, by making reasonable assumptions about defaults).
    With fastai, you can focus on creating deep learning applications without having
    to worry about all the details.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are curious and want to get an overview of PyTorch now, you can check
    out this introductory tutorial: [https://pytorch.org/tutorials/beginner/nlp/pytorch_tutorial.html](https://pytorch.org/tutorials/beginner/nlp/pytorch_tutorial.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Contrasting fastai with Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll cover some of the similarities and differences between
    fastai and Keras. While both frameworks provide high-level APIs for deep learning,
    there are some significant differences between them in terms of their architecture
    and approach to the problem, as well as differences between the communities using
    each. By contrasting these two frameworks, you will get a clearer idea of the
    strengths of fastai and be better prepared for the detailed examinations of fastai
    applications that are coming in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you have used Keras recently, then you''ll be in good shape to benefit from
    this section. If you haven''t used Keras before, or it''s been a while since you''ve
    used it, I recommend that you take a brief look at this tutorial so that you have
    a fresh overview of Keras: [https://keras.io/getting_started/intro_to_keras_for_engineers/](https://keras.io/getting_started/intro_to_keras_for_engineers/).'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will compare a Keras approach to the MNIST problem with
    the fastai MNIST solution that we reviewed earlier in this chapter. You can see
    the Keras approach in the `ch1` directory of the repository, in `keras_sequential_api_hello_world.ipynb`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, by default, you will not be able to execute this Keras notebook in
    your fastai Gradient instance because the required TensorFlow and Keras libraries
    are not installed in that instance. You will be able to run the Keras MNIST notebook
    in Colab, if you have that set up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compare the library `import` statements. Both MNIST examples require a similar
    number of `import` statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) Keras:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) fastai:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compare the setup and definition of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) Keras—The MNIST dataset is *oven ready* with Keras. Keras offers seven such
    datasets—for details, see [https://keras.io/api/datasets/](https://keras.io/api/datasets/).
    By comparison, fastai has over 25 such datasets. For details, see [https://course.fast.ai/datasets](https://course.fast.ai/datasets):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) fastai—This requires a `setup` statement that Keras doesn''t need (although
    this `setup` statement saves a step in the Drive mounting process when you are
    using Colab) but only requires two statements to define the dataset, versus three
    statements for Keras:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compare the model definition statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) Keras—Every layer in the model needs to be explicitly spelled out:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) fastai—A single statement defines the model. The ability to specify the
    architecture (in this case, `resnet18`) with a single parameter streamlines the
    model definition. Note that the architecture specified for the fastai model is
    not identical to the architecture for the Keras model. For example, if you compared
    the layers listed in the output of the `learn.summary()` cell in this notebook
    with the layers specified in the definition of the Keras model, you can see that
    the fastai model has many more layers than the Keras model. In sum, the contrast
    between the fastai and Keras solutions for MNIST is not strictly *apples to apples*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compare the `fit` statements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) Keras:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) fastai:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compare the performance of the Keras model and the fastai model. Again, note
    that because of differences between the models (including the architecture and
    details of the fitting process), it''s not possible to draw a general conclusion
    from the differences in performance between the two models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) Keras:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'b) fastai:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.48 – Results of training the MNIST model in fastai'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_01_48.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.48 – Results of training the MNIST model in fastai
  prefs: []
  type: TYPE_NORMAL
- en: You have now seen a quick comparison of fastai and Keras for the same MNIST
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What does this comparison between a Keras solution for MNIST and a fastai solution
    for MNIST tell us?
  prefs: []
  type: TYPE_NORMAL
- en: Keras offers far fewer *oven-ready* datasets than fastai, and the fastai statements
    for defining such datasets are simpler. This is a critical benefit for fastai,
    particularly for beginners. It really helps in the process of learning about deep
    learning to have a wide variety of datasets that can be ingested easily. fastai
    really delivers on this count thanks to the big and varied set of *oven-ready*
    datasets available with fastai. We'll spend some time in the next chapter taking
    a closer look at these datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other than the model definition, there isn't that much difference in the number
    of lines of code between Keras and fastai for each of the steps in the solution.
    This means that for the MNIST problem, Keras isn't far behind fastai's standard
    of delivering a complete solution with a handful of lines of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model definition is more complex in Keras, primarily because fastai lets
    us define the layers that make up the model with a single architecture parameter,
    whereas we have to explicitly define the layers in Keras. A mitigating factor
    for the complexity of the model definition in Keras is readability. In Keras,
    the layers are explicitly listed. By comparison, in the high-level fastai API,
    the layers are not listed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: fastai offers better usability than Keras by making it possible for users to
    use the high-level fastai API without having to worry about all the explicit details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The statement for fitting the model is simpler in fastai. In addition, fastai
    incorporates best practices in default settings that often result in faster fitting
    times and better performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras benefits from greater transparency because the layers are explicitly listed.
    fastai has superior usability and out-of-the box performance thanks to carefully
    selected defaults for many settings. We are not going to do additional Keras versus
    fastai bakeoffs in this book, but I expect that, based on my experience using
    both Keras and fastai, fastai's benefits would stand out even more in complex
    applications. In addition, fastai has a big advantage because of its large set
    of curated, *oven-ready* datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Test your knowledge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have completed the recipes in this chapter, you can follow the
    next steps to exercise that you have learned:'
  prefs: []
  type: TYPE_NORMAL
- en: Make a copy of the `mnist_hello_world.ipynb` notebook—call it `mnist_hello_world_variations.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update your new copy of the notebook to ingest a variation of the MNIST dataset,
    called `MNIST_SAMPLE`. Which statement will you need to update to ingest this
    dataset rather than the full-blown MNIST curated dataset?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `path.ls()` statement to examine the directory structure of the `MNIST_SAMPLE`
    dataset. How is the output of this statement different from its output for the
    full-blown MNIST dataset?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Keeping in mind the difference in the directory structure of the `MNIST_SAMPLE`
    dataset, update the values of the `train` and `valid` parameters in the following
    statement so that it will work with this dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Again keeping the directory structure in mind, update the following statement
    so that it will work with the `MNIST_SAMPLE` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `MNIST_SAMPLE` dataset is smaller than the full-blown MNIST dataset. Keeping
    this in mind, update the following statements so that they will work with the
    smaller dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that you have updated the notebook to work with the `MNIST_SAMPLE` dataset,
    run the whole notebook to confirm that it can run to the end with no errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Congratulations! If you have completed this section, then you have successfully
    adapted a recipe to work with another curated dataset.
  prefs: []
  type: TYPE_NORMAL
