["```py\nTime (s): 134.3672107196594\n```", "```py\nTime (s): 135.26983547210693\n```", "```py\nTime (s): 134.47382940625321\n```", "```py\nTime (s): 111.36750531196594\n```", "```py\nTime (s): 24.319150686264038\n```", "```py\ninput_transform_fn = mx.gluon.data.vision.transforms.Compose([\nmx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\nmx.gluon.data.vision.transforms.CenterCrop(image_size), mx.gluon.data.vision.transforms.ToTensor(),\nmx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n])\n```", "```py\nTime (s): 38.973774433135986\n```", "```py\nTime (s): 25.39602303504944\n```", "```py\nTime (s): 67.73443150520325\n```", "```py\nTime (s): 23.22727918624878\n```", "```py\nTime (s): 34.58254957199097\n```", "```py\nimport multiprocessing\nmultiprocessing.cpu_count()\n```", "```py\n4\n```", "```py\nInput data type: <class 'numpy.float32'> Model Parameters data type: <class 'numpy.float32'>\n```", "```py\na = mx.nd.array([1/3], dtype=np.float32)\n b = a.astype(np.float16)\nprint(\"1/3 as Float32: {0:.30f}\".format(a.asscalar()))\nprint(\"1/3 as Float16: {0:.30f}\".format(b.asscalar()))\n```", "```py\n1/3 as Float32: 0.333333343267440795898437500000\n1/3 as Float16: 0.333251953125000000000000000000\n```", "```py\ndeeplab_ft_direct_f16.cast('float16')\n```", "```py\ndata  = data.astype('float16', copy=False)\n label = label.astype('float16', copy=False)\n```", "```py\nTraining time for 10 epochs: 594.4833037853241 / Best validation loss: 0.6800425\n```", "```py\nTraining time for 10 epochs: 199.80901980400085 / Best validation loss: nan\n```", "```py\namp.init()\n```", "```py\namp.init_trainer(trainer)\n```", "```py\nwith amp.scale_loss(loss, trainer) as scaled_loss:\nmx.autograd.backward(scaled_loss)\n```", "```py\nTraining time for 10 epochs: 217.64903020858765 / Best validation loss: 0.7082735\n```", "```py\nTraining time for 10 epochs: 218.82141995429993 / Best validation loss: 0.18198483\n```", "```py\nTraining time for 10 epochs: 645.7392318248749 / Best validation loss: 0.16439788\n```", "```py\nctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]\n```", "```py\ndeeplab_ft_direct_f32 = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx_list)\n [...]\ndeeplab_ft_direct_f32.head.initialize(ctx=ctx_list)\n```", "```py\nnum_gpus = len(ctx_list)\n [...]\nbatch_size_per_gpu = 4\nbatch_size = len(ctx_list) * batch_size_per_gpu\n [...]\ntrainer = mx.gluon.Trainer(deeplab_ft_direct_f32.collect_params(), \"sgd\", {\"learning_rate\": 0.5})\n```", "```py\ndata_list   = mx.gluon.utils.split_and_load(data, ctx_list=ctx_list)\n label_list  = mx.gluon.utils.split_and_load(label, ctx_list=ctx_list)\n```", "```py\nwith mx.autograd.record():\noutputs = [model(data_slice) for data_slice in data_list]\nlosses = [loss_fn(output[0], label_slice) for output, label_slice in zip(outputs, label_list)]\nfor loss in losses:\nloss.backward()\ntrainer.step(batch_size)\n```", "```py\ncurrent_loss = sum([l.sum().asscalar() for l in losses])\n```", "```py\nTraining time for 10 epochs: 647.753002166748 / Best validation loss: 0.0937674343585968\n```", "```py\nTraining time for 10 epochs: 177.23532104492188 / Best validation loss: 0.082047363743186\n```", "```py\nPre-processing time (s): 0.12470602989196777\n```", "```py\nData-Loading in GPU time (s): 0.4085373878479004\n```", "```py\n# Epochs & Batch Size\nepochs = 10\nbatch_size = 4\n# Define Optimizer and Hyper Parameters\ntrainer = mx.gluon.Trainer(deeplab_ft_direct_naive.collect_params(), \"sgd\", {\"learning_rate\": 0.1})\n```", "```py\nTraining time for 10 epochs (s): 638.9948952198029 / Best validation loss: 0.09416388\n```", "```py\nPixAcc:  0.9627800347222222\nmIoU  :  0.9070747450272697\n```", "```py\nNumber of CPUs: 16\nNumber of GPUs: 4\n```", "```py\n# Context variable is now a list,\n # with each element corresponding to a GPU device\nctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]\n num_gpus = len(ctx_list)\n```", "```py\np_train_gpu = mx.gluon.data.SimpleDataset(\n    [(data.as_in_context(ctx_list[idx % num_gpus]), label.as_in_context(ctx_list[idx % num_gpus]))\n     for idx, (data, label) in enumerate(pedestrian_train_dataset)])\n p_val_gpu   = mx.gluon.data.SimpleDataset(\n    [(data.as_in_context(ctx_list[idx % num_gpus]), label.as_in_context(ctx_list[idx % num_gpus]))\n     for idx, (data, label) in enumerate(pedestrian_val_dataset)])\n p_test_gpu  = mx.gluon.data.SimpleDataset(\n    [(data.as_in_context(ctx_list[idx % num_gpus]), label.as_in_context(ctx_list[idx % num_gpus]))\n     for idx, (data, label) in enumerate(pedestrian_test_dataset)])\np_train_opt = p_train_gpu.transform(train_val_transform, lazy=False)\n p_val_opt   = p_val_gpu.transform(train_val_transform, lazy=False)\n p_test_opt  = p_test_gpu.transform(test_transform, lazy=False)\n```", "```py\nto_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n```", "```py\n# AMP\namp.init()\n```", "```py\namp.init_trainer(trainer)\n```", "```py\nwith amp.scale_loss(losses, trainer) as scaled_losses: mx.autograd.backward(scaled_losses)\n```", "```py\n# Context variable is now a list,\n # with each element corresponding to a GPU device\nctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)\n num_gpus = len(ctx_list)\n```", "```py\nbatch_size = len(ctx_list) * batch_size_per_gpu\n```", "```py\ndata_list  = mx.gluon.utils.split_and_load(data , ctx_list=ctx_list)\nlabel_list = mx.gluon.utils.split_and_load(label, ctx_list=ctx_list)\n```", "```py\noutputs = [model(data_slice) for data_slice in data_list]\nlosses = [loss_fn(output[0], label_slice) for output, label_slice in zip(outputs, label_list)]\n```", "```py\nwith amp.scale_loss(losses, trainer) as scaled_losses:\nmx.autograd.backward(scaled_losses)\n```", "```py\nPre-processing time (s): 0.10713815689086914\n```", "```py\nData-Loading in GPU time (s): 0.18216562271118164\n```", "```py\n# Epochs & Batch Size\nepochs = 10\nbatch_size_per_gpu = 4\nbatch_size = len(ctx_list) * batch_size_per_gpu\n# Define Optimizer and Hyper Parameters\ntrainer = mx.gluon.Trainer(deeplab_ft_direct_opt.collect_params(), \"sgd\", {\"learning_rate\": 0.5})\n```", "```py\nTraining time for 10 epochs: 59.86336851119995 / Best validation loss: 0.08904324161509672\n```", "```py\nPixAcc:  0.9679262152777778\nmIoU  :  0.9176786683400912\n```", "```py\nPre-processing time (s): 2.697735548019409\n```", "```py\nData-Loading in GPU time (s): 27.328779935836792\n```", "```py\n# Epochs & Batch Size\nhparams.epochs = 5\nhparams.lr = 0.00003\n# hparam.batch_size = 256\n```", "```py\nTraining time for 5 epochs: 11406.558312892914 / Best validation loss: 1.4029905894300159\n```", "```py\nWMT16 test loss: 1.28; test bleu score: 27.05\n```", "```py\nQualitative Evaluation: Translating from English to German\nExpected translation:\n Ich lerne neue Dinge jeden Tag.\n In English:\n I learn new things every day.\n The German translation is:\n Immer wieder erfährt ich Neues.\n```", "```py\nNumber of CPUs: 16\nNumber of GPUs: 4\n```", "```py\n# Context variable is now a list,\n # with each element corresponding to a GPU device\nctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]\n num_gpus = len(ctx_list)\n```", "```py\nwmt2016_train_data_processed_gpu = mx.gluon.data.SimpleDataset([(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) for idx, (data, label) in enumerate(wmt2016_train_data_processed)])\nwmt2016_train_data_processed_gpu = mx.gluon.data.SimpleDataset([(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) for idx, (data, label) in enumerate(wmt2016_train_data_processed)])\nwmt2016_val_data_processed_gpu = mx.gluon.data.SimpleDataset([(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) for idx, (data, label) in enumerate(wmt2016_val_data_processed)])\nwmt2016_ test _data_processed_gpu = mx.gluon.data.SimpleDataset([(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) for idx, (data, label) in enumerate(wmt2016_ test _data_processed)])\n```", "```py\n# AMP\namp.init()\n```", "```py\namp.init_trainer(trainer)\n```", "```py\n# Context variable is now a list,\n # with each element corresponding to a GPU device\nctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]\n num_gpus = len(ctx_list)\n```", "```py\nbatch_size = len(ctx_list) * batch_size_per_gpu\n```", "```py\nsrc_seq_list = mx.gluon.utils.split_and_load(src_seq, ctx_list=ctx_list, even_split=False)\n tgt_seq_list = mx.gluon.utils.split_and_load(tgt_seq, ctx_list=ctx_list, even_split=False)\n src_valid_length_list = mx.gluon.utils.split_and_load(src_valid_length, ctx_list=ctx_list, even_split=False)\n tgt_valid_length_list = mx.gluon.utils.split_and_load(tgt_valid_length, ctx_list=ctx_list, even_split=False)\n```", "```py\nout_slice, _ = wmt_transformer_model_ft_direct_opt(\nsrc_seq_slice,\ntgt_seq_slice[:, :-1],\nsrc_valid_length_slice,\ntgt_valid_length_slice - 1)\nloss = loss_function(out_slice, tgt_seq_slice[:, 1:], tgt_valid_length_slice - 1)\n```", "```py\nPre-processing time (s): 50.427586793899536\n```", "```py\nData-Loading in GPU time (s): 72.83465576171875\n```", "```py\nData-Loading in CPU with Gluon DataLoaders time (s): 24.988255500793457\n```", "```py\n# Epochs & Batch Size\nhparams.epochs = 5\nhparams.lr = 0.0001\n# hparams.batch_size = num_gpus * 256\n```", "```py\nTraining time for 5 epochs: 1947.1244320869446 / Best validation loss: 1.2199710432327155\n```", "```py\nWMT16 test loss: 1.27; test bleu score: 28.20\n```", "```py\nQualitative Evaluation: Translating from English to German\nExpected translation:\n Ich lerne neue Dinge.\n In English:\n I learn new things every day.\n The German translation is:\n Ich lerne jedes Mal Neues.\n```"]