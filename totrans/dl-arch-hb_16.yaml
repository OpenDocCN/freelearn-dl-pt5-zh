- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Governing Deep Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deploying a model is just the beginning of its journey. Once it’s out in the
    real world, it’s like a living thing – it requires efficient use to make the most
    of it, upgrades to stay sharp, care to perform consistently well, and, eventually,
    a graceful exit. Imagine a car on the road: you start driving, but you also need
    to use the car effectively, fuel it, maintain it, and eventually replace it or
    its components. The same goes for deep learning models in action.'
  prefs: []
  type: TYPE_NORMAL
- en: Model governance acts as the guiding force that oversees the use of a model
    and maintains constant vigilance over its performance and context to ensure the
    continuous, consistent, and dependable delivery of value through the model. In
    the realm of deep learning, model governance is crucial for ensuring that these
    complex models adhere to the highest standards of quality, reliability, and fairness.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter delves into the three fundamental pillars of model governance
    for deep learning models: steering the ship of model utilization, which focuses
    on the appropriate application of deep learning models, keeping a watchful eye
    on its performance on all fronts with model monitoring, and ensuring it stays
    at its best in the ever-evolving landscape of deep learning with model maintenance.
    By implementing a robust model governance framework, deep learning architects
    can effectively manage the challenges posed by these intricate models and harness
    their immense potential to drive valuable insights and decisions in production.
    In this chapter, we will learn about these pillars of model governance in detail.
    *Figure 16**.1* shows a holistic view of the concept of model governance that
    we will explore in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1 – Holistic overview of model governance in the context of concepts
    that will be introduced in this chapter](img/B18187_16_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.1 – Holistic overview of model governance in the context of concepts
    that will be introduced in this chapter
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Governing deep learning model utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Governing a deep learning model through monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Governing a deep learning model through maintenance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter covers a practical example of monitoring metrics and setting up
    alerts, leveraging the code from the previous tutorial in [*Chapter 15*](B18187_15.xhtml#_idTextAnchor217),
    *Deploying Deep Learning Models in Production*. This tutorial requires you to
    have a Linux machine with an NVIDIA GPU device ideally in Ubuntu with Python 3.10
    and the `nvidia-docker` tool installed. Additionally, we will require the following
    Python libraries to be installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`numpy`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transformers==4.21.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nvidia-tensorrt==8.4.1.5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`torch==1.12.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transformers-deploy`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tritonclient`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code files are available on GitHub: [https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_16](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_16).'
  prefs: []
  type: TYPE_NORMAL
- en: Governing deep learning model utilization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Model utilization, the first pillar of model governance for deep learning models,
    is crucial for the responsible and ethical deployment of these sophisticated tools.
    In this section, we will explore the integral aspects of model utilization, including
    guardrail filters, accountability, compliance, validation, shared access, transparency,
    and decision support systems. By comprehensively addressing these aspects, deep
    learning architects can ensure effective model utilization that maximizes value
    from the model while mitigating potential risks and unintended consequences. Let’s
    dive deeper into these aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Guardrail filters**: These play a crucial role in ensuring that models operate
    within established boundaries, minimizing the risks associated with inaccurate
    or harmful predictions. These filters help maintain the original purpose of the
    models. While the objectives of using a model’s predictions can significantly
    vary based on individual use cases, several common types of guardrails are widely
    applicable:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prevent harmful use on a per-prediction basis**: Harmful use of the model
    or its predictions can encompass a wide range of issues, including biases related
    to sensitive attributes, malicious attacks such as adversarial attacks, and harassment-related
    text generation. *Figure 16.2* shows the OpenAI ChatGPT’s way of displaying its
    predictions after the guardrail of harmful use has been triggered.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 16.2 – OpenAI ChatGPT’s harmful use guardrail triggered response](img/B18187_16_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.2 – OpenAI ChatGPT’s harmful use guardrail triggered response
  prefs: []
  type: TYPE_NORMAL
- en: '**Prevent usage of unconfident predictions on a per-prediction basis**: To
    maintain the reliability of a model’s output, it is essential to prevent the use
    of predictions with low confidence. The issue, however, is that regression model
    predictions do not have prediction values that could be treated as a confidence
    score. Additionally, although classification model prediction typically has a
    softmax operation applied to allow predictions to add up to 1, it is not properly
    calibrated toward actual statistical probabilities. *Conformal predictions* are
    a more battle-tested statistical and robust technique to provide a robust confidence
    interval for each prediction, allowing for a better understanding of the model’s
    certainty. Additionally, input data that goes out of training data bounds or has
    drifted may deteriorate the model’s performance and can be treated as a special
    case of unconfident predictions without even generating the predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prevent the use of an inaccurate model**: By continuously monitoring and
    assessing a model’s accuracy performance, one can determine when to stop the usage
    of a model, especially in high-risk use cases, and proceed to perform model maintenance,
    which is to retrain and update the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mitigating bias**: Guardrail filters can help minimize bias related to sensitive
    attributes, such as race, gender, or ethnicity. By preventing the model from producing
    predictions that may lead to discriminatory outcomes, guardrail filters contribute
    to a more equitable and fair application of these technologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prevent known data conditions that can negatively affect the model’s performance**:
    For example, face recognition systems should only predict on frontal, unobstructed
    faces without masks or glasses. Adversarial performance analysis, introduced in
    *Chapter 14*, *Analyzing Adversarial Performance*, must be performed prior to
    deployment to identify the traits that could negatively affect the model’s performance.
    During deployment, appropriate thresholds of the identified traits that are estimated
    to deteriorate the model’s performance can be applied as a guardrail for prediction
    prevention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement human-in-the-loop oversight only for critical predictions**: In
    high-stakes scenarios, such as medical drug recommendations, it is vital to involve
    human experts in the decision-making process, and higher-level experts when specific
    predictions are made.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accountability**: This entails the clear assignment of roles and responsibilities,
    and addresses questions related to model ownership, compliance with regulations,
    training data, and the approval process at each stage of development. Accountability
    is a critical aspect of AI and machine learning systems, ensuring that there is
    a clear understanding of roles, responsibilities, and ownership throughout the
    model’s life cycle. It encompasses the following two facets:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model ownership**: Clearly defining who owns the model is essential for establishing
    accountability. This includes determining the parties responsible for the model’s
    development, maintenance, and updates, as well as those who will be held liable
    for any adverse consequences resulting from the model’s use. Some additional key
    considerations related to model ownership are the following:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling personnel changes**: In the event of a model owner’s departure or
    role change within the organization, a well-defined process should be in place
    to transfer ownership and responsibilities to another suitable individual or team.
    This ensures that the model continues to receive proper oversight and maintenance
    and that accountability remains clear.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shared access and default admin roles**: To promote effective model governance
    and minimize potential disruptions, it is vital to establish shared access and
    default admin roles. This allows multiple team members to oversee the model’s
    development, maintenance, and updates, reducing the dependency on a single individual.
    Such shared access should be accompanied by clear guidelines on roles and responsibilities
    to avoid confusion and maintain accountability.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling open source models**: Proprietary models are typically developed
    within a single organization, which makes it straightforward to deal with accountability
    with the considerations discussed previously. In open source models, the development
    process often involves multiple contributors from diverse backgrounds, which makes
    establishing accountability more challenging. To address this, it is essential
    to provide clear guidelines for contributions, maintain transparent documentation
    of the model’s development history, and implement community-driven governance
    structures or assign a core group of maintainers to oversee the project. As an
    alternative, a key model owner can be established in an organization that assumes
    all responsibility for using the open source model in that organization.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictions ownership**: Predictions ownership in high-risk use cases is
    crucial for maintaining accountability and ensuring accurate, reliable outcomes.
    Since raw predictions may not always be easily understandable, post-processing
    steps are often needed to convert them into more digestible insights or nested
    outcomes. Approvals of the outcomes at each post-processing stage further ensure
    the quality and relevance of the final outcomes, fostering the responsible and
    effective use of AI and machine learning models.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model and prediction transparency**: This is essential for fostering trust
    and understanding in AI systems. This entails offering clear explanations and
    relevant information about the model’s development, including its architecture,
    training data, and methodology. Providing such insights enables users to grasp
    how the model generates predictions and ensures that the AI system aligns with
    ethical and responsible practices, ultimately contributing to better decision-making
    and more reliable outcomes. These can be the same explanations that were used
    to understand and compare different models and predictions during the model development
    stage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision support systems**: This involves building interfaces or platforms
    that enable decision-makers to interact with model predictions and insights. This
    includes providing user-friendly dashboards, reports, and visualization tools
    in the system while incorporating business rules, regulations, and policies into
    the decision-making process. This is again useful in high-risk use cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we will dive into the second component of model governance, which is about
    monitoring deployed models.
  prefs: []
  type: TYPE_NORMAL
- en: Governing a deep learning model through monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model monitoring is essential for maintaining the performance, reliability,
    and fairness of deep learning models throughout their life cycle. As data landscapes
    and business requirements evolve, continuous monitoring enables the early detection
    of issues such as model drift, performance degradation, and potential biases,
    thereby ensuring the consistent delivery of accurate and valuable predictions.
    This process involves the collection and analysis of key performance metrics,
    the ongoing evaluation of model outputs against ground-truth data, and the identification
    of any emerging trends that could impact the model’s efficacy. By implementing
    a robust model monitoring framework, deep learning architects can proactively
    address challenges and make informed decisions about model updates, refinements,
    and retraining, ultimately optimizing the model’s value and mitigating risks associated
    with its deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Model monitoring holds value only when it results in corrective actions addressing
    deteriorating performance or concerning conditions. Thus, the objective of monitoring
    should be to identify and rectify undesirable behavior. The actions that can be
    taken are more broadly grouped into the third pillar of model governance, called
    model maintenance, which we will discuss separately in the next section. Now,
    let’s delve into the various categories and specific metrics for a deployed machine
    learning model, accompanied by examples of conditions that can prompt the initiation
    of model maintenance procedures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model accuracy-based performance metrics**: These are the typical model evaluation
    metrics we introduced more comprehensively in [*Chapter 10*](B18187_10.xhtml#_idTextAnchor161),
    *Exploring Model Evaluation Methods*, such as accuracy, recall, precision, F1
    score, AUC-ROC, and log-loss. The same metrics that were used for model evaluation
    in the model development and delivery model insights stage should be reused here.
    These metrics can be monitored when the true labels can be obtained at a future
    time, in two ways:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Naturally**: When the use case is a time-series use case to predict a future
    target or the target is just not immediately accessible to the model owner, the
    targets can be obtained in the future naturally'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manual labeling**: Labeling is recommended to be carried out in a regular
    cadence with a sample of the historical production input data to verify the validity
    of the model performance'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditions that can cause a trigger of model maintenance here are using the
    same use case validity thresholds that were referred to in the model building
    and evaluation experimentation process. As emphasized in *Chapter 10*, *Exploring
    Model Evaluation Methods*, this threshold should ideally be tied to the business
    metrics threshold in some way.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Data quality metrics**: Data quality metrics provide essential insights into
    the validity, characteristics, and consistency of the input data. Data quality
    is linked to the accuracy and bias performance of the model and thus any deviations
    from the norm can potentially cause accuracy degradations. Examples of such metrics
    are the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Missing or incomplete data count**: This refers to the number of instances
    in the dataset where the data is either absent or not fully available. This can
    impact the accuracy and reliability of the model, as it may not have enough information
    to infer a prediction from.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Invalid data bounds count**: This refers to the instances where data values
    fall outside the acceptable or expected range. This can lead to incorrect model
    predictions, as the model may infer from incorrect data points that were not learned
    from.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outlier and anomaly indicator metrics**: They are used to identify unusual
    or extreme data points that deviate significantly from the overall pattern or
    trend in the dataset. This has the same root cause as invalid data bounds.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data drift**: This occurs when the distribution of input features in the
    data changes over time. This can happen due to various reasons, such as evolving
    data sources, changing user behavior, or external factors influencing the data
    generation process. Data drift may lead to a decline in model performance as the
    model was trained on a different distribution of data and may not generalize well
    to the new distribution. Monitoring for data drift helps in identifying when retraining
    or adjusting the model is necessary to maintain its accuracy and effectiveness.
    In [*Chapter 17*](B18187_17.xhtml#_idTextAnchor247), *Managing Drift Effectively
    in a Dynamic Environment*, we will dive into the techniques that we can use to
    detect data drift focused on deep learning-specific data inputs.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Concept drift**: It refers to the change in the relationship between input
    features and the target variable over time. This change can cause a previously
    accurate model to degrade in performance as the model’s learned patterns no longer
    align with the evolving relationships. This is also related to the label consistency
    metric introduced in the data quality section in [*Chapter 1*](B18187_01.xhtml#_idTextAnchor015),
    *Deep Learning* *Life Cycle*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System performance metrics**: These metrics help ensure that the deployed
    model meets the operational requirements. The key subgroups under system performance
    metrics are the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inference latency**: Refers to the measurement of the time taken by the model
    to generate predictions or output from the input data. Low latency is crucial
    for real-time applications and user experiences, as it ensures the model provides
    quick and timely results.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput**: Measures the number of predictions or outputs the model can
    generate within a specific time frame. High throughput is vital for handling large-scale
    data processing and maintaining the desired level of performance, especially in
    high-demand scenarios.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource utilization**: Evaluates the efficiency of resource usage, such
    as CPU, memory, and storage, by the model during its operation. Optimizing resource
    utilization ensures that the model can run efficiently on the available infrastructure,
    reducing costs and allowing for better scalability.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Queueing delay and request counts**: Queueing delay refers to the waiting
    time experienced by each request before being processed by the deployed deep learning
    model. Monitoring the queueing delay and the number of requests can help identify
    potential bottlenecks in the system and optimize the model’s capacity to handle
    multiple requests simultaneously.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert and incident metrics**: These metrics help ensure timely identification
    and resolution of problems, enabling optimal system performance. They are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert frequency**: This metric refers to the number of alerts generated over
    a specific time period, indicating potential issues or anomalies in the system.
    Monitoring alert frequency helps identify patterns and trends, enabling proactive
    measures to prevent or mitigate recurring problems.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert severity**: This measures the degree of impact an issue has on overall
    system performance. By categorizing alerts based on severity, it is possible to
    prioritize and address the most critical issues first, ensuring efficient use
    of resources and minimizing negative impacts on the system.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incident resolution time**: This is the time taken to address and resolve
    incidents arising from alerts. Tracking this metric helps evaluate the effectiveness
    of the incident response process and identify areas for improvement, ultimately
    leading to faster resolution times and better system performance.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model fairness and bias metrics**: The same metrics that were introduced
    in [*Chapter 13*](B18187_13.xhtml#_idTextAnchor196), *Exploring Bias and Fairness*,
    to compare different models in development, can also be applied to monitor model
    fairness on a deployed model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business metrics**: Monitoring business-related metrics is crucial for evaluating
    the impact of a deployed deep learning model on the organization’s goals and ensuring
    its alignment with business objectives. Not everything can be monitored with numbers,
    so figure out the components that are quantifiable. Here are some metrics to consider:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Key Performance Indicators** (**KPIs**): Identify and track KPIs that are
    directly influenced by the model’s predictions, such as revenue, customer satisfaction,
    return on investment, or operational efficiency. This helps assess the model’s
    overall contribution to the business.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User adoption and engagement**: Monitor how users interact with the model,
    including usage patterns, frequency, and feedback. This can provide insights into
    the model’s relevance, ease of use, and overall effectiveness in addressing user
    needs.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporating the monitoring of the various metric groups not only provides
    a comprehensive view of deep learning model performance, reliability, and fairness
    but also facilitates the identification of emerging trends and patterns. By closely
    monitoring these metrics, potential issues, such as model drift, performance degradation,
    and biases, can be proactively addressed, ensuring consistent delivery of accurate
    predictions. This also means that analyzing patterns from the monitored metrics
    is crucial in developing improvement plans to enhance deep learning model performance
    and address any potential issues.
  prefs: []
  type: TYPE_NORMAL
- en: To effectively analyze and consume the metrics that are monitored, it is recommended
    to consolidate the key metrics in a comprehensive dashboard, which allows for
    easy tracking and assessment of the model’s overall health, and ultimately enhances
    the monitoring process. Grafana, a popular open source analytics and monitoring
    platform, can effectively meet these requirements by offering a variety of features
    and integrations. As we move forward, we will explore a practical tutorial on
    monitoring deep learning models by using NVIDIA Triton Inference Server, Prometheus,
    and Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring a deployed deep learning model with NVIDIA Triton Server, Prometheus,
    and Grafana
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NVIDIA Triton Server hosts configured metrics via a REST HTTP API in Prometheus
    format, offering real-time insights without persisting historical data. To persist
    metrics data over time, Prometheus needs to be configured to connect with NVIDIA
    Triton Server. While Prometheus tracks and logs metrics over time, it lacks visualization
    capabilities. This is where Grafana comes in. It’s a platform that can leverage
    Prometheus-logged data to create dynamic dashboards with custom graphs and tables.
    Prometheus conveniently shares its logged information through a separate REST
    HTTP API, facilitating Grafana’s seamless connectivity. Additionally, Grafana
    allows alert rules to be set up reliably.
  prefs: []
  type: TYPE_NORMAL
- en: The first step in monitoring is to plan the metrics that we want to monitor,
    which we will discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing metrics to monitor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Any deployed model hosted through NVIDIA Triton Server will by default support
    a variety of standard metrics. These metrics are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inference request metrics**: Success count, failure count, inference count,
    and execution count'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPU-related metrics**: Power usage, power limit, energy consumption, GPU
    utilization, GPU total memory, and GPU used memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CPU-related metrics**: CPU utilization, CPU total memory, and CPU used memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response cache metrics**: Cache hit count, cache miss count, cache hit time,
    and cache miss time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that these metrics can be manually disabled. In this practical example,
    we will be leveraging the deployed language model implementation from the previous
    chapter in using NVIDIA Triton Server and additionally using the Prometheus and
    Grafana tools. The default standard metrics that NVIDIA Triton Server logs are
    useful, but we also need potential custom metrics that can be useful for a business
    and are specific to a language model. It is well documented that NVIDIA Triton
    Server supports custom metrics through their C API, which means you need to develop
    C code! However, a fairly new way to support custom metrics, since NVIDIA Triton
    Server version 23.05, is that you can define custom metrics for NVIDIA Triton
    Server using Python! We will be exploring this new feature in our practical tutorial,
    where we will be exploring the following custom metrics for a language model that
    can be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Number of tokens processed**: The larger the input data, the longer a request
    can take'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of tokens generated**: The larger the number of output tokens, the
    longer a request can take'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flesch reading score**: This is a reading comprehension metric that measures
    how well a text can be understood, which can be a useful business metric, as generated
    text needs to be well understood to be useful'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we are ready to dive into the practical example.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking and visualizing the chosen metrics over time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before we start, make sure you have installed `nvidia-docker`, Prometheus,
    Node Exporter, and Grafana version v10.0.3\. Also, make sure Prometheus and Grafana
    are callable from any location in the command line. Let’s start the process in
    a step-by-step manner, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We are leveraging the code from [*Chapter 15*](B18187_15.xhtml#_idTextAnchor217),
    *Deploying Deep Learning Models to Production*. The first change that is needed
    here is that we will make changes on top of `TritonPythonModel` in the `model.py`
    file. The Custom Metrics API in Python from NVIDIA allows you to define and log
    metrics directly in the three methods that you can define in `TritonPythonModel`.
    These methods are `initialize`, `execute`, and `finalize`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, the additional libraries that we will use are `textstat` and `nltk`,
    which will be used to compute the readability score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first step is to initialize the metric logging instance in the `initialize`
    method. Prometheus supports four metric types: counters for increasing values,
    gauges for fluctuating values, histograms for observing value distribution, and
    summaries for tracking quantiles in data. The three custom metrics we plan to
    add are inherently fluctuating values, and any histograms can be created in Grafana.
    Let’s define the metric family that we will use. You can set the name, description,
    and type of metric for a family. Additionally, you can create many metric families
    for any metric logical group. For our case, all three metrics we plan for are
    business metrics and are fluctuating values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s define the metrics in this metric family:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Conveniently, you can do versioning of the metric in case any logic needs to
    be changed, which makes for a more robust monitoring process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we will be logging the metrics in every execution. We will be defining
    a helper method that will in turn be executed at the end of the `execute` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we will use this helper method under the `execute` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we need to start the NVIDIA Triton Server `nvidia-docker` instance with
    the same command, which is the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After that, we are in the Docker environment, where the next step is to install
    the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For production usage, please be sure to create a Docker image where all the
    libraries are fixed, and you don’t need to manually install libraries anymore.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can execute the `python triton_client.py` command in the command line
    and get your predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The default metrics and the custom metrics are immediately hosted in the URL
    `http://localhost:8002/metrics`, where you can view the real-time metrics in text
    form. `localhost` can be replaced with the IP of your remote server if you are
    using one. The following snippet shows the real-time Prometheus-formatted metrics
    that can be found at the preceding URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As these are only real-time metrics, we need to set up a local server or use
    an online Prometheus server. In this step, we will opt for a locally hosted Prometheus
    server where the following commands need to be run in the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we need to add the NVIDIA Triton Server endpoint into the Prometheus configuration
    file to track metrics. To do that, execute `sudo gedit /etc/prometheus/prometheus.yml`
    in the command line and add the following job details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With that, Prometheus is all set up to log metrics from NVIDIA Triton Server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Prometheus hosts its web app by default with port `9090`. So, accessing the
    link `localhost:9090` in a web browser will take you to the Prometheus home page.
    Going to the **Status** tab and clicking on **Targets** in the dropdown will show
    the following screenshot, which verifies that the Triton endpoint is being tracked.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.3 – Prometheus web app home page on the left and targets that Prometheus
    is tracking and polling metrics from on the right](img/B18187_16_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.3 – Prometheus web app home page on the left and targets that Prometheus
    is tracking and polling metrics from on the right
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus by default doesn’t include user account enforcement but it can be
    configured to be enforced.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will set up Grafana to connect to the locally hosted Prometheus instance.
    First, we have to start up the Grafana service by executing the following command
    in the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 16.4 – Screenshots showing how to navigate to the Add data source
    page in the Grafana web app](img/B18187_16_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.4 – Screenshots showing how to navigate to the Add data source page
    in the Grafana web app
  prefs: []
  type: TYPE_NORMAL
- en: Next, click on Prometheus as the data source, where you will be presented with
    the screen shown in *Figure 16**.5 (a)*. Set the Prometheus default hosted web
    app link to `http://localhost:9090` and click on **Save & Test**. This should
    result in the success screen shown in *Figure* *16**.5 (b)*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.5 – Grafana Prometheus data source settings tab in (a) and successfully
    created screen (b)](img/B18187_16_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.5 – Grafana Prometheus data source settings tab in (a) and successfully
    created screen (b)
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, you will see that the data source has been created as shown in *Figure
    16**.6 (a)*. At this point, we will be able to create a dashboard to visualize
    the metrics we are monitoring. Grafana allows you to create dashboards in three
    ways: importing through its publicly shared dashboard IDs, importing through an
    exported dashboard JSON file, and creating a new dashboard. In Grafana, you can
    create many types of visualizations manually using the in-built visualization
    UI builder system or the **PromQL**-based visualizations and choose how you want
    them to be displayed. However, in this tutorial, we will be using a ready-made
    dashboard with visualizations by importing it through a dashboard JSON file. To
    do that, navigate to the dashboard page using the same three-line button dropdown
    shown in *Figure 16**.4 (a)*. Once, you are on the dashboard page, click on **New**
    and then on **Import**, as shown in *Figure* *16**.6 (b)*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.6 – Grafana Data sources tab showing the created data source and
    the Dashboards tab showing the dropdown of the New button](img/B18187_16_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.6 – Grafana Data sources tab showing the created data source and the
    Dashboards tab showing the dropdown of the New button
  prefs: []
  type: TYPE_NORMAL
- en: Drag the provided `Triton Inference Server-1692252636911.json` file straight
    into the import area and then connect to the Prometheus database you created,
    and you’ll see the dashboard shown in *Figure 16**.7*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.7 – A custom Grafana dashboard for the monitoring tutorial](img/B18187_16_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.7 – A custom Grafana dashboard for the monitoring tutorial
  prefs: []
  type: TYPE_NORMAL
- en: Note that there were two GPUs in the machine that generated this metric, which
    is why there are two GPU stats. This visualization effectively represents most
    of the default NVIDIA Triton Server metrics, along with the three extra custom
    metrics we added, by displaying them on a graph that captures their historical
    values up to the present moment. However, hardware-resource-specific stats are
    an exception, as they are shown only in real-time.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the component missing from monitoring is to create rules and conditions
    that would be considered an alarming incident, called the incident alerting component.
    Monitoring deployed deep learning models without alerts is like having a security
    camera but no alarm. You won’t know if something has gone wrong until it’s too
    late to do anything about it. Incidents can include deteriorating model accuracy,
    consistently delayed responses, consistent resource bottlenecks, consistently
    unexpected output variations during the monitoring of deployed deep learning models,
    and hardware failures. Grafana has an in-built alert management, notifications
    management, and contact management system that we will leverage in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up alerts with Grafana
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s go through the steps on how to set up alerts with Grafana:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **Alerting** tab, shown in *Figure 16**.4 (a)*, and then on **Alert
    rules**. You will see the screen shown in *Figure 16**.8*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.8 – Alert rules tab settings for NVIDIA Triton request failure
    alert rule](img/B18187_16_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.8 – Alert rules tab settings for NVIDIA Triton request failure alert
    rule
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will set an alert to trigger when there is any failed NVIDIA
    Triton Server inference request. So, in the same tab, choose the `nv_inference_request_failure`
    metric tab, and set the threshold to a number that is lower than 1 so that a single
    failed request will trigger the alarm. In *Figure 16**.8*, the number is set to
    `0.8`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, set the evaluation interval to be one minute and to raise an alarm only
    if there are consistent request failures for five minutes straight, as shown in
    *Figure 16**.9*. Then, click on the **Save and** **exit** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.9 – Evaluation interval settings for alert rules](img/B18187_16_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.9 – Evaluation interval settings for alert rules
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three possible statuses that alerts in Grafana can have: **Normal**,
    which indicates that the condition wasn’t triggered; **Pending**, which indicates
    that the condition was partially triggered but there isn’t a consistent behavior
    yet; and **Firing**, which indicates that the condition has been consistently
    satisfied and an alarm has been triggered. Now that an alert rule is saved and
    created, you will see the screen shown in *Figure 16**.10 (a)*, where the status
    is **Normal**. *Figure 16**.10 (b)* shows the **Pending** stage, where a failure
    has been detected but is not yet consistent enough to send an alert. *Figure 16**.10
    (c)*, on the other hand, shows the **Firing** stage, where the failure has consistently
    happened per the configured time interval.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.10 – Alert status of Normal in (a), Pending in (b), and Firing
    in (c)](img/B18187_16_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.10 – Alert status of Normal in (a), Pending in (b), and Firing in
    (c)
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure where and who these alerts will be sent to, we’ll work with the
    **Contact points** and **Notification policies** tabs in the **Alerting** section.
    Let’s start by clicking on the **Contact points** tab to set up the individuals
    who will receive notifications. You can even organize these into groups, but for
    simplicity in this tutorial, we’ll have notifications sent to ourselves. Grafana
    offers various contact platform integrations: Alertmanager, Cisco Webex Teams,
    DingDing, Discord, Email, Google Chat, Kafka REST policy, LINE, Microsoft Teams,
    Opsgenie, PagerDuty, Pushover, Sensu Go, Slack, Telegram, Threema Gateway, VictorOps,
    Webhook, and WeCom. To keep things straightforward, we’ll choose a widely available
    integration type: email. Grafana uses the **sSMTP** software for sending emails,
    so ensure you have an email account with credentials set up before proceeding.
    Within the contact points settings, provide your name and email, then click on
    **Test** to generate a test notification to confirm that the credentials are accurate.
    Once you’ve verified that you’ve received the email notification, save your settings.
    Refer to *Figure 16**.11* for an example of the settings interface.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.11 – Contact points tab with email set up](img/B18187_16_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.11 – Contact points tab with email set up
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to link up the contact as part of the default notification policy.
    Proceed to the **Notification policies** tab, click on **Settings**, and change
    the default contact point to be the email contact we set in *step 4*. You will
    then see a similar screen to *Figure 16**.12*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.12 – The default notification policy set up to notify us](img/B18187_16_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.12 – The default notification policy set up to notify us
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are all set up to receive email notifications! As a challenge, try to
    figure out ways you can make the inference server request fail, and if you can’t,
    change the rule to something that will definitely trigger so you can get an example
    actual alert notification come through email. *Figure 16**.13* shows the example
    email that you will get through a mobile phone interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 16.13 – Example triggered alert email notification with the Firing
    status](img/B18187_16_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.13 – Example triggered alert email notification with the Firing status
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have successfully set up a monitoring and alerting system for
    a deployed deep learning model! A notable caveat in this implementation is the
    fact that metrics are bundled up in the same execution as the model. A solution
    to make it decoupled to not increase the runtime for prediction-specific inference
    is to use the C API instead to build the custom metrics. If the time needed to
    get the metrics logged is not crucial, you can also consider hosting another “model”
    in NVIDIA Triton Server that takes in outputs from the prediction-specific model
    and log metrics. NVIDIA Triton Server also provides a tool called `perf_client`,
    which evaluates the runtime of different configurations, helping you optimize
    your system’s performance. Specifically, the tool measures and reports the throughput
    and latency with different load conditions.
  prefs: []
  type: TYPE_NORMAL
- en: However, just having monitoring and alerts doesn’t provide a full picture of
    model monitoring. We need to dive into those numbers, cross-reference them, spot
    connections, and find patterns. It’s like checking the fuel efficiency, tire pressure,
    and engine temperature of a car to ensure a smooth ride.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, alerts alone won’t fix issues. They’re like the car’s warning
    lights – they tell you something’s up, but you still need to pull over, pop the
    hood, and fix the problem. That’s where model maintenance comes in. In the next
    section, we’ll explore how to not only detect issues but also take action to keep
    your model running smoothly and efficiently over time.
  prefs: []
  type: TYPE_NORMAL
- en: Governing a deep learning model through maintenance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics logging, dashboard building, logged metrics analysis, and alerts are
    essential components of model monitoring, but they are only effective when followed
    by appropriate actions, which are covered under model maintenance. Model maintenance
    is akin to a skilled pit crew in a car race, regularly fine-tuning and optimizing
    the performance of deep learning models to keep them running efficiently and effectively.
    Like how a pit crew conducts rapid repairs, refuels, and adjusts the car’s components
    to adapt to changing race conditions, model maintenance involves updating the
    models to account for environmental changes, improving and refining the models
    with new data obtained from feedback loops, and performing incident responses
    on miscellaneous issues. This ensures that the models consistently stay on track,
    deliver valuable insights, and drive informed decision-making in the ever-evolving
    landscape of data and business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Key aspects of model maintenance comprehensively include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Establishing a feedback loop**: Establishing a feedback loop is vital for
    capturing real-world outcomes and validating model predictions, enabling deep
    learning practitioners to identify areas for improvement, and adapting the model
    accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retraining**: Retraining is an essential part of model maintenance, ensuring
    that the model stays up to date with the latest data and trends, thereby maintaining
    its accuracy and relevance. Regular retraining enables the model to learn from
    new insights and adapt to evolving data landscapes, ensuring consistent performance.
    Fortunately, for deep learning models, a fine-tuning process can be employed,
    which is much faster than a full retraining process. Two use cases that highlight
    the importance of frequent updates with model retraining are the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**E-commerce product recommendation**: Consumer preferences and product availability
    change rapidly in e-commerce. To provide relevant product recommendations, deep
    learning models need to be retrained frequently, maybe weekly or even daily, to
    understand the latest trends and customer behavior.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Social media sentiment analysis**: Social media platforms are constantly
    evolving with new trends, hashtags, and user behaviors. To accurately gauge public
    sentiment and opinion, deep learning models need to be retrained frequently, maybe
    quarterly, to account for these changes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incident response handling**: When alerts signal potential issues, it’s vital
    to have a dedicated response team to triage and address the problem promptly.
    This team should be well equipped to investigate the root cause, implement corrective
    measures, and prevent similar issues from recurring in the future. Let’s discover
    response-handling recommendations for different groups of incidents:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data-related incidents**: These incidents occur when the model receives incorrect,
    incomplete, or biased input data. To handle such issues, the response team should
    work closely with the data provider to identify the cause, correct the data, and
    retrain the model as needed.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model performance incidents**: These incidents involve the model generating
    inaccurate or unexpected predictions. Proper handling requires collaboration between
    the model owner (responsible for model creation or approving the model usage)
    and the prediction owner (responsible for approving the usage of the predictions),
    as described in the *Governing deep learning model utilization* section earlier.
    They should analyze the model’s performance, identify potential issues in its
    architecture or training, and implement improvements to ensure better performance
    in the future.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Infrastructure-related incidents**: These incidents are caused by hardware
    or software failures, affecting the model’s deployment environment. The response
    team should work with the infrastructure provider or team to resolve the issue
    and ensure the model runs smoothly.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security incidents**: These incidents involve unauthorized access, data breaches,
    or other malicious activities targeting the model. The response team should follow
    the organization’s security policies, identify the threat, and take appropriate
    measures to mitigate the risk.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance and regulatory incidents**: These incidents occur when the model’s
    output or operation violates legal or regulatory requirements. The response team
    should work with legal and compliance teams to address the violation and modify
    the model to comply with the necessary regulations.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By comprehensively considering model maintenance components shared here, organizations
    can effectively address challenges associated with deployed deep learning models,
    ensuring their continuous improvement and alignment with business requirements.
    Traditionally, these maintenance actions are executed manually after alerts are
    raised. However, it is possible to schedule custom tasks to be executed automatically
    given an alert event. Consider using Apache Airflow to orchestrate your desired
    automated tasks from your model monitoring alerts. Apache Airflow is like a conductor
    for your data tasks, allowing you to choreograph and schedule complex workflows
    in a directed acyclic graph format. It lets you define, automate, and monitor
    sequences of tasks, making sure they happen in the right order and at the right
    time. However, there are some inherent limitations and risks with creating automated
    tasks from model monitoring alerts, which we will briefly explore next.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring limitations and risks of using automated tasks triggered by model
    monitoring alerts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While automating tasks based on model monitoring alerts can save time and resources,
    it also comes with limitations and potential risks that need to be considered
    when implementing such an approach. Some limitations of automating tasks based
    on model monitoring alerts are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complexity of issues**: Some issues may be too complex or nuanced to be handled
    effectively by an automated process. For example, in a deep learning model for
    medical image analysis, an automated task might be triggered to retrain the model
    when the monitoring alerts indicate a drop in accuracy. However, the complexity
    of the issue may stem from an imbalance in the training data, such as an underrepresentation
    of a certain disease, which cannot be resolved by simply retraining the model.
    In this case, automated processes might not be able to effectively address the
    root cause of the problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of context**: Automated tasks may lack the ability to consider the broader
    context of an issue or understand its potential impact on other aspects of the
    system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider a deep learning model that predicts customer churn based on various
    behavioral and demographic factors. An automated task might be set up to send
    promotional offers to customers identified as high risk for churn. However, the
    task may not have the context to consider external factors, such as a recent negative
    publicity event or a widespread service outage, which might be causing a temporary
    increase in churn risk. This lack of context may lead to unnecessary promotional
    offers and an ineffective use of resources.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Inadequate or inappropriate responses**: Automated tasks might not always
    choose the most appropriate action in response to an alert, potentially leading
    to suboptimal outcomes. For example, an AI model monitoring social media posts
    for harmful content may detect a post containing offensive language. An automated
    response system might remove the post or ban the user immediately, without considering
    the possibility of false positives or the post’s broader context (e.g., quoting
    offensive language to criticize it).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As for risks associated with enabling automated tasks with model monitoring
    alerts, they are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Over-reliance on automation**: Relying too heavily on automated tasks can
    lead to a lack of human oversight and expertise in the model maintenance process.
    This may result in overlooking subtle patterns and trends that only human intuition
    can detect, potentially leading to suboptimal model performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inaccurate or premature triggers**: Automated tasks are often triggered by
    specific conditions in the monitored metrics. If these conditions are not carefully
    defined, tasks may be triggered inaccurately or prematurely, leading to unnecessary
    or even detrimental actions being taken on the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inflexibility**: Automated tasks are typically designed for specific scenarios
    or issues and may not be flexible enough to handle unforeseen or complex situations.
    This could limit their effectiveness in addressing unique challenges that arise
    during model maintenance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Risk of compounding errors**: When automated tasks are executed based on
    erroneous alerts or inaccurate metrics, they can compound the issue by making
    unnecessary or incorrect adjustments to the model. This may lead to further deterioration
    in model performance or even irreversible damage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security risks**: Automating tasks based on alerts can expose the model and
    its infrastructure to potential security risks, especially if the automation system
    is not adequately secured. Unauthorized access or manipulation of the automation
    system could lead to unintended consequences or malicious actions on the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To mitigate these limitations and risks, it is essential to strike a balance
    between automation and human involvement in the model maintenance process. This
    can be achieved by incorporating human-in-the-loop systems, ensuring proper validation
    and calibration of monitoring metrics and alerts, and implementing robust security
    measures to protect the automation infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have covered all the components of deep learning model governance.
    This holistic three-pillar approach to model governance ultimately enables organizations
    to consistently and continuously harness the full potential of deep learning models,
    driving valuable insights and informed decision-making in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we explored the three fundamental pillars of model governance
    for deep learning models: model utilization, model monitoring, and model maintenance.
    Model utilization ensures the effective, efficient, ethical, and responsible utilization
    of deep learning models, while model monitoring allows for ongoing evaluation
    of performance, identification of potential bias or drift, and infrastructure-related
    metrics. Model maintenance, on the other hand, focuses on regular updates and
    refinements to keep models aligned with evolving data landscapes and business
    requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: We also dove into and learned about the technical steps for monitoring deep
    learning models using NVIDIA Triton Server, Prometheus, and Grafana. By diligently
    considering the components for model governance, deep learning architects can
    effectively manage the challenges posed by these complex models in production
    and consistently harness their potential for driving valuable insights and decisions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will further dive deeper into the details of drift detection
    for deep learning models.
  prefs: []
  type: TYPE_NORMAL
