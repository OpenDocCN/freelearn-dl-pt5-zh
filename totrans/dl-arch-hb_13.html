<html><head></head><body>
<div id="_idContainer120">
<h1 class="chapter-number" id="_idParaDest-187"><a id="_idTextAnchor196"/><span class="koboSpan" id="kobo.1.1">13</span></h1>
<h1 id="_idParaDest-188"><a id="_idTextAnchor197"/><span class="koboSpan" id="kobo.2.1">Exploring Bias and Fairness</span></h1>
<p><span class="koboSpan" id="kobo.3.1">A biased machine learning model produces and amplifies unfair or discriminatory predictions against certain groups. </span><span class="koboSpan" id="kobo.3.2">Such models can produce biased predictions that lead to negative consequences such as social or economic inequality. </span><span class="koboSpan" id="kobo.3.3">Fortunately, some countries have discrimination and equality laws that protect minority groups against unfavorable treatment. </span><span class="koboSpan" id="kobo.3.4">One of the worst scenarios a machine learning practitioner or anyone who deploys a biased model could face is either receiving a legal notice imposing a heavy fine or receiving a lawyer letter from being sued and forced to shut down their deployed model. </span><span class="koboSpan" id="kobo.3.5">Here are a few examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">such situations:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.5.1">The ride-hailing app Uber faced legal action from two unions in the UK for its facial verification system, which showed racial bias against dark-skinned people by displaying more frequent verification errors. </span><span class="koboSpan" id="kobo.5.2">This impeded their work as Uber </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">drivers (</span></span><a href="https://www.bbc.com/news/technology-58831373"><span class="No-Break"><span class="koboSpan" id="kobo.7.1">https://www.bbc.com/news/technology-58831373</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.8.1">).</span></span></li>
<li><span class="koboSpan" id="kobo.9.1">Creators filed a lawsuit against YouTube for its racial and other minority group discrimination against them as YouTube’s algorithm automatically removed their videos without proper explanation, removing their capability to earn ad </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">revenue (</span></span><a href="https://www.washingtonpost.com/technology/2020/06/18/black-creators-sue-youtube-alleged-race-discrimination/"><span class="No-Break"><span class="koboSpan" id="kobo.11.1">https://www.washingtonpost.com/technology/2020/06/18/black-creators-sue-youtube-alleged-race-discrimination/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.12.1">).</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Facebook was charged with racial, gender, religion, familial status, and disability discrimination for its housing ads by the housing department of the US and had to pay under 5 million US </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">dollars (</span></span><a href="https://www.npr.org/2019/03/28/707614254/hud-slaps-facebook-with-housing-discrimination-charge"><span class="No-Break"><span class="koboSpan" id="kobo.15.1">https://www.npr.org/2019/03/28/707614254/hud-slaps-facebook-with-housing-discrimination-charge</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.16.1">).</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.17.1">Thus, utmost care must be taken to prevent bias from being perpetuated against sensitive and protected attributes of the underlying data and environment the machine learning model will be exposed to. </span><span class="koboSpan" id="kobo.17.2">In this chapter, we will approach this topic step by step, starting with an exploration of the types of bias, learning to detect and evaluate methods needed to identify bias and fairness, and finally exploring ways to mitigate bias. </span><span class="koboSpan" id="kobo.17.3">The concepts and techniques that will be presented in this chapter are relevant to all machine learning models. </span><span class="koboSpan" id="kobo.17.4">However, bias mitigation is an exception; there, we will explore a neural network-specific method that can reliably mitigate bias. </span><span class="koboSpan" id="kobo.17.5">More formally, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.19.1">Exploring the types </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">of bias</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Understanding the source of </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">AI bias</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">Discovering bias and fairness </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">evaluation methods</span></span></li>
<li><span class="koboSpan" id="kobo.25.1">Evaluating the bias and fairness of a deep </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">learning model</span></span></li>
<li><span class="koboSpan" id="kobo.27.1">Tailoring bias and fairness measures across </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">use cases</span></span></li>
<li><span class="koboSpan" id="kobo.29.1">Mitigating </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">AI bias</span></span></li>
</ul>
<h1 id="_idParaDest-189"><a id="_idTextAnchor198"/><span class="koboSpan" id="kobo.31.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.32.1">This chapter includes some practical implementations in the Python programming language. </span><span class="koboSpan" id="kobo.32.2">To complete it, you will need to have a computer with the following </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">libraries installed:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.34.1">pandas</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.35.1">matplotlib</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.36.1">scikit-learn</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.37.1">numpy</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.38.1">pytorch</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.39.1">transformers==4.28.0</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.40.1">accelerate==0.6.0</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.41.1">captum</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.42.1">catalyst</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.43.1">The code files are available on GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">at </span></span><a href="https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_13"><span class="No-Break"><span class="koboSpan" id="kobo.45.1">https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_13</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.46.1">.</span></span></p>
<h1 id="_idParaDest-190"><a id="_idTextAnchor199"/><span class="koboSpan" id="kobo.47.1">Exploring the types of bias</span></h1>
<p><span class="koboSpan" id="kobo.48.1">Bias can be described as</span><a id="_idIndexMarker953"/><span class="koboSpan" id="kobo.49.1"> a natural tendency or inclination toward a specific viewpoint, opinion, or belief system, regardless of whether it is treated as positive, neutral, or negative. </span><span class="koboSpan" id="kobo.49.2">AI bias, on the other hand, specifically occurs when mathematical models perpetuate the biases embedded by their creators or underlying data. </span><span class="koboSpan" id="kobo.49.3">Be aware that not all information is treated as biases, as some information can also be knowledge. </span><span class="koboSpan" id="kobo.49.4">Bias is a type of subjective information, and knowledge refers to factual information, understanding, or awareness acquired through learning, experience, or research. </span><span class="koboSpan" id="kobo.49.5">In other words, knowledge is the truth </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">without bias.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.51.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.52.1">Do not confuse bias in this book with the bias from the infamous “bias versus variance” concept in machine learning. </span><span class="koboSpan" id="kobo.52.2">Bias in this concept refers to the specific bias on how simple a machine learning model is concerning a certain task to learn. </span><span class="koboSpan" id="kobo.52.3">For completeness, variance specifies the sensitivity of the model toward the change in the data features. </span><span class="koboSpan" id="kobo.52.4">Here, a high bias would correspond to a low variance and underfitting behavior and indicate that a machine learning model is too simple. </span><span class="koboSpan" id="kobo.52.5">A low bias in this concept would correspond to high variance and </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">overfitting behavior.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">In this book, we will use the term bias more colloquially. </span><span class="koboSpan" id="kobo.54.2">More well-known attributes of bias, such as race, gender, and age, are considered social bias, or stereotyping. </span><span class="koboSpan" id="kobo.54.3">However, the scope of bias is much broader. </span><span class="koboSpan" id="kobo.54.4">Here are some </span><a id="_idIndexMarker954"/><span class="koboSpan" id="kobo.55.1">interesting examples of other types </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">of bias:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.57.1">Cultural bias</span></strong><span class="koboSpan" id="kobo.58.1">: The influence </span><a id="_idIndexMarker955"/><span class="koboSpan" id="kobo.59.1">cultural perspectives, values, and norms have on judgments, decisions, and behaviors. </span><span class="koboSpan" id="kobo.59.2">It can manifest in machine learning models through biased data collection, skewed training data, or algorithms that reflect </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">cultural prejudices.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.61.1">Cognitive bias</span></strong><span class="koboSpan" id="kobo.62.1">: Systematic patterns of deviation from rationality in thinking or decision-making. </span><span class="koboSpan" id="kobo.62.2">Let’s look at a few examples of cognitive bias along with possible phenomena that portray the bias in a machine </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">learning project:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.64.1">Confirmation bias</span></strong><span class="koboSpan" id="kobo.65.1">: Favoring data that aligns with </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">existing beliefs</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.67.1">Anchoring bias</span></strong><span class="koboSpan" id="kobo.68.1">: Overemphasizing certain features or variables during </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">model training</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.70.1">Availability bias</span></strong><span class="koboSpan" id="kobo.71.1">: Relying on easily accessible data sources, potentially overlooking relevant but less </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">accessible ones</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.73.1">Overconfidence bias</span></strong><span class="koboSpan" id="kobo.74.1">: Overestimating model capabilities </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">or accuracy</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.76.1">Hindsight bias</span></strong><span class="koboSpan" id="kobo.77.1">: Believing that model predictions were more predictable after </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">observing them</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.79.1">Automation bias</span></strong><span class="koboSpan" id="kobo.80.1">: Placing excessive trust in the model’s outputs without </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">critical evaluation</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.82.1">Framing bias</span></strong><span class="koboSpan" id="kobo.83.1">: Influencing the model’s learning process through biased </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">data presentation</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.85.1">Selection bias</span></strong><span class="koboSpan" id="kobo.86.1">: Non-random sampling leading to </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">unrepresentative data</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.88.1">Sampling bias</span></strong><span class="koboSpan" id="kobo.89.1">: Skewed data due to an </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">unrepresentative sample</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.91.1">Reporting bias</span></strong><span class="koboSpan" id="kobo.92.1">: Misrepresentation due to individuals’ preferences </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">or beliefs</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.94.1">Algorithmic bias</span></strong><span class="koboSpan" id="kobo.95.1">: Presence of any biases in algorithms such as machine learning algorithms. </span><span class="koboSpan" id="kobo.95.2">Another example of such bias is </span><strong class="bold"><span class="koboSpan" id="kobo.96.1">aggregation bias</span></strong><span class="koboSpan" id="kobo.97.1">, which has skewed predictions due to data grouping or </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">aggregation methods.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.99.1">Measurement bias</span></strong><span class="koboSpan" id="kobo.100.1">: Inaccuracies or errors in data collection </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">and measurement.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.102.1">These bias groups are just the tip of the iceberg and can span to very niche bias groups such as political bias, industry bias, media</span><a id="_idIndexMarker956"/><span class="koboSpan" id="kobo.103.1"> bias, and so on. </span><span class="koboSpan" id="kobo.103.2">Now that we understand what bias is and what it covers, let’s discover the source of </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">AI bias.</span></span></p>
<h1 id="_idParaDest-191"><a id="_idTextAnchor200"/><span class="koboSpan" id="kobo.105.1">Understanding the source of AI bias</span></h1>
<p><span class="koboSpan" id="kobo.106.1">AI bias can happen at any</span><a id="_idIndexMarker957"/><span class="koboSpan" id="kobo.107.1"> point in the deep learning life cycle. </span><span class="koboSpan" id="kobo.107.2">Let’s go through bias at those stages one </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">by one:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.109.1">Planning</span></strong><span class="koboSpan" id="kobo.110.1">: During the planning stage of the machine learning life cycle, biases can emerge as decisions are made regarding project objectives, data collection methods, and model design. </span><span class="koboSpan" id="kobo.110.2">Bias may arise from subjective choices, assumptions, or the use of unrepresentative data sources. </span><span class="koboSpan" id="kobo.110.3">Project planners need to maintain a critical perspective, actively consider potential biases, engage diverse perspectives, and prioritize fairness and </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">ethical considerations.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.112.1">Data preparation</span></strong><span class="koboSpan" id="kobo.113.1">: This stage involves the </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">following phases:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.115.1">Data collection</span></strong><span class="koboSpan" id="kobo.116.1">: During the data collection phase, bias can creep in if the collected data fails to represent the target population accurately. </span><span class="koboSpan" id="kobo.116.2">Several factors can contribute to this bias, including sampling bias, selection bias, or the underrepresentation of specific groups. </span><span class="koboSpan" id="kobo.116.3">These issues can lead to the creation of an imbalanced dataset that does not reflect the true diversity of the </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">intended population.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.118.1">Data labeling</span></strong><span class="koboSpan" id="kobo.119.1">: Bias can also infiltrate the data labeling process. </span><span class="koboSpan" id="kobo.119.2">Each labeler may possess their own inherent biases, consciously or subconsciously, which can influence their decision-making when assigning labels to the data. </span><span class="koboSpan" id="kobo.119.3">If the labelers lack diversity or comprehensive training, their biases may seep into the annotations, ultimately leading to the development of biased models that perpetuate unfairness and discrimination. </span><span class="koboSpan" id="kobo.119.4">As a result, the final combined data can contain multiple biases which may even conflict with each other, causing difficulties in the </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">learning process.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.121.1">Model development</span></strong><span class="koboSpan" id="kobo.122.1">: Bias can be introduced in two ways in a deep </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">learning model:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.124.1">Feature selection</span></strong><span class="koboSpan" id="kobo.125.1">: Biases can arise from the features selected for model training. </span><span class="koboSpan" id="kobo.125.2">If certain features are correlated with protected attributes (such as race or gender), the model may inadvertently learn and reinforce those biases, leading to </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">discriminatory outcomes.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.127.1">Pretrained models</span></strong><span class="koboSpan" id="kobo.128.1">: A pretrained deep learning model might be a biased model. </span><span class="koboSpan" id="kobo.128.2">For example, if the model has been trained on biased data, it may learn and perpetuate those biases in its predictions. </span><span class="koboSpan" id="kobo.128.3">Even if fine-tuning was done, the bias is not likely to </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">go away.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.130.1">Deliver model insights</span></strong><span class="koboSpan" id="kobo.131.1">: Bias can happen particularly when interpreting explanations of model behavior. </span><span class="koboSpan" id="kobo.131.2">The process of understanding and explaining the inner workings of a model involves subjective reasoning and is susceptible to bias. </span><span class="koboSpan" id="kobo.131.3">The interpretation of model insights heavily relies on the perspective and preconceptions of the individuals involved, which can introduce biases based on their own beliefs, experiences, or implicit biases. </span><span class="koboSpan" id="kobo.131.4">It is essential to approach the interpretation of model explanations with awareness of these potential biases and strive for objectivity and fairness to avoid misinterpretation or reinforcing existing biases. </span><span class="koboSpan" id="kobo.131.5">Critical thinking and diverse perspectives are vital to ensuring that the insights delivered accurately reflect the model’s behavior without introducing </span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">additional bias.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.133.1">Model deployment</span></strong><span class="koboSpan" id="kobo.134.1">: This stage covers bias that can happen when a model is deployed, which includes the </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">following components:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.136.1">User interactions</span></strong><span class="koboSpan" id="kobo.137.1">: Bias can arise during model deployment when users provide feedback or responses and be introduced if the feedback is biased or if the system responds differently based on user characteristics. </span><span class="koboSpan" id="kobo.137.2">For example, the chat history mechanism in the ChatGPT UI allows a user to provide </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">biased input.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.139.1">Human-in-the-loop bias</span></strong><span class="koboSpan" id="kobo.140.1">: Biases can be introduced when human reviewers or operators make decisions based on the model’s predictions, exhibiting their own biases or interpreting outputs unfairly. </span><span class="koboSpan" id="kobo.140.2">This can impact the perceived fairness of the </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">decision-making process.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.142.1">Environment bias</span></strong><span class="koboSpan" id="kobo.143.1">: Some features might be treated and perceived differently in unseen areas, leading to data drift. </span><span class="koboSpan" id="kobo.143.2">Models were evaluated to be unbiased during the development stage, but with the new data, it could still produce </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">biased predictions.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.145.1">New data source for retraining bias</span></strong><span class="koboSpan" id="kobo.146.1">: New data can be collected and labeled for retraining, which can be a source </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">of bias.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.148.1">Model governance</span></strong><span class="koboSpan" id="kobo.149.1">: Bias can emerge when the person responsible for monitoring the deployed model needs to establish thresholds for various types of drift (which will be introduced in </span><a href="B18187_16.xhtml#_idTextAnchor238"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.150.1">Chapter 16</span></em></span></a><span class="koboSpan" id="kobo.151.1">, </span><em class="italic"><span class="koboSpan" id="kobo.152.1">Governing Deep Learning Models</span></em><span class="koboSpan" id="kobo.153.1">), analyze prediction summaries, and examine data summaries. </span><span class="koboSpan" id="kobo.153.2">Setting these thresholds introduces the potential for bias based on subjective decisions or assumptions. </span><span class="koboSpan" id="kobo.153.3">Additionally, when analyzing prediction and data summaries, there is a risk of overlooking certain biases or unintentionally reinforcing existing biases if not approached with diligence and a critical mindset. </span><span class="koboSpan" id="kobo.153.4">It is crucial to maintain awareness of these biases and ensure that monitoring and analysis processes are conducted rigorously and with a focus on fairness </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">and accuracy.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.155.1">Now that we’ve discovered </span><a id="_idIndexMarker958"/><span class="koboSpan" id="kobo.156.1">some of the possible sources of bias in each stage of the deep learning life cycle, we are ready to dive into discovering bias detection and fairness </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">evaluation methods.</span></span></p>
<h1 id="_idParaDest-192"><a id="_idTextAnchor201"/><span class="koboSpan" id="kobo.158.1">Discovering bias and fairness evaluation methods</span></h1>
<p><span class="koboSpan" id="kobo.159.1">Fairness and bias are opposing </span><a id="_idIndexMarker959"/><span class="koboSpan" id="kobo.160.1">concepts. </span><span class="koboSpan" id="kobo.160.2">Fairness seeks to ensure fair and equal treatment in decision-making for all individuals or groups, while bias refers to unfair or unequal treatment. </span><span class="koboSpan" id="kobo.160.3">Mitigating bias is a crucial step in achieving fairness. </span><span class="koboSpan" id="kobo.160.4">Bias can exist in different forms and addressing all potential biases is complicated. </span><span class="koboSpan" id="kobo.160.5">Additionally, it’s important to understand that achieving fairness in one aspect doesn’t guarantee the complete absence of bias </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1">in general.</span></span></p>
<p><span class="koboSpan" id="kobo.162.1">To understand both how much bias and how fair our data and model are, what we need is a set of bias and fairness metrics to objectively measure and evaluate. </span><span class="koboSpan" id="kobo.162.2">This will then enable a feedback mechanism to iteratively and objectively mitigate bias and achieve fairness. </span><span class="koboSpan" id="kobo.162.3">Let’s go through a few robust bias and fairness metrics that you need to have in your arsenal of tools to </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">achieve fairness:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.164.1">Equal representation-based metrics</span></strong><span class="koboSpan" id="kobo.165.1">: This </span><a id="_idIndexMarker960"/><span class="koboSpan" id="kobo.166.1">set of metrics focuses on the equal proportions of either the data or the decision outcomes without considering </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">the errors:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.168.1">Disparate impact</span></strong><span class="koboSpan" id="kobo.169.1">: Disparate impact examines whether the model treats different groups fairly or if there are significant relative disparities in the outcomes they receive by taking a ratio of the proportion of favorable outcomes between groups. </span><span class="koboSpan" id="kobo.169.2">Disparate impact for a chosen group in a chosen attribute can be computed using the </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">following formula:</span></span></li></ul></li>
</ul>
<p><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.171.1">D</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.172.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.173.1">s</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.174.1">p</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.175.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.176.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.177.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.178.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.179.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.180.1">I</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.181.1">m</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.182.1">p</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.183.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.184.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.185.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.186.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.187.1">G</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.188.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.189.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.190.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.191.1">p</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.192.1">A</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.193.1">)</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.194.1">=</span></span></span></p>
<p><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.195.1">(</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.196.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.197.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.198.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.199.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.200.1">p</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.201.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.202.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.203.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.204.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.205.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.206.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.207.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.208.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.209.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.210.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.211.1">s</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.212.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.213.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.214.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.215.1">v</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.216.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.217.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.218.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.219.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.220.1">d</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.221.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.222.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.223.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.224.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.225.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.226.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.227.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.228.1">f</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.229.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.230.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.231.1">G</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.232.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.233.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.234.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.235.1">p</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.236.1">A</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.237.1">     </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.238.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.239.1">__________________________________________________________</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.240.1">      </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.241.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.242.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.243.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.244.1">p</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.245.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.246.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.247.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.248.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.249.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.250.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.251.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.252.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.253.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.254.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.255.1">s</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.256.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.257.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.258.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.259.1">v</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.260.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.261.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.262.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.263.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.264.1">d</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.265.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.266.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.267.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.268.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.269.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.270.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.271.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.272.1">f</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.273.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.274.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.275.1">R</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.276.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.277.1">f</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.278.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.279.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.280.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.281.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.282.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.283.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.284.1">G</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.285.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.286.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.287.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.288.1">p</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.289.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.290.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.291.1">A</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.292.1">g</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.293.1">g</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.294.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.295.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.296.1">g</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.297.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.298.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.299.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.300.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.301.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.302.1">O</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.303.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.304.1">h</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.305.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.306.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.307.1">G</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.308.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.309.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.310.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.311.1">p</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.312.1">s</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.313.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.314.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.315.1">)</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.316.1">    Disparate impact across groups can be averaged to obtain a single global </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">representative value.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.318.1">Statistical parity difference</span></strong><span class="koboSpan" id="kobo.319.1">: This extends similar benefits as disparate impact but provides an absolute disparity measure instead of relative by using a difference instead of a ratio. </span><span class="koboSpan" id="kobo.319.2">The absolute difference is useful when you can and need to translate the values into tangible impacts, such as the number of individuals who were discriminated against based on a new sample size. </span><span class="koboSpan" id="kobo.319.3">It can be computed using the </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">following formula:</span></span></li>
</ul>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.321.1">S</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.322.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.323.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.324.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.325.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.326.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.327.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.328.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.329.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.330.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.331.1">l</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.332.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.333.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.334.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.335.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.336.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.337.1">y</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.338.1">D</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.339.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.340.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.341.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.342.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.343.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.344.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.345.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.346.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.347.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.348.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.349.1">|</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.350.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.351.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.352.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.353.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.354.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.355.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.356.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.357.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.358.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.359.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.360.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.361.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.362.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.363.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.364.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.365.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.366.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.367.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.368.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.369.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.370.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.371.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.372.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.373.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.374.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.375.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.376.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.377.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.378.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.379.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.380.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.381.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.382.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.383.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.384.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.385.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.386.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.387.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.388.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.389.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.390.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.391.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.392.1">g</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.393.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.394.1">d</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.395.1">G</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.396.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.397.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.398.1">u</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.399.1">p</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.400.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.401.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.402.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.403.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.404.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.405.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.406.1">p</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.407.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.408.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.409.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.410.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.411.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.412.1">n</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.413.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.414.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.415.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.416.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.417.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.418.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.419.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.420.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.421.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.422.1">e</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.423.1">P</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.424.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.425.1">e</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.426.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.427.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.428.1">c</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.429.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.430.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.431.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.432.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.433.1">s</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.434.1">f</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.435.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.436.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.437.1">U</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.438.1">n</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.439.1">p</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.440.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.441.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.442.1">v</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.443.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.444.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.445.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.446.1">g</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.447.1">e</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.448.1">d</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.449.1">G</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.450.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.451.1">o</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.452.1">u</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.453.1">p</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.454.1">)</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.455.1">|</span></span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.456.1">Equal error-based metrics</span></strong><span class="koboSpan" id="kobo.457.1">: These are the metrics that consider the bias in error rates </span><span class="No-Break"><span class="koboSpan" id="kobo.458.1">between groups.</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.459.1">Average Odd Difference</span></strong><span class="koboSpan" id="kobo.460.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.461.1">AOD</span></strong><span class="koboSpan" id="kobo.462.1">): This measures</span><a id="_idIndexMarker961"/><span class="koboSpan" id="kobo.463.1"> the average discrepancy in the odds of true positive and false positive outcomes across groups. </span><span class="koboSpan" id="kobo.463.2">AOD is computed by taking the average of the odds differences across different groups. </span><span class="koboSpan" id="kobo.463.3">The odds difference for a specific group is calculated as the difference between the odds of positive prediction for that group and the odds of positive prediction for a reference group using the </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">following formula:</span></span></li></ul></li>
</ul>
<p><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.465.1">A</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.466.1">O</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.467.1">D</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.468.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.469.1">(</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.470.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.471.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.472.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.473.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.474.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.475.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.476.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.477.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal"><span class="koboSpan" id="kobo.478.1">*</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.479.1">Σ</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.480.1">[</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.481.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.482.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.483.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.484.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.485.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.486.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.487.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.488.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.489.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.490.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.491.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.492.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.493.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.494.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.495.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.496.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.497.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.498.1">F</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.499.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.500.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.501.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.502.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.503.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.504.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.505.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.506.1">F</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.507.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.508.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.509.1">_</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.510.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.511.1">)</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.512.1">]</span></span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.513.1">   Here, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.514.1">n</span></span><span class="koboSpan" id="kobo.515.1"> is the total number of groups, </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.516.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.517.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.518.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.519.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.520.1">i</span></span><span class="koboSpan" id="kobo.521.1"> is the true positive rate (sensitivity) for group </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.522.1">i</span></span><span class="koboSpan" id="kobo.523.1">, </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.524.1">F</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.525.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.526.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.527.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.528.1">i</span></span><span class="koboSpan" id="kobo.529.1"> is the false positive rate (fallout) for group </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.530.1">i</span></span><span class="koboSpan" id="kobo.531.1">, </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.532.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.533.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.534.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.535.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.536.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.537.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.538.1">f</span></span><span class="koboSpan" id="kobo.539.1"> is the true positive rate for the reference group, and </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.540.1">F</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.541.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.542.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.543.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.544.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.545.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.546.1">f</span></span><span class="koboSpan" id="kobo.547.1"> is the false positive rate for the </span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">reference group.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.549.1">Average Absolute Odds Difference</span></strong><span class="koboSpan" id="kobo.550.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.551.1">AAOD</span></strong><span class="koboSpan" id="kobo.552.1">): This extends similar benefits to AOD but adds an absolute term</span><a id="_idIndexMarker962"/><span class="koboSpan" id="kobo.553.1"> in the individual group computations, </span><span class="No-Break"><span class="koboSpan" id="kobo.554.1">as follows:</span></span></li>
</ul>
<p><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.555.1">A</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.556.1">O</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.557.1">D</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.558.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.559.1">(</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.560.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.561.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.562.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.563.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.564.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.565.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.566.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.567.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal"><span class="koboSpan" id="kobo.568.1">*</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.569.1">Σ</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.570.1">[</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.571.1">|</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.572.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.573.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.574.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.575.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.576.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.577.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.578.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.579.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.580.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.581.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.582.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.583.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.584.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.585.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.586.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.587.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.588.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.589.1">F</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.590.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.591.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.592.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.593.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.594.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.595.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.596.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.597.1">F</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.598.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.599.1">R</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.600.1">_</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.601.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.602.1">)</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.603.1">|</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.604.1">]</span></span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.605.1">This should be used over AOD when you care about the discrepancies in general and not only whether the group discrepancy is favored </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1">or non-favored.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.607.1">Distributional fairness through g</span></strong><strong class="bold"><span class="koboSpan" id="kobo.608.1">eneralized entropy index</span></strong><span class="koboSpan" id="kobo.609.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.610.1">GEI</span></strong><span class="koboSpan" id="kobo.611.1">): This is designed to measure the level of inequality </span><a id="_idIndexMarker963"/><span class="koboSpan" id="kobo.612.1">based on distribution across individuals of an entire population using only the numerical outcome. </span><span class="koboSpan" id="kobo.612.2">The formula for GEI is </span><span class="No-Break"><span class="koboSpan" id="kobo.613.1">as follows:</span></span></li>
</ul>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.614.1">G</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.615.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.616.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.617.1">α</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.618.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.619.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.620.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.621.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.622.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.623.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.624.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.625.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.626.1">a</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.627.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.628.1">a</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.629.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.630.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.631.1">)</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.632.1"> </span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.633.1">∑</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.634.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.635.1">i</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.636.1">=</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.637.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.638.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.639.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.640.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.641.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.642.1">n</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.643.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.644.1">a</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.645.1">w</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.646.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.647.1">a</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.648.1">−</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.649.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.650.1">)</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.651.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.652.1">a</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.653.1">≠</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.654.1">0,1</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.655.1">,</span></span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.656.1">G</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.657.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.658.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.659.1">α</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.660.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.661.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Function_v-normal"><span class="koboSpan" id="kobo.662.1">log</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.663.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.664.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.665.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.666.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.667.1">∑</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.668.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.669.1">i</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.670.1">=</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.671.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.672.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.673.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.674.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.675.1">w</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.676.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.677.1">i</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Function_v-normal"><span class="koboSpan" id="kobo.678.1">log</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.679.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.680.1">w</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.681.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.682.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.683.1">)</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.684.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.685.1">a</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.686.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.687.1">1</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.688.1">,</span></span></span></p>
<p><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.689.1">G</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.690.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.691.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.692.1">α</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.693.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.694.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.695.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Function_v-normal"><span class="koboSpan" id="kobo.696.1">log</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.697.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.698.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.699.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.700.1">−</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.701.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.702.1">1</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.703.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.704.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.705.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.706.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.707.1"> </span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.708.1">∑</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.709.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.710.1">i</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.711.1">=</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.712.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.713.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.714.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.715.1"> </span></span><span class="_-----MathTools-_Math_Function_v-normal"><span class="koboSpan" id="kobo.716.1">log</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.717.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.718.1">w</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.719.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.720.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.721.1">)</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.722.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.723.1">a</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.724.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.725.1">0</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.726.1">Here, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.727.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.728.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.729.1">T</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.730.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.731.1">∑</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.732.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.733.1">i</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.734.1">=</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.735.1">1</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.736.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.737.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.738.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.739.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.740.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.741.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.742.1">i</span></span><span class="koboSpan" id="kobo.743.1"> and </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.744.1">w</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.745.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.746.1">i</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.747.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.748.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.749.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.750.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.751.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.752.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.753.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.754.1"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.755.1">E</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.756.1"> </span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.757.1">T</span></span></span></p>
<p class="list-inset"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.758.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.759.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.760.1">i</span></span><span class="koboSpan" id="kobo.761.1">is the value of the chosen attribute of a specific entity, </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.762.1">E</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.763.1"> </span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.764.1">T</span></span><span class="koboSpan" id="kobo.765.1"> is the total summed value of all, and </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.766.1">n</span></span><span class="koboSpan" id="kobo.767.1"> is the total number of individuals or entities. </span><span class="koboSpan" id="kobo.767.2">Two foundational notions of inequality can be configured through the </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.768.1">α</span></span><span class="koboSpan" id="kobo.769.1"> parameter </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">of GEI:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.771.1">Theil index</span></strong><span class="koboSpan" id="kobo.772.1">: The general inequality of all individuals across all groups. </span><span class="koboSpan" id="kobo.772.2">It has an </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.773.1">α</span></span><span class="koboSpan" id="kobo.774.1"> value </span><span class="No-Break"><span class="koboSpan" id="kobo.775.1">of 1.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.776.1">Coefficient of variation</span></strong><span class="koboSpan" id="kobo.777.1">: The inequality that’s measured by computing the variability of individuals in a population</span><a id="_idIndexMarker964"/><span class="koboSpan" id="kobo.778.1"> group. </span><span class="koboSpan" id="kobo.778.2">The more varied the population group is, the more biased the population group is. </span><span class="koboSpan" id="kobo.778.3">It has an </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.779.1">α</span></span><span class="koboSpan" id="kobo.780.1"> value </span><span class="No-Break"><span class="koboSpan" id="kobo.781.1">of 2.</span></span></li>
</ul>
<p class="list-inset"><span class="koboSpan" id="kobo.782.1">Use the Theil index as your main option if you want an overall inequality and switch to the coefficient of variation when you want to understand inequality </span><span class="No-Break"><span class="koboSpan" id="kobo.783.1">by group.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.784.1">Individual fairness metric</span></strong><span class="koboSpan" id="kobo.785.1">: Disparity or similarity of outcome based on similar individuals is a single individual-based metric. </span><span class="koboSpan" id="kobo.785.2">Proximity algorithms such as KNN allow you to consider the multiple associating features of an individual and compute fairness metrics based on similar examples. </span><span class="koboSpan" id="kobo.785.3">You must perform the </span><span class="No-Break"><span class="koboSpan" id="kobo.786.1">following steps:</span></span><ol><li class="upper-roman"><span class="koboSpan" id="kobo.787.1">Find a chosen number of similar examples with associative features, excluding the protected attribute with KNN for </span><span class="No-Break"><span class="koboSpan" id="kobo.788.1">the individual.</span></span></li><li class="upper-roman"><span class="koboSpan" id="kobo.789.1">Compute the inequality of the outcome using a chosen fairness metric. </span><span class="koboSpan" id="kobo.789.2">The most common metric that’s used here is the average similarity of the outcomes of similar examples to </span><span class="No-Break"><span class="koboSpan" id="kobo.790.1">the individual.</span></span></li></ol></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.791.1">Fair accuracy-based performance metric through Balanced accuracy</span></strong><span class="koboSpan" id="kobo.792.1">: This provides a balanced evaluation of a classification model’s performance, especially when dealing with imbalanced datasets. </span><span class="koboSpan" id="kobo.792.2">Balanced accuracy is </span><a id="_idIndexMarker965"/><span class="koboSpan" id="kobo.793.1">computed by calculating the average of the </span><span class="No-Break"><span class="koboSpan" id="kobo.794.1">class-wise accuracies.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.795.1">Even though the metrics we’ve introduced here only cover a partial set of bias and fairness metrics available in the field, it is</span><a id="_idIndexMarker966"/><span class="koboSpan" id="kobo.796.1"> general enough to satisfy most machine learning use cases. </span><span class="koboSpan" id="kobo.796.2">Now, let’s explore how to use these metrics practically in a deep learning project to measure bias </span><span class="No-Break"><span class="koboSpan" id="kobo.797.1">and fairness.</span></span></p>
<h1 id="_idParaDest-193"><a id="_idTextAnchor202"/><span class="koboSpan" id="kobo.798.1">Evaluating the bias and fairness of a deep learning model</span></h1>
<p><span class="koboSpan" id="kobo.799.1">In this practical example, we</span><a id="_idIndexMarker967"/><span class="koboSpan" id="kobo.800.1"> will be exploring </span><a id="_idIndexMarker968"/><span class="koboSpan" id="kobo.801.1">the infamous real-world use case of face recognition. </span><span class="koboSpan" id="kobo.801.2">This practical example will be leveraged for the practical implementation of bias mitigation in the next section. </span><span class="koboSpan" id="kobo.801.3">The basis of face recognition is to generate feature vectors that can be used to carry out KNN-based classification so that new faces don’t need to undergo additional network training. </span><span class="koboSpan" id="kobo.801.4">In this example, we will be training a classification model and evaluating it using traditional classification accuracy-based metrics; we won’t be demonstrating the recognition part of the use case, which allows us to handle unknown facial </span><span class="No-Break"><span class="koboSpan" id="kobo.802.1">identity classes.</span></span></p>
<p><span class="koboSpan" id="kobo.803.1">The goal here is to ensure that the resulting facial classification model has low gender bias. </span><span class="koboSpan" id="kobo.803.2">We will be using a publicly available facial dataset </span><a id="_idIndexMarker969"/><span class="koboSpan" id="kobo.804.1">called </span><strong class="bold"><span class="koboSpan" id="kobo.805.1">BUPT-CBFace-50</span></strong><span class="koboSpan" id="kobo.806.1">, which has a diverse coverage of facial images that have different facial expressions, poses, lighting conditions, and occlusions. </span><span class="koboSpan" id="kobo.806.2">The dataset consists of 500,000 images of 10,000 facial identity classes. </span><span class="koboSpan" id="kobo.806.3">In this practical example, you will require a GPU with at least 12 GB of RAM so that training can be done in a reasonable time. </span><span class="koboSpan" id="kobo.806.4">Before starting the example, download the dataset from the official source (</span><a href="https://buptzyb.github.io/CBFace/?reload=true"><span class="koboSpan" id="kobo.807.1">https://buptzyb.github.io/CBFace/?reload=true</span></a><span class="koboSpan" id="kobo.808.1">). </span><span class="koboSpan" id="kobo.808.2">You can find it in the same directory as </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">your project.</span></span></p>
<p><span class="koboSpan" id="kobo.810.1">Let’s start with the step-by-step code walkthrough by using Python and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.811.1">pytorch</span></strong><span class="koboSpan" id="kobo.812.1"> library with </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.813.1">catalyst</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.814.1"> again:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.815.1">First, let’s import the necessary libraries, which include </span><strong class="source-inline"><span class="koboSpan" id="kobo.816.1">pytorch</span></strong><span class="koboSpan" id="kobo.817.1"> as the deep learning framework, </span><strong class="source-inline"><span class="koboSpan" id="kobo.818.1">mlflow</span></strong><span class="koboSpan" id="kobo.819.1"> for tracking and comparison, </span><strong class="source-inline"><span class="koboSpan" id="kobo.820.1">torchvision</span></strong><span class="koboSpan" id="kobo.821.1"> for the pretrained ResNet50 model, </span><strong class="source-inline"><span class="koboSpan" id="kobo.822.1">catalyst</span></strong><span class="koboSpan" id="kobo.823.1"> for efficient PyTorch model handling, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.824.1">albumentations</span></strong><span class="koboSpan" id="kobo.825.1"> for simple image </span><span class="No-Break"><span class="koboSpan" id="kobo.826.1">data processing:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.827.1">
import os
import albumentations as albu
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from albumentations.pytorch.transforms import ToTensorV2
from PIL import Image
from sklearn.model_selection import StratifiedShuffleSplit
from torch.optim import SGD, Adam
from torch.utils.data import DataLoader, Dataset
from torchvision import models
from torchvision.models import resnet50
import mlflow
from catalyst import dl, utils, metrics
from catalyst.contrib.layers import ArcFace
from catalyst.loggers.mlflow import MLflowLogger
from captum.attr import IntegratedGradients
from captum.attr import NoiseTunnel
from captum.attr import visualization as viz
os.environ["CUDA_VISIBLE_DEVICES"] = "0"</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.828.1">The last line sets the first GPU of your machine to be visible to CUDA, the computing interface for the GPU to </span><span class="No-Break"><span class="koboSpan" id="kobo.829.1">be used.</span></span></p></li> <li><span class="koboSpan" id="kobo.830.1">Next, we will define the configuration that will be used for different components. </span><span class="koboSpan" id="kobo.830.2">This will include training process-specific</span><a id="_idIndexMarker970"/><span class="koboSpan" id="kobo.831.1"> parameters </span><a id="_idIndexMarker971"/><span class="koboSpan" id="kobo.832.1">such as the batch sizes, learning rate, number of epochs, the number of early stopping epochs before stopping the training process, and the number of epochs to wait for validation metric improvements before reducing </span><span class="No-Break"><span class="koboSpan" id="kobo.833.1">the learning:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.834.1">
batch_size = 64
val_batch_size = 100
lr = 0.05
num_epochs = 20
early_stopping_epochs = 12
reduce_lr_patience = 3</span></pre></li> <li><span class="koboSpan" id="kobo.835.1">Additionally, it will include the specification of the privileged and unprivileged groups that we will choose for computing the gender-based bias and fairness metrics. </span><span class="koboSpan" id="kobo.835.2">There are approximately two times more males than females in the dataset, so the privileged group here is expected to </span><span class="No-Break"><span class="koboSpan" id="kobo.836.1">be </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.837.1">Male</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.838.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.839.1">
priviledged_group = 'Male'
unpriviledged_group = 'Female'</span></pre></li> <li><span class="koboSpan" id="kobo.840.1">Finally, we will set some names for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.841.1">mlflow</span></strong><span class="koboSpan" id="kobo.842.1"> experiment name, the directory to save the models, and the extra parameters that we won’t be enabling </span><span class="No-Break"><span class="koboSpan" id="kobo.843.1">for now:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.844.1">
experiment_mlflow = "bias_mitigation_v1"
logdir = 'experiments/face_modelv1'
only_male=False
distill_model=False</span></pre></li> <li><span class="koboSpan" id="kobo.845.1">Next, we’ll proceed to load the CSV file that contains the dataset metadata, primarily consisting of the image paths for the downloaded and unzipped </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.846.1">BUPT_CBFace</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.847.1"> dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.848.1">
train = pd.read_csv('face_age_gender.csv')
image_path = train['image_path'].values
targets = train['target'].values
gender_data = train['gender'].values</span></pre></li> <li><span class="koboSpan" id="kobo.849.1">Additionally, we will set up the </span><strong class="source-inline"><span class="koboSpan" id="kobo.850.1">name2class</span></strong><span class="koboSpan" id="kobo.851.1"> mapper, along with the class ID targets array and the number </span><span class="No-Break"><span class="koboSpan" id="kobo.852.1">of classes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.853.1">
name2class = {name: idx for idx, name in enumerate(sorted(set(targets)))}
id_targets = np.array([name2class[target] for target in targets])
num_classes = len(name2class)</span></pre></li> <li><span class="koboSpan" id="kobo.854.1">Next, we will perform stratified splitting on this data to put it into training and validation sets for the facial identity classes </span><a id="_idIndexMarker972"/><span class="koboSpan" id="kobo.855.1">so that both</span><a id="_idIndexMarker973"/><span class="koboSpan" id="kobo.856.1"> validation and training will have all the available facial </span><span class="No-Break"><span class="koboSpan" id="kobo.857.1">identity classes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.858.1">
splitter = StratifiedShuffleSplit(test_size=.20, n_splits=2, random_state = 7)
split = splitter.split(image_path, targets)
train_inds, val_inds = next(split)
train_images = image_path[train_inds]
val_images = image_path[val_inds]
train_targets = id_targets[train_inds]
val_targets = id_targets[val_inds]
train_gender_data = gender_data[train_inds]
val_gender_data = gender_data[val_inds]
if only_male:
    pass</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.859.1">The logic of the last </span><strong class="source-inline"><span class="koboSpan" id="kobo.860.1">if</span></strong><span class="koboSpan" id="kobo.861.1"> clause will be covered in the next section on bias mitigation. </span><span class="koboSpan" id="kobo.861.2">For the subsequent steps, treat the usage of </span><strong class="source-inline"><span class="koboSpan" id="kobo.862.1">pass</span></strong><span class="koboSpan" id="kobo.863.1"> as </span><span class="No-Break"><span class="koboSpan" id="kobo.864.1">an indicator.</span></span></p></li> <li><span class="koboSpan" id="kobo.865.1">Next, we will define the model we want to use based on the ResNet50 model. </span><span class="koboSpan" id="kobo.865.2">We will use the ARCFace layer here with the ResNet50 model base, a type of metric learning algorithm. </span><span class="koboSpan" id="kobo.865.3">It utilizes angular margin loss to enhance the discriminative power of the learned face embeddings, enabling more accurate and robust face recognition across varying poses, illuminations, </span><span class="No-Break"><span class="koboSpan" id="kobo.866.1">and identities:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.867.1">
class ARCResNet50(nn.Module):
    def __init__(self, num_classes):
        super(ARCResNet50, self).__init__()
        self.model =  models.resnet50(pretrained=True)
        s=2**0.5*np.log(num_classes - 1)
        s=13
        self.model.fc = nn.Linear(self.model.fc.in_features, self.model.fc.in_features)
        self.head = ArcFace(self.model.fc.out_features, num_classes, s=s, m=0.15)
    def get_last_conv_features(self, x):
        pass
    def special_forward(self, x, targets=None):
        pass
    def forward(self, x, targets=None):
        outputs = self.model(x)
        outputs = self.head(outputs, targets)
        return outputs</span></pre></li> <li><span class="koboSpan" id="kobo.868.1">Next, we will initialize the model, assign it to use GPU, define the cross-entropy loss variable, define the SGD optimizer variable, and define the reduced learning rate engine on </span><span class="No-Break"><span class="koboSpan" id="kobo.869.1">validation degradation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.870.1">
if distill_model:
    pass
model = ARCResNet50(num_classes=num_classes)
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-5)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=reduce_lr_patience, factor=0.1)</span></pre></li> <li><span class="koboSpan" id="kobo.871.1">Next, we will need to </span><a id="_idIndexMarker974"/><span class="koboSpan" id="kobo.872.1">define </span><a id="_idIndexMarker975"/><span class="koboSpan" id="kobo.873.1">the PyTorch dataset class to take in the image file paths and the sensitive attributes, which are gender data, the target, and the specified albumentation transform. </span><span class="koboSpan" id="kobo.873.2">The last variable will be utilized in the </span><span class="No-Break"><span class="koboSpan" id="kobo.874.1">next section:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.875.1">
class ImagesDataset(Dataset):
    def __init__(self, files, sensitive_attributes, targets=None, transforms=None, teacher_model_features=None):
        self.files = files
        self.sensitive_attributes = sensitive_attributes
        self.targets = targets
        self.transforms = transforms
        self.teacher_model_features = teacher_model_features
    def __len__(self):
        return len(self.files)
    def __getitem__(self, index):
        file = self.files[index]
        img = np.array(Image.open(file))
        if self.transforms is not None:
            img = self.transforms(image=img)["image"]
        if self.targets is None:
            return img
        target = self.targets[index]
        sensitive_attribute = self.sensitive_attributes[index]
        if self.teacher_model_features is None:
            return img, sensitive_attribute, target
        else:
            teacher_model_feature = torch.from_numpy(self.teacher_model_features[index])
            return img, sensitive_attribute, target, teacher_model_feature</span></pre></li> <li><span class="koboSpan" id="kobo.876.1">Now, we want to apply a </span><a id="_idIndexMarker976"/><span class="koboSpan" id="kobo.877.1">simple set of transform operations from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.878.1">albumentation</span></strong><span class="koboSpan" id="kobo.879.1"> library. </span><span class="koboSpan" id="kobo.879.2">Let’s define the method to</span><a id="_idIndexMarker977"/><span class="koboSpan" id="kobo.880.1"> return a transform instance with augmentation for training and without augmentation for validation purposes. </span><span class="koboSpan" id="kobo.880.2">Both require the transform instance to convert the image values into </span><span class="No-Break"><span class="koboSpan" id="kobo.881.1">PyTorch tensors:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.882.1">
def get_transforms(dataset: str):
     if dataset.lower() == "train":
           return albu.Compose([
           albu.Resize(224, 224),
            albu.HorizontalFlip(),
            albu.Normalize(),
            ToTensorV2()
        ])
    else:
      return albu.Compose([ albu.Resize(224, 224), albu.Normalize(), ToTensorV2()])</span></pre></li> <li><span class="koboSpan" id="kobo.883.1">Next, let’s initialize the dataset and the subsequent </span><span class="No-Break"><span class="koboSpan" id="kobo.884.1">dataset loader:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.885.1">
if distill_model:
    pass
else:
    train_dataset = ImagesDataset(train_images, train_gender_data, train_targets,  get_transforms('train'))
    val_dataset =  ImagesDataset(val_images, val_gender_data, val_targets, get_transforms('valid'))
loaders = {"train": DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8),
           "valid": DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=8)}</span></pre></li> <li><span class="koboSpan" id="kobo.886.1">Now, we will define the helper methods to help compute the multiclass bias and fairness metrics, which consist of performing safe division handling and zero division to prevent NaN values and computing false positives, true negatives, total positives, total negatives, and total data. </span><span class="koboSpan" id="kobo.886.2">Since this is a multiclass problem, we have to either choose macro-averaged or micro-averaged stats by class. </span><span class="koboSpan" id="kobo.886.3">Micro-averaged treats all samples equally, while macro-averaged treats all classes equally. </span><span class="koboSpan" id="kobo.886.4">Macro has an underlying issue where if the performance concerning a minority class is good, it </span><a id="_idIndexMarker978"/><span class="koboSpan" id="kobo.887.1">will give </span><a id="_idIndexMarker979"/><span class="koboSpan" id="kobo.888.1">a fake perception that the model is good in general. </span><span class="koboSpan" id="kobo.888.2">So, we will use </span><span class="No-Break"><span class="koboSpan" id="kobo.889.1">micro-averaged here:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.890.1">
def compute_classwise_stats(y_pred, y_true):
    unique_classes = np.unique(y_true)
    num_classes = len(unique_classes)
    false_positives = np.zeros(num_classes)
    total_negatives = np.zeros(num_classes)
    true_positives = np.zeros(num_classes)
    total_positives = np.zeros(num_classes)
    for c_idx in range(num_classes):
        class_label = unique_classes[c_idx]
        class_predictions = (y_pred == class_label)
        class_labels = (y_true == class_label)
        false_positives[c_idx] = np.sum(class_predictions &amp; ~class_labels)
        total_negatives[c_idx] = np.sum(~class_labels)
        true_positives[c_idx] = np.sum(class_predictions &amp; class_labels)
        total_positives[c_idx] = np.sum(class_labels)
    return {
        "false_positives":false_positives,
        "total_negatives": total_negatives,
        "true_positives": true_positives,
        "total_positives": total_positives,
        "total": total_negatives + total_positives,
    }
def safe_division(a, b):
    return a/b if b else 0.0</span></pre></li> <li><span class="koboSpan" id="kobo.891.1">Finally, we will utilize these helper methods to define the method that will compute four bias and fairness metrics using common computed results – that is, disparate impact, statistical parity difference, AOD, </span><span class="No-Break"><span class="koboSpan" id="kobo.892.1">and AAOD:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.893.1">
def compute_multiclass_fairness_metrics(
  y_pred, y_true, sensitive_attribute, priviledged_group, unpriviledged_group
):</span></pre></li> <li><span class="koboSpan" id="kobo.894.1">We will start by obtaining the false positives, true negatives, total positives, total negatives, and total data for the two groups, which are the privileged group and the non-privileged group, using the </span><span class="No-Break"><span class="koboSpan" id="kobo.895.1">helper method:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.896.1">
  y_pred = y_pred.argmax(1)
  group_stats = {}
  for group in [priviledged_group, unpriviledged_group]:
    group_idx = sensitive_attribute == group
    group_stats[group] = compute_classwise_stats(
      y_pred[group_idx], y_true[group_idx])</span></pre></li> <li><span class="koboSpan" id="kobo.897.1">Next, we will compute the</span><a id="_idIndexMarker980"/><span class="koboSpan" id="kobo.898.1"> true positive ratio of both the privileged and non-privileged groups using the computed group stats </span><a id="_idIndexMarker981"/><span class="koboSpan" id="kobo.899.1">so that it can be used directly to compute disparate impact and statistical </span><span class="No-Break"><span class="koboSpan" id="kobo.900.1">parity difference:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.901.1">
  disparities = []
  priviledged_true_positive_ratio = safe_division(
    np.sum(group_stats[priviledged_group]["true_positives"]),np.sum(group_stats[unpriviledged_group]["total"]))
  unpriviledged_true_positive_ratio = safe_division(
    np.sum(group_stats[unpriviledged_group]["true_positives"]),np.sum(group_stats[unpriviledged_group]["total"]))</span></pre></li> <li><span class="koboSpan" id="kobo.902.1">Now, we will compute the two mentioned metrics using the true </span><span class="No-Break"><span class="koboSpan" id="kobo.903.1">positive ratios:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.904.1">
  disparate_impact = safe_division(unpriviledged_true_positive_ratio, priviledged_true_positive_ratio)
  statistical_parity_diff = priviledged_true_positive_ratio - unpriviledged_true_positive_ratio</span></pre></li> <li><span class="koboSpan" id="kobo.905.1">Finally, we will compute AOD and AAOD using the true positive rates, </span><strong class="source-inline"><span class="koboSpan" id="kobo.906.1">tpr</span></strong><span class="koboSpan" id="kobo.907.1">, and false positive </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">rates, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.909.1">fpr</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.910.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.911.1">
  for group in [priviledged_group, unpriviledged_group]:
    group_stats[group]["fpr"] = safe_division(
      np.sum(group_stats[priviledged_group]["false_positives"]),np.sum(group_stats[priviledged_group]["total_negatives"]))
    group_stats[group]["tpr"] = safe_division(
      np.sum(group_stats[priviledged_group]["true_positives"]),
np.sum(group_stats[priviledged_group]["total_positives"])
        )
  AOD = (
        (group_stats[unpriviledged_group]["fpr"] - group_stats[priviledged_group]["fpr"])
        + (group_stats[unpriviledged_group]["tpr"] - group_stats[priviledged_group]["fpr"])
    ) / 2
  AAOD = (
        np.abs(group_stats[unpriviledged_group]["fpr"] - group_stats[priviledged_group]["fpr"])
        + np.abs(group_stats[unpriviledged_group]["tpr"] - group_stats[priviledged_group]["fpr"])
    ) / 2
    return {
        "disparate_impact": disparate_impact,
        "statistical_parity_diff": statistical_parity_diff,
        "average_odds_diff": AOD,
        "average_abs_odds_diff": AAOD
    }</span></pre></li> <li><span class="koboSpan" id="kobo.912.1">We will be</span><a id="_idIndexMarker982"/><span class="koboSpan" id="kobo.913.1"> computing </span><a id="_idIndexMarker983"/><span class="koboSpan" id="kobo.914.1">these four metrics during training and will be able to monitor and track the metrics as they’re being trained. </span><span class="koboSpan" id="kobo.914.2">To track the experiment, we will record the parameters and monitor their performance by iteration and epoch. </span><span class="koboSpan" id="kobo.914.3">We will use MLflow to do this. </span><span class="koboSpan" id="kobo.914.4">Let’s define the </span><strong class="source-inline"><span class="koboSpan" id="kobo.915.1">mlflow</span></strong><span class="koboSpan" id="kobo.916.1"> logger and log the parameters we defined earlier in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.917.1">step 2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.918.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.919.1">
mlflow_params = dict(
    batch_size=batch_size,
    lr=lr,
    num_epochs=num_epochs,
    early_stopping_epochs=early_stopping_epochs,
    reduce_lr_patience=reduce_lr_patience,
    experiment_mlflow=experiment_mlflow,
    logdir=logdir,
    only_male=only_male,
    distill_model=distill_model,
)
all_metrics = [
    "loss", "accuracy", "disparate_impact","statistical_parity_diff", "average_odds_diff","average_abs_odds_diff"
]
mlflow_logger = MLflowLogger(experiment=experiment_mlflow, tracking_uri="experiment/")
mlflow_logger.log_hparams(mlflow_params)</span></pre></li> <li><span class="koboSpan" id="kobo.920.1">As we will require a slightly specialized flow to be able to compute custom metrics and perform bias mitigation methods later on, we will define a custom runner using </span><strong class="source-inline"><span class="koboSpan" id="kobo.921.1">catalyst</span></strong><span class="koboSpan" id="kobo.922.1"> that will be used to train the ResNet50 model. </span><span class="koboSpan" id="kobo.922.2">We will need to define three custom logic for four methods: </span><strong class="source-inline"><span class="koboSpan" id="kobo.923.1">on_loader_start</span></strong><span class="koboSpan" id="kobo.924.1"> (to initialize the metric aggregator functionality), </span><strong class="source-inline"><span class="koboSpan" id="kobo.925.1">handle_batch</span></strong><span class="koboSpan" id="kobo.926.1"> (to obtain the loss), </span><strong class="source-inline"><span class="koboSpan" id="kobo.927.1">on_loader_end</span></strong><span class="koboSpan" id="kobo.928.1"> (to finalize the aggregated batch metrics and update the learning rate scheduler), and </span><strong class="source-inline"><span class="koboSpan" id="kobo.929.1">get_loggers</span></strong><span class="koboSpan" id="kobo.930.1"> (to log data into MLflow). </span><span class="koboSpan" id="kobo.930.2">Let’s start with </span><span class="No-Break"><span class="koboSpan" id="kobo.931.1">defining </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.932.1">on_loader_start</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.933.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.934.1">
class CustomRunner(dl.Runner):
  def on_loader_start(self, runner):
    super().on_loader_start(runner)
    self.meters = {key: metrics.AdditiveMetric(compute_on_call=False)
            for key in all_metrics}</span></pre></li> <li><span class="koboSpan" id="kobo.935.1">Next, we will define the batch handler logic, which will load the data from the batch data loader in a custom way, perform </span><a id="_idIndexMarker984"/><span class="koboSpan" id="kobo.936.1">forward</span><a id="_idIndexMarker985"/><span class="koboSpan" id="kobo.937.1"> propagation using the model initialized in the runner, and then compute loss, accuracy, and multiclass </span><span class="No-Break"><span class="koboSpan" id="kobo.938.1">fairness metrics:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.939.1">
  def handle_batch(self, batch):
    is_distill_mode = len(batch) == 4
    if is_distill_mode:
      pass
    else:
      features, sensitive_attribute, targets = batch
      logits = self.model(features, targets)
      loss = self.criterion(logits, targets)
    accuracy = (logits.argmax(1) == targets).float().mean().detach().cpu()
    batch_metrics = {
      "loss": loss.item(),"accuracy": accuracy.item()}
    batch_metrics.update(
**compute_multiclass_fairness_metrics(logits.detach().cpu().numpy(), targets.detach().cpu().numpy(), np.array(sensitive_attribute),priviledged_group,
unpriviledged_group))</span></pre></li> <li><span class="koboSpan" id="kobo.940.1">In the same method, we will also be required to update the current batch metric and the aggregated batch metrics so that they can be logged properly and finally perform backpropagation if it is training mode instead of </span><span class="No-Break"><span class="koboSpan" id="kobo.941.1">validation mode:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.942.1">
    self.batch_metrics.update(batch_metrics)
      for key in all_metrics:
        self.meters[key].update(
          self.batch_metrics[key], self.batch_size
        )
        if self.is_train_loader:
            loss.backward()
            self.optimizer.step()
            self.optimizer.zero_grad()</span></pre></li> <li><span class="koboSpan" id="kobo.943.1">Now, we must define the final two </span><span class="No-Break"><span class="koboSpan" id="kobo.944.1">straightforward methods:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.945.1">
  def on_loader_end(self, runner):
        for key in all_metrics:
            self.loader_metrics[key] = self.meters[key].compute()[0]
        if runner.is_valid_loader:
            runner.scheduler.step(self.loader_metrics[self._valid_metric])
        super().on_loader_end(runner)
  def get_loggers(self):
        return {
            "console": dl.ConsoleLogger(),
            "mlflow": mlflow_logger
        }</span></pre></li> <li><span class="koboSpan" id="kobo.946.1">Finally, we will </span><a id="_idIndexMarker986"/><span class="koboSpan" id="kobo.947.1">initialize</span><a id="_idIndexMarker987"/><span class="koboSpan" id="kobo.948.1"> the runner and train </span><span class="No-Break"><span class="koboSpan" id="kobo.949.1">the model:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.950.1">
runner = CustomRunner()
runner.train(
    model=model,
    criterion=criterion,
    optimizer=optimizer,
    loaders=loaders,
    logdir=logdir,
    num_epochs=num_epochs,
    valid_loader="valid",
    valid_metric="loss", # loss"
    minimize_valid_metric=True,
    fp16=False,
    verbose=True,
    load_best_on_end=True,
    scheduler=scheduler,
    callbacks=[
        dl.EarlyStoppingCallback(
            patience=early_stopping_epochs, loader_key="valid", metric_key="loss", minimize=True
        ),
        dl.CheckpointCallback(
            logdir=logdir, save_best=True, load_best_on_end=True, metric_key='loss'
        )
    ]
)</span></pre><p class="list-inset"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.951.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.952.1">.1</span></em><span class="koboSpan" id="kobo.953.1"> shows the </span><strong class="source-inline"><span class="koboSpan" id="kobo.954.1">mlflow</span></strong><span class="koboSpan" id="kobo.955.1"> plotted performance graph of the accuracy, AOD, disparate impact, and statistical parity difference at every epoch of both the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.956.1">validation partitions:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer116">
<span class="koboSpan" id="kobo.957.1"><img alt="Figure 13.1 – Performance graph of ResNet50 by epochs" src="image/B18187_13_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.958.1">Figure 13.1 – Performance graph of ResNet50 by epochs</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.959.1">The validation scores </span><a id="_idIndexMarker988"/><span class="koboSpan" id="kobo.960.1">ended up </span><a id="_idIndexMarker989"/><span class="koboSpan" id="kobo.961.1">with 0.424 for both AAOD and AOD, 0.841 accuracy, 0.398 disparate impact, and 0.051 </span><span class="No-Break"><span class="koboSpan" id="kobo.962.1">statistical parity.</span></span></p>
<ol>
<li value="25"><span class="koboSpan" id="kobo.963.1">The graph shows that while accuracy increased epoch after epoch, the bias and fairness metrics gradually became worse but stagnated at a value. </span><span class="koboSpan" id="kobo.963.2">The lowest bias model is at the 0</span><span class="superscript"><span class="koboSpan" id="kobo.964.1">th</span></span><span class="koboSpan" id="kobo.965.1"> epoch, where everything was close to zero, including the accuracy. </span><span class="koboSpan" id="kobo.965.2">Even though the model is not biased, the model is not useful at all. </span><span class="koboSpan" id="kobo.965.3">Another interesting observation is at the 16</span><span class="superscript"><span class="koboSpan" id="kobo.966.1">th</span></span><span class="koboSpan" id="kobo.967.1"> epoch mark – the model managed to get a better validation accuracy performance on the male samples as the AOD value became higher at the same point. </span><span class="koboSpan" id="kobo.967.2">Depending on the circumstances, you can opt to choose to take the model at the 15</span><span class="superscript"><span class="koboSpan" id="kobo.968.1">th</span></span><span class="koboSpan" id="kobo.969.1"> epoch, which has a somewhat good accuracy score but not the best and a lower </span><span class="No-Break"><span class="koboSpan" id="kobo.970.1">bias score.</span></span></li>
<li><span class="koboSpan" id="kobo.971.1">To make a deeper analysis, let’s take a look at where the model is focusing when it’s making predictions using the integrated gradients technique from Captum. </span><span class="koboSpan" id="kobo.971.2">Let’s visualize images that are mostly frontal facing. </span><span class="koboSpan" id="kobo.971.3">To do this, we must define the necessary </span><span class="No-Break"><span class="koboSpan" id="kobo.972.1">transform method:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.973.1">
resize_transform = albu.Resize(224, 224)
norm_transform = albu.Compose([
            albu.Normalize(),
            ToTensorV2()
        ])</span></pre></li> <li><span class="koboSpan" id="kobo.974.1">Now, let’s define the frontal faces </span><span class="No-Break"><span class="koboSpan" id="kobo.975.1">to visualize:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.976.1">
val_df = pd.read_csv('val_pose_info.csv')
straight_indexes = val_df[
    (val_df['pitch']&gt;-10) &amp;
    (val_df['pitch']&lt;10) &amp;
    (val_df['yaw']&gt;-10) &amp;
    (val_df['yaw']&lt;10)
].index.values</span></pre></li> <li><span class="koboSpan" id="kobo.977.1">Finally, let’s visualize</span><a id="_idIndexMarker990"/><span class="koboSpan" id="kobo.978.1"> the </span><a id="_idIndexMarker991"/><span class="No-Break"><span class="koboSpan" id="kobo.979.1">focus area:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.980.1">
integrated_gradients = IntegratedGradients(model)
noise_tunnel = NoiseTunnel(integrated_gradients)
for val_idx in straight_indexes[:5]: #range(1):
    image_path = val_images[val_idx]
    pred_label_idx = val_targets[val_idx]
    pil_image = Image.open(image_path)
    img = np.array(pil_image)
    transformed_image = resize_transform(image=img)["image"]
    input =  norm_transform(image=img)["image"].unsqueeze(0)
    attributions_ig_nt = noise_tunnel.attribute(
        input, nt_samples=5, nt_type="smoothgrad_sq",
        target=int(pred_label_idx)
    )
    _ = viz.visualize_image_attr_multiple(
        np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),
        transformed_image,
        ["original_image", "heat_map"],
        ["all", "positive"],
        cmap="turbo",
        show_colorbar=True
    )</span></pre><p class="list-inset"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.981.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.982.1">.2</span></em><span class="koboSpan" id="kobo.983.1"> shows the original images and focus areas of </span><span class="No-Break"><span class="koboSpan" id="kobo.984.1">the model:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer117">
<span class="koboSpan" id="kobo.985.1"><img alt="Figure 13.2 – Saliency explanations results of the trained ResNet50 model" src="image/B18187_13_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.986.1">Figure 13.2 – Saliency explanations results of the trained ResNet50 model</span></p>
<ol>
<li value="29"><span class="koboSpan" id="kobo.987.1">These visuals show that the model exhibits bias by focusing incorrectly on the hair of female faces. </span><span class="koboSpan" id="kobo.987.2">For males, the model </span><a id="_idIndexMarker992"/><span class="koboSpan" id="kobo.988.1">did not</span><a id="_idIndexMarker993"/><span class="koboSpan" id="kobo.989.1"> focus on the hair. </span><span class="koboSpan" id="kobo.989.2">The model also focuses on the white background a little. </span><span class="koboSpan" id="kobo.989.3">We’ll learn how to remove this bias in the </span><span class="No-Break"><span class="koboSpan" id="kobo.990.1">next section.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.991.1">Now that we understand some popular bias and fairness metrics, we need to know which metrics to use in different </span><span class="No-Break"><span class="koboSpan" id="kobo.992.1">use cases.</span></span></p>
<h1 id="_idParaDest-194"><a id="_idTextAnchor203"/><span class="koboSpan" id="kobo.993.1">Tailoring bias and fairness measures across use cases</span></h1>
<p><span class="koboSpan" id="kobo.994.1">The process of figuring</span><a id="_idIndexMarker994"/><span class="koboSpan" id="kobo.995.1"> out bias and fairness metrics to use for our use case can flow similarly to the process of figuring out general model performance evaluation metrics, as introduced in </span><a href="B18187_10.xhtml#_idTextAnchor161"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.996.1">Chapter 10</span></em></span></a><span class="koboSpan" id="kobo.997.1">, </span><em class="italic"><span class="koboSpan" id="kobo.998.1">Exploring Model Evaluation Methods</span></em><span class="koboSpan" id="kobo.999.1">, in the </span><em class="italic"><span class="koboSpan" id="kobo.1000.1">Engineering the base model evaluation metric</span></em><span class="koboSpan" id="kobo.1001.1"> section. </span><span class="koboSpan" id="kobo.1001.2">So, be sure to check that topic out! </span><span class="koboSpan" id="kobo.1001.3">However, bias and fairness have unique aspects that require additional heuristical recommendations. </span><span class="koboSpan" id="kobo.1001.4">Earlier, recommendations for metrics that belong to the same metric group were explored. </span><span class="koboSpan" id="kobo.1001.5">Now, let’s explore general recommendations on the four </span><span class="No-Break"><span class="koboSpan" id="kobo.1002.1">metric groups:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1003.1">Equal representation is always desired when there is a sensitive and protected attribute. </span><span class="koboSpan" id="kobo.1003.2">So, when you see these attributes, be sure to use equal representation-based metrics on both your data and the model. </span><span class="koboSpan" id="kobo.1003.3">Examples include race, gender, religion, sexual orientation, disability, age, socioeconomic status, political affiliations, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1004.1">criminal history.</span></span></li>
<li><span class="koboSpan" id="kobo.1005.1">Predictive performance consistency is another desired trait of a machine learning model that deals with sensitive and protected attributes. </span><span class="koboSpan" id="kobo.1005.2">So, when you see these attributes, be sure to use equal error-based metrics on </span><span class="No-Break"><span class="koboSpan" id="kobo.1006.1">your model.</span></span></li>
<li><span class="koboSpan" id="kobo.1007.1">Both distributional fairness metrics and equal representation metrics measure inequality. </span><span class="koboSpan" id="kobo.1007.2">However, distributional fairness works on continuous variables directly while equal representation metrics work on categorical variables. </span><span class="koboSpan" id="kobo.1007.3">Binning can be done on continuous variables to transform them into categories but it’s not straightforward to decide on the proper binning strategy needed. </span><span class="koboSpan" id="kobo.1007.4">So, use distributional fairness metrics when the variable to measure bias and fairness is a </span><span class="No-Break"><span class="koboSpan" id="kobo.1008.1">continuous variable.</span></span></li>
<li><span class="koboSpan" id="kobo.1009.1">Consider all potential aspects of bias and fairness and measure them separately with a chosen bias and </span><span class="No-Break"><span class="koboSpan" id="kobo.1010.1">fairness metrics:</span></span><ul><li><span class="koboSpan" id="kobo.1011.1">Let’s consider a scenario where a machine learning model is used to predict loan approvals. </span><span class="koboSpan" id="kobo.1011.2">One aspect of fairness is to ensure that loan approvals are granted fairly across different demographic groups, such as race or gender. </span><span class="koboSpan" id="kobo.1011.3">Ensuring equal representation of the data and the resulting model can help you accomplish that. </span><span class="koboSpan" id="kobo.1011.4">However, solely focusing on equal representation may not capture the complete picture. </span><span class="koboSpan" id="kobo.1011.5">For example, even though the overall loan approval rates are equal across groups, there could be a significant disparity in the interest rates assigned to different groups. </span><span class="koboSpan" id="kobo.1011.6">This disparity in interest rates could lead to unfair and inequitable outcomes, as certain groups may be charged higher interest rates, resulting in financial disadvantages. </span><span class="koboSpan" id="kobo.1011.7">Any additional evaluation and monitoring that uses distributional fairness metrics can help you understand the impact and assist in targeted bias mitigation of </span><span class="No-Break"><span class="koboSpan" id="kobo.1012.1">unfavored groups.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.1013.1">Evaluating the individual fairness of the outcome is useful when you deploy the machine learning model and receive individual data during model inferencing. </span><span class="koboSpan" id="kobo.1013.2">A threshold can be set here to create an alert </span><a id="_idIndexMarker995"/><span class="koboSpan" id="kobo.1014.1">when the individual fairness score is too high and requires a human reviewer to evaluate and make a </span><span class="No-Break"><span class="koboSpan" id="kobo.1015.1">manual decision.</span></span></li>
<li><span class="koboSpan" id="kobo.1016.1">Compute these metrics separately by sensitive groups and compare them visually to get a sense of fairness across groups. </span><span class="koboSpan" id="kobo.1016.2">This can help you craft targeted bias mitigation responses to </span><span class="No-Break"><span class="koboSpan" id="kobo.1017.1">vulnerable groups.</span></span></li>
<li><span class="koboSpan" id="kobo.1018.1">Prediction explanations may help in understanding the reasons for bias </span><span class="No-Break"><span class="koboSpan" id="kobo.1019.1">and fairness.</span></span></li>
<li><span class="koboSpan" id="kobo.1020.1">Bias and fairness measures can conflict with accuracy-based </span><span class="No-Break"><span class="koboSpan" id="kobo.1021.1">performance measures.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1022.1">Additionally, two global opposing views that will affect how you see fairness are </span><span class="No-Break"><span class="koboSpan" id="kobo.1023.1">worth mentioning:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1024.1">We’re All Equal</span></strong><span class="koboSpan" id="kobo.1025.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1026.1">WAE</span></strong><span class="koboSpan" id="kobo.1027.1">): The notion that</span><a id="_idIndexMarker996"/><span class="koboSpan" id="kobo.1028.1"> data may not accurately represent reality due to the presence of inherent biases </span><span class="No-Break"><span class="koboSpan" id="kobo.1029.1">within it</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1030.1">What You See Is What You Get</span></strong><span class="koboSpan" id="kobo.1031.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1032.1">WYSIWYG</span></strong><span class="koboSpan" id="kobo.1033.1">): The </span><a id="_idIndexMarker997"/><span class="koboSpan" id="kobo.1034.1">notion is that the information presented by the data reflects an unbiased representation of reality, even if it </span><span class="No-Break"><span class="koboSpan" id="kobo.1035.1">reveals inequalities</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1036.1">An extreme of either view will either remove any chances of building a model (WAE) or be too ignorant to care about fairness biases that will eventually lead to negative consequences, as mentioned earlier in this chapter (WYSIWYG). </span><span class="koboSpan" id="kobo.1036.2">To create a successful machine learning model in our use case, we will need to balance the two views strategically so that both accuracy performance and fairness requirements can be satisfied. </span><span class="koboSpan" id="kobo.1036.3">A good strategy here to employ is to apply common sense and accept what seems logical for a causal relationship (WYSIWYG), and practice fair processes that help us understand and mitigate the partial aspect of bias (WAE) even when true fairness can’t </span><span class="No-Break"><span class="koboSpan" id="kobo.1037.1">be achieved.</span></span></p>
<p><span class="koboSpan" id="kobo.1038.1">Here are some examples with views to adopt that will make the </span><span class="No-Break"><span class="koboSpan" id="kobo.1039.1">most sense:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1040.1">Adopting WYSIWYG</span></strong><span class="koboSpan" id="kobo.1041.1">: In the domain of personalized advertising using machine learning, the WYSIWYG view would involve tailoring advertisements based on observed user behavior and preferences. </span><span class="koboSpan" id="kobo.1041.2">For example, if a user frequently engages with content related to fitness, the system will present ads for fitness equipment or gym memberships. </span><span class="koboSpan" id="kobo.1041.3">The goal is to provide a personalized user experience that aligns with their interests and needs. </span><span class="koboSpan" id="kobo.1041.4">In this use case, any notion of the WAE view will fail the project as it contradicts the goal </span><span class="No-Break"><span class="koboSpan" id="kobo.1042.1">of personalization.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1043.1">Adopting something like 75% WYSIWYG and 25% WAE</span></strong><span class="koboSpan" id="kobo.1044.1">: In the context of making hiring decisions using machine learning, the WAE view would help advocate for equal consideration of all candidates without any bias related to gender, race, or other protected attributes. </span><span class="koboSpan" id="kobo.1044.2">The WYSIWYG view will then allow a machine learning model to be built based solely on their qualifications and skills. </span><span class="koboSpan" id="kobo.1044.3">The strategy to create a fair and unbiased selection process will help promote equal opportunities for all applicants while still allowing a functional machine learning model to be </span><span class="No-Break"><span class="koboSpan" id="kobo.1045.1">built successfully.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1046.1">In terms of metrics, the equal representation-based metric group is associated with the WAE view while the equal error-based </span><a id="_idIndexMarker998"/><span class="koboSpan" id="kobo.1047.1">metric group is associated with the WYSIWYG view. </span><span class="koboSpan" id="kobo.1047.2">So, again, choose these two metric groups if the two views are involved in your </span><span class="No-Break"><span class="koboSpan" id="kobo.1048.1">use case.</span></span></p>
<p><span class="koboSpan" id="kobo.1049.1">Next, we’ll discover ways we can mitigate bias in our machine </span><span class="No-Break"><span class="koboSpan" id="kobo.1050.1">learning models.</span></span></p>
<h1 id="_idParaDest-195"><a id="_idTextAnchor204"/><span class="koboSpan" id="kobo.1051.1">Mitigating AI bias</span></h1>
<p><span class="koboSpan" id="kobo.1052.1">AI bias is an algorithmic bias</span><a id="_idIndexMarker999"/><span class="koboSpan" id="kobo.1053.1"> that either comes from the model itself through its learning process or the data it used to learn from. </span><span class="koboSpan" id="kobo.1053.2">The most obvious solution to mitigate bias is not programmatic mitigation methods but ensuring fair processes when collecting data. </span><span class="koboSpan" id="kobo.1053.3">A data collection and preparation process is only truly fair when it not only ensures the resulting data is balanced by sensitive attributes but also ensures all inherent and systematic biases are </span><span class="No-Break"><span class="koboSpan" id="kobo.1054.1">not included.</span></span></p>
<p><span class="koboSpan" id="kobo.1055.1">Unfortunately, a balanced dataset based on the sensitive attribute does not guarantee a fair model. </span><span class="koboSpan" id="kobo.1055.2">There can be differences in appearance among subgroups under the hood or associative groups of the data concerning multiple factors, which can potentially cause a biased system. </span><span class="koboSpan" id="kobo.1055.3">Bias, however, can be mitigated partially when the dataset is balanced compared to without concerning the observable sensitive groups. </span><span class="koboSpan" id="kobo.1055.4">But what are all these attributes? </span><span class="koboSpan" id="kobo.1055.5">It might be easier to identify data attributes in tabular structured data with defined column names, but for unstructured data meant for deep learning, it’s impossible to cover all the </span><span class="No-Break"><span class="koboSpan" id="kobo.1056.1">possible attributes.</span></span></p>
<p><span class="koboSpan" id="kobo.1057.1">To dive deeper into actual examples, text data can contain a ton of attributes with examples, such as language, genre, topic, length, style, tone, time period, authorship, geographic origin, and cultural perspective. </span><span class="koboSpan" id="kobo.1057.2">Image data can also contain a ton of attributes with examples such as subject/content, perspective, lighting, composition, color, texture, resolution, orientation, context, and cultural relevance. </span><span class="koboSpan" id="kobo.1057.3">Finally, audio data can also contain a ton of attributes, such as genre, language, duration, sound quality, instrumentation, vocal style, tempo, mood, cultural influence, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1058.1">recording environment.</span></span></p>
<p><span class="koboSpan" id="kobo.1059.1">It’s hard to ensure equal representation in all facets - more so when data is readily available and is already originally highly imbalanced with only a few examples for certain categories and plenty for others. </span><span class="koboSpan" id="kobo.1059.2">Ideally, bias mitigation should always be executed right from the data preparation stage. </span><span class="koboSpan" id="kobo.1059.3">However, if that's not possible, programmatic</span><a id="_idIndexMarker1000"/><span class="koboSpan" id="kobo.1060.1"> bias mitigation methods can be applied after data collection. </span></p>
<p><span class="koboSpan" id="kobo.1061.1">To get a clearer idea of these methods, have a look at </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1062.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.1063.1">.3</span></em><span class="koboSpan" id="kobo.1064.1">, which presents an overview of various </span><span class="No-Break"><span class="koboSpan" id="kobo.1065.1">bias-reducing approaches:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer118">
<span class="koboSpan" id="kobo.1066.1"><img alt="Figure 13.3 – The four steps of bias mitigation under two machine learning life cycle stages" src="image/B18187_13_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1067.1">Figure 13.3 – The four steps of bias mitigation under two machine learning life cycle stages</span></p>
<p><span class="koboSpan" id="kobo.1068.1">Programmatic bias</span><a id="_idIndexMarker1001"/><span class="koboSpan" id="kobo.1069.1"> mitigation provides methods that can be applied in three different stages of the </span><span class="No-Break"><span class="koboSpan" id="kobo.1070.1">model-building process:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1071.1">Pre-processing</span></strong><span class="koboSpan" id="kobo.1072.1">: This is part</span><a id="_idIndexMarker1002"/><span class="koboSpan" id="kobo.1073.1"> of the data preparation ML life cycle stage. </span><span class="koboSpan" id="kobo.1073.2">Here are some examples of bias mitigation methods that belong to </span><span class="No-Break"><span class="koboSpan" id="kobo.1074.1">this group:</span></span><ul><li><span class="koboSpan" id="kobo.1075.1">Eliminating protected attributes from being used in the model. </span><span class="koboSpan" id="kobo.1075.2">However, information about the protected attribute could still present itself in other associative attributes. </span><span class="koboSpan" id="kobo.1075.3">Additionally, some attributes are deeply interconnected with other key information that’s required to predict the desired label, and unfortunately can’t be removed easily. </span><span class="koboSpan" id="kobo.1075.4">Examples include gender in </span><span class="No-Break"><span class="koboSpan" id="kobo.1076.1">facial images.</span></span></li><li><span class="koboSpan" id="kobo.1077.1">Disparate Impact Remover, available in the AIF360 open source library. </span><span class="koboSpan" id="kobo.1077.2">It balances the dataset group proportions by dropping data rows to achieve a better </span><span class="No-Break"><span class="koboSpan" id="kobo.1078.1">disparate score.</span></span></li><li><span class="koboSpan" id="kobo.1079.1">Weigh privileged class loss so that it’s lower than unprivileged class loss during training so that errors between the classes are </span><span class="No-Break"><span class="koboSpan" id="kobo.1080.1">more equal.</span></span></li><li><span class="koboSpan" id="kobo.1081.1">Targeted data augmentation for unprivileged classes. </span><span class="koboSpan" id="kobo.1081.2">Augmentation adds more data variations and can be applied in </span><span class="No-Break"><span class="koboSpan" id="kobo.1082.1">two ways:</span></span><ul><li><span class="koboSpan" id="kobo.1083.1">Adding more data variations in unprivileged groups with augmentation will help increase accuracy performance there and contribute to the balancing of error rates, especially when the unprivileged class </span><span class="No-Break"><span class="koboSpan" id="kobo.1084.1">is underrepresented.</span></span></li><li><span class="koboSpan" id="kobo.1085.1">Counterfactual role reversal augmentation inverts the privileged group into the unprivileged group and vice versa and allows for equal representation. </span><span class="koboSpan" id="kobo.1085.2">Here are some augmentations that can be used based on </span><span class="No-Break"><span class="koboSpan" id="kobo.1086.1">variable type:</span></span></li></ul></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.1087.1">          • </span><strong class="bold"><span class="koboSpan" id="kobo.1088.1">Text</span></strong><span class="koboSpan" id="kobo.1089.1">: Use </span><span class="No-Break"><span class="koboSpan" id="kobo.1090.1">word swap</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.1091.1">          • </span><strong class="bold"><span class="koboSpan" id="kobo.1092.1">All variable types</span></strong><span class="koboSpan" id="kobo.1093.1">: Use style transfer techniques. </span><span class="koboSpan" id="kobo.1093.2">Example techniques are </span><span class="No-Break"><span class="koboSpan" id="kobo.1094.1">as follows:</span></span></p><ul><li><span class="koboSpan" id="kobo.1095.1">Using Generative AI techniques from a trained StarGAN, which is an image generator that can invert a person’s gender, change a person’s age, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1096.1">much more.</span></span></li><li><span class="koboSpan" id="kobo.1097.1">Optimize the desired image to mimic the style of another image by reducing the distance between a chosen intermediate layer between the images. </span><span class="koboSpan" id="kobo.1097.2">This method is called transfer by input optimization and is based on the neural interpretation technique mentioned in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1098.1">previous chapter.</span></span></li><li><span class="koboSpan" id="kobo.1099.1">Targeted</span><a id="_idIndexMarker1003"/><span class="koboSpan" id="kobo.1100.1"> counterfactual role reversal not through additional augmentation but a permanent input replacement for a deployed model. </span><span class="koboSpan" id="kobo.1100.2">This allows you to explicitly control the equality of the results </span><span class="No-Break"><span class="koboSpan" id="kobo.1101.1">during deployment.</span></span></li><li><span class="koboSpan" id="kobo.1102.1">OpenAI changed “male” to “female” in their Dall-E text-to-image prompts randomly as the model is biased to depict males for roles such as professor </span><span class="No-Break"><span class="koboSpan" id="kobo.1103.1">and CEO.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1104.1">In-processing</span></strong><span class="koboSpan" id="kobo.1105.1">: This is part of </span><a id="_idIndexMarker1004"/><span class="koboSpan" id="kobo.1106.1">the model development machine learning life cycle stage and is the process of training a model. </span><span class="koboSpan" id="kobo.1106.2">Here are some examples of bias mitigation methods that belong to </span><span class="No-Break"><span class="koboSpan" id="kobo.1107.1">this group:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.1108.1">Knowledge distillation</span></strong><span class="koboSpan" id="kobo.1109.1">: This was introduced in </span><a href="B18187_08.xhtml#_idTextAnchor125"><em class="italic"><span class="koboSpan" id="kobo.1110.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.1111.1">, </span><em class="italic"><span class="koboSpan" id="kobo.1112.1">Exploring Supervised Deep Learning</span></em><span class="koboSpan" id="kobo.1113.1">. </span><span class="koboSpan" id="kobo.1113.2">The idea is that a teacher model that has been trained with a much bigger and more representative dataset will be less biased compared to a student model that is being trained on a much smaller custom dataset. </span><span class="koboSpan" id="kobo.1113.3">Ideally, the fairness from the teacher model will be distilled into the student model. </span><span class="koboSpan" id="kobo.1113.4">However, knowledge distillation can also cause an increased bias in the resulting student model when you distill it with a biased </span><span class="No-Break"><span class="koboSpan" id="kobo.1114.1">teacher model.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.1115.1">Adversarial debiasing</span></strong><span class="koboSpan" id="kobo.1116.1">: This method iteratively trains a classifier to optimize prediction accuracy while simultaneously minimizing an adversary model’s ability to infer the protected attribute from the predictions. </span><span class="koboSpan" id="kobo.1116.2">The classifier aims to make accurate predictions on the target variable, while the adversary tries to discern the sensitive attribute associated with bias. </span><span class="koboSpan" id="kobo.1116.3">This simultaneous training process creates a competitive environment where the classifier learns to encode important information about the target variable while reducing the influence of potentially biased features. </span><span class="koboSpan" id="kobo.1116.4">By doing so, adversarial debiasing promotes fairness by mitigating the impact of sensitive attributes and enhancing the overall equity of the </span><span class="No-Break"><span class="koboSpan" id="kobo.1117.1">model’s predictions.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.1118.1">Regularization</span></strong><span class="koboSpan" id="kobo.1119.1">: In deep learning, regularization involves any addition or modification to the neural network, data, or training process that is used to increase the generalization of the model to external data. </span><span class="koboSpan" id="kobo.1119.2">This can indirectly contribute to reducing bias in the model. </span><span class="koboSpan" id="kobo.1119.3">Some common regularization methods include dropout layers, L1/L2 regularization, batch normalization, group normalization, weight standardization, stochastic depth, label smoothing, and data augmentation. </span><span class="koboSpan" id="kobo.1119.4">By improving generalization, regularization methods can help the model learn more general patterns in the data instead of fitting too closely to the training set, which might contain </span><a id="_idIndexMarker1005"/><span class="koboSpan" id="kobo.1120.1">biased features. </span><span class="koboSpan" id="kobo.1120.2">This method was explored more extensively in </span><a href="B18187_02.xhtml#_idTextAnchor040"><em class="italic"><span class="koboSpan" id="kobo.1121.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.1122.1">, </span><em class="italic"><span class="koboSpan" id="kobo.1123.1">Designing Deep </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1124.1">Learning Architectures</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1125.1">.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1126.1">Post-processing</span></strong><span class="koboSpan" id="kobo.1127.1">: This is part</span><a id="_idIndexMarker1006"/><span class="koboSpan" id="kobo.1128.1"> of the model development machine learning life cycle stage but only covers processing the trained model’s outputs to mitigate bias. </span><span class="koboSpan" id="kobo.1128.2">Here are some examples of bias mitigation methods that belong to </span><span class="No-Break"><span class="koboSpan" id="kobo.1129.1">this group:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.1130.1">Test-time counterfactual role reversal augmentation ensemble</span></strong><span class="koboSpan" id="kobo.1131.1">: This method involves performing two predictions each using opposite roles and performing an ensemble of the predictions. </span><span class="koboSpan" id="kobo.1131.2">A max or exponential mean operation for ensembling performs much better than an average operation, as shown </span><span class="No-Break"><span class="koboSpan" id="kobo.1132.1">in </span></span><a href="https://www.amazon.science/publications/mitigating-gender-bias-in-distilled-language-models-via-counterfactual-role-reversal"><span class="No-Break"><span class="koboSpan" id="kobo.1133.1">https://www.amazon.science/publications/mitigating-gender-bias-in-distilled-language-models-via-counterfactual-role-reversal</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1134.1">.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.1135.1">Equalized odds postprocessing</span></strong><span class="koboSpan" id="kobo.1136.1">: This method involves modifying the output predictions of a classifier to ensure equal false positive and false negative rates across</span><a id="_idIndexMarker1007"/><span class="koboSpan" id="kobo.1137.1"> different groups through threshold optimization by groups. </span><span class="koboSpan" id="kobo.1137.2">Specifically, prediction thresholds for each protected group are </span><span class="No-Break"><span class="koboSpan" id="kobo.1138.1">determined separately.</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.1139.1">It is important to note </span><a id="_idIndexMarker1008"/><span class="koboSpan" id="kobo.1140.1">that a fairer model obtained after bias mitigation would likely cause a reduction in accuracy-based metrics. </span><span class="koboSpan" id="kobo.1140.2">If the loss in an accuracy-based metric is minor enough, a fair model is highly desired as there would not be an issue in using bias mitigation methods. </span><span class="koboSpan" id="kobo.1140.3">To that end, always start by creating a baseline model and evaluate fairness with the chosen bias and fairness metrics to ensure that bias even exists in your model before using any bias mitigation methods. </span><span class="koboSpan" id="kobo.1140.4">Bias mitigation methods always cause a substantial increase in training time needed, so make sure it’s </span><span class="No-Break"><span class="koboSpan" id="kobo.1141.1">worth it.</span></span></p>
<p><span class="koboSpan" id="kobo.1142.1">Additionally, there are a few behaviors related to bias that are useful to </span><span class="No-Break"><span class="koboSpan" id="kobo.1143.1">know about:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1144.1">Decision-making algorithms tend to be biased toward more common occurrences, so balanced data can help reduce </span><span class="No-Break"><span class="koboSpan" id="kobo.1145.1">this bias</span></span></li>
<li><span class="koboSpan" id="kobo.1146.1">Pruned models increase bias (more </span><span class="No-Break"><span class="koboSpan" id="kobo.1147.1">at </span></span><a href="https://arxiv.org/pdf/2106.07849.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1148.1">https://arxiv.org/pdf/2106.07849.pdf</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.1149.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.1150.1">Models with limited capacity (smaller models) tend to exploit the biases in the dataset (</span><a href="https://aclanthology.org/2022.gebnlp-1.27.pdf"><span class="koboSpan" id="kobo.1151.1">https://aclanthology.org/2022.gebnlp-1.27.pdf</span></a><span class="koboSpan" id="kobo.1152.1">), so be wary when you’re performing knowledge distillation on a smaller model and evaluate bias </span><span class="No-Break"><span class="koboSpan" id="kobo.1153.1">and fairness</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1154.1">When it comes to mitigating </span><a id="_idIndexMarker1009"/><span class="koboSpan" id="kobo.1155.1">bias, you might be wondering which of the four groups of methods to choose from. </span><span class="koboSpan" id="kobo.1155.2">Here’s a suggestion: it’s best to begin by addressing bias as early as possible in the process, where you have the most control and flexibility. </span><span class="koboSpan" id="kobo.1155.3">You don’t want to be stuck with limited options to mitigate bias and end up not being able to satisfactorily mitigate bias. </span><span class="koboSpan" id="kobo.1155.4">If you don’t have access to the data collection stage, you can utilize data preprocessing techniques. </span><span class="koboSpan" id="kobo.1155.5">On the other hand, if you don’t have access to the data itself but have a trained model, postprocessing techniques should be used. </span><span class="koboSpan" id="kobo.1155.6">Techniques can be combined, so be sure to measure bias using the metrics introduced to ensure that each technique that’s applied improves the fairness of the resulting model. </span><span class="koboSpan" id="kobo.1155.7">Also, consider using multiple methods to mitigate </span><span class="No-Break"><span class="koboSpan" id="kobo.1156.1">more bias.</span></span></p>
<p><span class="koboSpan" id="kobo.1157.1">The programmatic bias mitigation methods we’ve introduced so far are separated into three groups. </span><span class="koboSpan" id="kobo.1157.2">However, a robust bias mitigation method exists for deep learning models that lies in the intersection of all three of them. </span><span class="koboSpan" id="kobo.1157.3">The method is a fusion between counterfactual augmentation, mix-up augmentation, knowledge distillation, and counterfactual test time augmentation. </span><span class="koboSpan" id="kobo.1157.4">The idea is to do </span><span class="No-Break"><span class="koboSpan" id="kobo.1158.1">the following:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1159.1">Use counterfactual augmentation to train both the teacher model and student on the </span><span class="No-Break"><span class="koboSpan" id="kobo.1160.1">entire dataset.</span></span></li>
<li><span class="koboSpan" id="kobo.1161.1">Distill the counterfactual ensembled chosen layer features of the teacher model with exponential max to the student model. </span><span class="koboSpan" id="kobo.1161.2">This is similar to mix-up augmentation but on the </span><span class="No-Break"><span class="koboSpan" id="kobo.1162.1">feature layer.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.1163.1">However, counterfactual role reversal remains to be a technique that’s more accessible to text. </span><span class="koboSpan" id="kobo.1163.2">Let’s discover how to use the generic knowledge distillation method to reduce bias on the same use case we explored in the previous section on face classification. </span><span class="koboSpan" id="kobo.1163.3">The method we will be introducing here is from </span><a href="https://arxiv.org/pdf/2112.09786.pdf"><span class="koboSpan" id="kobo.1164.1">https://arxiv.org/pdf/2112.09786.pdf</span></a><span class="koboSpan" id="kobo.1165.1">, which provides </span><span class="No-Break"><span class="koboSpan" id="kobo.1166.1">two methods:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1167.1">(Distill and debias) D&amp;D++</span></strong><span class="koboSpan" id="kobo.1168.1">: First, train the teacher model using only privileged group data. </span><span class="koboSpan" id="kobo.1168.2">Then, initialize the student model with the teacher model weights and train the student model with normal loss and the knowledge distillation loss using the cosine similarity of the chosen feature layer. </span><span class="koboSpan" id="kobo.1168.3">Lastly, initialize a final student network using the previously trained student model and train on the entire dataset with knowledge distillation from the previous student model as the </span><span class="No-Break"><span class="koboSpan" id="kobo.1169.1">teacher model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1170.1">One-step distillation D&amp;D</span></strong><span class="koboSpan" id="kobo.1171.1">: To make it simpler, but still immediately effective, the steps can be simplified. </span><span class="koboSpan" id="kobo.1171.2">First, train the teacher model using only privileged group data. </span><span class="koboSpan" id="kobo.1171.3">Then, train the student model on the entire dataset with knowledge distillation from the </span><span class="No-Break"><span class="koboSpan" id="kobo.1172.1">teacher model.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1173.1">Let’s explore the one-step distillation D&amp;D method practically by using the use case we experimented with in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1174.1">previous section:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1175.1">First, we will be </span><a id="_idIndexMarker1010"/><span class="koboSpan" id="kobo.1176.1">training a teacher model using only the privileged group data, which only consists of male facial identities. </span><span class="koboSpan" id="kobo.1176.2">Let’s define the specifically different configurations for </span><span class="No-Break"><span class="koboSpan" id="kobo.1177.1">this example:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1178.1">
batch_size = 64
lr = 0.05
num_epochs = 22
early_stopping_epochs = 12
reduce_lr_patience = 3
experiment_mlflow = "bias_mitigation_v2"
logdir = 'experiments/face_modelv2'
only_male=False
distill_model=False</span></pre></li> <li><span class="koboSpan" id="kobo.1179.1">We will be using the same code base we introduced in the previous section but with some additional custom code. </span><span class="koboSpan" id="kobo.1179.2">The first is an addition to the code in </span><em class="italic"><span class="koboSpan" id="kobo.1180.1">step 6</span></em><span class="koboSpan" id="kobo.1181.1"> of the </span><em class="italic"><span class="koboSpan" id="kobo.1182.1">Evaluating the bias and fairness of a deep learning model</span></em><span class="koboSpan" id="kobo.1183.1"> section, where we will be removing the female data in both the training and </span><span class="No-Break"><span class="koboSpan" id="kobo.1184.1">validation data:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1185.1">
if only_male:
  train_raw_targets = targets[train_inds]
  val_raw_targets = targets[val_inds]
  train_male_inds = np.where(train_gender_data=='Male')[0]
  train_images = train_images[train_male_inds]
  train_targets = train_targets[train_male_inds]
  train_gender_data = train_gender_data[train_male_inds]                          val_male_inds = np.where(
  val_gender_data=='Male')[0]
  val_images = val_images[val_male_inds]
  val_targets = val_targets[val_male_inds]
  val_gender_data = val_gender_data[val_male_inds]</span></pre></li> <li><span class="koboSpan" id="kobo.1186.1">Second is </span><em class="italic"><span class="koboSpan" id="kobo.1187.1">step 7</span></em><span class="koboSpan" id="kobo.1188.1">, where we will define a special forward method and the method to get the last conv features. </span><span class="koboSpan" id="kobo.1188.2">The idea is that we want to make sure the focus areas are the</span><a id="_idIndexMarker1011"/><span class="koboSpan" id="kobo.1189.1"> same and not the probabilities of the facial identity themselves, which will be useless when the model is used as a facial recognition featurizer. </span><span class="koboSpan" id="kobo.1189.2">The special forward method is designed to return both the output logits and the last convolutional features in one forward pass, </span><span class="No-Break"><span class="koboSpan" id="kobo.1190.1">reducing latency:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1191.1">
def get_last_conv_features(self, x):
        x = self.model.conv1(x)
        x = self.model.bn1(x)
        x = self.model.relu(x)
        x = self.model.maxpool(x)
        x = self.model.layer1(x)
        x = self.model.layer2(x)
        x = self.model.layer3(x)
        x = self.model.layer4(x)
        x = self.model.avgpool(x)
        x = torch.flatten(x, 1)
        return x
    def special_forward(self, x, targets=None):
        model_features = self.get_last_conv_features(x)
        outputs = self.model.fc(model_features)
        outputs = self.head(outputs, targets)
        return outputs, model_features</span></pre></li> <li><span class="koboSpan" id="kobo.1192.1">Next is </span><em class="italic"><span class="koboSpan" id="kobo.1193.1">step 8</span></em><span class="koboSpan" id="kobo.1194.1">, where we will extract the teacher model features once before starting training. </span><span class="koboSpan" id="kobo.1194.2">This will</span><a id="_idIndexMarker1012"/><span class="koboSpan" id="kobo.1195.1"> reduce the time and resources needed to train the student model as the teacher model’s features will remain fixed on the same data </span><span class="No-Break"><span class="koboSpan" id="kobo.1196.1">without augmentation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1197.1">
device = torch.device("cuda")
if distill_model:
  if os.path.exists('all_teacher_model_features.npy'):
    all_teacher_model_features = np.load('all_teacher_model_features.npy')
 else:
    teacher_model = ARCResNet50(num_classes=num_classes)
    state_dict = torch.load(os.path.join(distill_model, "model.last.pth"))
    teacher_model.load_state_dict(state_dict)
    teacher_model.to(device)
    cpu_device = torch.device('cpu')
    entire_dataset =  ImagesDataset(image_path, gender_data, targets=id_targets, transforms=get_transforms('valid'))
    entire_data_loader = DataLoader(entire_dataset, batch_size=val_batch_size, shuffle=False, num_workers=8)
    all_teacher_model_features = []
    for batch in tqdm_notebook(entire_data_loader):
      inputs, sensitive_attribute, targets = batch
      with torch.no_grad():
        outputs = teacher_model.get_last_conv_features(inputs.to(device)).to(cpu_device).numpy()
      all_teacher_model_features.append(outputs)
    del teacher_model
    all_teacher_model_features = np.vstack(all_teacher_model_features)
    np.save('all_teacher_model_features.npy', all_teacher_model_features)
    train_teacher_model_features = all_teacher_model_features[train_inds]
    val_teacher_model_features = all_teacher_model_features[val_inds]</span></pre></li> <li><span class="koboSpan" id="kobo.1198.1">Next, we will define the </span><a id="_idIndexMarker1013"/><span class="koboSpan" id="kobo.1199.1">training and validation dataset that takes in the training and validation teacher model features separately from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1200.1">step 10</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1201.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1202.1">
if distill_model:
    train_dataset = ImagesDataset(
        train_images,
        train_gender_data,
        train_targets,
        get_transforms('train'),
        train_teacher_model_features,
    )
    val_dataset =  ImagesDataset(
        val_images,
        val_gender_data,
        val_targets,
        get_transforms('valid'),
        val_teacher_model_features,
    )</span></pre></li> <li><span class="koboSpan" id="kobo.1203.1">The final change is to add handling of the batch loading by taking the extra teacher model features </span><a id="_idIndexMarker1014"/><span class="koboSpan" id="kobo.1204.1">and loss using both cross entropy loss and the cosine similarity loss of the student and teacher model’s last convolutional layer features from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1205.1">step 14</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1206.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1207.1">
if is_distill_mode:
  features, sensitive_attribute, targets, teacher_model_features = batch
  logits, child_model_features = self.model.special_forward(features, targets)
  loss = self.criterion(logits, targets) + nn.functional.cosine_similarity(teacher_model_features, child_model_features).mean()</span></pre></li> <li><span class="koboSpan" id="kobo.1208.1">Now, run through all the steps from the previous section with the changes; you’ll get an approximate validation metric score of 0.774 accuracy with all other scores of 0 as there are no females in this </span><span class="No-Break"><span class="koboSpan" id="kobo.1209.1">first step.</span></span></li>
<li><span class="koboSpan" id="kobo.1210.1">To execute the next step of one-step distillation, execute the previous code once more but with the following </span><span class="No-Break"><span class="koboSpan" id="kobo.1211.1">configuration changes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1212.1">
batch_size = 64
val_batch_size = 100
lr = 0.05
num_epochs = 150
early_stopping_epochs = 5
reduce_lr_patience = 2
experiment_mlflow = "bias_mitigation_v3"
logdir = 'experiments/face_modelv3'
only_male=False
distill_model = 'experiments/face_modelv2'</span></pre></li> <li><span class="koboSpan" id="kobo.1213.1">The validation scores for the one-step distillation D&amp;D approach end up with 0.3838 for both </span><a id="_idIndexMarker1015"/><span class="koboSpan" id="kobo.1214.1">AAOD and AOD, 0.76 accuracy, 0.395 disparate impact, and 0.04627 statistical parity. </span><span class="koboSpan" id="kobo.1214.2">For a fair comparison, the performance of basic training in terms of accuracy is an accuracy of 0.76333, 0.38856 for both AAOD and AOD, a 0.3885 disparate impact, and a 0.04758 statistical parity. </span><span class="koboSpan" id="kobo.1214.3">This means that the improvements are mainly from the AOD with a 0.0047 difference and statistical parity with a </span><span class="No-Break"><span class="koboSpan" id="kobo.1215.1">0.00131 difference.</span></span></li>
<li><span class="koboSpan" id="kobo.1216.1">By using the integrated gradients code from </span><em class="italic"><span class="koboSpan" id="kobo.1217.1">step 19</span></em><span class="koboSpan" id="kobo.1218.1"> again on the model we trained with bias mitigation methods, the following results can </span><span class="No-Break"><span class="koboSpan" id="kobo.1219.1">be obtained:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer119">
<span class="koboSpan" id="kobo.1220.1"><img alt="Figure 13.4: Explanations of the one-step distillation D&amp;D model" src="image/B18187_13_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1221.1">Figure 13.4: Explanations of the one-step distillation D&amp;D model</span></p>
<p><span class="koboSpan" id="kobo.1222.1">The model now focuses on the right features – that is, facial features without backgrounds or hair regardless </span><span class="No-Break"><span class="koboSpan" id="kobo.1223.1">of gender.</span></span></p>
<p><span class="koboSpan" id="kobo.1224.1">Now, experiment with D&amp;D++ for yourself and see what improvements you </span><span class="No-Break"><span class="koboSpan" id="kobo.1225.1">can get!</span></span></p>
<p><span class="koboSpan" id="kobo.1226.1">In this section, we discovered a variety of mitigation techniques that apply to neural network models and also indirectly showed that metrics are not the only indicators </span><span class="No-Break"><span class="koboSpan" id="kobo.1227.1">of bias.</span></span></p>
<p><span class="koboSpan" id="kobo.1228.1">While this chapter predominantly focused on deep learning models and unstructured data, it is important to note that the concepts, techniques, and metrics we discussed also apply to structured data. </span><span class="koboSpan" id="kobo.1228.2">Bias can exist in structured data in the form of imbalanced classes, skewed attribute distributions, or unrepresentative samples, and can manifest in the model’s predictions, leading to unfair outcomes. </span><span class="koboSpan" id="kobo.1228.3">A notable difference is that for structured data-based use cases, biases are usually more directly perpetuated by the input features. </span><span class="koboSpan" id="kobo.1228.4">The </span><a id="_idIndexMarker1016"/><span class="koboSpan" id="kobo.1229.1">bias and fairness evaluation methods, such as equal representation-based metrics, equal error-based metrics, and distributional fairness metrics, can be used to assess the fairness of machine learning models trained on </span><span class="No-Break"><span class="koboSpan" id="kobo.1230.1">structured data.</span></span></p>
<h1 id="_idParaDest-196"><a id="_idTextAnchor205"/><span class="koboSpan" id="kobo.1231.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1232.1">In this chapter, we focused on the critical issue of bias and fairness in machine learning models. </span><span class="koboSpan" id="kobo.1232.2">The potential negative consequences of deploying biased models, such as legal actions and fines, were emphasized. </span><span class="koboSpan" id="kobo.1232.3">We covered various types of biases and identified stages in the deep learning life cycle where bias can emerge, including planning, data preparation, model development, </span><span class="No-Break"><span class="koboSpan" id="kobo.1233.1">and deployment.</span></span></p>
<p><span class="koboSpan" id="kobo.1234.1">Several metrics for detecting and evaluating bias and fairness were also introduced, including equal representation-based metrics, equal error-based metrics, distributional fairness metrics, and individual fairness metrics. </span><span class="koboSpan" id="kobo.1234.2">This chapter provided recommendations on selecting the right metrics for specific use cases and highlighted the importance of balancing opposing views, such as WAE and WYSIWYG, when evaluating fairness. </span><span class="koboSpan" id="kobo.1234.3">This chapter also discussed programmatic bias mitigation methods that can be applied during the pre-processing, in-processing, and post-processing stages of model building. </span><span class="koboSpan" id="kobo.1234.4">Examples of these methods include eliminating protected attributes, disparate impact remover, adversarial debiasing, and equalized </span><span class="No-Break"><span class="koboSpan" id="kobo.1235.1">odds post-processing.</span></span></p>
<p><span class="koboSpan" id="kobo.1236.1">Finally, this chapter presented a comprehensive bias mitigation approach for deep learning models, combining counterfactual augmentation, mix-up augmentation, knowledge distillation, and counterfactual test-time augmentation. </span><span class="koboSpan" id="kobo.1236.2">This approach aims to balance accuracy performance and fairness requirements in </span><span class="No-Break"><span class="koboSpan" id="kobo.1237.1">the model.</span></span></p>
<p><span class="koboSpan" id="kobo.1238.1">With this, you have learned about the importance and techniques of addressing bias and fairness in machine learning models and their potential negative consequences if not properly addressed. </span><span class="koboSpan" id="kobo.1238.2">This knowledge will help you create machine learning systems that not only perform well on accuracy-based metrics but also consider the ethical implications and fairness aspects, ensuring a responsible and effective deployment of AI solutions, ultimately leading to better and more equitable outcomes in </span><span class="No-Break"><span class="koboSpan" id="kobo.1239.1">real-world applications.</span></span></p>
<p><span class="koboSpan" id="kobo.1240.1">As we move forward, the next chapter will shift focus and analyze adversarial performance, a crucial aspect of ensuring robust and reliable machine learning models </span><span class="No-Break"><span class="koboSpan" id="kobo.1241.1">in production.</span></span></p>
</div>
</body></html>