["```py\nimport pandas as pd\nimport os\nfilepath_dict = {'imdb':   'sentiment labelled sentences/imdb_labelled.txt'}\ndocument_list = []\nfor source, filepath in filepath_dict.items():\n    document = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n    document['source'] = source\n    document_list.append(document)\ndocument = pd.concat(document_list)\nprint(document.iloc[0])\n```", "```py\nfrom sklearn.feature_extraction.text import CountVectorizer\n# min_df is the minimum proportion of documents that contain the word (excludes words that\n# are rarer than this proportion)\n# max_df is the maximum proportion of documents that contain the word (excludes words that\n# are rarer than this proportion\n# max_features is the maximum number of words that will be considered\n# the documents will be lowercased\nvectorizer = CountVectorizer(min_df = 0, max_df = 1.0, max_features = 1000, lowercase = True)\n```", "```py\n# split the data into training and test\nfrom sklearn.model_selection import train_test_split\ndocument_imdb = document[document['source'] == 'imdb']\nreviews = document_imdb['sentence'].values\ny = document_imdb['label'].values\n# since this is just an example, we will omit the dev test set\n# 'reviews.data' is the movie reviews\n# 'y_train' is the categories assigned to each review in the training data\n# 'test_size = .20' is the proportion of the data that should be reserved for testing\n# 'random_state = 42' is an integer that controls the randomization of the data so that the results are reproducible\nreviews_train, reviews_test, y_train, y_test = train_test_split(\n   reviews, y, test_size = 0.20, random_state = 42)\n```", "```py\nvectorizer.fit(reviews_train)\nvectorizer.fit(reviews_test)\nX_train = vectorizer.transform(reviews_train)\nX_test  = vectorizer.transform(reviews_test)\n```", "```py\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import models\n# Number of features (words)\n# This is based on the data and the parameters that were provided to the vectorizer\n# min_df, max_df and max_features\ninput_dimension = X_train.shape[1]\nprint(input_dimension)\n```", "```py\n# a Sequential model is a stack of layers where each layer has one input and one output tensor\n# Since this is a binary classification problem, there will be one output (0 or 1)\n# depending on whether the review is positive or negative\n# so the Sequential model is appropriate\nmodel = Sequential()\nmodel.add(layers.Dense(16, input_dim = input_dimension, activation = 'relu'))\nmodel.add(layers.Dense(16, activation = 'relu'))\nmodel.add(layers.Dense(16, activation = 'relu'))\n# output layer\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n```", "```py\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer = 'adam',\n              metrics = ['accuracy'])\n```", "```py\nmodel.summary()\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #\n=================================================================\n dense (Dense)               (None, 16)                13952\n dense_1 (Dense)             (None, 16)                272\n dense_2 (Dense)             (None, 16)                272\n dense_3 (Dense)             (None, 1)                 17\n=================================================================\nTotal params: 14,513\nTrainable params: 14,513\nNon-trainable params: 0\n```", "```py\nhistory = model.fit(X_train, y_train,\n                    epochs=20,\n                    verbose=True,\n                    validation_data=(X_test, y_test),\n                    batch_size=10)\n```", "```py\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\ndef plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    x = range(1, len(acc) + 1)\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, 'b', label='Training accuracy')\n    plt.plot(x, val_acc, 'r', label = 'Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, 'b', label='Training loss')\n    plt.plot(x, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()\nplot_history(history)\n```"]