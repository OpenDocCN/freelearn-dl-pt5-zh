["```py\n    import evaluate\n    import numpy as np\n    import pandas as pd\n    import syllables\n    import torch\n    from audiomentations import TimeStretch\n    from datasets import load_dataset\n    from evidently.metric_preset import DataDriftPreset\n    from evidently.metrics import ColumnSummaryMetric\n    from evidently.metrics import DataDriftTable\n    from evidently.report import Report\n    from tqdm import tqdm_notebook\n    from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n    ```", "```py\n    ds = load_dataset(\"google/fleurs\", 'en_us', split=\"validation\")\n    device = torch.device(\"cuda\")\n    model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n    processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n    model.to(device)\n    ```", "```py\n    wer = evaluate.load(\"wer\")\n    def get_wer_scores(dataset, transcriptions=None, sampling_rates=None, is_hg_ds=False, verbose=True):\n      all_wer_score = []\n      for idx, audio_data in tqdm_notebook(enumerate(dataset), total=len(dataset), disable=not verbose):\n         inputs = processor(\n            audio_data[\"audio\"][\"array\"] if is_hg_ds else audio_data, sampling_rate=audio_data[\"audio\"][\"sampling_rate\"] if is_hg_ds else sampling_rates[idx], return_tensors=\"pt\")\n         generated_ids = model.generate(\n            inputs[\"input_features\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device))\n         transcription = processor.batch_decode(\n    generated_ids, skip_special_tokens=True)\n         wer_score = wer.compute(predictions=transcription, references=[audio_data['transcription'] if is_hg_ds else transcriptions[idx]])\n         all_wer_score.append(wer_score)\n         return np.array(all_wer_score)\n    ```", "```py\n    def get_augmented_samples_wer_results(all_baseline_samples, transcriptions, all_sampling_rates, rates_to_change):\n         all_augmented_samples = []\n         for idx, audio_sample in enumerate(all_baseline_samples):\n            if rates_to_change[idx] != 0:\n               augment = TimeStretch(min_rate=rates_to_change[idx], max_rate=rates_to_change[idx], p=1.0)\n               augmented_samples = augment(samples=audio_sample, sample_rate=all_sampling_rates[idx])\n               all_augmented_samples.append(\n    augmented_samples)\n            else:\n               all_augmented_samples.append(audio_sample)\n               wer_scores = get_wer_scores( all_augmented_samples, transcriptions, sampling_rates=all_sampling_rates, is_hg_ds=False)\n         return wer_scores, all_augmented_samples\n    ```", "```py\n    all_syllables_per_second = []\n    original_dataset = []\n    all_sampling_rates = []\n    transcriptions = []\n         for audio_data in ds:\n         num_syllables = syllables.estimate(audio_data['transcription'])\n         syllables_per_second = num_syllables / (audio_data['num_samples'] / audio_data['audio']['sampling_rate'])\n         all_syllables_per_second.append(\n    syllables_per_second)\n         original_dataset.append(audio_data['audio']['array'])\n         all_sampling_rates.append(audio_data['audio']['sampling_rate'])\n         transcriptions.append(\n    audio_data['transcription'])\n    ```", "```py\n    reference_wer_scores, reference_samples = get_augmented_samples_wer_results(original_dataset, transcriptions, all_sampling_rates, rates_to_change=[3] * len(original_dataset)\n    )\n    reference_df = pd.DataFrame({\n      \"wer_score\": reference_wer_scores,\n      \"syllables_per_second\": [sps / 3.0 for sps in all_syllables_per_second]})\n    ```", "```py\n    majority_number = int(len(reference_samples) * 0.9)\n    minority_number = len(reference_samples) - majority_number\n    majority_rates = []\n    for i in range(majority_number):\n         majority_rates.append(10.0 / all_syllables_per_second[i])\n         current_wer_scores, current_samples = get_augmented_samples_wer_results(reference_samples, transcriptions, all_sampling_rates, rates_to_change=majority_rates + [0] * minority_number)\n    reference_syllables_per_second = reference_df[\n      'syllables_per_second'].values.tolist()\n    current_df = pd.DataFrame({\n      \"wer_score\": current_wer_scores,\n      \"syllables_per_second\": [10] * majority_number + reference_syllables_per_second[-minority_number:]})\n    ```", "```py\n    data_drift_dataset_report = Report(metrics=[\n      DataDriftTable(columns=[\"syllables_per_second\"]),\n      ColumnSummaryMetric(column_name=\"wer_score\")])\n    data_drift_dataset_report.run(reference_data=reference_df, current_data=current_df)\n    data_drift_dataset_report.show(mode='inline')\n    ```", "```py\n    wer_scores = get_wer_scores(original_dataset, transcriptions, sampling_rates=all_sampling_rates, is_hg_ds=False)\n    current_df = pd.DataFrame({\"wer_score\": wer_scores,\n      \"syllables_per_second\":all_syllables_per_second})\n    data_drift_dataset_report = Report(metrics=[\n      DataDriftTable(columns=[\"syllables_per_second\"]),\n      ColumnSummaryMetric(column_name=\"wer_score\")])\n    data_drift_dataset_report.run(reference_data=reference_df, current_data=current_df)\n    data_drift_dataset_report.show(mode='inline')\n    ```"]