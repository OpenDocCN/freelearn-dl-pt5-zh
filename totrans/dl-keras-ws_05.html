<html><head></head><body>
		<div>
			<div id="_idContainer109" class="Content">
			</div>
		</div>
		<div id="_idContainer110" class="Content">
			<h1 id="_idParaDest-103"><a id="_idTextAnchor104"/>5. Improving Model Accuracy</h1>
		</div>
		<div id="_idContainer123" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">This chapter introduces the concept of regularization for neural networks. Regularization aims to prevent the model from overfitting the training data during the training process and provides more accurate results when the model is tested on new unseen data. You will learn to utilize different regularization techniques—L1 and L2 regularization and dropout regularization—to improve model performance. Regularization is an important component as it prevents neural networks from overfitting the training data and helps us build robust, accurate models that perform well on new, unseen data. By the end of this chapter, you will be able to implement a grid search and random search in scikit-learn and find the optimal hyperparameters.</p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor105"/>Introduction</h1>
			<p>In the previous chapter, we continued to develop our knowledge of creating accurate models with neural networks by experimenting with cross-validation as a method to test how various hyperparameters perform in an unbiased manner. We utilized leave-one-out cross-validation, in which we leave one record out of the training process for use in validation and repeat this for every record in the dataset. Then, we looked at k-fold cross-validation, in which we split the training dataset into <strong class="source-inline">k</strong> folds, train the model on <strong class="source-inline">k-1</strong> folds, and use the final fold for validation. These cross-validation methods allow us to train models with different hyperparameters and test their performance on unbiased data.</p>
			<p>Deep learning is not only about building neural networks, training them using an available dataset, and reporting the model accuracy. It involves trying to understand your model and the dataset, as well as moving beyond a basic model by improving it in many aspects. In this chapter, you will learn about two very important groups of techniques for improving machine learning models in general, and deep learning models in particular. These techniques are regularization methods and hyperparameter tuning.</p>
			<p>This chapter will further cover regularization methods—specifically, why we need them and how they help. Then, we'll introduce two of the most important and most commonly used regularization techniques. Here, you'll learn about parameter regularization and its two variations, <strong class="source-inline">L1</strong> and<strong class="source-inline"> L2</strong> norm regularizations, in great detail. You will then learn about a regularization technique that was specifically designed for neural networks called <strong class="bold">dropout regulation</strong>. You will also practice implementing each of these techniques on Keras models by completing activities that involve real-life datasets. We'll end our discussion of regularization by briefly introducing some other regularization techniques that you may find helpful later in your work.</p>
			<p>Then, we will talk about the importance of <strong class="bold">hyperparameter tuning</strong>, especially for deep learning models, by exploring how tuning the values of hyperparameters can dramatically affect model accuracy, as well as the challenge of tuning the many hyperparameters that require it when building deep neural networks. You will learn two very helpful methods in scikit-learn that you can use for performing hyperparameter tuning on Keras models, the benefits and drawbacks of each method, and how to combine them to gain the most from both. Lastly, you will practice implementing hyperparameter tuning for Keras models using scikit-learn optimizers by completing an activity.</p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor106"/>Regularization</h1>
			<p>Since deep neural networks are highly flexible models, overfitting is an issue that can often arise when training them. Therefore, one very important part of becoming a deep learning expert is knowing how to detect overfitting, and subsequently how to address the overfitting problem in your model. Overfitting in your models will be clear if your model performs excellently on the training data but performs poorly on new, unseen data. </p>
			<p>For example, if you build a model to classify images of dogs and cats into their respective classes and your image classifier performs with high accuracy during the training process but does not perform well on new examples, then this is an indication that your model has overfitted the training data. Regularization techniques are an important group of methods specifically aimed at reducing overfitting in machine learning models. </p>
			<p>Understanding regularization techniques thoroughly and being able to apply them to your deep neural networks is an essential step toward building deep neural networks in order to solve real-life problems. In this section, you will learn about the underlying concepts of regularization, which will provide you with the foundation that's required for the following sections, where you will learn how to implement various types of regularization methods using Keras.</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor107"/>The Need for Regularization</h2>
			<p>The main goal of machine learning is to build models that perform well, not only on the examples they are trained on but also on new examples that were not included in the training. A good machine learning model is one that finds the form and the parameters of the true underlying process/function that's producing the training examples but does not capture the noise associated with individual training examples. Such a machine learning model can generalize well to new data that's produced by the same process later.</p>
			<p>The approaches we discussed previously—such as splitting a dataset into a training set and a test set, and cross-validation—were all designed to estimate the generalization ability of a trained model. In fact, the term that's used to refer to a test set error and cross-validation error is "generalization error." This simply means the error rate on examples that were not used in training. Once again, the main goal of machine learning is to build models with low generalization error rates.</p>
			<p>In <em class="italic">Chapter 3</em>, <em class="italic">Deep Learning with Keras</em>, we discussed two very important issues with machine learning models: overfitting and underfitting. We stated that underfitting is the scenario where the estimated model is not flexible or complex enough to capture all the relations and patterns associated with the true process. This is a model with <strong class="source-inline">high bias</strong> and is detected when the training error is high. On the other hand, overfitting is the scenario where the model that's used for estimating the true process is too flexible or complex. This is a model with <strong class="source-inline">high variance</strong> and is diagnosed when there is a large gap between the training error and the generalization error. An overview of these scenarios for a binary classification problem can be seen in the following images:</p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B15777_05_01.jpg" alt="Figure 5.1: Underfitting&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1: Underfitting</p>
			<p>As you can see above, Underfitting is a less problematic issue than overfitting. In fact, underfitting can be fixed easily by making the model more flexible/complex. In deep neural networks, this means changing the architecture of the network, making the network larger by adding more layers to it or increasing the number of units in the layers.</p>
			<p>Now let's look at overfitting image below:</p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B15777_03_16.jpg" alt="Figure 5.2: Overfitting&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.2: Overfitting</p>
			<p>Similarly, there are simple solutions for addressing overfitting, such as making the model less flexible/complex (again, by changing the architecture of the network) or providing the network with more training examples. However, making the network less complex sometimes comes at the cost of a dramatic increase in bias or training error rate. The reason for this is that most of the time, the cause of overfitting is not the flexibility of the model but too few training examples. On the other hand, providing more data examples in order to decrease overfitting is not always possible. As a result, finding ways to reduce the generalization error while keeping model complexity and the number of training examples fixed is both important and challenging.</p>
			<p>Now let's look at the Right fit image below:</p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B15777_05_03.jpg" alt="Figure 5.3: Right Fit&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.3: Right Fit</p>
			<p>That is why we need regularization techniques when building highly flexible machine learning models, such as deep neural networks, to suppress the flexibility of the model so that it cannot overfit to individual examples. In the next section, we will describe how regularization methods reduce the overfitting of models on the training data to reduce the variance in the model.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor108"/>Reducing Overfitting with Regularization</h2>
			<p><strong class="source-inline">Regularization</strong> methods try to modify the learning algorithm in a way that reduces the variance of the model. By decreasing the variance, regularization techniques intend to reduce the generalization error while not increasing the training error (or, at least, not increasing the training error drastically).</p>
			<p>Regularization methods provide some kind of restriction that helps with the stability of the model. There are several ways that this can be achieved. One of the most common ways of performing regularization on deep neural networks is by putting some type of penalizing term on weights to keep the weights small.</p>
			<p>Keeping the weights small makes the network less sensitive to noise in individual data examples. Weights in a neural network are, in fact, the coefficients that determine how big or small an effect each processing unit will have on the final output of the network. If the units have large weights, it means that each of them will have a significant influence on the output. Combining all the large influences that are caused by each processing unit will result in many fluctuations in the final output.</p>
			<p>On the other hand, keeping the weights small reduces the amount of influence each unit will have on the final output. Indeed, by keeping the weights near zero, some of the units will have almost no effect on the output. Training a large neural network where each unit has little or no effect on the output is the equivalent of training a much simpler network, and so variance and overfitting are reduced. The following figure shows the schematic view of how regularization zeroes out the effect of some units in a large network:</p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B15777_05_04.jpg" alt="Figure 5.4: Schematic view of how regularization zeroes out the effect of some units in a large network&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.4: Schematic view of how regularization zeroes out the effect of some units in a large network</p>
			<p>The preceding diagram is a schematic view of the regularization process. The top network shows a network without regularization, while the bottom network shows an example of a network with regularization in which the white units represent units that have little to no effect on the output because they have been penalized by the regularization process.</p>
			<p>So far, we have learned about the concepts behind regularization. In the next section, we will look at the most common methods of regularization for deep learning models—<strong class="source-inline">L1</strong>, <strong class="source-inline">L2</strong>, and dropout regularization—along with how to implement them in Keras.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor109"/>L1 and L2 Regularization</h1>
			<p>The most common type of regularization for deep learning models is the one that keeps the weights of the network small. This type of regularization is called <strong class="bold">weight regularization</strong> and has two different variations: <strong class="bold">L2 regularization</strong> and <strong class="bold">L1 regularization</strong>. In this section, you will learn about these regularization methods in detail, along with how to implement them in Keras. Additionally, you will practice applying them to real-life problems and observe how they can improve the performance of a model.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor110"/>L1 and L2 Regularization Formulation</h2>
			<p>In weight regularization, a penalizing term is added to the loss function. This term is either the <strong class="bold">L2 norm</strong> (the sum of the squared values) of the weights or the <strong class="bold">L1 norm</strong> (the sum of the absolute values) of the weights. If the L1 norm is used, then it will be called <strong class="source-inline">L1 regularization</strong>. If the L2 norm is used, then it will be called <strong class="source-inline">L2 regularization</strong>. In each case, the sum is multiplied by a hyperparameter called a <strong class="bold">regularization parameter</strong> (<strong class="bold">lambda</strong>).</p>
			<p>Therefore, for <strong class="source-inline">L1 regularization</strong>, the formula is as follows: </p>
			<p><em class="italic">Loss function = Old loss function + lambda * sum of absolute values of the weights</em></p>
			<p>And for <strong class="source-inline">L2 regularization</strong>, the formula is as follows:</p>
			<p><em class="italic">Loss function = Old loss function + lambda * sum of squared values of the weights</em></p>
			<p><strong class="source-inline">Lambda</strong> can take any value between <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>, where <strong class="source-inline">lambda=0</strong> means no penalty at all (equivalent to a network with no regularization) and <strong class="source-inline">lambda=1</strong> means full penalty.</p>
			<p>Like every other hyperparameter, the right value for <strong class="source-inline">lambda</strong> can be selected by trying out different values and observing which value provides a lower generalization error. In fact, it's good practice to start with a network with no regularization and observe the results. Then, you should perform regularization with increasing values of lambda, such as <strong class="source-inline">0.001</strong>, <strong class="source-inline">0.01</strong>, <strong class="source-inline">0.1</strong>, <strong class="source-inline">0.5</strong>, …, and observe the results in each case in order to figure out how much penalizing on the weight's values is suitable for a particular problem.</p>
			<p>In each iteration of the optimization algorithm with regularization, the weights (w) become smaller and smaller. That is why weight regularization is commonly referred to as <strong class="bold">weight decay</strong>.</p>
			<p>So far, we have only discussed regularizing weights in a deep neural network. However, you need to keep in mind that the same procedure can be applied to biases as well. More precisely, we can update the loss function again by adding a bias penalizing term to it as well and therefore keep the values of biases small during the training of a neural network.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you perform regularization by adding two terms to the loss function (one for penalizing weights and one for penalizing biases), then we call it <strong class="bold">parameter regularization</strong> instead of weight regularization.</p>
			<p>However, regularizing bias values is not very common in deep learning. The reason for this is that weights are much more important parameters of neural networks. In fact, usually, adding another term to regularize biases will not change the results dramatically in comparison to only regularizing the weight values.</p>
			<p><strong class="source-inline">L2 regularization</strong> is the most common regularization technique that's used in machine learning in general. The difference between <strong class="source-inline">L1 regularization</strong> and <strong class="source-inline">L2 regularization</strong> is that <strong class="source-inline">L1</strong> results in a sparser weights matrix, meaning there are more weights equal to zero, and therefore more nodes that are completely removed from the network. <strong class="source-inline">L2 regularization</strong>, on the other hand, is more subtle. It decreases the weights drastically, but at the same time leaves you with fewer weights equal to 0. It is also possible to perform both <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 regularization</strong> at the same time.</p>
			<p>Now that you have learned about how <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 regularization</strong> work, you are ready to move on to implementing <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 regularization</strong> on deep neural networks in Keras.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor111"/>L1 and L2 Regularization Implementation in Keras</h2>
			<p>Keras provides a regularization API that can be used to add penalizing terms to the loss function in order to regularize weights or biases in each layer of a deep neural network. To define the penalty term or <strong class="source-inline">regularizer</strong>, you need to define the desired regularization method under <strong class="source-inline">keras.regularizers</strong>.</p>
			<p>For example, to define an <strong class="source-inline">L1 regularizer</strong> with <strong class="source-inline">lambda=0.01</strong>, you can write this:</p>
			<p class="source-code">from keras.regularizers import l1</p>
			<p class="source-code">keras.regularizers.l1(0.01)</p>
			<p>Similarly, to define an <strong class="source-inline">L2 regularizer</strong> with <strong class="source-inline">lambda=0.01</strong>, you can write this:</p>
			<p class="source-code">from keras.regularizers import l2</p>
			<p class="source-code">keras.regularizers.l2(0.01)</p>
			<p>Finally, to define both <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 regularizers</strong> with <strong class="source-inline">lambda=0.01</strong>, you can write this:</p>
			<p class="source-code">from keras.regularizers import l1_l2</p>
			<p class="source-code">keras.regularizers.l1_l2(l1=0.01, l2=0.01)</p>
			<p>Each of these <strong class="source-inline">regularizers</strong> can be applied to weights and/or biases in a layer. For example, if we would like to apply <strong class="source-inline">L2 regularization</strong> (with <strong class="source-inline">lambda=0.01</strong>) on both the weights and biases of a dense layer with eight nodes, we can write this:</p>
			<p class="source-code">from keras.layers import Dense</p>
			<p class="source-code">from keras.regularizers import l2</p>
			<p class="source-code">model.add(Dense(8, kernel_regularizer=l2(0.01), \</p>
			<p class="source-code">          bias_regularizer=l2(0.01)))</p>
			<p>We will practice implementing <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 regularization</strong> further in <em class="italic">Activity 5.01</em>, <em class="italic">Weight Regularization on an Avila Pattern Classifier</em>, in which you will apply regularization on the deep learning model for the diabetes dataset and observe how the results change in comparison to previous activities.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">All the activities in this chapter will be developed in Jupyter Notebooks. Please download this book's GitHub repository, along with all the prepared templates, from <a href="https://packt.live/2OOBjqq">https://packt.live/2OOBjqq</a>.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor112"/>Activity 5.01: Weight Regularization on an Avila Pattern Classifier</h2>
			<p>The Avila dataset has been extracted from <strong class="source-inline">800</strong> images of the <strong class="source-inline">Avila Bible</strong>, a giant 12<span class="superscript">th</span>-century Latin copy of the Bible. The dataset consists of various features about the images of the text, such as intercolumnar distance and the margins of the text. The dataset also contains a class label that indicates if a pattern of the image falls into the most frequently occurring category or not. In this activity, you will build a Keras model to perform classification on this dataset according to given network architecture and hyperparameter values. The goal is to apply different types of weight regularization on the model and observe how each type changes the result. </p>
			<p>In this activity, we will use the <strong class="source-inline">training set</strong>/<strong class="source-inline">test set</strong> approach to perform the evaluation for two reasons. First, since we are going to try several different regularizers, performing cross-validation will take a long time. Second, we would like to plot the trends in the training error and the test error in order to understand, in a visual way, how regularization prevents the model from overfitting to data examples.</p>
			<p>Follow these steps to complete this activity:</p>
			<ol>
				<li>Load the dataset from the <strong class="source-inline">data</strong> subfolder of <strong class="source-inline">Chapter05</strong> from GitHub using <strong class="source-inline">X = pd.read_csv('../data/avila-tr_feats.csv')</strong> and <strong class="source-inline">y = pd.read_csv('../data/avila-tr_target.csv')</strong>. Split the dataset into a training set and a test set using the <strong class="source-inline">sklearn.model_selection.train_test_split</strong> method. Hold back <strong class="source-inline">20%</strong> of the data examples for the test set.</li>
				<li>Define a Keras model with three hidden layers, the first of <strong class="source-inline">size 10</strong>, the second of <strong class="source-inline">size 6</strong>, and the third of <strong class="source-inline">size 4</strong>, to perform the classification. Use these values for the hyperparameters: <strong class="source-inline">activation='relu'</strong>, <strong class="source-inline">loss='binary_crossentropy'</strong>, <strong class="source-inline">optimizer='sgd'</strong>, <strong class="source-inline">metrics=['accuracy']</strong>, <strong class="source-inline">batch_size=20</strong>, <strong class="source-inline">epochs=100</strong>, and <strong class="source-inline">shuffle=False</strong>.</li>
				<li>Train the model on the training set and evaluate it with the test set. Store the training loss and test loss at every iteration. After training is complete, plot the trends in <strong class="source-inline">training error</strong> and <strong class="source-inline">test error</strong> (change the limits of the vertical axis to (<strong class="source-inline">0, 1</strong>) so that you can observe the changes in losses better). What is the minimum error rate on the test set?</li>
				<li>Add <strong class="source-inline">L2 regularizers</strong> with <strong class="source-inline">lambda=0.01</strong> to the hidden layers of your model and repeat the training. After training is complete, plot the trends in training error and test error. What is the minimum error rate on the test set?</li>
				<li>Repeat the previous step for <strong class="source-inline">lambda=0.1</strong> and <strong class="source-inline">lambda=0.005</strong>, train the model for each value of <strong class="source-inline">lambda</strong>, and report the results. Which value of <strong class="source-inline">lambda</strong> is a better choice for performing <strong class="source-inline">L2 regularization</strong> on this deep learning model and this dataset?</li>
				<li>Repeat the previous step, this time with <strong class="source-inline">L1 regularizers</strong> for <strong class="source-inline">lambda=0.01</strong> and <strong class="source-inline">lambda=0.005</strong>, train the model for each value of <strong class="source-inline">lambda</strong>, and report the results. Which value of <strong class="source-inline">lambda</strong> is a better choice for performing <strong class="source-inline">L1 regularization</strong> on this deep learning model and this dataset?</li>
				<li>Add <strong class="source-inline">L1_L2 regularizers</strong> with the <strong class="source-inline">L1 lambda=0.005</strong> and the <strong class="source-inline">L2 lambda=0.005</strong> to the hidden layers of your model and repeat the training. After training is complete, plot the trends in training error and test error. What is the minimum error rate on the test set?</li>
			</ol>
			<p>After implementing these steps, you should get the following expected output:</p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B15777_05_05.jpg" alt="Figure 5.5: A plot of the training error and validation error during training for the model with L1 lambda equal to 0.005 and L2 lambda equal to 0.005&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.5: A plot of the training error and validation error during training for the model with L1 lambda equal to 0.005 and L2 lambda equal to 0.005</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found on page 398.</p>
			<p>In this activity, you practiced implementing <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 weight regularizations</strong> for a real-life problem and compared the results of the regularized model with those of a model without any regularization. In the next section, we will explore the regulation of a different technique, known as dropout regularization.</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor113"/>Dropout Regularization</h1>
			<p>In this section, you will learn how dropout regularization works, how it helps with reducing overfitting, and how to implement it using Keras. Lastly, you will practice what you have learned about dropout by completing an activity involving a real-life dataset.</p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor114"/>Principles of Dropout Regularization</h2>
			<p>Dropout regularization works by randomly removing nodes from a neural network during training. More precisely, dropout sets up a probability on each node. This probability refers to the chance that the node is included in the training at each iteration of the learning algorithm. Imagine we have a large neural network where a dropout chance of <strong class="source-inline">0.5</strong> is assigned to each node. In such a case, at each iteration, the learning algorithm flips a coin for each node to decide whether that node will be removed from the network or not. An illustration of such a process can be seen in the following diagram:</p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B15777_05_06.jpg" alt="Figure 5.6: Illustration of removing nodes from a deep neural network using dropout regularization&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.6: Illustration of removing nodes from a deep neural network using dropout regularization</p>
			<p>This process is repeated at each iteration; this means that, at each iteration, randomly selected nodes are removed from the network, which means the parameter-updating process is done on a different smaller network. For example, the network shown at the bottom of the preceding diagram would be used for one iteration of the training only. For the next iteration, some other randomly selected nodes would be crossed out from the top network so the network that results from removing those nodes would be different from the bottom network in the diagram.</p>
			<p>When some nodes are chosen to be removed/ignored in an iteration of a learning algorithm, it means that they won't participate in the parameter-updating process at all in that iteration. More precisely, the forward propagation to predict the output, the loss computation, and the backpropagation to compute the derivatives are all to be done on the smaller network with some nodes removed. Consequently, parameter updating will only be done on the nodes that are present in the network in that iteration; the weights and biases of removed nodes won't be updated.</p>
			<p>However, it is important to keep in mind that to evaluate the performance of the model on the test set or hold-out set, the original complete network is always used. If we perform the evaluation of a network with random nodes deleted from it, the noise will be introduced to the results, and this is not desirable.</p>
			<p>In <strong class="source-inline">dropout regularization</strong>, <strong class="source-inline">training</strong> is always performed on the networks that result from randomly selected nodes being removed from the original network. <strong class="source-inline">Evaluation</strong> is always performed using the original network. In the next section, we will gain an understanding of why dropout regularization helps prevent overfitting.</p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor115"/>Reducing Overfitting with Dropout</h2>
			<p>In this section, we are going to discuss the concepts behind dropout as a regularization method. As we discussed previously, the goal of regularization techniques is to prevent a model from overfitting data. Therefore, we are going to look at how randomly removing a portion of nodes from a neural network helps reduce variance and overfitting.</p>
			<p>The most obvious explanation of why removing random nodes from the network prevents overfitting is that by removing nodes from a network, we are performing training on a smaller network in comparison to the original network. As you learned previously, a smaller neural network provides less flexibility, so the chance of the network overfitting to data is lower.</p>
			<p>There is another reason why dropout regularization does such a good job of reducing overfitting. By randomly removing inputs at each layer in a deep neural network, the overall network becomes less sensitive to single inputs. We know that, while training a neural network, the weights are updated in a way that the final model will fit to the training examples. By removing some of the weights from the training process at random, dropout forces other weights to participate in learning the patterns related to the training examples at that iteration, and so the final weight values will better spread out more.</p>
			<p>In other words, instead of some weights updating too much in order to fit some input values, all the weights learn to participate in learning those input values and, consequently, overfitting decreases. This is why performing dropout results in a much more robust model—performing better on new, unseen data—in comparison to simply using a smaller network. In fact, <strong class="source-inline">dropout regularization</strong> tends to work better on larger networks. </p>
			<p>Now that you have learned all about the underlying procedure of dropout and the reasons behind its effectiveness, we can move on to implementing <strong class="source-inline">dropout regularization</strong> in Keras.</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor116"/>Exercise 5.01: Dropout Implementation in Keras</h2>
			<p><strong class="source-inline">Dropout regularization</strong> is provided as a core layer in Keras. As such, you can add dropout to your model in the same way that you would add layers to your network. When defining a dropout layer in Keras, you need to provide the <strong class="source-inline">rate</strong> hyperparameter as an argument. <strong class="source-inline">rate</strong> can take any value between <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong> and determines the portions of the input units to be removed or ignored. In this exercise, you will learn the step-by-step process of implementing a Keras deep learning model with dropout layers.</p>
			<p>Our simulated dataset represents various measurements of trees, such as height, the number of branches, and the girth of the trunk at the base. Our goal is to classify the records into either deciduous (a class value of <strong class="source-inline">1</strong>) or coniferous (a class value of <strong class="source-inline">0</strong>) type trees based on the measurements given. The dataset consists of <strong class="source-inline">10000</strong> records that consist of two classes, representing the two tree types, and each data example has <strong class="source-inline">10</strong> feature values. Follow these steps to complete this exercise:</p>
			<ol>
				<li value="1">First, execute the following code block to load in the dataset and split the dataset into a <strong class="source-inline">training set</strong> and a <strong class="source-inline">test set</strong>:<p class="source-code"># Load the data</p><p class="source-code">import pandas as pd</p><p class="source-code">X = pd.read_csv('../data/tree_class_feats.csv')</p><p class="source-code">y = pd.read_csv('../data/tree_class_target.csv')</p><p class="source-code">"""</p><p class="source-code">Split the dataset into training set and test set with a 80-20 ratio</p><p class="source-code">"""</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">seed = 1</p><p class="source-code">X_train, X_test, \</p><p class="source-code">y_train, y_test = train_test_split(X, y, \</p><p class="source-code">                                   test_size=0.2, \</p><p class="source-code">                                   random_state=seed)</p></li>
				<li>Import all the necessary dependencies. Build a four-layer Keras sequential model without <strong class="source-inline">dropout regularization</strong>. Build the network with 16 units in the first hidden layer, <strong class="source-inline">12</strong> units in the second hidden layer, <strong class="source-inline">8</strong> units in the third hidden layer, and <strong class="source-inline">4</strong> units in the fourth hidden layer, all with <strong class="source-inline">ReLU activation</strong> functions. Add an output layer with a <strong class="source-inline">sigmoid activation</strong> function:<p class="source-code">#Define your model</p><p class="source-code">from keras.models import Sequential</p><p class="source-code">from keras.layers import Dense, Activation</p><p class="source-code">import numpy as np</p><p class="source-code">from tensorflow import random</p><p class="source-code">np.random.seed(seed)</p><p class="source-code">random.set_seed(seed)</p><p class="source-code">model_1 = Sequential()</p><p class="source-code">model_1.add(Dense(16, activation='relu', input_dim=10))</p><p class="source-code">model_1.add(Dense(12, activation='relu'))</p><p class="source-code">model_1.add(Dense(8, activation='relu'))</p><p class="source-code">model_1.add(Dense(4, activation='relu'))</p><p class="source-code">model_1.add(Dense(1, activation='sigmoid'))</p></li>
				<li>Compile the model with <strong class="source-inline">binary cross-entropy</strong> as the <strong class="source-inline">loss</strong> function and <strong class="source-inline">sgd</strong> as the optimizer and train the model for <strong class="source-inline">300</strong> epochs with <strong class="source-inline">batch_size=50</strong> on the <strong class="source-inline">training set</strong>. Then, evaluate the trained model on  the <strong class="source-inline">test set</strong>:<p class="source-code">model_1.compile(optimizer='sgd', loss='binary_crossentropy')</p><p class="source-code"># train the model</p><p class="source-code">model_1.fit(X_train, y_train, epochs=300, batch_size=50, \</p><p class="source-code">            verbose=0, shuffle=False)</p><p class="source-code"># evaluate on test set</p><p class="source-code">print("Test Loss =", model_1.evaluate(X_test, y_test))</p><p>Here's the expected output:</p><p class="source-code">2000/2000 [==============================] - 0s 23us/step</p><p class="source-code">Test Loss = 0.1697693831920624</p><p>Therefore, the test error rate for predicting the species of tree after training the model for <strong class="source-inline">300</strong> epochs is equal to <strong class="source-inline">16.98%</strong>.</p></li>
				<li>Redefine the model with the same number of layers and same size in each layer as the prior model. However, add a <strong class="source-inline">dropout regularization</strong> of <strong class="source-inline">rate=0.1</strong> to the first hidden layer of your model and repeat the compilation, training, and evaluation steps of the model on the test data:<p class="source-code">"""</p><p class="source-code">define the keras model with dropout in the first hidden layer</p><p class="source-code">"""</p><p class="source-code">from keras.layers import Dropout</p><p class="source-code">np.random.seed(seed)</p><p class="source-code">random.set_seed(seed)</p><p class="source-code">model_2 = Sequential()</p><p class="source-code">model_2.add(Dense(16, activation='relu', input_dim=10))</p><p class="source-code">model_2.add(Dropout(0.1))</p><p class="source-code">model_2.add(Dense(12, activation='relu'))</p><p class="source-code">model_2.add(Dense(8, activation='relu'))</p><p class="source-code">model_2.add(Dense(4, activation='relu'))</p><p class="source-code">model_2.add(Dense(1, activation='sigmoid'))</p><p class="source-code">model_2.compile(optimizer='sgd', loss='binary_crossentropy')</p><p class="source-code"># train the model</p><p class="source-code">model_2.fit(X_train, y_train, \</p><p class="source-code">            epochs=300, batch_size=50, \</p><p class="source-code">            verbose=0, shuffle=False)</p><p class="source-code"># evaluate on test set</p><p class="source-code">print("Test Loss =", model_2.evaluate(X_test, y_test))</p><p>Here's the expected output:</p><p class="source-code">2000/2000 [==============================] - 0s 29us/step</p><p class="source-code">Test Loss = 0.16891103076934816</p><p>After adding a dropout regularization of <strong class="source-inline">rate=0.1</strong> to the first layer of the network, the test error rate is reduced from <strong class="source-inline">16.98%</strong> to <strong class="source-inline">16.89%</strong>.</p></li>
				<li>Redefine the model with the same number of layers and the same size in each layer as the prior model. However, add a dropout regularization of <strong class="source-inline">rate=0.2</strong> to the first hidden layer and <strong class="source-inline">rate=0.1</strong> to the remaining layers of your model and repeat the compilation, training, and evaluation steps of the model on the test data:<p class="source-code"># define the keras model with dropout in all hidden layers</p><p class="source-code">np.random.seed(seed)</p><p class="source-code">random.set_seed(seed)</p><p class="source-code">model_3 = Sequential()</p><p class="source-code">model_3.add(Dense(16, activation='relu', input_dim=10))</p><p class="source-code">model_3.add(Dropout(0.2))</p><p class="source-code">model_3.add(Dense(12, activation='relu'))</p><p class="source-code">model_3.add(Dropout(0.1))</p><p class="source-code">model_3.add(Dense(8, activation='relu'))</p><p class="source-code">model_3.add(Dropout(0.1))</p><p class="source-code">model_3.add(Dense(4, activation='relu'))</p><p class="source-code">model_3.add(Dropout(0.1))</p><p class="source-code">model_3.add(Dense(1, activation='sigmoid'))</p><p class="source-code">model_3.compile(optimizer='sgd', loss='binary_crossentropy')</p><p class="source-code"># train the model</p><p class="source-code">model_3.fit(X_train, y_train, epochs=300, \</p><p class="source-code">            batch_size=50, verbose=0, shuffle=False)</p><p class="source-code"># evaluate on test set</p><p class="source-code">print("Test Loss =", model_3.evaluate(X_test, y_test))</p><p>Here's the expected output:</p><p class="source-code">2000/2000 [==============================] - 0s 40us/step</p><p class="source-code">Test Loss = 0.19390961921215058</p></li>
			</ol>
			<p>By keeping the dropout regularization of <strong class="source-inline">rate=0.2</strong> in the first layer while adding dropout regularizations of <strong class="source-inline">rate=0.1</strong> to the subsequent layers, the test error rate increased from <strong class="source-inline">16.89%</strong> to <strong class="source-inline">19.39%</strong>. Like the <strong class="source-inline">L1</strong> and <strong class="source-inline">L2 regularizations</strong>, adding too much dropout can prevent the model from learning the underlying function associated with the training data and leads to higher bias than without dropout regularization.</p>
			<p>As you saw in this exercise, you can also apply dropout with different rates to the different layers depending on how much overfitting you think can happen in those layers. Usually, we prefer not to perform dropout on the input layer and the output layer. Regarding the hidden layers, we need to tune the <strong class="source-inline">rate</strong> values and observe the results in order to decide what value is best suited to a particular problem.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3iugM7K">https://packt.live/3iugM7K</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/31HlSYo">https://packt.live/31HlSYo</a>.</p>
			<p>In the following activity, you will practice implementing deep learning models along with dropout regularization in Keras on the Traffic Volume dataset.</p>
			<h2 id="_idParaDest-116">Activi<a id="_idTextAnchor117"/>ty 5.02: Dropout Regularization on the Traffic Volume Dataset</h2>
			<p>In <em class="italic">Activity 4.03</em>, <em class="italic">Model Selection Using Cross-Validation on a Traffic Volume Dataset</em>, of <em class="italic">Chapter 4</em>, <em class="italic">Evaluating Your Model with Cross-Validation Using Keras Wrappers</em>, you used the Traffic Volume dataset to build a model for predicting the volume of traffic across a city bridge when given various normalized features related to traffic data such as the time of day and the volume on the previous day, among others. The dataset contains <strong class="source-inline">10000</strong> records and for each of them, <strong class="source-inline">10</strong> attributes/features are included in the dataset.</p>
			<p>In this activity, you will start with the model from <em class="italic">Activity 4.03</em>, <em class="italic">Model Selection Using Cross-Validation on a Traffic Volume Dataset</em>, of <em class="italic">Chapter 4</em>, <em class="italic">Evaluating Your Model with Cross-Validation Using Keras Wrappers</em>. You will use the training set/test set approach to train and evaluate the model, plot the trends in training error and the generalization error, and observe the model overfitting data examples. Then, you will attempt to improve model performance by addressing the overfitting issue through the use of dropout regularization. In particular, you will try to find out which layers you should add dropout regularization to and what <strong class="source-inline">rate</strong> value will improve this specific model the most. Follow these steps to complete this activity:</p>
			<ol>
				<li value="1">Load the dataset using the pandas <strong class="source-inline">read_csv</strong> function. The dataset is also stored in the <strong class="source-inline">data</strong> subfolder of the <em class="italic">Chapter05</em> GitHub repository. Split the dataset into a training set and a test set with an <strong class="source-inline">80-20</strong> ratio.</li>
				<li>Define a Keras model with two hidden layers of <strong class="source-inline">size</strong> <strong class="source-inline">10</strong> to predict the traffic volume. Use these values for the following hyperparameters: <strong class="source-inline">activation='relu'</strong>, <strong class="source-inline">loss='mean_squared_error'</strong>, <strong class="source-inline">optimizer='rmsprop'</strong>, <strong class="source-inline">batch_size=50</strong>, <strong class="source-inline">epochs=200</strong>, and <strong class="source-inline">shuffle=False</strong>.</li>
				<li>Train the model on the training set and evaluate on the test set. Store the training loss and test loss at every iteration. </li>
				<li>After training is completed, plot the trends in training error and test error. What are the lowest error rates on the training set and the test set?</li>
				<li>Add dropout regularization with <strong class="source-inline">rate=0.1</strong> to the first hidden layer of your model and repeat the training process (since training with dropout takes longer, train for <strong class="source-inline">200</strong> epochs). After training is completed, plot the trends in training error and test error. What are the lowest error rates on the training set and the test set?</li>
				<li>Repeat the previous step, this time adding dropout regularization with <strong class="source-inline">rate=0.1</strong> to both hidden layers of your model and train the model and report the results.</li>
				<li>Repeat the previous step, this time with <strong class="source-inline">rate=0.2</strong> on the first layer and <strong class="source-inline">0.1</strong> on the second layer and train the model and report the results.</li>
				<li>Which dropout regularization has resulted in the best performance on this deep learning model and this dataset so far?</li>
			</ol>
			<p>After implementing these steps, you should get the following expected output:</p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B15777_05_07.jpg" alt="Figure 5.7: A plot of training errors and validation errors while training the model with dropout regularization, with rate=0.2 in the first layer and rate=0.1 in the second layer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.7: A plot of training errors and validation errors while training the model with dropout regularization, with rate=0.2 in the first layer and rate=0.1 in the second layer</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found on page 413.</p>
			<p>In this activity, you learned how to implement dropout regularization in Keras and practiced using it on a problem involving the Traffic Volume dataset. <strong class="source-inline">Dropout regularization</strong> is specifically designed for the purpose of reducing overfitting in neural networks and works by randomly removing nodes from a neural network during the training process. This procedure results in a neural network with well spread out weight values, which leads to less overfitting in individual data examples. In the next section, we will discuss other regularization methods that can be applied to prevent a model overfitting the training data.</p>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor118"/>Other Regularization Methods</h1>
			<p>In this section, you will briefly learn about some other regularization techniques that are commonly used and have been shown to be effective in deep learning. It is important to keep in mind that regularization is a wide-ranging and active research field in machine learning. As a result, covering all the available regularization methods in one chapter is not possible (and most likely not necessary, especially in a book on applied deep learning). Therefore, in this section, we will briefly cover three more regularization methods, called <strong class="bold">early stopping</strong>, <strong class="bold">data augmentation</strong>, and <strong class="bold">adding noise</strong>. You will learn about their underlying ideas and gain a few tips and recommendations on how to use them.</p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor119"/>Early Stopping</h2>
			<p>Earlier in this chapter, we discussed that the main assumption in machine learning is that there is a true function or process that produces training examples. However, this process is unknown and there is no explicit way to find it. Not only is there no way to find the exact underlying process but choosing a model with the right level of flexibility or complexity for estimating the process is challenging as well. Therefore, one good practice is to select a highly flexible model, such as a deep neural network, to model the process and monitor the training process carefully. </p>
			<p>By monitoring the training process, we can train the model just enough for it to capture the form of the process, and we can stop the training right before it starts to overfit to individual data examples. This is the underlying idea behind early stopping. We discussed the idea of early stopping briefly in the <em class="italic">Model Evaluation</em> section of <em class="italic">Chapter 3</em>, <em class="italic">Deep Learning with Keras</em>. We stated that, by monitoring and observing the changes in <strong class="source-inline">training error</strong> and <strong class="source-inline">test error</strong> during training, we can determine how little training is too little and how much training is too much. </p>
			<p>The following plot shows a view of the changes in training error and test error when a highly flexible model is trained on a dataset. As we can see, the training needs to stop in the region labeled <strong class="bold">Right Fit</strong> to avoid overfitting:</p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B15777_05_08.jpg" alt="Figure 5.8: Plot of the training error and test error while training a model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.8: Plot of the training error and test error while training a model</p>
			<p>In <em class="italic">Chapter 3</em>, <em class="italic">Deep Learning with Keras</em>, we practiced storing and plotting changes in training error and test error in order to identify overfitting. You learned that you can provide a validation set or test set when training a Keras model and store the metrics values for each of them at each epoch of training by using the following code:</p>
			<p class="source-code">history=model.fit(X_train, y_train, validation_data=(X_test, y_test), \</p>
			<p class="source-code">                  epochs=epochs)</p>
			<p>In this section, you are going to learn how to implement early stopping in Keras. This means forcing the Keras model to stop the training when a desired metric—for example, the <strong class="source-inline">test error rate</strong>—is not improving anymore. In order to do so, you need to define an <strong class="source-inline">EarlyStopping()</strong> callback and provide it as an argument to <strong class="source-inline">model.fit()</strong>.</p>
			<p>When defining an <strong class="source-inline">EarlyStopping()</strong> callback, you need to provide it with the right arguments. The first argument is <strong class="source-inline">monitor</strong>, which determines what metric will be monitored during training for the purpose of performing early stopping. Usually, <strong class="source-inline">monitor='val_loss'</strong> is a good choice, meaning that we would like to monitor the test error rate. </p>
			<p>Also, depending on what argument you have chosen for the <strong class="source-inline">monitor</strong>, you need to set the <strong class="source-inline">mode</strong> argument to either <strong class="source-inline">'min'</strong> or <strong class="source-inline">'max'</strong>. If the metric is error/loss, we would like to minimize it. For example, the following code block defines an <strong class="source-inline">EarlyStopping()</strong> callback that monitors the test error during training and detects if it is not decreasing anymore:</p>
			<p class="source-code">from keras.callbacks import EarlyStopping</p>
			<p class="source-code">es_callback = EarlyStopping(monitor='val_loss', mode='min')</p>
			<p>If there are a lot of fluctuations or noise in the error rates, it is probably not a good idea to stop the training when the loss begins to increase at all. For this reason, we can set the <strong class="source-inline">patience</strong> argument to a number of epochs to give the early stopping method some time to monitor the desired metric for longer before stopping the training process:</p>
			<p class="source-code">es_callback = EarlyStopping(monitor='val_loss', \</p>
			<p class="source-code">                            mode='min', patience=20)</p>
			<p>We can also modify the <strong class="source-inline">EarlyStopping()</strong> callback to stop the training process if a minimal improvement in the <strong class="source-inline">monitor</strong> metric has not happened in the past <strong class="source-inline">epoch</strong>, or the <strong class="source-inline">monitor</strong> metric has reached a baseline level:</p>
			<p class="source-code">es_callback = EarlyStopping(monitor='val_loss', \</p>
			<p class="source-code">                            mode='min', min_delta=1)</p>
			<p class="source-code">es_callback = EarlyStopping(monitor='val_loss', \</p>
			<p class="source-code">                            mode='min', baseline=0.2)</p>
			<p>After defining the <strong class="source-inline">EarlyStopping()</strong> callback, you can provide it as a <strong class="source-inline">callbacks</strong> argument to <strong class="source-inline">model.fit()</strong> and train the model. The training will automatically stop according to the <strong class="source-inline">EarlyStopping()</strong> callback:</p>
			<p class="source-code">history=model.fit(X_train, y_train, validation_data=(X_test, y_test), \</p>
			<p class="source-code">                  epochs=epochs, callbacks=[es_callback])</p>
			<p>We will explore how early stopping can be achieved in practice in the next exercise.</p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor120"/>Exercise 5.02: Implementing Early Stopping in Keras</h2>
			<p>In this exercise, you will learn how to implement early stopping on a Keras deep learning model. The dataset we will use is a simulated dataset that represents various measurements of trees, such as height, the number of branches and the girth of the trunk at the base. Our goal is to classify the records into either deciduous or coniferous trees based on the measurements given. </p>
			<p>First, execute the following code block to load a simulated dataset of <strong class="source-inline">10000</strong> records that consist of two classes representing the two tree species, with a class value of <strong class="source-inline">1</strong> for deciduous tree species and a class value of <strong class="source-inline">0</strong> for coniferous tree species. Each record has <strong class="source-inline">10</strong> feature values. </p>
			<p>The goal is to build a model in order to predict the species of the tree when given the measurements of the tree. Now, let's go through the steps:</p>
			<ol>
				<li value="1">Load the dataset using the pandas <strong class="source-inline">read_csv</strong> function and split the dataset in an <strong class="source-inline">80-20</strong> split using the <strong class="source-inline">train_test_split</strong> function:<p class="source-code"># Load the data</p><p class="source-code">import pandas as pd</p><p class="source-code">X = pd.read_csv('../data/tree_class_feats.csv')</p><p class="source-code">y = pd.read_csv('../data/tree_class_target.csv')</p><p class="source-code">"""</p><p class="source-code">Split the dataset into training set and test set with an 80-20 ratio</p><p class="source-code">"""</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">seed=1</p><p class="source-code">X_train, X_test, \</p><p class="source-code">y_train, y_test = train_test_split(X, y, test_size=0.2, \</p><p class="source-code">                                   random_state=seed)</p></li>
				<li>Import all the necessary dependencies. Build a three-layer Keras sequential model without early stopping. The first layer will have <strong class="source-inline">16</strong> units, the second layer will have <strong class="source-inline">8</strong> units, and the third layer will have <strong class="source-inline">4</strong> units, all with <strong class="source-inline">ReLU activation</strong> functions. Add the <strong class="source-inline">output layer</strong> with a <strong class="source-inline">sigmoid activation function</strong>:<p class="source-code"># Define your model</p><p class="source-code">from keras.models import Sequential</p><p class="source-code">from keras.layers import Dense, Activation</p><p class="source-code">import numpy as np</p><p class="source-code">from tensorflow import random</p><p class="source-code">np.random.seed(seed)</p><p class="source-code">random.set_seed(seed)</p><p class="source-code">model_1 = Sequential()</p><p class="source-code">model_1.add(Dense(16, activation='relu', \</p><p class="source-code">                  input_dim=X_train.shape[1]))</p><p class="source-code">model_1.add(Dense(8, activation='relu'))</p><p class="source-code">model_1.add(Dense(4, activation='relu'))</p><p class="source-code">model_1.add(Dense(1, activation='sigmoid'))</p></li>
				<li>Compile the model with the <strong class="source-inline">loss</strong> function as binary cross-entropy and the optimizer as <strong class="source-inline">SGD</strong>. Train the model for <strong class="source-inline">300</strong> epochs with <strong class="source-inline">batch_size=50</strong>, all while storing the <strong class="source-inline">training error</strong> and the <strong class="source-inline">test error</strong> at every iteration:<p class="source-code">model_1.compile(optimizer='sgd', loss='binary_crossentropy')</p><p class="source-code"># train the model</p><p class="source-code">history = model_1.fit(X_train, y_train, \</p><p class="source-code">                      validation_data=(X_test, y_test), \</p><p class="source-code">                      epochs=300, batch_size=50, \</p><p class="source-code">                      verbose=0, shuffle=False)</p></li>
				<li>Import the required packages for plotting:<p class="source-code">import matplotlib.pyplot as plt </p><p class="source-code">import matplotlib</p><p class="source-code">%matplotlib inline</p></li>
				<li>Plot the <strong class="source-inline">training error</strong> and <strong class="source-inline">test error</strong> that are stored in the variable that was created during the fitting process:<p class="source-code">matplotlib.rcParams['figure.figsize'] = (10.0, 8.0) </p><p class="source-code">plt.plot(history.history['loss'])</p><p class="source-code">plt.plot(history.history['val_loss'])</p><p class="source-code">plt.ylim(0,1)</p><p class="source-code">plt.ylabel('loss')</p><p class="source-code">plt.xlabel('epoch')</p><p class="source-code">plt.legend(['train loss', 'validation loss'], \</p><p class="source-code">           loc='upper right')</p><p>Here's the expected output:</p><div id="_idContainer119" class="IMG---Figure"><img src="image/B15777_05_09.jpg" alt="Figure 5.9: Plot of the training error and validation error while training the model without early stopping&#13;&#10;"/></div><p class="figure-caption">Figure 5.9: Plot of the training error and validation error while training the model without early stopping</p><p>As you can see from the preceding plot, training the model for <strong class="source-inline">300</strong> epochs results in a gap that grows between the <strong class="source-inline">training error</strong> and <strong class="source-inline">validation error</strong>, which is indicative of overfitting beginning to happen.</p></li>
				<li>Redefine the model by creating the model with the same number of layers and with the same number of units within each layer. This ensures the model is initialized in the same way. Add a callback <strong class="source-inline">es_callback = EarlyStopping(monitor='val_loss', mode='min')</strong> to the training process. Repeat <em class="italic">step 4</em> to plot the training error and validation error:<p class="source-code">#Define your model with early stopping on test error</p><p class="source-code">from keras.callbacks import EarlyStopping</p><p class="source-code">np.random.seed(seed)</p><p class="source-code">random.set_seed(seed)</p><p class="source-code">model_2 = Sequential()</p><p class="source-code">model_2.add(Dense(16, activation='relu', \</p><p class="source-code">                  input_dim=X_train.shape[1]))</p><p class="source-code">model_2.add(Dense(8, activation='relu'))</p><p class="source-code">model_2.add(Dense(4, activation='relu'))</p><p class="source-code">model_2.add(Dense(1, activation='sigmoid'))</p><p class="source-code">"""</p><p class="source-code">Choose the loss function to be binary cross entropy and the optimizer to be SGD for training the model</p><p class="source-code">"""</p><p class="source-code">model_2.compile(optimizer='sgd', loss='binary_crossentropy')</p><p class="source-code"># define the early stopping callback</p><p class="source-code">es_callback = EarlyStopping(monitor='val_loss', \</p><p class="source-code">                            mode='min')</p><p class="source-code"># train the model</p><p class="source-code">history=model_2.fit(X_train, y_train, \</p><p class="source-code">                    validation_data=(X_test, y_test), \</p><p class="source-code">                    epochs=300, batch_size=50, \</p><p class="source-code">                    callbacks=[es_callback], verbose=0, \</p><p class="source-code">                    shuffle=False)</p></li>
				<li>Now plot the loss values:<p class="source-code"># plot training error and test error</p><p class="source-code">matplotlib.rcParams['figure.figsize'] = (10.0, 8.0) </p><p class="source-code">plt.plot(history.history['loss'])</p><p class="source-code">plt.plot(history.history['val_loss'])</p><p class="source-code">plt.ylim(0,1)</p><p class="source-code">plt.ylabel('loss')</p><p class="source-code">plt.xlabel('epoch')</p><p class="source-code">plt.legend(['train loss', 'validation loss'], \</p><p class="source-code">           loc='upper right')</p><p>Here's the expected output:</p><div id="_idContainer120" class="IMG---Figure"><img src="image/B15777_05_10.jpg" alt="Figure 5.10: Plot of training error and validation error while training the model with early stopping (patience=0)&#13;&#10;"/></div><p class="figure-caption">Figure 5.10: Plot of training error and validation error while training the model with early stopping (patience=0)</p><p>By adding the early stopping callback with <strong class="source-inline">patience=0</strong> to the model, the training process automatically stops after about <strong class="source-inline">39</strong> epochs.</p></li>
				<li>Repeat <em class="italic">step 5</em> while adding <strong class="source-inline">patience=10</strong> to your early stopping callback. Repeat <em class="italic">step 3</em> to plot the <strong class="source-inline">training error</strong> and <strong class="source-inline">validation error</strong>:<p class="source-code">"""</p><p class="source-code">Define your model with early stopping on test error with patience=10</p><p class="source-code">"""</p><p class="source-code">from keras.callbacks import EarlyStopping</p><p class="source-code">np.random.seed(seed)</p><p class="source-code">random.set_seed(seed)</p><p class="source-code">model_3 = Sequential()</p><p class="source-code">model_3.add(Dense(16, activation='relu', \</p><p class="source-code">                  input_dim=X_train.shape[1]))</p><p class="source-code">model_3.add(Dense(8, activation='relu'))</p><p class="source-code">model_3.add(Dense(4, activation='relu'))</p><p class="source-code">model_3.add(Dense(1, activation='sigmoid'))</p><p class="source-code">"""</p><p class="source-code">Choose the loss function to be binary cross entropy and the optimizer to be SGD for training the model</p><p class="source-code">"""</p><p class="source-code">model_3.compile(optimizer='sgd', loss='binary_crossentropy')</p><p class="source-code"># define the early stopping callback</p><p class="source-code">es_callback = EarlyStopping(monitor='val_loss', \</p><p class="source-code">                            mode='min', patience=10)</p><p class="source-code"># train the model</p><p class="source-code">history=model_3.fit(X_train, y_train, \</p><p class="source-code">                    validation_data=(X_test, y_test), \</p><p class="source-code">                    epochs=300, batch_size=50, \</p><p class="source-code">                    callbacks=[es_callback], verbose=0, \</p><p class="source-code">                    shuffle=False)</p></li>
				<li>Then plot the loss again:<p class="source-code"># plot training error and test error</p><p class="source-code">matplotlib.rcParams['figure.figsize'] = (10.0, 8.0) </p><p class="source-code">plt.plot(history.history['loss'])</p><p class="source-code">plt.plot(history.history['val_loss'])</p><p class="source-code">plt.ylim(0,1)</p><p class="source-code">plt.ylabel('loss')</p><p class="source-code">plt.xlabel('epoch')</p><p class="source-code">plt.legend(['train loss', 'validation loss'], \</p><p class="source-code">           loc='upper right')</p><p>Here's the expected output:</p></li>
			</ol>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/B15777_05_11.jpg" alt="Figure 5.11: Plot of training error and validation error while training the model with early stopping (patience=10)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.11: Plot of training error and validation error while training the model with early stopping (patience=10)</p>
			<p>By adding the early stopping callback with <strong class="source-inline">patience=10</strong> to the model, the training process automatically stops after about <strong class="source-inline">150</strong> epochs.</p>
			<p>In this exercise, you learned how to stop the model to prevent your Keras model from overfitting the training data. To do this, you utilized the <strong class="source-inline">EarlyStopping</strong> callback and trained the model with it. We used this callback to stop the model any time the validation loss increased and added a <strong class="source-inline">patience</strong> parameter, which waits for a given number of epochs before stopping. We practiced using this callback on a problem involving the Traffic Volume dataset to train our Keras model.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3iuM4eL">https://packt.live/3iuM4eL</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/38AbweB">https://packt.live/38AbweB</a>.</p>
			<p>In the next section, we will discuss other regularization methods that can be applied to prevent overfitting.<span class="Annotation-reference"> </span></p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor121"/>Data Augmentation</h2>
			<p><strong class="bold">Data augmentation</strong> is a regularization technique that tries to address overfitting by training the model on more training examples in an inexpensive way. In data augmentation, the available data is transformed in different ways and fed to the model as new training data. This type of regularization has been shown to be effective, especially for some specific applications, such as object detection/recognition in computer vision and speech processing.</p>
			<p>For example, in computer vision applications, you can simply double or triple the size of your training dataset by adding mirrored versions and rotated versions of each image to the dataset. The new training examples that are generated by these transformations are obviously not as good as the original training examples. However, they are shown to improve the model in terms of overfitting.</p>
			<p>One challenging aspect of performing data augmentation is choosing the right transformations to be performed on data. Transformations need to be selected carefully, depending on the type of dataset and the application.</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor122"/>Adding Noise</h2>
			<p>The underlying idea behind regularizing a model by adding noise to the data is the same as that for data augmentation regularization. Training a deep neural network on a small dataset increases the chance of the network memorizing single data examples as opposed to capturing the relations between inputs and outputs. </p>
			<p>This will result in poor performance on new data later, which is indicative of the model overfitting the training data. In contrast, training a model on a large dataset increases the chance of the model capturing the true underlying process instead of memorizing single data points, and therefore reduces the chances of overfitting.</p>
			<p>One way to expand the training data and reduce overfitting is to generate new data examples by injecting noise into the available data. This type of regularization has been shown to reduce overfitting to an extent that is comparable to weight regularization techniques. </p>
			<p>By adding different versions of a single example to the training data (each created by adding a small amount of noise to the original example), we can ensure that the model will not fit the noise in the data. Additionally, increasing the size of the training dataset by including these modified examples provides the model with a better representation of the underlying data generation process and increases the chance of the model learning the true process.</p>
			<p>In deep learning applications, you can improve model performance by adding noise to the weights or activations of the hidden layers, or gradients of the network, or even to the output layer, as well as by adding noise to the training examples (input layer). Deciding where to add noise in a deep neural network is another challenge that needs to be addressed by trying different networks and observing the results.</p>
			<p>In Keras, you can easily define noise as a layer and add it to your model. For example, to add <strong class="source-inline">Gaussian noise</strong> with a <strong class="source-inline">standard deviation</strong> of <strong class="source-inline">0.1</strong> (the mean is equal to <strong class="source-inline">0</strong>) to your model, you can write this:</p>
			<p class="source-code">from keras.layers import GaussianNoise</p>
			<p class="source-code">model.add(GaussianNoise(0.1))</p>
			<p>The following code will add <strong class="source-inline">Gaussian noise</strong> to the outputs/activations of the first hidden layer of the model:</p>
			<p class="source-code">model = Sequential()</p>
			<p class="source-code">model.add(Dense(4, input_dim=30, activation='relu'))</p>
			<p class="source-code">model.add(GaussianNoise(0.01))</p>
			<p class="source-code">model.add(Dense(4, activation='relu'))</p>
			<p class="source-code">model.add(Dense(4, activation='relu'))</p>
			<p class="source-code">model.add(Dense(1, activation='sigmoid')) </p>
			<p>In this section, you learned about three regularization methods: <strong class="source-inline">early stopping</strong>, <strong class="source-inline">data augmentation</strong>, and <strong class="source-inline">adding noise</strong>. In addition to their basic concepts and procedures, you also learned about how they reduce overfitting and were given some tips and recommendations on how to use them. In the next section, you will learn how to tune hyperparameters using functions provided by scikit-learn. By doing this, we can incorporate Keras models into a scikit-learn workflow.</p>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor123"/>Hyperparameter Tuning with scikit-learn</h1>
			<p>Hyperparameter tuning is a very important technique for improving the performance of deep learning models. In <em class="italic">Chapter 4</em>, <em class="italic">Evaluating Your Model with Cross-Validation Using Keras Wrappers</em>, you learned about using a Keras wrapper with scikit-learn, which allows for Keras models to be used in a scikit-learn workflow. As a result, different general machine learning and data analysis tools and methods that are available in scikit-learn can be applied to Keras deep learning models. Among those methods are scikit-learn hyperparameter optimizers. </p>
			<p>In the previous chapter, you learned how to perform hyperparameter tuning by writing user-defined functions to loop over possible values for each hyperparameter. In this section, you will learn how to perform it in a much easier way by using the various hyperparameter optimization methods that are available in scikit-learn. You will also get to practice applying those methods by completing an activity involving a real-life dataset.</p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor124"/>Grid Search with scikit-learn</h2>
			<p>So far, we have established that building deep neural networks involves making decisions about several hyperparameters. The list of hyperparameters includes the number of hidden layers, the number of units in each hidden layer, the activation function for each layer, the loss function for the network, the type of optimizer and its parameters, the type of regularizer and its parameters, the batch size, the number of epochs, and others. We also observed that different values of hyperparameters can affect the performance of a model significantly. </p>
			<p>Therefore, finding the best values for hyperparameters is one of the most important and challenging parts of becoming a deep learning expert. Since there are no absolute rules for picking the hyperparameters that work for every dataset and every problem, deciding on the values of hyperparameters needs to be done through trial and error for each particular problem. This process of training and evaluating models with different hyperparameters and deciding about the final hyperparameters based on model performance is called <strong class="bold">hyperparameter tuning</strong> or <strong class="bold">hyperparameter optimization</strong>.</p>
			<p>Having a range or a set of possible values for each hyperparameter that we are interested in tuning can create a grid such as the one shown in the following image. Therefore, hyperparameter tuning can be seen as a grid search problem; we would like to try every cell in the grid (every possible combination of hyperparameters) and find the one cell that results in the best performance for the model:</p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/B15777_05_12.jpg" alt="Figure 5.12: A hyperparameter grid created by some values for optimizer, batch_size, and epochs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.12: A hyperparameter grid created by some values for optimizer, batch_size, and epochs</p>
			<p>Scikit-learn provides a parameter optimizer called <strong class="source-inline">GridSearchCV()</strong> to perform this exhaustive grid search. <strong class="source-inline">GridSearchCV()</strong> receives the model as the <strong class="source-inline">estimator</strong> argument and the dictionary containing all possible values for the hyperparameters as the <strong class="source-inline">param_grid</strong> argument. Then, it goes through every point in the grid, performs cross-validation on the model using the hyperparameter values at that point, and returns the best cross-validation score, along with the values of the hyperparameters that led to that score.</p>
			<p>In the previous chapter, you learned that in order to use Keras models in scikit-learn, you need to define a function that returns a Keras model. For example, the following code block defines a Keras model that we would like to perform hyperparameter tuning on later:</p>
			<p class="source-code">from keras.models import Sequential</p>
			<p class="source-code">from keras.layers import Dense</p>
			<p class="source-code">def build_model():</p>
			<p class="source-code">    model = Sequential(optimizer)</p>
			<p class="source-code">    model.add(Dense(10, input_dim=X_train.shape[1], \</p>
			<p class="source-code">                    activation='relu'))</p>
			<p class="source-code">    model.add(Dense(10, activation='relu'))</p>
			<p class="source-code">    model.add(Dense(1))</p>
			<p class="source-code">    model.compile(loss='mean_squared_error', \</p>
			<p class="source-code">                  optimizer= optimizer)</p>
			<p class="source-code">    return model</p>
			<p>The next step would be to define the grid of parameters. For example, say we would like to tune over <strong class="source-inline">optimizer=['rmsprop', 'adam', 'sgd', 'adagrad']</strong>, <strong class="source-inline">epochs = [100, 150]</strong>, <strong class="source-inline">batch_size = [1, 5, 10]</strong>. To do so, we would write the following:</p>
			<p class="source-code">optimizer = ['rmsprop', 'adam', 'sgd', 'adagrad']</p>
			<p class="source-code">epochs = [100, 150]</p>
			<p class="source-code">batch_size = [1, 5, 10]</p>
			<p class="source-code">param_grid = dict(optimizer=optimizer, epochs=epochs, \</p>
			<p class="source-code">                  batch_size= batch_size)</p>
			<p>Now that the hyperparameter grid has been created, we can create the wrapper so that we can build the interface for the Keras model and use it as an estimator to perform the grid search:</p>
			<p class="source-code">from keras.wrappers.scikit_learn import KerasRegressor</p>
			<p class="source-code">model = KerasRegressor(build_fn=build_model, \</p>
			<p class="source-code">                       verbose=0, shuffle=False)</p>
			<p class="source-code">from sklearn.model_selection import GridSearchCV</p>
			<p class="source-code">grid_search = GridSearchCV(estimator=model, \</p>
			<p class="source-code">                           param_grid=param_grid, cv=10)</p>
			<p class="source-code">results = grid_search.fit(X, y)</p>
			<p>The preceding code through goes through every cell in the grid exhaustively and performs 10-fold cross-validation using hyperparameter values in each cell (here, it performs <strong class="source-inline">10-fold cross-validation</strong> 4*2*3=24 times). Then, it returns the cross-validation score for each of these <strong class="source-inline">24</strong> cells, along with the one that resulted in the best score.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Performing k-fold cross-validation on many possible combinations of hyperparameters sure takes a long time. For this reason, you can parallelize the process by passing the <strong class="source-inline">n_jobs=-1</strong> argument to <strong class="source-inline">GridSearchCV()</strong>, which results in using every processor available to perform the grid search. The default value for this argument is <strong class="source-inline">n_jobs=1</strong>, which means no parallelization.</p>
			<p>Creating a hyperparameter grid is just one way to iterate through hyperparameters to find the optimal selection. Another way is to simply randomize the selection of hyperparameters, which we will learn about in the next topic.</p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor125"/>Randomized Search with scikit-learn</h2>
			<p>As you may have realized, an exhaustive grid search may not be the best choice for tuning the hyperparameters of a deep learning model since it is not very efficient. There are many hyperparameters in deep learning, and especially if you would like to try a large range of values for each, an exhaustive grid search would simply take too long to complete. An alternative way to perform hyperparameter optimization is to perform random sampling on the grid and perform k-fold cross-validation on some randomly selected cells. Scikit-learn provides an optimizer called <strong class="source-inline">RandomizedSearchCV()</strong> to perform a random search for the purpose of hyperparameter optimization.</p>
			<p>For example, we can change the code from the previous section from an exhaustive grid search to a random search like so:</p>
			<p class="source-code">from keras.wrappers.scikit_learn import KerasRegressor</p>
			<p class="source-code">model = KerasRegressor(build_fn=build_model, verbose=0)</p>
			<p class="source-code">from sklearn.model_selection import RandomizedSearchCV</p>
			<p class="source-code">grid_search = RandomizedSearchCV(estimator=model, \</p>
			<p class="source-code">                                 param_distributions=param_grid, \</p>
			<p class="source-code">                                 cv=10, n_iter=12)</p>
			<p class="source-code">results = grid_search.fit(X, y)</p>
			<p>Notice that <strong class="source-inline">RandomizedSearchCV()</strong> requires the extra <strong class="source-inline">n_iter</strong> argument, which determines how many random cells must be selected. This determines how many times k-fold cross-validation will be performed. Therefore, by choosing a smaller number, fewer hyperparameter combinations will be considered and the method will take less time to complete. Also, please note that the <strong class="source-inline">param_grid</strong> argument is changed to <strong class="source-inline">param_distributions</strong> here. The <strong class="source-inline">param_distributions</strong> argument can take a dictionary with parameter names as keys, and either list of parameters or distributions as values for each key.</p>
			<p>It could be argued that <strong class="source-inline">RandomizedSearchCV()</strong> is not as good as <strong class="source-inline">GridSearchCV()</strong> since it does not consider all the possible values and combinations of values for hyperparameters, which is reasonable. As a result, one smart way of performing hyperparameter tuning for deep learning models is to start with either <strong class="source-inline">RandomizedSearchCV()</strong> on many hyperparameters, or <strong class="source-inline">GridSearchCV()</strong> on fewer hyperparameters with larger gaps between them. </p>
			<p>By beginning with a randomized search on many hyperparameters, we can determine which hyperparameters have the most influence on a model's performance. It can also help narrow down the range for important hyperparameters. Then, you can complete your hyperparameter tuning by performing <strong class="source-inline">GridSearchCV()</strong> on the smaller number of hyperparameters and the smaller ranges for each of them. This is called the <strong class="bold">coarse-to-fine</strong> approach to hyperparameter tuning.</p>
			<p>Now, you are ready to practice implementing hyperparameter tuning using scikit-learn optimizers. In the next activity, you will try to improve your model for the diabetes dataset by tuning the hyperparameters.</p>
			<h2 id="_idParaDest-125">Activity 5.0<a id="_idTextAnchor126"/>3: Hyperparameter Tuning on the Avila Pattern Classifier</h2>
			<p>The Avila dataset has been extracted from <strong class="source-inline">800</strong> images of the Avila Bible, a giant 12<span class="superscript">th</span>-century Latin copy of the Bible. The dataset consists of various features about the images of the text, such as intercolumnar distance and margins of the text. The dataset also contains a class label that indicates if the pattern of the image falls into the most frequently occurring category or not. In this activity, you will build a Keras model similar to those in the previous activities, but this time, you will add regularization methods to your model as well. Then, you will use scikit-learn optimizers to perform tuning on the model hyperparameters, including the hyperparameters of the regularizers. Here are the steps you need to complete in this activity:</p>
			<ol>
				<li value="1">Load the dataset from the <strong class="source-inline">data</strong> subfolder of the <strong class="source-inline">Chapter05</strong> folder from GitHub using <strong class="source-inline">X = pd.read_csv('../data/avila-tr_feats.csv')</strong> and <strong class="source-inline">y = pd.read_csv('../data/avila-tr_target.csv')</strong>. </li>
				<li>Define a function that returns a Keras model with three hidden layers, the first of <strong class="source-inline">size 10</strong>, the second of <strong class="source-inline">size 6</strong>, and the third of <strong class="source-inline">size 4</strong>, all with <strong class="source-inline">L2 weight regularizations</strong>. Use these values as the hyperparameters for your model: <strong class="source-inline">activation='relu'</strong>, <strong class="source-inline">loss='binary_crossentropy'</strong>, <strong class="source-inline">optimizer='sgd'</strong>, and <strong class="source-inline">metrics=['accuracy']</strong>. Also, make sure to pass the <strong class="source-inline">L2 lambda</strong> hyperparameter as an argument to your function so that we can tune it later.</li>
				<li>Create the wrapper for your Keras model and perform <strong class="source-inline">GridSearchCV()</strong> on it using <strong class="source-inline">cv=5</strong>. Then, add the following values in the parameter grid: <strong class="source-inline">lambda_parameter = [0.01, 0.5, 1]</strong>, <strong class="source-inline">epochs = [50, 100]</strong>, and <strong class="source-inline">batch_size = [20]</strong>. This might take some time to process. Once the parameter search is complete, print the accuracy and the hyperparameters of the best cross-validation score. You can also print every other cross-validation score, along with the hyperparameters that resulted in that score.</li>
				<li>Repeat the previous step, this time using <strong class="source-inline">GridSearchCV()</strong> on a narrower range with <strong class="source-inline">lambda_parameter = [0.001, 0.01, 0.05, 0.1]</strong>, <strong class="source-inline">epochs = [400]</strong>, and <strong class="source-inline">batch_size = [10]</strong>. It might take some time to process.</li>
				<li>Repeat the previous step, but remove the <strong class="source-inline">L2 regularizers</strong> from your Keras model and instead of adding dropout regularization with the <strong class="source-inline">rate</strong> parameter at each hidden layer. Perform <strong class="source-inline">GridSearchCV()</strong> on the model using the following values in the parameter grid and print the results:<strong class="source-inline"> rate = [0, 0.2, 0.4]</strong>, <strong class="source-inline">epochs = [350, 400]</strong>, and <strong class="source-inline">batch_size = [10]</strong>.</li>
				<li>Repeat the previous step using <strong class="source-inline">rate = [0.0, 0.05, 0.1]</strong> and <strong class="source-inline">epochs=[400]</strong>.</li>
			</ol>
			<p>After implementing these steps, you should see the following expected output:</p>
			<p class="source-code">Best cross-validation score= 0.7862895488739013</p>
			<p class="source-code">Parameters for Best cross-validation score= {'batch_size': 20, 'epochs': 100, 'rate': 0.0}</p>
			<p class="source-code">Accuracy 0.786290 (std 0.013557) for params {'batch_size': 20, 'epochs': 100, 'rate': 0.0}</p>
			<p class="source-code">Accuracy 0.786098 (std 0.005184) for params {'batch_size': 20, 'epochs': 100, 'rate': 0.05}</p>
			<p class="source-code">Accuracy 0.772004 (std 0.013733) for params {'batch_size': 20, 'epochs': 100, 'rate': 0.1}</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found on page 422.</p>
			<p>In this activity, we learned how to implement hyperparameter tuning on a Keras model with regularizers to perform classification using a real-life dataset. We learned how to use scikit-learn optimizers to perform tuning on model hyperparameters, including the hyperparameters of the regularizers. In this section, we implemented hyperparameter tuning by creating a grid of hyperparameters and iterating through them. This allows us to find the optimal set of hyperparameters using a scikit-learn workflow.</p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor127"/>Summary</h1>
			<p>In this chapter, you learned about two very important groups of techniques for improving the accuracy of your deep learning models: regularization and hyperparameter tuning. You learned how regularization helps address the overfitting problem by means of several different methods, including L1 and L2 norm regularization and dropout regularization—the more commonly used regularization techniques. You discovered the importance of hyperparameter tuning for machine learning models and the challenge of hyperparameter tuning for deep learning models in particular. You even practiced using scikit-learn optimizers to perform hyperparameter tuning on Keras models.</p>
			<p>In the next chapter, you will explore the limitations of accuracy metrics when evaluating model performance, as well as other metrics (such as <strong class="source-inline">precision</strong>, <strong class="source-inline">sensitivity</strong>, <strong class="source-inline">specificity</strong>, and <strong class="source-inline">AUC-ROC score</strong>), including how to use them in order to gauge the quality of your model's performance better.</p>
		</div>
		<div>
			<div id="_idContainer124" class="Content">
			</div>
		</div>
	</body></html>