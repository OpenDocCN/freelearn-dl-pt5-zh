<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Training Multiple Layers of Neurons
                </header>
            
            <article>
                
<p>Previously, in <a href="4e4b45a6-1924-4918-b2cd-81f0448fb213.xhtml">Chapter 6</a>, <em>Training a Single Neuron</em>, we explored a model involving a single neuron and the concept of the perceptron. A limitation of the perceptron model is that, at best, it can only produce linear solutions on a multi-dimensional hyperplane. However, this limitation can be easily solved by using multiple neurons and multiple layers of neurons in order to produce highly complex non-linear solutions for separable and non-separable problems. This chapter introduces you to the first challenges of deep learning using the <strong>Multi-Layer Perceptron</strong><span> (</span><strong>MLP</strong><span>)</span> algorithm, such as a gradient descent technique for error minimization, followed by hyperparameter optimization experiments to determine trustworthy accuracy.</p>
<p>The following topics will be covered in this chapter: </p>
<ul>
<li>The MLP model</li>
<li>Minimizing the error</li>
<li>Finding the best hyperparameters</li>
</ul>
<h1 id="uuid-77e7ee06-3418-4d08-8e30-65cd3d96f3bd">The MLP model</h1>
<p>We have previously seen, in <a href="4e4b45a6-1924-4918-b2cd-81f0448fb213.xhtml">Chapter 5</a>, <em>Training a Single Neuron</em>, that Rosenblatt's perceptron model is simple and powerful for some problems (<span>Rosenblatt, F. 1958)</span>. However, for more complicated and highly non-linear problems, Rosenblatt did not give enough attention to his models that connected many more neurons in different architectures, including deeper models (Tappert, C. 2019).</p>
<p class="mce-root"/>
<p>Years later, in the 1990s, Prof. Geoffrey Hinton, the 2019 Turing Award winner, continued working to connect more neurons together since this is more brain-like than simple neurons (<span>Hinton, G. 1990). Most people today know this type of approach as <em>connectionist</em>.<em> </em>The main idea is to connect neurons in different ways that will resemble brain connections. One of the first successful models was the MLP, </span>which uses a supervised gradient descent-based learning algorithm that learns to approximate a function, <img class="fm-editor-equation" src="assets/f8bc26a8-f3ac-430b-b3a0-0bf4dab209f0.png" style="width:2.42em;height:1.50em;"/>, using labeled data, <img class="fm-editor-equation" src="assets/a99bcb2f-d199-4000-afb9-9665eeb321ce.png" style="width:8.08em;height:1.58em;"/>. </p>
<p><em>Figure 6.1</em> depicts an MLP with one layer of multiple neurons that indicate how the input connects to all neurons through weights, which stimulate a neuron to produce a large (non-zero) numerical response, depending on the variable weights that need to be <em>learned</em>:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/23b21eea-b260-4f2d-bbc7-02be5377d5b1.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6.1 – Multiple perceptrons in one hidden layer</div>
<p>For completeness, <em>Figure 6.2</em> depicts the same architecture but vertically; it also shows positive weights in light gray and negative weights in darker gray. <em>Figure 6.2</em> aims to show that some features might stimulate some neurons more than others:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/1ffd2130-584b-49fa-8742-da9b062fc576.png"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6.2 – MLP with weights that are grayscale-coded: lighter grays denote positive weights, darker grays denote negative weights</div>
<p class="mce-root">Based on <em>Figure 6.2</em>, the layer of neurons at the top is known as the <strong>input layer</strong>. These features are connected to different neurons in a layer known as a <strong>hidden layer</strong>. This layer usually consists of at least one layer of neurons, but in deep learning, it may contain many more. </p>
<div class="packt_infobox"><strong>On the interpretation of the weights close to the input layer</strong>:<strong> </strong>One of the key differences between the MLP and the perceptron is that the interpretation of the weights in the input layer is lost in the MLP unless the hidden layer contains only one neuron. Usually, in a perceptron, you can argue that the importance of certain features is directly correlated to the value (weight) directly associated with those features. For example, the feature associated with the most negative weight is said to negatively <span>influence the outcome, and the feature associated with the most positive weight is also influencing the outcome in a significant manner. Therefore, looking into the absolute value of the weights in a perceptron (and in linear regression) can inform us about feature importance. Not so much in the MLP; the more neurons are involved and the more layers are involved, the chances of interpreting weights and feature importance is reduced significantly. You must not rely heavily on the first-layer weights to deduce feature importance. Be careful.</span></div>
<p>From <em>Figure 6.1</em>, we can see that neurons, <img class="fm-editor-equation" src="assets/ce8c7434-1308-4835-9eef-56f1500898e1.png" style="width:3.67em;height:1.50em;"/>, are simplified to imply that there is some non-linear activation function, <sub><img class="fm-editor-equation" src="assets/5f7fc36f-88a3-48dd-a180-fce9b6554ca7.png" style="width:1.67em;height:1.25em;"/></sub>, over the scalar, resulting from adding the products of the features and the weights associated with those features and that neuron, <img class="fm-editor-equation" src="assets/83f57141-0dcf-4762-8213-a0c10510bb30.png" style="width:2.67em;height:1.42em;"/>. In deeper MLP layers, the input is no longer data from the input layer, <img class="fm-editor-equation" src="assets/d2fab579-f5ed-47a4-9f99-17afa1dba090.png" style="width:0.92em;height:1.00em;"/>, but <span>are</span><span> </span><span>rather outputs from previous layers:</span> <img style="font-size: 1em;width:5.00em;height:1.42em;" class="fm-editor-equation" src="assets/023944b5-18a7-4fec-b8bc-92a950d346a6.png"/><span>. We will make some changes to the notation in the next section to describe this process more formally.</span></p>
<p class="mce-root">For now, what you need to know is that the MLP is a lot better than the perceptron in that is has the ability to learn highly complex non-linear models. The perceptron is only able to provide linear models. But with this power comes great responsibility. The MLP has a non-convex and non-smooth loss function that limits how the learning process is achieved, and although there has been much progress, their problems still persist. Another disadvantage is that the learning algorithms may need other hyperparameters to assure the success (convergence) of the algorithm. Finally, it is worth noting that the MLP requires preprocessing of the input features (normalization) to mitigate neurons overfitting on specific features.</p>
<p>Now, let's examine how the learning process actually happens.</p>
<h1 id="uuid-5597f45e-b614-4db6-8826-7227fd4f044e">Minimizing the error</h1>
<p>Learning from data using an MLP was one of the major problems since its conception. As we pointed out before, one of the major problems with neural networks was the computational tractability of deeper models, and the other was stable learning algorithms that would converge to a reasonable minimum. One of the major breakthroughs in machine learning, and what paved the way for deep learning, was the development of the learning algorithm based on backpropagation. Many scientists independently derived and applied forms of backpropagation in the 1960s; however, most of the credit has been given to Prof. G. E. Hinton and his group (Rumelhart, D. E., et.al. 1986). In the next few paragraphs, we will go over this algorithm, whose sole purpose is to <strong>minimize the error</strong> caused by incorrect predictions made during training.</p>
<p class="mce-root"/>
<p>To begin, we will describe the dataset, which is called <strong>spirals</strong><em>. </em>This is a widely known benchmark dataset that has two classes that are separable, yet highly non-linear. The positive and negative classes go around each other on opposite sides of a two-dimensional space as they grow from the center outward, as shown in <em>Figure 6.3</em>:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/97403252-c001-4e6a-b531-65055aded079.png" style="width:28.00em;height:27.58em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6.3 – Sample data from the two-spiral benchmark</div>
<p>The dataset can be produced using the following function in Python:</p>
<pre>def twoSpirals(N):<br/>  np.random.seed(1)<br/>  n = np.sqrt(np.random.rand(N,1)) * 780 * (2*np.pi)/360<br/>  x = -np.cos(n)*n<br/>  y = np.sin(n)*n<br/>  return (np.vstack((np.hstack((x,y)),np.hstack((-x,-y)))), <br/>          np.hstack((np.ones(N)*-1,np.ones(N))))<br/><br/>X, y = twoSpirals(300)  #Produce 300 samples</pre>
<p>In this code fragment, we will receive in <kbd>X</kbd> a two-column matrix whose rows are samples of the spiral dataset, and <kbd>y</kbd> contains the corresponding target class in the <img class="fm-editor-equation" src="assets/20c250a1-a4d1-42b6-81a5-a0a4224ba882.png" style="width:4.75em;height:1.42em;"/> set. <em>Figure 6.3</em> was produced based on the preceding code fragment, which contains 300 samples.</p>
<p>We will also use a very simple MLP architecture with only three neurons in a single hidden layer; this is only to explain <em>backpropagation</em> as clearly as possible. The proposed MLP is shown in <em>Figure 6.4</em>:</p>
<div class="packt_tip">Backpropagation is known among the professionals today as <strong>backprop</strong><em>. </em>If you read any recent online discussions about it, it will most likely be referred to as backprop, for short.</div>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/681215c7-cbf6-4b98-b884-8fd0ddb2e2d4.png" style="width:31.92em;height:23.67em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6.4 - Simple MLP architecture for backpropagation-based learning on the spiral dataset</div>
<p class="mce-root"/>
<p>The architecture of the network shown in <em>Figure 6.4</em> assumes that there is a well-defined input vector <span>containing multiple vectors, </span><img class="fm-editor-equation" src="assets/ade78908-fbaa-441d-95df-05554ba3fa62.png" style="width:0.75em;height:0.83em;"/><span> (a matrix), represented as </span><img class="fm-editor-equation" src="assets/ac0661e9-7c97-4ce4-acc3-c76ebead6fa6.png" style="width:4.92em;height:1.17em;"/><span>, and multiple individual targets represented as a vector, </span><img class="fm-editor-equation" src="assets/91f42c43-effa-40ab-b990-29ae9d78b06b.png" style="width:5.50em;height:1.42em;"/><span>. Also, each layer, <img class="fm-editor-equation" src="assets/d16b47e7-3267-4767-822c-a2317f7bc349.png" style="width:4.33em;height:1.25em;"/>, has a matrix of weights,</span> <span><img class="fm-editor-equation" src="assets/2f1013b9-18cc-496b-8e0d-87e17bce2e02.png" style="width:1.75em;height:1.00em;"/>, which is the case with the first layer. For example, from <em>Figure 6.4</em>,</span><span> the weight matrices would be as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><span><img class="fm-editor-equation" src="assets/20f071f2-4395-4dd8-a4d1-14ce57fc7b06.png" style="width:16.50em;height:3.75em;"/></span></p>
<p class="CDPAlignCenter CDPAlign"><span><img class="fm-editor-equation" src="assets/92af53a3-84d9-4d77-968b-e8745ef359ad.png" style="width:10.75em;height:4.75em;"/></span><span>.</span></p>
<p class="mce-root">These matrices have real values initialized at random. The hidden layer, <img class="fm-editor-equation" src="assets/e7bdbf92-3a53-4f0f-a836-88df5a020e1e.png" style="width:2.17em;height:0.92em;"/>, consists of three neurons. Each neuron in receives as input, <img class="fm-editor-equation" src="assets/d305bc5a-7909-4ecc-ab93-76328e67de8c.png" style="width:1.58em;height:1.58em;"/>, a weighted sum of observations consisting of the inner product of the features and the weights leading to the <em>i</em>th neuron; for example, for the first neuron it would be as follows:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/68263946-1dec-4a7b-88af-95e0423c887f.png" style="width:12.75em;height:3.50em;"/></p>
<p class="mce-root">Here, <img class="fm-editor-equation" src="assets/9eb3fd4a-2973-460a-9eb4-d53ef2db7fb3.png" style="width:2.50em;height:1.50em;"/> denotes the output of the activation function of the first neuron in the first layer, which in this case would be a sigmoid.</p>
<div class="packt_infobox">The sigmoid activation function is denoted as <img class="fm-editor-equation" src="assets/57a4a874-66bc-40f8-92bf-e2182fb49c42.png" style="width:6.58em;height:2.25em;"/>. This function is interesting because it squashes whatever value it receives as input and maps it to values between 0 and 1. It is also a nice function to use in gradient calculation since its derivative is well known and easy to compute: <img class="fm-editor-equation" src="assets/8df4cea8-a438-4497-a673-8887fe5d4439.png" style="width:9.75em;height:2.00em;"/>.</div>
<p class="mce-root"/>
<p>In Python, we could easily code the sigmoid as follows:</p>
<pre>def sigmoid(z, grad=False):<br/>  if grad:<br/>    return z * (1. - z)<br/>  return 1. / (1. + np.exp(-z))</pre>
<p class="mce-root">Finally, the output layer consists of two neurons that, in this case, we will use to model each of the target classes, the positive spiral, and the negative spiral. </p>
<p class="mce-root">With this in mind, we can do backprop to correct the weights based on the direction of the gradient that minimizes the error for a given set of labeled samples; for more details, refer to this tutorial (Florez, O. U. 2017). We will be following the steps outlined in the following sections.</p>
<h2 id="uuid-212e4189-df5b-42f2-ba23-1c8242f6b001">Step 1 –<strong> I</strong>nitialization</h2>
<p class="mce-root">We will perform an initial step in which we <em>randomly initialize</em> the network weights. In our example, we will use the following values:</p>
<p class="CDPAlignCenter CDPAlign"><span><img class="fm-editor-equation" src="assets/3d2e1892-0403-49d9-83f3-999d370f3f82.png" style="width:37.58em;height:3.08em;"/></span></p>
<p class="CDPAlignCenter CDPAlign"><span><img class="fm-editor-equation" src="assets/12423628-7956-4956-92bd-bb2f26ca49f6.png" style="width:27.17em;height:4.67em;"/></span></p>
<p>In Python, we can generate these weights between <kbd>-1</kbd> and <kbd>1</kbd> by using the following:</p>
<pre>w1 = 2.0*np.random.random((2, 3))-1.0<br/>w2 = 2.0*np.random.random((3, 2))-1.0</pre>
<p class="mce-root"/>
<h2 id="uuid-5004d89f-fa2a-4495-a828-6c95692950bf">Step 2 – The forward pass</h2>
<p class="mce-root">The next step would be the <strong>forward pass</strong>. In this step, the input, <img class="fm-editor-equation" src="assets/ac0661e9-7c97-4ce4-acc3-c76ebead6fa6.png" style="width:5.25em;height:1.25em;"/>, is presented at the input layer and propagated forward into the network until we observe the resulting vector in the output layer. The forward pass in our small example would be as follows. We first begin with a linear transformation of a single sample, <img class="fm-editor-equation" src="assets/c8374d95-3dae-4f96-bdb1-b0346cc68a35.png" style="width:1.17em;height:1.00em;"/>, using weight <img class="fm-editor-equation" src="assets/a3f1d43f-f209-430f-8494-f86c66078dd5.png" style="width:1.92em;height:1.00em;"/> in the first layer:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e2b5afa8-5943-4bbc-9b45-388f78621b69.png" style="width:24.83em;height:3.42em;"/></p>
<p>Thus, for some cases of <sub><img class="fm-editor-equation" src="assets/76b30968-7c2c-49fc-bf0c-153e1850d087.png" style="width:13.67em;height:1.17em;"/></sub>, we calculate the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/494ef2a0-670b-4f9e-ad84-f12556367caa.png" style="width:37.75em;height:2.50em;"/></p>
<p>This would result in the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/773c3be4-8bd4-44d9-87e3-59b2eeeed61a.png" style="width:25.92em;height:1.58em;"/></p>
<p>Then, we pass <img class="fm-editor-equation" src="assets/21bd032a-0138-413e-9733-354daa3b2bc6.png" style="width:2.00em;height:1.50em;"/> through the sigmoid function and obtain <img class="fm-editor-equation" src="assets/9cce632f-89d6-4696-a577-11600b215a51.png" style="width:2.17em;height:1.33em;"/>, which is the output of the three neurons in the first hidden layer. This results in the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/209f362a-3c70-43a8-b01c-6d846a062c5e.png" style="width:34.33em;height:1.67em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8bb3dfca-4b6d-4d08-a799-ca3301dd95e8.png" style="width:23.33em;height:1.50em;"/></p>
<p>This could be implemented as follows:</p>
<pre>o1 = sigmoid(np.matmul(X, w1))</pre>
<p>One interesting way to look at what we have accomplished so far in the first layer is that we have mapped the input data, which was in two dimensions, into three dimensions, which will be now processed to observe the output back in two dimensions.</p>
<p>The same process is repeated for any subsequent layers in the group of hidden layers. In our example, we will do this only one more time for the output layer. We calculate the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/20021201-4248-4189-866b-7f574e564d0c.png" style="width:27.75em;height:5.08em;"/></p>
<p>This results in the following calculation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/9811422c-83a4-45a6-bf05-14f1acbbe4d0.png" style="width:36.17em;height:4.33em;"/></p>
<p>This leads to the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/02620605-1286-4589-990a-108cea5d8da7.png" style="width:18.83em;height:1.75em;"/></p>
<p>Again, we pass <span><img class="fm-editor-equation" src="assets/47d30185-f322-4978-b271-65d1317e2fc4.png" style="width:1.33em;height:1.00em;"/></span> through the sigmoid<span> </span>function and obtain <span><img class="fm-editor-equation" src="assets/0b3f0d9a-2f04-4ab4-903a-e68566f7d410.png" style="width:2.00em;height:1.17em;"/></span>, which is the output of the two neurons in the output layer. This results in the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/cd3a9429-e4b9-46db-a9e1-9e39fafac287.png" style="width:25.17em;height:1.67em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/26ce4485-4520-44e6-b87c-2e9a6f3f589b.png" style="width:17.17em;height:1.50em;"/></p>
<p>We implement this as follows:</p>
<pre>o2 = sigmoid(np.matmul(o1, w2))</pre>
<p class="mce-root">At this point, we need to give some meaning to this output so that we can determine the next step. What we would like to model in these two last neurons is the probability of the input data, <img class="fm-editor-equation" src="assets/01f2e877-eafd-4a0d-ab5a-f136d34f193e.png" style="width:1.17em;height:1.00em;"/>, belonging to the positive class in <img class="fm-editor-equation" src="assets/11d943f1-5879-4507-b3d3-29b4bf9cf0f8.png" style="width:1.75em;height:1.00em;"/>, and the probability of it belonging to the negative class in <img class="fm-editor-equation" src="assets/f61d8b20-a71c-42c9-8d70-bc8e929c32d3.png" style="width:1.75em;height:1.00em;"/>. The next step is to establish an error metric in order to learn. </p>
<div class="packt_tip">Error metrics, or error functions, are also known as <strong>loss</strong> functions.</div>
<h2 id="uuid-1365a6e2-6fb5-498d-968a-628fac3d48c3">Step 3 – Calculating loss</h2>
<p>The next step is to define and <strong>calculate the total loss</strong>. In <a href="7f55e68e-2e9f-486f-9337-5b2ea7bdb504.xhtml">Chapter 4</a>, <em>Learning from Data</em>, we discussed some error metrics (or losses), such as the <strong>Mean Squared Error</strong> (<strong>MSE</strong>):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/557a0c88-66bc-44cf-bfa2-6e2951d1efe6.png" style="width:11.58em;height:3.92em;"/></p>
<p>It is important to think about this loss in terms of its derivative since we want to adjust the weights of the network in terms of the gradient as given by this loss function. Thus, we can do small changes that do not affect at all the overall result of the learning process but can result in nice derivatives. For example, if we take the derivative of <img class="fm-editor-equation" src="assets/4ccc438c-c376-4129-933f-88b8f8071a1f.png" style="width:0.83em;height:1.00em;"/>, the square will imply a multiplication by a factor of 2, but we could nullify the effect of that by slightly modifying the MSE, introducing a division by 2, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dddcf0c5-0e8f-44c0-aea5-50e5a1d0fd75.png" style="width:10.67em;height:3.42em;"/></p>
<p>This loss, therefore, can be used to determine how "wrong" the predictions are from the actual target outcome. In the preceding example, the desired outcome was as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/19fb4378-3d63-470b-9df5-289c8b3d8de9.png" style="width:5.58em;height:1.25em;"/></p>
<p>The predicted response was as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/87a96822-6701-4595-b8e3-a825c19c20e9.png" style="width:15.58em;height:1.33em;"/></p>
<p>This is normal since the weights were initialized at random; thus, it is expected from the model to perform poorly. The network can be further improved by using a modern approach that penalizes weights from taking on very large values. In neural networks, there is always a risk of having <em>exploding</em> or <em>vanishing</em> gradients, and a simple technique to reduce the effects of large gradients is to put a limit on the scale of the numbers that the weights can take. This is widely known as <strong>regularization</strong><em>.</em> It leads to other nice properties, such as <em>sparse </em>models. We can achieve this regularization by modifying the loss as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/130cef99-5d09-40e4-8ab4-dfc60e4ee288.png" style="width:19.50em;height:3.58em;"/></p>
<p class="mce-root"/>
<p>This loss can be implemented as follows:</p>
<pre>L = np.square(y-o2).sum()/(2*N) + lambda*(np.square(w1).sum()+np.square(w2).sum())/(2*N)</pre>
<p class="mce-root">The added regularization term adds up all the weights in each layer and large weights are penalized according to the <sub><img class="fm-editor-equation" src="assets/db43bf9a-01db-41ef-9b36-e1ef465034dd.png" style="width:0.58em;height:0.83em;"/></sub> parameter. This is a hyperparameter that needs to be fine-tuned by ourselves. A large <sub><img class="fm-editor-equation" src="assets/06a4486b-5db9-45b3-919d-207024d4c9f8.png" style="width:0.50em;height:0.75em;"/></sub> value penalizes heavily any large weights, and a small <sub><img class="fm-editor-equation" src="assets/b2c50ffc-d77b-4ca8-8302-f1fffbdc908c.png" style="width:0.50em;height:0.75em;"/></sub> value ignores any effects of the weights in the learning process. This is the loss function we will use in this model, and note that the regularization term is also easily differentiable.</p>
<h2 id="uuid-aa9864c2-fc3a-4ed6-a342-d6106e4d7f04">Step 4 – The backward pass</h2>
<p class="mce-root">The next step is to perform the <strong>backward pass</strong>. The goal is to adjust the weights in proportion to the loss and in a direction that reduces it. We start by calculating the partial derivative of <img class="fm-editor-equation" src="assets/249ffbfe-f393-437b-bd72-7a54f1c8039d.png" style="width:0.75em;height:0.92em;"/> with respect to the weights in the output layer, <img class="fm-editor-equation" src="assets/c953fad4-6078-47d9-9fe2-bca5e1dbdb72.png" style="width:2.33em;height:1.83em;"/>, and then with respect to the first layer,<img class="fm-editor-equation" src="assets/ad16f9ee-de9c-4e84-b2ea-fa99247469ad.png" style="width:2.33em;height:1.83em;"/>.</p>
<p>Let's begin the <em>backward pass</em> by solving the first partial derivative. We can do so by using the well-known chain rule that allows us to decompose the main derivative in pieces that represent the same process; we do that as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/168170fe-622b-46db-9d3d-9bcb86e1ee2d.png" style="width:11.33em;height:2.50em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/e40ad2d2-af44-43ac-bbc2-822951f2f39a.png" style="width:5.83em;height:1.58em;"/> for all cases of <img class="fm-editor-equation" src="assets/fb3adba7-f666-4239-97c6-576e47a83bcd.png" style="width:3.83em;height:1.08em;"/>. If we define each piece of these partial derivatives independently, we arrive at the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b94ddeac-2053-40a2-b653-47cc064ef75b.png" style="width:8.17em;height:2.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/fb13fb48-5849-40a3-a9f1-69bbe20a5f61.png" style="width:9.92em;height:2.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ab902ca0-b5c6-404f-9bde-6cc193f959b6.png" style="width:6.08em;height:2.92em;"/></p>
<p class="mce-root">These three partial derivatives have an exact solution every time. In our example, their values would be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/399a46ae-839d-47bf-acf3-d691b35bbc1f.png" style="width:36.00em;height:2.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/076e587b-de5f-44e5-96e4-f742f263be96.png" style="width:27.92em;height:3.42em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7dbe6388-5a1c-49da-aa72-7eb361e876c5.png" style="width:20.58em;height:2.50em;"/></p>
<p>Now, since we need to update the weights, <img class="fm-editor-equation" src="assets/0a204667-c6e2-48b4-9b72-cacff3d9de90.png" style="width:5.25em;height:1.08em;"/>, we need a <span>3 x 2 matrix, and, therefore, we can get this update by multiplying the vectors of the partial derivatives, as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2789ffb5-2f1c-41db-8937-c4e706cc7551.png" style="width:34.75em;height:8.42em;"/></p>
<p>To get this result, we first need to perform an element-wise multiplication of the two small vectors on the right, and then perform an ordinary multiplication by the left transposed vector. In Python, we could do this:</p>
<pre>dL_do2 = -(y - o2)<br/>do2_dz2 = sigmoid(o2, grad=True)<br/>dz2_dw2 = o1<br/>dL_dw2 = dz2_dw2.T.dot(dL_do2*do2_dz2) + lambda*np.square(w2).sum()</pre>
<p>Now that we have calculated the derivative, we can perform an update of the weights using a traditional scaling factor on the gradient known as the <strong>learning rate</strong>. We calculate the new <img class="fm-editor-equation" src="assets/60a35181-ab53-4305-9cfe-8f5abc430dfe.png" style="width:1.67em;height:1.08em;"/> value, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/549867f0-5708-447b-934e-bb0e66cd71cd.png" style="width:10.42em;height:2.42em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e7219868-e0c4-4927-81b5-2cb7d6dd3731.png" style="width:28.92em;height:6.92em;"/></p>
<div class="packt_infobox">The <strong>learning rate</strong> is a mechanism that we use in machine learning to limit the influence of the derivatives in the update process. Remember that the derivative is interpreted as the rate of change of the weights given some input data. A <em>large</em> learning rate values too much the direction and magnitude of the derivatives and has the risk of skipping a good local minimum. A <em>small</em> learning rate only partially considers the information of the derivative at the risk of making very slow progress toward a local minimum. The learning rate is another hyperparameter that needs to be tuned.</div>
<p>Now, we proceed to calculate the next derivative, <img class="fm-editor-equation" src="assets/ad16f9ee-de9c-4e84-b2ea-fa99247469ad.png" style="width:2.92em;height:2.33em;"/>, which will allow us to calculate the update on <img class="fm-editor-equation" src="assets/d34676f3-5d66-40b6-9a7f-fa10370f8fe6.png" style="width:1.92em;height:1.00em;"/>. We begin by defining the partial derivative and attempt to simplify its calculation, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/709107ac-e03d-46ec-95c8-9e42c7b2eb1b.png" style="width:11.75em;height:2.58em;"/></p>
<p>If we pay close attention to the first partial derivative, <img class="fm-editor-equation" src="assets/13627e0b-94a6-4a58-88d2-c8481dc86166.png" style="width:1.83em;height:2.25em;"/>, we can notice that its derivative is defined as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/cd8c817a-371a-4817-abb3-59a86126e61f.png" style="width:7.92em;height:2.92em;"/></p>
<p>But the underlined term has already been calculated before! Notice that the underlined term is equivalent to the underlined term in the previously defined equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1d1e6ffe-8f5f-4dc1-b1ce-7d2708de3be0.png" style="width:12.08em;height:3.08em;"/></p>
<p class="mce-root"/>
<p>This is a nice property that is possible due to the chain rule in differentiation and allows us to <em>recycle</em> computations and have a much more efficient learning algorithm. This nice property also tells us that we are indeed incorporating information of deeper layers into layers closer to the input. Let's now proceed to the individual calculation of each partial derivative knowing that we have done some of the work already.</p>
<p>Since <img class="fm-editor-equation" src="assets/83fa979c-2b29-4a23-b18f-1bd464a3a6ac.png" style="width:5.50em;height:2.33em;"/>, then the first term can be expressed as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7ea41332-0f82-4bd3-bdb1-f0fa00ab77b2.png" style="width:24.58em;height:2.58em;"/></p>
<p>In our example, this leads to the following result:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bb58611e-b0c9-45b9-b2fd-97e409c8f584.png" style="width:38.75em;height:5.00em;"/></p>
<p>Now, the second term in the partial derivative can be calculated as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d4314651-4f29-4dcf-9ce7-75532d6d1ce6.png" style="width:43.58em;height:3.75em;"/></p>
<p>This leads to the following vector:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2da31a23-bb5c-43bb-9293-c6b49399ed30.png" style="width:21.42em;height:2.42em;"/></p>
<p>After this, we are now able to calculate the last term, which can be directly computed as follows:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5894600e-742e-4e45-945c-c075eca06b7b.png" style="width:17.33em;height:2.50em;"/></p>
<p class="mce-root"/>
<p class="mce-root">Finally, we can replace the results of the individual partial derivatives into the products of the chain rule:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/74ed95e2-363a-43a8-b0b0-54f5c24ab4b2.png" style="width:53.75em;height:6.25em;"/></p>
<p>This is obtained by rearranging the vectors to obtain a resulting matrix consistent with the weight matrix dimensions, <img class="fm-editor-equation" src="assets/91f5bfed-c333-4cf4-ab43-616158f52c3a.png" style="width:4.92em;height:1.00em;"/>. The multiplications lead to the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4f483e72-8f66-4e58-aa68-e822e281194b.png" style="width:25.33em;height:2.67em;"/></p>
<p>In Python, we do this like so:</p>
<pre>dL_dz2 = dL_do2 * do2_dz2<br/>dz2_do1 = w2<br/>dL_do1 = dL_dz2.dot(dz2_do1.T)<br/>do1_dz1 = sigmoid(o1, grad=True)<br/>dz1_dw1 = X<br/>dL_dw1 = dz1_dw1.T.dot(dL_do1*do1_dz1) + lambda*np.square(w1).sum()</pre>
<p class="mce-root">Lastly, the corresponding <img class="fm-editor-equation" src="assets/0c08586d-1664-4776-adea-550af80cbb2e.png" style="width:1.58em;height:1.00em;"/> update is calculated as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/93769393-a7a5-48b0-bee5-dc4ce5605f54.png" style="width:11.17em;height:2.58em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/39fcb173-a44a-4dbd-8a0e-04dd4175e45e.png" style="width:49.17em;height:5.42em;"/></p>
<p>This concludes the backprop algorithm by assigning <sub><img class="fm-editor-equation" src="assets/c339651e-da7e-44c6-98d5-a09c2c9e7846.png" style="width:9.92em;height:1.25em;"/></sub> at iteration <img class="fm-editor-equation" src="assets/9d9a52b0-eb5f-436e-9623-c6b32f0993b3.png" style="width:0.58em;height:1.25em;"/> (or <em>epoch</em>), which we implement as follows:</p>
<pre>w1 += -alpha*dL_dw1<br/>w2 += -alpha*dL_dw2</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The process repeats for as many epochs as we wish. We could let the algorithm run with the following parameters:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e328a616-4152-4492-9b54-5da84e242069.png" style="width:64.25em;height:5.25em;"/></p>
<p class="mce-root">Then, the resulting separating hyperplane would look like that in the following figure:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/86648a66-1ff6-40fc-9fef-cd5461a595b3.png" style="width:31.25em;height:30.58em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6.5 - Separating the hyperplane of the sample three-neuron MLP</div>
<p>This figure shows that there are many samples that are misclassified, which are depicted as black dots. The total accuracy is 62%. Clearly, three neurons are good enough to produce a classifier better than random chance; however, this is not the best possible outcome. What we must do now is tune-up the classifier by changing the hyperparameters and the number of neurons or layers. This is what we will discuss next.</p>
<p class="mce-root"/>
<h1 id="uuid-c89435ed-4db6-40c1-844d-e5004318f2fe">Finding the best hyperparameters</h1>
<p>There is a simpler way of coding what we coded in the previous section using Keras. We can rely on the fact that the backprop is coded correctly and is improved for stability and there is a richer set of other features and algorithms that can improve the learning process. Before we begin the process of optimizing the set of hyperparameters of the MLP, we should indicate what would be the equivalent implementation using Keras. The following code should reproduce the same model, almost the same loss function, and almost the same backprop methodology:</p>
<pre>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense<br/><br/>mlp = Sequential()<br/>mlp.add(Dense(3, input_dim=2, activation='sigmoid'))<br/>mlp.add(Dense(2, activation='sigmoid'))<br/><br/>mlp.compile(loss='mean_squared_error',<br/>            optimizer='sgd',<br/>            metrics=['accuracy'])<br/><br/># This assumes that you still have X, y from earlier<br/># when we called X, y = twoSpirals(300)<br/>mlp.fit(X, y, epochs=1000, batch_size=60)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>This would produce an error of 62.3% and a decision boundary like the one shown in <em>Figure 6.7</em>: </p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img src="assets/616deaf2-cbe7-4c52-b3b8-d2cc511a89bb.png" style="width:29.92em;height:27.75em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Figure 6.6 – Keras-based MLP for the same model as in <em>Figure 6.5</em></div>
<p>The figure is very similar to <em>Figure 6.6</em>, which is expected since they are the same model. But let's review briefly the meaning of the model described in the code. </p>
<p>As explained before, <kbd>from tensorflow.keras.models import Sequential</kbd> imports the Sequential library, which allows us to create a <em>sequential </em>model as opposed to a <em>functional</em> approach to model creation, <kbd>mlp = Sequential()</kbd>, and it also allows us to add elements to the model, <span><kbd>mlp.add()</kbd>,</span> such as multiple layers of neurons (dense layers): <kbd>Dense(...)</kbd>.</p>
<p>The first layer of the sequential model must specify the dimension of the input (input layer size), which in this case is <kbd>2</kbd>, and the activation function, which is a sigmoid: <kbd>mlp.add(Dense(3, input_dim=2, activation='sigmoid'))</kbd>. In this case, the number <kbd>3</kbd> indicates how many neurons this model <span>will</span><span> </span><span>have in the first hidden layer.</span></p>
<p>The second (and last) layer is similar but denotes the two neurons in the output layer: <kbd>mlp.add(Dense(2, activation='sigmoid'))</kbd>. </p>
<p>Once the sequential model has been specified, we must compile it, <span><kbd>mlp.compile(...)</kbd></span>, defining the loss to be minimized, <kbd><span>loss='mean_squared_error'</span></kbd>, the optimization (backprop) algorithm to be used, <span><kbd>optimizer='sgd'</kbd>, </span>and also a list of what metrics to report after each training epoch, <kbd>metrics=['accuracy']</kbd>. The mean squared loss defined here does not include the regularization term described before, but this should not have a greater impact here; the loss is, therefore, something we have seen before:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/557a0c88-66bc-44cf-bfa2-6e2951d1efe6.png" style="width:9.67em;height:3.25em;"/></p>
<p>The <span><kbd>sgd</kbd> </span><span>optimizer </span><span>defines an algorithm known as </span><strong>stochastic gradient descent</strong><span>. This is a robust way of calculating the gradient and updating the weights accordingly and has been around since the 1950s [Amari, S. I. 1993]. In Keras, it has a default</span> <em>learning rate</em> <span>of</span> <img style="font-size: 1em;width:4.42em;height:1.00em;" class="fm-editor-equation" src="assets/be921a2e-9df9-4a81-8421-690fd18bdd18.png"/><span>; however, this rate has a decay strategy that allows the learning rate to adapt to the learning process.</span></p>
<p>With this in mind, what we will do is vary the following hyperparameters:</p>
<ul>
<li>The learning rate, <img class="fm-editor-equation" src="assets/ca7c445c-d7a6-406b-b680-84ed8102ad32.png" style="width:3.17em;height:1.17em;"/>, is adaptive.</li>
<li><span>The number of layers, between 2, 3, and 4, with 16 neurons each (except the output layer).</span></li>
<li><span>The activation function, either ReLU or sigmoid.</span></li>
</ul>
<p>This can be achieved by running several experiments with cross-validation, as explained before in <a href="7f55e68e-2e9f-486f-9337-5b2ea7bdb504.xhtml">Chapter 4</a>, <em>Learning from Data</em>. The following table shows a comprehensive list of the experiments performed under five-fold cross-validation and the corresponding results:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p><strong>Exp.</strong></p>
</td>
<td>
<p><strong>Hyperparameters</strong></p>
</td>
<td>
<p><strong>Mean Accuracy</strong></p>
</td>
<td>
<p><strong>Std.</strong></p>
</td>
</tr>
<tr>
<td>
<p><kbd>a</kbd></p>
</td>
<td>
<p>(16-Sigmoid, 2-Sigmoid)</p>
</td>
<td>
<p>0.6088</p>
</td>
<td>
<p>0.004</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span>b</span></kbd></p>
</td>
<td>
<p><span>(16-ReLU, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.7125</p>
</td>
<td>
<p>0.038</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span><span>c</span></span></kbd></p>
</td>
<td>
<p><span><span>(16-Sigmoid, </span></span><span>16-Sigmoid, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.6128</p>
</td>
<td>
<p>0.010</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span>d</span></kbd></p>
</td>
<td>
<p><span>(16-ReLU, </span><span>16-Sigmoid, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.7040</p>
</td>
<td>
<p>0.067</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span><span>e</span></span></kbd></p>
</td>
<td>
<p><span><span>(</span></span><span><span>16-Sigmoid, </span></span><span>16-Sigmoid, </span><span>16-Sigmoid, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.6188</p>
</td>
<td>
<p>0.010</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span>f</span></kbd></p>
</td>
<td>
<p><span>(</span><span>16-ReLU, </span><span>16-Sigmoid, </span><span>16-ReLU, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.7895</p>
</td>
<td>
<p>0.113</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span>g</span></kbd></p>
</td>
<td>
<p><span>(</span><span>16-ReLU, </span><span>16-ReLU, </span><span>16-Sigmoid, 2-Sigmoid)</span></p>
</td>
<td>
<p><strong>0.9175</strong></p>
</td>
<td>
<p>0.143</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span>h</span></kbd></p>
</td>
<td>
<p><span>(</span><span>16-ReLU, </span><span>16-ReLU, </span><span>16-ReLU, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.9050</p>
</td>
<td>
<p>0.094</p>
</td>
</tr>
<tr>
<td>
<p><kbd><span>i</span></kbd></p>
</td>
<td>
<p><span>(</span><span>16-ReLU, </span><span>16-Sigmoid, </span><span><span>16-</span></span><span>Sigmoid, 2-Sigmoid)</span></p>
</td>
<td>
<p>0.6608</p>
</td>
<td>
<p>0.073</p>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Note that other experiments were performed with an additional fifth layer, but the results were not much better in terms of average performance and variability. It appears that four layers with as little as 16 neurons in each layer (except the output layer, with 2) are sufficient to produce adequate class separation. <em>Figure 6.8</em> shows a sample run from experiment <kbd>g</kbd>, which achieved the highest performance with 99% accuracy:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img src="assets/ec897d46-8327-46cb-8928-07f4081803f9.png" style="width:32.00em;height:30.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Figure 6.7 – Classification boundaries for the two-spirals dataset using a four-layered (16,16,16,2) neural network. Corresponds to experiment g in Table 1</div>
<p>A visual inspection of <em>Figure 6.8</em> reveals that the largest margin of confusion is in the center area where the spirals originate and are very close to each other. Notice also that the separating hyperplane seems to be non-smooth in some areas, which is typical of the MLP. Some suggest that this phenomenon is due to the fact that neurons in the input layer are using a linear function to approximate a function, and deeper layers are mixtures of linear functions that produce non-linear functions based on such linear functions. Of course, it is much more complicated than that, but it is interesting to note here.</p>
<p class="mce-root"/>
<p>Before we conclude this chapter, note that there are other hyperparameters that we could have optimized empirically. We could have chosen different optimizers, such as <kbd>adam</kbd> or <kbd>rmsprop</kbd>; we could have tried other activation functions such as <kbd>tanh</kbd>, or <kbd>softmax</kbd>; we could have tried more layers; or we could have tried more (or less) and different numbers of neurons in increasing, decreasing, or mixed order. However, for now, these experiments are sufficient to make the point that experimentation with different things is key in finding what works best for us in our particular application or the problem we are trying to solve.</p>
<p>This concludes our introductory chapters, and the coming ones will look at specific types of architecture that have a specific purpose, as opposed to the MLP, which is usually considered a multipurpose, fundamental neural network. Our next chapter will deal with autoencoders; they can be seen as a special type of neural network aiming to encode input data into a smaller dimensional space and then reconstructing it back to the original input space, minimizing the loss of information in the reconstructed data. An autoencoder allows us to compress data, and learn from the data without the label associated with it. The latter makes the autoencoder a special kind of neural network that learns using what is categorized as <strong>unsupervised learning</strong><em>.</em> </p>
<h1 id="uuid-9e33de1f-ac2b-4a75-912b-12d76036395e">Summary </h1>
<p>This intermediate-introductory chapter showed the design of an MLP and the paradigms surrounding its functionality. We covered the theoretical framework behind its elements and we had a full discussion and treatment of the widely known backprop mechanism to perform gradient descent on a loss function. Understanding the backprop algorithm is key for further chapters since some models are designed specifically to overcome some potential difficulties with backprop. You should feel confident that what you have learned about backprop will serve you well in knowing what deep learning is all about. This backprop algorithm, among other things, is what makes deep learning an exciting area. Now, you should be able to understand and design your own MLP with different layers and different neurons. Furthermore, you should feel confident in changing some of its parameters, although we will cover more of this in the further reading.</p>
<p><a href="480521d9-845c-4c0a-b82b-be5f15da0171.xhtml">Chapter 7</a>, <em>Autoencoders,</em><span> will continue with an architecture very similar to the MLP that is widely used today for many different learning tasks associated with learning representations of data</span>. This chapter begins a new part that is dedicated to <em>unsupervised</em> <em>learning</em> algorithms and models based on the type of learning where you can learn from data even if it is not labeled.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<h1 id="uuid-fe837106-8f3c-40f5-a2cd-63b75668c8bf">Questions and answers</h1>
<ol>
<li><strong>Why is the MLP better than the perceptron model?</strong></li>
</ol>
<p style="padding-left: 60px">The larger number and layers of neurons give the MLP the advantage over the perceptron to model non-linear problems and solve much more complicated pattern recognition problems.</p>
<ol start="2">
<li><strong>Why is backpropagation so important to know about? </strong></li>
</ol>
<p style="padding-left: 60px">Because it is what makes neural networks learn in the era of big data.</p>
<ol start="3">
<li><strong>Does the MLP always converge?</strong></li>
</ol>
<p style="padding-left: 60px">Yes and no. It does always converge to a local minimum in terms of the loss function; however, it is not guaranteed to converge to a global minimum since, usually, most loss functions are non-convex and non-smooth.</p>
<ol start="4">
<li><strong>Why should we try to optimize the hyperparameters of our models?</strong></li>
</ol>
<p style="padding-left: 60px">Because anyone can train a simple neural network; however, not everyone knows what things to change to make it better. The success of your model depends heavily on you trying different things and proving to yourself (and others) that your model is the best that it can be. This is what will make you a better learner and a better deep learning professional.</p>
<h1 id="uuid-af9d2781-e758-49bd-9790-04e17d2cb626">References</h1>
<ul>
<li><span>Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. </span><em>Psychological Review</em><span>, </span><span>65</span><span>(6), 386.</span></li>
<li>Tappert, C. C. (2019). Who is the Father of Deep Learning? <em>Symposium on Artificial Intelligence.</em></li>
<li>Hinton, G. E. (1990). Connectionist learning procedures. <em>Machine learning</em>. Morgan Kaufmann, 555-610.</li>
<li>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. <em>Nature</em>, 323(6088), 533-536.</li>
<li>Florez, O. U. (2017). One LEGO at a time: Explaining the Math of How Neural Networks Learn. <em>Online</em>: <a href="https://omar-florez.github.io/scratch_mlp/">https://omar-florez.github.io/scratch_mlp/</a>.</li>
<li>Amari, S. I. (1993). Backpropagation and stochastic gradient descent method. <em>Neurocomputing</em>, 5(4-5), 185-196.</li>
</ul>


            </article>

            
        </section>
    </body></html>