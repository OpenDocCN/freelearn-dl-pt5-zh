["```py\nX = tf.Variable([[0.,0.],[0.,1.],\\\n                 [1.,0.],[1.,1.]], \\\n                 tf.float32)\ny = tf.Variable([0, 1, 1, 1], tf.float32)\n```", "```py\nnumber_of_features = x.shape[1]\nnumber_of_units = 1\nWeight = tf.Variable(tf.zeros([number_of_features, \\\n                               number_of_units]), \\\n                               tf.float32)\n```", "```py\nB = tf.Variable(tf.zeros([1, 1]), tf.float32)\n```", "```py\nz = tf.add(tf.matmul(X, W), B)\n```", "```py\noutput = tf.sigmoid(z)\n```", "```py\ndef perceptron(X):\n    z = tf.add(tf.matmul(X, W), B)\n    output = tf.sigmoid(z)\n    return output\n```", "```py\nz = tf.add(tf.matmul(X, W), B)\n```", "```py\nm = tf.matmul(X, W)\n```", "```py\nm = x1*w1 + x2*w2\n```", "```py\nz = tf.add(m, B)\n```", "```py\nm + b\n```", "```py\nz = x1*w1 + x2*w2 + b\n```", "```py\noutput= tf.sigmoid(z)\n```", "```py\n    import tensorflow as tf\n    ```", "```py\n    X = tf.Variable([[0.,0.],[0.,1.],\\\n                     [1.,0.],[1.,1.]], \\\n                     dtype=tf.float32)\n    print(X)\n    ```", "```py\n    <tf.Variable 'Variable:0' shape=(4, 2) dtype=float32, \n    numpy=array([[0., 0.],\n                 [0., 1.],\n                 [1., 0.],\n                 [1., 1.]], dtype=float32)>\n    ```", "```py\n    y = tf.Variable([0, 1, 1, 1], dtype=tf.float32)\n    y = tf.reshape(y, [4,1])\n    print(y)\n    ```", "```py\n    tf.Tensor(\n    [[0.]\n     [1.]\n     [1.]\n     [1.]], shape=(4, 1), dtype=float32)\n    ```", "```py\n    NUM_FEATURES = X.shape[1]\n    OUTPUT_SIZE = 1\n    ```", "```py\n    W = tf.Variable(tf.zeros([NUM_FEATURES, \\\n                              OUTPUT_SIZE]), \\\n                              dtype=tf.float32)\n    print(W)\n    ```", "```py\n    <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, \\\n    numpy=array([[0.], [0.]], dtype=float32)>\n    ```", "```py\n    B = tf.Variable(tf.zeros([OUTPUT_SIZE, 1]), dtype=tf.float32)\n    print(B)\n    ```", "```py\n    <tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, \n    numpy=array([[0.]], dtype=float32)>\n    ```", "```py\n    def perceptron(X):\n        z = tf.add(tf.matmul(X, W), B)\n        output = tf.sigmoid(z)\n        return output\n    print(perceptron(X))\n    ```", "```py\n    tf.Tensor(\n    [[0.5]\n     [0.5]\n     [0.5]\n     [0.5]], shape=(4, 1), dtype=float32)\n    ```", "```py\ntf.Tensor(\n[[0.5]\n [0.5]\n [0.5]\n [0.5]], shape=(4, 1), dtype=float32)\n```", "```py\nlearning_rate = 0.01\noptimizer = tf.optimizers.SGD(learning_rate)\n```", "```py\nno_of_epochs = 1000\nfor n in range(no_of_epochs):\n    loss = lambda:abs(tf.reduce_mean(tf.nn.\\\n           sigmoid_cross_entropy_with_logits\\\n           (labels=y,logits=perceptron(X))))\n    optimizer.minimize(loss, [W, B])\n```", "```py\n[[0.412449151]\n[0.412449151]]\n```", "```py\n0.236065879\n```", "```py\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y, ypred))\n```", "```py\n    import tensorflow as tf\n    import pandas as pd\n    from sklearn.metrics import confusion_matrix\n    from sklearn.metrics import accuracy_score\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    ```", "```py\n    df = pd.read_csv('data.csv')\n    ```", "```py\n    df.head()\n    ```", "```py\n    plt.scatter(df[df['label'] == 0]['x1'], \\\n                df[df['label'] == 0]['x2'], \\\n                marker='*')\n    plt.scatter(df[df['label'] == 1]['x1'], \\\n                df[df['label'] == 1]['x2'], marker='<')\n    ```", "```py\n    X_input = df[['x1','x2']].values\n    y_label = df[['label']].values\n    ```", "```py\n    x = tf.Variable(X_input, dtype=tf.float32)\n    y = tf.Variable(y_label, dtype=tf.float32)\n    ```", "```py\n    Exercise2.02.ipynb\n    Number_of_features = 2\n    Number_of_units = 1\n    learning_rate = 0.01\n    # weights and bias\n    weight = tf.Variable(tf.zeros([Number_of_features, \\\n                                   Number_of_units]))\n    bias = tf.Variable(tf.zeros([Number_of_units]))\n    #optimizer\n    optimizer = tf.optimizers.SGD(learning_rate)\n    def perceptron(x):\n        z = tf.add(tf.matmul(x,weight),bias)\n        output = tf.sigmoid(z)\n        return output\n    The complete code for this step can be found at https://packt.live/3gJ73bY.\n    ```", "```py\n    tf.print(weight, bias)\n    ```", "```py\n    [[-0.844034135]\n     [0.673354745]] [0.0593947917]\n    ```", "```py\n    ypred = perceptron(x)\n    ```", "```py\n    ypred = tf.round(ypred)\n    ```", "```py\n    acc = accuracy_score(y.numpy(), ypred.numpy())\n    print(acc)\n    ```", "```py\n    1.0\n    ```", "```py\n    cnf_matrix = confusion_matrix(y.numpy(), \\\n                                  ypred.numpy())\n    print(cnf_matrix)\n    ```", "```py\n    [[12  0]\n    [ 0  9]]\n    ```", "```py\nvalues = tf.Variable([3,1,7,2,4,5], dtype=tf.float32)\noutput = tf.nn.softmax(values)\ntf.print(output)\n```", "```py\n[0.0151037546 0.00204407098 0.824637055 \n 0.00555636082 0.0410562605 0.111602485]\n```", "```py\n    import tensorflow as tf\n    import pandas as pd\n    from sklearn.metrics import confusion_matrix\n    from sklearn.metrics import accuracy_score\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    from pandas import get_dummies\n    ```", "```py\n    df = pd.read_csv('iris.csv')\n    ```", "```py\n    df.head()\n    ```", "```py\n    plt.scatter(df[df['species'] == 0]['sepallength'],\\\n                df[df['species'] == 0]['sepalwidth'], marker='*')\n    plt.scatter(df[df['species'] == 1]['sepallength'],\\\n                df[df['species'] == 1]['sepalwidth'], marker='<')\n    plt.scatter(df[df['species'] == 2]['sepallength'], \\\n                df[df['species'] == 2]['sepalwidth'], marker='o')\n    ```", "```py\n    x = df[['petallength', 'petalwidth', \\\n            'sepallength', 'sepalwidth']].values\n    y = df['species'].values\n    ```", "```py\n    y = get_dummies(y)\n    y = y.values\n    ```", "```py\n    x = tf.Variable(x, dtype=tf.float32)\n    ```", "```py\n    Number_of_features = 4\n    Number_of_units = 3 \n\n    # weights and bias\n    weight = tf.Variable(tf.zeros([Number_of_features, \\\n                                   Number_of_units]))\n    bias = tf.Variable(tf.zeros([Number_of_units]))   \n    def perceptron(x):\n        z = tf.add(tf.matmul(x, weight), bias)\n        output = tf.nn.softmax(z)\n        return output\n    ```", "```py\n    optimizer = tf.optimizers.Adam(.01)\n    ```", "```py\n    def train(i):\n        for n in range(i):\n            loss=lambda: abs(tf.reduce_mean\\\n                            (tf.nn.softmax_cross_entropy_with_logits(\\\n                             labels=y, logits=perceptron(x))))\n            optimizer.minimize(loss, [weight, bias])\n    ```", "```py\n    train(1000)\n    ```", "```py\n    tf.print(weight) \n    ```", "```py\n    [[0.684310317 0.895633 -1.0132345]\n     [2.6424644 -1.13437736 -3.20665336]\n     [-2.96634197 -0.129377216 3.2572844]\n     [-2.97383809 -3.13501668 3.2313652]]\n    ```", "```py\n    ypred=perceptron(x)\n    ypred=tf.round(ypred)\n    accuracy_score(y, ypred)\n    ```", "```py\n    0.98\n    ```", "```py\n    import tensorflow as tf\n    import pandas as pd\n    from sklearn.metrics import accuracy_score\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    from pandas import get_dummies\n    ```", "```py\n    mnist = tf.keras.datasets.mnist\n    ```", "```py\n    (train_features, train_labels), (test_features, test_labels) = \\\n    mnist.load_data()\n    ```", "```py\n    train_features, test_features = train_features / 255.0, \\\n                                    test_features / 255.0\n    ```", "```py\n    x = tf.reshape(train_features,[60000, 784])\n    ```", "```py\n    x = tf.Variable(x)\n    x = tf.cast(x, tf.float32)\n    ```", "```py\n    y_hot = get_dummies(train_labels)\n    y = y_hot.values\n    ```", "```py\n    Exercise2.04.ipynb\n    #defining the parameters\n    Number_of_features = 784\n    Number_of_units = 10  \n    # weights and bias\n    weight = tf.Variable(tf.zeros([Number_of_features, \\\n                                   Number_of_units]))\n    bias = tf.Variable(tf.zeros([Number_of_units]))\n    The complete code for this step can be accessed from https://packt.live/3efd7Yh.\n    ```", "```py\n    # Prepare the test data to measure the accuracy. \n    test = tf.reshape(test_features, [10000, 784])\n    test = tf.Variable(test)\n    test = tf.cast(test, tf.float32)\n    test_hot = get_dummies(test_labels)\n    test_matrix = test_hot.values\n    ```", "```py\n    ypred = perceptron(test)\n    ypred = tf.round(ypred)\n    ```", "```py\n    accuracy_score(test_hot, ypred)\n    ```", "```py\n    0.9304\n    ```", "```py\n    import tensorflow as tf\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    # Import Keras libraries\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense\n    ```", "```py\n    df = pd.read_csv('data.csv')\n    ```", "```py\n    df.head()\n    ```", "```py\n    plt.scatter(df[df['label'] == 0]['x1'], \\\n                df[df['label'] == 0]['x2'], marker='*')\n    plt.scatter(df[df['label'] == 1]['x1'], \\\n                df[df['label'] == 1]['x2'], marker='<')\n    ```", "```py\n    x_input = df[['x1','x2']].values\n    y_label = df[['label']].values\n    ```", "```py\n    model = Sequential()\n    model.add(Dense(units=1, input_dim=2, activation='sigmoid'))\n    ```", "```py\n    model.compile(optimizer='adam', \\\n                  loss='binary_crossentropy',\\\n                  metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(x_input, y_label, epochs=1000)\n    ```", "```py\n    model.evaluate(x_input, y_label)\n    ```", "```py\n    21/21 [==============================] - 0s 611us/sample - loss:  0.2442 - accuracy: 1.0000\n    [0.24421504139900208, 1.0]\n    ```", "```py\nvalues = tf.Variable([1.0, -2., 0., 0.3, -1.5], dtype=tf.float32)\noutput = tf.nn.relu(values)\ntf.print(output)\n```", "```py\n[1 0 0 0.3 0]\n```", "```py\n    import tensorflow as tf\n    import pandas as pd \n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    ##Import Keras libraries\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense\n    ```", "```py\n    df = pd.read_csv('data.csv')\n    df.head()\n    ```", "```py\n    plt.scatter(df[df['label'] == 0]['x1'], \\\n                df[df['label'] == 0]['x2'], marker='*')\n    plt.scatter(df[df['label'] == 1]['x1'], \\\n                df[df['label'] == 1]['x2'], marker='<')\n    ```", "```py\n    x_input = df[['x1','x2']].values\n    y_label = df[['label']].values\n    ```", "```py\n    model = Sequential()\n    model.add(Dense(units = 50,input_dim=2, activation = 'relu'))\n    model.add(Dense(units = 20 , activation = 'relu'))\n    model.add(Dense(units = 1,input_dim=2, activation = 'sigmoid'))\n    ```", "```py\n    model.compile(optimizer='adam', \\\n                  loss='binary_crossentropy', metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(x_input, y_label, epochs=50)\n    ```", "```py\n    model.evaluate(x_input, y_label)\n    ```", "```py\n    21/21 [==============================] - 0s 6ms/sample - loss:   0.1038 - accuracy: 1.0000\n    [0.1037961095571518, 1.0]\n    ```", "```py\n    import tensorflow as tf\n    import pandas as pd \n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    # Import Keras libraries\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense\n    from tensorflow.keras.layers import Flatten\n    ```", "```py\n    mnist = tf.keras.datasets.mnist\n    (train_features,train_labels), (test_features,test_labels) = \\\n    mnist.load_data()\n    ```", "```py\n    train_features, test_features = train_features / 255.0, \\\n                                    test_features / 255.0\n    ```", "```py\n    model = Sequential()\n    model.add(Flatten(input_shape=(28,28)))\n    model.add(Dense(units = 50, activation = 'relu'))\n    model.add(Dense(units = 20 , activation = 'relu'))\n    model.add(Dense(units = 10, activation = 'softmax'))\n    ```", "```py\n    model.compile(optimizer = 'adam', \\\n                  loss = 'sparse_categorical_crossentropy', \\\n                  metrics = ['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(train_features, train_labels, epochs=50)\n    ```", "```py\n    model.evaluate(test_features, test_labels)\n    ```", "```py\n    10000/10000 [==============================] - 1s 76us/sample - loss:   0.2072 - accuracy: 0.9718\n    [0.20719025060918111, 0.9718]\n    ```", "```py\n    loc = 200\n    test_image = test_features[loc]\n    ```", "```py\n    test_image.shape\n    ```", "```py\n    (28,28)\n    ```", "```py\n    test_image = test_image.reshape(1,28,28)\n    ```", "```py\n    result = model.predict(test_image)\n    print(result)\n    ```", "```py\n    [[2.9072076e-28 2.1215850e-29 1.7854708e-21 \n      1.0000000e+00 0.0000000e+00 1.2384960e-15 \n      1.2660366e-34 1.7712217e-32 1.7461657e-08 \n      9.6417470e-29]]\n    ```", "```py\n    result.argmax()\n    ```", "```py\n    3\n    ```", "```py\n    test_labels[loc]\n    ```", "```py\n    3\n    ```", "```py\n    plt.imshow(test_features[loc])\n    ```", "```py\nmodel.add(Dense(units = 300, activation = 'relu')) #Hidden layer1\nmodel.add(Dense(units = 200, activation = 'relu')) #Hidden Layer2\nmodel.add(Dropout(.20))\nmodel.add(Dense(units = 100, activation = 'relu')) #Hidden Layer3\n```"]