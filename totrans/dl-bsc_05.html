<html><head></head><body>
		<div>
			<div id="_idContainer103" class="Content">
			</div>
		</div>
		<div id="_idContainer104" class="Content">
			<h1 id="_idParaDest-92"><a id="_idTextAnchor094"/>4. Neural Network Training</h1>
		</div>
		<div id="_idContainer150" class="Content">
			<p>This chapter describes neural network training. When we talk about "training" in this context, we mean obtaining the optimal weight parameters automatically from training data. In this chapter, we will introduce a criterion called a loss function; this enables a neural network to learn. The purpose of training is to discover the weight parameters that lead to the smallest value of the loss function. In this chapter, we will be introduced to the method of using the gradient of a function, called a gradient method, to discover the smallest loss function value.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor095"/>Learning from Data</h2>
			<p>The essential characteristic of a neural network is its ability to learn from data. Training from data means that weight parameter values can be automatically determined. If you have to determine all the parameters manually, it is quite hard work. For example, for a sample perceptron, as shown in <em class="italics">Chapter 2</em>, <em class="italics">Perceptrons</em>, we determined the parameter values manually while looking at the truth table. There are as few as three parameters. However, in an actual neural network, the number of parameters can range between thousands and tens of thousands. For deep learning with more layers, the number of parameters may reach hundreds of millions. It is almost impossible to determine them manually. This chapter describes neural network training, or how to determine parameter values from data, and implements a model that learns handwritten digits from the MNIST dataset with Python.</p>
			<h4>Note</h4>
			<p class="callout">For a linearly separable problem, a perceptron can learn automatically from data. That training, when completed a finite number of times, can solve a linearly separable problem, which is known as "the perceptron convergence theorem." On the other hand, a nonlinear separation problem cannot be solved (automatically).</p>
			<h3 id="_idParaDest-94"><a id="_idTextAnchor096"/>Data-Driven</h3>
			<p>Data is critical in machine learning. Machine learning looks for an answer in the data, finds a pattern in the data, and tells a story based on it. It can do nothing without data. Therefore, "data" exists at the center of machine learning. We can say that this data-driven approach is a departure from a "man"-centered approach.</p>
			<p>Usually, when we solve a problem—especially when we need to find a pattern—we must consider various things to find an answer. "This problem seems to have this pattern." "No, there may be a cause somewhere else." Based on our experience and intuition, we advance this task through trial and error. Machine learning avoids human intervention as much as possible. It tries to find an answer (pattern) from the collected data. Moreover, a neural network and deep learning have an important characteristic in common in that they can avoid human intervention more than traditional machine learning.</p>
			<p>Let's look at a specific problem here. Suppose that we want to implement a program that recognizes the number "5", for example. Let's suppose that our goal is implementing the program that determines whether handwritten images, as shown in <em class="italics">Figure 4.1</em>, are "5" or not "5". This problem seems relatively simple. What algorithm can we use?</p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/fig04_1.jpg" alt="Figure 4.1: Sample handwritten digits – how &quot;5&quot; is written varies from person to person&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.1: Sample handwritten digits – how "5" is written varies from person to person</h6>
			<p>When you try to design a program that can classify "5" correctly, you will find that it is a more difficult problem than expected. We can easily recognize "5", but it is difficult to clarify the rule for recognizing an image as "5". As shown in <em class="italics">Figure 4.1</em>, how it is written differs from person to person. This tells us that finding the rule for recognizing "5" will be hard work and that it may take a lot of time.</p>
			<p>Now, instead of "working out" the algorithm that recognizes "5" from scratch, we want to use data effectively to solve the problem. One of the methods we can use is to extract features from an image and use machine learning technology to learn the pattern of the features. A feature indicates a converter that is designed to extract essential data (important data) from input data (input image) accurately. The feature of an image is usually described as a vector. Famous features in the field of computer vision include SIFT, SURF, and HOG. You can use these features to convert image data into vectors and use a classifier in machine learning, such as SVM and KNN, to learn the converted vectors.</p>
			<p>In this machine learning approach, a "machine" discovers a pattern from the collected data. This can solve a problem more efficiently and reduce the burden on a "person" compared to when we invent an algorithm from scratch. However, we must note that the features that are used when images are converted into vectors are designed by a "man." This is because good results cannot be obtained without using features that are suitable for the problem (or without designing the features). For example, to recognize the face of a dog, a person may need to select the features that are different from those for recognizing "5". After all, even the approach of using features and machine learning may need suitable features to be selected by a "man," depending on the problem.</p>
			<p>So far, we have discussed two approaches to machine learning problems. These two approaches are shown in the upper rows in <em class="italics">Figure 4.2</em>. Meanwhile, the approach to using a neural network (deep learning) is shown in the lower row of <em class="italics">Figure 4.2</em>. It is represented by a block without human intervention.</p>
			<p>As shown in <em class="italics">Figure 4.2</em>, a neural network learns images "as they are." In the second approach, an example that uses features and machine learning, called human-designed features, are used, while in a neural network, a "machine" learns important features from images:</p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/fig04_2.jpg" alt="Figure 4.2: A paradigm shift from man-made rules to a &quot;machine&quot; learning from data – &#13;&#10;a block without human intervention is shown in gray&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.2: A paradigm shift from man-made rules to a "machine" learning from data – a block without human intervention is shown in gray</h6>
			<h4>Note</h4>
			<p class="callout">Deep learning is sometimes called "end-to-end machine learning." "<strong class="bold">End-to-end</strong>" means "from one end to the other end," that is, the acquisition of the desired result (output) from raw data (input).</p>
			<p>The advantage of a neural network is that it can solve all the problems in the same flow; for example, whether trying to recognize "5", a dog, or a human face, a neural network learns the provided data patiently, trying to discover a pattern in the given problem. A neural network can learn data as it is "end-to-end," regardless of the problem to solve.</p>
			<h3 id="_idParaDest-95"><a id="_idTextAnchor097"/>Training Data and Test Data</h3>
			<p>In this chapter, we will cover neural network training, beginning with some best practices when handling data in machine learning.</p>
			<p>In machine learning problems, we usually use <strong class="bold">training data</strong> and <strong class="bold">test data</strong> according to the purpose. First, we use only training data to find optimal parameters. Then, we use test data to evaluate the ability of the trained model. Why should we divide training data and test data? Because we want the generalization capability of the model. We must separate the training data and test data because we want to evaluate this <strong class="bold">generalization</strong> correctly. </p>
			<p>Generalization means the ability of unknown data (data that is not contained in the training data), and the ultimate goal of machine learning is to obtain this generalization. For example, handwritten digit recognition may be used in a system for reading postal codes on postcards automatically. In that case, handwritten digit recognition must be able to recognize the characters written by "someone." That "someone" is not "a specific character written by a specific person," but "an arbitrary character is written by an arbitrary person." Even if the model can distinguish only your training data well, it may have learned only specific characters of the person's handwriting contained in the data.</p>
			<p>Therefore, if you use only one dataset to learn parameters and evaluate them, the correct evaluation will not be provided. This results in a model that can handle a certain dataset well but cannot handle another one. When a model has become too adapted to only one dataset, <strong class="bold">overfitting</strong> occurs. Avoiding overfitting is an important challenge in machine learning.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor098"/>Loss Function</h2>
			<p>How do you answer when you are asked, "How happy are you now?". We may usually answer vaguely: "I am moderately happy" or "I am not very happy." You may be surprised if someone answers, "My current happiness score is 10.23" because the person can only quantify their happiness with one score. If such a person exists, the person may lead their life only based on their "happiness score."</p>
			<p>This "happiness score" is an allegory used to illustrate some similar things which occur in neural network training. In neural network training, one "score" is used to indicate the current status. Based on the score, optimal weight parameters are searched for. As this person looks for an "optimal life" based on the "happiness score," a neural network searches for optimal parameters using "one score" as a guide. The score that's used in neural network training is called a <strong class="bold">loss function</strong>. Although any function can be used as the loss function, the sum of squared errors or a cross-entropy error is usually used.</p>
			<h4>Note</h4>
			<p class="callout">A loss function is an index that indicates the "poorness" of a neural network's ability. It indicates how unfit the current neural network is for labeled data and how it deviates from labeled data. You may feel that it's unnatural for the "poorness of ability" to be the score, but you can interpret the loss function multiplied by a negative value as the score of the opposite of "how poor the ability is" (that is, the score of "how good the ability is"). "To minimize poorness of ability" is the same as "to maximize the goodness of ability." Therefore, the index of the "poorness" of ability is essentially the same as that of the "goodness" of ability.</p>
			<h3 id="_idParaDest-97"><a id="_idTextAnchor099"/>Sum of Squared Errors</h3>
			<p>There are a few functions that are used as loss functions. Probably the most famous one is the <strong class="bold">sum of squared errors</strong>. It is expressed by the following equation:</p>
			<table id="table001-2" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style CellOverride-1">
							<div>
								<div id="_idContainer107">
									<img src="image/Figure_4.2a.png" alt="18"/>
								</div>
							</div>
						</td>
						<td class="No-Table-Style">
							<p>(4.1)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>Here, <em class="italics">y</em><span class="P---Subscript">k</span> is the output of the neural network, <em class="italics">t</em><span class="P---Subscript">k</span> is labeled data, and <em class="italics">k</em> is the number of dimensions of the data. For example, in the section, <em class="italics">Handwritten Digit Recognition</em>, of <em class="italics">Chapter 3</em>, <em class="italics">Neural networks</em>, <em class="italics">y</em><span class="P---Subscript">k,</span> and <em class="italics">t</em><span class="P---Subscript">k</span> are data items that consist of 10 elements:</p>
			<p class="source-code">&gt;&gt;&gt; y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]</p>
			<p class="source-code">&gt;&gt;&gt; t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</p>
			<p>The elements of these arrays correspond to numbers "0," "1," "2," ... in order from the first index. Here, the output of the neural network, y, is the output of a softmax function. The output of the softmax function can be interpreted as a probability. In this example, the probability of "0" is 0.1, that of "1" is 0.05, that of "2" is 0.6, and so on. Meanwhile, t is labeled data. In the labeled data, the correct label is 1 and the other labels are 0. Here, label "2" is 1, which indicates that the correct answer is "2." Setting 1 for the correct label and 0 for other labels is called <strong class="bold">one-hot representation</strong>.</p>
			<p>As shown in equation (4.1), the sum of squared errors is the sum of the squares of the differences between the outputs of the neural network and the corresponding elements of the correct teacher data. Now, let's implement the sum of squared errors in Python. You can implement it as follows:</p>
			<p class="source-code">def sum_squared_error(y,  t):</p>
			<p class="source-code">    return 0.5 * np.sum((y-t)**2)</p>
			<p>Here, the <strong class="inline">y</strong> and <strong class="inline">t</strong> arguments are NumPy arrays. Because this simply implements equation (4.1), we won't explain this here. Now, we will use this function to perform a calculation:</p>
			<p class="source-code">&gt;&gt;&gt; # Assume that "2" is correct</p>
			<p class="source-code">&gt;&gt;&gt; t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</p>
			<p class="source-code">&gt;&gt;&gt;</p>
			<p class="source-code">&gt;&gt;&gt;  #  Example 1: "2" is the most probable (0.6)</p>
			<p class="source-code">&gt;&gt;&gt; y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]</p>
			<p class="source-code">&gt;&gt;&gt; sum_squared_error(np.array(y), np.array(t))</p>
			<p class="source-code">0.097500000000000031</p>
			<p class="source-code">&gt;&gt;&gt;</p>
			<p class="source-code">&gt;&gt;&gt;  #  Example 2: "7" is the most probable (0.6)</p>
			<p class="source-code">&gt;&gt;&gt; y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]</p>
			<p class="source-code">&gt;&gt;&gt; sum_squared_error(np.array(y), np.array(t))</p>
			<p class="source-code">0.59750000000000003</p>
			<p>There are two examples here. In the first one, the correct answer is "2", and the output of the neural network is the largest at "2." Meanwhile, in the second one, the correct answer is "2," but the output of the neural network is the largest at "7." As the result of this experiment shows, the loss function of the first example is smaller, which indicates that the difference in the labeled data is smaller. In other words, the sum of squared errors indicates that the output in the first example fits the labeled data better.</p>
			<h3 id="_idParaDest-98"><a id="_idTextAnchor100"/>Cross-Entropy Error</h3>
			<p>Other than the sum of squared errors, a <strong class="bold">cross-entropy error</strong> is also often used as a loss function. It is expressed by the following equation:</p>
			<table id="table002-2" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style CellOverride-1">
							<div>
								<div id="_idContainer108">
									<img src="image/Figure_4.2b.png" alt="19"/>
								</div>
							</div>
						</td>
						<td class="No-Table-Style">
							<p>(4.2)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>Here, log indicates the natural logarithm, that is, the logarithm to the base of <em class="italics">e (log</em><span class="P---Subscript">e</span><em class="italics">)</em>. yk is the output of the neural network and tk is the correct label. In tk, only the index for the correct label is 1; the other indices are 0 (one-hot representation). Therefore, equation (4.2) only calculates the logarithm of the output that corresponds to the correct label, 1. For example, if "2" is the index of the correct label, and the corresponding output from the neural network is 0.6, a cross-entropy error is <strong class="inline">-log 0.6 = 0.51</strong>. If the output for "2" is 0.1, the error is <strong class="inline">-log 0.1 = 2.30</strong>. A cross-entropy error depends on the output result from the correct label. <em class="italics">Figure 4.3</em> shows the graph of this natural logarithm:</p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/fig04_3.jpg" alt="Figure 4.3: Graph of the natural logarithm y = log x&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.3: Graph of the natural logarithm y = log x</h6>
			<p>As shown in <em class="italics">Figure 4.3</em>, <em class="italics">y</em> is 0 when <em class="italics">x</em> is 1, and the value of <em class="italics">y</em> is getting smaller as <em class="italics">x</em> approaches 0. Therefore, since the output corresponding to the correct label is larger, equation (4.2) approaches 0. When the output is 1, the cross-entropy error becomes 0. When the output corresponding to the correct label is smaller, the value of equation (4.2) is larger.</p>
			<p>Now, let's implement a cross-entropy error:</p>
			<p class="source-code">def cross_entropy_error(y, t):</p>
			<p class="source-code">    delta = 1e-7</p>
			<p class="source-code">    return -np.sum(t * np.log(y + delta))</p>
			<p>Here, the y and t arguments are NumPy arrays. When <strong class="inline">np.log</strong> is calculated, a very small value, delta, is added. If <strong class="inline">np.log(0)</strong> is calculated, <strong class="inline">-inf</strong>, which indicates minus infinity, is returned. At this point, the calculation cannot be advanced further. To avoid this, a very small value is added so that minus infinity does not occur. Now, let's use <strong class="inline">cross_entropy_error(y, t)</strong> for ease of calculation:</p>
			<p class="source-code">&gt;&gt;&gt; t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</p>
			<p class="source-code">&gt;&gt;&gt; y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]</p>
			<p class="source-code">&gt;&gt;&gt; cross_entropy_error(np.array(y), np.array(t))</p>
			<p class="source-code">0.51082545709933802</p>
			<p class="source-code">&gt;&gt;&gt;</p>
			<p class="source-code">&gt;&gt;&gt; y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]</p>
			<p class="source-code">&gt;&gt;&gt; cross_entropy_error(np.array(y), np.array(t))</p>
			<p class="source-code">2.3025840929945458</p>
			<p>In the first example, the output of the correct label is 0.6 and the cross-entropy error is 0.51. In the next example, the output of the correct label is as small as 0.1 and the cross-entropy error is 2.3. These results are consistent with what we've discussed so far.</p>
			<h3 id="_idParaDest-99"><a id="_idTextAnchor101"/>Mini-Batch Learning</h3>
			<p>For a machine learning problem, training data is used for training. To be precise, it means finding the loss function for the training data and finding the parameters that make that value as small as possible. Therefore, all the training data must be used to obtain the loss function. If there are 100 pieces of training data, the sum of their 100 loss functions must be used as the index.</p>
			<p>In the example of the loss function we described earlier, the loss function for one piece of data was used. For a cross-entropy error, equation (4.3) can calculate the sum of the loss functions for all training data:</p>
			<table id="table003-2" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style CellOverride-1">
							<div>
								<div id="_idContainer110">
									<img src="image/Figure_4.3a.png" alt="20"/>
								</div>
							</div>
						</td>
						<td class="No-Table-Style">
							<p>(4.3)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>Suppose that the number of data elements is N. t<span class="P---Subscript">nk</span> means the k-<span class="P---Superscript">th</span> value of the n-<span class="P---Superscript">th</span> data (y<span class="P---Subscript">nk</span> is the output of the neural network, and t<span class="P---Subscript">nk</span> is labeled data). Although this equation seems a little complicated, it is only an extension of equation (4.2), which expresses the loss function for one piece of data for N items of data. In the end, it is divided by <strong class="inline">N</strong> for normalization. Division by N calculates the "average loss function" per data. The average can be used as a consistent index, regardless of the amount of training data. For example, even when the number of training data elements is 1,000 or 10,000, you can calculate the average loss function per data element.</p>
			<p>The MNIST dataset contains 60,000 items of training data. Calculating the sum of the loss functions for all this data takes a while. Big data sometimes contains millions or tens of millions of pieces of data. In that case, calculating the loss functions for all the data is not practical. Therefore, some data is extracted to approximate all the data. Also, in neural network training, some training data is selected, and training is conducted for each group of data, which is called a mini-batch (small collection). For example, 100 pieces of data are selected at random from 60,000 items of training data to be used for training. This training method is called <strong class="bold">mini-batch training</strong>.</p>
			<p>Now, let's write some code that selects the specified amount of data from the training data at random for mini-batch training. Before that, the following is the code for loading the MNIST dataset:</p>
			<p class="source-code">import sys, os</p>
			<p class="source-code">sys.path.append(os.pardir)</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">from dataset.mnist import load_mnist</p>
			<p class="source-code">(x_train,  t_train),  (x_test,  t_test)  =  /</p>
			<p class="source-code">    load_mnist(normalize=True, one_hot_label=True)</p>
			<p class="source-code">print(x_train.shape) # (60000, 784)</p>
			<p class="source-code">print(t_train.shape) # (60000, 10)</p>
			<p>As described in <em class="italics">Chapter 3</em>, <em class="italics">Neural Networks</em>, the <strong class="inline">load_mnist</strong> function loads the MNIST dataset. It is located in the <strong class="inline">dataset/mnist.py</strong> file provided with this book. This function loads the training and test data. By specifying the <strong class="inline">one_hot_label=True</strong> argument, you can use one-hot representation, where the correct label is 1 and the other labels are 0.</p>
			<p>When you load the preceding MNIST data, you will find that the number of training data is 60,000 and that the input data contains 784 rows of image data (originally 28x28). Labeled data is data with 10 rows. Therefore, the shapes of <strong class="inline">x_train</strong> and <strong class="inline">t_train</strong> are (60000, 784) and (60000, 10), respectively.</p>
			<p>Now, how can we extract 10 pieces of data at random from the training data? We can write the following code by using NumPy's <strong class="inline">np.random.choice()</strong> function:</p>
			<p class="source-code">train_size = x_train.shape[0]</p>
			<p class="source-code">batch_size = 10</p>
			<p class="source-code">batch_mask = np.random.choice(train_size, batch_size) </p>
			<p class="source-code">x_batch = x_train[batch_mask]</p>
			<p class="source-code">t_batch = t_train[batch_mask]</p>
			<p>By using <strong class="inline">np.random.choice()</strong>, you can select the desired number of numerals at random from the specified numerals. For example, <strong class="inline">np.random.choice(60000, 10)</strong> selects 10 numerals at random from the numerals between 0 and less than 60,000. In the actual code, as shown here, you can obtain the indices as an array for selecting mini-batches:</p>
			<p class="source-code">&gt;&gt;&gt; np.random.choice(60000, 10)</p>
			<p class="source-code">array([ 8013, 14666, 58210, 23832, 52091, 10153, 8107, 19410, 27260,</p>
			<p class="source-code">21411])</p>
			<p>Now, you can specify the randomly selected indices to extract mini-batches. We will use these mini-batches to calculate loss functions.</p>
			<h4>Note</h4>
			<p class="callout">To measure television viewership, not all households, but selected ones, are targeted. For example, by measuring viewership among 1,000 households randomly selected from Tokyo, you can approximate the viewership throughout Tokyo. The viewership among these 1,000 households is not exactly the same as the whole viewership, but it can be used as an approximate value. Like the viewership described here, the loss function of a mini-batch is measured by using sample data to approximate the whole data. In short, a small group of randomly selected data (mini-batch) is used as the approximation of the whole training data.</p>
			<h3 id="_idParaDest-100"><a id="_idTextAnchor102"/>Implementing Cross-Entropy Error (Using Batches)</h3>
			<p>How can we use batch data such as mini-batches to implement a cross-entropy error? By improving the cross-entropy error we implemented earlier, which targets only one piece of data, we can implement it easily. Here, we will support both the input of a single piece of data and the input of data as batches:</p>
			<p class="source-code">def cross_entropy_error(y, t):</p>
			<p class="source-code">    if y.ndim == 1:</p>
			<p class="source-code">        t = t.reshape(1, t.size)</p>
			<p class="source-code">        y = y.reshape(1, y.size)</p>
			<p class="source-code">    batch_size = y.shape[0]</p>
			<p class="source-code">    return -np.sum(t * np.log(y + 1e-7)) / batch_size</p>
			<p>Here, <strong class="inline">y</strong> is the output of the neural network, and <strong class="inline">t</strong> is labeled data. If <strong class="inline">y</strong> is one-dimensional (that is, to calculate the cross-entropy error for one piece of data), the shape of the data is changed. The average cross-entropy error per data is calculated by normalization based on the amount of data in a batch. </p>
			<p>If labeled data is provided as labels (not in one-hot representation format but as labels such as "2" and "7"), we can implement a cross-entropy error as follows:</p>
			<p class="source-code">def cross_entropy_error(y, t): </p>
			<p class="source-code">    if y.ndim == 1:</p>
			<p class="source-code">        t = t.reshape(1, t.size)</p>
			<p class="source-code">        y = y.reshape(1, y.size)</p>
			<p class="source-code">    batch_size = y.shape[0]</p>
			<p class="source-code">    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size</p>
			<p>Please note that if <strong class="inline">t</strong> of an element is 0 in one-hot representation, its cross-entropy error is also <strong class="inline">0</strong>, and you can ignore this calculation. In other words, if you can obtain the output of the neural network for a correct label, you can calculate the cross-entropy error. Therefore, for <strong class="inline">t</strong> as the one-hot representation, <strong class="inline">t * np.log(y)</strong> is used, while for <strong class="inline">t</strong> as labels, <strong class="inline">np.log( y[np.arange(batch_size), t] )</strong> is used for the same processing (here, the description of "a very small value, <strong class="inline">1e-7</strong>" has been omitted for visibility).</p>
			<p>For reference, we can cover <strong class="inline">np.log( y[np.arange(batch_size), t] )</strong> briefly. <strong class="inline">np.arange(batch_size)</strong> generates an array from 0 to <strong class="inline">batch_size-1</strong>. When <strong class="inline">batch_size</strong> is 5, <strong class="inline">np.arange(batch_size)</strong> generates a NumPy array, [0, 1, 2, 3, 4]. <strong class="inline">t</strong> contains labels, as in [2, 7, 0, 9, 4] and <strong class="inline">y[np.arange(batch_size), t]</strong> extracts the output of the neural network corresponding to the correct label for each piece of data (in this example, <strong class="inline">y[np.arange(batch_size), t]</strong> generates a NumPy array, <strong class="inline">[y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]</strong>).</p>
			<h3 id="_idParaDest-101"><a id="_idTextAnchor103"/>Why Do We Configure a Loss Function?</h3>
			<p>Some people may wonder why we introduce a loss function. For example, in the case of number recognition, we want parameters to improve recognition accuracy. Isn't it extra work to introduce a loss function? Our goal is to achieve a neural network that maximizes recognition accuracy. So, surely, we should use "recognition accuracy" as a score?</p>
			<p>You can find the answer to this question by paying attention to the role of the "derivative" in neural network training. This will be explained in detail in the next section. Neural network training looks for optimal parameters (weights and biases) so that the value of the loss function is the smallest. To look for the position of the smallest loss function, the derivative (gradient, to be precise) of a parameter is calculated, and the parameter value is updated gradually, based on the value of the derivative.</p>
			<p>For example, suppose that a virtual neural network exists here. We will pay attention to one weight parameter in the neural network. Here, the derivative of the loss function of the weight parameter indicates how  the loss function changes when the value of the weight parameter is changed a little. If the derivative becomes a negative value, you can reduce the loss function by changing the weight parameter in a positive direction. On the other hand, if the derivative is a positive value, you can reduce the loss function by changing the weight parameter in the negative direction. However, when the value of the derivative becomes 0, the value of the loss function does not change, no matter how the weight parameter is moved. Updating the weight parameter is stopped there.</p>
			<p>We cannot use recognition accuracy as the score because the derivative becomes 0 at almost all positions, preventing parameters from being updated. Now, let's neatly summarize this.</p>
			<h4>Note</h4>
			<p class="callout">When training a neural network, we should not use recognition accuracy as the score. The reason is that if you use recognition accuracy as the score, the derivative of the parameters will be zero in most places.</p>
			<p>So why does recognition accuracy as the score lead the derivative of the parameter to 0 at almost all positions? Well, to explain this, let's consider another example. Say that a neural network can recognize 32 out of 100 items of training data. This means that the recognition accuracy is 32%. If we use the recognition accuracy as the score, slightly changing the weight parameter will leave it at 32% and cause no change. Slightly adjusting the parameters does not improve recognition accuracy. Even if the recognition accuracy is improved, the change will not be continuous, such as 32.0123…%, but discontinuous, such as 33% and 34%. On the other hand, if the loss function is used as the score, the current value of the loss function is represented as a value, such as 0.92543… Slightly changing the parameter value also changes the loss function continuously, such as 0.93432…</p>
			<p>Slightly adjusting the parameter only changes the recognition accuracy a bit, and any change is discontinuous and sudden. This is also true of the "step function" of an activation function. If you use a step function for an activation function, a neural network cannot learn appropriately for the same reason. The reason for this is that the derivative of a step function is 0 almost anywhere (positions other than 0), as shown in <em class="italics">Figure 4.4</em>. When you use a step function, a slight change to the parameter is erased by the step function, and the value of the loss function shows no changes, even if you use it as the score.</p>
			<p>A step function changes only at some moments, like a shishi-odoshi or scarecrow. On the other hand, for the derivative (tangent) of a sigmoid function, the output (value of the vertical axis) changes continuously and the gradient of the curve also changes continuously, as shown in <em class="italics">Figure 4.4</em>. In short, the derivative of a sigmoid function is not 0 at any position. This is important for "training" in a neural network. Because the gradient is never 0, a neural network can learn correctly:</p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/fig04_4.jpg" alt="Figure 4.4: Step function and sigmoid function – the gradient of a step function is 0 at almost all positions, while the gradient of a sigmoid function (tangent) is never 0&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.4: Step function and sigmoid function – the gradient of a step function is 0 at almost all positions, while the gradient of a sigmoid function (tangent) is never 0</h6>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor104"/>Numerical Differentiation</h2>
			<p>The gradient method uses information from the gradient to determine which direction to follow. This section describes what a gradient is and its characteristics, beginning with a "derivative."</p>
			<h3 id="_idParaDest-103"><a id="_idTextAnchor105"/>Derivative</h3>
			<p>For example, let's assume that you ran 2 km in 10 minutes from the start of a full marathon. You can calculate the speed as <em class="italics">2 / 10 = 0.2</em> [km/minute]. You ran at a speed of 0.2 km per minute.</p>
			<p>In this example, we calculated how much the "running distance" changed over "time." Strictly speaking, this calculation indicates the "average speed" for 10 minutes because you ran 2 km in 10 minutes. A derivative indicates the amount of change at "a certain moment." Therefore, by minimizing the time of 10 minutes (the distance in the last 1 minute, the distance in the last 1 second, the distance in the last 0.1 seconds, and so on), you can obtain the amount of change at a certain moment (instantaneous speed).</p>
			<p>Thus, a derivative indicates the amount of change at a certain moment. This is defined by the following equation:</p>
			<table id="table004-1" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style CellOverride-1">
							<div>
								<div id="_idContainer112">
									<img src="image/Figure_4.4a.png" alt="21"/>
								</div>
							</div>
						</td>
						<td class="No-Table-Style">
							<p>(4.4)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>Equation (4.4) indicates the derivative of a function. The left-hand side <img src="image/Figure_4.4b.png" alt="22"/> indicates the derivative of <em class="italics">f(x)</em> with respect to <em class="italics">x</em> – the degree of changes of f(x) with respect to <em class="italics">x</em>. The derivative expressed by equation (4.4) indicates how the value of the function, <em class="italics">f(x)</em>, changes because of a "slight change" in <em class="italics">x</em>. Here, the slight change, <em class="italics">h</em>, is brought close to 0 infinitely, which is indicated as <img src="image/Figure_4.4c.png" alt="23"/>.</p>
			<p>Let's write a program to obtain the derivative of a function based on equation (4.4). To implement equation (4.4) directly, you can assign a small value to h for calculation purposes:</p>
			<p class="source-code"># Bad implementation sample</p>
			<p class="source-code">def numerical_diff(f,  x): </p>
			<p class="source-code">    h = 10e-50</p>
			<p class="source-code">    return (f(x+h) - f(x)) / h</p>
			<p>The function is named <strong class="inline">numerical_diff(f, x)</strong>, after <strong class="bold">numerical differentiation</strong>. It takes two arguments: the function, f, and the argument, x, of the function, f. This implementation seems correct, but two improvements can be made.</p>
			<p>The preceding implementation uses a small value of <strong class="inline">10e-50</strong> ("0.00...1" containing 50 0s) as h because we want to use the smallest possible value as h (we want to bring h infinitely close to 0 if possible). But the problem of a <strong class="bold">rounding error</strong> occurs here. A rounding error occurs in the final calculation result by omitting a numeric value in the small range of a decimal (for example, by omitting eight or more places of decimals). The following example shows a rounding error in Python:</p>
			<p class="source-code">&gt;&gt;&gt; np.float32(1e-50)</p>
			<p class="source-code">0.0</p>
			<p>When you represent <strong class="inline">1e-50</strong> in the float32 type (a 32-bit floating-point number), the value becomes 0.0. You cannot express it correctly. Using too small value causes a problem in computer calculation. Now, here is the first improvement. You can use 10<span class="P---Superscript">−4</span> as the small value, h. It is known that a value of around 10<span class="P---Superscript">−4</span> brings about good results.</p>
			<p>The second improvement is in terms of the difference in the function, f. The preceding implementation calculates the difference in the function f between x + h and x. You should observe that this calculation causes an error in the first place. As shown in <em class="italics">Figure 4.5</em>, the "true derivative " corresponds to the gradient of the function at the position of <em class="italics">x</em> (called a tangent), while the derivative in this implementation corresponds to the gradient between (<em class="italics">x</em> + <em class="italics">h</em>) and x. Therefore, the true derivative (true tangent) is not strictly identical to the value of this implementation. This difference occurs because you cannot bring <em class="italics">h</em> close to 0 infinitely:</p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/fig04_5.jpg" alt="Figure 4.5: True derivative (true tangent) and numerical differentiation (tangent &#13;&#10;by approximation) are different in value&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.5: True derivative (true tangent) and numerical differentiation (tangent by approximation) are different in value</h6>
			<p>As shown in <em class="italics">Figure 4.5</em>, a numerical differential contains an error. To reduce this error, you can calculate the difference of the function, (<em class="italics">f</em>), between (<em class="italics">x + h</em>) and (<em class="italics">x - h</em>). This difference is called a <strong class="bold">central difference</strong> because it is calculated around <em class="italics">x</em> (on the other hand, the difference between (<em class="italics">x + h</em>) and <em class="italics">x</em> is called a <strong class="bold">forward difference</strong>). Now, let's implement a numerical differentiation (numerical gradient) based on these two improvements:</p>
			<p class="source-code">def numerical_diff(f,  x): </p>
			<p class="source-code">    h = 1e-4 # 0.0001</p>
			<p class="source-code">    return (f(x+h) - f(x-h)) / (2*h)</p>
			<h4>Note</h4>
			<p class="callout">As the preceding code shows, calculating a derivative by using a very small value difference is called <strong class="bold">numerical differentiation</strong>. On the other hand, obtaining a derivative with the expansion is called an "analytical solution" or "analytically obtaining a derivative," for example, by using the word "analytic." You can obtain the derivative of <em class="italics">y</em> = <em class="italics">x</em><span class="P---Superscript">2</span> analytically as <img src="image/Figure_4.5a.png" alt="24"/>. Therefore, you can calculate the derivative of <em class="italics">y</em> as <em class="italics">x</em> = 2, and this is 4. An analytic derivative is the "true derivative" without errors.</p>
			<h3 id="_idParaDest-104"><a id="_idTextAnchor106"/>Examples of Numerical Differentiation</h3>
			<p>Let's differentiate an easy function by using numerical differentiation. The first example is the quadratic function expressed by the following equation:</p>
			<table id="table005-1" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><a id="_idTextAnchor107"/><img src="image/Figure_4.5b.png" alt="25"/></p>
						</td>
						<td class="No-Table-Style">
							<p>(4.5)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>Implement equation (4.5) in Python as follows:</p>
			<p class="source-code">def function_1(x):</p>
			<p class="source-code">    return 0.01*x**2 + 0.1*x</p>
			<p>Draw the graph of this function. The following shows the code for drawing a graph and the resulting graph (<em class="italics">Figure 4.6</em>):</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import  matplotlib.pylab  as  plt</p>
			<p class="source-code">x = np.arange(0.0, 20.0, 0.1) # The array x containing 0 to 20 in increments of 0.1</p>
			<p class="source-code">y = function_1(x)</p>
			<p class="source-code">plt.xlabel("x")</p>
			<p class="source-code">plt.ylabel("f(x)")</p>
			<p class="source-code">plt.plot(x, y)</p>
			<p class="source-code">plt.show()</p>
			<p>Now calculate the differentials of the function when x=5 and x=10:</p>
			<p class="source-code">&gt;&gt;&gt; numerical_diff(function_1, 5)</p>
			<p class="source-code">0.1999999999990898</p>
			<p class="source-code">&gt;&gt;&gt; numerical_diff(function_1, 10)</p>
			<p class="source-code">0.2999999999986347</p>
			<p>The differential calculated here is the amount of change of <em class="italics">f(x)</em> for <em class="italics">x</em>, which corresponds to the gradient of the function. By the way, the analytical solution of <em class="italics">f (x) = 0.01x</em><span class="P---Superscript">2</span><em class="italics"> + 0.1x</em> is <img src="image/Figure_4.6c.png" alt="26"/><em class="italics"> = 0.02x + 0.1</em>. The true derivative when <em class="italics">x=5</em> and 10 are 0.2 and 0.3, respectively. They are not strictly identical to the results from numerical differentiation, but the error is very small. Actually, the error is so small that they can be regarded as almost identical values:</p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/fig04_6.jpg" alt="Figure 4.6: Graph of f (x) = 0.01x2 + 0.1x&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.6: Graph of <em class="italics">f</em> (<em class="italics">x</em>) = 0.01<em class="italics">x</em><span class="P---Superscript">2</span> + 0.1<em class="italics">x</em></h6>
			<p>We will use the preceding results of our numerical differentiation to plot graphs of lines whose gradients are the values of the numerical differentiation. The results are shown in <em class="italics">Figure 4.7</em>. Here, you can see that the derivatives correspond to the tangents of the function (the source code is located at <strong class="inline">ch04/gradient_1d.py</strong>):</p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/fig04_7.jpg" alt="Figure 4.7: Tangents when x = 5 and x = 10 – using the values from numerical differentiation as the "/>
				</div>
			</div>
			<h6>Figure 4.7: Tangents when <em class="italics">x</em> = 5 and <em class="italics">x</em> = 10 – using the values from numerical differentiation as the gradients of lines</h6>
			<h3 id="_idParaDest-105"><a id="_idTextAnchor108"/>Partial Derivative</h3>
			<p>Next, let's look at the function expressed by equation (4.6). This simple equation calculates the square sum of the arguments. Note that it has two variables, unlike the previous example:</p>
			<table id="table006-1" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><a id="_idTextAnchor109"/><img src="image/Figure_4.7a.png" alt="27"/></p>
						</td>
						<td class="No-Table-Style">
							<p>(4.6)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>You can implement it in Python as follows:</p>
			<p class="source-code">def function_2(x):</p>
			<p class="source-code">    return x[0]**2 + x[1]**2</p>
			<p class="source-code">    # or return np.sum(x**2)</p>
			<p>Here, it is assumed that NumPy arrays are passed as arguments. The function simply squares each element of the NumPy arrays and sums it up (<strong class="inline">np.sum(x**2)</strong> can implement the same processing). Now, let's draw the graph of this function. This three-dimensional graph appears as follows:</p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/fig04_8.jpg" alt="Figure 4.8: Graph of &#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.8: Graph of <img src="image/Figure_4.8a.png" alt="28"/></h6>
			<p>Now, we want to calculate the derivative of equation (4.6). Here, please note that equation (4.6) has two variables. Therefore, you must specify for which of the two variables,<em class="italics"> x</em><span class="P---Subscript">0</span> and <em class="italics">x</em><span class="P---Subscript">1</span>, the differentials are calculated. The derivative of a function that consists of multiple variables is called a <strong class="bold">partial derivative</strong>. They are expressed as <img src="image/Figure_4.8b.png" alt="29"/>.</p>
			<p>To illustrate this, consider the following two partial derivative problems and their solutions:</p>
			<p><strong class="bold">Question 1</strong>: Calculate the partial derivative, <img src="image/Figure_4.8c.png" alt="30"/>, for <strong class="inline">x0</strong> when <strong class="inline">x0 = 3</strong> and <strong class="inline">x1 = 4</strong>:</p>
			<p class="source-code">&gt;&gt;&gt; def function_tmp1(x0):</p>
			<p class="source-code">...	return x0*x0 + 4.0**2.0</p>
			<p class="source-code">...</p>
			<p class="source-code">&gt;&gt;&gt; numerical_diff(function_tmp1, 3.0)</p>
			<p class="source-code">6.00000000000378</p>
			<p><strong class="bold">Question 2</strong>: Calculate the partial derivative, <img src="image/Figure_4.8d.png" alt="4a"/>, for <strong class="inline">x1</strong> when <strong class="inline">x0 = 3</strong> and <strong class="inline">x1 = 4</strong>:</p>
			<p class="source-code">&gt;&gt;&gt; def function_tmp2(x1):</p>
			<p class="source-code">...	return 3.0**2.0 + x1*x1</p>
			<p class="source-code">...</p>
			<p class="source-code">&gt;&gt;&gt; numerical_diff(function_tmp2, 4.0)</p>
			<p class="source-code">7.999999999999119</p>
			<p>To solve these problems, a function with one variable is defined, and the derivative for the function is calculated. For example, in <strong class="bold">Question 1</strong>, a new function for <strong class="inline">x1=4</strong> is defined, and the function, which has only one variable, <strong class="inline">x0</strong>, is passed to the function to calculate a numerical differentiation. Based on the results, the answer to <strong class="bold">Question 1</strong> is <strong class="inline">6.00000000000378</strong>, and the answer to <strong class="bold">Question 2</strong> is <strong class="inline">7.999999999999119</strong>. They are mostly the same as the solutions from analytical differentiation.</p>
			<p>In this way, the partial derivative calculates the gradient at a certain position, such as the differentiation for one variable. However, for the partial derivative, one of the variables is targeted, and the other variables are fixed at a certain value. In the preceding implementation, a new function was defined to hold the other variables at a specific value. The newly defined function was passed to the previous numerical differential function to calculate the partial derivative.</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor110"/>Gradient</h2>
			<p>In the previous example, the partial derivatives of <em class="italics">x</em><span class="P---Subscript">0</span> and <em class="italics">x</em><span class="P---Subscript">1</span> were calculated for each variable. Now, we want to calculate the partial derivatives of <em class="italics">x</em><span class="P---Subscript">0</span> and <em class="italics">x</em><span class="P---Subscript">1</span> collectively. For example, let's calculate the partial derivatives of (<em class="italics">x</em><span class="P---Subscript">0</span>, <em class="italics">x</em><span class="P---Subscript">1</span>) when <strong class="inline">x0 = 3</strong> and <strong class="inline">x1 = 4</strong> as (<img src="image/Figure_4.8b1.png" alt="31"/>)<a id="_idTextAnchor111"/>The vector that collectively indicates the partial differentials of all the variables, such as (<img src="image/Figure_4.8b2.png" alt="32"/>) is called a <strong class="bold">gradient</strong>. You can implement a gradient as follows:</p>
			<p class="source-code">def numerical_gradient(f,   x): </p>
			<p class="source-code">    h = 1e-4 # 0.0001</p>
			<p class="source-code">    grad = np.zeros_like(x) # Generate an array with the same shape as x</p>
			<p class="source-code">    for idx in range(x.size):</p>
			<p class="source-code">        tmp_val = x[idx]</p>
			<p class="source-code">        # Calculate f(x+h)</p>
			<p class="source-code">        x[idx] = tmp_val + h</p>
			<p class="source-code">        fxh1 = f(x)</p>
			<p class="source-code">        # Calculate f(x-h)</p>
			<p class="source-code">        x[idx] = tmp_val - h</p>
			<p class="source-code">        fxh2 = f(x)</p>
			<p class="source-code">        grad[idx] = (fxh1 - fxh2) / (2*h)</p>
			<p class="source-code">        x[idx] = tmp_val # Restore the original value</p>
			<p class="source-code">    return grad</p>
			<p>Implementing the <strong class="inline">numerical_gradient(f, x)</strong> function seems a little complicated, but the processes are almost the same as those in numerical differentiation for one variable. Note that <strong class="inline">np.zeros_like(x)</strong> generates an array that has the same shape as <strong class="inline">x</strong> and whose elements are all zero.</p>
			<p>The <strong class="inline">numerical_gradient(f, x)</strong> function takes the <strong class="inline">f (function)</strong> and <strong class="inline">x (NumPy array)</strong> arguments and obtains numerical differentiations for each element of the NumPy array, <strong class="inline">x</strong>. Now, let's use this function to calculate a gradient. Here, we will obtain the gradients at points (3, 4), (0, 2), and (3, 0):</p>
			<p class="source-code">&gt;&gt;&gt; numerical_gradient(function_2, np.array([3.0, 4.0]))</p>
			<p class="source-code">array([ 6., 8.])</p>
			<p class="source-code">&gt;&gt;&gt; numerical_gradient(function_2, np.array([0.0, 2.0]))</p>
			<p class="source-code">array([ 0., 4.])</p>
			<p class="source-code">&gt;&gt;&gt; numerical_gradient(function_2, np.array([3.0, 0.0]))</p>
			<p class="source-code">array([  6.,    0.])</p>
			<h4>Note</h4>
			<p class="callout">The actual result is [6.0000000000037801, 7.9999999999991189], but [6., 8.] is returned. This is because a returned NumPy array is formatted to enhance the visibility of the values.</p>
			<p>Thus, we can calculate the gradient at each point of (<em class="italics">x</em><span class="P---Subscript">0</span>, <em class="italics">x</em><span class="P---Subscript">1</span>). The preceding example shows that the gradient for point (3, 4) is (6, 8), that for point (0, 2) is (0, 4), and that for point (3, 0) is (6, 0). What do these gradients mean? To understand this, let's look at the gradients of <img src="image/Figure_4.8g.png" alt="33"/>. Here, we will make the gradients negative and draw the vectors (the source code is located at <strong class="inline">ch04/gradient_2d.py</strong>).</p>
			<p>The gradients of <img src="image/Figure_4.8g1.png" alt="34"/> are shown as the vectors (arrows) that have the direction toward the lowest point, as shown in <em class="italics">Figure 4. 9</em>. In <em class="italics">Figure 4.9</em>, the gradients seem to point at "the lowest position (smallest value)" of the function, <em class="italics">f</em>(<em class="italics">x</em><span class="P---Subscript">0</span>, <em class="italics">x</em><span class="P---Subscript">1</span>). Just like a compass, the arrows point to one point. The more distant they are from "the lowest position," the larger the size of the arrow:</p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/fig04_9.jpg" alt="Figure 4.9: Gradients of &#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.9: Gradients of <img src="image/Figure_4.9a.png" alt="35"/></h6>
			<p>In the example shown in <em class="italics">Figure 4.9</em>, the gradients point at the lowest position, but this is not always the case. In fact, gradient points in the lower direction at each position. To be more precise, the direction of a gradient is <strong class="bold">the direction that reduces the value of the function most at each position</strong>. This is an important point, so please keep this in mind.</p>
			<h3 id="_idParaDest-107"><a id="_idTextAnchor112"/>Gradient Method</h3>
			<p>Many machine learning problems look for optimal parameters during training. A neural network also needs to find optimal parameters (weights and biases) during training. The optimal parameter here is the parameter value when the loss function takes the minimum value. However, a loss function can be complicated. The parameter space is vast, and we cannot guess where it takes the minimum value. A gradient method makes good use of gradients to find the minimum value (or the smallest possible value) of the function.</p>
			<p>A gradient shows the direction that reduces the value of the function most at each position. Therefore, whether the position that a gradient points in is really the minimum value of the function, in other words, whether the direction is really the one to take, cannot be guaranteed. Actually, in a complicated function, the direction that a gradient points to is not the minimum value in most cases.</p>
			<h4>Note</h4>
			<p class="callout">The gradient is 0 at the local minimum, the minimum, and at a point called the saddle point of a function. A local minimum is locally the smallest value, which is the minimum value in a limited range. A saddle point is a position of the local maximum in one direction and of the local minimum in another direction. A gradient method looks for the position where a gradient is 0, but where the position is not always the global minimum (it can be the local minimum or a saddle point). When a function has a complicated and distorted shape, learning enters an (almost) flat land and a stagnant period called a "plateau" might occur, leading to stagnation in training.</p>
			<p>Even if the direction of a gradient does not always point at the global minimum value, moving in that direction can reduce the value of the function the most. Therefore, to look for the position of the minimum value or to look for the position where the function has the smallest possible value, you should determine the direction of movement based on the information about gradients.</p>
			<p>Now, let's look at the gradient method. In the gradient method, you move a fixed distance from the current position in the gradient direction. By doing this, you obtain a gradient at the new position and move in the gradient direction again. Thus, you move in the gradient direction repeatedly. Reducing the value of a function gradually by going in the gradient direction repeatedly is known as the <strong class="bold">gradient method</strong>. This method is often used in optimization problems for machine learning. It is typically used when training neural networks.</p>
			<h4>Note</h4>
			<p class="callout">A gradient method is called by another name if it looks for the minimum or the maximum value. To be precise, the method for the minimum value is called the <strong class="bold">gradient descent method</strong>, while the method for the maximum value is called the <strong class="bold">gradient ascent method</strong>. However, reversing the sign of a loss function can change this from a problem for the minimum value into a problem for the maximum value. So, the difference between "descent" and "ascent" is not especially important. Generally, a "gradient descent" method is often used in neural networks (deep learning).</p>
			<p>Now, let's express a gradient method with an equation. Equation (4.7) shows a gradient method:</p>
			<table id="table007-1" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><img src="image/Figure_4.9b.png" alt="36"/></p>
						</td>
						<td class="No-Table-Style">
							<p>(4.7)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>In equation (4.7), η adjusts the amount to be updated. This is called a <strong class="bold">learning rate</strong> in neural network. A learning rate determines how much needs to be learned and how much to update the parameters.</p>
			<p>Equation (4.7) shows an update equation for one training instance, and the step is repeated. Each step updates the variable values, as shown in equation (4.7), and the step is repeated several times to reduce the value of the function gradually. This example has two variables, but even when the number of variables is increased, a similar equation—a partial differential value for each variable—is used for updating.</p>
			<p>You must specify the value of the learning rate, such as 0.01 and 0.001, in advance. Generally, if this value is too large or too small, you cannot reach a "good place." In neural network training, we usually check whether training is successful by changing the value of the learning rate.</p>
			<p>Now, let's implement a gradient descent method in Python. This can be done as follows:</p>
			<p class="source-code">def gradient_descent(f,  init_x,  lr=0.01,  step_num=100): </p>
			<p class="source-code">    x = init_x</p>
			<p class="source-code">    for i in range(step_num):</p>
			<p class="source-code">        grad = numerical_gradient(f, x)</p>
			<p class="source-code">        x -= lr * grad</p>
			<p class="source-code">    return x</p>
			<p>The <strong class="inline">f</strong> argument is a function to optimize, the <strong class="inline">init_x</strong> argument is an initial value, the <strong class="inline">lr</strong> argument is a learning rate, and the <strong class="inline">step_num</strong> argument is the number of repetitions in a gradient method. The gradient of the function is obtained by <strong class="inline">numerical_gradient(f, x)</strong> and the gradient updated by multiplying it by the learning rate, which is repeated the number of times specified by <strong class="inline">step_num</strong>.</p>
			<p>You can use this function to obtain the local minimum of the function and even the minimum value if you are lucky. Now, let's try solving a problem.</p>
			<p><strong class="bold">Question</strong>: Obtain the minimum value of <a id="_idTextAnchor113"/><img src="image/Figure_4.9d.png" alt="37"/> with a gradient method:</p>
			<p class="source-code">&gt;&gt;&gt; def function_2(x):</p>
			<p class="source-code">...    return x[0]**2 + x[1]**2</p>
			<p class="source-code">...</p>
			<p class="source-code">&gt;&gt;&gt; init_x = np.array([-3.0, 4.0])</p>
			<p class="source-code">&gt;&gt;&gt; gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)</p>
			<p class="source-code">array([ -6.11110793e-10, 8.14814391e-10])</p>
			<p>Here, specify (-3.0, 4.0) as the initial value and start looking for the minimum value by using a gradient method. The final result is (-6.1e-10, 8.1e-10), which is almost near (0, 0). Actually, the true minimum value is (0, 0). You successfully obtained almost correct results by using a gradient method. <em class="italics">Figure 4.10</em> shows the process of updating with a gradient method. The origin is the lowest position, and you can see that the result is approaching it gradually. The source code to draw this graph is located at <strong class="inline">ch04/gradient_method.py</strong> (<strong class="inline">ch04/gradient_method.py</strong> does not display dashed lines, which show the contour lines in the graph):</p>
			<div>
				<div id="_idContainer135" class="IMG---Figure">
					<img src="image/fig04_10.jpg" alt="Figure 4.10: Updating  with a gradient method – the dashed lines show &#13;&#10;the contour lines of the function&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.10: Updating <img src="image/Figure_4.10a.png" alt="38"/> with a gradient method – the dashed lines show the contour lines of the function</h6>
			<p>As mentioned earlier, an overly large or small learning rate does not achieve good results. Let's do some experiments regarding both cases here:</p>
			<p class="source-code"># When the learning rate is too large: lr=10.0</p>
			<p class="source-code">&gt;&gt;&gt; init_x = np.array([-3.0, 4.0])</p>
			<p class="source-code">&gt;&gt;&gt;  gradient_descent(function_2,  init_x=init_x,  lr=10.0,  step_num=100)</p>
			<p class="source-code">array([ -2.58983747e+13, -1.29524862e+12])</p>
			<p class="source-code"># When the learning rate is too small: lr=1e-10</p>
			<p class="source-code">&gt;&gt;&gt; init_x = np.array([-3.0, 4.0])</p>
			<p class="source-code">&gt;&gt;&gt; gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)</p>
			<p class="source-code">array([-2.99999994, 3.99999992])</p>
			<p>As this experiment shows, the result diverges to a large value if the learning rate is too large. On the other hand, almost no updates occur if the learning rate is too small. Setting an appropriate learning rate is important.</p>
			<h4>Note</h4>
			<p class="callout">A parameter such as a learning rate is called a <strong class="bold">hyperparameter</strong>. It is different from the parameters (weights and biases) of a neural network in terms of its characteristics. Weight parameters in a neural network can be obtained automatically with training data and a training algorithm, while a hyperparameter must be specified manually. Generally, you must change this hyperparameter to various values to find a value that enables good training.</p>
			<h3 id="_idParaDest-108"><a id="_idTextAnchor114"/>Gradients for a Neural Network</h3>
			<p>You must also calculate gradients in neural network training. The gradients here are those of a loss function for weight parameters. For example, let's assume that a neural network has the weight W (2x3 array) only, and the loss function is L. In this case, we can express the gradient as <img src="image/Figure_4.10b.png" alt="39"/>. The following equation shows this:</p>
			<table id="table008-1" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><img src="image/Figure_4.10c.png" alt="40"/></p>
						</td>
						<td class="No-Table-Style">
							<p>(4.8)</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>Each element of <img src="image/Figure_4.10e.png" alt="41"/> is the partial derivative for each element. For example, the element at the first row and column, <img src="image/Figure_4.10f.png" alt="42"/>, indicates how a slight change in w<span class="P---Subscript">11</span> changes the loss function, L. What is important here is that the shape of <img src="image/Figure_4.10g.png" alt="43"/> is the same as that of W. Actually, in equation (4.8), both W and <img src="image/Figure_4.10h.png" alt="44"/> are the same (2x3) in shape.</p>
			<p>Now, let's implement a program that calculates a gradient by taking an easy neural network as an example. To do that, we will implement a class named <strong class="inline">simpleNet</strong> (the source code is located at <strong class="inline">ch04/gradient_simplenet.py</strong>):</p>
			<p class="source-code">import sys, os</p>
			<p class="source-code">sys.path.append(os.pardir)</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">from common.functions import softmax, cross_entropy_error</p>
			<p class="source-code">from common.gradient import numerical_gradient</p>
			<p class="source-code">class simpleNet:</p>
			<p class="source-code">    def __ init __ (self):</p>
			<p class="source-code">        self.W = np.random.randn(2,3) # Initialize with a Gaussian distribution</p>
			<p class="source-code">    def predict(self, x):</p>
			<p class="source-code">        return np.dot(x, self.W)</p>
			<p class="source-code">    def loss(self, x, t):</p>
			<p class="source-code">        z = self.predict(x) </p>
			<p class="source-code">        y = softmax(z)</p>
			<p class="source-code">        loss = cross_entropy_error(y, t)</p>
			<p class="source-code">        return  loss</p>
			<p>Here, the <strong class="inline">softmax</strong> and <strong class="inline">cross_entropy_error</strong> methods in <strong class="inline">common/functions.py</strong> are being used. The <strong class="inline">numerical_gradient</strong> method in <strong class="inline">common/gradient.py</strong> is also being used. The <strong class="inline">simpleNet</strong> class has only one instance variable, which is the weight parameters with a shape of 2x3. It has two methods: one is <strong class="inline">predict(x)</strong> for prediction, and the other is <strong class="inline">loss(x, t)</strong> for obtaining the value of the loss function. Here, the <strong class="inline">x</strong> argument is the input data and the <strong class="inline">t</strong> argument is a correct label. Now, let's try using <strong class="inline">simpleNet</strong>:</p>
			<p class="source-code">&gt;&gt;&gt; net = simpleNet()</p>
			<p class="source-code">&gt;&gt;&gt; print(net.W) # Weight parameters</p>
			<p class="source-code">[[ 0.47355232 0.9977393 0.84668094]</p>
			<p class="source-code">[ 0.85557411 0.03563661 0.69422093]]</p>
			<p class="source-code">&gt;&gt;&gt;</p>
			<p class="source-code">&gt;&gt;&gt; x = np.array([0.6, 0.9])</p>
			<p class="source-code">&gt;&gt;&gt; p = net.predict(x)</p>
			<p class="source-code">&gt;&gt;&gt; print(p)</p>
			<p class="source-code">[ 1.05414809 0.63071653 1.1328074]</p>
			<p class="source-code">&gt;&gt;&gt; np.argmax(p) # Index for the maximum value</p>
			<p class="source-code">2</p>
			<p class="source-code">&gt;&gt;&gt;</p>
			<p class="source-code">&gt;&gt;&gt; t = np.array([0, 0, 1]) # Correct label</p>
			<p class="source-code">&gt;&gt;&gt; net.loss(x, t)</p>
			<p class="source-code">0.92806853663411326</p>
			<p>Next, let's obtain the gradients,using <strong class="inline">numerical_gradient(f, x)</strong>. The <strong class="inline">f(W)</strong> function defined here takes a dummy argument, <strong class="inline">W</strong>. Because the <strong class="inline">f(x)</strong> function is executed inside <strong class="inline">numerical_gradient(f, x)</strong>,  <strong class="inline">f(W)</strong> is defined for consistency:</p>
			<p class="source-code">&gt;&gt;&gt; def f(W):</p>
			<p class="source-code">...    return net.loss(x, t)</p>
			<p class="source-code">...</p>
			<p class="source-code">&gt;&gt;&gt; dW = numerical_gradient(f, net.W)</p>
			<p class="source-code">&gt;&gt;&gt; print(dW)</p>
			<p class="source-code">[[ 0.21924763 0.14356247 -0.36281009]</p>
			<p class="source-code"> [ 0.32887144 0.2153437 -0.54421514]]</p>
			<p>The <strong class="inline">f</strong> argument of <strong class="inline">numerical_gradient(f, x)</strong> is a function and the <strong class="inline">x</strong> argument is the argument to the function, <strong class="inline">f</strong>. Therefore, a new function, <strong class="inline">f</strong>, is defined here. It takes <strong class="inline">net.W</strong> as an argument and calculates the loss function. The newly defined function is passed to <strong class="inline">numerical_gradient(f, x)</strong>.</p>
			<p><strong class="inline">numerical_gradient(f, net.W)</strong> returns <strong class="inline">dW</strong>, which is a two-dimensional 2x3 array. <strong class="inline">dW</strong> shows that <img src="image/Figure_4.10i.png" alt="45"/> for <img src="image/Figure_4.10j.png" alt="46"/> is around <strong class="inline">0.2</strong>, for example. This indicates that when w<span class="P---Subscript">11</span> is increased by h, the value of the loss function increases by 0.2h. <img src="image/Figure_4.10k.png" alt="47"/> is about <strong class="inline">-0.5</strong>, which indicates that when w<span class="P---Subscript">23</span> is increased by h, the value of the loss function decreases by 0.5h. Therefore, to reduce the loss function, you should update w<span class="P---Subscript">23</span> in a positive direction and w<span class="P---Subscript">1</span>1 in a negative direction. You can also see that updating w<span class="P---Subscript">23</span> contributes to the reduction more than updating w<span class="P---Subscript">11</span>.</p>
			<p>In the preceding implementation, the new function is written as <strong class="inline">def f(x):…</strong> In Python, you can use a <strong class="inline">lambda</strong> notation to write and implement a simple function, as follows:</p>
			<p class="source-code">&gt;&gt;&gt; f = lambda w: net.loss(x, t)</p>
			<p class="source-code">&gt;&gt;&gt; dW = numerical_gradient(f, net.W)</p>
			<p>After obtaining the gradients for a neural network, all you have to do is use a gradient method to update the weight parameters. In the next section, we will implement all these training processes for a two-layer neural network.</p>
			<h4>Note</h4>
			<p class="callout">The <strong class="inline">numerical_gradient()</strong> function we used here is slightly different from the previous implementation for handling multi-dimensional arrays such as the weight parameter, <strong class="inline">W</strong>. However, these changes are simple and are only for handling multidimensional arrays. For further details, please refer to the source code (<strong class="inline">common/gradient.py</strong>).</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor115"/>Implementing a Training Algorithm</h2>
			<p>So far, we have learned about the basics of neural network training. Important keywords such as "loss function", "mini-batch", "gradient", and "gradient descent method" have appeared in succession. Here, we will look at the procedure of neural network training for review purposes. Let's go over the neural network training procedure.</p>
			<p class="H3---Subheading">Presupposition</p>
			<p>A neural network has adaptable weights and biases. Adjusting them so that they fit the training data is called "training." Neural network training consists of four steps.</p>
			<p class="H3---Subheading">Step 1 (mini-batch)</p>
			<p>Select some data at random from the training data. The selected data is called a mini-batch. The purpose here is to reduce the value of the loss function for the mini-batch.</p>
			<p class="H3---Subheading">Step 2 (calculating gradients)</p>
			<p>To reduce the loss function for the mini-batch, calculate the gradient for each weight parameter. The gradient shows the direction that reduces the value of the loss function the most.</p>
			<p class="H3---Subheading">Step 3 (updating parameters)</p>
			<p>Update the weight parameters slightly in the gradient direction.</p>
			<p class="H3---Subheading">Step 4 (repeating)</p>
			<p>Repeat <em class="italics">steps</em> <em class="italics">1</em>, <em class="italics">2</em>, and <em class="italics">3</em>.</p>
			<p>The preceding four steps are used for neural network training. This method uses a gradient descent method to update parameters. Because the data used here is selected at random as a mini-batch, it is referred to as <strong class="bold">stochastic gradient descent</strong>. "Stochastic" means "selecting data at random stochastically." Therefore, stochastic gradient descent means "the gradient descent method for randomly selected data." In many deep learning frameworks, stochastic gradient descent is usually implemented as the <strong class="bold">SGD</strong> function, which is named after its initials.</p>
			<p>Now, let's implement the neural network that actually learns handwritten digits. Here, a two-layer neural network (with one hidden layer) will use the MNIST dataset for training.</p>
			<h3 id="_idParaDest-110"><a id="_idTextAnchor116"/>A Two-Layer Neural Network as a Class</h3>
			<p>First, let's implement a two-layer neural network as a class. This class is named <strong class="inline">TwoLayerNet</strong> and is implemented as follows (implementing <strong class="inline">TwoLayerNet</strong> is based on the Python source code provided by the CS231n (<em class="italics">Convolutional Neural Networks for Visual Recognition</em> (<a href="http://cs231n.github.io/">http://cs231n.github.io/</a>) course at Stanford University). The source code is located at <strong class="inline">ch04/two_layer_net.py</strong>:</p>
			<p class="source-code">import sys, os</p>
			<p class="source-code">sys.path.append(os.pardir)</p>
			<p class="source-code">from common.functions import *</p>
			<p class="source-code">from common.gradient import numerical_gradient</p>
			<p class="source-code">class TwoLayerNet:</p>
			<p class="source-code">    def __ init __ (self, input_size, hidden_size, output_size,</p>
			<p class="source-code">                          weight_init_std=0.01):</p>
			<p class="source-code">        # Initialize weights</p>
			<p class="source-code">        self.params = {}</p>
			<p class="source-code">        self.params['W1'] = weight_init_std * /</p>
			<p class="source-code">                            np.random.randn(input_size, hidden_size)</p>
			<p class="source-code">        self.params['b1'] = np.zeros(hidden_size) </p>
			<p class="source-code">        self.params['W2'] = weight_init_std * /</p>
			<p class="source-code">                            np.random.randn(hidden_size, output_size)</p>
			<p class="source-code">        self.params['b2'] = np.zeros(output_size)</p>
			<p class="source-code">    def predict(self, x):</p>
			<p class="source-code">        W1, W2 = self.params['W1'], self.params['W2']</p>
			<p class="source-code">        b1, b2 = self.params['b1'], self.params['b2']</p>
			<p class="source-code">        a1 = np.dot(x, W1) + b1</p>
			<p class="source-code">        z1 = sigmoid(a1)</p>
			<p class="source-code">        a2 =  np.dot(z1, W2) + b2</p>
			<p class="source-code">        y = softmax(a2)</p>
			<p class="source-code">        return y</p>
			<p class="source-code">    # x: input data, t: label data</p>
			<p class="source-code">    def loss(self, x, t):</p>
			<p class="source-code">        y = self.predict(x)</p>
			<p class="source-code">        return cross_entropy_error(y, t)</p>
			<p class="source-code">    def accuracy(self, x, t):</p>
			<p class="source-code">        y = self.predict(x)</p>
			<p class="source-code">        y = np.argmax(y, axis=1)</p>
			<p class="source-code">        t = np.argmax(t, axis=1)</p>
			<p class="source-code">        accuracy = np.sum(y == t) / float(x.shape[0])</p>
			<p class="source-code">        return accuracy</p>
			<p class="source-code">    # x: input data, t: teacher data</p>
			<p class="source-code">    def numerical_gradient(self, x, t):</p>
			<p class="source-code">        loss_W = lambda  W:  self.loss(x,  t)</p>
			<p class="source-code">        grads = {}</p>
			<p class="source-code">        grads['W1'] = numerical_gradient(loss_W, self.params['W1']) </p>
			<p class="source-code">        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])</p>
			<p class="source-code">        grads['W2'] = numerical_gradient(loss_W, self.params['W2']) </p>
			<p class="source-code">        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])</p>
			<p class="source-code">        return grads</p>
			<p>The implementation of this class is a little long, but nothing that new appears. It has many things in common with the implementation of forward processing a neural network covered in the previous chapter. First, let's look at the variables and methods that were used in this class. <em class="italics">Table 4.1</em> shows the important variables, while <em class="italics">Table 4.2</em> shows all the methods:</p>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="image/Figure_4_Table01.jpg" alt="Table 4. 1: Variables used in the TwoLayerNet class&#13;&#10;"/>
				</div>
			</div>
			<h6>Table 4. 1: Variables used in the TwoLayerNet class</h6>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="image/Figure_4_Table02.jpg" alt="Table 4.2: Methods used in the TwoLayerNet class&#13;&#10;"/>
				</div>
			</div>
			<h6>Table 4.2: Methods used in the TwoLayerNet class</h6>
			<p>The <strong class="inline">TwoLayerNet</strong> class has two dictionary variables, <strong class="inline">params</strong> and <strong class="inline">grads</strong>, as instance variables. The <strong class="inline">params</strong> variable contains the weight parameters. For example, the weight parameters for layer 1 are stored in <strong class="inline">params['W1']</strong> as a NumPy array. You can access the bias for layer 1 using <strong class="inline">params['b1']</strong>. Here is an example:</p>
			<p class="source-code">net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)</p>
			<p class="source-code">net.params['W1'].shape # (784, 100)</p>
			<p class="source-code">net.params['b1'].shape # (100,)</p>
			<p class="source-code">net.params['W2'].shape # (100, 10)</p>
			<p class="source-code">net.params['b2'].shape # (10,)</p>
			<p>As shown here, the <strong class="inline">params</strong> variable contains all the parameters required for this network. The weight parameters contained in the <strong class="inline">params</strong> variable are used for predicting (forward processing). You can make a prediction as follows:</p>
			<p class="source-code">x = np.random.rand(100, 784) # Dummy input data (for 100 images)</p>
			<p class="source-code">y = net.predict(x)</p>
			<p>The <strong class="inline">grads</strong> variable contains the gradient for each parameter so that it corresponds to the <strong class="inline">params</strong> variable. When you calculate gradients by using the <strong class="inline">numerical_gradient()</strong> method, gradient information is stored in the <strong class="inline">grads</strong> variable, as follows:</p>
			<p class="source-code">x = p.random.rand(100, 784) # Dummy input data (for 100 images)</p>
			<p class="source-code">t = np.random.rand(100, 10) # Dummy correct label (for 100 images)</p>
			<p class="source-code">grads = net.numerical_gradient(x, t) # Calculate gradients</p>
			<p class="source-code">grads['W1'].shape # (784, 100)</p>
			<p class="source-code">grads['b1'].shape # (100,)</p>
			<p class="source-code">grads['W2'].shape # (100, 10)</p>
			<p class="source-code">grads['b2'].shape # (10,)</p>
			<p>Now, let's look at the implementation of the methods in <strong class="inline">TwoLayerNet</strong>. The <strong class="inline">__init__</strong> (<strong class="inline">self</strong>, <strong class="inline">input_size</strong>, <strong class="inline">hidden_size</strong>, <strong class="inline">output_size</strong>) method is the initialization method of the class ( called when <strong class="inline">TwoLayerNet</strong> is generated). The arguments are the numbers of neurons in the input layer, in the hidden layer, and the output layer in order from left to right. For handwritten digit recognition, a total of 784 input images that are 28x28 in size are provided and 10 classes are returned. Therefore, we specify the <strong class="inline">input_size=784</strong> and <strong class="inline">output_size=10</strong> arguments and set an appropriate value for <strong class="inline">hidden_size</strong> as the number of hidden layers.</p>
			<p>This initialization method also initializes the weight parameters. Determining what values to set as the initial weight parameters is important for successful neural network training. We will discuss the initialization of weight parameters in detail later. Here, the weights are initialized by using the random numbers based on Gaussian distribution, and the biases are initialized by 0. <strong class="inline">predict(self, x)</strong>, and <strong class="inline">accuracy(self, x, t)</strong> are almost the same as in the implementation of predicting in relation to the neural network, which we looked at in the previous chapter. If you have any questions, please refer to the previous chapter. The <strong class="inline">loss(self, x, t)</strong> method calculates the value of the loss function. It obtains a cross-entropy error based on the result of <strong class="inline">predict()</strong> and the correct label.</p>
			<p>The remaining <strong class="inline">numerical_gradient(self, x, t)</strong> method calculates the gradient of each parameter. It uses numerical differentiation to calculate the gradient for the loss function of each parameter. The <strong class="inline">gradient(self, x, t)</strong> method will be implemented in the next chapter. </p>
			<h4>Note</h4>
			<p class="callout"><strong class="inline">numerical_gradient(self, x, t)</strong> uses numerical differentiation to calculate the gradients of the parameters. In the next chapter, we will look at how to calculate gradients quickly using backpropagation, which returns almost the same result as using numerical differentiation, but with faster processing. The method for obtaining a gradient through backpropagation will be implemented as <strong class="inline">gradient(self, x, t)</strong> in the next chapter. If you want to save time, you can use <strong class="inline">gradient(self, x, t)</strong> instead of <strong class="inline">numerical_gradient(self, x, t)</strong> because neural network training takes time.</p>
			<h3 id="_idParaDest-111"><a id="_idTextAnchor117"/>Implementing Mini-Batch Training</h3>
			<p>Here, we will use mini-batch training to implement neural network training. In mini-batch training, we extract some data randomly from training data (called a mini-batch) and use it to update the parameters using a gradient method. Let's conduct training for the <strong class="inline">TwoLayerNet</strong> class by using the MNIST dataset (the source code is located at <strong class="inline">ch04/train_neuralnet.py</strong>):</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">from dataset.mnist import load_mnist</p>
			<p class="source-code">from two_layer_net import TwoLayerNet</p>
			<p class="source-code">(x_train, t_train), (x_test, t_test) = \</p>
			<p class="source-code">    load_mnist(normalize=True, one_hot_label=True)</p>
			<p class="source-code">train_loss_list = []</p>
			<p class="source-code"># Hyper-parameters</p>
			<p class="source-code">iters_num = 10000</p>
			<p class="source-code">train_size = x_train.shape[0]</p>
			<p class="source-code">batch_size = 100</p>
			<p class="source-code">learning_rate = 0.1</p>
			<p class="source-code">network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)</p>
			<p class="source-code">for i in range(iters_num):</p>
			<p class="source-code">    # Obtain a mini-batch</p>
			<p class="source-code">    batch_mask = np.random.choice(train_size, batch_size)</p>
			<p class="source-code">    x_batch = x_train[batch_mask]</p>
			<p class="source-code">    t_batch = t_train[batch_mask]</p>
			<p class="source-code">    # Calculate a gradient</p>
			<p class="source-code">    grad = network.numerical_gradient(x_batch, t_batch)</p>
			<p class="source-code">    # grad = network.gradient(x_batch, t_batch) # fast version!</p>
			<p class="source-code">    # Update the parameters</p>
			<p class="source-code">    for key in ('W1', 'b1', 'W2', 'b2'): </p>
			<p class="source-code">        network.params[key] -= learning_rate * grad[key]</p>
			<p class="source-code">    # Record learning progress</p>
			<p class="source-code">    loss = network.loss(x_batch, t_batch)</p>
			<p class="source-code">    train_loss_list.append(loss)</p>
			<p>Here, the size of a mini-batch is 100. Each time, 100 pieces of data (image data and correct label data) are extracted randomly from 60,000 pieces of training data. Then, gradients are obtained for the mini-batch, and the parameters are updated using <strong class="bold">stochastic gradient descent</strong> (<strong class="bold">SGD</strong>). Here, the number of updates made by a gradient method;that is, the number of iterations is 10,000. At each update, the loss function for the training data is calculated, and the value is added to the array. <em class="italics">Figure 4.11</em> shows the graph of how the value of this loss function changes.</p>
			<p><em class="italics">Figure 4.11</em> shows that, as the number of training increases, the value of the loss function decreases. It indicates that training is successful. The weight parameters of the neural network are adapting to the data gradually. The neural network is indeed learning. By being exposed to data repeatedly, it is approaching the optimal weight parameters:</p>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="image/fig04_11.jpg" alt="Figure 4.11: Transition of the loss function – the image on the left shows the transition up to 10,000 iterations, while the image on the right shows the transition up to 1,000 iterations&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.11: Transition of the loss function – the image on the left shows the transition up to 10,000 iterations, while the image on the right shows the transition up to 1,000 iterations</h6>
			<h3 id="_idParaDest-112"><a id="_idTextAnchor118"/>Using Test Data for Evaluation</h3>
			<p>The result of <em class="italics">Figure 4.11</em> shows that repeatedly training the data reduces the value of the loss function gradually. However, the value of the loss function is the value of "the loss function for the mini-batch of training data." The reduction in the value of the loss function for the training data indicates that the neural network is learning well. However, this result does not prove that it can handle a different dataset as well as this one.</p>
			<p>In neural network training, we must check whether data other than training data can be recognized correctly. We must check whether "overfitting" does not occur. Overfitting means that only the number of images contained in the training data can be recognized correctly, and those that are not contained there cannot be recognized, for example.</p>
			<p>The goal of neural network training is to obtain generalization capability. To do that, we must use data that is not contained in the training data to evaluate the generalization capability of the neural network. In the next implementation, we will record the recognition accuracy for the test data and the training data periodically during training. We will record the recognition accuracy for the test data and the training data for each epoch.</p>
			<h4>Note</h4>
			<p class="callout">An epoch is a unit. One epoch indicates the number of iterations when all the training data has been used for training. For example, let's assume that 100 mini-batches are used to learn 10,000 pieces of training data. After a stochastic gradient descent method is repeated 100 times, all the training data has been seen. In this case, <strong class="inline">100 iterations = 1 epoch</strong>.</p>
			<p>Now, we will change the previous implementation slightly to gain a correct evaluation. Here, the differences from the previous implementation are shown in bold:</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">from dataset.mnist import load_mnist</p>
			<p class="source-code">from two_layer_net import TwoLayerNet</p>
			<p class="source-code">(x_train, t_train), (x_test, t_test) = \</p>
			<p class="source-code">    load_mnist(normalize=True, one_hot_label=True)</p>
			<p class="source-code">train_loss_list = []</p>
			<p class="source-code"><strong class="inline">train_acc_list = []</strong></p>
			<p class="source-code"><strong class="inline">test_acc_list = []</strong></p>
			<p class="source-code"><strong class="inline"># Number of iterations per epoch</strong></p>
			<p class="source-code"><strong class="inline">iter_per_epoch = max(train_size / batch_size, 1)</strong></p>
			<p class="source-code"># Hyper-parameters</p>
			<p class="source-code">iters_num = 10000</p>
			<p class="source-code">batch_size = 100</p>
			<p class="source-code">learning_rate = 0.1</p>
			<p class="source-code">network = TwoLayerNet(input_size=784, hidden_size=50, </p>
			<p class="source-code">output_size=10)</p>
			<p class="source-code">for i in range(iters_num):</p>
			<p class="source-code">    # Obtain a mini-batch</p>
			<p class="source-code">    batch_mask = np.random.choice(train_size, batch_size) </p>
			<p class="source-code">    x_batch = x_train[batch_mask]</p>
			<p class="source-code">    t_batch = t_train[batch_mask]</p>
			<p class="source-code">    # Calculate a gradient</p>
			<p class="source-code">    grad = network.numerical_gradient(x_batch, t_batch) </p>
			<p class="source-code">    # grad = network.gradient(x_batch, t_batch) # Quick version!</p>
			<p class="source-code">    # Update the parameters</p>
			<p class="source-code">    for key in ('W1', 'b1', 'W2', 'b2'): </p>
			<p class="source-code">        network.params[key] -= learning_rate * grad[key]</p>
			<p class="source-code">    loss = network.loss(x_batch, t_batch)</p>
			<p class="source-code">    train_loss_list.append(loss)</p>
			<p class="source-code"><strong class="inline">    # Calculate recognition accuracy for each epoch</strong></p>
			<p class="source-code"><strong class="inline">    if i % iter_per_epoch == 0:</strong></p>
			<p class="source-code"><strong class="inline">        train_acc = network.accuracy(x_train, t_train)</strong></p>
			<p class="source-code"><strong class="inline">        test_acc = network.accuracy(x_test, t_test)</strong></p>
			<p class="source-code"><strong class="inline">        train_acc_list.append(train_acc)</strong></p>
			<p class="source-code"><strong class="inline">        </strong><strong class="inline">test_acc_list.append(test_acc)</strong></p>
			<p class="source-code"><strong class="inline">        print("train acc, test acc | " + str(train_acc) + " , " + str(test_acc))</strong></p>
			<p>In the preceding example, the recognition accuracy is calculated for all the training and test data and the results are recorded for each epoch. The recognition accuracy is calculated for each epoch because it takes time if it is calculated repeatedly in a <strong class="inline">for</strong> statement. Also, we do not need to record recognition accuracy frequently (all we need is the approximate transition of recognition accuracy). Therefore, the transition of recognition accuracy is recorded for each epoch of training data.</p>
			<p>Now, let's show the results of the preceding code in a graph:</p>
			<div>
				<div id="_idContainer149" class="IMG---Figure">
					<img src="image/fig04_12.jpg" alt="Figure 4.12: Transition of recognition accuracy for training data and test data. The horizontal &#13;&#10;axis shows the epochs&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 4.12: Transition of recognition accuracy for training data and test data. The horizontal axis shows the epochs</h6>
			<p>In <em class="italics">Figure 4.12</em>, the solid line shows the recognition accuracy of the training data, while the dashed line shows that of the test data. As you can see, as the number of epochs increases (training advances), the recognition accuracies for both the training data and the test data improve. Here, we can see that the two recognition accuracies are almost the same as the two lines mostly overlap. This indicates that overfitting did not occur here.</p>
			<h2 id="_idParaDest-113"><a id="_idTextAnchor119"/>Summary</h2>
			<p>This chapter described neural network training. First, we introduced a <strong class="inline">score</strong> called a loss function so that a neural network can learn. The goal of neural network training is to discover the weight parameters that lead to the smallest value of the loss function. Then, we learned how to use the gradient of a function, called the gradient method, to discover the smallest loss function value. This chapter covered the following points:</p>
			<ul>
				<li>In machine learning, we use training data and test data.</li>
				<li>Training data is used for training, while test data is used to evaluate the generalization capability of the trained model.</li>
				<li>A loss function is used as a score in neural network training. Weight parameters are updated so that the value of the loss function will decrease.</li>
				<li>To update the weight parameters, their gradients are used to update their values in the gradient direction repeatedly.</li>
				<li>Calculating a derivative based on the difference when very small values are provided is called numerical differentiation.</li>
				<li>You can use numerical differentiation to obtain the gradients for the weight parameters.</li>
				<li>Numerical differentiation takes time to calculate, but its implementation is easy. On the other hand, backpropagation, which will be described in the next chapter, is slightly complicated, but it can calculate gradients quickly.</li>
			</ul>
		</div>
		<div>
			<div id="_idContainer151" class="Content">
			</div>
		</div>
		<div>
			<div id="_idContainer152" class="Content">
			</div>
		</div>
		<div>
			<div id="_idContainer153" class="Content">
			</div>
		</div>
		<div>
			<div id="_idContainer154" class="Content">
			</div>
		</div>
		<div>
			<div id="_idContainer155" class="Content">
			</div>
		</div>
	</body></html>