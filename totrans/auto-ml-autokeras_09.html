<html><head></head><body>
		<div id="_idContainer084">
			<h1 id="_idParaDest-107"><em class="italic"><a id="_idTextAnchor109"/>Chapter 7</em>: Sentiment Analysis Using AutoKeras</h1>
			<p>Let's start by defining the unusual term in the title. <strong class="bold">Sentiment analysis</strong> is a term that's widely used in text classification and it is basically about using <strong class="bold">natural language processing </strong>(<strong class="bold">NLP</strong>) in conjunction with <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) to interpret and classify emotions in text.</p>
			<p>To get an idea of this, let's imagine the task of determining whether a review for a film is positive or negative. You could do this yourself just by reading it, right? However, if our boss sends us a list of 1,000 movie reviews for tomorrow, things become complicated. That's where sentiment analysis becomes an interesting option.</p>
			<p>In this chapter, we will use a text classifier to extract sentiments from text data. Most of the concepts of text classification were already explained in <a href="B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063"><em class="italic">Chapter 4</em></a>, <em class="italic">Image Classification and Regression Using AutoKeras</em>, so in this chapter, we will apply them in a practical way by implementing a sentiment predictor. However, before we do that, we will look at the technical requirements we'll need to start working on it.</p>
			<p>Specifically, the following topics will be covered in this chapter:</p>
			<ul>
				<li>Creating a sentiment analyzer</li>
				<li>Creating the classifier</li>
				<li>Evaluating the model</li>
				<li>Visualizing the model</li>
				<li>Analyzing the sentiment in specific sentences </li>
			</ul>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor110"/>Technical requirements </h1>
			<p>All the code examples in this book are available as Jupyter notebooks that can be downloaded from <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras">https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras</a>.</p>
			<p>Since code cells can be executed, each notebook can be self-installed; you just need to add the code snippet with the requirements you need. For this reason, at the beginning of each notebook, there is a code cell for environment setup that installs AutoKeras and its dependencies.</p>
			<p>So, to run the code examples for this chapter, you only need a computer with Ubuntu Linux as your OS and install the Jupyter Notebook with the following code:</p>
			<p class="source-code">$ apt-get install python3-pip jupyter-notebook</p>
			<p>Alternatively, you can also run these notebooks using Google Colaboratory, in which case you will only need a web browser. See the <em class="italic">AutoKeras with Google Colaboratory</em> section of <a href="B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with AutoKeras</em>, for more details. Furthermore, in the <em class="italic">Installing AutoKeras</em> section of that chapter, you will find other installation options.</p>
			<p>Now, let's put what we've learned into practice by looking at some practical examples.</p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor111"/>Creating a sentiment analyzer</h1>
			<p>The model we are <a id="_idIndexMarker308"/>going to create will be a binary classifier for sentiments (1=Positive/0=Negative) from the IMDb sentiments dataset. This is a dataset for binary sentiment classification that contains a set of 25,000 sentiment labeled movie reviews for training and 25,000 for testing:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B16953_07_01.jpg" alt="Figure 7.1 – Example of sentiment analysis being used on two samples"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – Example of sentiment analysis being used on two samples</p>
			<p>Similar to the Reuters example from <a href="B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063"><em class="italic">Chapter 4</em></a>, <em class="italic">Image Classification and Regression Using AutoKeras</em>, each review is encoded as a list of word indexes (integers). For convenience, words are indexed by their overall frequency in the dataset. So, for instance, the integer <em class="italic">3</em> encodes the third most frequent word in the data. </p>
			<p>The notebook that contains the complete source code can be found at <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb">https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb</a>.</p>
			<p>Now, let's have a <a id="_idIndexMarker309"/>look at the relevant cells of the notebook in detail:</p>
			<ul>
				<li><strong class="bold">Installing AutoKeras</strong>: As we've mentioned in other examples, this snippet at the top of the notebook is responsible for installing AutoKeras and its dependencies using the pip package manager:<p class="source-code">!pip3 install autokeras</p></li>
				<li><strong class="bold">Importing the necessary packages</strong>: The following lines load TensorFlow, the built-in Keras Reuters dataset, NumPy, and AutoKeras as needed dependencies for this project:<p class="source-code">import tensorflow as tf</p><p class="source-code">import numpy as np</p><p class="source-code">import autokeras as ak</p></li>
				<li><strong class="bold">Creating the datasets</strong>: First, we must load and preprocess the IMDb sentiment dataset by using the <strong class="source-inline">imdb_sentiment_raw</strong> function. Have a look at the code in the notebook for more details:<p class="source-code">(x_train, y_train), (x_test, y_test) = imdb_sentiment_raw()</p><p class="source-code">print(x_train.shape)  # (25000,)</p><p class="source-code">print(y_train.shape)  # (25000, 1)</p><p>Here is the output:</p><p class="source-code">(25000,)</p><p class="source-code">(25000, 1)</p></li>
				<li><strong class="bold">Showing some samples</strong>: Next, we can print some words from the first sample to get an idea of what it contains:<p class="source-code">print(x_train[0][:50])</p><p>Here is the output:</p><p class="source-code">&lt;START&gt; vs from it as must exporters ability whole</p></li>
			</ul>
			<p>To see this <a id="_idIndexMarker310"/>more clearly, let's render a word cloud with the most frequent words. A word cloud (also known <a id="_idIndexMarker311"/>as a tag cloud) is a text-based data visualization technique, in which words are displayed in different sizes based on how often they appear in the text:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B16953_07_02.jpg" alt="Figure 7.2 – A word cloud containing the most frequent words of the dataset"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – A word cloud containing the most frequent words of the dataset</p>
			<p>Now, it's time to create the classifier model.</p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor112"/>Creating the sentiment predictor</h1>
			<p>Now, we will use the AutoKeras <strong class="source-inline">TextClassifier</strong> to find the best classification model. Just <a id="_idIndexMarker312"/>for this example, we will set <strong class="source-inline">max_trials</strong> (the maximum number of different Keras models to try) to <strong class="source-inline">2</strong>; we do not need to set the epochs parameter; instead, we must define an <strong class="source-inline">EarlyStopping</strong> callback of <strong class="source-inline">2</strong> epochs so that the training process stops if the validation loss does not improve in two consecutive epochs:</p>
			<p class="source-code">clf = ak.TextClassifier(max_trials=2)</p>
			<p class="source-code">cbs = [tf.keras.callbacks.EarlyStopping(patience=2)]</p>
			<p>Let's run the training process and search for the optimal classifier for the training dataset: </p>
			<p class="source-code">clf.fit(x_train, y_train, callbacks=cbs)</p>
			<p>Here is the output:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B16953_07_03.jpg" alt="Figure 7.3 – Notebook output of text classifier training"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3 – Notebook output of text classifier training</p>
			<p>The previous output shows that the accuracy of the training dataset is increasing. </p>
			<p>As we can see, we are getting a loss of <strong class="source-inline">0.28</strong> in the validation set. This isn't bad just for a few minutes of training. We have limited the search to two architectures (<strong class="source-inline">max_trials = 2</strong>). As with the rest of the examples, increasing this number would give us a more accurate model, although it would also take longer to finish.</p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor113"/>Evaluating the model</h1>
			<p>Now, it's <a id="_idIndexMarker313"/>time to evaluate the best model with the testing dataset:</p>
			<p class="source-code">clf.evaluate(x_test, y_test)</p>
			<p>Here is the output:</p>
			<p class="source-code">782/782 [==============================] - 41s 52ms/step - loss: 0.3118 - accuracy: 0.8724</p>
			<p class="source-code"> </p>
			<p class="source-code">[0.31183066964149475, 0.8723599910736084]</p>
			<p>As we can see, <strong class="source-inline">0.8724</strong> is a really good final prediction accuracy for the time we've invested.</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor114"/>Visualizing the model</h1>
			<p>Now, we can view a little <a id="_idIndexMarker314"/>summary of the architecture for the best generated model:</p>
			<p class="source-code">model = clf.export_model()</p>
			<p class="source-code">model.summary()</p>
			<p>Here is the output:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B16953_07_04.jpg" alt="Figure 7.4 – Best model architecture summary"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – Best model architecture summary</p>
			<p>As we can <a id="_idIndexMarker315"/>see, AutoKeras, as we did in the classification example in <a href="B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063"><em class="italic">Chapter 4</em></a>, <em class="italic">Image Classification and Regression Using AutoKeras</em>, has chosen a convolution model (Conv1D) for this task. As we explained in the beginning of that chapter, this kind of architecture works really well when the order of the input sentences is not important for the prediction; there are no correlations between the different movie reviews.</p>
			<p>Here is a visual representation of this:</p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B16953_07_05.jpg" alt="Figure 7.5 – Best model architecture visualization graph"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.5 – Best model architecture visualization graph</p>
			<p>As you already know, generating the models and choosing the best one is done by AutoKeras automatically, but let's explain these blocks in more detail. </p>
			<p>Each block represents a layer and the output of each is connected to the input of the next except for the first <a id="_idIndexMarker316"/>block, whose input is the text, and the last block, whose output is the predicted number. The blocks before Conv1D are all data preprocessing blocks and they are in charge of vectorizing the text generating embeddings to feed this Conv1D block, as well as reducing the dimension of the filters through the max pooling layer. Notice that AutoKeras has also added several dropout blocks to reduce overfitting.</p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor115"/>Analyzing the sentiment in specific sentences </h1>
			<p>Now, let's <a id="_idIndexMarker317"/>take a look at some predicted samples from the test set:</p>
			<p class="source-code">import tensorflow as tf</p>
			<p class="source-code">tf.get_logger().setLevel('ERROR')</p>
			<p class="source-code">def get_sentiment(val):</p>
			<p class="source-code">    return "Positive" if val == 1 else "Negative"</p>
			<p class="source-code">for i in range(10):</p>
			<p class="source-code">    print(x_test[i])</p>
			<p class="source-code">    print("label: %s, prediction: %s" % (get_sentiment(y_test[i][0]), get_sentiment(clf.predict(x_test[i:i+1])[0][0])))</p>
			<p>Here is the output of the preceding code:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B16953_07_06.jpg" alt="Figure 7.6 – Some predictions based on the first 10 sentences of the test dataset&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.6 – Some predictions based on the first 10 sentences of the test dataset</p>
			<p>As you can see, the <a id="_idIndexMarker318"/>model predictions match every label for the first 10 samples in the test dataset.</p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor116"/>Summary</h1>
			<p>In this chapter, we learned about the importance of sentiment analysis in the real world, as well as how to extract sentiments from text data and how to implement a sentiment predictor in just a few lines of code.</p>
			<p>In the next chapter, we will cover a very interesting topic: we will use AutoKeras to classify news topics based on their content by using a text classifier. </p>
		</div>
	</body></html>