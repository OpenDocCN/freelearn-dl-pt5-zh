["```py\npip install numpy pandas scikit-learn\n```", "```py\nwget https://github.com/PacktPublishing/The-Regularization-Cookbook/blob/main/chapter_02/train.csv\n```", "```py\n    import pandas as pd\n    ```", "```py\n    # Load the data as a DataFrame\n    ```", "```py\n    df = pd.read_csv('train.csv')\n    ```", "```py\n    # Display the first 5 rows of the dataset\n    ```", "```py\n    df.head()\n    ```", "```py\n   PassengerId  Survived  Pclass  \\\n0        1            0         3\n1        2            1         1\n2        3            1         3\n3        4            1         1\n4        5            0         3\n      Name                      Sex   Age     SibSp  \\\n0   Braund, Mr. Owen Harris     male  22.0       1\n1  Cumings, Mrs. John Bradley (Florence Briggs Th...\n                               female  38.0        1\n2  Heikkinen, Miss. Laina  female  26.0        0\n3  Futrelle, Mrs. Jacques Heath (Lily May Peel)\n                            female  35.0        1\n4  Allen, Mr. William Henry     male  35.0        0\n Parch      Ticket   Fare   Cabin        Embarked\n0  0         A/5   21171   7.2500   NaN           S\n1  0       PC 17599  71.2833   C85       C\n2  0      STON/O2\\. 3101282   7.9250   NaN       S\n3  0        113803  53.1000  C123           S\n4  0        373450   8.0500   NaN    S\n```", "```py\n    # Import the train_test_split function\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n    # Split the data\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n    ```", "```py\n        df.drop(columns=['Survived']), df['Survived'],\n    ```", "```py\n        test_size=0.2, stratify=df['Survived'],\n    ```", "```py\n        random_state=0)\n    ```", "```py\n    from sklearn.impute import SimpleImputer\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    ```", "```py\n    quanti_columns = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n    ```", "```py\n    # Get the quantitative columns\n    ```", "```py\n    X_train_quanti = X_train[quanti_columns]\n    ```", "```py\n    X_test_quanti = X_test[quanti_columns]\n    ```", "```py\n    # Impute missing quantitative values with mean feature value\n    ```", "```py\n    quanti_imputer = SimpleImputer(strategy='mean')\n    ```", "```py\n    # Fit and impute the training set\n    ```", "```py\n    X_train_quanti = quanti_imputer.fit_transform(X_train_quanti)\n    ```", "```py\n    # Just impute the test set\n    ```", "```py\n    X_test_quanti = quanti_imputer.transform(X_test_quanti)\n    ```", "```py\n    # Instantiate the standard scaler\n    ```", "```py\n    scaler = StandardScaler()\n    ```", "```py\n    # Fit and transform the training set\n    ```", "```py\n    X_train_quanti = scaler.fit_transform(X_train_quanti)\n    ```", "```py\n    # Just transform the test set\n    ```", "```py\n    X_test_quanti = scaler.transform(X_test_quanti)\n    ```", "```py\n# Display the number of missing data for each column\nX_train[quanti_columns].isna().sum()\n```", "```py\nPclass        0\nAge         146\nFare           0\nSibSp         0\nParch         0\n```", "```py\n    import numpy as np\n    ```", "```py\n    from sklearn.impute import SimpleImputer\n    ```", "```py\n    from sklearn.preprocessing import OneHotEncoder\n    ```", "```py\n    quali_columns = ['Sex', 'Embarked']\n    ```", "```py\n    # Get the quantitative columns\n    ```", "```py\n    X_train_quali = X_train[quali_columns]\n    ```", "```py\n    X_test_quali = X_test[quali_columns]\n    ```", "```py\n    # Impute missing qualitative values with most frequent feature value\n    ```", "```py\n    quali_imputer =SimpleImputer(strategy='most_frequent')\n    ```", "```py\n    # Fit and impute the training set\n    ```", "```py\n    X_train_quali = quali_imputer.fit_transform(X_train_quali)\n    ```", "```py\n    # Just impute the test set\n    ```", "```py\n    X_test_quali = quali_imputer.transform(X_test_quali)\n    ```", "```py\n        # Instantiate the encoder\n        ```", "```py\n        encoder=OneHotEncoder(drop='first', handle_unknown='ignore')\n        ```", "```py\n    # Fit and transform the training set\n    ```", "```py\n    X_train_quali = encoder.fit_transform(X_train_quali).toarray()\n    ```", "```py\n    # Just encode the test set\n    ```", "```py\n    X_test_quali = encoder.transform(X_test_quali).toarray()\n    ```", "```py\n    # Concatenate the data back together\n    ```", "```py\n    X_train = np.concatenate([X_train_quanti,\n    ```", "```py\n        X_train_quali], axis=1)\n    ```", "```py\n    X_test = np.concatenate([X_test_quanti, X_test_quali], axis=1)\n    ```", "```py\nimport pickle\npickle.dump((X_train, X_test, y_train, y_test),\n    open('prepared_titanic.pkl', 'wb'))\n```", "```py\n    from sklearn.linear_model import LogisticRegression\n    ```", "```py\n    # Instantiate the model\n    ```", "```py\n    lr = LogisticRegression()\n    ```", "```py\n    # Fit on the training data\n    ```", "```py\n    lr.fit(X_train, y_train)\n    ```", "```py\n    # Compute and store predictions on the test data\n    ```", "```py\n    y_pred = lr.predict(X_test)\n    ```", "```py\nfrom sklearn.metrics import accuracy_score\n# Compute the accuracy on test of our model\nprint('accuracy on test set:', accuracy_score(y_pred,\n    y_test))\n```", "```py\naccuracy on test set: 0.7877094972067039\n```", "```py\n# Define the hyperparameters we want to test\nparam_grid = { 'C': [0.01, 0.03, 0.1] }\n```", "```py\n    # Instantiate the grid search object\n    ```", "```py\n    grid = GridSearchCV(\n    ```", "```py\n        LogisticRegression(),\n    ```", "```py\n        param_grid,\n    ```", "```py\n        scoring='accuracy',\n    ```", "```py\n        cv=5,\n    ```", "```py\n        return_train_score=True\n    ```", "```py\n    )\n    ```", "```py\n    # Fit and wait\n    ```", "```py\n    grid.fit(X_train, y_train)\n    ```", "```py\n    GridSearchCV(cv=5, estimator=LogisticRegression(),\n    ```", "```py\n        param_grid={'C': [0.01, 0.03, 0.1]},\n    ```", "```py\n        return_train_score=True, scoring='accuracy')\n    ```", "```py\n    y_pred = grid.predict(X_test)\n    ```", "```py\n    print('Hyperparameter optimized accuracy:',\n    ```", "```py\n        accuracy_score(y_pred, y_test))\n    ```", "```py\nHyperparameter optimized accuracy: 0.781229050279329\n```"]