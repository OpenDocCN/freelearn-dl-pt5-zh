- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep Learning Fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will introduce **deep learning** (**DL**) and **deep neural
    networks** (**DNNs**) – that is, **neural networks** (**NNs**) with multiple hidden
    layers. You might be wondering what the point of using more than one hidden layer
    is, given the universal approximation theorem. This is in no way a naive question,
    and for a long time, NNs were used in that way.
  prefs: []
  type: TYPE_NORMAL
- en: Without going into too much detail, one reason is that approximating a complex
    function might require a huge number of units in the hidden layer, making it impractical
    to use. There is also another, more important, reason for using deep networks,
    which is not directly related to the number of hidden layers, but to the level
    of learning. A deep network does not simply learn to predict output *Y* given
    input, *X*; it also understands the basic features of the input. It’s able to
    learn abstractions of features of input samples, understand the basic characteristics
    of the samples, and make predictions based on those characteristics. This level
    of abstraction is missing in other basic **machine learning** (**ML**) algorithms
    and shallow NNs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to DL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fundamental DL concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training deep networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications of DL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing popular DL libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ll implement the example in this chapter using Python, PyTorch, and Keras
    as part of **TensorFlow** (**TF**). If you don’t have an environment set up with
    these tools, fret not – the example is available as a Jupyter notebook on Google
    Colab. You can find the code examples in this book’s GitHub repository: [https://github.com/PacktPublishing/Python-Deep-Learning-Third-Edition/tree/main/Chapter03](https://github.com/PacktPublishing/Python-Deep-Learning-Third-Edition/tree/main/Chapter03).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to DL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In 2012, Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton published a milestone
    paper titled *ImageNet Classification with Deep Convolutional Neural Networks*
    ([https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)).
    The paper describes their use of NNs to win the ImageNet competition of the same
    year, which we mentioned in [*Chapter 2*](B19627_02.xhtml#_idTextAnchor047). At
    the end of their paper, they noted that the network’s performance degrades even
    if a single layer is removed. Their experiments demonstrated that removing any
    of the middle layers resulted in an about 2% top-1 accuracy loss of the model.
    They concluded that network depth is important for the performance of the network.
    The basic question is: what makes the network’s depth so important?'
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical English saying is a picture is worth a thousand words. Let’s use
    this approach to understand what DL is. We’ll use images from the highly cited
    paper *Convolutional Deep Belief Networks for Scalable Unsupervised Learning of
    Hierarchical Representations* ([https://ai.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf](https://ai.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf)).
    Here, the authors trained an NN with pictures of different categories of either
    objects or animals. The following figure shows how the different layers of the
    network learn different characteristics of the input data. In the first layer,
    the network learns to detect some small basic features, such as lines and edges,
    which are common for all images in all categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – The ﬁrst layer weights (top) and the second layer weights (bottom)
    after training](img/B19627_03_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – The ﬁrst layer weights (top) and the second layer weights (bottom)
    after training
  prefs: []
  type: TYPE_NORMAL
- en: 'But the next layers, which we can see in the following figure, combine those
    lines and edges to compose more complex features that are specific to each category.
    In the first row of the bottom-left image, we can see how the network can detect
    different features of human faces, such as eyes, noses, and mouths. In the case
    of cars, these would be wheels, doors, and so on, as seen in the second image
    from the left in the following figure. These features are **abstract** – that
    is, the network has learned the generic shape of a feature (such as a mouth or
    a nose) and can detect this feature in the input data, despite the variations
    it might have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Columns 1 to 4 represent the second-layer (top) and third-layer
    (bottom) weights learned for a speciﬁc object category (class). Column 5 represents
    the weights learned for a mixture of four object categories (faces, cars, airplanes,
    and motorbikes)](img/B19627_03_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – Columns 1 to 4 represent the second-layer (top) and third-layer
    (bottom) weights learned for a speciﬁc object category (class). Column 5 represents
    the weights learned for a mixture of four object categories (faces, cars, airplanes,
    and motorbikes)
  prefs: []
  type: TYPE_NORMAL
- en: In the second row of the preceding figure, we can see how, in the deeper layers,
    the network combines these features in even more complex ones, such as faces and
    whole cars. One strength of DNNs is that they can learn these high-level abstract
    representations by themselves, deducting them from the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss these properties of DNNs in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamental DL concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 1801, Joseph Marie Charles invented the **Jacquard loom**. Charles was not
    a scientist, but simply a merchant. The Jacquard loom used a set of punched cards,
    where each card represented a pattern to be reproduced on the loom. At the same
    time, each card was an abstract representation of that pattern. Punched cards
    have been used, for example, in the tabulating machine invented by Herman Hollerith
    in 1890, or in the first computers as a means to input code. In the tabulating
    machine, the cards were simply abstractions of samples to be fed into the machine
    to calculate statistics on a population. But in the Jacquard loom, their use was
    subtler, and each card represented the abstraction of a pattern that could be
    combined with others to create more complex patterns. The punched card is an abstract
    representation of a feature of reality, the final weaved design.
  prefs: []
  type: TYPE_NORMAL
- en: In a way, the Jacquard loom sowed the seeds of what DL is today, the definition
    of reality through the representations of its features. A DNN does not simply
    recognize what makes a cat a cat, or a squirrel a squirrel, but it understands
    what features are present in a cat and a squirrel, respectively. It learns to
    design a cat or a squirrel using those features. If we were to design a weaving
    pattern in the shape of a cat using a Jacquard loom, we would need to use punched
    cards that have whiskers on the nose, such as those of a cat, and an elegant and
    slender body. Conversely, if we were to design a squirrel, we would need to use
    a punched card that makes a furry tail. A deep network that learns basic representations
    of its output can make classifications using the assumptions it has made. For
    example, if there is no furry tail, it will probably not be a squirrel, but rather
    a cat. In this way, the amount of information the network learns is much more
    complete and robust, and the most exciting part is that DNNs learn to do this
    automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Feature learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To illustrate how DL works, let’s consider the task of recognizing a simple
    geometric figure, such as a cube, as seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – An abstraction of an NN representing a cube. Diﬀerent layers
    encode features with diﬀerent levels of abstraction](img/B19627_03_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – An abstraction of an NN representing a cube. Diﬀerent layers encode
    features with diﬀerent levels of abstraction
  prefs: []
  type: TYPE_NORMAL
- en: The cube is composed of edges (or lines), which intersect in vertices. Let’s
    say that each possible point in the three-dimensional space is associated with
    a unit (forget for a moment that this will require an infinite number of units).
    All the points/units are in the first (input) layer of a multilayer feedforward
    network. An input point/unit is active if the corresponding point lies on a line.
    The points/units that lie on a common line (edge) have strong positive connections
    to a single common edge/unit in the next layer. Conversely, they have negative
    connections to all other units in the next layer. The only exceptions are the
    units that lie on the vertices. Each such unit lies simultaneously on three edges
    and is connected to its three corresponding units in the subsequent layer.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have two hidden layers, with different levels of abstraction – the first
    for points and the second for edges. However, this is not enough to encode a whole
    cube in the network. Let’s try this with another layer for vertices. Here, each
    three active edges/units of the second layer, which form a vertex, have a significant
    positive connection to a single common vertex/unit of the third layer. Since an
    edge of the cube forms two vertices, each edge/unit will have positive connections
    to two vertices/units and negative connections to all others. Finally, we’ll introduce
    the last hidden layer (the cube). The four vertices/units forming the cube will
    have positive connections to a single cube/unit from the cube/layer.
  prefs: []
  type: TYPE_NORMAL
- en: This cube representation example is oversimplified, but we can draw several
    conclusions from it. One of them is that DNNs lend themselves well to hierarchically
    organized data. For example, an image consists of pixels, which form lines, edges,
    regions, and so on. This is also true for speech, where the building blocks are
    called **phonemes**, as well as text, where we have characters, words, and sentences.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we dedicated layers to specific cube features deliberately,
    but in practice, we wouldn’t do that. Instead, a deep network will “discover”
    features automatically during training. These features might not be immediately
    obvious and, in general, wouldn’t be interpretable by humans. Also, we wouldn’t
    know the level of the features encoded in the different layers of the network.
    Our example is more akin to classic ML algorithms, where the user has to use their
    own experience to select what they think are the best features. This process is
    called **feature engineering**, and it can be labor-intensive and time-consuming.
    Allowing a network to automatically discover features is not only easier, but
    those features are highly abstract, which makes them less sensitive to noise.
    For example, human vision can recognize objects of different shapes, sizes, in
    different lighting conditions, and even when their view is partly obscured. We
    can recognize people with different haircuts and facial features, even when they
    wear a hat or a scarf that covers their mouth. Similarly, the abstract features
    the network learns will help it recognize faces better, even in more challenging
    conditions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll discuss some of the reasons DL has become so popular.
  prefs: []
  type: TYPE_NORMAL
- en: The reasons for DL’s popularity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’ve followed ML for some time, you may have noticed that many DL algorithms
    are not new. **Multilayer perceptrons** (**MLPs**) have been around for nearly
    50 years. Backpropagation was discovered a couple of times but finally gained
    recognition in 1986\. Yann LeCun, a famous computer scientist, perfected his work
    on convolutional networks in the 1990s. In 1997, Sepp Hochreiter and Jürgen Schmidhuber
    invented long short-term memory, a type of recurrent NN still in use today. In
    this section, we’ll try to understand why we have AI summer now, and why we only
    had AI winters ([https://en.wikipedia.org/wiki/AI_winter](https://en.wikipedia.org/wiki/AI_winter))
    before.
  prefs: []
  type: TYPE_NORMAL
- en: The first reason is that today, we have a lot more data than in the past. The
    rise of the internet and software in different industries has generated a lot
    of computer-accessible data. We also have more benchmark datasets, such as ImageNet.
    With this comes the desire to extract value from that data by analyzing it. And,
    as we’ll see later, DL algorithms work better when they are trained with a lot
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: The second reason is the increased computing power. This is most visible in
    the drastically increased processing capacity of **graphical processing units**
    (**GPUs**). NNs are organized in such a way as to take advantage of this parallel
    architecture. Let’s see why. As we learned in [*Chapter 2*](B19627_02.xhtml#_idTextAnchor047),
    units from a network layer are not connected to units from the same layer. We
    also learned that we could represent many layer operations as matrix multiplications.
    Matrix multiplication is embarrassingly parallel (trust me, this is a term – you
    can Google it!). The computation of each output cell is not related to the computation
    of any other output cell. Therefore, we can compute all of the outputs in parallel.
    Not coincidentally, GPUs are well suited for highly parallel operations like this.
    On the one hand, a GPU has a high number of computational cores compared to a
    **central processing unit** (**CPU**). Even though a CPU core is faster than a
    GPU one, we can still compute a lot more output cells in parallel. But what’s
    even more important is that GPUs are optimized for memory bandwidth, while CPUs
    are optimized for latency. This means that a CPU can fetch small chunks of memory
    very quickly but will be slow when it comes to fetching large chunks. The GPU
    does the opposite. For matrix multiplication in a deep network with a lot of wide
    layers, bandwidth becomes the bottleneck, not latency. In addition, the L1 cache
    of the GPU is much faster than the L1 cache for the CPU and is also larger. The
    L1 cache represents the memory of the information that the program is likely to
    use next, and storing this data can speed up the process. Much of the memory gets
    reused in DNNs, which is why L1 cache memory is important.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, *Deep neural networks*, we’ll give a more precise definition
    of the key NN architectures that will be thoroughly introduced in the coming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Deep neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We could define DL as a class of ML techniques, where information is processed
    in hierarchical layers to understand representations and features from data in
    increasing levels of complexity. In practice, all DL algorithms are NNs, which
    share some common basic properties. They all consist of a graph of interconnected
    operations, which operate with input/output tensors. Where they differ is network
    architecture (or the way units are organized in the network), and sometimes in
    the way they are trained. With that in mind, let’s look at the main classes of
    NNs. The following list is not exhaustive, but it represents most NN types in
    use today:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multilayer perceptron** (**MLP**): An NN with feedforward propagation, fully
    connected layers, and at least one hidden layer. We introduced MLPs in [*Chapter
    2*](B19627_02.xhtml#_idTextAnchor047).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convolutional neural network** (**CNN**): A CNN is a feedforward NN with
    several types of special layers. For example, convolutional layers apply a filter
    to the input image (or sound) by sliding that filter all across the incoming signal,
    to produce an *n*-dimensional activation map. There is some evidence that units
    in CNNs are organized similarly to how biological cells are organized in the visual
    cortex of the brain. We’ve mentioned CNNs several times so far, and that’s not
    a coincidence – today, they outperform all other ML algorithms on many computer
    vision and NLP tasks. We’ll discuss CNNs in [*Chapter 4*](B19627_04.xhtml#_idTextAnchor107).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent neural network** (**RNN**): This type of NN has an internal state
    (or memory), which is based on all, or part of, the input data that’s already
    been fed to the network. The output of a recurrent network is a combination of
    its internal state (memory of inputs) and the latest input sample. At the same
    time, the internal state changes to incorporate newly input data. Because of these
    properties, recurrent networks are good candidates for tasks that work on sequential
    data, such as text or time series data. We’ll discuss recurrent networks in [*Chapter
    6*](B19627_06.xhtml#_idTextAnchor185).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transformer**: Like RNNs, the transformer is suited to work with sequential
    data. It uses a mechanism called **attention**, which allows it *direct simultaneous
    access* to all elements of the input sequence. This is unlike an RNN, which processes
    the sequence elements one by one and updates its internal state after each element.
    As we’ll see in [*Chapter 7*](B19627_07.xhtml#_idTextAnchor202), the attention
    mechanism has several major advantages over the classic RNNs. Because of this,
    in recent years, transformers have superseded RNNs in many tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autoencoders**: As we mentioned in [*Chapter 1*](B19627_01.xhtml#_idTextAnchor016),
    autoencoders are a class of unsupervised learning algorithms, in which the output
    shape is the same as the input, which allows the network to better learn basic
    representations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we’ve outlined the major types of DNNs, let’s discuss how to train
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Training deep neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Historically, the scientific community has understood that deeper networks have
    greater representational power compared to shallow ones. However, there were various
    challenges in training networks with more than a few hidden layers. We now know
    that we can successfully train DNNs using a combination of gradient descent and
    backpropagation, just as we discussed in [*Chapter 2*](B19627_02.xhtml#_idTextAnchor047).
    In this section, we’ll see how to improve them so that we can solve some of the
    problems that exist uniquely for DNNs and not shallow NNs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first edition of this book included networks such as **Restricted Boltzmann
    Machines** (**RBMs**) and **Deep Belief Networks** (**DBNs**). They were popularized
    by Geoffrey Hinton, a Canadian scientist, and one of the most prominent DL researchers.
    Back in 1986, he was also one of the inventors of backpropagation. RBMs are a
    special type of generative NN, where the units are organized into two layers,
    namely visible and hidden. Unlike feedforward networks, the data in an RBM can
    flow in both directions – from visible to hidden units, and vice versa. In 2002,
    Prof. Hinton introduced **contrastive divergence**, which is an unsupervised algorithm
    for training RBMs. In 2006, he introduced **deep belief networks** (**DBNs**),
    which are DNNs that are formed by stacking multiple RBMs. Thanks to their novel
    training algorithm, it was possible to create a DBN with more hidden layers than
    had previously been possible. But even with contrastive divergence, training a
    DBN is not easy. It is a two-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we have to train each RBM with contrastive divergence, and gradually
    stack them on top of each other. This phase is called **pre-training**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In effect, pre-training serves as a sophisticated weight initialization algorithm
    for the next phase, called **fine-tuning**. With fine-tuning, we transform the
    DBN into a regular MLP and continue training it using supervised backpropagation
    and gradient descent, in the same way as we saw in [*Chapter 2*](B19627_02.xhtml#_idTextAnchor047).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Thanks to some algorithmic advances, it’s now possible to train deep networks
    using plain old backpropagation, thus effectively eliminating the pre-training
    phase. These advances rendered DBNs and RBMs obsolete. They are, without a doubt,
    interesting from a research perspective, but they are rarely used in practice
    anymore and we’ll omit them from this edition.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss the algorithmic advances that made training of NNs with
    backpropagation possible.
  prefs: []
  type: TYPE_NORMAL
- en: Improved activation functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'But why is training deep networks so hard? One of the main challenges that
    pre-training solved is the so-called **vanishing gradients** problem. To understand
    it, we’ll assume that we’ll use backpropagation to train a regular MLP with multiple
    hidden layers and logistic sigmoid activation at each layer. Let’s focus on the
    sigmoid function (the same applies to tanh). As a reminder, it is computed as
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext>/</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math>](img/233.png)![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext>/</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math>](img/234.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Logistic sigmoid (uninterrupted) and its derivative (interrupted)
    (left); consecutive sigmoid activations, which “squash” the data (right)](img/B19627_03_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Logistic sigmoid (uninterrupted) and its derivative (interrupted)
    (left); consecutive sigmoid activations, which “squash” the data (right)
  prefs: []
  type: TYPE_NORMAL
- en: 'The vanishing gradients manifest themselves in the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: In the forward phase, the outputs of the first sigmoid layer are represented
    by the blue uninterrupted line (both left and right images in the preceding figure)
    and fall in the range (0, 1). The dotted lines on the right image represent the
    sigmoid activations of each of the consecutive layers after the first. Even after
    three layers, we can see that the activation is “squashed” in a narrow range and
    converges to around 0.66, regardless of the input value. For example, if the input
    value of the first layer is 2, then ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.881</mml:mn></mml:math>](img/235.png),
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>σ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.71</mml:mn></mml:math>](img/236.png),
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>σ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>σ</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.67</mml:mn></mml:math>](img/237.png),
    and so on. This peculiarity of the sigmoid function acts as an eraser of any information
    coming from the preceding layers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We now know that to train an NN, we need to compute the derivative of the activation
    function (along with all the other derivatives) for the backward phase. The derivative
    of the sigmoid function is represented by the green interrupted line on the left
    image in the preceding figure. We can see that it has a significant value in a
    very narrow interval, centered around 0, and converges toward 0 in all other cases.
    In networks with many layers, the derivative would likely converge to 0 when propagated
    to the first layers of the network. Effectively, this means we cannot propagate
    the error to these layers and we cannot update their weights in a meaningful way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thankfully, the **ReLU** activation we introduced in [*Chapter 2*](B19627_02.xhtml#_idTextAnchor047)
    can solve both of these problems with a single stroke. To recap, the following
    figure shows the ReLU graph and its derivative:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – ReLU activation (uninterrupted) and its derivative (interrupted)](img/B19627_03_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – ReLU activation (uninterrupted) and its derivative (interrupted)
  prefs: []
  type: TYPE_NORMAL
- en: 'ReLU has the following desirable properties:'
  prefs: []
  type: TYPE_NORMAL
- en: It is **idempotent**. If we pass a value through an arbitrary number of ReLU
    activations, it will not change; for example, *ReLU(2) = 2*, *ReLU(ReLU(2)) =
    2*, and so on. This is not the case for a sigmoid. The idempotence of ReLU makes
    it theoretically possible to create networks with more layers compared to the
    sigmoid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can also see that its derivative is either 0 or 1, regardless of the backpropagated
    value. In this way, we can avoid vanishing gradients in the backward pass as well.
    Strictly speaking, the derivative ReLU at value 0 is undefined, which makes the
    ReLU only semi-differentiable (more information about this can be found at [https://en.wikipedia.org/wiki/Semi-differentiability](https://en.wikipedia.org/wiki/Semi-differentiability)).
    But in practice, it works well enough.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It creates sparse activations. Let’s assume that the weights of the network
    are initialized randomly through normal distribution. Here, there is a 0.5 chance
    that the input for each ReLU unit is < 0\. Therefore, the output of about half
    of all activations will also be 0\. The sparse activations have several advantages,
    which we can roughly summarize as Occam’s razor in the context of NNs – it’s better
    to achieve the same result with a simpler data representation than a complex one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s faster to compute in both the forward and backward passes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Despite these ReLU advantages, during training, the network weights can be
    updated in such a way that some of the ReLU units in a layer will always receive
    inputs smaller than 0, which, in turn, will cause them to permanently output 0
    as well. This phenomenon is known as **dying ReLUs**. To solve this, several ReLU
    modifications have been proposed. The following is a non-exhaustive list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Leaky ReLU**: When the input is larger than 0, leaky ReLU repeats its input
    in the same way as the regular ReLU does. However, when *x < 0*, the leaky ReLU
    outputs *x* multiplied by some constant, α (*0 < α < 1*), instead of 0\. The following
    diagram shows the leaky ReLU formula, its derivative, and their graphs for *α
    =* *0.2*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.6 – The leaky ReLU activation function](img/B19627_03_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – The leaky ReLU activation function
  prefs: []
  type: TYPE_NORMAL
- en: '**Parametric ReLU** (**PReLU**; see *Delving Deep into Rectifiers: Surpassing
    Human-Level Performance on ImageNet Classification*, [https://arxiv.org/abs/1502.01852):](https://arxiv.org/abs/1502.01852):)
    This activation is the same as the leaky ReLU, but *α* is tunable and is adjusted
    during training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exponential linear unit** (**ELU**; see *Fast and Accurate Deep Network Learning
    by Exponential Linear Units (ELUs)*, [https://arxiv.org/abs/1511.07289):](https://arxiv.org/abs/1511.07289):)
    When the input is larger than 0, ELU repeats its input in the same way as ReLU
    does. However, when *x < 0*, the ELU output becomes ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math>](img/238.png),
    where *α* is a tunable parameter. The following diagram shows the ELU formula,
    its derivative, and their graphs for *α =* *0.2*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.7 – The ELU activation function](img/B19627_03_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – The ELU activation function
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaled exponential linear unit** (**SELU**; see *Self-Normalizing Neural
    Networks*, [https://arxiv.org/abs/1706.02515):](https://arxiv.org/abs/1706.02515):)
    This activation is like ELU, except that the output (both smaller and larger than
    0) is scaled with an additional training parameter, *λ*. The SELU is part of a
    larger concept called **self-normalizing NNs** (**SNNs**), which is described
    in the source paper.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid Linear Unit (SiLU)**, **Gaussian Error Linear Unit** (**GELU**; see
    *Gaussian Error Linear Units (GELUs)*, [https://arxiv.org/abs/1606.08415](https://arxiv.org/abs/1606.08415)),
    and **Swish** (see *Searching for Activation Functions*, [https://arxiv.org/abs/1710.05941](https://arxiv.org/abs/1710.05941)):
    This is a collection of three similar (but not the same) functions that closely
    resemble ReLU but are differentiable at the 0 point. For the sake of simplicity,
    we’ll only show the SiLU graph (*σ* is the sigmoid function):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.8 – The SiLU activation function](img/B19627_03_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – The SiLU activation function
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have softmax, which is the activation function of the output layer
    in classification problems. Let’s assume that the output of the final network
    layer is a vector, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi mathvariant="bold">z</mml:mi><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/239.png).
    Each of the *n* elements represents one of *n* classes, to which the input sample
    might belong. To determine the network prediction, we’ll take the index, *i*,
    of the highest value, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/240.png),
    and assign the input sample to the class it represents. However, we can also interpret
    the network output as a probability distribution of a discrete random variable
    – that is, each value, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/241.png),
    represents the probability that the input sample belongs to that particular class.
    To help us with this, we’ll use the softmax activation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>f</mi><mfenced
    open="(" close=")"><msub><mi>z</mi><mi>i</mi></msub></mfenced><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mfenced
    open="(" close=")"><msub><mi>z</mi><mi>i</mi></msub></mfenced></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mfenced
    open="(" close=")"><msub><mi>z</mi><mi>j</mi></msub></mfenced></mrow></mrow></mfrac></mrow></mrow></math>](img/242.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It has the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The denominator in the formula acts as a normalizer. This is important for
    the probability interpretation we just introduced:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every value, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/243.png),
    is constrained within the [0, 1] range, which allows us to treat it as a probability
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The total sum of values of ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>f</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/244.png)
    is equal to 1: ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><msubsup><mo>∑</mo><mi>j</mi><mrow
    /></msubsup><mrow><mi>f</mi><mfenced open="(" close=")"><msub><mi>z</mi><mi>j</mi></msub></mfenced></mrow></mrow><mo>=</mo><mn>1</mn></mrow></mrow></math>](img/245.png),
    which also aligns with the probability interpretation'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A bonus (in fact, obligatory) is that the function is differentiable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The softmax activation has one more subtle property. Before we normalize the
    data, we transform each vector component exponentially with ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math>](img/246.png).
    Let’s imagine that two of the vector components are ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>](img/247.png)
    and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math>](img/248.png).
    Here, we would have exp(1) = 2.7 and exp(2) = 7.39\. As we can see, the ratios
    between the components before and after the transformation are very different
    – 0.5 and 0.36\. In effect, the softmax function increases the probability of
    higher scores compared to lower ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In practice, **softmax** is often used in combination with the **cross-entropy
    loss** function. It compares the difference between the estimated class probabilities
    and the actual class distribution (the difference is known as cross-entropy).
    We can define the cross-entropy loss for a single training sample as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>H</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/249.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/250.png)
    is the estimated probability of the output belonging to class *j* (out of *n*
    total classes) and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/251.png)![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:math>](img/252.png)
    is the actual probability. The actual distribution, *P(X)*, is usually a one-hot-encoded
    vector, where the real class has a probability of 1, and all others have a probability
    of 0\. In this case, the cross-entropy loss will only capture the error on the
    target class and will discard all other errors.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve learned how to prevent vanishing gradients and we’re able to
    interpret the NN output as a probability distribution, we’ll focus on the next
    challenge in front of DNNs – overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: DNN regularization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we’ve learned that an NN can approximate any function. But with great
    power comes great responsibility. The NN may learn to approximate the noise of
    the target function rather than its useful components. For example, imagine that
    we are training an NN to classify whether an image contains a car or not, but
    for some reason, the training set contains mostly red cars. It may turn out that
    the NN will associate the color red with the car, rather than its shape. Now,
    if the network sees a green car in inference mode, it may not recognize it as
    such because the color doesn’t match. As we discussed in [*Chapter 1*](B19627_01.xhtml#_idTextAnchor016),
    this problem is referred to as overfitting and it is central to ML (and even more
    so in deep networks). In this section, we’ll discuss several ways to prevent it.
    Such techniques are collectively known as regularization.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the context of NNs, these regularization techniques usually impose some
    artificial limitations or obstacles on the training process to prevent the network
    from approximating the target function too closely. They try to guide the network
    to learn generic rather than specific approximation of the target function in
    the hope that this representation will generalize well on previously unseen examples
    of the test dataset. Let’s start with regularization techniques that apply to
    the input data before we feed it to the NN:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Min-max normalization**: ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math>](img/253.png).
    Here, *x* is a single element of the input vector, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math>](img/254.png)
    is the smallest element of the training dataset, and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math>](img/255.png)
    is the largest element. This operation scales all the inputs in the [0, 1] range.
    For example, a grayscale image will have a min color value of 0 and a max color
    value of 255\. Then, a pixel with an intensity of 125 would have a scaled value
    of ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mfenced
    separators="|"><mml:mrow><mml:mn>125</mml:mn><mml:mo>-</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mtext>/</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:mn>255</mml:mn><mml:mo>-</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.49</mml:mn></mml:math>](img/256.png).
    Min-max is fast and easy to implement. One problem with this normalization is
    that data outliers could have an outsized impact on the result over the whole
    dataset. For example, if a single erroneous element has a very large value, it
    will enter the formula as ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math>](img/257.png)
    and it will drive all normalized dataset values toward 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard score** (or **z-score**): ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:math>](img/258.png).
    It handles data outliers better than min-max. To understand how, let’s focus on
    the formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext>/</mml:mtext><mml:mi>N</mml:mi><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>](img/259.png)
    is the mean value of all elements of the dataset, where ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/115.png)
    is a single element of the input vector and *N* is the total size of the dataset.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mtext>/</mml:mtext><mml:mi>N</mml:mi><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:math>](img/261.png)
    is the **standard deviation** of all dataset elements. It measures how far apart
    the dataset values are from the mean value. There is also **variance,** **![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext>/</mml:mtext><mml:mi>N</mml:mi><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/262.png)**![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mtext>/</mml:mtext><mml:mi>N</mml:mi><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/263.png),
    which removes the square root from the standard deviation. The variance is theoretically
    correct but is less intuitive than standard deviation, which is measured in the
    same units as the original data, *x*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, we can compute μ and σ per sample if it’s not practical to compute
    them over the entire dataset. The standard score maintains the dataset’s mean
    value close to 0 and its standard deviation close to 1.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Data augmentation**: This is where we artificially increase the size of the
    training set by applying random modifications to the training samples before feeding
    them to the network. In the case of images, these would be rotation, skew, scaling,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next class of regularization techniques are applied within the DNN structure
    itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dropout**: Here, we randomly and periodically remove some of the units of
    a layer (along with their input and output connections) from the network. During
    a training mini-batch, each unit has a probability, *p*, of being stochastically
    dropped. This is to ensure that no unit ends up relying too much on other units
    and “learns” something useful for the NN instead. Dropout is only applied during
    the training phase and all the units in the network fully participate during the
    inference phase. In the following figure, we can see a dropout for fully connected
    layers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "![Figure 3.9 – An example of dropout on full\uFEFFy connected layers](img/B19627_03_9.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – An example of dropout on fully connected layers
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch normalization** (**BN**; see *Batch Normalization: Accelerating Deep
    Network Training by Reducing Internal Covariate Shift*, [https://arxiv.org/abs/1502.03167):](https://arxiv.org/abs/1502.03167):)
    This is a way to apply data processing, not unlike the standard score, for the
    hidden layers of the network. It normalizes the outputs of the hidden layer for
    each mini-batch (hence the name) in a way that maintains its mean activation value
    close to 0 (**re-centering**) and its standard deviation close to 1 (**re-scaling**).
    The intuition is that as information is propagated through the layers, these values
    can deviate from the desired values. Let’s say that the mini-batch is represented
    by an *m×n* matrix, **X**. Each row of **X**, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/264.png),
    represents a single input vector (this vector is an output of a preceding layer).
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/265.png)
    is the *j*-th element of the *i*-th vector. We can compute BN for each matrix
    element in the following way:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="bold">X</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math>](img/266.png):
    This is the mini-batch mean. We compute a single *μ* value over all cells of the
    mini-batch matrix.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="bold">X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math>](img/267.png):
    This is the mini-batch variance. We compute a single ![<math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mi>σ</mi><mrow
    /><mn>2</mn></msubsup></mrow></math>](img/268.png) value over all cells of the
    mini-batch matrix.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="bold">X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi
    mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>ε</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:math>](img/269.png):
    We normalize each cell of the matrix. *ε* is a constant that’s added for numerical
    stability, so the denominator cannot become 0.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mi>γ</mml:mi><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>≡</mml:mo><mml:mtext>B</mml:mtext><mml:msub><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mrow><mml:mtext>γ,β</mml:mtext></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/270.png):
    This formula represents the scale and shift of the original data. *γ* and *β*
    are learnable parameters and we compute them over each location, *ij* (![<mml:math
    xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/271.png)
    and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/272.png)),
    over all cells of the mini-batch matrix.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer normalization** (**LN**; see *Layer Normalization*, [https://arxiv.org/abs/1607.06450):](https://arxiv.org/abs/1607.06450):)
    LN is similar to BN, but with one key difference: the mean and variance are computed
    separately over each mini-batch sample. This is unlike BN, where these values
    are computed across the whole mini-batch. As with BN, the mini-batch is an *m×n*
    matrix, **X**, and each row vector, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi
    mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/273.png),
    is the output of a preceding layer, and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/274.png)
    is the *j*-th element of the *i*-th vector. Then, we have the following for the
    *i*-th input vector:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi
    mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>](img/275.png)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi
    mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi
    mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/276.png)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mover><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo
    stretchy="true">ˆ</mo></mover><mo>←</mo><mstyle scriptlevel="+1"><mfrac><mrow><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>μ</mi><msub><mi
    mathvariant="bold">x</mi><mi>i</mi></msub></msub></mrow><msqrt><mrow><msubsup><mi>σ</mi><msub><mi
    mathvariant="bold">x</mi><mi>i</mi></msub><mn>2</mn></msubsup><mo>+</mo><mi>ε</mi></mrow></msqrt></mfrac></mstyle></mrow></mrow></math>](img/277.png)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mi>γ</mml:mi><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>≡</mml:mo><mml:mtext>L</mml:mtext><mml:msub><mml:mrow><mml:mtext>N</mml:mtext></mml:mrow><mml:mrow><mml:mtext>γ,β</mml:mtext></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/278.png)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_IMG
- en: '**Root mean square layer normalization** (**RMSNorm**; see [https://arxiv.org/abs/1910.07467):](https://arxiv.org/abs/1910.07467):)
    The authors of RMSNorm argue that the main benefit of LN comes just from the re-scaling,
    rather than the combination of re-centering and re-scaling. Therefore, RMSNorm
    is a simplified and faster version of LN, which only applies re-scaling using
    the root mean square statistic. We’ll use the same notation as with LN. So, we
    can define RMSNorm as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mtext>RMS</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:msqrt></mml:math>](img/279.png).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext>RMS</mml:mtext><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/280.png):
    Here, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/281.png)
    is the gain parameter used to re-scale the standardized summed inputs (it is set
    to 1 at the beginning). It is equivalent to the *γ* parameter in BN.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure illustrates the difference between BN and LN. On the left,
    we compute single *μ* and *σ* values across the whole mini-batch. To the right,
    we can see ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/282.png)
    and ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/283.png)
    for each row:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – BN and LN computation of μ and σ](img/B19627_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – BN and LN computation of μ and σ
  prefs: []
  type: TYPE_NORMAL
- en: 'The final type of regularization we’ll introduce is **L2 regularization**.
    This technique adds a special regularization term to the cost function. To understand
    it, let’s take the MSE cost. We can add L2 regularization to it in the following
    way (the underscored part of the formula):'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>J</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mfenced
    open="[" close="]" separators="|"><mml:mrow><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mfenced
    separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:munder
    underaccent="false"><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>_</mml:mo></mml:munder></mml:mrow></mml:mfenced></mml:math>](img/284.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/165.png)
    is one of *m* total network weights and *λ* is the weight decay coefficient. The
    rationale is that if the network weights, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>](img/174.png),
    are large, then the cost function will also increase. In effect, weight decay
    penalizes large weights (hence the name). This prevents the network from relying
    too heavily on a few features associated with these weights. There is less chance
    of overfitting when the network is forced to work with multiple features. In practical
    terms, when we compute the derivative of the weight decay cost function (the preceding
    formula) concerning each weight and then propagate it to the weights themselves,
    the weight update rule changes from the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>η</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>J</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math>](img/287.png)
    to ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>η</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>J</mml:mi><mml:mfenced
    separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math>](img/288.png)'
  prefs: []
  type: TYPE_IMG
- en: With this discussion of DNN regularization, we’ve covered our theoretical base.
    Next, let’s see what the real-world applications of DNNs are.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of DL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML in general, and DL in particular, is producing more and more astonishing
    results in terms of the quality of predictions, feature detection, and classification.
    Many of these recent results have made the news. Such is the pace of progress
    that some experts are worrying that machines will soon be more intelligent than
    humans. But I hope that any such fears you might have will be alleviated after
    you have read this book. For better or worse, we’re still far from machines having
    human-level intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B19627_02.xhtml#_idTextAnchor047), we mentioned how DL algorithms
    have occupied the leaderboard of the ImageNet competition. They are successful
    enough to make the jump from academia to industry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s talk about some real-world use cases of DL:'
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, new cars have a suite of safety and convenience features that aim
    to make the driving experience safer and less stressful. One such feature is automated
    emergency braking if the car sees an obstacle. Another one is lane-keeping assist,
    which allows the vehicle to stay in its current lane without the driver needing
    to make corrections with the steering wheel. To recognize lane markings, other
    vehicles, pedestrians, and cyclists, these systems use a
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: forward-facing camera. One of the most prominent suppliers of such systems,
    Mobileye ([https://www.mobileye.com/](https://www.mobileye.com/)), has produced
    custom chips that use CNNs to detect these objects on the road ahead. To give
    you an idea of the importance of this sector, in 2017, Intel acquired Mobileye
    for $15.3 billion. This is not an outlier, and Tesla’s famous Autopilot system
    also relies on CNNs to achieve the same results. The former director of AI at
    Tesla, Andrej Karpathy ([https://karpathy.ai/](https://karpathy.ai/)), is a well-known
    researcher in the field of DL. We can speculate that future autonomous vehicles
    will also use deep networks for computer vision.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Both Google’s **Vision API** ([https://cloud.google.com/vision/](https://cloud.google.com/vision/))
    and Amazon’s **Rekognition** ([https://aws.amazon.com/rekognition/](https://aws.amazon.com/rekognition/))
    services use DL models to provide various computer vision capabilities. These
    include recognizing and detecting objects and scenes in images, text recognition,
    face recognition, content moderation, and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If these APIs are not enough, you can run your own models in the cloud. For
    example, you can use Amazon’s AWS DL AMIs (short for **Amazon Machine Images**;
    see [https://aws.amazon.com/machine-learning/amis/](https://aws.amazon.com/machine-learning/amis/)),
    which are virtual machines that come configured with some of the most popular
    DL libraries. Google offers a similar service with their Cloud AI ([https://cloud.google.com/products/ai/](https://cloud.google.com/products/ai/)),
    but they’ve gone one step further. They created **tensor processing units** (**TPUs**;
    see https://cloud.google.com/tpu/) – microprocessors that are optimized for fast
    NN operations such as matrix multiplication and activation functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DL has a lot of potential for medical applications. However, strict regulatory
    requirements, as well as patient data confidentiality, have slowed down its adoption.
    Nevertheless, we’ll identify several areas in which DL could have a high impact:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical imaging is an umbrella term for various non-invasive methods of creating
    visual representations of the inside of the body. Some of these include **magnetic
    resonance images** (**MRIs**), ultrasound, **computed axial tomography** (**CAT**)
    scans, X-rays, and histology images. Typically, such an image is analyzed by a
    medical professional to determine the patient’s condition.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Computer-aided diagnosis, and computer vision, in particular, can help specialists
    by detecting and highlighting important features of images. For example, to determine
    the degree of malignancy of colon cancer, a pathologist would have to analyze
    the morphology of the glands using histology imaging. This is a challenging task
    because morphology can vary greatly. A DNN could segment the glands from the image
    automatically, leaving the pathologist to verify the results. This would reduce
    the time needed for analysis, making it cheaper and more accessible.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Another medical area that could benefit from DL is the analysis of medical history
    records. When a doctor diagnoses a patient’s condition and prescribes treatment,
    they consult the patient’s medical history first. A DL algorithm could extract
    the most relevant and important information from those records, even if they are
    handwritten. In this way, the doctor’s job would be made easier, and the risk
    of errors would also be reduced.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: One area where DNNs have already had an impact is in protein folding. Proteins
    are large, complex molecules, whose function depends on their 3D shape. The building
    blocks of proteins are amino acids, and their sequence determines the shape of
    the protein. The protein folding problem seeks to understand the relationship
    between the initial amino acid sequence and the final 3D shape of the protein.
    DeepMind’s **AlphaFold 2** model (believed to be based on transformers; see [https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe](https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe))
    has managed to predict 200 million protein structures, which represents almost
    all known cataloged proteins.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Google’s Neural Machine Translation API ([https://arxiv.org/abs/1609.08144](https://arxiv.org/abs/1609.08144))
    uses – you guessed it – DNNs for machine translation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Siri ([https://machinelearning.apple.com/2017/10/01/hey-siri.html](https://machinelearning.apple.com/2017/10/01/hey-siri.html)),
    Google Assistant, and Amazon Alexa ([https://aws.amazon.com/deep-learning/](https://aws.amazon.com/deep-learning/))
    rely on deep networks for speech recognition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AlphaGo** is an AI machine based on DL that made the news in 2016 by beating
    the world Go champion, Lee Sedol. AlphaGo had already made the news, in January
    2016, when it beat the European champion, Fan Hui. At the time, however, it seemed
    unlikely that it could go on to beat the world champion. Fast-forward a couple
    of months and AlphaGo was able to achieve this remarkable feat by sweeping its
    opponent in a 4-1 victory series. This was an important milestone because Go has
    many more possible game variations than other games, such as chess, and it’s impossible
    to consider every possible move in advance. Also, unlike chess, in Go, it’s very
    difficult to even judge the current position or value of a single stone on the
    board. In 2017, DeepMind released an updated version of AlphaGo called **AlphaZero**
    ([https://arxiv.org/abs/1712.01815](https://arxiv.org/abs/1712.01815)), and in
    2019, they released a further update called **MuZero** ([https://arxiv.org/abs/1911.08265](https://arxiv.org/abs/1911.08265)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools such as GitHub Copilot ([https://github.com/features/copilot](https://github.com/features/copilot))
    and ChatGPT ([https://chat.openai.com/](https://chat.openai.com/)) utilize generative
    DNN models to transform natural language requests into source code snippets, functions,
    and entire programs. We already mentioned Stable Diffusion ([https://stability.ai/blog/stable-diffusion-public-release](https://stability.ai/blog/stable-diffusion-public-release))
    and DALL-E ([https://openai.com/dall-e-2/](https://openai.com/dall-e-2/)), which
    can generate realistic images based on text description.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this short list, we aimed to cover the main areas in which DL is applied,
    such as computer vision, NLP, speech recognition, and **reinforcement learning**
    (**RL**). This list is not exhaustive, however, as there are many other uses for
    DL algorithms. Still, I hope this has been enough to spark your interest. Next,
    we’ll formally introduce two of the most popular DL libraries – PyTorch and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing popular DL libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We already implemented a simple example with PyTorch in [*Chapter 1*](B19627_01.xhtml#_idTextAnchor016).
    In this section, we’ll introduce this library, and Keras, more systemically. Let’s
    start with the common features of most DNN libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: All libraries use Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic unit for data storage is the **tensor**. Mathematically, the definition
    of a tensor is more complex, but in the context of DL libraries, they are multi-dimensional
    (with an arbitrary number of axes) arrays of base values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NNs are represented as a **computational graph** of operations. The nodes of
    the graph represent the operations (weighted sum, activation function, and so
    on). The edges represent the flow of data, which is how the output of one operation
    serves as an input for the next one. The inputs and outputs of the operations
    (including the network inputs and outputs) are tensors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All libraries include **automatic differentiation**. This means that all you
    need to do is define the network architecture and activation functions, and the
    library will automatically figure out all of the derivatives required for training
    with backpropagation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, we’ve referred to GPUs in general, but in reality, the vast majority
    of DL projects work exclusively with NVIDIA GPUs. This is because of the better
    software support NVIDIA provides. These libraries are no exception – to implement
    GPU operations, they rely on the CUDA Toolkit ([https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit))
    in combination with the cuDNN library ([https://developer.nvidia.com/cudnn](https://developer.nvidia.com/cudnn)).
    cuDNN is an extension of CUDA, built specifically for DL applications. As mentioned
    in the *Applications of DL* section, you can also run your DL experiments in the
    cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch is an independent library, while Keras is built on top of TF and acts
    as a user-friendly TF interface. We’ll continue by implementing a simple classification
    example using both PyTorch and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying digits with Keras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Keras exists either as a standalone library with TF as the backend or as a
    sub-component of TF itself. You can use it in both flavors. To use Keras as part
    of TF, we need only to install TF itself. Once we’ve done this, we can use the
    library with the following import:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The standalone Keras supports different backends besides TF, such as Theano.
    In this case, we can install Keras itself and then use it with the following import:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The large majority of Keras’s use is with the TF backend. The author of Keras
    recommends using the library as a TF component (the first option) and we’ll do
    so in the rest of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we’ll use Keras via TF to classify the images of the MNIST
    dataset. It’s comprised of 70,000 examples of digits that have been handwritten
    by different people. The first 60,000 are typically used for training and the
    remaining 10,000 for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – A sample of digits taken from the MNIST dataset](img/B19627_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – A sample of digits taken from the MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll build a simple MLP with one hidden layer. Let’s start:'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the advantages of Keras is that it can import this dataset for you without
    you needing to explicitly download it from the web (it will download it for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, `(X_train, Y_train)` is the training images and labels, and `(X_validation,
    Y_validation)` is the test images and labels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We need to modify the data so that we can feed it to the NN. `X_train` contains
    60,000 28×28 pixel images, and `X_validation` contains 10,000\. To feed them to
    the network as inputs, we want to reshape each sample as a 784-pixel-long array,
    rather than a 28×28 two-dimensional matrix. We’ll also normalize them in the [0:1]
    range. We can accomplish this with these two lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The labels indicate the value of the digit depicted in the images. We want
    to convert this into a 10-entry **one-hot-encoded** vector comprised of 0s and
    just one 1 in the entry corresponding to the digit. For example, 4 is mapped to
    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]. Conversely, our network will have 10 output units:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the NN. In this case, we’ll use the `Sequential` model, where each layer
    serves as an input to the next. In Keras, `Dense` means a fully connected layer.
    We’ll use a network with one hidden layer with 100 units, BN, ReLU activation,
    and softmax output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can define our gradient descent parameters. We’ll use the Adam optimizer
    and categorical cross-entropy loss (this is cross entropy, optimized for softmax
    outputs):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, run the training for 100 epochs and a batch size of 100\. In Keras, we
    can do this with the `fit` method, which iterates over the dataset internally.
    Keras will default to GPU training, but if a GPU is not available, it will fall
    back to the CPU:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'All that’s left to do is add code to evaluate the network’s accuracy on the
    test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: And that’s it. The validation accuracy will be about 97.7%, which is not a great
    result, but this example runs in less than 30 seconds on a CPU. We can make some
    simple improvements, such as a larger number of hidden units, or a higher number
    of epochs. We’ll leave those experiments to you so that you can familiarize yourself
    with the code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To see what the network has learned, we can visualize the weights of the hidden
    layer. The following code allows us to obtain them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the weights for each unit back to a 28×28 two-dimensional array and
    then display them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can see the result in the following figure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.12 – A composite ﬁgure of what was learned by all the hidden units](img/B19627_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 – A composite ﬁgure of what was learned by all the hidden units
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us see the example for PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying digits with PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we’ll implement the same example that we did in the *Classifying
    digits with Keras* section but this time with PyTorch. Let’s start:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll select the device we’re using (CPU or GPU). We’ll try with the
    GPU first and fall back to the CPU if the GPU is not available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Like Keras, PyTorch supports MNIST out of the box. Here’s how we can instantiate
    the train and validation sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The dataset is automatically downloaded and split into training and validation
    parts. The `ToTensor()` transformation converts the images from `numpy` arrays
    into PyTorch tensors and normalizes them in the [0:1] range (as opposed to [0:255]
    originally). The `torch.flatten` transform flattens the two-dimensional 28×28
    images to a one-dimensional 784 tensor so that we can feed it to the NN.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we’ll wrap the datasets in `DataLoader` instances:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The data `DataLoader` instance takes care of creating mini-batches and shuffles
    the data randomly. They are also iterators, which supply mini-batches one at a
    time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we’ll define the NN `model`. We’ll use the same MLP with a single hidden
    layer, as in the Keras example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This definition is like the one in Keras. One difference is that the `Linear`
    (fully connected) layers require both input and output dimensions since they cannot
    extract the output dimension of the preceding layer. The activations are defined
    as separate operations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, let’s define the cross-entropy loss and the Adam optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can define the `train_model` function, which, as its name suggests,
    takes care of training the model. It takes our predefined `model`, `cost_function`,
    `optimizer`, and `data_loader` and runs the training for a single epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Unlike Keras and its `fit` function, we have to implement the PyTorch training
    ourselves. `train_model` iterates over all mini-batches provided by `train_loader`.
    For each mini-batch, `optimizer.zero_grad()` resets the gradients from the previous
    iteration. Then, we initiate the forward and backward passes, and finally the
    weight updates.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We’ll also define the `test_model` function, which will run the model in inference
    mode to check its results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: BN and dropout layers are not used in evaluation (only in training), so `model.eval()`
    turns them off. We iterate over the validation set, initiate a forward pass, and
    aggregate the validation loss and accuracy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s run the training for 20 epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This model achieves 97.6% accuracy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explained what DL is and how it’s related to DNNs. We discussed
    the different types of DNNs and how to train them, and we paid special attention
    to various regularization techniques that help with the training process. We also
    mentioned many real-world applications of DL and tried to analyze the reasons
    for its efficiency. Finally, we introduced two of the most popular DL libraries,
    namely PyTorch and Keras. We also implemented identical MNIST classification examples
    with both libraries.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll discuss how to solve classification tasks over more
    complex image datasets with the help of convolutional networks – one of the most
    popular and effective deep network models. We’ll talk about their structure, building
    blocks, and what makes them uniquely suited to computer vision tasks. To spark
    your interest, let’s recall that convolutional networks have consistently won
    the popular ImageNet challenge since 2012, delivering top-five accuracy from 74.2%
    to 99%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep Neural Networks for Computer Vision
  prefs: []
  type: TYPE_NORMAL
- en: In this part, we’ll introduce **convolutional neural networks** (**CNNs**) –
    a type of neural network suitable for computer vision applications. Building on
    top of the first three chapters, we’ll discuss the rationale behind CNNs, their
    building blocks, and their architecture. We’ll also outline the most popular CNN
    models in use today. Finally, we’ll focus on the advanced applications of CNNs
    – object detection, image segmentation, and image generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B19627_04.xhtml#_idTextAnchor107), *Computer Vision with Convolutional
    Networks*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B19627_05.xhtml#_idTextAnchor146), *Advanced Computer Vision
    Applications*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
