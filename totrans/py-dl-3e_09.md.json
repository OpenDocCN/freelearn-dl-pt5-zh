["```py\n    from transformers import pipeline\n    ```", "```py\n    img_classification_pipeline = pipeline(\n         task=\"image-classification\",\n         model=\"google/vit-base-patch16-224\")\n    ```", "```py\n    img_classification_pipeline(\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Left_side_of_Flying_Pigeon.jpg/640px-Left_side_of_Flying_Pigeon.jpg\")\n    ```", "```py\n    [{'score': 0.4616938531398773, 'label': 'tricycle,\n         trike, velocipede'}]\n    ```", "```py\n    ViTForImageClassification(\n      (vit): ViTModel(\n         (embeddings): ViTEmbeddings(\n            (patch_embeddings): ViTPatchEmbeddings(\n               (projection): Conv2d(3, 768,\n                            kernel_size=(16, 16),\n                            stride=(16, 16))\n            )\n            (dropout): Dropout(p=0.0)\n         )\n         (encoder): ViTEncoder(\n            (layer): ModuleList(\n               (0-11): 12 x ViTLayer(\n                  (attention): ViTAttention(\n                     (attention): ViTSelfAttention(\n                        (query): Linear(in_f=768,\n                                  out_f=768)\n                        (key): Linear(in_f=768, out_f=768)\n                        (value): Linear(in_f=768,\n                                  out_f=768)\n                        (dropout): Dropout(p=0.0)\n                     )\n                     (output): ViTSelfOutput(\n                        (dense): Linear(in_f=768,\n                                  out_f=768)\n                        (dropout): Dropout(p=0.0)\n                     )\n                  )\n                  (intermediate): ViTIntermediate(\n                    (dense): Linear(in_f=768, out_f=3072)\n                    (intermediate_act_fn):GELUActivation()\n                  )\n                  (output): ViTOutput(\n                    (dense): Linear(in_f=3072, out_f=768)\n                    (dropout): Dropout(p=0.0)\n                  )\n                  (layernorm_before): LayerNorm((768,))\n                  (layernorm_after): LayerNorm((768,))\n               )\n            )\n         )\n         (layernorm): LayerNorm((768,))\n      )\n      (classifier): Linear(in_f=768, out_f=1000)\n    )\n    ```", "```py\nfrom transformers import pipeline\nobj_detection_pipeline = pipeline(\n     task=\"object-detection\",\n     model=\"facebook/detr-resnet-50\")\nobj_detection_pipeline(\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Left_side_of_Flying_Pigeon.jpg/640px-Left_side_of_Flying_Pigeon.jpg\")\n```", "```py\n{'score': 0.997983455657959,\n  'label': 'bicycle',\n  'box': {'xmin': 16, 'ymin': 14, 'xmax': 623, 'ymax': 406}}\n```", "```py\n(input_projection): Conv2d(2048, 256,\n                   kernel_size=(1, 1),\n                   stride=(1, 1))\n```", "```py\n(query_position_embeddings): Embedding(100, 256)\n```", "```py\n(encoder): DetrEncoder(\n  (layers): ModuleList(\n     (0-5): 6 x DetrEncoderLayer(\n        (self_attn): DetrAttention(\n           (k_proj): Linear(in_f=256, out_f=256)\n           (v_proj): Linear(in_f=256, out_f=256)\n           (q_proj): Linear(in_f=256, out_f=256)\n           (out_proj): Linear(in_f=256, out_f=256)\n        )\n        (self_attn_layer_norm): LayerNorm((256,))\n        (activation_fn): ReLU()\n        (fc1): Linear(in_f=256, out_f=2048)\n        (fc2): Linear(in_f=2048, out_f=256)\n        (final_layer_norm): LayerNorm((256,))\n     )\n  )\n)\n```", "```py\n(decoder): DetrDecoder(\n  (layers): ModuleList(\n     (0-5): 6 x DetrDecoderLayer(\n        (self_attn): DetrAttention(\n           (k_proj): Linear(in_f=256, out_f=256)\n           (v_proj): Linear(in_f=256, out_f=256)\n           (q_proj): Linear(in_f=256, out_f=256)\n           (out_proj): Linear(in_f=256, out_f=256)\n        )\n        (activation_fn): ReLU()\n        (self_attn_layer_norm): LayerNorm((256,))\n        (encoder_attn): DetrAttention(\n           (k_proj): Linear(in_f=256, out_f=256)\n           (v_proj): Linear(in_f=256, out_f=256)\n           (q_proj): Linear(in_f=256, out_f=256)\n           (out_proj): Linear(in_f=256, out_f=256)\n        )\n        (encoder_attn_layer_norm): LayerNorm((256,))\n        (fc1): Linear(in_f=256, out_f=2048)\n        (fc2): Linear(in_f=2048, out_f=256)\n        (final_layer_norm): LayerNorm((256,))\n     )\n  )\n  (layernorm): LayerNorm((256,))\n)\n```", "```py\n(class_labels_classifier): Linear(in_f=256, out_f=92)\n(bbox_predictor): DetrMLPPredictionHead(\n  (layers): ModuleList(\n     (0-1): 2 x Linear(in_f=256, out_f=256)\n     (2): Linear(in_f=256, out_f=4)\n  )\n)\n```", "```py\n    import torch\n    from diffusers import StableDiffusionPipeline\n    ```", "```py\n    sd_pipe = StableDiffusionPipeline.from_pretrained(\n         \"stabilityai/stable-diffusion-2-1\",\n         torch_dtype=torch.float16)\n    sd_pipe.to('cuda')\n    ```", "```py\n    prompt = \\\n      \"High quality photo of a racing car on a track\"\n    image = sd_pipe(\n         prompt,\n         num_inference_steps=100).images[0]\n    ```", "```py\nStableDiffusionPipeline {\n  \"safety_checker\": [null, null],\n  \"tokenizer\": [\"transformers\", \"CLIPTokenizer\"],\n  \"text_encoder\": [\"transformers\", \"CLIPTextModel\"],\n  \"unet\": [\"diffusers\", \"UNet2DConditionModel\"],\n  \"vae\": [\"diffusers\", \"AutoencoderKL\"],\n  \"scheduler\": [\"diffusers\", \"DDIMScheduler\"]\n}\n```", "```py\n    from datasets import load_dataset\n    dataset = load_dataset('rotten_tomatoes')\n    ```", "```py\n    from transformers import AutoTokenizer\n    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n    ```", "```py\n    tok_dataset = dataset.map(\n        lambda x: tokenizer(\n            text=x['text'],\n            padding='max_length',\n            truncation=True),\n        batched=True)\n    ```", "```py\n    from transformers import AutoModelForSequenceClassification\n    model = AutoModelForSequenceClassification.from_pretrained(\n        'distilbert-base-uncased')\n    ```", "```py\n    from transformers import TrainingArguments\n    training_args = TrainingArguments(\n        output_dir='test_trainer',\n        evaluation_strategy='epoch')\n    ```", "```py\n    import evaluate\n    accuracy = evaluate.load('accuracy')\n    ```", "```py\n    from transformers import Trainer\n    import numpy as np\n    trainer = Trainer(\n        model=model,\n        train_dataset=tok_dataset['train'],\n        eval_dataset=tok_dataset['test'],\n        args=training_args,\n        compute_metrics=\n            lambda x: accuracy.compute(\n                predictions=x[0],\n                references=x[1]),\n        preprocess_logits_for_metrics=\n            lambda x, _: np.argmax(x.cpu(), axis=-1)\n    )\n    ```", "```py\n    trainer.train()\n    ```", "```py\n    from langchain.chat_models import ChatOpenAI\n    model = ChatOpenAI(temperature=0)\n    ```", "```py\n    # Tools\n    from langchain.agents.tools import Tool\n    # Search tool\n    from langchain import SerpAPIWrapper\n    search = Tool(\n        name='Search',\n        func=SerpAPIWrapper().run,\n        description='Google search tool')\n    ```", "```py\n    from langchain import LLMMathChain\n    llm_math_chain = LLMMathChain.from_llm(\n        llm=model,\n        verbose=True)\n    calculator = Tool(\n        name='Calculator',\n        func=llm_math_chain.run,\n        description='Calculator tool')\n    ```", "```py\n    from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n    agent = PlanAndExecute(\n        planner=load_chat_planner(\n            llm=model),\n        executor=load_agent_executor(\n            llm=model,\n            tools=[search, calculator],\n            verbose=True),\n        verbose=True)\n    ```", "```py\n    agent.run('What is the sum of the elevations of the deepest section of the ocean and the highest peak on Earth? Use metric units only.')\n    ```", "```py\n1\\. 'Find the depth of the deepest section of the ocean in metric units.'\n2\\. 'Find the elevation of the highest peak on Earth in metric units.'\n3\\. 'Add the depth of the deepest section of the ocean to the elevation of the highest peak on Earth.'\n4\\. 'Round the sum to an appropriate number of decimal places.'\n5\\. \"Given the above steps taken, respond to the user's original question. \\n\"\n```", "```py\n'Action: {\n    \"action\": \"Search\",\n    \"action_input\": \"depth of the deepest section of the ocean in metric units\"\n}'\n```"]