<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer004">
<h1 id="_idParaDest-5" lang="en-GB"><a id="_idTextAnchor004"/>Preface</h1>
<p lang="en-GB">Developers working with 3D computer vision will be able to put their knowledge to work with this practical guide to 3D deep learning. The book provides a hands-on approach to implementation and associated methodologies that will have you up and running and productive in <span class="No-Break" lang="">no time.</span></p>
<p lang="en-GB">Complete with step-by-step explanations of essential concepts, practical examples, and self-assessment questions, you will begin by exploring state-of-the-art 3D <span class="No-Break" lang="">deep learning.</span></p>
<p lang="en-GB">You will learn about basic 3D mesh and point cloud data processing using PyTorch3D, such as loading and saving PLY and OBJfiles, projecting 3D points onto camera coordinates using perspective camera models or orthographic camera models, and rendering point clouds and meshes to images, among other things. You will also learn how to implement certain state-of-the-art 3D deep learning algorithms, such as differential rendering, NeRF, SynSin, and Mesh R-CNN because coding for these deep learning models becomes easier using the <span class="No-Break" lang="">PyTorch3D library.</span></p>
<p lang="en-GB">By the end of this book, you will be able to implement your own 3D deep <span class="No-Break" lang="">learning models.</span></p>
<h1 id="_idParaDest-6" lang="en-GB"><a id="_idTextAnchor005"/>Who this book is for</h1>
<p lang="en-GB">This book is for beginners and intermediate-level machine learning practitioners, data scientists, machine learning engineers, and deep learning engineers who are looking to become well-versed in computer vision techniques using <span class="No-Break" lang="">3D data.</span></p>
<h1 id="_idParaDest-7" lang="en-GB"><a id="_idTextAnchor006"/>What this book covers</h1>
<p lang="en-GB"><a href="B18217_01.xhtml#_idTextAnchor015"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 1</em></span></a>, <em class="italic" lang="">Introducing 3D Data Processing</em>, will cover the basics of 3D data, such as how 3D data is stored and the basic concepts of meshes and point clouds, world coordinations, and camera coordinations. It also shows us what NDC is (a frequently used coordination), how to convert between different coordinations, perspective cameras, and orthographic cameras, and which camera models should <span class="No-Break" lang="">be used.</span></p>
<p lang="en-GB"><a href="B18217_02.xhtml#_idTextAnchor030"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 2</em></span></a>, <em class="italic" lang="">Introducing 3D Computer Vision and Geometry</em>, will show us the basic concepts in computer graphics, such as rendering and shading. We will learn about some fundamental concepts that will be required in the later chapters of this book, including, 3D geometry transforms, PyTorch tensors, <span class="No-Break" lang="">and optimization.</span></p>
<p lang="en-GB"><a href="B18217_03.xhtml#_idTextAnchor046"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 3</em></span></a>, <em class="italic" lang="">Fitting Deformable Mesh Models to Raw Point Clouds</em>, will present a hands-on project of using a deformable 3D model to fit a noisy 3D observation using all the knowledge that we have learned in the previous chapters. We will explore frequently used cost functions, why these cost functions are important, and when these cost functions are usually used. Finally, we will explore a concrete example of which cost functions have been selected for which tasks and how to set up the optimization loop to obtain the results that <span class="No-Break" lang="">we want.</span></p>
<p lang="en-GB"><a href="B18217_04.xhtml#_idTextAnchor059"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 4</em></span></a>, <em class="italic" lang="">Learning Object Pose Detection and Tracking by Differentiable Rendering</em>, will talk about the basic concepts of differentiable rendering. It will help you understand the basic concepts and know when you can apply these techniques to solve your <span class="No-Break" lang="">own problems.</span></p>
<p lang="en-GB"><a href="B18217_05.xhtml#_idTextAnchor070"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 5</em></span></a>, <em class="italic" lang="">Understanding Differentiable Volumetric Rendering</em>, will present a hands-on project using differentiable rendering to estimate camera positions from a single image and a known 3D mesh model. We will learn how to practically use PyTorch3D to set up cameras, renders, and shaders. We will also get hands-on experience in using different cost functions to get <span class="No-Break" lang="">optimization results.</span></p>
<p lang="en-GB"><a href="B18217_06.xhtml#_idTextAnchor081"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 6</em></span></a>, <em class="italic" lang="">Exploring Neural Radiance Fields (NeRF)</em>, will provide a hands-on project using differentiable rendering to estimate 3D mesh models from several images and <span class="No-Break" lang="">texture models.</span></p>
<p lang="en-GB"><a href="B18217_07.xhtml#_idTextAnchor094"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 7</em></span></a>, <em class="italic" lang="">Exploring Controllable Neural Feature Fields</em>, will cover a very important algorithm for view synthesis, which is NeRF. We will learn what it is all about, how to use it, and where it <span class="No-Break" lang="">is valuable.</span></p>
<p lang="en-GB"><a href="B18217_08.xhtml#_idTextAnchor108"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 8</em></span></a>, <em class="italic" lang="">Modeling the Human Body in 3D</em>, will explore 3D human body fitting using the <span class="No-Break" lang="">SMPL algorithm.</span></p>
<p lang="en-GB"><a href="B18217_09.xhtml#_idTextAnchor124"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 9</em></span></a>, <em class="italic" lang="">Performing End-to-End View Synthesis with SynSin</em>, will cover SynSin, which is a state-of-the-art deep learning image <span class="No-Break" lang="">synthesis model.</span></p>
<p lang="en-GB"><a href="B18217_10.xhtml#_idTextAnchor134"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 10</em></span></a>, <em class="italic" lang="">Mesh R-CNN</em>, will introduce us to Mesh R-CNN, which is another state-of-the-art method for predicting 3D voxel models from a single <span class="No-Break" lang="">input image.</span></p>
<h1 id="_idParaDest-8" lang="en-GB"><a id="_idTextAnchor007"/>To get the most out of this book</h1>
<table class="No-Table-Style" id="table001">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p lang="en-GB"><strong class="bold" lang="">Software/hardware covered in </strong><span class="No-Break" lang=""><strong class="bold" lang="">the book</strong></span></p>
</td>
<td class="No-Table-Style">
<p lang="en-GB"><strong class="bold" lang="">Operating </strong><span class="No-Break" lang=""><strong class="bold" lang="">system requirements</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p lang="en-GB"><span class="No-Break" lang="">Python 3.6+</span></p>
</td>
<td class="No-Table-Style">
<p lang="en-GB">Windows, macOS, <span class="No-Break" lang="">or Linux</span></p>
</td>
</tr>
</tbody>
</table>
<p lang="en-GB"><strong class="bold" lang="">If you are using the digital version of this book, we advise you to type the code yourself or access </strong><strong class="bold" lang="">the code from the book’s GitHub repository (a link is available in the next section). Doing so will help you avoid any potential errors related to copying and </strong><span class="No-Break" lang=""><strong class="bold" lang="">pasting code.</strong></span></p>
<p lang="en-GB">Please check out these papers <span class="No-Break" lang="">for reference:</span></p>
<p lang="en-GB"><a href="B18217_06.xhtml#_idTextAnchor081"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 6</em></span></a><em class="italic" lang="">: </em><a href="https://arxiv.org/abs/2003.08934"><span class="No-Break" lang="">https://arxiv.org/abs/2003.08934</span></a><span class="No-Break" lang=""><em class="italic" lang="">, </em></span><a href="https://github.com/yenchenlin/nerf-pytorch"><span class="No-Break" lang="">https://github.com/yenchenlin/nerf-pytorch</span></a></p>
<p lang="en-GB"><a href="B18217_07.xhtml#_idTextAnchor094"><span class="No-Break" lang=""><em class="italic" lang="">Chapter </em></span><span class="No-Break" lang=""><em class="italic" lang="">7</em></span></a><span class="No-Break" lang=""><em class="italic" lang="">: </em></span><a href="https://m-niemeyer.github.io/project-pages/giraffe/index.xhtml"><span class="No-Break" lang="">https://m-niemeyer.github.io/project-pages/giraffe/index.xhtml</span></a><span class="No-Break" lang=""><em class="italic" lang="">,</em></span><em class="italic" lang=""> </em><a href="https://arxiv.org/abs/2011.12100"><span class="No-Break" lang="">https://arxiv.org/abs/2011.12100</span></a></p>
<p lang="en-GB"><a href="B18217_08.xhtml#_idTextAnchor108"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 8</em></span></a><em class="italic" lang="">: </em><a href="https://smpl.is.tue.mpg.de/">https://smpl.is.tue.mpg.de/</a><em class="italic" lang="">, </em><a href="https://smplify.is.tue.mpg.de/"><span class="No-Break" lang="">https://smplify.is.tue.mpg.de/, https://smpl-x.is.tue.mpg.de/</span></a></p>
<p lang="en-GB"><a href="B18217_09.xhtml#_idTextAnchor124"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 9</em></span></a><em class="italic" lang="">: </em><a href="https://arxiv.org/pdf/1912.08804.pdf">https://arxiv.org/pdf/1912.08804.pdf</a><em class="italic" lang=""> </em></p>
<p lang="en-GB"><a href="B18217_10.xhtml#_idTextAnchor134"><span class="No-Break" lang=""><em class="italic" lang="">Chapter 10</em></span></a><em class="italic" lang="">: </em><a href="https://arxiv.org/abs/1703.06870"><span class="No-Break" lang="">https://arxiv.org/abs/1703.06870</span></a><span class="No-Break" lang="">,</span><span class="No-Break" lang=""> </span><a href="https://arxiv.org/abs/1906.02739"><span class="No-Break" lang="">https://arxiv.org/abs/1906.02739</span></a></p>
<h1 id="_idParaDest-9" lang="en-GB"><a id="_idTextAnchor008"/>Download the example code files</h1>
<p lang="en-GB">You can download the example code files for this book from GitHub at <a href="https://github.com/PacktPublishing/3D-Deep-Learning-with-Python">https://github.com/PacktPublishing/3D-Deep-Learning-with-Python</a>. If there’s an update to the code, it will be updated in the <span class="No-Break" lang="">GitHub repository.</span></p>
<p lang="en-GB">We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check <span class="No-Break" lang="">them out!</span></p>
<h1 id="_idParaDest-10" lang="en-GB"><a id="_idTextAnchor009"/>Download the color images</h1>
<p lang="en-GB">We also provide a PDF file that has color images of the screenshots and diagrams used in this book. You can download it <span class="No-Break" lang="">here: </span><a href="https://packt.link/WJr0Q"><span class="No-Break" lang="">https://packt.link/WJr0Q</span></a><span class="No-Break" lang="">.</span></p>
<h1 id="_idParaDest-11" lang="en-GB"><a id="_idTextAnchor010"/>Conventions used</h1>
<p lang="en-GB">There are a number of text conventions used throughout <span class="No-Break" lang="">this book.</span></p>
<p lang="en-GB"><strong class="source-inline" lang="">Code in text</strong>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: “ Next, we need to update the <strong class="source-inline" lang="">./</strong><span class="No-Break" lang=""><strong class="source-inline" lang="">options/options.py</strong></span><span class="No-Break" lang=""> file”</span></p>
<p lang="en-GB">A block of code is set <span class="No-Break" lang="">as follows:</span></p>
<pre class="source-code" lang="en-GB">elif opt.dataset == 'kitti':</pre>
<pre class="source-code" lang="en-GB">   opt.min_z = 1.0</pre>
<pre class="source-code" lang="en-GB">   opt.max_z = 50.0</pre>
<pre class="source-code" lang="en-GB">   opt.train_data_path = (</pre>
<pre class="source-code" lang="en-GB">       './DATA/dataset_kitti/'</pre>
<pre class="source-code" lang="en-GB">   )</pre>
<pre class="source-code" lang="en-GB">   from data.kitti import KITTIDataLoader</pre>
<pre class="source-code" lang="en-GB">   return KITTIDataLoader</pre>
<p lang="en-GB">When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set <span class="No-Break" lang="">in bold:</span></p>
<pre class="source-code" lang="en-GB"><strong class="bold" lang="">wget https://dl.fbaipublicfiles.com/synsin/checkpoints/realestate/synsin.pth</strong></pre>
<p lang="en-GB">Any command-line input or output is written <span class="No-Break" lang="">as follows:</span></p>
<p class="source-code" lang="en-GB">bash ./download_models.sh</p>
<p lang="en-GB"><strong class="bold" lang="">Bold</strong>: Indicates a new term, an important word, or words that you see onscreen. For instance, words in menus or dialog boxes appear in <strong class="bold" lang="">bold</strong>. Here is an example: “The refinement module (<strong class="bold" lang="">g</strong>) gets inputs from the neural point cloud renderer and then outputs the final <span class="No-Break" lang="">reconstructed image.”</span></p>
<p class="callout-heading" lang="en-GB">Tips or important notes</p>
<p class="callout" lang="en-GB">Appear like this.</p>
<h1 id="_idParaDest-12" lang="en-GB"><a id="_idTextAnchor011"/>Get in touch</h1>
<p lang="en-GB">Feedback from our readers is <span class="No-Break" lang="">always welcome.</span></p>
<p lang="en-GB"><strong class="bold" lang="">General feedback</strong>: If you have questions about any aspect of this book, email us at <a href="http://customercare@packtpub.com">customercare@packtpub.com</a> and mention the book title in the subject of <span class="No-Break" lang="">your message.</span></p>
<p lang="en-GB"><strong class="bold" lang="">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a> and fill in <span class="No-Break" lang="">the form.</span></p>
<p lang="en-GB"><strong class="bold" lang="">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <a href="http://copyright@packt.com">copyright@packt.com</a> with a link to <span class="No-Break" lang="">the material.</span></p>
<p lang="en-GB"><strong class="bold" lang="">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please <span class="No-Break" lang="">visit </span><a href="http://authors.packtpub.com"><span class="No-Break" lang="">authors.packtpub.com</span></a><span class="No-Break" lang="">.</span></p>
<h1 id="_idParaDest-13" lang="en-GB"><a id="_idTextAnchor012"/>Share Your Thoughts</h1>
<p lang="en-GB">Once you’ve read <em class="italic" lang="">3D Deep Learning with Python</em>, we’d love to hear your thoughts! <a href="https://packt.link/r/1-803-24782-7">Please click here to go straight to the Amazon review page</a> for this book and share <span class="No-Break" lang="">your feedback.</span></p>
<p lang="en-GB">Your review is important to us and the tech community and will help us make sure we’re delivering excellent <span class="No-Break" lang="">quality content.</span></p>
<h1 id="_idParaDest-14" lang="en-GB"><a id="_idTextAnchor013"/>Download a free PDF copy of this book</h1>
<p lang="en-GB">Thanks for purchasing <span class="No-Break" lang="">this book!</span></p>
<p lang="en-GB">Do you like to read on the go but are unable to carry your print <span class="No-Break" lang="">books everywhere?</span></p>
<p lang="en-GB">Is your eBook purchase not compatible with the device of <span class="No-Break" lang="">your choice?</span></p>
<p lang="en-GB">Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at <span class="No-Break" lang="">no cost.</span></p>
<p lang="en-GB">Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into <span class="No-Break" lang="">your application.</span></p>
<p lang="en-GB">The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your <span class="No-Break" lang="">inbox daily</span></p>
<p lang="en-GB">Follow these simple steps to get <span class="No-Break" lang="">the benefits:</span></p>
<ol>
<li lang="en-GB">Scan the QR code or visit the link below</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer003">
<img alt="" height="200" src="image/B18217_QR_Free_PDF.jpg" width="200"/>
</div>
</div>
<p class="Basic-Paragraph" lang="en-GB"><a href="https://packt.link/free-ebook/9781803247823">https://packt.link/free-ebook/9781803247823</a></p>
<ol>
<li lang="en-GB" value="2">Submit your proof of purchase</li>
<li lang="en-GB">That’s it! We’ll send your free PDF and other benefits to your email directly</li>
</ol>
</div>
</div>

<div id="sbo-rt-content"><div>
<div class="Basic-Graphics-Frame" id="_idContainer005">
</div>
</div>
<div class="Content" id="_idContainer006">
<h1 id="_idParaDest-15" lang="en-GB"><a id="_idTextAnchor014"/>PART 1: 3D Data Processing Basics</h1>
<p lang="en-GB">This first part of the book will define the most basic concepts for data and image processing since these concepts are essential to our later discussions. This part of the book makes the book self-contained so that readers do not need to read any other books to get started with learning <span class="No-Break" lang="">about PyTorch3D.</span></p>
<p lang="en-GB">This part includes the <span class="No-Break" lang="">following chapters:</span></p>
<ul>
<li lang="en-GB"><a href="B18217_01.xhtml#_idTextAnchor015"><em class="italic" lang="">Chapter 1</em></a>, <em class="italic" lang="">Introducing 3D Data Processing</em></li>
<li lang="en-GB"><a href="B18217_02.xhtml#_idTextAnchor030"><em class="italic" lang="">Chapter 2</em></a>, <em class="italic" lang="">Introducing 3D Computer Vision and Geometry</em></li>
</ul>
</div>
<div>
<div id="_idContainer007">
</div>
</div>
</div></body></html>