<html><head></head><body>
		<div id="_idContainer109">
			<h1 id="_idParaDest-195" class="chapter-number"><a id="_idTextAnchor217"/>12</h1>
			<h1 id="_idParaDest-196"><a id="_idTextAnchor218"/>Applying Unsupervised Learning Approaches</h1>
			<p>In earlier chapters, such as <a href="B19005_05.xhtml#_idTextAnchor107"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, we discussed the fact that supervised learning requires annotated data, where a <a id="_idIndexMarker915"/>human annotator makes a decision about how a <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) system should analyze it – that is, a human has <em class="italic">annotated</em> it. For example, with the movie review data, a human has looked at each review and decided whether it is positive or negative. We also pointed out that this annotation process can be expensive <span class="No-Break">and time-consuming.</span></p>
			<p>In this chapter, we will look at techniques that don’t require annotated data, thereby saving this time-consuming step in data preparation. Although unsupervised learning will not be suitable for every NLP problem, it is very useful to have an understanding of the general area so that you can decide how to incorporate it into your <span class="No-Break">NLP projects.</span></p>
			<p>At a deeper level, we will discuss applications of unsupervised learning, such as topic modeling, including the value of unsupervised learning for exploratory applications and maximizing scarce data. We will also cover label generation in unsupervised classification and mention some approaches to make the most of limited labeled data, with techniques for <span class="No-Break">partial supervision.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>What is <span class="No-Break">unsupervised learning?</span></li>
				<li>Topic modeling using clustering techniques and <span class="No-Break">label derivation</span></li>
				<li>Making the most of data with <span class="No-Break">partial supervision</span></li>
			</ul>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor219"/>What is unsupervised learning?</h1>
			<p>The applications that we worked with in earlier chapters were based on data that was manually categorized by human annotators. For example, each review in the movie review corpus <a id="_idIndexMarker916"/>that we have used several times was read by a human annotator and assigned a category, <em class="italic">positive</em> or <em class="italic">negative</em>, based on the human’s opinion. The review-category pairs were then used to train models, using the machine learning algorithms <a id="_idIndexMarker917"/>that we previously learned about to categorize new reviews. This whole process is called <strong class="bold">supervised learning</strong> because the training process is, in effect, <em class="italic">supervised</em> by the training data. The training data labeled by humans is referred to as the <em class="italic">gold standard</em> or <span class="No-Break"><em class="italic">ground truth.</em></span></p>
			<p>Supervised approaches have some disadvantages, however. The most obvious disadvantage is the cost of developing the ground-truth data because of the cost of human annotators. Another consideration is the possibility that the manual annotations from different annotators, or even the same annotator at different times, will be inconsistent. Inconsistent annotation can also occur if the data labels themselves are subjective or not clear-cut, which makes it harder for the annotators to agree on the <span class="No-Break">correct annotation.</span></p>
			<p>For many applications, supervised approaches are the only option, but there are other applications, which we will be exploring in this chapter, where <strong class="bold">unsupervised techniques</strong> <span class="No-Break">are useful.</span></p>
			<p>These unsupervised applications don’t require labeled training data because what we want to learn from the natural language data doesn’t require any human judgment. Rather, it can be found by just examining the raw text, which can be done by an algorithm. These kinds of applications include grouping documents by similarity and computing the similarity <a id="_idIndexMarker918"/>of documents. In particular, we will be looking at <strong class="bold">clustering</strong>, which is the process of putting data, documents in particular, into similar groups. Finding similar groups of documents is often a first step in the process of developing a classification application, before the categories of documents are known. Once the clusters are identified, there are additional techniques that can help find human-readable labels for the clusters, although in some cases, it is easy to identify how the clusters should be labeled by manual inspection of the clusters. We will look at tools to find cluster labels later in <span class="No-Break">this chapter.</span></p>
			<p>In addition to <a id="_idIndexMarker919"/>clustering, another important application of unsupervised learning is the training process for the <strong class="bold">large language models</strong> (<strong class="bold">LLMs</strong>) that we covered in <a href="B19005_11.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>. Training LLMs doesn’t require any supervision because the training process only looks at words in the context of other words. However, we will not cover the training process for LLMs in this book because this is a very computationally intensive process and requires expensive computational resources that are not available to the vast majority of developers. In addition, LLM training is not needed for most practical applications, since existing LLMs that have already been trained are <span class="No-Break">widely available.</span></p>
			<p>In this chapter, we will illustrate in detail a practical NLP problem where unsupervised learning can be very useful – <em class="italic">topic modeling</em>. In topic modeling, we start with a collection of <a id="_idIndexMarker920"/>text items, such as documents or user inputs in chatbot applications, but we don’t have a pre-determined set of categories. Instead, we use the words in the texts themselves to find semantic similarities among the texts that enable us to group them into categories, <span class="No-Break">or topics.</span></p>
			<p>We will start by reviewing a few general considerations about semantically grouping <span class="No-Break">similar texts.</span></p>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor220"/>Topic modeling using clustering techniques and label derivation</h1>
			<p>We’ll start <a id="_idIndexMarker921"/>our exploration of topic modeling <a id="_idIndexMarker922"/>by looking at some considerations relating <a id="_idIndexMarker923"/>to grouping semantically similar documents <a id="_idIndexMarker924"/>in general, and then we’ll look at a <span class="No-Break">specific example.</span></p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor221"/>Grouping semantically similar documents</h2>
			<p>Like most <a id="_idIndexMarker925"/>of the machine learning problems we’ve discussed so far, the overall task generally breaks down into two sub-problems, representing the data and performing a task based on the representations. We’ll look at these two <span class="No-Break">sub-problems next.</span></p>
			<h3>Representing the data</h3>
			<p>The data representations we’ve looked at so far were reviewed in <a href="B19005_07.xhtml#_idTextAnchor144"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>. These <a id="_idIndexMarker926"/>approaches included the simple <strong class="bold">bag of words</strong> (<strong class="bold">BoW</strong>) variants, <strong class="bold">term frequency - inverse document frequency</strong> (<strong class="bold">TF-IDF</strong>), and <a id="_idIndexMarker927"/>newer approaches, including <strong class="bold">Word2Vec</strong>. Word2Vec is based on word vectors, which are vectors <a id="_idIndexMarker928"/>that represent words in isolation, without taking into <a id="_idIndexMarker929"/>account the context in which they occur. A newer <a id="_idIndexMarker930"/>representation, used in the <strong class="bold">BERT</strong> system that we discussed in the previous chapter, takes into account the contexts of words in a sentence or document to create numerical word representations, or <em class="italic">embeddings</em>. We will use BERT embeddings in this chapter to uncover similarities <span class="No-Break">among documents.</span></p>
			<h3>Working with data representations</h3>
			<p>This section <a id="_idIndexMarker931"/>will discuss two aspects of processing embeddings. First, we will discuss grouping similar texts into clusters, and then we will discuss visualizing <span class="No-Break">the clusters.</span></p>
			<h4>Clustering – grouping similar items</h4>
			<p><strong class="bold">Clustering</strong> is the <a id="_idIndexMarker932"/>main NLP task we’ll talk about in this chapter. Clustering is the name for a wide variety of algorithms that attempt to group data items together, based on similarities in the data representation. Clustering can be used with any dataset, whether or not the data items are text-based, as long as there is a numerical way of representing their similarity. In this chapter, we will review a practical set of tools to perform clustering, but you should be aware that there are many other options, and undoubtedly, there will be many new ones as technology moves forward. Two common approaches to clustering are k-means <span class="No-Break">and HDBSCAN:</span></p>
			<ul>
				<li><strong class="bold">k-means</strong>: The k-means <a id="_idIndexMarker933"/>algorithm, which we reviewed in <a href="B19005_06.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, is a very common clustering <a id="_idIndexMarker934"/>approach in which data points are initially randomly assigned to one of k clusters, the means of the clusters are computed, and the distance of the data points from the centers of the clusters is minimized through an iterative process. The value of k, or the number of clusters, is a hyperparameter that is selected by the developer. It can be considered to be the most <em class="italic">useful</em> number of clusters for the application. The k-means algorithm is often used because it is efficient and easy to implement, but other clustering algorithms – in particular, HDBSCAN – can yield <span class="No-Break">better results.</span></li>
				<li><strong class="bold">HDBSCAN</strong>: HDBSCAN <a id="_idIndexMarker935"/>is another popular clustering algorithm and stands for <strong class="bold">Hierarchical Density-Based Spatial Clustering of Applications with Noise</strong>. HDBSCAN takes into account the density of the data <a id="_idIndexMarker936"/>points within the clusters. Because of this, it is able to find oddly sized and differently sized clusters. It can also detect outliers or items that don’t fit well into a cluster, while k-means forces every item into <span class="No-Break">a cluster.</span></li>
			</ul>
			<h4>Visualizing the clusters</h4>
			<p><strong class="bold">Visualization</strong> is very <a id="_idIndexMarker937"/>important in unsupervised approaches, such as clustering, because it allows us to see what groups of similar data items look like and helps us judge whether or not the grouping result is useful. While clusters of similar items can be represented in any number of dimensions, we are only able to effectively visualize <a id="_idIndexMarker938"/>clusters in, at most, three dimensions. Consequently, in practice, dimensionality reduction is needed to reduce the number of dimensions. We will use a tool called <strong class="bold">Uniform Manifold Approximation and Projection</strong> (<strong class="bold">UMAP</strong>) for <span class="No-Break">dimensionality reduction.</span></p>
			<p>In the next section, we will use clustering and visualization to illustrate a specific application of unsupervised learning called topic modeling. The general problem that can be solved using topic modeling is that of classifying documents into different topics. The unique characteristic of this technique is that, unlike the classification examples we saw in earlier chapters, we don’t know what the topics are at the outset. Topic modeling can help us identify groups of similar documents, even if we don’t know what the eventual categories will be. </p>
			<p>In this example, we will use BERT transformer embeddings to represent the documents and HDBSCAN for clustering. Specifically, we will use the BERTopic Python library found at <a href="https://maartengr.github.io/BERTopic/index.html">https://maartengr.github.io/BERTopic/index.html</a>. The BERTopic library is customizable, but we will stick with the default settings for the most part in <span class="No-Break">our example.</span></p>
			<p>The data we’ll look at is a well-known dataset called <strong class="source-inline">20 newsgroups</strong>, which is a collection of 20,000 newsgroup documents from 20 different internet newsgroups. This is a popular dataset that is often used in text processing. The data is email messages of varying lengths <a id="_idIndexMarker939"/>that are posted to newsgroups. Here’s one example of a short message from this dataset, with the email <span class="No-Break">headers removed:</span></p>
			<pre class="source-code">
I searched the U Mich archives fairly thoroughly for 3D graphics packages,
I always thought it to be a mirror of sumex-aim.stanford.edu... I was wrong.
I'll look into GrafSys... it does sound interesting!
Thanks Cheinan.
BobC</pre>
			<p>The <strong class="source-inline">20 newsgroups</strong> dataset can be imported from the scikit-learn datasets or downloaded from the following <span class="No-Break">website: </span><a href="http://qwone.com/~jason/20Newsgroups/"><span class="No-Break">http://qwone.com/~jason/20Newsgroups/</span></a><span class="No-Break">.</span></p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout">Ken Lang, <em class="italic">Newsweeder: Learning to filter netnews</em>, 1995, <em class="italic">Proceedings of the Twelfth International Conference on Machine </em><span class="No-Break"><em class="italic">Learning</em></span><span class="No-Break">, 331–339</span></p>
			<p>In the following sections, we will go over topic modeling in detail using the <strong class="source-inline">20 newsgroups</strong> dataset and the BERTopic package. We will create embeddings, construct the model, generate proposed labels for the topics, and visualize the resulting clusters. The last step will be to show the process of finding topics for new documents using <span class="No-Break">our model.</span></p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor222"/>Applying BERTopic to 20 newsgroups</h2>
			<p>The first step <a id="_idIndexMarker940"/>in this application is to install BERTopic and import the necessary libraries in a Jupyter notebook, as <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
!pip install bertopic
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer
from sentence_transformers import SentenceTransformer
from bertopic import BERTopic
from umap import UMAP
from hdbscan import HDBSCAN
# install data
docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']</pre>
			<h3>Embeddings</h3>
			<p>The next step <a id="_idIndexMarker941"/>is to prepare the data representations, or embeddings, shown in <a id="_idIndexMarker942"/>the following code block. Because this is a slow process, it is useful to set <strong class="source-inline">show_progress_bar ()</strong> to <strong class="source-inline">True</strong> so that we can ensure that the process is moving along, even if it takes a <span class="No-Break">long time:</span></p>
			<pre class="source-code">
# Prepare embeddings
docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']
#The model is a Hugging Face transformer model
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
corpus_embeddings = embedding_model.encode(docs, show_progress_bar = True)
Batches: 100%|########################################################################| 589/589 [21:48&lt;00:00,  2.22s/it]</pre>
			<p>Instead of the earlier BERT word embeddings that we worked with in <a href="B19005_11.xhtml#_idTextAnchor193"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> in this exercise, we will work with <a id="_idIndexMarker943"/>sentence embeddings using <strong class="bold">Sentence </strong><span class="No-Break"><strong class="bold">Bert</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">SBERT</strong></span><span class="No-Break">).</span></p>
			<p>SBERT produces one embedding per sentence. We will use a package called <strong class="source-inline">SentenceTransformers</strong>, available from Hugging Face, and the <strong class="source-inline">all-MiniLM-L6-v2</strong> model, which is <a id="_idIndexMarker944"/>recommended by BERTopic. However, many other transformer <a id="_idIndexMarker945"/>models can be used. These include, for example, the <strong class="source-inline">en_core_web_trf</strong> spaCy model, or the <strong class="source-inline">distilbert-base-cased</strong> Hugging Face model. BERTopic provides a guide to a wide selection of other models that you can use <span class="No-Break">at </span><a href="https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html"><span class="No-Break">https://maartengr.github.io/BERTopic/getting_started/embeddings/embeddings.html</span></a><span class="No-Break">.</span></p>
			<p>We can see what the actual embeddings look like in the <span class="No-Break">following output:</span></p>
			<pre class="source-code">
corpus_embeddings.view()
array([[ 0.002078  ,  0.02345043,  0.02480883, ...,  0.00143592,
         0.0151075 ,  0.05287581],
       [ 0.05006033,  0.02698092, -0.00886482, ..., -0.00887168,
        -0.06737082,  0.05656359],
       [ 0.01640477,  0.08100049, -0.04953594, ..., -0.04184629,
        -0.07800221, -0.03130952],
       ...,
       [-0.00509084,  0.01817271,  0.04388074, ...,  0.01331367,
        -0.05997065, -0.05430664],
       [ 0.03508159, -0.05842971, -0.03385153, ..., -0.02824297,
        -0.05223113,  0.03760364],
       [-0.06498063, -0.01133722,  0.03949645, ..., -0.03573753,
         0.07217913,  0.02192113]], dtype=float32)</pre>
			<p>Using the <strong class="source-inline">corpus_embeddings.view()</strong> method shown here, we can see a summary of the embeddings, which are an array of arrays of floating point numbers. Looking directly <a id="_idIndexMarker946"/>at the embeddings isn’t particularly useful itself, but it <a id="_idIndexMarker947"/>gives you something of a sense of what the actual data <span class="No-Break">looks like.</span></p>
			<h3>Constructing the BERTopic model</h3>
			<p>Once the embeddings have been computed, we can build the BERTopic model. The BERTopic model <a id="_idIndexMarker948"/>can take a large number of parameters, so we won't show them all. We will show some useful ones, but there are many more, and you can consult the BERTopic documentation for additional ideas. The BERTopic model can be constructed very simply, with just the documents and the embeddings as parameters, as <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
model = BERTopic().fit(docs, corpus_embeddings)</pre>
			<p>This simple model has defaults for the parameters that will usually lead to a reasonable result. However, to illustrate some of the flexibility that’s possible with BERTopic, we’ll show next how the model can be constructed with a richer set of parameters, with the code <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
from sklearn.feature_extraction.text import CountVectorizer
vectorizer_model = CountVectorizer(stop_words = "english", max_df = .95, min_df = .01)
# setting parameters for HDBSCAN (clustering) and UMAP (dimensionality reduction)
hdbscan_model = HDBSCAN(min_cluster_size = 30, metric = 'euclidean', prediction_data = True)
umap_model = UMAP(n_neighbors = 15, n_components = 10, metric = 'cosine', low_memory = False)
# Train BERTopic
model = BERTopic(
    vectorizer_model = vectorizer_model,
    nr_topics = 'auto',
    top_n_words = 10,
    umap_model = umap_model,
    hdbscan_model = hdbscan_model,
    min_topic_size = 30,
    calculate_probabilities = True).fit(docs, corpus_embeddings)</pre>
			<p>In the preceding code, we start by defining several useful models. The first one is <strong class="source-inline">CountVectorizer</strong>, which we saw in <a href="B19005_07.xhtml#_idTextAnchor144"><span class="No-Break"><em class="italic">Chapter 7</em></span></a> and <a href="B19005_10.xhtml#_idTextAnchor184"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, where we used it to vectorize text documents to formats such as BoW. Here, we will use the <a id="_idIndexMarker949"/>vectorizer to remove stopwords after dimensionality reduction and clustering so that they don’t end up being included in <span class="No-Break">topic labels.</span></p>
			<p><strong class="bold">Stopwords</strong> should not <a id="_idIndexMarker950"/>be removed from documents before preparing embeddings because the transformers have been trained on normal text, including stopwords, and the models will be less effective without <span class="No-Break">the stopwords.</span></p>
			<p>The vectorizer model parameters indicate that the model is constructed with English stopwords and that only words that occur in fewer than 95% of the documents and more than 1% are included. This is to exclude extremely common and extremely rare words from the model, which are unlikely to be helpful to <span class="No-Break">distinguish topics.</span></p>
			<p>The second <a id="_idIndexMarker951"/>model we will define is the HDBSCAN model, which is used for clustering. Some of the parameters include <span class="No-Break">the following:</span></p>
			<ul>
				<li>The <strong class="source-inline">min_cluster_size</strong> parameter is the minimum number of documents that we want to be in a cluster. Here, we’ve selected '<strong class="source-inline">30'</strong> as the minimum cluster size. This parameter can vary, depending on the problem you’re trying to solve, but you might want to consider a larger number if the number of documents in the dataset <span class="No-Break">is large.</span></li>
				<li><strong class="source-inline">prediction_data</strong> is set to <strong class="source-inline">True</strong> if we want <a id="_idIndexMarker952"/>to be able to predict the topics of new documents after the model <span class="No-Break">is trained.</span></li>
			</ul>
			<p>The next <a id="_idIndexMarker953"/>model is the <strong class="bold">uniform manifold approximation and projection</strong> (<strong class="bold">UMAP</strong>) model, which is used for dimensionality reduction. Besides making it easier to visualize multidimensional data, UMAP also <a id="_idIndexMarker954"/>makes it easier to cluster. Some of its parameters include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="source-inline">n-neighbors</strong>: This constrains the size of the area that UMAP will look at when learning the structure of <span class="No-Break">the data.</span></li>
				<li><strong class="source-inline">n-components</strong>: This determines the dimensionality of the reduced dimension space we <span class="No-Break">will use.</span></li>
				<li><strong class="source-inline">low_memory</strong>: This determines system memory management behavior. If the parameter is <strong class="source-inline">False</strong>, the algorithm will use a faster and more memory-intensive approach. If running out of memory is a problem with large datasets, you can set <strong class="source-inline">low_memory</strong> <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">True</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>With these preliminary models defined, we can move on to defining the BERTopic model itself. The parameters <a id="_idIndexMarker955"/>that are set in this example are <span class="No-Break">the following:</span></p>
			<ul>
				<li>The models for the three tools we’ve already defined – the vectorizer model, the UMAP model, and the <span class="No-Break">HDBSCAN model.</span></li>
				<li><strong class="source-inline">nr_topics</strong>: If we have an idea of how many topics we want to find, this parameter can be set to that number. In this case, it is set to <strong class="source-inline">auto</strong>, and HDBSCAN will find a good estimate of the number <span class="No-Break">of topics.</span></li>
				<li><strong class="source-inline">top_n_words</strong>: When generating labels, BERTopic should consider only the <em class="italic">n</em> most frequent words in <span class="No-Break">a cluster.</span></li>
				<li><strong class="source-inline">min_topic_size</strong>: The minimum number of documents that should be considered to form <span class="No-Break">a topic.</span></li>
				<li><strong class="source-inline">calculate_probabilities</strong>: This calculates the probabilities of all topics <span class="No-Break">per document.</span></li>
			</ul>
			<p>Running the code <a id="_idIndexMarker956"/>in this section will create clusters from the original documents. The number and size of the clusters will vary, depending on the parameters that were set in the generation of the model. You are encouraged to try different settings of the parameters and compare the results. As you think about the goals of your application, consider whether some of the settings seem to yield more or less <span class="No-Break">helpful results.</span></p>
			<p>Up to this point, we have used clusters of similar documents, but they are not labeled with any categories. It would be more useful if the clusters had names. Let’s see how we can get names or labels for the clusters that relate to what they are about. The next section will review ways to label <span class="No-Break">the clusters.</span></p>
			<h3>Labeling</h3>
			<p>Once we have the clusters, there are various approaches to labeling them with topics. A manual approach, where you just look at the documents and think about what a good label might be, should <a id="_idIndexMarker957"/>not necessarily be ruled out. However, there are <a id="_idIndexMarker958"/>automatic approaches that can suggest topics based on the words that occur in the documents in the <span class="No-Break">various clusters.</span></p>
			<p>BERTopic uses a method to <a id="_idIndexMarker959"/>suggest topic labels called class-based <strong class="source-inline">tf-idf</strong>, or <strong class="source-inline">c-tf-idf</strong>. You will <a id="_idIndexMarker960"/>recall that TF-IDF was discussed in earlier chapters as a document vectorization approach that identifies the most diagnostic terms for a document class. It does this by taking into account the frequency of a term in a document, compared to its frequency in the overall document collection. Terms that are frequent in one document but not overall in the dataset are likely to be indicative that a document should be assigned to a <span class="No-Break">specific category.</span></p>
			<p>Class-based TF-IDF takes this intuition a step further by treating each cluster as if it were a single document. It then looks at the terms that occur frequently in a cluster, but not overall in the entire dataset, to identify words that are useful to label a topic. Using this metric, labels can be generated for the topics using the most diagnostic words for each cluster. We can see in <em class="italic">Table 12.1</em> the labels generated for the 10 most frequent topics in a dataset, along with the number of documents in <span class="No-Break">each topic.</span></p>
			<p>Note that the <a id="_idIndexMarker961"/>first topic in the table, <em class="italic">-1</em>, is a catchall topic that includes the <a id="_idIndexMarker962"/>documents that don’t fall into <span class="No-Break">any topic.</span></p>
			<table id="table001-6" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Topic</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Count</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Name</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>0</p>
						</td>
						<td class="No-Table-Style">
							<p>-1</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">6,928</span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="source-inline">-</strong><span class="No-Break"><strong class="source-inline">1_maxaxaxaxaxaxaxaxaxaxaxaxaxaxax_dont_know_like</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p>0</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,820</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">0_game_team_games_players</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p>1</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,569</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">1_space_launch_nasa_orbit</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p>2</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,313</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">2_car_bike_engine_cars</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style">
							<p>3</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">1,168</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">3_image_jpeg_window_file</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p>4</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">990</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">4_armenian_armenians_people_turkish</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>6</p>
						</td>
						<td class="No-Table-Style">
							<p>5</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">662</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">5_drive_scsi_drives_ide</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>7</p>
						</td>
						<td class="No-Table-Style">
							<p>6</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">636</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">6_key_encryption_clipper_chip</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>8</p>
						</td>
						<td class="No-Table-Style">
							<p>7</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">633</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">7_god_atheists_believe_atheism</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>9</p>
						</td>
						<td class="No-Table-Style">
							<p>8</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">427</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">8_cheek___</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">10</span></p>
						</td>
						<td class="No-Table-Style">
							<p>9</p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">423</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">9_israel_israeli_jews_arab</strong></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 12.1 – The top 10 topics and automatically generated labels</p>
			<h3>Visualization</h3>
			<p>Visualization is <a id="_idIndexMarker963"/>extremely useful in unsupervised learning, because deciding how <a id="_idIndexMarker964"/>to proceed in the development process often depends on intuitions that can be assisted by looking at results in <span class="No-Break">different ways.</span></p>
			<p>There are many ways of visualizing the results of topic modeling. One useful visualization can be obtained with a BERTopic method, <strong class="source-inline">model.visualize_barchart()</strong>, which shows the top topics and their top words, as shown in <span class="No-Break"><em class="italic">Figure 12</em></span><em class="italic">.1</em>. For example, looking at the top words in <strong class="bold">Topic 1</strong> suggests that this topic is about space, and <em class="italic">Table 12.1</em> suggests that this topic could be <span class="No-Break">labeled </span><span class="No-Break"><strong class="source-inline">space_launch_nasa_orbit</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B19005_12_01.jpg" alt="Figure 12.1﻿ – The top seven topics and their most significant words"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1 – The top seven topics and their most significant words</p>
			<p>Another important visualization technique that is often used in clustering is representing <a id="_idIndexMarker965"/>each item in a cluster as a dot, representing their similarities <a id="_idIndexMarker966"/>by the distance between the dots, and assigning different colors or markers to the clusters. This clustering can be produced with a BERTopic method, <strong class="source-inline">visualize_documents()</strong>, as shown in the following code with the minimal <strong class="source-inline">docs</strong> and <span class="No-Break"><strong class="source-inline">embeddings</strong></span><span class="No-Break"> parameters:</span></p>
			<pre class="source-code">
model.visualize_documents(docs, embeddings = corpus_embeddings)</pre>
			<p>Additional parameters can be set to configure a cluster plot in various ways, as documented in the BERTopic documentation. For example, you can set the display to show or hide the cluster labels, or to only show the <span class="No-Break">top topics.</span></p>
			<p>The clustering for the top seven topics in the <strong class="source-inline">20 newsgroups</strong> data can be seen in <span class="No-Break"><em class="italic">Figure 12</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B19005_12_02.jpg" alt="Figure 12.2﻿ – The clustered documents for the top seven topics in the 20 newsgroups dataset with their generated labels"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.2 – The clustered documents for the top seven topics in the 20 newsgroups dataset with their generated labels</p>
			<p>There are <a id="_idIndexMarker967"/>seven topics displayed in <span class="No-Break"><em class="italic">Figure 12</em></span><em class="italic">.2</em>, corresponding to the seven topics in <span class="No-Break"><em class="italic">Figure 12</em></span><em class="italic">.1</em>, each labeled with its automatically generated label. In addition, there are <a id="_idIndexMarker968"/>documents in <span class="No-Break"><em class="italic">Figure 12</em></span><em class="italic">.2</em> shown in light gray that were not assigned to any cluster. These are the documents shown as belonging to topic <em class="italic">-1</em> in <span class="No-Break"><em class="italic">Table 12.1</em></span><span class="No-Break">.</span></p>
			<p>One insight we can gain from the cluster display is the fact that there are many unassigned documents, which means that we may want to increase the number of topics to look for (by increasing the <strong class="source-inline">nr_topic</strong>s parameter to <strong class="source-inline">model()</strong>). Another insight is that some of the topics – for example, <strong class="source-inline">1_space_launch_nasa</strong> – seem to be split over several clusters. This means that it might be more meaningful for them to be considered as separate topics. As in the case of unclassified documents, we can investigate this possibility by increasing the number of topics to <span class="No-Break">look for.</span></p>
			<p>We have shown two of the most useful BERTopic visualizations, but there are many more. You are encouraged to consult the BERTopic documentation for <span class="No-Break">other ideas.</span></p>
			<h3>Finding the topic of a new document</h3>
			<p>Once the <a id="_idIndexMarker969"/>clustering is complete, the model can be used to find the topics of new documents, similar to a classification application. This can be done with the <strong class="source-inline">model.transform()</strong> method, as <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
sentence_model = SentenceTransformer("all-MiniLM-L6-v2")
new_docs = ["I'm looking for a new graphics card","when is the next nasa launch"]
embeddings = sentence_model.encode(new_docs)
topics, probs = model.transform(new_docs,embeddings)
print(topics)
[-1, 3]</pre>
			<p>The predicted topics for the two documents in <strong class="source-inline">new_docs</strong> are <strong class="source-inline">-1</strong> (no topic) and <strong class="source-inline">3</strong>, which stands <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">3_space_launch_orbit_nasa</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor223"/>After clustering and topic labeling</h2>
			<p>Recall that the most common application of clustering is to explore the data, often in preparation <a id="_idIndexMarker970"/>to develop a supervised classification application. We can look at the clustering results and decide, for example, that some of the clusters are very similar and close to each other. In that case, it might be difficult to distinguish documents in those topics from each other, even after supervised training, and it would be a good idea to combine those clusters into a single topic. Similarly, if we find very small clusters, we would probably get more reliable results if the small clusters are combined with similar <span class="No-Break">large clusters.</span></p>
			<p>We can also modify labels to make them more helpful or informative. For example, topic <em class="italic">1</em> in <em class="italic">Table 12.1</em> is <strong class="source-inline">1_space_launch_nasa_orbit</strong>. You might decide that <strong class="source-inline">space</strong> would be a simpler label that is, nevertheless, just as informative as the automatically <span class="No-Break">generated label.</span></p>
			<p>After making any adjustments to the clusters and labels that you find helpful, the result will be a supervised dataset, just like the supervised datasets we worked with, such as the movie reviews. You can use this as you would use any supervised dataset in <span class="No-Break">NLP applications.</span></p>
			<p>While <a id="_idIndexMarker971"/>unsupervised topic modeling can be a very useful technique, it is also possible to take advantage of data that is even partially supervised. We will summarize some of the ideas that the NLP research community has explored to use partially annotated data in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-202"><a id="_idTextAnchor224"/>Making the most of data with weak supervision</h1>
			<p>In between completely supervised and unsupervised learning are several approaches to partial supervision, where only x data is supervised. Like unsupervised approaches, the goal <a id="_idIndexMarker972"/>of these techniques is to make the most of supervised data, which can be expensive to obtain. One <a id="_idIndexMarker973"/>advantage of partial supervision over unsupervised approaches is that unsupervised results don’t automatically have useful labels. The labels have to be supplied, either manually or through some of the techniques we saw earlier in this chapter. In general, with weak supervision, the labels are supplied based on the subset of the data that <span class="No-Break">is supervised.</span></p>
			<p>This is an active research area, and we will not go into it in detail. However, it is useful to know what the general tactics of weak supervision are so that you will be able to apply them as they relate to specific tasks, depending on the kind of labeled data that <span class="No-Break">is available.</span></p>
			<p>Some tactics <a id="_idIndexMarker974"/>for weak supervision include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Incomplete supervision, where only partial data has <span class="No-Break">ground-truth labels</span></li>
				<li>Inexact supervision, where the data has <span class="No-Break">coarse-grained labels</span></li>
				<li>Inaccurate supervision, where some of the labels might <span class="No-Break">be incorrect</span></li>
				<li>Semi-supervised learning, where some predefined labels are provided to help push a model toward <span class="No-Break">known classes</span></li>
			</ul>
			<p>These approaches are worth considering in applications where full annotation is too expensive or takes too long. In addition, they can also be useful in situations where unsupervised <a id="_idIndexMarker975"/>learning would <a id="_idIndexMarker976"/>be problematic because there are predefined labels that are required by other parts of the overall application, such as <span class="No-Break">a database.</span></p>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor225"/>Summary</h1>
			<p>In this chapter, you learned about the basic concepts of unsupervised learning. We also worked through a specific application of unsupervised learning, topic modeling, using a BERT-based tool called BERTopic. We used the BERTopic package to identify clusters of semantically similar documents and propose labels for the clusters based on the words they contain, without needing to use any supervised annotations of the <span class="No-Break">cluster topics.</span></p>
			<p>In the next chapter, <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, we will address the question of measuring how good our results are using quantitative techniques. Quantitative evaluation is useful in research applications to compare results to those from previous research, and it is useful in practical applications to ensure that the techniques being used meet the application’s requirements. Although evaluation was briefly discussed in earlier chapters, <a href="B19005_13.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 13</em></span></a> will discuss it in depth. It will include segmenting data into training, validation, and test data, evaluation with cross-validation, evaluation metrics such as precision and recall, the area under the curve, ablation studies, statistical significance, inter-annotator agreement, and <span class="No-Break">user testing.</span></p>
		</div>
	</body></html>