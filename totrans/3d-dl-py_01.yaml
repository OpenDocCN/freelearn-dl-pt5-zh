- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developers working with 3D computer vision will be able to put their knowledge
    to work with this practical guide to 3D deep learning. The book provides a hands-on
    approach to implementation and associated methodologies that will have you up
    and running and productive in no time.
  prefs: []
  type: TYPE_NORMAL
- en: Complete with step-by-step explanations of essential concepts, practical examples,
    and self-assessment questions, you will begin by exploring state-of-the-art 3D
    deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: You will learn about basic 3D mesh and point cloud data processing using PyTorch3D,
    such as loading and saving PLY and OBJfiles, projecting 3D points onto camera
    coordinates using perspective camera models or orthographic camera models, and
    rendering point clouds and meshes to images, among other things. You will also
    learn how to implement certain state-of-the-art 3D deep learning algorithms, such
    as differential rendering, NeRF, SynSin, and Mesh R-CNN because coding for these
    deep learning models becomes easier using the PyTorch3D library.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this book, you will be able to implement your own 3D deep learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for beginners and intermediate-level machine learning practitioners,
    data scientists, machine learning engineers, and deep learning engineers who are
    looking to become well-versed in computer vision techniques using 3D data.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B18217_01.xhtml#_idTextAnchor015), *Introducing 3D Data Processing*,
    will cover the basics of 3D data, such as how 3D data is stored and the basic
    concepts of meshes and point clouds, world coordinations, and camera coordinations.
    It also shows us what NDC is (a frequently used coordination), how to convert
    between different coordinations, perspective cameras, and orthographic cameras,
    and which camera models should be used.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B18217_02.xhtml#_idTextAnchor030), *Introducing 3D Computer Vision
    and Geometry*, will show us the basic concepts in computer graphics, such as rendering
    and shading. We will learn about some fundamental concepts that will be required
    in the later chapters of this book, including, 3D geometry transforms, PyTorch
    tensors, and optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B18217_03.xhtml#_idTextAnchor046), *Fitting Deformable Mesh Models
    to Raw Point Clouds*, will present a hands-on project of using a deformable 3D
    model to fit a noisy 3D observation using all the knowledge that we have learned
    in the previous chapters. We will explore frequently used cost functions, why
    these cost functions are important, and when these cost functions are usually
    used. Finally, we will explore a concrete example of which cost functions have
    been selected for which tasks and how to set up the optimization loop to obtain
    the results that we want.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B18217_04.xhtml#_idTextAnchor059), *Learning Object Pose Detection
    and Tracking by Differentiable Rendering*, will talk about the basic concepts
    of differentiable rendering. It will help you understand the basic concepts and
    know when you can apply these techniques to solve your own problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18217_05.xhtml#_idTextAnchor070), *Understanding Differentiable
    Volumetric Rendering*, will present a hands-on project using differentiable rendering
    to estimate camera positions from a single image and a known 3D mesh model. We
    will learn how to practically use PyTorch3D to set up cameras, renders, and shaders.
    We will also get hands-on experience in using different cost functions to get
    optimization results.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18217_06.xhtml#_idTextAnchor081), *Exploring Neural Radiance
    Fields (NeRF)*, will provide a hands-on project using differentiable rendering
    to estimate 3D mesh models from several images and texture models.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18217_07.xhtml#_idTextAnchor094), *Exploring Controllable Neural
    Feature Fields*, will cover a very important algorithm for view synthesis, which
    is NeRF. We will learn what it is all about, how to use it, and where it is valuable.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18217_08.xhtml#_idTextAnchor108), *Modeling the Human Body in
    3D*, will explore 3D human body fitting using the SMPL algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18217_09.xhtml#_idTextAnchor124), *Performing End-to-End View
    Synthesis with SynSin*, will cover SynSin, which is a state-of-the-art deep learning
    image synthesis model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18217_10.xhtml#_idTextAnchor134), *Mesh R-CNN*, will introduce
    us to Mesh R-CNN, which is another state-of-the-art method for predicting 3D voxel
    models from a single input image.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Python 3.6+ | Windows, macOS, or Linux |'
  prefs: []
  type: TYPE_TB
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access** **the code from the book’s GitHub repository (a
    link is available in the next section). Doing so will help you avoid any potential
    errors related to copying and** **pasting code.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please check out these papers for reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18217_06.xhtml#_idTextAnchor081)*:* [https://arxiv.org/abs/2003.08934](https://arxiv.org/abs/2003.08934)*,*
    [https://github.com/yenchenlin/nerf-pytorch](https://github.com/yenchenlin/nerf-pytorch)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter* *7*](B18217_07.xhtml#_idTextAnchor094)*:* [https://m-niemeyer.github.io/project-pages/giraffe/index.xhtml](https://m-niemeyer.github.io/project-pages/giraffe/index.xhtml)*,*[https://arxiv.org/abs/2011.12100](https://arxiv.org/abs/2011.12100)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18217_08.xhtml#_idTextAnchor108)*:* [https://smpl.is.tue.mpg.de/](https://smpl.is.tue.mpg.de/)*,*
    [https://smplify.is.tue.mpg.de/, https://smpl-x.is.tue.mpg.de/](https://smplify.is.tue.mpg.de/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18217_09.xhtml#_idTextAnchor124)*:* [https://arxiv.org/pdf/1912.08804.pdf](https://arxiv.org/pdf/1912.08804.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18217_10.xhtml#_idTextAnchor134)*:* [https://arxiv.org/abs/1703.06870](https://arxiv.org/abs/1703.06870),
    [https://arxiv.org/abs/1906.02739](https://arxiv.org/abs/1906.02739)'
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/3D-Deep-Learning-with-Python](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python).
    If there’s an update to the code, it will be updated in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots and diagrams
    used in this book. You can download it here: [https://packt.link/WJr0Q](https://packt.link/WJr0Q).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “ Next, we need to update the `./``options/options.py`
    file”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    “The refinement module (**g**) gets inputs from the neural point cloud renderer
    and then outputs the final reconstructed image.”'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](http://customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](http://copyright@packt.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share Your Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *3D Deep Learning with Python*, we’d love to hear your thoughts!
    [Please click here to go straight to the Amazon review page](https://packt.link/r/1-803-24782-7)
    for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link below
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18217_QR_Free_PDF.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/9781803247823](https://packt.link/free-ebook/9781803247823)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'PART 1: 3D Data Processing Basics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This first part of the book will define the most basic concepts for data and
    image processing since these concepts are essential to our later discussions.
    This part of the book makes the book self-contained so that readers do not need
    to read any other books to get started with learning about PyTorch3D.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part includes the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B18217_01.xhtml#_idTextAnchor015), *Introducing 3D Data Processing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B18217_02.xhtml#_idTextAnchor030), *Introducing 3D Computer Vision
    and Geometry*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
