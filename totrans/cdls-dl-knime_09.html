<html><head></head><body>
		<div id="_idContainer713">
			<h1 id="_idParaDest-121"><em class="italic"><a id="_idTextAnchor230"/>Chapter 7: </em>Implementing NLP Applications</h1>
			<p>In <a href="B16391_06_Final_VK_ePUB.xhtml#_idTextAnchor181"><em class="italic">Chapter 6</em></a>, <em class="italic">Recurrent Neural Networks for Demand Prediction</em>, we introduced <strong class="bold">Recurrent Neural Networks</strong> (<strong class="bold">RNNs</strong>) as a family of neural networks that are especially powerful to analyze sequential data. As a case study, we trained a <strong class="bold">Long Short-Term Memory</strong> (<strong class="bold">LSTM</strong>)-based RNN to predict the next value in the time series of consumed electrical energy. However, RNNs are not just suitable for strictly numeric time series, as they have also been applied successfully to other types of time series.</p>
			<p>Another field where RNNs are state of the art is <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>). Indeed, RNNs have been applied successfully to text classification, language models, and neural machine translation. In all of these tasks, the time series is a sequence of words or characters, rather than numbers.</p>
			<p>In this chapter, we will run a short review of some classic NLP case studies and their RNN-based solutions: a sentiment analysis application, a solution for free text generation, and a similar solution for the generation of name candidates for new products.</p>
			<p>We will start with an overview of text encoding techniques to prepare the sequence of words/characters to feed our neural network. The first case study, then, classifies text based on its sentiment. The last two case studies generate new text as sequences of new words, and new words as sequences of new characters, respectively.</p>
			<p>In this chapter we will cover the following topics:</p>
			<ul>
				<li>Exploring Text Encoding Techniques for Neural Networks</li>
				<li>Finding the Tone of your Customers' Voice – Sentiment Analysis</li>
				<li>Generating Free Text with RNNs</li>
				<li>Generating Product Names with RNNs</li>
			</ul>
			<h1 id="_idParaDest-122"><a id="_idTextAnchor231"/>Exploring Text Encoding Techniques for Neural Networks</h1>
			<p>In <a href="B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a>, <em class="italic">Building and Training a Feedforward Neural Network</em>, you learned that feedforward networks – and all other neural networks<a id="_idIndexMarker563"/> as well – are trained on numbers and don't understand nominal values. In this chapter, we want to feed words and characters into neural <a id="_idIndexMarker564"/>networks. Therefore, we need to introduce some techniques to encode sequences of words or characters – that is, sequences of nominal values – into sequences of numbers or numerical vectors. In addition, in NLP applications with RNNs, it is mandatory that the order of words or characters in the sequence is retained throughout the text encoding procedure. </p>
			<p>Let's have a look at some <strong class="bold">text encoding</strong> techniques before we dive into the NLP case studies.</p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor232"/>Index Encoding</h2>
			<p>In <a href="B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a>, <em class="italic">Building and Training a Feedforward Neural Network</em>, you learned about <strong class="bold">index encoding</strong> for nominal values. The idea was to represent each nominal class with an<a id="_idIndexMarker565"/> integer value, also called an index. </p>
			<p>We can use this same idea for text encoding. Here, instead of encoding each class with a different index, we encode each word or each character with a different index. First, a dictionary must be created to map all words/characters in the text collection to an index; afterward, through this mapping, each word/character is transformed into its corresponding index and, therefore, each sequence of words/characters into the sequence of corresponding indexes. In the end, each text is represented as a sequence of indexes, where each index encodes a word or a character. The following figure gives you an example:</p>
			<p class="figure-caption"><a id="_idTextAnchor233"/></p>
			<div>
				<div id="_idContainer624" class="IMG---Figure">
					<img src="image/B16391_07_001.jpg" alt="Figure 7.1 – An example of text encoding via indexes at the word level"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1 – An example of text encoding via indexes at the word level</p>
			<p>Notice that<a id="_idIndexMarker566"/> index 1, for the word <em class="italic">the</em>, and index 13, for the word <em class="italic">brown</em>, are repeated twice in the sequence, as the words appear twice in the example sentence, <em class="italic">the quick brown fox jumped over the brown dog</em>.</p>
			<p>Later in this chapter, in the <em class="italic">Finding the Tone of Your Customers' Voice – Sentiment Analysis</em> section, we'll use index encoding on words to represent text.</p>
			<p>In the <em class="italic">Free Text Generation with RNNs</em> section, on the other hand, we'll use one-hot vectors as text encoding on characters. Let's explore what one-hot vector encoding is.</p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor234"/>One-Hot Vector Encoding</h2>
			<p>The sequence of indexes has the disadvantage that it introduces an artificial distance between words/characters. For example, if <em class="italic">apple</em> is encoded as 1, <em class="italic">shoe</em> as 2, and <em class="italic">pear</em> as 3, <em class="italic">apple</em> and <em class="italic">pear</em> are further away from each other (distance = 2) than <em class="italic">shoe</em> and <em class="italic">pear</em> (distance = 1), which semantically might not make sense. In this way, as words don't have an ordered structure, we would introduce an artificial distance/similarity between words that might not exist in reality. We also encountered this problem in <a href="B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a>, <em class="italic">Building and Training a Feedforward Neural Network</em>, and we solved it by introducing the concept of one-hot vectors.</p>
			<p>The idea of <strong class="bold">one-hot vector encoding</strong> is to<a id="_idIndexMarker567"/> represent each feature with a vector, where the distance across all vectors is the same. In the case of word or character encoding, the features are the different words/characters and each word/character is represented by a one-hot vector. A one-hot vector consists of as many binary components as the number of different words/characters in the dataset. Each component is associated with one word/character and it is set to <strong class="source-inline">1</strong> to encode a specific word/character, or otherwise to <strong class="source-inline">0</strong>. This means that each word/character is represented as a one-hot vector and therefore, each text is a sequence of one-hot vectors. The following figure shows an example of one-hot vector encoding for the sentence <em class="italic">the quick brown fox jumped over the brown dog</em>.</p>
			<p>Notice, in <em class="italic">Figure 7.2</em>, that the <a id="_idIndexMarker568"/>one-hot vectors for the words <em class="italic">the</em> and <em class="italic">brown</em> repeat twice in the sequence:<a id="_idTextAnchor235"/></p>
			<div>
				<div id="_idContainer625" class="IMG---Figure">
					<img src="image/B16391_07_002.jpg" alt="Figure 7.2 – An example of text encoding via one-hot vectors at the word level"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2 – An example of text encoding via one-hot vectors at the word level</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Remember that the <strong class="bold">Keras Learner</strong> node<a id="_idIndexMarker569"/> can convert index-based encodings into one-hot vectors. Thus, to train a neural network on one-hot-vectors, it is sufficient to feed it with an index-based encoding of the text document.</p>
			<p>A commonly used text encoding – similar to one-hot vectors but that doesn't retain the word order – are <strong class="bold">document vectors</strong>. Here, a vector is built from all the words available in the <a id="_idIndexMarker570"/>document collection and each word becomes a component in the vector space. Thus, each text is transformed into a vector of 0s and 1s, encoding the presence (<strong class="source-inline">1</strong>) or absence (<strong class="source-inline">0</strong>) of the words. One vector represents one text document and contains multiple 1s. Notice that this encoding does not retain the word order because all of the text is encoded within the same vector structure regardless of the word order.</p>
			<p>Working with words, the dimension of one-hot vectors is equal to the dictionary size – that is, to the number of words available in the document corpus. If the document corpus is large, the dictionary size quickly becomes the number of words in the whole language. Therefore, one-hot vector encoding on a word level can lead to very large and sparse representations.</p>
			<p>Working with characters, the dictionary size is the size of the character set, which, even including punctuation and special signs, is much smaller than in the previous case. Thus, one-hot vector encoding fits well for character encoding but might lead to dimensionality explosion on word encoding.</p>
			<p>To encode a document at the word level, a much more appropriate method is embeddings. </p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor236"/>Embeddings for Word Encoding</h2>
			<p>The goal <a id="_idIndexMarker571"/>of word embeddings<a id="_idIndexMarker572"/> is to map words into a geometric space. This is done by associating a numeric vector to every word in a dictionary in a way that words with similar meanings have similar vectors and the distance between any two vectors captures part of the semantic relationship between the two associated words. The geometric space formed by these vectors is called the <em class="italic">embedding space</em>. For word encoding, the embedding space has a lower dimension (only a few tens or hundreds) than the vector space for one-hot vector encodings (in the order of many thousands).</p>
			<p>To learn the projection of each word into the continuous vector space, a dedicated neural network layer is used, which is called the embedding layer. This layer learns to associate a vector representation with each word. The best-known word<a id="_idIndexMarker573"/> embedding techniques <a id="_idIndexMarker574"/>are <strong class="bold">Word2vec</strong> and <strong class="bold">GloVe</strong>.</p>
			<p>There are two ways that <a id="_idIndexMarker575"/>words embeddings can be used (J. Brownlee, <em class="italic">How to Use Word Embedding Layers for Deep Learning with Keras</em>, Machine Learning <a id="_idIndexMarker576"/>Mastery Blog, 2017, <a href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/">https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/</a>):</p>
			<ul>
				<li>Adopting a ready-to-go layer previously trained on some external text corpus</li>
				<li>Training a new embedding layer as part of your neural network</li>
			</ul>
			<p>If trained jointly with a neural network, the input to an embedding layer is an index-based encoded sequence. The number of output units in the embedding layer defines the dimension of the embedding space. The weights of the embedding layer, which are used to calculate the embedding representation of each index, and therefore of each word, are learned during the training of the network.</p>
			<p>Now that we are familiar with different text encoding techniques, let's move on to our first NLP use case.</p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor237"/>Finding the Tone of Your Customers' Voice – Sentiment Analysis</h1>
			<p>A common use case for<a id="_idIndexMarker577"/> NLP is <strong class="bold">sentiment analysis</strong>. Here, the goal is to identify the underlying emotion in some text, whether positive or negative, and all the nuances in between. Sentiment analysis is implemented in many fields, such as to analyze incoming messages, emails, reviews, recorded conversations, and other similar texts.</p>
			<p>Generally, sentiment analysis <a id="_idIndexMarker578"/>belongs to a bigger group of NLP applications known as text classification. In the case of sentiment analysis, the goal is to predict the sentiment class.</p>
			<p>Another common example of text classification is <a id="_idIndexMarker579"/>language detection. Here, the goal is to recognize the text language. In both cases, if we use an RNN for the task, we need to adopt a <em class="italic">many-to-one architecture</em>. A many-to-one neural architecture accepts a sequence of inputs at different times, <img src="image/Formula_B16391_07_001.png" alt=""/>, and uses the final state of the output unit to predict the one single class – that is, sentiment or language.</p>
			<p><em class="italic">Figure 7.3</em> shows an example of a many-to-one arch<a id="_idTextAnchor238"/>itecture:</p>
			<div>
				<div id="_idContainer627" class="IMG---Figure">
					<img src="image/B16391_07_003.jpg" alt="Figure 7.3  –  An example of a many-to-one neural architecture: a sequence of many inputs at different times and only the final status of the output"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.3  –  An example of a many-to-one neural architecture: a sequence of many inputs at different times and only the final status of the output</p>
			<p>In our first use case in this chapter, we want to analyze the sentiment of movie reviews. The goal is to train an RNN at a word level, with an embedding layer and an LSTM layer.</p>
			<p>For this example, we will use the IMDb dataset, which contains two columns: the text of the movie reviews and the sentiment. The sentiment is encoded as <strong class="source-inline">1</strong> for positive reviews and as <strong class="source-inline">0</strong> for negative reviews.</p>
			<p><em class="italic">Figure 7.4</em> shows you a small subset with some positive and some negative movie <a id="_idTextAnchor239"/>reviews:</p>
			<div>
				<div id="_idContainer628" class="IMG---Figure">
					<img src="image/B16391_07_004.jpg" alt="Figure 7.4 – Extract of the IMDb dataset, showing positive- and negative-labeled reviews"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.4 – Extract of the IMDb dataset, showing positive- and negative-labeled reviews</p>
			<p>Let's start with reading and encoding the texts of the movie reviews.</p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor240"/>Preprocessing Movie Reviews</h2>
			<p>The<a id="_idIndexMarker580"/> embedding <a id="_idIndexMarker581"/>layer expects index-based encoded input sequences. That is, each review must be encoded as a sequence of indexes, where each index (an integer value) represents a word in the dictionary. </p>
			<p>As the number of words available in the IMDb document corpus is very high, we decided to reduce them during the text preprocessing phase, by removing stop words and reducing all words to their stems. In addition, only the <img src="image/Formula_B16391_07_002.png" alt=""/> most frequent terms in the training set are encoded with a dedicated index, while all others receive just the default index.</p>
			<p>In theory, RNNs can handle sequences of variable length. In practice, though, the sequence length for all input samples in one training batch must be the same. As the number of words per review might differ, we define a fixed sequence length and we zero-pad too-short sequences – that is, we add 0s to complete the sequence – and we truncate too-long sequences.</p>
			<p>All these preprocessing steps are applied to the training set and the test set, with one difference. In the preprocessing of the training set, the dictionary with the <img src="image/Formula_B16391_06_021.png" alt=""/> most frequent terms is created. This dictionary is then only applied during the preprocessing of the t<a id="_idTextAnchor241"/>est set.</p>
			<p>In summary, we perform the following preprocessing steps:</p>
			<ol>
				<li>Read and partition the dataset into training and test sets.</li>
				<li>Tokenize, clean, and stem the movie reviews in the training set and the test set.</li>
				<li>Create a dictionary of all the terms. The <img src="image/Formula_B16391_03_029.png" alt=""/> most frequent terms in the training set are represented by dedicated indexes and all other terms by a default index.</li>
				<li>Map the words in the training and test set to the corresponding dictionary indexes.</li>
				<li>Truncate too-long word sequences in the training set and test set.</li>
				<li>Zero-pad<a id="_idIndexMarker582"/> too-short <a id="_idIndexMarker583"/>sequences in the training set and test set.</li>
			</ol>
			<p>The workflow in <em class="italic">Figure 7.5</em> performs all these s<a id="_idTextAnchor242"/>teps:</p>
			<div>
				<div id="_idContainer632" class="IMG---Figure">
					<img src="image/B16391_07_005.jpg" alt="Figure 7.5 – Preprocessing workflow snippet for the sentiment analysis case study"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.5 – Preprocessing workflow snippet for the sentiment analysis case study</p>
			<p>The first metanode, <strong class="bold">Read and partition data</strong>, reads the table with the movie reviews and sentiment information and partitions the dataset into a training set and a test set. The <strong class="bold">Preprocessing training set</strong> metanode performs the different preprocessing steps on the training set and creates and applies the dictionary, which is available at the second output port. The last metanode, <strong class="bold">Preprocess test set</strong>, applies the created dictionary to the test set and performs the different <a id="_idIndexMarker584"/>preprocessing steps<a id="_idIndexMarker585"/> on the test set.</p>
			<p>Let's see how all these steps are implemented in KNIME Analytics Platform.</p>
			<h3>Reading and Partitioning the Dataset</h3>
			<p>The first part, reading and <a id="_idIndexMarker586"/>partitioning the dataset, is performed<a id="_idIndexMarker587"/> by the <strong class="bold">Read and partition data</strong> metanode.</p>
			<p><em class="italic">Figure 7.6</em> shows you the workflow snippet inside the m<a id="_idTextAnchor243"/>etanode:</p>
			<div>
				<div id="_idContainer633" class="IMG---Figure">
					<img src="image/B16391_07_006.jpg" alt="Figure 7.6 – Workflow snippet inside the Read and partition metanode"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.6 – Workflow snippet inside the Read and partition metanode</p>
			<p>The <strong class="bold">Table Reader</strong> node<a id="_idIndexMarker588"/> reads the table with the sentiment information as an integer value and the movie reviews as a string value. Next, the sentiment information is transformed into a string with the <strong class="bold">Number To String</strong> node. This<a id="_idIndexMarker589"/> step is necessary to allow stratified sampling in <a id="_idIndexMarker590"/>the <strong class="bold">Partitioning</strong> node. In the last step, the data type of the column sentiment is transformed back into an integer using the <strong class="bold">String To Number</strong> node<a id="_idIndexMarker591"/> so that it can be used as the target column during training by the Keras Learner node.</p>
			<p>Now that we have a training set and a test set, let's continue with the preprocessing of the training set.</p>
			<h3>Preprocessing the Training Set and Dictionary Creation</h3>
			<p>The <a id="_idIndexMarker592"/>preprocessing of the training set and the creation of the dictionary is performed in the <strong class="bold">Preprocess training set</strong> metanode.</p>
			<p><em class="italic">Figure 7.7</em> shows you the inside of t<a id="_idTextAnchor244"/>he metanode:</p>
			<div>
				<div id="_idContainer634" class="IMG---Figure">
					<img src="image/B16391_07_007.jpg" alt="Figure 7.7 – Workflow snippet inside the Preprocess training set metanode"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.7 – Workflow snippet inside the Preprocess training set metanode</p>
			<p>For the preprocessing of the movie reviews, the <strong class="bold">KNIME Text Processing</strong> extension is used.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The KNIME Text Processing extension includes nodes to read and write documents from and to a variety of text formats; to transform words; to clean up sentences of spurious characters and meaningless words; to transform a text into a numeric table; to calculate all required text statistics; and finally, to explore topics and sentiment.</p>
			<p>The KNIME Text Processing extension relies on a new data type: <strong class="bold">Document object</strong>. Raw text becomes a document when additional metadata, such as title, author(s), source, and class, are added to it. Text in a document is tokenized following one of the many available language-specific tokenization algorithms. <strong class="bold">Document tokenization</strong> produces a hierarchical structure of the text items: sections, paragraphs, sentences, and words. Words are often referred to as tokens or terms.</p>
			<p>To make use <a id="_idIndexMarker593"/>of the preprocessing nodes of the KNIME Text Processing extension, we need to transform the movie reviews into documents, via the <strong class="bold">Strings To Document</strong> node. This <a id="_idIndexMarker594"/>node collects values from different columns and turns them into a document object, after tokenizing the main text. </p>
			<p><em class="italic">Figure 7.8</em> shows you the configuration window of the <strong class="bold">Strings To D<a id="_idTextAnchor245"/>ocument</strong> node:</p>
			<div>
				<div id="_idContainer635" class="IMG---Figure">
					<img src="image/B16391_07_008.jpg" alt="Figure 7.8 – Configuration window of the Strings To Document node"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.8 – Configuration window of the Strings To Document node</p>
			<p>The node <a id="_idIndexMarker595"/>gives you the opportunity to define the following:</p>
			<ul>
				<li>The document text via the <strong class="bold">Full text</strong> option.</li>
				<li>The document title, as a <strong class="bold">Column</strong>, <strong class="bold">Row ID</strong>, or <strong class="bold">Empty string</strong> value.</li>
				<li>The document source, document category, document authors, and document publication date as a fixed string or a column value. If column values are used, remember to enable the corresponding flag. Often, the <strong class="bold">Document category</strong> field is used to store the task class. </li>
				<li>The document type, as <strong class="bold">Transaction</strong>, <strong class="bold">Proceeding</strong>, <strong class="bold">Book</strong>, or just <strong class="bold">UNKNOWN</strong>. </li>
				<li>The name of the output document column.</li>
				<li>The maximum number of parallel processes to execute the word tokenizer.</li>
				<li>The word tokenizer algorithm. </li>
			</ul>
			<p>Next, the <a id="_idIndexMarker596"/>document objects are cleaned through a sequence of text preprocessing nodes, contained in the <strong class="bold">Text Preprocessing</strong> component of the workflow in <em class="italic">Figure 7.7</em>. The inside of the <strong class="bold">Text Preprocessing</strong> component is shown <a id="_idTextAnchor246"/>in <em class="italic">Figure 7.9</em>:</p>
			<div>
				<div id="_idContainer636" class="IMG---Figure">
					<img src="image/B16391_07_009.jpg" alt="Figure 7.9 – Workflow snippet showing the inside of the Preprocessing component "/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.9 – Workflow snippet showing the inside of the Preprocessing component </p>
			<p>The workflow snippet starts <a id="_idIndexMarker597"/>with the <strong class="bold">Punctuation Erasure</strong> node, to strip all punctuation from the input documents.</p>
			<p>The <strong class="bold">Number Filter</strong> node<a id="_idIndexMarker598"/> filters out all numbers, expressed as digits, including decimal separators (<strong class="bold">,</strong> or <strong class="bold">.</strong>) and possible leading signs (<strong class="bold">+</strong> or <strong class="bold">-</strong>).</p>
			<p>The <strong class="bold">N Chars Filter</strong> node<a id="_idIndexMarker599"/> filters out all terms with less than <img src="image/Formula_B16391_07_005.png" alt=""/> – in our case, <img src="image/Formula_B16391_07_006.png" alt=""/> – characters, as specified in the configuration window of the node.</p>
			<p>Filler words, such as <em class="italic">so</em>, <em class="italic">thus</em>, and so on, are<a id="_idIndexMarker600"/> called <strong class="bold">stop words</strong>. They carry little information and can be removed with the <strong class="bold">Stop Word Filter</strong> node. This <a id="_idIndexMarker601"/>node filters out all terms that are contained in the selected stop word list. A custom stop word list can be passed to the node via the second input port, or a default built-in<a id="_idIndexMarker602"/> stop word list can be adopted. A number of built-in stop word lists are available for various languages.</p>
			<p>The <strong class="bold">Case Converter</strong> node<a id="_idIndexMarker603"/> converts all terms into upper or lowercase. In this case study, they are converted into lowercase.</p>
			<p>Lastly, the <strong class="bold">Snowball Stemmer</strong> node<a id="_idIndexMarker604"/> reduces words to their stem, removing the grammar inflection, using the Snowball stemming library (<a href="http://snowball.tartarus.org/">http://snowball.tartarus.org/</a>).</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The goal of stemming is to reduce inflectional forms and derivationally related forms to a common base form. For example, <em class="italic">look</em>, <em class="italic">looking</em>, <em class="italic">looks</em>, and <em class="italic">looked</em> are all replaced by their stem, <em class="italic">look</em>.</p>
			<p>Now that we have cleaned up the text of the movie reviews of the training set, we can create the dictionary.</p>
			<h4>Creating the Dictionary Based on the Training Set</h4>
			<p>The <a id="_idIndexMarker605"/>dictionary must assign two indexes to each word:</p>
			<ul>
				<li><strong class="bold">Index</strong>: A progressive integer index to each of the <img src="image/Formula_B16391_07_007.png" alt=""/> most frequent terms in the training set and the same default index to all other terms.</li>
				<li><strong class="bold">Counter</strong>: A progressive eight-digit index to each of the words. This eight-digit index is just a temporary index that will help us deal with truncation. </li>
			</ul>
			<p><em class="italic">Figure 7.10</em> shows <a id="_idIndexMarker606"/>you a subset of the dictionary we want to create:</p>
			<div>
				<div id="_idContainer640" class="IMG---Figure">
					<img src="image/B16391_07_010.jpg" alt="Figure 7.10 – A small subset of the dictionary, where each word is represented by a progressive integer index and another progressive eight-digit integer index"/>
				</div>
			</div>
			<p class="figure-caption">F<a id="_idTextAnchor247"/>igure 7.10 – A small subset of the dictionary, where each word is represented by a progressive integer index and another progressive eight-digit integer index</p>
			<p>Both indexes are created in the <strong class="bold">Create Dictionary</strong> component and <em class="italic">Figure 7.11</em> shows you the workflow snippet inside the component:</p>
			<div>
				<div id="_idContainer641" class="IMG---Figure">
					<img src="image/B16391_07_011.jpg" alt="Figure 7.11 – Workflow snippet contained in the Create Dictionary component"/>
				</div>
			</div>
			<p class="figure-caption">Fi<a id="_idTextAnchor248"/>gure 7.11 – Workflow snippet contained in the Create Dictionary component</p>
			<p>The <strong class="bold">Create Dictionary</strong> component has a configuration window, which you can see in <em class="italic">Figure 7.12</em>. The<a id="_idIndexMarker607"/> input option in the configuration window is inherited from<a id="_idIndexMarker608"/> the <strong class="bold">Integer Configuration</strong> node and requests the dictionary size as the number of the <img src="image/Formula_B16391_03_173.png" alt=""/> most frequent words in the document collection. The default is <img src="image/Formula_B16391_07_009.png" alt=""/>:</p>
			<div>
				<div id="_idContainer644" class="IMG---Figure">
					<img src="image/B16391_07_012.jpg" alt="Figure 7.12 – Configuration window of the Create Dictionary component"/>
				</div>
			</div>
			<p class="figure-caption">Figur<a id="_idTextAnchor249"/>e 7.12 – Configuration window of the Create Dictionary component</p>
			<p>The workflow<a id="_idIndexMarker609"/> inside the component first creates a global<a id="_idIndexMarker610"/> set of unique terms over all the documents by using the <strong class="bold">Unique Term Extractor</strong> node:</p>
			<div>
				<div id="_idContainer645" class="IMG---Figure">
					<img src="image/B16391_07_013.jpg" alt="Figure 7.13 – Configuration window of the Unique Term Extractor node"/>
				</div>
			</div>
			<p class="figure-caption">Figu<a id="_idTextAnchor250"/>re 7.13 – Configuration window of the Unique Term Extractor node</p>
			<p>This node allows us to create an index column and a frequency column, as shown in the preceding screenshot. The index column contains a progressive integer number starting from <strong class="source-inline">1</strong>, where <strong class="source-inline">1</strong> is assigned to the most frequent term.</p>
			<p>The node <a id="_idIndexMarker611"/>optionally provides the possibility to filter the top <em class="italic">k</em> most frequent terms. For that, three frequency measures are <a id="_idIndexMarker612"/>available: the <strong class="bold">term frequency</strong>, the <strong class="bold">document frequency</strong>, and <a id="_idIndexMarker613"/>the <strong class="bold">inverse document frequency</strong>. For now, we want to select <a id="_idIndexMarker614"/>all terms and we will work on the dictionary size later.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout"><strong class="bold">Term frequency</strong> (<strong class="bold">TF</strong>): The number of occurrences of a term in all documents </p>
			<p class="callout"><strong class="bold">Document frequency</strong> (<strong class="bold">DF</strong>): The number of documents in which a term occurs</p>
			<p class="callout"><strong class="bold">Inverse document frequency</strong> (<strong class="bold">IDF</strong>): Logarithm of the number of documents divided by DF</p>
			<p>The eight-digit index is created via the <strong class="bold">Counter Generation</strong> node. This node adds a new <strong class="bold">Counter</strong> column to the input <a id="_idIndexMarker615"/>data table, starting from a minimum value (<strong class="bold">Min Value</strong>) of 10,000,000 and using <strong class="source-inline">1</strong> as the step size. This minimum value guarantees the eight-digit format.</p>
			<p>The <strong class="bold">Index</strong> and <strong class="bold">Counter</strong> columns are then converted from integers into strings with the <strong class="bold">Number To String</strong> node.</p>
			<p>Next comes the reduction of the dictionary size. The top <img src="image/Formula_B16391_03_173.png" alt=""/> most frequent terms keep the progressive index assigned <a id="_idIndexMarker616"/>by the <strong class="bold">Unique Term Extractor</strong> node, while all other terms get a default index of <img src="image/Formula_B16391_07_011.png" alt=""/>. Remember that <img src="image/Formula_B16391_03_252.png" alt=""/> can be changed via the component's configuration window. For this example, <img src="image/Formula_B16391_07_013.png" alt=""/> was set to 20,000. In the lower part of the component sub-workflow, the <strong class="bold">Row Splitter</strong> node<a id="_idIndexMarker617"/> splits the input data table into two sub-tables: the top <img src="image/Formula_B16391_07_007.png" alt=""/> rows (top output port) and the rest of the rows (lower output port).</p>
			<p>The <strong class="bold">Constant Value Column</strong> node then <a id="_idIndexMarker618"/>replaces all index values with the default<a id="_idIndexMarker619"/> index value <img src="image/Formula_B16391_07_015.png" alt=""/> in the lower sub-table. Lastly, the two sub-tables are concatenated back together.</p>
			<p>Now that the dictionary is ready, we can continue with the truncation of the movie reviews.</p>
			<h4>Truncating Too-Long Documents</h4>
			<p>We have<a id="_idIndexMarker620"/> stated that we will work with fixed-size documents – that is, with a maximum number of words for each document. If a document has more words than allowed, it will be truncated. If it has fewer words than allowed, it will be zero-padded. Let's see how the <strong class="bold">truncation</strong> procedure works – that is, how <a id="_idIndexMarker621"/>we remove the last words from a too-long document. This all happens in the <strong class="bold">Truncation</strong> component. <em class="italic">Figure 7.14</em> shows you the workflow snippet inside the component:</p>
			<div>
				<div id="_idContainer652" class="IMG---Figure">
					<img src="image/B16391_07_014.jpg" alt="Figure 7.14 – Workflow snippet inside the Truncation component"/>
				</div>
			</div>
			<p class="figure-caption">Figure<a id="_idTextAnchor251"/> 7.14 – Workflow snippet inside the Truncation component</p>
			<p>First, we set the <a id="_idIndexMarker622"/>maximum number, <img src="image/Formula_B16391_07_016.png" alt=""/>, of terms allowed in a document. Again, this is a parameter that can be changed through the component's configuration window, shaped via the <strong class="bold">Integer Configuration</strong> node. We set the maximum number of terms in a document – that is, the maximum document size – as <img src="image/Formula_B16391_07_017.png" alt=""/> terms. If a document is too long, we should just keep the first <img src="image/Formula_B16391_07_018.png" alt=""/> terms and throw away the rest.</p>
			<p>It is not easy to count the number of words in a text. Since words have variable lengths, we should detect the spaces separating the words within a loop and then count the words. Loops, however, often slow down execution. So, an alternative trick is to use the eight-digit representation of the words inside the text. </p>
			<p>Within the text, each word is substituted <a id="_idIndexMarker623"/>by its eight-digit code via the <strong class="bold">Dictionary Replacer</strong> node. The <strong class="bold">Dictionary Replacer</strong> node matches terms in the input documents at the top input port with dictionary terms at the lower input port and then replaces them with the corresponding value in the dictionary table. </p>
			<p>The <strong class="bold">Dictionary Replacer</strong> node has <a id="_idIndexMarker624"/>two input ports:</p>
			<ul>
				<li>The upper input port for the documents containing the terms to be replaced</li>
				<li>The lower input port with the dictionary table for the matching and replacement operation<p class="callout-heading">Important note</p><p class="callout">The dictionary table must consist of at least two string columns. One string column contains the terms to replace (keys) and the other string column contains the replacement strings (values). In the configuration window, we can set both columns from the data table at the lower input port.</p></li>
			</ul>
			<p>At this point, we have text with terms of fixed length (<strong class="source-inline">8 digits + 1 &lt;space&gt;</strong>) and not <a id="_idIndexMarker625"/>words of variable length. So, limiting a text to <img src="image/Formula_B16391_07_019.png" alt=""/> words is the same as limiting a text to <img src="image/Formula_B16391_07_020.png" alt=""/> characters, if <img src="image/Formula_B16391_07_021.png" alt=""/>, to 720 characters. This operation is much easier to carry out <a id="_idIndexMarker626"/>without loops or complex node structures, but just with a <strong class="bold">String Manipulation</strong> node. However, the <strong class="bold">String Manipulation</strong> node works on string objects and not on documents. To use it, we need to move temporarily back to text as strings.</p>
			<p>The text is extracted from the document as a simple string with the <strong class="bold">Document Data Extractor</strong> node. This node<a id="_idIndexMarker627"/> extracts information, such as, for example, the text and title, from a document cell.</p>
			<p>The <strong class="bold">Math Formula (Variable)</strong> node<a id="_idIndexMarker628"/> takes the flow variable for the maximum document size and calculates the maximum number of characters allowed in a document.</p>
			<p>The <strong class="bold">String Manipulation</strong> node extracts the substring from the text starting from the first character (at position <strong class="source-inline">0</strong>) until the maximum number of characters allowed, using the <strong class="source-inline">substr()</strong> function. This effectively keeps only the top <img src="image/Formula_B16391_03_031.png" alt=""/> terms and <a id="_idIndexMarker629"/>removes all others.</p>
			<p>Lastly, the text is transformed back into a document, called <strong class="bold">Truncated Document</strong>, and all superfluous columns are removed in the <strong class="bold">Column Filter</strong> node.</p>
			<p>At this point, the eight-digit indexes have exhausted their task and can be substituted with the progressive integer index for the encoding. This is done in the <strong class="bold">Dictionary Replacer</strong> node, once again.</p>
			<p>With that, we have truncated too-long documents to the maximum number of terms allowed. Next, we need to zero-pad too-short documents.</p>
			<h4>Zero-Padding Too-Short Documents</h4>
			<p>When sequences<a id="_idIndexMarker630"/> are too short with respect to a set number of values, <strong class="bold">zero-padding</strong> is often applied. Zero-padding means that 0s are added to the <a id="_idIndexMarker631"/>sequence until the set number of values is reached. In our case, if a document has fewer words than the set number, we fill the remaining empty spaces with 0s. This happens in the <strong class="bold">Zero Pad</strong> component.</p>
			<p><em class="italic">Figure 7.15</em> shows you the workflow snippet inside the Zero Pad component:</p>
			<div>
				<div id="_idContainer660" class="IMG---Figure">
					<img src="image/B16391_07_015.jpg" alt="Figure 7.15 – Workflow snippet inside the Zero Pad component"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.15<a id="_idTextAnchor252"/> – Workflow snippet inside the Zero Pad component</p>
			<p>Zero-padding<a id="_idIndexMarker632"/> is again performed at the string level, and not at the document level. After the text has been extracted as a string from the input document<a id="_idIndexMarker633"/> using the <strong class="bold">Document Data Extractor</strong> node, the <strong class="bold">Cell Splitter</strong> node splits the<a id="_idIndexMarker634"/> input text at each <strong class="source-inline">&lt;space&gt;</strong> and creates one new column for each index.</p>
			<p>Remember that all truncated text now has a maximum length of <img src="image/Formula_B16391_03_255.png" alt=""/> indexes from the previous step. So, from those texts, the number of newly generated columns is surely <img src="image/Formula_B16391_03_255.png" alt=""/>. For all other texts with shorter-term sequences, the <strong class="bold">Cell Splitter</strong> node will fill the empty columns with missing values. It is enough to turn these missing values into 0s and the zero-padding procedure is complete. This replacement of missing values with 0s is performed by the <strong class="bold">Missing Value</strong> node.</p>
			<p>Lastly, all superfluous columns are removed within the <strong class="bold">Column Filter</strong> node.</p>
			<p>Now that all term sequences – that is, all text – have the same length, collection cells are created with the <strong class="bold">Create Collection Cell</strong> node<a id="_idIndexMarker635"/> to feed the Keras Learner node.</p>
			<p>Next, we need to perform the same preprocessing on the test and apply the created dictionary.</p>
			<h3>Preprocessing the Test Set</h3>
			<p>The<a id="_idIndexMarker636"/> preprocessing of the test set is performed in the <strong class="bold">Preprocess test set</strong> metanode. This metanode has two input ports: the upper port for the dictionary created in the <strong class="bold">Preprocess training set</strong> metanode and the lower port for the test set.</p>
			<p><em class="italic">Figure 7.16</em> shows you the workflow snippet inside the Preprocess test set metanode:</p>
			<div>
				<div id="_idContainer663" class="IMG---Figure">
					<img src="image/B16391_07_016.jpg" alt="Figure 7.16 – Workflow snippet inside the Preprocess test set metanode"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.16<a id="_idTextAnchor253"/> – Workflow snippet inside the Preprocess test set metanode</p>
			<p>The lower part of the workflow is similar to the workflow snippet inside the <strong class="bold">Preprocess training set</strong> metanode, only the part including the creation of the dictionary is different. Here, the dictionary for the test set is based on the dictionary from the training set. All terms available in the training set dictionary receive the corresponding index encoding; all remaining terms receive the default index.</p>
			<p>Therefore, first a list of all terms in the test set is created using the <strong class="bold">Unique Term Extractor</strong> node. Next, this list is joined with the list of terms in the training set dictionary using a right outer join. A right outer join allows us to keep all the rows from the lower input port – that is, all terms in the test set – and to add the indexes from the training dictionary, if available. For all terms that are not in the training dictionary, the joiner node creates missing values in the index columns. These missing values are then replaced with the default index value using the <strong class="bold">Missing Value</strong> node.</p>
			<p>All other steps, such<a id="_idIndexMarker637"/> as truncation and zero-padding, are performed in the same way as in the preprocessing of the training set.</p>
			<p>We have finished the preprocessing phase and we can now continue with the definition of the network architecture and its training.</p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor254"/>Defining and Training the Network Architecture</h2>
			<p>In this section, we will<a id="_idIndexMarker638"/> define and train <a id="_idIndexMarker639"/>the network architecture for this sentiment classification task.</p>
			<h3>Network Architecture</h3>
			<p>We want to use an<a id="_idIndexMarker640"/> LSTM-based RNN, where we train the embedding as well. The embedding is trained by an embedding layer. Therefore, we create a neural network with four layers:</p>
			<ul>
				<li>An <strong class="bold">input layer</strong> to define the input size</li>
				<li>An <strong class="bold">embedding layer</strong> to produce an embedding representation of the term space</li>
				<li>An <strong class="bold">LSTM layer</strong> to exploit the sequential property of the text</li>
				<li>A <strong class="bold">dense layer</strong> with one unit with the sigmoid activation function, as we have a binary classification problem at hand</li>
			</ul>
			<p>The embedding layer expects a sequence of index-based encoded terms as input. Therefore, the input layer must accept sequences of <img src="image/Formula_B16391_03_031.png" alt=""/> integer indexes (in our case, <img src="image/Formula_B16391_07_026.png" alt=""/>). This means <strong class="source-inline">Shape = 80</strong> and <strong class="source-inline">data type = Int 32</strong> in the configuration window of the <strong class="bold">Keras Input Layer</strong> node.</p>
			<p>Next, the <strong class="bold">Keras Embedding Layer</strong> node<a id="_idIndexMarker641"/> must learn to embed the integer indexes into <a id="_idIndexMarker642"/>an appropriate high-dimensional vector space. <em class="italic">Figure 7.17</em> shows its configuration window. The input tensor is directly recovered from the output of the previous input layer:</p>
			<div>
				<div id="_idContainer666" class="IMG---Figure">
					<img src="image/B16391_07_017.jpg" alt="Figure 7.17 – Configuration window of the Keras Embedding Layer node"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1<a id="_idTextAnchor255"/>7 – Configuration window of the Keras Embedding Layer node</p>
			<p>There are two important configuration settings for the <strong class="bold">Keras Embedding Layer</strong> node. For the <strong class="bold">Input dimension</strong> setting, we need to provide the dictionary size – that is, the number of unique indexes. The number of unique indexes is the maximum index value plus 1 since the counter started from 0. For <strong class="bold">Output dimension</strong>, we provide the dimension of the final embedding space. We have arbitrarily chosen an embedding dimension of <strong class="source-inline">128</strong>. The output tensor of the <strong class="bold">Keras Embedding Layer</strong> node then has the dimension <strong class="source-inline">[sequence length </strong><img src="image/Formula_B16391_03_255.png" alt=""/><strong class="source-inline">, embedding dimension]</strong>. In our case, this is <strong class="source-inline">[80, 128]</strong>.</p>
			<p>Next, the <strong class="bold">Keras LSTM Layer</strong> node<a id="_idIndexMarker643"/> is used to add an LSTM-based recurrent layer to the network. This node is used with the default settings and <strong class="source-inline">128</strong> units, which means <strong class="source-inline">Units = 128</strong>, <strong class="source-inline">Activation = Tanh</strong>, <strong class="source-inline">Recurrent activation = Hard sigmoid</strong>, <strong class="source-inline">Dropout = 0.2</strong>, <strong class="source-inline">Recurrent dropout = 0.2</strong>, and return sequences, return state, go backward, and unroll all <strong class="source-inline">unchecked</strong>.</p>
			<p>Lastly, a <strong class="bold">Keras Dense Layer</strong> node<a id="_idIndexMarker644"/> with one unit with the sigmoid activation function is<a id="_idIndexMarker645"/> used to predict the final binary sentiment classification.</p>
			<p>Now that we have our preprocessed data and the neural architecture, we can start training the network.</p>
			<h3>Training the Recurrent Network with Embeddings</h3>
			<p>The <a id="_idIndexMarker646"/>network is trained, as usual, with <a id="_idIndexMarker647"/>the <strong class="bold">Keras Network Learner</strong> node.</p>
			<p>In the first tab, <strong class="bold">Input Data</strong>, the <strong class="bold">From Collection of Number (integer)</strong> conversion is selected, as our input is a collection cell of integer values (the indexes), encoding our movie reviews. Next, the collection cell is selected as input.</p>
			<p>In the second tab, <strong class="bold">Target Data</strong>, the <strong class="bold">From Number (integer)</strong> conversion type and the column with the sentiment class are selected. In the lower part, the binary cross-entropy is selected as the loss function since it is a binary classification task.</p>
			<p>In the third tab, <strong class="bold">Options</strong>, the following training parameters are set: <strong class="source-inline">Epochs = 30</strong>, <strong class="source-inline">Training batch size = 100</strong>, shuffle training data before each epoch is activated, and <strong class="source-inline">Optimizer = Adam</strong> (with the default settings).</p>
			<p>Now that the <a id="_idIndexMarker648"/>network is trained, we can apply it to the test set and evaluate how good its performance is at predicting the sentiment behind a review text.</p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor256"/>Executing and Evaluating the Network on the Test Set</h2>
			<p>To execute the <a id="_idIndexMarker649"/>network on the <a id="_idIndexMarker650"/>test set, the <strong class="bold">Keras Network Executor</strong> node<a id="_idIndexMarker651"/> is used.</p>
			<p>In the configuration window, we again select <strong class="bold">From Collection of Number (integer)</strong> as the conversion type and the collection cell as input.</p>
			<p>As output, we are interested in the output of the last dense layer, as this gives us the probability for sentiment being equal to <strong class="source-inline">1</strong> (positive). Therefore, we click on the <strong class="bold">add output</strong> button, select the sigmoid layer, and make sure that the <strong class="bold">To Number (double)</strong> conversion is used.</p>
			<p>The <strong class="bold">Keras Network Executor</strong> node adds one new column to the input table with the probability for the positive class encoded as <strong class="source-inline">1</strong>. </p>
			<p>Next, the <strong class="bold">Rule Engine</strong> node translates this probability into a class prediction with the following expression:</p>
			<p class="source-code">$dense_1/Sigmoid:0_0$ &gt; 0.5 =&gt; 1</p>
			<p class="source-code">TRUE =&gt; 0</p>
			<p>Here, <strong class="source-inline">$dense_1/Sigmoid:0_0$</strong> is the name of the output column from the network.</p>
			<p>The expression transforms all values above <strong class="source-inline">0.5</strong> into 1s, and into 0s otherwise.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Remember that the different instruction lines in a <strong class="bold">Rule Engine</strong> node are executed sequentially. Execution stops when the antecedent in one line is verified.</p>
			<p>Lastly, the <strong class="bold">Scorer</strong> node evaluates the performance of the model and the <strong class="bold">Keras Network Writer</strong> node<a id="_idIndexMarker652"/> saves the trained <a id="_idIndexMarker653"/>network for deployment. <em class="italic">Figure 7.18</em> shows the network performance, in the view of the <strong class="bold">Scorer</strong> node, achieving a respectable 83% of correct sentiment classification on the movie reviews:</p>
			<div>
				<div id="_idContainer668" class="IMG---Figure">
					<img src="image/B16391_07_018.jpg" alt="Figure 7.18 – Performance of the LSTM and embedding-based network on sentiment classification"/>
				</div>
			</div>
			<p class="figure-caption">Fi<a id="_idTextAnchor257"/>gure 7.18 – Performance of the LSTM and embedding-based network on sentiment classification</p>
			<p>With this, we have finished our first NLP case study. <em class="italic">Figure 7.19</em> displays the complete workflow used to implement the example. You can download the workflow from the KNIME Hub at https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%207/:</p>
			<div>
				<div id="_idContainer669" class="IMG---Figure">
					<img src="image/B16391_07_019.jpg" alt="Figure 7.19 – Complete workflow to prepare the text and build, train, and evaluate the neural network for sentiment analysis"/>
				</div>
			</div>
			<p class="figure-caption">Fig<a id="_idTextAnchor258"/>ure 7.19 – Complete workflow to prepare the text and build, train, and evaluate the neural network for sentiment analysis</p>
			<p>For now, we offer no <a id="_idIndexMarker654"/>deployment workflow. In <a href="B16391_10_Final_VK_ePUB.xhtml#_idTextAnchor367"><em class="italic">Chapter 10</em></a>, <em class="italic">Deploying a Deep Learning Network</em>, we will come<a id="_idIndexMarker655"/> back to this trained network to build a deployment workflow.</p>
			<p>Let's now move on to the next NLP application: free text generation with RNNs.</p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor259"/>Generating Free Text with RNNs</h1>
			<p>Now that <a id="_idIndexMarker656"/>we have seen how RNNs can be used for text classification, we can move on to the next case study. Here, we want to train an RNN to generate new free text in a certain style, be it Shakespearean English, a rap song, or mimicking a Brothers Grimm fairy tale. We will focus on the last application: training a network to generate free text in the style of Brothers Grimm fairy tales. However, the network and the process can be easily adjusted to produce a new rap song or a text in old Shakespearean English.</p>
			<p>So, how can we train an RNN to generate new text?</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor260"/>The Dataset</h2>
			<p>First of all, you need <a id="_idIndexMarker657"/>a text corpus to train the network to generate new text. Any text corpus is good. However, keep in mind that the text you use for training will define the style of the text automatically generated. If you train the network on Shakespearean theater, you will get new text in old Shakespearean English; if you train the network on rap songs, you will get urban-style text, maybe even with rhyme; if you train the network on fairy tales, you will get text in the fairy tale style.</p>
			<p>Thus, for a network to generate new fairy tales, it must be trained on existing fairy tales. We downloaded the Brothers Grimm corpus from the Gutenberg project, from <a href="https://www.gutenberg.org/ebooks/2591">https://www.gutenberg.org/ebooks/2591</a>.</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor261"/>Predicting Words or Characters?</h2>
			<p>The second decision to make is whether to train the network at the word or character level. Both options have their pros and cons.</p>
			<p>Training a <a id="_idIndexMarker658"/>network at the word level<a id="_idIndexMarker659"/> sounds more logical since languages are structured by words and not by characters. Input sequences (sequences of words) are short but the dictionary size (all words in the domain) is large. On the other hand, training the network at a character level relies on much smaller and more manageable dictionaries, but might lead to very long input sequences. According to Wikipedia, the English language, for example, has around 170,000 different words and only 26 different letters. Even if we distinguish between uppercase and lowercase, and we add numbers, punctuation signs, and special characters, we have a dictionary with less than 100 characters.</p>
			<p>We want to train a network to generate text in the Brothers Grimm style. In order to do that, we train the network with a few Brothers Grimm tales, which already implies a very large number of words in the dictionary. So, to avoid the problem of a huge dictionary and the consequent possibly unmanageable network size, we opt to train our fairy tale generator at the character level.</p>
			<p>Training at the character level means that the network must learn to predict the next character after the past <img src="image/Formula_B16391_03_029.png" alt=""/> characters have passed through the input. The training set, then, must consist of many samples of sequences of <img src="image/Formula_B16391_05_005.png" alt=""/> characters together with the next character to predict (the target value).</p>
			<p>During <a id="_idIndexMarker660"/>deployment, a start<a id="_idIndexMarker661"/> sequence of <img src="image/Formula_B16391_05_005.png" alt=""/> characters must trigger the network to generate the new text. Indeed, this first sequence predicts the next character; then in the next step, the <img src="image/Formula_B16391_07_031.png" alt=""/> most recent initial characters and the predicted character will make the new input sequence to predict the next character, and so on.</p>
			<p>In the next section, we will explain how to clean, transform, and encode the text data from the Grimms' fairy tales to feed the network.</p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor262"/>Preprocessing and Encoding</h2>
			<p>We populate the<a id="_idIndexMarker662"/> training set using the sliding <a id="_idIndexMarker663"/>window approach – that is, with partially overlapping sequences. To make this clearer, let's include the sentence <strong class="source-inline">Once upon a time</strong> in the training set using a window length of <img src="image/Formula_B16391_07_032.png" alt=""/> and a sliding step of <strong class="source-inline">1</strong>. The five characters <strong class="source-inline">Once&lt;space&gt;</strong> should predict <strong class="source-inline">u</strong>; then we slide the window one step to the right, and <strong class="source-inline">nce&lt;space&gt;u</strong> should predict <strong class="source-inline">p</strong>. Again, we slide the window one character to the right and <strong class="source-inline">ce&lt;space&gt;up</strong> should predict <strong class="source-inline">o</strong>, and so on.</p>
			<p>On the left of <em class="italic">Figure 7.20</em>, you can see the created input sequences and the target values:</p>
			<div>
				<div id="_idContainer675" class="IMG---Figure">
					<img src="image/B16391_07_020.jpg" alt="Figure 7.20 – Example of overlapping sequences used for training"/>
				</div>
			</div>
			<p class="figure-caption">Fig<a id="_idTextAnchor263"/>ure 7.20 – Example of overlapping sequences used for training</p>
			<p>Next, we need<a id="_idIndexMarker664"/> to encode the character<a id="_idIndexMarker665"/> sequences. In order to avoid introducing an artificial distance among characters, we opted for one-hot vector encoding. We will perform the one-hot encoding in two steps. First, we perform an index-based encoding; then we convert it into one-hot encoding in the <strong class="bold">Keras Network Learner</strong> node via the <strong class="bold">From Collection of Number (integer)</strong> conversion option to <strong class="bold">One-Hot Tensor</strong>. The resulting overlapping index-encoded sequences for the training set are shown on the right of <em class="italic">Figure 7.20</em>.</p>
			<p>The workflow snippet in the next figure reads and transforms the fairy tales into overlapping index-based encoded character sequences and their associated target character. Both the input sequence and target character are stored in a collection-type column:</p>
			<div>
				<div id="_idContainer676" class="IMG---Figure">
					<img src="image/B16391_07_021.jpg" alt="Figure 7.21 – Preprocessing workflow snippet reading and transforming text from &#13;&#10;Brothers Grimm fairy tales"/>
				</div>
			</div>
			<p class="figure-caption">Fi<a id="_idTextAnchor264"/>gure 7.21 – Preprocessing workflow snippet reading and transforming text from Brothers Grimm fairy tales</p>
			<p>The workflow <a id="_idIndexMarker666"/>performs the following steps:</p>
			<ul>
				<li>Reads all the<a id="_idIndexMarker667"/> fairy tales from the corpus and extracts five fairy tales for training and <strong class="source-inline">Snow white and Rose red</strong> as the seed for deployment</li>
				<li>Reshapes the text, placing one character per row in a single column</li>
				<li>Creates and applies the index-based dictionary, consisting, in this case, of the character set, including punctuation and special signs</li>
				<li>Using the <strong class="bold">Lag Column</strong> node, creates the<a id="_idIndexMarker668"/> overlapping sequences and then re-sorts them from the oldest to the newest character in the sequence</li>
				<li>Encapsulates the input sequence and target character into collection-type columns</li>
			</ul>
			<p>Let's have a look at these steps in detail.</p>
			<h3>Reading and Extracting Fairy Tales</h3>
			<p>The <a id="_idIndexMarker669"/>workflow snippet, in the <strong class="bold">Read and Extract Fairy Tales</strong> metanode, first<a id="_idIndexMarker670"/> reads the fairy tales using a <strong class="bold">File Reader</strong> node. The table has one column, where the content of each row corresponds to one line of a fairy tale.</p>
			<p>Then, a <strong class="bold">Row Filter</strong> node removes the unnecessary meta-information at the top and the bottom of the file, such as the author, title, table of contents, and license agreement. We will not use any of this meta-information during training or deployment.</p>
			<p>The <strong class="bold">Row Splitter</strong> node splits the collection of fairy tales into two subsets: at the lower output port, only <strong class="source-inline">Snow white and Rose red</strong> and at the top output port, all the other <a id="_idIndexMarker671"/>fairy tales. We'll save <strong class="source-inline">Snow white and Rose red</strong> for deployment.</p>
			<p>Next, a <strong class="bold">Row Filter</strong> node is <a id="_idIndexMarker672"/>used to extract the first five fairy tales, which are used for training.</p>
			<p>The next step is the reshaping of the text into a sequence of characters with one single column.</p>
			<h3>Reshaping the Text</h3>
			<p>Before we can create<a id="_idIndexMarker673"/> the overlapping sequences of characters to feed the network, we need to transform all the fairy tales text into a long sequence (column) of single characters: one character in each row. This<a id="_idIndexMarker674"/> step is called <strong class="bold">reshaping</strong> and it is implemented in the <strong class="bold">Reshape Text</strong> metanode. <em class="italic">Figure 7.22</em> shows its conten<a id="_idTextAnchor265"/>ts:</p>
			<div>
				<div id="_idContainer677" class="IMG---Figure">
					<img src="image/B16391_07_022.jpg" alt="Figure 7.22 – Workflow snippet inside the Reshape Text metanode"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.22 – Workflow snippet inside the Reshape Text metanode</p>
			<p>It starts with two <strong class="bold">String Manipulation</strong> nodes. The first one replaces each white space with a tilde character. The second one replaces each character with the character itself plus a <strong class="source-inline">&lt;space&gt;</strong> character, by using the <strong class="source-inline">regexReplace()</strong> function. <strong class="source-inline">regexReplace()</strong> takes advantage of regular expressions, such as <strong class="source-inline">"[^\\s]"</strong> to match any character in the input string and <strong class="source-inline">"$0 "</strong> for the matched character plus <strong class="source-inline">&lt;space&gt;</strong>. The final syntax for the <strong class="source-inline">regexReplace()</strong> function, used within the <strong class="bold">String Manipulation</strong> node and applied to the input column, <strong class="source-inline">$Col0$</strong>, is then the following:</p>
			<p class="source-code">regexReplace($Col0$,"[^\\s]" ,"$0 ")</p>
			<p>Next, the <strong class="bold">Cell Splitter</strong> node splits the text at each <strong class="source-inline">&lt;space&gt;</strong> character, producing many columns with one character per cell.</p>
			<p>Notice that the<a id="_idIndexMarker675"/> last character in the paragraph (the newline) has not received the <strong class="source-inline">&lt;space&gt;</strong> character afterward. To solve this problem, a constant column with a <strong class="source-inline">&lt;space&gt;</strong> character is added <a id="_idIndexMarker676"/>using the <strong class="bold">Constant Value Column</strong> node.</p>
			<p>The <strong class="bold">Unpivoting</strong> node<a id="_idIndexMarker677"/> reshapes the data table from many columns into one column only with a sequence of single characters. Let's spend a bit of time on the <strong class="bold">Unpivoting</strong> node and its unsuspected tricks for reshaping data tables. The <strong class="bold">Unpivoting</strong> node performs a disaggregation of the input data table. <em class="italic">Figure 7.23</em> shows you an example. It distinguishes between value columns and retaining columns. The selected value columns are then rotated to become rows and attached to the corresponding values in the retaining columns. Since the rotation of the value columns might result in more than one row, a duplication of the rows with the retaining column values might be neces<a id="_idTextAnchor266"/>sary:</p>
			<div>
				<div id="_idContainer678" class="IMG---Figure">
					<img src="image/B16391_07_023.jpg" alt="Figure 7.23 – Example for the unpivoting operation, where Product 1 and Product 2 are the selected Value columns, and ID and City are the selected retaining columns"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.23 – Example for the unpivoting operation, where Product 1 and Product 2 are the selected Value columns, and ID and City are the selected retaining columns</p>
			<p>For the reshaping<a id="_idIndexMarker678"/> of the text, we set all columns as value columns and none as retaining columns. The result is the representation of the fairy tale as a long sequence of characters within one column.</p>
			<p>At last, some cleaning up: all rows with missing values are removed with the <strong class="bold">Row Filter</strong> node.</p>
			<h3>Creating and Applying the Dictionary</h3>
			<p>We <a id="_idIndexMarker679"/>now need to create the <a id="_idIndexMarker680"/>dictionary and the index-based mapping for the index-based encoding. Since we work at the character level, the dictionary here is nothing more than the character set – that is, the list of unique characters in the fairy tales corpus. To get this list, we remove all duplicate characters from the reshaped text using the <strong class="bold">Remove Duplicate Filter</strong> node.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The <strong class="bold">Remove Duplicate Filter</strong> node<a id="_idIndexMarker681"/> is a powerful node when it comes to detecting and handling duplicate records in the dataset.</p>
			<p>Next, we assign an index to each row – that is, to each unique character – with the <strong class="bold">Counter Generation</strong> node, which we<a id="_idIndexMarker682"/> introduced already in the first case study of this chapter. Here, we use <strong class="source-inline">0</strong> for <strong class="bold">Min Value</strong> and <strong class="source-inline">1</strong> for <strong class="bold">Scale Unit</strong>.</p>
			<p>Now that we<a id="_idIndexMarker683"/> have the dictionary<a id="_idIndexMarker684"/> ready, we apply it with the <strong class="bold">Cell Replacer</strong> node, already introduced in <a href="B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a>, <em class="italic">Building and Training a Feedforward Neural Network</em>.</p>
			<h3>Creating and Resorting the Overlapping Sequences</h3>
			<p>To create<a id="_idIndexMarker685"/> the overlapping sequences of characters, we use the <strong class="bold">Lag Column</strong> node, which we already<a id="_idIndexMarker686"/> introduced and explained in the previous chapter, <a href="B16391_06_Final_VK_ePUB.xhtml#_idTextAnchor181"><em class="italic">Chapter 6</em></a>, <em class="italic">Recurrent Neural Networks for Demand Prediction</em>. In this case study, we use sequences of <img src="image/Formula_B16391_07_033.png" alt=""/> consecutive characters to predict the next character. Therefore, in the <strong class="bold">Lag Column</strong> node, <strong class="bold">Lag</strong> is set to <strong class="source-inline">100</strong>, <strong class="bold">Lag interval</strong> is set to <strong class="source-inline">1</strong>, and incomplete rows at the beginning and end of the output table are skipped.</p>
			<p>According to the way the <strong class="bold">Lag Column</strong> node works, we end up with a data table sorted on a growing time from right to left. The oldest character of each sequence (<strong class="source-inline">col-100</strong>) is in the farthest column to the right; the current character to predict (<strong class="source-inline">col</strong>) is in the farthest column to the left. Basically, the time of the sequence is sorted backward with respect to what the network is expecting.</p>
			<p>The following figure shows you <a id="_idTextAnchor267"/>an example:</p>
			<div>
				<div id="_idContainer680" class="IMG---Figure">
					<img src="image/B16391_07_024.jpg" alt="Figure 7.24 – Resulting output of the Lag Column node, where the time is sorted in ascending order from right to left"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.24 – Resulting output of the Lag Column node, where the time is sorted in ascending order from right to left</p>
			<p>We need to<a id="_idIndexMarker687"/> reorder the <a id="_idIndexMarker688"/>columns to follow an ascending order from left to right, in order to have the oldest character on the left and the most recent character on the right. This re-sorting is performed by the <strong class="bold">Resort Columns</strong> metanode.</p>
			<p><em class="italic">Figure 7.25</em> shows you the inside of t<a id="_idTextAnchor268"/>he metanode:</p>
			<div>
				<div id="_idContainer681" class="IMG---Figure">
					<img src="image/B16391_07_025.jpg" alt="Figure 7.25 – Workflow snippet contained in the Resort Columns metanode"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.25 – Workflow snippet contained in the Resort Columns metanode</p>
			<p>Here, the <strong class="bold">Reference Column Resorter</strong> node<a id="_idIndexMarker689"/> changes the order of the data columns in the table at the top input port according to the order established in the data table at the lower input port. The reference data table at the lower input port must contain a string-type column with the column headers from the first input table in a particular order. The columns in the first data table are then sorted according to the row order of the column names in the second data table.</p>
			<p>To create the table with sorted column headers, we extract the column headers with the <strong class="bold">Extract Column Header</strong> node. The <strong class="bold">Extract Column Header</strong> node separates the column headers from the table <a id="_idIndexMarker690"/>content and outputs the column headers at the top output port and the content at the lower output port.</p>
			<p>Then, the row<a id="_idIndexMarker691"/> of column headers<a id="_idIndexMarker692"/> is transposed into a column with<a id="_idIndexMarker693"/> the <strong class="bold">Transpose</strong> node.</p>
			<p>Finally, we assign an increasing integer number to each column header via the <strong class="bold">Counter Generation</strong> node and we sort them by counter value in descending order using the <strong class="bold">Sorter</strong> node. </p>
			<p>Now that we have the column headers from the first table sorted correctly in time, we can input it at the lower port <a id="_idIndexMarker694"/>of the <strong class="bold">Reference Column Resorter</strong> node. The result is a data table where each row is a sequence of <img src="image/Formula_B16391_07_034.png" alt=""/> characters, time is sorted from left to right, and subsequent rows contain overlapping character sequences. At this point, we can create the collection cells for the input and target data of the network.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Even though the target data consists of only one single value, we still need to transform it into a collection cell so that the index can be transformed into a one-hot vector by the <strong class="bold">Keras Network Learner</strong> node.</p>
			<p>Let's move on to the next step: defining and training the network architecture.</p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor269"/>Defining and Training the Network Architecture</h2>
			<p>Let's now<a id="_idIndexMarker695"/> design and <a id="_idIndexMarker696"/>train an appropriate neural network architecture to deal with time series, character encoding, and overfitting, and to predict the next character in the sequence.</p>
			<h3>Defining the Network Architecture</h3>
			<p>For this case study, we<a id="_idIndexMarker697"/> decided to use a neural network with four layers: </p>
			<ul>
				<li>A <strong class="bold">Keras input layer</strong>, to define the input shape</li>
				<li>A <strong class="bold">Keras LSTM layer</strong>, to deal with time series</li>
				<li>A <strong class="bold">Keras dropout layer</strong>, to prevent overfitting</li>
				<li>A <strong class="bold">Keras dense layer</strong>, to output the probability of the next character</li>
			</ul>
			<p>As usual, we define the input shape of the neural network using a <strong class="bold">Keras Input Layer</strong> node. The input here is a second-order tensor: the first dimension is the sequence length (<img src="image/Formula_B16391_07_035.png" alt=""/>, but we will allow a variable length <em class="italic">?</em>) and the second dimension is the size of the one-hot vectors – that is, the size of the character set (65). So, the input shape is <strong class="source-inline">?, 65</strong>.</p>
			<p>As we don't need the intermediate hidden states, we leave most of the settings as default in the <strong class="bold">Keras LSTM Layer</strong> node. We just set the number of units to <strong class="source-inline">512</strong>. </p>
			<p>Free text generation can be seen as a multi-class classification application, where the characters are the classes. Therefore, the <strong class="bold">Keras Dense Layer</strong> node at the output of the network is set to have 65 units (one for each character in the character set) with the softmax activation function, to score the probability of each character to be the next character.</p>
			<p>Let's proceed with training this network on the encoded overlapping sequences.</p>
			<h3>Training the Network</h3>
			<p>Again, to train the <a id="_idIndexMarker698"/>network, we use the by-now-familiar <strong class="bold">Keras Network Learner</strong> node.</p>
			<p>In the first configuration tab, <strong class="bold">Input Data</strong>, we select <strong class="bold">From Collection of Number (integer) to One-Hot-Tensor</strong> to handle encoding conversion and the collection column with the character sequence as input.</p>
			<p>In the second configuration tab, <strong class="bold">Target Data</strong>, we select <strong class="bold">From Collection of Number (integer) to One-Hot-Tensor</strong> again on the collection column containing the target value. As this is a multi-class classification problem, we set the loss function to <strong class="bold">Categorical Cross Entropy</strong>.</p>
			<p>In the third configuration tab, <strong class="bold">Options</strong>, we provide the training parameters: <strong class="source-inline">50 epochs</strong>, training batch size <strong class="source-inline">256</strong>, shuffling option <strong class="source-inline">on</strong>, and optimizer as <strong class="source-inline">Adam</strong> with default settings for the learning rate.</p>
			<p>The network is finally saved in <strong class="bold">Keras format</strong> with the <strong class="bold">Keras Network Writer</strong> node. In addition, the network is converted into a TensorFlow network with the <strong class="bold">Keras to TensorFlow Network Converter</strong> node and saved with the <strong class="bold">TensorFlow Network Writer</strong> node. The TensorFlow network is used in deployment to avoid a time-consuming Python startup, required by the Keras network.</p>
			<p><em class="italic">Figure 7.26</em> shows the full workflow implementing all the described steps to train a neural network to generate fairy tales. This workflow and the used dataset are available on KNIME Hub at https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/lat<a id="_idTextAnchor270"/>est/Chapter%207/:</p>
			<div>
				<div id="_idContainer684" class="IMG---Figure">
					<img src="image/B16391_07_026.jpg" alt="Figure 7.26 – Workflow to train a neural network to generate fairy tales"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.26 – Workflow to train a neural network to generate fairy tales</p>
			<p>Now that we have trained and saved the network, let's move on to deployment to generate a new fairy tale's text.</p>
			<h2 id="_idParaDest-135"><a id="_idTextAnchor271"/>Building a Deployment Workflow</h2>
			<p>To trigger the <a id="_idIndexMarker699"/>generation of new text during deployment, we start with an input sequence of the same length as each of the training sequences (<img src="image/Formula_B16391_07_036.png" alt=""/>). We feed the network with that sequence to predict the next character; then, we delete the oldest character in the sequence, add the predicted one, and apply the network again to our new input sequence, and so on. This is exactly the same procedure that we used in the case study for demand prediction. So, we will implement it here again with a recursive loop (<em class="italic">Figure 7.27</em>):</p>
			<div>
				<div id="_idContainer686" class="IMG---Figure">
					<img src="image/B16391_07_027.jpg" alt="Figure 7.27 – Deployment workflow to generate new free text"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.27 – Deployment workflow to generate new free text</p>
			<p>The trigger <a id="_idIndexMarker700"/>sequence was taken from the <strong class="bold">Snow white and Rose red</strong> fairy tale. The text for the trigger sequence was preprocessed, sequenced, and encoded as in the workflow used to train the network. This is done in the <strong class="bold">Read and Pre-Process</strong> metanode, shown in <em class="italic">Figure 7.28</em>:</p>
			<div>
				<div id="_idContainer687" class="IMG---Figure">
					<img src="image/B16391_07_028.jpg" alt="Figure 7.28 – Workflow content in the Read and Pre-Process metanode to read and preprocess the trigger sequence"/>
				</div>
			</div>
			<p class="figure-caption">F<a id="_idTextAnchor272"/>igure 7.28 – Workflow content in the Read and Pre-Process metanode to read and preprocess the trigger sequence</p>
			<p>The workflow reads the <strong class="bold">Snow white and Rose red</strong> fairy tale as well as the dictionary from the files created in the training workflow. Then, the same preprocessing steps as in the training workflow are applied.</p>
			<p>After that, we read the trained TensorFlow network and apply it to the trigger sequence with the <strong class="bold">TensorFlow Network Executor</strong> node.</p>
			<p>The output of the network is the probability of each character to be the next. We can pick the predicted character following two possible strategies:</p>
			<ul>
				<li>The<a id="_idIndexMarker701"/> character with the highest probability is assigned to be the next character, known as the greedy strategy.</li>
				<li>The next character is picked randomly according to the probability distribution.</li>
			</ul>
			<p>We have implemented both strategies in the <strong class="bold">Extract Index</strong> metanode in two different deployment workflows. </p>
			<p><em class="italic">Figure 7.29</em> shows the content of the <strong class="bold">Extract Index</strong> metanode when implementing the first strategy:</p>
			<div>
				<div id="_idContainer688" class="IMG---Figure">
					<img src="image/B16391_07_029.jpg" alt="Figure 7.29 – Workflow snippet to extract the character with the highest probability"/>
				</div>
			</div>
			<p class="figure-caption">F<a id="_idTextAnchor273"/>igure 7.29 – Workflow snippet to extract the character with the highest probability</p>
			<p>This metanode takes as input the output probabilities from the executed network and extracts the character with the highest probability. The key node here is the <strong class="bold">Many to One</strong> node, which extracts the cell with the highest score (probability) from the network output.</p>
			<p><em class="italic">Figure 7.30</em> shows the content of the <strong class="bold">Extract Index</strong> metanode when implementing the second strategy:</p>
			<div>
				<div id="_idContainer689" class="IMG---Figure">
					<img src="image/B16391_07_030.jpg" alt="Figure 7.30 – Workflow snippet to pick the next character based on a probability distribution"/>
				</div>
			</div>
			<p class="figure-caption">Fi<a id="_idTextAnchor274"/>gure 7.30 – Workflow snippet to pick the next character based on a probability distribution</p>
			<p>This workflow<a id="_idIndexMarker702"/> snippet expects as input the probability distribution for the characters and picks one according to it. The key node here is the <strong class="bold">Random Label Assigner (Data)</strong> node, which assigns a value based on the input probability distribution.</p>
			<p>The <strong class="bold">Random Label Assigner (Data)</strong> node<a id="_idIndexMarker703"/> assigns one index to each data row at the lower input port based on the probability distribution at the upper input port. The data table at the upper input port must have two columns: one column with the class values – in our case, the index-encoded characters in string format – and one column with the corresponding probabilities. Therefore, the first part of the workflow snippet in <em class="italic">Figure 7.30</em> prepares the data table for the top input port of the <strong class="bold">Random Label Assigner (Data)</strong> node, from the network output, using the <strong class="bold">Transpose</strong> node, the <strong class="bold">Counter Generation</strong> node, and the <strong class="bold">Number To String</strong> node, while the <strong class="bold">Table Creator</strong> node creates a new table with only one row using the <strong class="bold">Table Creator</strong> node. This means the <strong class="bold">Random Label Assigner (Data)</strong> node then picks one index, based on the probability distribution defined by the table at the first input port.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The idea of the recursive loop and its implementation are explained in detail in <a href="B16391_06_Final_VK_ePUB.xhtml#_idTextAnchor181"><em class="italic">Chapter 6</em></a>, <em class="italic">Recurrent Neural Networks for Demand Prediction</em>.</p>
			<p>You can download the deployment workflow, implementing both options, from the KNIME Hub: https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%207/.</p>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor275"/>The New Fairy Tale</h2>
			<p>At last, I am sure <a id="_idIndexMarker704"/>you want to see the kind of free text that the network was able to produce. The following is an example of free generated text, using the first strategy.</p>
			<p>The trigger sequence of 100 characters (not italics) comes from the first sentence of the fairy tale, <em class="italic">Snow white and Rose red</em>. The remaining text has been automatically generated by the network.</p>
			<p class="author-quote"><em class="italic">SNOW-WHITE AND ROSE-RED There was once a poor widow who lived in a lonely cottage</em>. In front of the cas, and a hunbred of wine behind the door of the; and he said the ansmer: 'What want yeurnKyow yours went for bridd, like is good any, or cries, and we will say I only gave the witeved to the brood of the country to go away with it.' But when the father said, 'The cat soon crick.' The youth, the old …</p>
			<p>The network has successfully learned the structure of the English language. Although the text is not perfect, you can see sensible character combinations, full words, some correct usage of quotation marks, and other similarly interesting features that the network has assimilated from the training text.</p>
			<h1 id="_idParaDest-137"><a id="_idTextAnchor276"/>Generating Product Names with RNNs</h1>
			<p>This last <a id="_idIndexMarker705"/>NLP case study is similar to the previous one. There, we wanted the network to create new free text based on a start sequence; here, we want the network to create new free words based on a start token. There, we wanted the network to create new sequences of words; here, we want the network to create new sequences of characters. Indeed, the goal of this product name generation case study is to create new names – that is, new words. While there'll be some differences, the approaches will be similar.</p>
			<p>In this section, we will explore the details of this new approach.</p>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor277"/>The Problem of Product Name Generation</h2>
			<p>Normally, we don't<a id="_idIndexMarker706"/> associate artificial intelligence with creativity, as it is usually used to predict the outcome based on previously seen examples. The challenge for this case study is to use artificial intelligence to create something new, which is thought to be in the domain of creative minds.</p>
			<p>Let's take a classic creative marketing example: product naming. Before a new product can be launched to the market, it actually needs a name. To find the name, the most creative minds of the company come together to generate a number of proposals for product names, taking different requirements into account. For example, the product name should sound familiar to the customers and yet be new and fresh too. Of all those candidates, ultimately only one will survive and be adopted as the name for the new product. Not an easy task!</p>
			<p>Now, let's take one of the most creative industries: fashion. A company specializing in outdoor wear has a new line of clothes ready for the market. The task is to generate a sufficiently large number of name candidates for the new line of clothing. Names of mountains were proposed, as many other outdoor fashion labels have. Names of mountains evoke the feeling of nature and sound familiar to potential customers. However, new names must also be copyright free and original enough to stand out in the market.</p>
			<p>Why not use fictitious mountain names then? Since they are fictitious, they are copyright free and differ from competitor names; however, since they are similar to existing mountain names, they also sound familiar enough to potential customers. Could an artificial intelligence model help generate new fictitious mountain names that still sound realistic enough and are evocative of adventure? What kind of network architecture could we use for such a task?</p>
			<p>As we want to be able to form new words that are somehow reminiscent of mountain names, the network must be trained on the names of already-existing mountains.</p>
			<p>To form the training set, we use a list of 33,012 names of US mountains, as extracted from Wikipedia through a Wikidata query.</p>
			<p><em class="italic">Figure 7.31</em> shows you a <a id="_idIndexMarker707"/>subset of the training data:<a id="_idTextAnchor278"/></p>
			<div>
				<div id="_idContainer690" class="IMG---Figure">
					<img src="image/B16391_07_031.jpg" alt="Figure 7.31 – Subset of US mountain names in the training set"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.31 – Subset of US mountain names in the training set</p>
			<p>Now that we have some training data, we can think about the network architecture. This time, we want to train a <strong class="bold">many-to-many</strong> LSTM-based RNN (see <em class="italic">Figure 7.32</em>). This means that during training, we have a sequence as input and a sequence as output. During deployment, the RNN, based on some initialized hidden states and the start token, must predict the first character of the new name candidate; then at the next step, based on the predicted character and on the updated hidden states, it must predict the next character – and so on until an end token is predicted and the process of generating the new candidate name is concluded:</p>
			<p class="figure-caption"><a id="_idTextAnchor279"/></p>
			<div>
				<div id="_idContainer691" class="IMG---Figure">
					<img src="image/B16391_07_032.jpg" alt="Figure 7.32 – Simplified, unrolled visualization of the many-to-many RNN architecture for the product name generation case study"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.32 – Simplified, unrolled visualization of the many-to-many RNN architecture for the product name generation case study</p>
			<p>To train the <a id="_idIndexMarker708"/>LSTM unit for this task, we need two sequences: an input sequence, made of a start token plus the mountain name, and a target sequence, made of the mountain name plus an end token. Notice that, at each training iteration, we feed the correct character into the network from the training set and not its prediction. This is <a id="_idIndexMarker709"/>called the <strong class="bold">teacher forcing</strong> training approach.</p>
			<p>Let's focus first on preprocessing and encoding input and target sequences.</p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor280"/>Preprocessing and Encoding Mountain Names</h2>
			<p>The goal of the<a id="_idIndexMarker710"/> preprocessing is to create and encode input and target sequences, including the<a id="_idIndexMarker711"/> start and end tokens. As in the previous case study, we want to use one-hot encoding. Therefore, we create an index-based encoding, and we use the <strong class="bold">From Collection of Number (integer) to One-Hot Tensor in the Keras Network Learner</strong> node conversion option. We also want to use <strong class="source-inline">1</strong> as the start token index and <strong class="source-inline">0</strong> as the end token index.</p>
			<p>In the last case study, you learned that during training, the lengths of the sequences in one batch have to be the same. Therefore, we take the number of characters of the longest mountain name (58) plus 1 as the sequence length. Since this is the length of the longest mountain name, there is no need for truncation, but all shorter sequences will be zero-padded by adding multiple end tokens:</p>
			<div>
				<div id="_idContainer692" class="IMG---Figure">
					<img src="image/B16391_07_033.jpg" alt="Figure 7.33 – Workflow to read, encode, and create the input and target sequences for mountain name generation"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.33 – Workflow to read, encode, and create the input and target sequences for mountain name generation</p>
			<p>The workflow <a id="_idIndexMarker712"/>snippet in the <a id="_idIndexMarker713"/>preceding figure creates the input and target sequences by doing the following:</p>
			<ol>
				<li value="1">Reading the mountain names and removing duplicates by using the <strong class="bold">Table Reader</strong> node and the <strong class="bold">Duplicate Row Filter</strong> node</li>
				<li>Replacing each <strong class="source-inline">&lt;space&gt;</strong> with a tilde character and afterward, each character with the character itself and <strong class="source-inline">&lt;space&gt;</strong>, using two <strong class="bold">String Manipulation</strong> nodes (this step is described in detail in the preprocessing of the previous case study, <em class="italic">Free text generation with RNNs</em>)</li>
				<li>Creating and applying a dictionary (we will have a close look at this step in the next sub-section)</li>
				<li>Character splitting based on <strong class="source-inline">&lt;space&gt;</strong> and replacing all missing values with end tokens, to zero pad too-short sequences</li>
				<li>Creating input and target sequences as collection type cells</li>
			</ol>
			<p>Most of the steps<a id="_idIndexMarker714"/> are similar to the preprocessing steps in the case study of free text generation with RNNs. We <a id="_idIndexMarker715"/>will only take a closer look at <em class="italic">step 3</em> and <em class="italic">step 5</em>. Let's start with <em class="italic">step 3</em>.</p>
			<h3>Creating and Applying a Dictionary</h3>
			<p>Creating and applying<a id="_idIndexMarker716"/> the dictionary<a id="_idIndexMarker717"/> is implemented in the <strong class="bold">Create and apply dictionary</strong> metanode. <em class="italic">Figure 7.34</em> shows its contents. The input to this metanode is mountain names with spaced char<a id="_idTextAnchor281"/>acters:</p>
			<div>
				<div id="_idContainer693" class="IMG---Figure">
					<img src="image/B16391_07_034.jpg" alt="Figure 7.34 – Workflow snippet inside the Create and apply dictionary metanode"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.34 – Workflow snippet inside the Create and apply dictionary metanode</p>
			<p>In this metanode, we again use nodes from the KNIME Text Processing extension. The <strong class="bold">Strings To Document</strong> node tokenizes these names with spaced characters so that each character becomes its own term. Then, the <strong class="bold">Unique Term Extractor</strong> node gives us the list of unique characters in all documents – that is, the character set. The <strong class="bold">Counter Generation</strong> node assigns an index to each character starting from <strong class="source-inline">2</strong>, as we want to use indexes <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong> for the end and start tokens. To <a id="_idIndexMarker718"/>use it as a dictionary <a id="_idIndexMarker719"/>in the next step, the created numerical indexes are transformed into strings by the <strong class="bold">Number To String</strong> node. Finally, the dictionary is applied (the <strong class="bold">Dictionary Replacer</strong> node), to transform characters into indexes in the original mountain names, and the text is extracted from the document (the <strong class="bold">Document Data Extractor</strong> node).</p>
			<p class="callout-heading">Tip </p>
			<p class="callout">The KNIME Text Processing extension and some of their nodes, such as <strong class="bold">Strings To Document</strong>, <strong class="bold">Unique Term Extractor</strong>, <strong class="bold">Dictionary Replacer</strong>, and <strong class="bold">Document Data Extractor</strong>, were introduced more in detail in the first case study of this chapter, <em class="italic">Finding the Tone of Your Customers' Voice – Sentiment Analysis</em>.</p>
			<p>In the separate, lower branch of the workflow snippet, we finalize the dictionary for the deployment by adding one more row for the end token, using the <strong class="bold">Empty Table Row</strong> node (see <em class="italic">Figure 7.35</em>). This node adds a number of rows to the input data table, either with missing values or with predefined constant values for each cell type. In our case, we add one additional row, and we use <strong class="source-inline">0</strong> as the default value for the integer cells and an empty string for the string cells. This adds one new row to our dictionary table, with <strong class="source-inline">0</strong> in the index column and empty strings in the character columns. We need this additional row in the deployment workflow to remove the end t<a id="_idTextAnchor282"/>oken(s):</p>
			<div>
				<div id="_idContainer694" class="IMG---Figure">
					<img src="image/B16391_07_035.jpg" alt="Figure 7.35 – Configuration window of the Add Empty Rows node"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.35 – Configuration window of the Add Empty Rows node</p>
			<p>Let's move on to the last step of the preprocessing.</p>
			<h3>Creating the Input and Target Sequences</h3>
			<p>After the <strong class="bold">Missing Value</strong> node in the workflow in <em class="italic">Figure 7.35</em>, we have the zero-padded, encoded sequences. What is missing, though, is the start token at the beginning of the <a id="_idIndexMarker720"/>input sequence and the end token at the end of the target sequence, to make sure that the input and target sequence<a id="_idIndexMarker721"/> have the same length.</p>
			<p>The additional values are added with <strong class="bold">Constant Values Column</strong> nodes, where the constant value <strong class="source-inline">1</strong> is used for the start token in the input sequence and the value <strong class="source-inline">0</strong> for the end token in the target sequence. In the case of the input sequence, the new column with the start token must be at the beginning. This is taken care of by the <strong class="bold">Column Resorter</strong> node. Now, the sequences can be aggregated and transformed into collection cells, using the <strong class="bold">Create Collection Column</strong> node.</p>
			<p>Let's now design and train the appropriate network architecture.</p>
			<h1 id="_idParaDest-140"><a id="_idTextAnchor283"/>Defining and Training the Network Architecture</h1>
			<p>The <a id="_idIndexMarker722"/>process of designing and training the network is <a id="_idIndexMarker723"/>similar to the process used in the previous NLP case studies.</p>
			<h3>Designing the Network</h3>
			<p>In this case, we<a id="_idIndexMarker724"/> want to use a network with five layers:</p>
			<ul>
				<li>A <strong class="bold">Keras input layer</strong> to define the input shape</li>
				<li>A <strong class="bold">Keras LSTM layer</strong> for the sequence analysis </li>
				<li>A <strong class="bold">Keras dropout layer</strong> for regularization</li>
				<li>A <strong class="bold">Keras dense layers</strong> with linear activation</li>
				<li>A <strong class="bold">Keras softmax layer</strong> to transform the output into a probability distribution</li>
			</ul>
			<p>The number of unique characters in the training set – that is, the character set size – is <strong class="source-inline">95</strong>. Since we allow sequences of variable length, the shape of the input layer is <strong class="source-inline">?, 95</strong>. The <strong class="source-inline">?</strong> stands for a variable sequence length.</p>
			<p>Next, we have the <strong class="bold">Keras LSTM Layer</strong> node. This time, it is important to activate the <strong class="bold">Return sequences</strong> and <strong class="bold">Return state</strong> checkboxes, as we need the intermediate output states during the training process and the cell state in the deployment. We also set <strong class="source-inline">256</strong> units for this layer and we have left all other settings unchanged.</p>
			<p>In this case study, we want to add even more randomization to the character pick at the output layer, to increment the network creativity. This is done by introducing the <img src="image/Formula_B16391_07_037.png" alt=""/> <strong class="bold">temperature</strong> parameter in the softmax function of the trained output layer.</p>
			<p>Remember, the softmax function is defined as follows:</p>
			<p><img src="image/Formula_B16391_07_038.png" alt=""/> with <img src="image/Formula_B16391_07_039.png" alt=""/></p>
			<p>If we now introduce the additional <img src="image/Formula_B16391_07_040.png" alt=""/> <strong class="bold">temperature</strong> parameter, the formula for the activation function changes to the following:</p>
			<p><img src="image/Formula_B16391_07_041.png" alt=""/> with <img src="image/Formula_B16391_07_042.png" alt=""/></p>
			<p>This means we divide the <a id="_idIndexMarker725"/>linear part by <img src="image/Formula_B16391_07_043.png" alt=""/> before applying the softmax function.</p>
			<p>To be able to insert the temperature parameter after training, we split the output layer into two layers: one <strong class="bold">Keras Dense Layer</strong> node with a linear activation function for the linear part and one <strong class="bold">Keras Softmax Layer</strong> node to apply the activation function.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Temperature is a parameter that can be added after training to control the confidence of the network output. <img src="image/Formula_B16391_07_044.png" alt=""/> makes the network more confident but also more conservative. This often leads to generating the same results at every run.<img src="image/Formula_B16391_07_045.png" alt=""/> implements softer probability distributions over the different outputs. This leads to more diversity but, at the same time, also to more mistakes, such as in this case, character combinations that are impossible in English.</p>
			<h3>Training and Postprocessing the Network</h3>
			<p>The network<a id="_idIndexMarker726"/> is trained using the <strong class="bold">Keras Network Learner</strong> node. For the<a id="_idIndexMarker727"/> input data and the target data, the <strong class="bold">From Collection of Number (integer)</strong> conversion to <strong class="bold">One-Hot Tensor</strong> is selected. The different characters are again like different classes in a multi-class classification problem; therefore, the <strong class="bold">Categorical Cross Entropy</strong> loss function is adopted for training.</p>
			<p>In the third tab, <strong class="bold">Options</strong>, the training phase is set to run for <strong class="source-inline">30</strong> epochs, with a batch size of <strong class="source-inline">128</strong> data rows, shuffling the data before each epoch, and using <strong class="source-inline">Adam</strong> as the optimizer algorithm with the default settings. So far, this is all the same as in the previous NLP case studies.</p>
			<p>After training the network, the temperature, <img src="image/Formula_B16391_07_040.png" alt=""/>, is added by using the <strong class="bold">DL Python Editor</strong> node with the following lines of Python code:</p>
			<p class="source-code">from keras.models import Model</p>
			<p class="source-code">from keras.layers import Input, Lambda</p>
			<p class="source-code">from keras import backend as K</p>
			<p class="source-code"># Define Inputs</p>
			<p class="source-code">state1=Input((256,))</p>
			<p class="source-code">state2=Input((256,))</p>
			<p class="source-code">new_input=Input((1,95))</p>
			<p class="source-code"># Extract layers</p>
			<p class="source-code">lstm=input_network.layers[-4]</p>
			<p class="source-code">dense_softmax=input_network.layers[-1]</p>
			<p class="source-code">dense_linear=input_network.layers[-2]</p>
			<p class="source-code"># Apply LSTM Layer on new Inputs</p>
			<p class="source-code">x, h1, h2=lstm(new_input, initial_state=[state1, state2])</p>
			<p class="source-code"># Apply the linear layer</p>
			<p class="source-code">linear=dense_linear(x)</p>
			<p class="source-code"># Add lambda</p>
			<p class="source-code">linear_div_temp=Lambda(lambda x: x*0.9)(linear)</p>
			<p class="source-code"># Apply Softmax activation</p>
			<p class="source-code">probabilities = dense_softmax(linear_div_temp)</p>
			<p class="source-code">output_network = Model(inputs=[new_input, state1, state2], outputs=[probabilities, h1, h2])</p>
			<p>Remember that the <a id="_idIndexMarker728"/>hidden states of the previous LSTM unit are always used as input<a id="_idIndexMarker729"/> in the next LSTM unit. Therefore, three inputs are defined in the code: two for the two hidden states and one for the last predicted character encoded as a one-hot vector.</p>
			<p>Finally, the network is transformed into a TensorFlow network object and saved for deployment. The final training workflow is shown in <em class="italic">Figure 7.36</em>:</p>
			<div>
				<div id="_idContainer705" class="IMG---Figure">
					<img src="image/B16391_07_036.jpg" alt="Figure 7.36 – Training workflow for the product name generation case study"/>
				</div>
			</div>
			<p class="figure-caption"><a id="_idTextAnchor284"/>Figure 7.36 – Training workflow for the product name generation case study</p>
			<p>The workflow is available on the KNIME Hub: https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%207/.</p>
			<p>Let's continue with the deployment workflow.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor285"/>Building a Deployment Workflow</h2>
			<p>The deployment workflow <a id="_idIndexMarker730"/>again uses the recursive loop approach, similar to the deployment workflow of the NLP and the demand prediction case studies. This time, though, there is one big difference.</p>
			<p>In the last two case studies, the hidden state vectors were re-initialized at each iteration, as we always had <img src="image/Formula_B16391_03_031.png" alt=""/> previous characters or <img src="image/Formula_B16391_03_255.png" alt=""/> previous values as input. In this case study, we pass back, from the loop end node to the loop start node, not only the predicted index but also the two hidden state tensors from the LSTM layer.</p>
			<p>In <em class="italic">Figure 7.37</em>, you can see the <a id="_idIndexMarker731"/>deployment workflow, which is also available on the KNIME Hub: https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%207/. Let's look at the setting differences in detail:</p>
			<div>
				<div id="_idContainer708" class="IMG---Figure">
					<img src="image/B16391_07_037.jpg" alt="Figure 7.37 – Deployment workflow to create multiple possible product names"/>
				</div>
			</div>
			<p class="figure-caption">Fig<a id="_idTextAnchor286"/>ure 7.37 – Deployment workflow to create multiple possible product names</p>
			<p>The first component, <strong class="bold">Create Start Token</strong>, sets the number, <img src="image/Formula_B16391_07_049.png" alt=""/>, of new fictitious mountain names to generate. Then, it creates a table with three columns and <img src="image/Formula_B16391_03_036.png" alt=""/> rows. One column contains only start tokens – that is, a collection cell with the value <strong class="source-inline">1</strong>. The other two columns contain the initial hidden states – that is, collection cells with 256 zeros in both columns.</p>
			<p>The <strong class="bold">TensorFlow Network Executor</strong> node<a id="_idIndexMarker732"/> executes the network one first time, producing as output the probability distribution over the indexes. In the configuration window of <strong class="bold">TensorFlow Network Executor</strong>, we have selected as input the columns with the first hidden state, the second hidden state, and the input collection. In addition, we set three output columns: one output column for the probability distribution, one output column for the first hidden state, and one output column <a id="_idIndexMarker733"/>for the second hidden state. We then pick the next index-encoded character according to the output probability distribution using the <strong class="bold">Random Label Assigner (Data)</strong> node<a id="_idIndexMarker734"/> in the <strong class="bold">First Char</strong> metanode. All these output values, predicted indexes, and hidden states make their way to the loop start node to predict the second index-encoded character.</p>
			<p>Then, we start the recursive loop to generate one character after the next. At each iteration, we apply the network to the last predicted index and hidden states. We then pick the next character, again with the <strong class="bold">Random Number Assigner (Data)</strong> node, and <a id="_idIndexMarker735"/>we feed the last predicted value and the new hidden states into the lower input port of the <strong class="bold">Recursive Loop End</strong> node<a id="_idIndexMarker736"/> so that they can reach back to the loop start node.</p>
			<p>In the <strong class="bold">Extract Mountain Names</strong> component, we finally apply the dictionary – created in the training workflow – and we remove all the mountain names that appeared already in the training set.</p>
			<p>In <em class="italic">Figure 7.38</em>, you can see some of the generated mountain names. Indeed, they are new, copyright-free, evocative of mountains, and nature-feeling, and can be generated automatically in a number <img src="image/Formula_B16391_03_036.png" alt=""/> as high as desired:</p>
			<div>
				<div id="_idContainer712" class="IMG---Figure">
					<img src="image/B16391_07_038.jpg" alt="Figure 7.38 – Mountain names generated by the deployment workflow"/>
				</div>
			</div>
			<p class="figure-caption">Figur<a id="_idTextAnchor287"/>e 7.38 – Mountain names generated by the deployment workflow</p>
			<p>One of them will eventually be chosen as the new product name.</p>
			<h1 id="_idParaDest-142"><a id="_idTextAnchor288"/>Summary</h1>
			<p>We have reached the end of this relatively long chapter. Here, we have described three NLP case studies, each one solved by training an LSTM-based RNN applied to a time series prediction kind of problem.</p>
			<p>The first case study analyzed movie review texts to extract the sentiment hidden in it. We dealt there with a simplified problem, considering a binary classification (positive versus negative) rather than considering too many nuances of possible user sentiment.</p>
			<p>The second case study was language modeling. Training an RNN on a given text corpus with a given style produced a network capable of generating free text in that given style. Depending on the text corpus on which the network is trained, it can produce fairy tales, Shakespearean dialogue, or even rap songs. We showed an example that generates text in fairy tale style. The same workflows can be easily extended with more success to generate rap songs (R. Silipo, <em class="italic">AI generated rap songs</em>, CustomerThink, 2019, <a href="https://customerthink.com/ai-generated-rap-songs/">https://customerthink.com/ai-generated-rap-songs/</a>) or Shakespearean dialogue (R. Silipo, <em class="italic">Can AI write like Shakespeare?</em>, Towards data Science, 2019, <a href="https://towardsdatascience.com/can-ai-write-like-shakespeare-de710befbfee">https://towardsdatascience.com/can-ai-write-like-shakespeare-de710befbfee</a>).</p>
			<p>The last case study involved the generation of candidates for new product names that must be innovative and copyright-free, stands out in the market, and be evocative of nature. So, we trained an RNN to generate fictitious mountain names to be used as name candidates for a new outdoor clothing line.</p>
			<p>In the next chapter, we will describe one more NLP example: neural machine translation.</p>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor289"/>Questions and Exercises</h1>
			<ol>
				<li value="1">What is a word embedding?<p>a) An encoding functionality that can be trained within the neural network</p><p>b) A text cleaning procedure</p><p>c) A training algorithm for an RNN</p><p>d) A postprocessing technique to choose the most likely character </p></li>
				<li>Which statement regarding sentiment analysis is true?<p>a) Sentiment analysis can only be solved with RNNs.</p><p>b) Sentiment analysis is the same as emotion detection.</p><p>c) Sentiment analysis identifies the underlying sentiment in a text.</p><p>d) Sentiment analysis is an image processing task.</p></li>
				<li>What does a many-to-many architecture mean?<p>a) An architecture with an input sequence and an output sequence</p><p>b) An architecture with an input sequence and a vector as output</p><p>c) An architecture with many hidden units and many outputs</p><p>d) An architecture with one input feature and an output sequence</p></li>
				<li>Why do I need a trigger sequence for free text generation?<p>a) To calculate the probabilities</p><p>b) To compare the prediction with the target</p><p>c) To initialize the hidden states before predicting the next character</p><p>d) To save the network in TensorFlow format</p></li>
			</ol>
		</div>
	</body></html>