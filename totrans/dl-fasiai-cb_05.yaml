- en: '*Chapter 5*: Training Recommender Systems'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, so far we have worked through recipes to train deep learning with
    fastai for a variety of datasets. In this chapter, we will go through recipes
    that take advantage of fastai's support for **recommender systems**, also known
    as **collaborative filtering systems**. Recommender systems combine the characteristics
    of tabular data models introduced in [*Chapter 3*](B16216_03_Final_VK_ePub.xhtml#_idTextAnchor083),
    *Training Models with Tabular Data*, with characteristics of text data models
    introduced in [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109), *Training
    Models with Text Data*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommender systems cover a narrow, but well-established, use case: given a
    set of users and their ratings of a set of items, a recommender system predicts
    the rating that a user will give for an item that the user has not rated yet.
    For example, given a set of books and a set of readers'' assessments of these
    books, recommender systems can make predictions about a given reader''s assessment
    of a book they haven''t read yet.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to use fastai's built-in support for recommender
    systems by working through a series of recipes that train models on a variety
    of recommender system datasets. You will see fastai features that will be familiar
    to you from previous chapters, as well as some new features that are unique to
    recommender systems. By the time you have completed this chapter, you will be
    ready to use the fastai high-level API to create recommender systems on your own
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the recipes that will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Training a recommender system on a small curated dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a recommender system on a large curated dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a recommender system on a standalone dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test your knowledge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensure that you have completed the setup sections from [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, and have a working `ch5` folder. This folder contains
    the code samples described in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Training a recommender system on a small curated dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may recall that [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, described applications supported by fastai to cover
    four types of datasets: **tabular**, **text**, **recommender systems**, and **images**.
    In [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057), *Exploring and
    Cleaning Up Data with fastai*, you saw sections on examining tabular datasets,
    text datasets, and image datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: You may have wondered why there wasn't a section on examining recommender system
    datasets. The reason is that the data ingestion process for recommender systems
    in fastai is identical to the process for tabular datasets, as you will see in
    this section. While the ingestion process for recommender systems in fastai is
    identical to the ingestion process for tabular datasets, fastai does provide model
    training details that are specifically intended for recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will go through the process of training a recommender system
    on a curated dataset to learn how to train recommender systems with fastai.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will train your recommender system using a small curated
    dataset – `ML_SAMPLE`. This dataset is a subset of the MovieLens dataset ([https://grouplens.org/datasets/movielens](https://grouplens.org/datasets/movielens))
    that contains user scores for movies. In the *Training a recommender system on
    a large curated dataset* section, we will train a recommender system on a much
    larger subset of the MovieLens dataset – `ML_100k`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Confirm that you can open the `training_recommender_systems.ipynb` notebook
    in the `ch5` directory of your repository.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used in this section and *Training a recommender system on a large
    curated dataset* section are from the MovieLens Datasets. I gratefully acknowledge
    the opportunity to use this dataset to illustrate the recommender system capabilities
    of fastai.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and
    Christopher Potts. (2011). *Learning Word Vectors for Sentiment Analysis* ([http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf)).
    The 49th Annual Meeting of the Association for Computational Linguistics (ACL
    2011) [http://www.aclweb.org/anthology/P11-1015](http://www.aclweb.org/anthology/P11-1015)
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will be running through the `training_recommender_systems.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `path` object for this dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to examine the directory structure of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following output shows the directory structure of the dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Output of path.ls()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_1.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.1 – Output of path.ls()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to load the dataset into the `df` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to see some records from the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output, as shown in *Figure 5.2*, lists records from the dataset. Each
    record represents a user''s rating for a movie. The `userId` column has the ID
    for the user. The `movieId` column has the ID for the movie. The values in the
    `rating` column are the ratings given by the users for the movies. For example,
    user `73` gives movie `1097` a rating of 4.0:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Output of df.head()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_2.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.2 – Output of df.head()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define a `CollabDataLoaders` object for the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The definition of the `CollabDataLoaders` object uses the following arguments:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `df`: The DataFrame that you defined earlier in this notebook'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `bs`: The batch size for the model training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see a batch from the `CollabDataLoaders` object that
    you defined in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output displays the contents of the batch, as shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Output of show_batch()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_3.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.3 – Output of show_batch()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `collab_learner` object for the recommender
    system model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for the definition of the `collab_learner` object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `dls`: The `CollabDataLoaders` object that you defined in a previous step'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `y_range`: The range of values in the `rating` column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to train the collaborative filtering model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the argument for the model definition:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `5`: The number of epochs in the training run for the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output shows the training and validation loss, as shown in the following
    screenshot. You get an indication of the training improving as the validation
    loss decreases through the epochs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Output of training the collaborative filtering model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_4.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.4 – Output of training the collaborative filtering model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now that we have trained a recommender system, we want to test it out by getting
    it to predict the ratings that some users will give for some movies. To exercise
    the recommender system, we first have to create some test data. To create some
    test data, run the following cell to define a DataFrame that includes a couple
    of test entries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the key elements of this cell:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `scoring_columns`: A list of the column names of the DataFrame. Note that
    these column names are the same column names that you saw in the output of `show_batch()`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `test_df`: The DataFrame for containing the test entries with column names
    specified in the `scoring_columns` list.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output of `test_df.head()` shows the contents of the completed DataFrame,
    as shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Contents of the test_df DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_5.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.5 – Contents of the test_df DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'What do these entries in the `test_df` DataFrame mean? We will use this DataFrame
    to see what the recommender system will predict for the following combinations:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a) The rating that `userId` `388` will give for `movieId` `153`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) The rating that `userId` `607` will give for `movieId` `1210`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now that you have defined the `test_df` DataFrame to contain the entries you
    want to test the recommender system with, you can use it to exercise the trained
    recommender system. Run the following cell to get rating predictions from the
    recommender system for the entries in `test_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this cell shows the results of the recommender system, as shown
    in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Results of the recommender system'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_5_6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.6 – Results of the recommender system
  prefs: []
  type: TYPE_NORMAL
- en: 'What do these results mean? The recommender system is predicting the following:'
  prefs: []
  type: TYPE_NORMAL
- en: a) `userId` `388` will give a rating of `2.4156` for `movieId` `153`.
  prefs: []
  type: TYPE_NORMAL
- en: b) `userId` `607` will give a rating of `3.6090` for `movieId` `1210`.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have trained and exercised a recommender system in fastai
    using one of the curated datasets.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you worked through a recipe to train a very basic recommender
    system. Here''s a summary of the key fastai objects you created in this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A `path` object associated with the `URLs` object for the curated dataset:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A `DataLoaders` object:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A `learner` object:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These ingredients should look familiar to you; they are the same core ingredients
    that you used in the recipes in [*Chapter 3*](B16216_03_Final_VK_ePub.xhtml#_idTextAnchor083),
    *Training Models with Tabular Data*, and [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109),
    *Training Models with Text Data*. One of the strengths of the high-level fastai
    API is that it uses the same building blocks to create and train deep learning
    models for a broad variety of datasets, including the datasets you have seen in
    previous chapters and in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one part of this section that is different from most of the recipes
    that you have seen so far – exercising the trained deep learning model on a set
    of test samples. Recall how you exercised the language model in [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109),
    *Training Models with Text Data*. Here is the cell from the `text_model_training.ipynb`
    notebook that exercises the language model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'With a simple call to the `predict()` function, you get the results from the
    trained language model, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Prediction of a language model trained on a standalone text
    dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_5_7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.7 – Prediction of a language model trained on a standalone text dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'We will contrast the way that you exercised the language model in [*Chapter
    4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109), *Training Models with Text
    Data*, with what you needed to do in this recipe to train a recommender system
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a `test_df` DataFrame to contain the test samples, as shown in the following
    screenshot:![Figure 5.8 – Contents of the test_df DataFrame
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16216_5_8.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.8 – Contents of the test_df DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Call `test_dl` using the `test_df` DataFrame that you just created as an argument.
    You can think of `test_dl` applying the same pipeline to the `test_df` DataFrame
    that was applied to the `CollabDataLoaders` object, `dls`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output of this call is the test data loader object, `dl`. With this call
    to `test_dl`, you have transformed the DataFrame into a format to which the trained
    model (the recommender system) can be applied.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Call `get_preds` on the `learn` object to apply the trained recommender system
    to the data loader object, `dl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Why did you need the extra steps to exercise the recommender system that you
    didn't need when you were exercising the language model? The answer is that the
    text phrase that is the input to the language model does not need to go through
    a sample-specific pipeline before it can be applied to the model.
  prefs: []
  type: TYPE_NORMAL
- en: Behind the scenes, fastai uses the vocabulary associated with the `TextDataLoaders`
    object to convert the input string into tokens (by default, words) and then convert
    the tokens into numeric IDs. You don't have to explicitly invoke this pipeline
    – it gets invoked implicitly for you when you call `predict()` on the `learn`
    object for the language model.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the text string that feeds into the language model, the input to the
    recommender system has structure, and that's why you need to define the input
    sample for the recommender system as a DataFrame. Once you have defined the DataFrame,
    you need to call `test_dl` to apply the transformation pipeline (that was implicitly
    defined when you defined the `CollabDataLoaders` object) on the input sample.
    The output of `test_dl` can then be used to get a prediction from the recommender
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on to the next recipe, it's worth taking a closer look at the
    model from this recipe. A deeply detailed description of the model is beyond the
    scope of this book, so we will just focus on some highlights here.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the recipe, the model is defined as a `collab_learner` object (documentation
    here: [https://docs.fast.ai/collab.html#collab_learner](https://docs.fast.ai/collab.html#collab_learner)).
    This object is a specialization of the fastai `learner` object which you first
    saw in section *Understanding the world in four applications: tables, text, recommender
    systems*, and images of [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)*,
    Getting Started with fastai*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of `learn.model` shows that this model is an `EmbeddingDotBias`
    model (documentation here: [https://docs.fast.ai/collab.html#EmbeddingDotBias](https://docs.fast.ai/collab.html#EmbeddingDotBias)).'
  prefs: []
  type: TYPE_NORMAL
- en: Training a recommender system on a large curated dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Training a recommender system on a small curated dataset* section, we
    saw the basics of how to create a recommender system model. The resulting system
    left something to be desired because the dataset only included user IDs and movie
    IDs, so it wasn't possible to determine what movies were actually being rated
    by users and having their ratings predicted by the model.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to create a recommender system that addresses
    this gap in the previous recommender system because it is trained on a dataset
    that includes movie titles. Like the `ML_SAMPLE` dataset, the dataset we'll use
    in this section, `ML_100k`, is also derived from the MovieLens dataset, but it
    includes a much larger set of records and a much richer set of features. By creating
    a recommender system using this dataset, we will encounter additional features
    in fastai for ingesting and working with recommender system datasets and get a
    trained recommender system that is more interesting to use.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Confirm that you can open the `training_large_recommender_systems.ipynb` notebook
    in the `ch5` directory of your repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the recipe in this section, you will use the `tree` command to examine the
    directory that contains the dataset. If you have not already installed the `tree`
    command in your Gradient instance, follow these steps to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command in a Gradient terminal to prepare to install the
    `tree` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following command in a Gradient terminal to install the `tree` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that you have the `tree` command available to use in your Gradient environment,
    you are all ready to work through the recipe in this section.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will be running through the `training_large_recommender_systems.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `path` object for this dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to examine the directory structure of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output shows the directory structure of the dataset, as shown in *Figure
    5.9*. Note that the dataset has a more complex structure than `ML_SAMPLE`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Output of path.ls() for the ML_100k dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_9.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.9 – Output of path.ls() for the ML_100k dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can get an idea of the files that make up the dataset by examining the
    path directly. You can do this by running the `tree` command. First, run the following
    command in a Gradient terminal to make the root directory of the dataset your
    current directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, run the following command in the Gradient terminal to list the contents
    of the directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ├── README
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── allbut.pl
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── mku.sh
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u.data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u.genre
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u.info
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u.item
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u.occupation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u.user
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u1.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u1.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u2.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u2.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u3.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u3.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u4.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u4.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u5.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── u5.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── ua.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── ua.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ├── ub.base
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: └── ub.test
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to define the `df_data` DataFrame to contain the contents
    of the `u.data` file. This DataFrame will contain the ratings provided by users
    for movies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This DataFrame definition is the most complex one that we have seen so far.
    Let''s go through the arguments:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `path/''u.data''`: Specifies the source for this DataFrame, the `u.data`
    file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `delimiter = ''\t''`: Specifies that tabs are the delimiter that separates
    columns in this file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) `header = None`: Specifies that the `u.data` file does not include column
    names in the first row'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) `names = [''userId'',''movieId'',''rating'',''timestamp'']`: Assigns names
    to the columns of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `df_item` DataFrame to contain the contents
    of the `u.item` file. This DataFrame will contain details about movies, including
    their titles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for the definition of `df_item`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `path/''u.item''`: Specifies the source for this DataFrame, the `u.item`
    file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `delimiter = ''|''`: Specifies that the pipe character, ''`|`'', is the
    delimiter that separates columns in this file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) `header = None`: Specifies that this file does not include column names
    in the first row'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) `encoding = "ISO-8859-1"`: Specifies the encoding used to read the file.
    You will get an error if you do not specify this encoding'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see a sample of the contents of the `df_data` DataFrame
    that you created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this command shows the first few rows of the DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.10 – The first few rows of the df_data DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.10 – The first few rows of the df_data DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see the dimensions of the `df_data` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this command shows the number of rows and columns in the `df_data`
    DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Shape of the df_data DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.11 – Shape of the df_data DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see a sample of the contents of the `df_item` DataFrame
    that you created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this command shows the first few rows of the DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B16216_5_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 5.12 – The first few rows of the df_item DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see the dimensions of the `df_item` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to prepare the `df_item` DataFrame by removing most
    of the columns and adding column names for the remaining columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to combine the `df_data` and `df_item` DataFrames into
    a single new DataFrame, `df`, that combines the columns from the original DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for `merge` to combine the DataFrames:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `df_data`: The DataFrame containing the user ID, movie ID, and rating.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `df_item`: The DataFrame containing the movie ID and movie title.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) `on=[''movieId'']`: Specifies that the two DataFrames will be joined on
    the `movieID` column.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) `how=''left''`: Specifies that the rows from the `df_data` DataFrame will
    form the basis for the new DataFrame that is the result of the merge. That is,
    the new DataFrame will have the same number of rows as `df_data`, with each row
    including all the columns from `df_data` plus the `movieName` column from `df_item`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This cell produces as output the first few rows of the new `df` DataFrame,
    as shown in *Figure 5.15*. Compared to `df_data`, you can see that `df` has one
    additional column, `movieName`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.15 – The first few rows of df'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.15 – The first few rows of df
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see the dimensions of the `df` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to see the number of unique values in each column of
    the `df` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this command lists all the columns of the DataFrame with the
    count of unique items in each column:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Count of unique values in each column of the df DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.17 – Count of unique values in each column of the df DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see whether there are any missing values in any of
    the columns of `df`. If there are any missing values, we will need to deal with
    them prior to training the recommender system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this command lists the number of missing values for each column.
    Since there are no missing values, we can proceed with the steps to train the
    recommender system:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Count of missing values in each column of the df DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.18 – Count of missing values in each column of the df DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define a `CollabDataLoaders` object for the recommender
    system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for the definition of the `CollabDataLoaders` object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `df`: The DataFrame used to create the `CollabDataLoaders` object'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `item_name=''movieName''`: Specifies the column that contains the name of
    the item that is the subject of the recommender system, in this case, `movieName`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) `bs= 64`: Sets the batch size (the number of items on which the average
    loss is calculated) at 64'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see a batch from the `CollabDataLoaders` object that
    you defined in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output displays the contents of the batch, as shown in *Figure 5.19*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Output of show_batch'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.19 – Output of show_batch
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the model for the recommender system by defining
    a `collab_learner` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for the definition of the `collab_learner` object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `dls`: The `CollabDataLoaders` object that you defined for the dataset.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `y_range= [ 1 , 5 ]`: Specifies the range of the values being predicted
    by the recommender system. In our case, this is the range of values for movie
    ratings in the `rating` column of the dataset.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to train the model for the recommender system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the argument for the model definition:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `5`: The number of epochs in the training run for the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output displays the training and validation loss for each epoch, as shown
    in *Figure 5.20*. You get an indication of the training improving as the validation
    loss decreases through the epochs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Output of training the collaborative filtering model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.20 – Output of training the collaborative filtering model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Before we exercise the recommender system, let''s get an idea of what ratings
    users give to a movie that has a reputation for not being very good. Run the following
    cell to see the subset of the `df` DataFrame for the movie `Showgirls`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output shows the first few rows in the `df` DataFrame that contain ratings
    for *Showgirls*, as shown in *Figure 5.21*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Subset of the df DataFrame for a single movie'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.21 – Subset of the df DataFrame for a single movie
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'From the output of the previous cell, it seems like there is a range of ratings
    for this movie. Let''s see what the average rating is for this movie for all users.
    Run the following cell to see the average rating for this movie:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is shown in *Figure 5.22*. As we suspected, the average rating for
    this movie is indeed low:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.22 – Average rating for Showgirls'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.22 – Average rating for Showgirls
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To exercise the recommender system, we want to get rating predictions for one
    user for a set of movies. Run the following cell to define a test DataFrame to
    exercise the trained recommender system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the key elements of this cell:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `scoring_columns`: A list of the column names of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `test_df`: The DataFrame for containing the test entries with column names
    specified in the `scoring_columns` list'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that the value for `userId` is the same for every row in this DataFrame.
    When we apply this DataFrame to our recommender system, we will be getting predicted
    ratings for one user for three movies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output of `test_df.head()` shows the contents of the completed DataFrame,
    as shown in *Figure 5.23*. For each row in this DataFrame, we will get the recommender
    system to predict the rating that `userID` `607` would give for the movie in that
    row:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Contents of test_df DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.23 – Contents of test_df DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to get rating predictions from the recommender system
    for the entries in `test_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this cell shows the results of the recommender system, as shown
    in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.24 – Results of the recommender system'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_5_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.24 – Results of the recommender system
  prefs: []
  type: TYPE_NORMAL
- en: 'What do these results mean? The recommender system is predicting that `userID`
    `607` will give the following ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: a) `4.2557` for `Kolya`
  prefs: []
  type: TYPE_NORMAL
- en: b) `4.3637` for `L.A. Confidential`
  prefs: []
  type: TYPE_NORMAL
- en: c) `2.2996` for `Showgirls`
  prefs: []
  type: TYPE_NORMAL
- en: This is not an exhaustive test of the recommender system, but the ratings seem
    plausible because a high rating is predicted for `L.A. Confidential`, a well-regarded
    movie, and a low rating is predicted for `Showgirls`, a movie that received very
    poor reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have trained a recommender system in fastai using a large
    curated dataset that includes a broad variety of rating combinations.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you worked through a recipe to train a recommender system
    on a large dataset. It''s worth summarizing how this recipe differed from the
    recipe in *Training a recommender system on a small curated dataset* section.
    Here are the key differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ratings.csv`. The large dataset is made up of over 20 files, although we only
    use two for the recipe in this section: `u.data` (which contains user IDs, movie
    IDs, and the user''s ratings for the movies) and `u.item` (which contains additional
    information about movies, including their titles).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Size of the datasets**: The small dataset has a little over 6,000 records.
    The large dataset has 100 k records.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test DataFrame**: For the recommender system trained on a small dataset,
    the test DataFrame contained the user IDs and movie IDs for which we wanted to
    get predicted ratings. For the recommender system trained on a large dataset,
    the test DataFrame contained user IDs, movie IDs, and movie titles for which we
    wanted to get predicted ratings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The facilities of fastai make it easy to create recommender systems on both
    the small and large curated datasets. In the next section, we'll explore how to
    use fastai to create a recommender system on a standalone dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Training a recommender system on a standalone dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Training a recommender system on a small curated dataset* and *Training
    a recommender system on a large curated dataset* recipes, we used two curated
    datasets adapted from the MovieLens dataset that contains user IDs, movie IDs,
    and user ratings for these movies. Using these two curated datasets, we created
    recommender systems that predicted what rating a user would give to a particular
    movie.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will explore a dataset that is not a part of fastai's set
    of curated datasets. The dataset we will use in this section is the Amazon product
    dataset ([https://www.kaggle.com/saurav9786/amazon-product-reviews](https://www.kaggle.com/saurav9786/amazon-product-reviews)).
    This dataset contains user ratings for a large range of products available on
    Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will be working with a subset of the dataset, the subset
    related to electronic goods. In the recipe in this section, we will ingest this
    standalone dataset and then use it to train a recommender system that can predict
    a user's rating for an item.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Confirm that you can open the `training_recommender_systems_on_standalone_dataset.ipynb`
    notebook in the `ch5` directory of your repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure that you have uploaded the file for the Amazon product dataset to your
    Gradient environment by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the `archive.zip` file from [https://www.kaggle.com/saurav9786/amazon-product-reviews](https://www.kaggle.com/saurav9786/amazon-product-reviews).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unzip the downloaded `archive.zip` file to extract `ratings_Electronics (1).csv`.
    Rename this file to `ratings_Electronics.csv`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the terminal in your Gradient environment, make `/storage/archive` your
    current directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `/storage/archive/amazon_reviews` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Make `/storage/archive/amazon_reviews` your current directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upload the files you extracted in *step 2* (`ratings_Electronics.csv`) to `/storage/archive/amazon_reviews`.
    You can use the upload button in JupyterLab in Gradient to do the upload by following
    these steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) From the terminal in your Gradient environment, make `/notebooks` your current
    directory:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'temp your current folder, select the upload button (see *Figure 5.25*), and
    then select the ratings_Electronics.csv file from your local system folder where
    you extracted it in *step 2*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 5.25 – The upload button in JupyterLab'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_5_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.25 – The upload button in JupyterLab
  prefs: []
  type: TYPE_NORMAL
- en: 'd) From the terminal in your Gradient environment, copy the `ratings_Electronics.csv`
    file into the `/storage/archive/amazon_reviews` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: I gratefully acknowledge the opportunity to use the Amazon product dataset to
    illustrate the recommender system capabilities of fastai on non-curated datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: J. McAuley, C. Targett, J. Shi, A. van den Hengel (2015). *Image-based recommendations
    on styles and substitutes* ([http://cseweb.ucsd.edu/~jmcauley/pdfs/sigir15.pdf](http://cseweb.ucsd.edu/~jmcauley/pdfs/sigir15.pdf)).
    Special Interest Group on Information Retrieval (SIGIR 2015)
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have copied the dataset file into your Gradient environment, you
    are ready to go through the recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will be running through the `training_recommender_systems_on_standalone_dataset.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following cell to define the path object for this dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The argument `'amazon_reviews'` indicates that this path object is being defined
    to point to the `/storage/archive/amazon_reviews` directory that you created in
    the *Getting ready* section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to examine the directory structure of the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output shows the directory structure of the dataset, as shown in *Figure
    5.26*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.26 – The output of path.ls() for the Amazon product dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.26 – The output of path.ls() for the Amazon product dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `df` DataFrame to contain the contents
    of the `ratings_Electronics.csv` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for the definition of the `df` DataFrame:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `path/''ratings_Electronics.csv''`: Specifies the source for this DataFrame,
    the `ratings_Electronics.csv` file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `header = None`: Specifies that this file does not include column names
    in the first row'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define names for the columns of the `df` DataFrame.
    These column names come from the description of the dataset at [https://www.kaggle.com/saurav9786/amazon-product-reviews](https://www.kaggle.com/saurav9786/amazon-product-reviews):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following cell to examine the `df` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output, as shown in *Figure 5.26*, lists records from the dataset. Each
    record represents a user''s rating for a product. The `userID` column has the
    ID for the user. The `productID` column has the ID for the product. The `rating`
    column is the rating given by the user for the product:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.27 – Output of df.head()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.27 – Output of df.head()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to get the dimensions of the `df` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output, as shown in *Figure 5.27*, shows that the DataFrame has over 7
    million rows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.28 – Shape of DataFrame df'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.28 – Shape of DataFrame df
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `CollabDataLoaders` object, `dls`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments to the definition of the `CollabDataLoaders` object,
    `dls`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `df`: Specifies that the DataFrame you created for the dataset, `df`, is
    used to create the `CollabDataLoaders` object'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `bs = 64`: Specifies that the batch size is `64`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to see a batch from the `CollabDataLoaders` object that
    you defined in the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output displays the contents of the batch, as shown in *Figure 5.28*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.29 – Output of show_batch()'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.29 – Output of show_batch()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `collab_learner` object for the recommender
    system model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the arguments for the definition of the `collab_learner` object:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `dls`: The `CollabDataLoaders` object that you defined in a previous step'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `y_range`: The range of values in the `rating` column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to train the recommender system model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the argument for the model definition:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `1`: The number of epochs in the training run for the model.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The dataset you are using in this recipe is big. Recall that when you ran the
    cell to get the dimensions of the `df` DataFrame, you found that this DataFrame
    has over 7 million rows. What this means is that training the model will take
    some time. For example, it took me over 3 hours to train a recommender system
    model on this dataset in a Gradient environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output shows the training and validation loss, as shown in the following
    screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.30 – Output of training the collaborative filtering model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.30 – Output of training the collaborative filtering model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following cell to define the `test_df` DataFrame, which includes a
    couple of test entries that you can use to exercise the trained recommender system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here are the key elements of this cell:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'a) `scoring_columns`: A list of the column names of the DataFrame. Note that
    these column names are the same column names that you saw in the output of `show_batch()`
    in *Figure 5.29*.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `test_df`: The DataFrame for containing the test entries with column names
    specified in the `scoring_columns` list.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output of `test_df.head()` shows the contents of the completed `test_df`
    DataFrame, as shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.31 – Contents of the test_df DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16216_5_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.31 – Contents of the test_df DataFrame
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now that you have defined the `test_df` DataFrame, you can use it to exercise
    the trained recommender system. Run the following cell to get rating predictions
    from the recommender system for the entries in `test_df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this cell shows the results of the recommender system, as shown
    in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.32 – Results of the recommender system'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16216_5_32.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.32 – Results of the recommender system
  prefs: []
  type: TYPE_NORMAL
- en: What do these results mean?
  prefs: []
  type: TYPE_NORMAL
- en: a) The first entry in the output, `4.4364`, is the recommender system's prediction
    for the first entry in `test_df`. The recommender system is predicting that the
    user with a user ID of `A2NYK9KWFMJV4Y` will give a rating of `4.4364` for the
    product with a product ID of `B008ABOJKS`.
  prefs: []
  type: TYPE_NORMAL
- en: b) The second entry in the output, `2.5531`, is the recommender system's prediction
    for the second entry in `test_df`. The recommender system is predicting that the
    user with a user ID of `A29ZTEO6EKSRDV` will give a rating of `2.5531` for the
    product with a product ID of `B006202R44`.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have trained a recommender system in fastai using a standalone
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you worked through a recipe for training a recommender system
    on a standalone dataset. Like the standalone datasets that you encountered in
    [*Chapter 3*](B16216_03_Final_VK_ePub.xhtml#_idTextAnchor083), *Training Models
    with Tabular Data*, and [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109),
    *Training Models with Text Data*, the standalone dataset that you used in this
    section required you to take some additional steps compared to the fastai curated
    datasets that you used in the *Training a recommender system on a small curated
    dataset* and *Training a recommender system on a large curated dataset* recipes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a summary of the additional steps required for a standalone dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Find a dataset**. This may sound simplistic, but once you move beyond the
    world of the fastai curated datasets and try to learn more by using standalone
    datasets, it can be a challenge to find the right dataset. The Kaggle site, [https://www.kaggle.com/](https://www.kaggle.com/),
    is a great place to start. You want a dataset that''s big enough to give a fighting
    chance when it comes to training a deep learning model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: My experience has been that if I'm not using transfer learning (that is, starting
    off with a pre-existing model that has been trained on a general dataset that
    applies to the use case I want to train my deep learning model on), then I need
    to have a dataset that has at least several tens of thousands of items in it.
    .
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You want a dataset that's not too big. As you saw in the recipe in this section
    and in the language models you trained in [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109),
    *Training Models with Text Data*, training a model with a big dataset can take
    hours. If you're using a Gradient instance with a cost (as opposed to Colab or
    a free Gradient instance), you can end up spending several dollars for a single
    training run. Costs can add up if you need to do multiple training runs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Bring the dataset into your fastai environment**. As described in the *Getting
    ready* section of this recipe, after you have downloaded the dataset to your local
    system, you have to create a directory in your fastai environment to hold the
    dataset files and then upload the files to that directory.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One of the advantages of fastai is the large number of curated datasets. However,
    for dataset types such as recommender systems, where fastai only offers one or
    two curated datasets, it is advantageous for you to feel comfortable with finding
    standalone datasets with different characteristics, so you can perform a wider
    variety of experiments. By following the recommendations in this section, you
    will be able to expand your world of datasets beyond the fastai curated datasets
    when you're ready to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: Test your knowledge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have worked through some extended examples of training fastai recommender
    systems, you can try some variations to exercise what you've learned.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensure that you have followed the *Training a recommender system on a standalone
    dataset* recipe. In this section, you will be adapting the notebook worked through
    in that recipe to create a recommender system for a new standalone dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can follow the steps in this section to try some variations on the recommender
    system that you trained with the Amazon product dataset in the *Training a recommender
    system on a standalone dataset* recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make a copy of the `training_recommender_systems_on_standalone_dataset.ipynb`
    notebook that you worked through in the *Training a recommender system on a standalone
    dataset* recipe. Give your new copy of the notebook the following name: `training_recommender_systems_on_new_standalone_dataset.ipynb`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the description of the whole Amazon product dataset at [http://jmcauley.ucsd.edu/data/amazon/](http://jmcauley.ucsd.edu/data/amazon/).
    From the list of `small subsets for``experimentation`, select a category other
    than `Electronics`. You have already trained a recommender system with the `Electronics` dataset
    in the *Training a recommender system on a standalone dataset* recipe, so you
    will want to pick another category.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, you could pick `Office Products` or `Automotive`. I suggest avoiding
    the `Books` category because its file is three times larger than the `Electronics`
    dataset, so you could be facing a whole day training a recommender system on the
    *Books* dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adapt the steps in the *Getting ready* section of the *Training a recommender
    system on a standalone dataset* recipe to get the *ratings only* dataset for the
    category you chose in *Step 2* in your fastai environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update your `training_recommender_systems_on_new_standalone_dataset.ipynb` notebook
    to ingest the dataset you brought into your fastai environment in *Step 3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update your notebook to load the dataset into a DataFrame and then use the techniques
    you have seen in this chapter (including `head()` and `shape`) to examine the
    structure of the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using what you learned in *Step 5*, update the rest of your `training_recommender_systems_on_new_standalone_dataset.ipynb`
    notebook to create, train, and test a recommender system for the dataset you selected
    in *Step 2*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Congratulations! You have completed a review of training recommender systems
    using fastai.
  prefs: []
  type: TYPE_NORMAL
