["```py\n    cd ~/SageMaker\n    git clone https://github.com/PacktPublishing/Accelerate-Deep-Learning-Workloads-with-Amazon-SageMaker\n    ```", "```py\n    docker pull nvcr.io/nvidia/pytorch:22.06-py3\n    docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -it --rm -v ~/SageMaker/Accelerate-Deep-Learning-Workloads-with-Amazon-SageMaker/chapter8/1_src:/workspace/tensorrt_benchmark nvcr.io/nvidia/pytorch:22.06-py3\n    ```", "```py\n    cd tensorrt_benchmark/\n    bash data_download.sh\n    python benchmarking_resnet50.py\n    ```", "```py\n    import torch\n    resnet50_model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet50\", pretrained=True)\n    resnet50_model.eval()\n    ```", "```py\n    import torch_tensorrt\n    trt_model_fp32 = torch_tensorrt.compile(model, inputs = [torch_tensorrt.Input((128, 3, 224, 224), dtype=torch.float32)],\n        enabled_precisions = torch.float32,\n        workspace_size = 1 << 22\n    )\n    ```", "```py\n    trt_model_fp32.save('resnet50_fp32.pt')\n    loaded = torch.jit.load('resnet50_fp32.pt')\n    ```", "```py\n    chmod 400 <your_ssh_key>\n    ssh -i <your_ssh_key>ubuntu@<your_instance_public_DNS>\n    ```", "```py\n    git clone https://github.com/PacktPublishing/Accelerate-Deep-Learning-Workloads-with-Amazon-SageMaker\n    cd Accelerate-Deep-Learning-Workloads-with-Amazon-SageMaker/chapter8/\n    jupyter notebook --ip=0.0.0.0\n    ```", "```py\n    import torch\n    from torchvision import models, transforms, datasets\n    import torch_neuron\n    image = torch.zeros([1, 3, 224, 224], dtype=torch.float32)\n    model = models.resnet50(pretrained=True)\n    model.eval()\n    ```", "```py\n    torch.neuron.analyze_model(model, example_inputs=[image])\n    ```", "```py\n    model_neuron = torch.neuron.trace(model, example_inputs=[image])\n    ```", "```py\n    model_neuron.save(\"resnet50_neuron.pt\")\n    model_neuron = torch.jit.load('resnet50_neuron.pt')\n    ```", "```py\n    model_neuron_parallel = torch.neuron.DataParallel(model_neuron)\n    num_neuron_cores = 4\n    image = preprocess(batch_size=batch_size, num_neuron_cores=num_neuron_cores)\n    benchmark(model_neuron_parallel, image)\n    ```", "```py\nInput image shape is [4, 3, 224, 224]\nAvg. Throughput: 551, Max Throughput: 562\nLatency P50: 7\nLatency P90: 7\nLatency P95: 7\nLatency P99: 7\n```", "```py\n    batch_size = 5\n    image = torch.zeros([batch_size, 3, 224, 224], dtype=torch.float32)\n    model_neuron = torch.neuron.trace(model, example_inputs=[image])\n    model_neuron.save(\"resnet50_neuron_b{}.pt\".format(batch_size))\n    ```", "```py\n    Batch_size = 5\n    model_neuron = torch.jit.load(\"resnet50_neuron_b{}.pt\".format(batch_size))\n    model_neuron_parallel = torch.neuron.DataParallel(model_neuron)\n    image = preprocess(batch_size=batch_size, num_neuron_cores=num_neuron_cores)\n    benchmark(model_neuron_parallel, image)\n    ```", "```py\nInput image shape is [20, 3, 224, 224]\nAvg. Throughput: 979, Max Throughput: 998\nLatency P50: 20\nLatency P90: 21\nLatency P95: 21\nLatency P99: 24\n```", "```py\n    neuron_pipeline_model = torch.neuron.trace(model,\n                                               example_inputs=[image],\n                                               verbose=1,\n                                               compiler_args = ['--neuroncore-pipeline-cores', str(num_neuron_cores)])\n    ```", "```py\n    image = preprocess(batch_size=batch_size, num_neuron_cores=num_neuron_cores)\n    benchmark(neuron_pipeline_model, image)\n    ```", "```py\nInput image shape is [20, 3, 224, 224]\nAvg. Throughput: 271, Max Throughput: 274\nLatency P50: 73\nLatency P90: 74\nLatency P95: 74\nLatency P99: 79\n```", "```py\ndef serving_input_fn():\n    inputs = {\"x\": tf.placeholder(tf.float32, [None, 784])}\n    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n```", "```py\nmnist_estimator = TensorFlow(entry_point='mnist.py',\n                             source_dir=\"3_src\",\n                             role=role,\n                             instance_count=1,\n                             instance_type='ml.p3.2xlarge',\n                             framework_version='1.15.0',\n                             py_version='py3',\n                             )\nmnist_estimator.fit(training_data_uri)\n```", "```py\n    p2_estimator = mnist_estimator.compile_model(target_instance_family='ml_p2', \n                                  input_shape={'data':[1, 784]},\n                                  output_path=output_path)\n    p2_predictor = p2_estimator.deploy(initial_instance _count = 1,\n                                                     instance_type = 'ml.inf1.xlarge')\n    ```", "```py\n    c5_estimator = mnist_estimator.compile_model(target_instance_family='ml_c5', \n                                  input_shape={'data':[1, 784]},  \n                                  output_path=output_path)\n    c5_predictor = c5_estimator.deploy(initial_instance_count = 1,\n                                                     instance _type = 'ml.c5.xlarge')\n    ```", "```py\n    data = inference_data[i].reshape(1,784)\n    predict_response= p2_predictor.predict(data)\n    ```"]