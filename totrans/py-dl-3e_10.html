<html><head></head><body>
<div id="_idContainer1090">
<h1 class="chapter-number" id="_idParaDest-179" lang="en-GB"><a id="_idTextAnchor253"/><span class="koboSpan" id="kobo.1.1">10</span></h1>
<h1 id="_idParaDest-180" lang="en-GB"><a id="_idTextAnchor254"/><span class="koboSpan" id="kobo.2.1">Machine Learning </span><br/><span class="koboSpan" id="kobo.3.1">Operations (MLOps)</span></h1>
<p lang="en-GB"><span class="koboSpan" id="kobo.4.1">So far in this book, we have focused on the theory of </span><strong class="bold"><span class="koboSpan" id="kobo.5.1">neural networks</span></strong><span class="koboSpan" id="kobo.6.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.7.1">NNs</span></strong><span class="koboSpan" id="kobo.8.1">), various NN architectures, and the tasks we can solve with them. </span><span class="koboSpan" id="kobo.8.2">This chapter is a little different because we’ll focus on some of the practical aspects of NN development. </span><span class="koboSpan" id="kobo.8.3">We’ll delve into this topic because the development and production deployment of ML models (and NNs in particular) have some unique challenges. </span><span class="koboSpan" id="kobo.8.4">We can split this process into </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">three steps:</span></span></p>
<ol>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.10.1">Training dataset creation</span></strong><span class="koboSpan" id="kobo.11.1">: Data collection, cleanup, storage, transformations, and </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">feature engineering.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.13.1">Model development</span></strong><span class="koboSpan" id="kobo.14.1">: Experiment with different models and training algorithms and </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">evaluate them.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.16.1">Deployment</span></strong><span class="koboSpan" id="kobo.17.1">: Deploy trained models in the production environment and monitor their performance in computational and </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">accuracy terms.</span></span></li>
</ol>
<p lang="en-GB"><span class="koboSpan" id="kobo.19.1">This multi-step complex pipeline presupposes some of the challenges when solving </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">ML tasks:</span></span></p>
<ul>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.21.1">Diverse software toolkit</span></strong><span class="koboSpan" id="kobo.22.1">: Each step has multiple </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">competing tools.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.24.1">Model development is hard</span></strong><span class="koboSpan" id="kobo.25.1">: Each training instance has a large number of variables. </span><span class="koboSpan" id="kobo.25.2">These could be modifications in the NN architecture, variations in the training hyperparameters (such as learning rate or momentum), or different training data distributions. </span><span class="koboSpan" id="kobo.25.3">On top of that, NNs have sources of randomness, such as weight initialization or data augmentation. </span><span class="koboSpan" id="kobo.25.4">Therefore, if we cannot reproduce earlier results, it won’t be easy to pinpoint the reason. </span><span class="koboSpan" id="kobo.25.5">Even if we have a bug in the code, it might not result in an easily detectable runtime exception. </span><span class="koboSpan" id="kobo.25.6">Instead, it might just deteriorate the model accuracy slightly. </span><span class="koboSpan" id="kobo.25.7">So that we don’t lose track of all the experiments, we need a robust tracking and </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">monitoring system.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.27.1">Complex deployment and monitoring</span></strong><span class="koboSpan" id="kobo.28.1">: NNs require GPUs and batch-organized data for optimal performance. </span><span class="koboSpan" id="kobo.28.2">These requirements might collide with the real-world requirements of processing data in streams or sample-wise. </span><span class="koboSpan" id="kobo.28.3">In addition, the nature of the user data might change with time, which could cause </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.29.1">model drift</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">.</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.31.1">In this chapter, we will cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">main topics:</span></span></p>
<ul>
<li lang="en-GB"><span class="koboSpan" id="kobo.33.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">model development</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.35.1">Exploring </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">model deployment</span></span></li>
</ul>
<h1 id="_idParaDest-181" lang="en-GB"><a id="_idTextAnchor255"/><span class="koboSpan" id="kobo.37.1">Technical requirements</span></h1>
<p lang="en-GB"><span class="koboSpan" id="kobo.38.1">We’ll implement the examples in this chapter using Python, PyTorch, </span><strong class="bold"><span class="koboSpan" id="kobo.39.1">TensorFlow</span></strong><span class="koboSpan" id="kobo.40.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.41.1">TF</span></strong><span class="koboSpan" id="kobo.42.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.43.1">Hugging Face</span></strong><span class="koboSpan" id="kobo.44.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.45.1">HF</span></strong><span class="koboSpan" id="kobo.46.1">) Transformers, among others. </span><span class="koboSpan" id="kobo.46.2">If you don’t have an environment set up with these tools, fret not – the examples are available as Jupyter Notebooks on Google Colab. </span><span class="koboSpan" id="kobo.46.3">You can find the code examples in this book’s GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">repository: </span></span><a href="https://github.com/PacktPublishing/Python-Deep-Learning-Third-Edition/tree/main/Chapter10"><span class="No-Break"><span class="koboSpan" id="kobo.48.1">https://github.com/PacktPublishing/Python-Deep-Learning-Third-Edition/tree/main/Chapter10</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.49.1">.</span></span></p>
<h1 id="_idParaDest-182" lang="en-GB"><a id="_idTextAnchor256"/><span class="koboSpan" id="kobo.50.1">Understanding model development</span></h1>
<p lang="en-GB"><span class="koboSpan" id="kobo.51.1">In this section, we’ll discuss</span><a id="_idIndexMarker1402"/><span class="koboSpan" id="kobo.52.1"> various tools that will help us manage the model development phase of the ML solution life cycle. </span><span class="koboSpan" id="kobo.52.2">Let’s start with the most important question – which NN framework should </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">we choose?</span></span></p>
<h2 id="_idParaDest-183" lang="en-GB"><a id="_idTextAnchor257"/><span class="koboSpan" id="kobo.54.1">Choosing an NN framework</span></h2>
<p lang="en-GB"><span class="koboSpan" id="kobo.55.1">So far in this book, we’ve mostly used PyTorch and TensorFlow. </span><span class="koboSpan" id="kobo.55.2">We can refer to them as </span><strong class="bold"><span class="koboSpan" id="kobo.56.1">foundational</span></strong><span class="koboSpan" id="kobo.57.1"> frameworks </span><a id="_idIndexMarker1403"/><span class="koboSpan" id="kobo.58.1">as these are the </span><a id="_idIndexMarker1404"/><span class="koboSpan" id="kobo.59.1">most important components of the entire NN software stack. </span><span class="koboSpan" id="kobo.59.2">They serve as a</span><a id="_idIndexMarker1405"/><span class="koboSpan" id="kobo.60.1"> base for other components in the ML NN ecosystem, such as Keras or HF Transformers, which can use either of them as a backend (multi-backend support will come with Keras 3.0). </span><span class="koboSpan" id="kobo.60.2">In addition to TF, Google has also released JAX (</span><a href="https://github.com/google/jax"><span class="koboSpan" id="kobo.61.1">https://github.com/google/jax</span></a><span class="koboSpan" id="kobo.62.1">), a foundational library that supports GPU-accelerated NumPy operations and Autograd. </span><span class="koboSpan" id="kobo.62.2">Other popular libraries such as NumPy, pandas, and scikit-learn (</span><a href="https://scikit-learn.org"><span class="koboSpan" id="kobo.63.1">https://scikit-learn.org</span></a><span class="koboSpan" id="kobo.64.1">) go beyond the </span><a id="_idIndexMarker1406"/><span class="koboSpan" id="kobo.65.1">scope of this book as they are not strictly related to NNs. </span><span class="koboSpan" id="kobo.65.2">Because of the importance of </span><a id="_idIndexMarker1407"/><span class="koboSpan" id="kobo.66.1">foundational libraries, they are the first and most important choice in our toolkit. </span><span class="koboSpan" id="kobo.66.2">But which one should we choose if we</span><a id="_idIndexMarker1408"/><span class="koboSpan" id="kobo.67.1"> start a project </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">from scratch?</span></span></p>
<h2 id="_idParaDest-184" lang="en-GB"><a id="_idTextAnchor258"/><span class="koboSpan" id="kobo.69.1">PyTorch versus TensorFlow versus JAX</span></h2>
<p lang="en-GB"><span class="koboSpan" id="kobo.70.1">Let’s check the level of community adoption for</span><a id="_idIndexMarker1409"/><span class="koboSpan" id="kobo.71.1"> these libraries. </span><span class="koboSpan" id="kobo.71.2">Our first stop is </span><strong class="bold"><span class="koboSpan" id="kobo.72.1">Papers with Code</span></strong><span class="koboSpan" id="kobo.73.1"> (</span><a href="https://paperswithcode.com/"><span class="koboSpan" id="kobo.74.1">https://paperswithcode.com/</span></a><span class="koboSpan" id="kobo.75.1">), which indexes ML papers, code, datasets, and results. </span><span class="koboSpan" id="kobo.75.2">The site also</span><a id="_idIndexMarker1410"/><span class="koboSpan" id="kobo.76.1"> maintains the trend of paper</span><a id="_idIndexMarker1411"/><span class="koboSpan" id="kobo.77.1"> implementations grouped by framework (</span><a href="https://paperswithcode.com/trends"><span class="koboSpan" id="kobo.78.1">https://paperswithcode.com/trends</span></a><span class="koboSpan" id="kobo.79.1">). </span><span class="koboSpan" id="kobo.79.2">As of September 2023, 57% of the new papers are using</span><a id="_idIndexMarker1412"/><span class="koboSpan" id="kobo.80.1"> PyTorch. </span><span class="koboSpan" id="kobo.80.2">TF and JAX are distant </span><a id="_idIndexMarker1413"/><span class="koboSpan" id="kobo.81.1">second and third with 3% and 2%, respectively. </span><span class="koboSpan" id="kobo.81.2">This trend isn’t new – PyTorch was released in 2016, but it has already surpassed TF in 2019. </span><span class="koboSpan" id="kobo.81.3">This</span><a id="_idIndexMarker1414"/><span class="koboSpan" id="kobo.82.1"> particular data point indicates that PyTorch dominates cutting-edge research, which is what the most recent papers are. </span><span class="koboSpan" id="kobo.82.2">Therefore, if you</span><a id="_idIndexMarker1415"/><span class="koboSpan" id="kobo.83.1"> want to always use the latest and greatest in the field, it’s a good idea to stick to PyTorch. </span><span class="koboSpan" id="kobo.83.2">Next, let’s look at the ML models, hosted on the HF platform (</span><a href="https://huggingface.co/models"><span class="koboSpan" id="kobo.84.1">https://huggingface.co/models</span></a><span class="koboSpan" id="kobo.85.1">), where we can </span><a id="_idIndexMarker1416"/><span class="koboSpan" id="kobo.86.1">also filter by project framework. </span><span class="koboSpan" id="kobo.86.2">Out of ~335,000 total models hosted, ~131,000 use PyTorch, ~10,000 use TF, and ~9,000 use JAX. </span><span class="koboSpan" id="kobo.86.3">Again, this is a strong result in favor of PyTorch. </span><span class="koboSpan" id="kobo.86.4">However, this is not the full picture, as these results are for public and open source projects. </span><span class="koboSpan" id="kobo.86.5">They are not necessarily indicative of what companies use in production. </span><span class="koboSpan" id="kobo.86.6">More representative of this could be </span><a id="_idIndexMarker1417"/><span class="koboSpan" id="kobo.87.1">PyPI Stats (</span><a href="https://pypistats.org/"><span class="koboSpan" id="kobo.88.1">https://pypistats.org/</span></a><span class="koboSpan" id="kobo.89.1">), which provides aggregate download information on Python packages available from the </span><strong class="bold"><span class="koboSpan" id="kobo.90.1">Python Package Index</span></strong><span class="koboSpan" id="kobo.91.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.92.1">PyPi</span></strong><span class="koboSpan" id="kobo.93.1">, </span><a href="https://pypi.org/"><span class="koboSpan" id="kobo.94.1">https://pypi.org/</span></a><span class="koboSpan" id="kobo.95.1">). </span><span class="koboSpan" id="kobo.95.2">The </span><a id="_idIndexMarker1418"/><span class="koboSpan" id="kobo.96.1">picture here is a bit more nuanced – PyTorch has 11,348,753 downloads for the last month (August-September 2023) versus 16,253,288 for TF and 3,041,747 for JAX. </span><span class="koboSpan" id="kobo.96.2">However, we should be cautious with PyPi Stats because many automated processes (such as continuous integration) can inflate the PyPI download count, without indicating real-world use. </span><span class="koboSpan" id="kobo.96.3">In addition, the PyTorch download page advises installing the library</span><a id="_idIndexMarker1419"/><span class="koboSpan" id="kobo.97.1"> through Conda (</span><a href="https://conda.io/"><span class="koboSpan" id="kobo.98.1">https://conda.io/</span></a><span class="koboSpan" id="kobo.99.1">). </span><span class="koboSpan" id="kobo.99.2">The monthly statistics show 759,291 PyTorch downloads versus 154,504 for TF and 6,260 for JAX. </span><span class="koboSpan" id="kobo.99.3">Therefore, PyTorch leads here as well. </span><span class="koboSpan" id="kobo.99.4">Overall, my conclusion is that PyTorch is more popular than TF, but both libraries are used in </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">production environments.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.101.1">My advice, which you</span><a id="_idIndexMarker1420"/><span class="koboSpan" id="kobo.102.1"> can take with as many pinches of salt as you wish, would be to</span><a id="_idIndexMarker1421"/><span class="koboSpan" id="kobo.103.1"> select PyTorch if you</span><a id="_idIndexMarker1422"/><span class="koboSpan" id="kobo.104.1"> start a project now. </span><span class="koboSpan" id="kobo.104.2">This is why </span><a id="_idIndexMarker1423"/><span class="koboSpan" id="kobo.105.1">this book has put more emphasis on PyTorch compared to TF. </span><span class="koboSpan" id="kobo.105.2">One exception to this rule is if your project runs on mobile or</span><a id="_idIndexMarker1424"/><span class="koboSpan" id="kobo.106.1"> edge devices (</span><a href="https://en.wikipedia.org/wiki/Edge_device"><span class="koboSpan" id="kobo.107.1">https://en.wikipedia.org/wiki/Edge_device</span></a><span class="koboSpan" id="kobo.108.1">) with limited computational power. </span><span class="koboSpan" id="kobo.108.2">TF has better support for such devices through the TF Lite </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">library (</span></span><a href="https://www.tensorflow.org/lite"><span class="No-Break"><span class="koboSpan" id="kobo.110.1">https://www.tensorflow.org/lite</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.111.1">).</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.112.1">But ultimately, you can work </span><a id="_idIndexMarker1425"/><span class="koboSpan" id="kobo.113.1">with your preferred software stack and then convert your models into other libraries for deployment. </span><span class="koboSpan" id="kobo.113.2">We’ll see how</span><a id="_idIndexMarker1426"/><span class="koboSpan" id="kobo.114.1"> this is possible in the </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">next </span></span><span class="No-Break"><a id="_idIndexMarker1427"/></span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">section.</span></span></p>
<h2 id="_idParaDest-185" lang="en-GB"><a id="_idTextAnchor259"/><span class="koboSpan" id="kobo.117.1">Open Neural Network Exchange</span></h2>
<p lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.118.1">Open Neural Network Exchange</span></strong><span class="koboSpan" id="kobo.119.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.120.1">ONNX</span></strong><span class="koboSpan" id="kobo.121.1">, </span><a href="https://onnx.ai/"><span class="koboSpan" id="kobo.122.1">https://onnx.ai/</span></a><span class="koboSpan" id="kobo.123.1">) provides an open source format for</span><a id="_idIndexMarker1428"/><span class="koboSpan" id="kobo.124.1"> NN-based and traditional ML models (we’ll focus on NNs here). </span><span class="koboSpan" id="kobo.124.2">It defines an extensible computation</span><a id="_idIndexMarker1429"/><span class="koboSpan" id="kobo.125.1"> graph model, built-in operators, and standard data types. </span><span class="koboSpan" id="kobo.125.2">In other words, ONNX provides a universal NN representation format, which</span><a id="_idIndexMarker1430"/><span class="koboSpan" id="kobo.126.1"> allows us to convert models implemented with one library (for example, PyTorch) into others (such as TF), provided that both the source and target libraries support ONNX. </span><span class="koboSpan" id="kobo.126.2">In this way, you can train your model with one library and then convert it into another when deploying to production. </span><span class="koboSpan" id="kobo.126.3">This also makes sense because ONNX focuses on inference mode and not training (representing the training process using ONNX in </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">experimental mode).</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.128.1">ONNX represents an NN as a </span><a id="_idIndexMarker1431"/><span class="koboSpan" id="kobo.129.1">computational </span><strong class="bold"><span class="koboSpan" id="kobo.130.1">graph</span></strong><span class="koboSpan" id="kobo.131.1"> of operations (as we discussed in </span><a href="B19627_02.xhtml#_idTextAnchor047"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.132.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.133.1">), where the nodes are the</span><a id="_idIndexMarker1432"/><span class="koboSpan" id="kobo.134.1"> operations (or </span><strong class="bold"><span class="koboSpan" id="kobo.135.1">operators</span></strong><span class="koboSpan" id="kobo.136.1"> in ONNX terms) and the edges are the input/output connections (or ONNX </span><strong class="bold"><span class="koboSpan" id="kobo.137.1">variables</span></strong><span class="koboSpan" id="kobo.138.1">) between them. </span><span class="koboSpan" id="kobo.138.2">In</span><a id="_idIndexMarker1433"/><span class="koboSpan" id="kobo.139.1"> addition, it implements a Python runtime for evaluating ONNX models and Ops. </span><span class="koboSpan" id="kobo.139.2">Its purpose is to clarify the semantics of ONNX and to help understand and debug ONNX tools and converters, but it is not intended for production, and it is not optimized for performance. </span><span class="koboSpan" id="kobo.139.3">We’ll use it for its intended purpose and illustrate ONNX with a code example for a simple linear regression, defined as </span><span class="koboSpan" id="kobo.140.1"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;X&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;A&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;X&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;A&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/900.png" style="vertical-align:-0.257em;height:1.022em;width:10.582em"/></span><span class="koboSpan" id="kobo.141.1">. </span><span class="koboSpan" id="kobo.141.2">To do this, we’ll use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.142.1">onnx</span></strong><span class="koboSpan" id="kobo.143.1">  (</span><strong class="source-inline"><span class="koboSpan" id="kobo.144.1">!pip install onnx</span></strong><span class="koboSpan" id="kobo.145.1">) Python package. </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">Let’s start:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.147.1">Define the graph</span><a id="_idIndexMarker1434"/><span class="koboSpan" id="kobo.148.1"> representation’s input (</span><strong class="source-inline"><span class="koboSpan" id="kobo.149.1">X</span></strong><span class="koboSpan" id="kobo.150.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.151.1">A</span></strong><span class="koboSpan" id="kobo.152.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.153.1">B</span></strong><span class="koboSpan" id="kobo.154.1">) and output (</span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.155.1">Y</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">) variables:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.157.1">
import numpy as np
from onnx import TensorProto, numpy_helper
from onnx.helper import make_tensor_value_info
X = make_tensor_value_info(
    name='X',
    elem_type=TensorProto.FLOAT,
    shape=[None, None])
Y = make_tensor_value_info(
    'Y', TensorProto.FLOAT, [None])
A = numpy_helper.from_array(
    np.array([0.5, -0.6], dtype=np.float32),
    name='A')
B = numpy_helper.from_array(
    np.array([0.4], dtype=np.float32),
    name='B')</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.158.1">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.159.1">make_tensor_value_info</span></strong><span class="koboSpan" id="kobo.160.1"> declares a named graph I/O variables (</span><strong class="source-inline"><span class="koboSpan" id="kobo.161.1">X</span></strong><span class="koboSpan" id="kobo.162.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.163.1">Y</span></strong><span class="koboSpan" id="kobo.164.1">) with a type (</span><strong class="source-inline"><span class="koboSpan" id="kobo.165.1">elem_type</span></strong><span class="koboSpan" id="kobo.166.1">) and </span><strong class="source-inline"><span class="koboSpan" id="kobo.167.1">shape</span></strong><span class="koboSpan" id="kobo.168.1">. </span><strong class="source-inline"><span class="koboSpan" id="kobo.169.1">shape=[None]</span></strong><span class="koboSpan" id="kobo.170.1"> means any shape, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.171.1">shape=[None, None]</span></strong><span class="koboSpan" id="kobo.172.1"> means a two-dimensional tensor without specific dimension sizes. </span><span class="koboSpan" id="kobo.172.2">On</span><a id="_idIndexMarker1435"/><span class="koboSpan" id="kobo.173.1"> the other hand, </span><strong class="source-inline"><span class="koboSpan" id="kobo.174.1">A</span></strong><span class="koboSpan" id="kobo.175.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.176.1">B</span></strong><span class="koboSpan" id="kobo.177.1"> are the function parameters (weights), and we initialize them with pre-defined values from </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">NumPy arrays.</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.179.1">Define the </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">graph operations:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.181.1">
from onnx.helper import make_node
mat_mul = make_node(
    op_type='MatMul',
    inputs=['X', 'A'],
    outputs=['XA'])
addition = make_node('Add', ['XA', 'B'], ['Y'])</span></pre><p class="list-inset" lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.182.1">mat_mul</span></strong><span class="koboSpan" id="kobo.183.1"> represents matrix </span><a id="_idIndexMarker1436"/><span class="koboSpan" id="kobo.184.1">multiplication (</span><strong class="source-inline"><span class="koboSpan" id="kobo.185.1">MatMul</span></strong><span class="koboSpan" id="kobo.186.1">) between the </span><strong class="source-inline"><span class="koboSpan" id="kobo.187.1">X</span></strong><span class="koboSpan" id="kobo.188.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.189.1">A</span></strong><span class="koboSpan" id="kobo.190.1"> input matrices into the </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">XA</span></strong><span class="koboSpan" id="kobo.192.1"> output variable. </span><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">addition</span></strong><span class="koboSpan" id="kobo.194.1"> sums the output of </span><strong class="source-inline"><span class="koboSpan" id="kobo.195.1">mat_mul</span></strong><span class="koboSpan" id="kobo.196.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.197.1">XA</span></strong><span class="koboSpan" id="kobo.198.1">, with the </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">bias, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.200.1">B</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">.</span></span></p></li>
</ol>
<p class="callout-heading" lang="en-GB"><span class="koboSpan" id="kobo.202.1">ONNX operators</span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.203.1">This example introduces the </span><strong class="source-inline"><span class="koboSpan" id="kobo.204.1">MatMul</span></strong><span class="koboSpan" id="kobo.205.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.206.1">Add</span></strong><span class="koboSpan" id="kobo.207.1"> ONNX operators. </span><span class="koboSpan" id="kobo.207.2">The full list of supported</span><a id="_idIndexMarker1437"/><span class="koboSpan" id="kobo.208.1"> operators (available at </span><a href="https://onnx.ai/onnx/operators/"><span class="koboSpan" id="kobo.209.1">https://onnx.ai/onnx/operators/</span></a><span class="koboSpan" id="kobo.210.1">) includes many other NN building blocks, such as activation functions, convolutions, pooling, and tensor operators (for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.211.1">concat</span></strong><span class="koboSpan" id="kobo.212.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1">pad</span></strong><span class="koboSpan" id="kobo.214.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.215.1">reshape</span></strong><span class="koboSpan" id="kobo.216.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.217.1">flatten</span></strong><span class="koboSpan" id="kobo.218.1">). </span><span class="koboSpan" id="kobo.218.2">In addition, it supports the so-called </span><strong class="bold"><span class="koboSpan" id="kobo.219.1">control flow</span></strong><span class="koboSpan" id="kobo.220.1"> operators, which </span><a id="_idIndexMarker1438"/><span class="koboSpan" id="kobo.221.1">can create dynamic computational graphs. </span><span class="koboSpan" id="kobo.221.2">For example, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.222.1">if</span></strong><span class="koboSpan" id="kobo.223.1"> operator executes one subgraph or another, depending on a Boolean value. </span><span class="koboSpan" id="kobo.223.2">ONNX itself doesn’t implement the operators. </span><span class="koboSpan" id="kobo.223.3">Instead, the libraries that support it (such as PyTorch) have their own implementations. </span><span class="koboSpan" id="kobo.223.4">Conversely, the ONNX conversion will fail if your library model has operators that aren’t supported </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1">by ONNX.</span></span></p>
<ol>
<li lang="en-GB" value="3"><span class="koboSpan" id="kobo.225.1">We now have the</span><a id="_idIndexMarker1439"/><span class="koboSpan" id="kobo.226.1"> ingredients to define the </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">computational </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.228.1">graph</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.230.1">
from onnx.helper import make_graph
graph = make_graph(
    nodes=[mat_mul, addition],
    name='Linear regression',
    inputs=[X],
    outputs=[Y],
    initializer=[A, B])</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.231.1">We can see our computational graph in the </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">following figure:</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer1086">
<span class="koboSpan" id="kobo.233.1"><img alt="Figure 10.1 – Linear regression ONNX computational graph" src="image/B19627_10_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.234.1">Figure 10.1 – Linear regression ONNX computational graph</span></p>
<ol>
<li lang="en-GB" value="4"><span class="koboSpan" id="kobo.235.1">Use </span><strong class="source-inline"><span class="koboSpan" id="kobo.236.1">graph</span></strong><span class="koboSpan" id="kobo.237.1"> to</span><a id="_idIndexMarker1440"/><span class="koboSpan" id="kobo.238.1"> create an </span><strong class="source-inline"><span class="koboSpan" id="kobo.239.1">onnx_model</span></strong><span class="koboSpan" id="kobo.240.1"> instance. </span><span class="koboSpan" id="kobo.240.2">The model allows you to add additional metadata</span><a id="_idIndexMarker1441"/><span class="koboSpan" id="kobo.241.1"> to the graph, such as docstring, version, author, and license, </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">among others:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.243.1">
from onnx.helper import make_model
onnx_model = make_model(graph)
onnx_model.doc_string = 'Test model'
onnx_model.model_version = 1</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.244.1">Check the model for consistency. </span><span class="koboSpan" id="kobo.244.2">This verifies that the input type or shapes match between the </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">model components:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.246.1">
from onnx.checker import check_model
check_model(onnx_model)
print(onnx_model)</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.247.1">Finally, we can compute the output of the model for two random input samples with an instance </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.249.1">ReferenceEvaluator</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.251.1">
from onnx.reference import ReferenceEvaluator
sess = ReferenceEvaluator(onnx_model)
print(sess.run(
    output_names=None,
    feed_inputs={'X': np.random.randn(2, 2).astype(np.float32)}))</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.252.1">The result of the computation is a </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">NumPy array:</span></span></p><pre class="source-code" lang="en-GB">
<strong class="bold"><span class="koboSpan" id="kobo.254.1">[array([-0.7511951,  1.0294889], dtype=float32)]</span></strong></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.255.1">ONNX allows us to </span><a id="_idIndexMarker1442"/><span class="koboSpan" id="kobo.256.1">serialize and deserialize both the </span><a id="_idIndexMarker1443"/><span class="koboSpan" id="kobo.257.1">model structure and its weights with </span><strong class="bold"><span class="koboSpan" id="kobo.258.1">Protocol Buffers</span></strong><span class="koboSpan" id="kobo.259.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.260.1">protobuf</span></strong><span class="koboSpan" id="kobo.261.1">, </span><a href="https://protobuf.dev/"><span class="koboSpan" id="kobo.262.1">https://protobuf.dev/</span></a><span class="koboSpan" id="kobo.263.1">). </span><span class="koboSpan" id="kobo.263.2">Here’s how to </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">do this:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.265.1">
with open('model.onnx', 'wb') as f:
    f.write(onnx_model.SerializeToString())
from onnx import load
with open('model.onnx', 'rb') as f:
    onnx_model = load(f)</span></pre></li>
</ol>
<p lang="en-GB"><span class="koboSpan" id="kobo.266.1">Now that we have introduced ONNX, let’s see how we can use it in practice by exporting PyTorch and TF models </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">to ONNX.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.268.1">In addition to </span><strong class="source-inline"><span class="koboSpan" id="kobo.269.1">torch</span></strong><span class="koboSpan" id="kobo.270.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.271.1">tensorflow</span></strong><span class="koboSpan" id="kobo.272.1">, we’ll also need the </span><strong class="source-inline"><span class="koboSpan" id="kobo.273.1">torchvision</span></strong><span class="koboSpan" id="kobo.274.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.275.1">onnx</span></strong><span class="koboSpan" id="kobo.276.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">tf2onnx</span></strong><span class="koboSpan" id="kobo.278.1"> (</span><a href="https://github.com/onnx/tensorflow-onnx"><span class="koboSpan" id="kobo.279.1">https://github.com/onnx/tensorflow-onnx</span></a><span class="koboSpan" id="kobo.280.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.281.1">!pip install tf2onnx</span></strong><span class="koboSpan" id="kobo.282.1">) packages. </span><span class="koboSpan" id="kobo.282.2">Let’s start </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">with PyTorch:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.284.1">Load a pre-trained model (</span><strong class="source-inline"><span class="koboSpan" id="kobo.285.1">MobileNetV3</span></strong><span class="koboSpan" id="kobo.286.1">, refer to </span><a href="B19627_05.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.287.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.288.1">):</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.289.1">
import torch
from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights
torch_model = mobilenet_v3_small(
  weights=MobileNet_V3_Small_Weights.DEFAULT)</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.290.1">Then, export </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">the model:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.292.1">
torch.onnx.export(
    model=torch_model,
    args=torch.randn(1, 3, 224, 224),
    f="torch_model.onnx",
    export_params=True)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.293.1">Most parameters speak for themselves. </span><strong class="source-inline"><span class="koboSpan" id="kobo.294.1">args=torch.randn(1, 3, 224, 224)</span></strong><span class="koboSpan" id="kobo.295.1"> specifies a dummy tensor. </span><span class="koboSpan" id="kobo.295.2">This is necessary because the serializer might invoke the model once to infer the graph structure and tensor sizes. </span><span class="koboSpan" id="kobo.295.3">The dummy tensor will serve as input for this invocation. </span><span class="koboSpan" id="kobo.295.4">However, this exposes one of the limitations of the </span><a id="_idIndexMarker1444"/><span class="koboSpan" id="kobo.296.1">conversion process: if the model includes a dynamic computational graph, the converter will only convert the path of the current invocation. </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1">export_params</span></strong><span class="koboSpan" id="kobo.298.1"> tells the exporter to include the model weights, besides the </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">model structure.</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.300.1">Use ONNX to load the exported model and check it for consistency (spoiler: </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">it works):</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.302.1">
import onnx
torch_model_onnx = onnx.load('torch_model.onnx')
onnx.checker.check_model(torch_model_onnx)</span></pre></li>
</ol>
<p lang="en-GB"><span class="koboSpan" id="kobo.303.1">Next, let’s do the same but with TF. </span><span class="koboSpan" id="kobo.303.2">Unlike PyTorch, TF doesn’t have out-of-the-box ONNX serialization support. </span><span class="koboSpan" id="kobo.303.3">Instead, we’ll use the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.304.1">tf2onnx</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.305.1"> package:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.306.1">Load a pre-trained </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.307.1">MobileNetV3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.308.1"> model:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.309.1">
import tensorflow as tf
tf_model = tf.keras.applications.MobileNetV3Small(
  weights='imagenet',
  input_shape=(224, 224, 3),
)</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.310.1">Serialize the model using </span><strong class="source-inline"><span class="koboSpan" id="kobo.311.1">tf2onnx</span></strong><span class="koboSpan" id="kobo.312.1">. </span><span class="koboSpan" id="kobo.312.2">It follows the same principle as PyTorch, down to the dummy input tensor (</span><strong class="source-inline"><span class="koboSpan" id="kobo.313.1">input_signature</span></strong><span class="koboSpan" id="kobo.314.1">), which is necessary for </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">model invocation:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.316.1">
import tf2onnx
tf_model_onnx, _ = tf2onnx.convert.from_keras(
  model=tf_model,
  input_signature=[tf.TensorSpec([1, 224, 224, 3])])
onnx.save(tf_model_onnx, 'tf_model.onnx')</span></pre></li>
</ol>
<p lang="en-GB"><span class="koboSpan" id="kobo.317.1">Once again, we can load the model with ONNX to verify </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">its consistency.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.319.1">Next, we can </span><a id="_idIndexMarker1445"/><span class="koboSpan" id="kobo.320.1">use </span><strong class="bold"><span class="koboSpan" id="kobo.321.1">Netron</span></strong><span class="koboSpan" id="kobo.322.1"> (</span><a href="https://netron.app/"><span class="koboSpan" id="kobo.323.1">https://netron.app/</span></a><span class="koboSpan" id="kobo.324.1">, </span><a href="https://github.com/lutzroeder/netron"><span class="koboSpan" id="kobo.325.1">https://github.com/lutzroeder/netron</span></a><span class="koboSpan" id="kobo.326.1">) to visualize the NN graph by using the ONNX model file (</span><strong class="source-inline"><span class="koboSpan" id="kobo.327.1">torch_model.onnx</span></strong><span class="koboSpan" id="kobo.328.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1">tf_model.onnx</span></strong><span class="koboSpan" id="kobo.330.1">). </span><span class="koboSpan" id="kobo.330.2">This is a graphical </span><a id="_idIndexMarker1446"/><span class="koboSpan" id="kobo.331.1">viewer for NNs and other ML models. </span><span class="koboSpan" id="kobo.331.2">It exists as a web </span><strong class="bold"><span class="koboSpan" id="kobo.332.1">user interface</span></strong><span class="koboSpan" id="kobo.333.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.334.1">UI</span></strong><span class="koboSpan" id="kobo.335.1">) or a </span><a id="_idIndexMarker1447"/><span class="koboSpan" id="kobo.336.1">standalone app. </span><span class="koboSpan" id="kobo.336.2">It supports ONNX, TensorFlow Lite, and PyTorch (experimental), among other libraries. </span><span class="koboSpan" id="kobo.336.3">For example, the following figure shows the initial </span><strong class="bold"><span class="koboSpan" id="kobo.337.1">MobileNetV3</span></strong><span class="koboSpan" id="kobo.338.1"> layers in detail, as visualized by Netron (the full model visualization is too large to display within </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">this chapter):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer1087">
<span class="koboSpan" id="kobo.340.1"><img alt="Figure 10.2 – Netron visualization of the MobileNetV3 ONNX model file" src="image/B19627_10_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.341.1">Figure 10.2 – Netron visualization of the MobileNetV3 ONNX model file</span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.342.1">Here, the input shape is 3×224×224, </span><strong class="bold"><span class="koboSpan" id="kobo.343.1">W</span></strong><span class="koboSpan" id="kobo.344.1"> is the shape of the convolutional filter, and </span><strong class="bold"><span class="koboSpan" id="kobo.345.1">B</span></strong><span class="koboSpan" id="kobo.346.1"> is the bias. </span><span class="koboSpan" id="kobo.346.2">We introduced the rest of the convolution attributes in </span><a href="B19627_04.xhtml#_idTextAnchor107"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.347.1">Chapter 4</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.348.1">.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.349.1">Unfortunately, neither PyTorch nor TF comes with the integrated ability to load ONNX models. </span><span class="koboSpan" id="kobo.349.2">However, there are open source packages that allow us to do this. </span><span class="koboSpan" id="kobo.349.3">Two of them are </span><strong class="source-inline"><span class="koboSpan" id="kobo.350.1">onnx2torch</span></strong><span class="koboSpan" id="kobo.351.1"> (</span><a href="https://github.com/ENOT-AutoDL/onnx2torch"><span class="koboSpan" id="kobo.352.1">https://github.com/ENOT-AutoDL/onnx2torch</span></a><span class="koboSpan" id="kobo.353.1">) for PyTorch and </span><strong class="source-inline"><span class="koboSpan" id="kobo.354.1">onnx2tf</span></strong><span class="koboSpan" id="kobo.355.1"> (</span><a href="https://github.com/PINTO0309/onnx2tf"><span class="koboSpan" id="kobo.356.1">https://github.com/PINTO0309/onnx2tf</span></a><span class="koboSpan" id="kobo.357.1">) </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">for TF.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.359.1">Next, we’ll focus on a tool that will ease the </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">training process.</span></span></p>
<h2 id="_idParaDest-186" lang="en-GB"><a id="_idTextAnchor260"/><span class="koboSpan" id="kobo.361.1">Introducing TensorBoard</span></h2>
<p lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.362.1">TensorBoard</span></strong><span class="koboSpan" id="kobo.363.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.364.1">TB</span></strong><span class="koboSpan" id="kobo.365.1">, </span><a href="https://www.tensorflow.org/tensorboard/"><span class="koboSpan" id="kobo.366.1">https://www.tensorflow.org/tensorboard/</span></a><span class="koboSpan" id="kobo.367.1">, </span><a href="https://github.com/tensorflow/tensorboard"><span class="koboSpan" id="kobo.368.1">https://github.com/tensorflow/tensorboard</span></a><span class="koboSpan" id="kobo.369.1">) is a TF-complement web-based tool that provides visualization and tooling for machine learning</span><a id="_idIndexMarker1448"/><span class="koboSpan" id="kobo.370.1"> experiments. </span><span class="koboSpan" id="kobo.370.2">Some of its functions are </span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">as</span></span><span class="No-Break"><a id="_idIndexMarker1449"/></span><span class="No-Break"><span class="koboSpan" id="kobo.372.1"> follows:</span></span></p>
<ul>
<li lang="en-GB"><span class="koboSpan" id="kobo.373.1">Metrics (such as loss and accuracy) tracking </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">and visualization</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.375.1">Model graph visualization (similar </span><span class="No-Break"><span class="koboSpan" id="kobo.376.1">to Netron)</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.377.1">A time series histogram of the change of weights, biases, or other tensors </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">over time</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.379.1">Low-dimensional </span><span class="No-Break"><span class="koboSpan" id="kobo.380.1">embedding projections</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.381.1">TB can work with both TF/Keras and PyTorch, but it has better integration with TF (after all, it is developed by the TF team). </span><span class="koboSpan" id="kobo.381.2">In both cases, TB doesn’t communicate directly with the models during training. </span><span class="koboSpan" id="kobo.381.3">Instead, the training process stores its state and current progress in a special log file. </span><span class="koboSpan" id="kobo.381.4">TB tracks the file for changes and automatically updates its graphical interface with the latest information. </span><span class="koboSpan" id="kobo.381.5">In this way, it can visualize the training as it progresses. </span><span class="koboSpan" id="kobo.381.6">In addition, the file stores the entire training history to be displayed even after it finishes. </span><span class="koboSpan" id="kobo.381.7">To better understand how it works, we’ll add TB to the transfer learning computer vision examples that we introduced in </span><a href="B19627_05.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.382.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.383.1">. </span><span class="koboSpan" id="kobo.383.2">As a quick recap, we’ll start with ImageNet pre-trained MobileNetV3 models. </span><span class="koboSpan" id="kobo.383.3">Then, we’ll </span><a id="_idIndexMarker1450"/><span class="koboSpan" id="kobo.384.1">use two transfer</span><a id="_idIndexMarker1451"/><span class="koboSpan" id="kobo.385.1"> learning techniques, </span><strong class="bold"><span class="koboSpan" id="kobo.386.1">feature engineering</span></strong><span class="koboSpan" id="kobo.387.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.388.1">fine-tuning</span></strong><span class="koboSpan" id="kobo.389.1">, to train these models to classify the CIFAR-10 dataset. </span><span class="koboSpan" id="kobo.389.2">TB will visualize </span><span class="No-Break"><span class="koboSpan" id="kobo.390.1">the training.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.391.1">Let’s start with the Keras example. </span><span class="koboSpan" id="kobo.391.2">We’ll only include the relevant part of the code, and not the full example, as we discussed it in </span><a href="B19627_05.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.392.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.393.1">. </span><span class="koboSpan" id="kobo.393.2">More specifically, we’ll focus on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">train_model(model, epochs=5)</span></strong><span class="koboSpan" id="kobo.395.1"> function, which takes the pre-trained </span><strong class="source-inline"><span class="koboSpan" id="kobo.396.1">model</span></strong><span class="koboSpan" id="kobo.397.1"> and the number of training </span><strong class="source-inline"><span class="koboSpan" id="kobo.398.1">epochs</span></strong><span class="koboSpan" id="kobo.399.1"> as parameters. </span><span class="koboSpan" id="kobo.399.2">The following is the function’s body (please note t</span><a id="_idTextAnchor261"/><span class="koboSpan" id="kobo.400.1">hat the actual implementation </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">has indentation):</span></span></p>
<p class="callout-heading" lang="en-GB"><span class="koboSpan" id="kobo.402.1">Initializing TensorBoard</span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.403.1">This example </span><a id="_idIndexMarker1452"/><span class="koboSpan" id="kobo.404.1">assumes that TB is initialized and running (although the code works even if it is not available). </span><span class="koboSpan" id="kobo.404.2">We won’t include the initialization of TB because it differs depending on the environment. </span><span class="koboSpan" id="kobo.404.3">However, it is included in the Jupyter Notebook of </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">this example.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.406.1">Follow </span><span class="No-Break"><span class="koboSpan" id="kobo.407.1">these steps:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.408.1">First, we’ll configure the training of the pre-trained Keras model with the Adam optimizer, binary </span><a id="_idIndexMarker1453"/><span class="koboSpan" id="kobo.409.1">cross-entropy loss, and </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1">accuracy tracking:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.411.1">
model.compile(
    optimizer=tf.keras.optimizers.Adam(
        learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy'])</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.412.1">Next, we’ll add the special </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">tensorboard_callback</span></strong><span class="koboSpan" id="kobo.414.1">, which implements the </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">TB connection:</span></span><pre class="source-code" lang="en-GB">
<strong class="bold"><span class="koboSpan" id="kobo.416.1">tensorboard_callback</span></strong><span class="koboSpan" id="kobo.417.1"> = tf.keras.callbacks.TensorBoard(
    </span><strong class="bold"><span class="koboSpan" id="kobo.418.1">log_dir</span></strong><span class="koboSpan" id="kobo.419.1">='logs/tb/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S'),
    </span><strong class="bold"><span class="koboSpan" id="kobo.420.1">update_freq</span></strong><span class="koboSpan" id="kobo.421.1">='epoch',
    histogram_freq=1,
    write_graph=True,
    write_images=True,
    write_steps_per_second=True,
    profile_batch=0,
    embeddings_freq=0)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.422.1">The callback parameters are </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">as follows:</span></span></p><ul><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.424.1">log_dir</span></strong><span class="koboSpan" id="kobo.425.1">: This instructs </span><strong class="source-inline"><span class="koboSpan" id="kobo.426.1">tensorboard_callback</span></strong><span class="koboSpan" id="kobo.427.1"> to write the log file in a unique time-stamped folder, </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">'logs/tb/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')</span></strong><span class="koboSpan" id="kobo.429.1">, located in the main </span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">'logs/tb/'</span></strong><span class="koboSpan" id="kobo.431.1"> folder. </span><span class="koboSpan" id="kobo.431.2">TB will simultaneously pick all training folders under </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1">'logs/tb/'</span></strong><span class="koboSpan" id="kobo.433.1"> and display them in its UI as unique </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">training instances.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.435.1">update_freq=1</span></strong><span class="koboSpan" id="kobo.436.1">: Updates the log file once </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">per epoch.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.438.1">histogram_freq=1</span></strong><span class="koboSpan" id="kobo.439.1">: Computes weight histograms once </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">per epoch.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.441.1">write_graph=True</span></strong><span class="koboSpan" id="kobo.442.1">: Generates a graph visualization of the </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">NN architecture.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.444.1">write_images=True</span></strong><span class="koboSpan" id="kobo.445.1">: Visualizes the model weights as </span><span class="No-Break"><span class="koboSpan" id="kobo.446.1">an image.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.447.1">write_steps_per_second=True</span></strong><span class="koboSpan" id="kobo.448.1">: Logs the training steps </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">per second.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.450.1">profile_batch=1</span></strong><span class="koboSpan" id="kobo.451.1">: Profiles</span><a id="_idIndexMarker1454"/><span class="koboSpan" id="kobo.452.1"> the first batch to sample its </span><span class="No-Break"><span class="koboSpan" id="kobo.453.1">compute characteristics.</span></span></li><li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.454.1">Embeddings_freq=0</span></strong><span class="koboSpan" id="kobo.455.1">: The frequency (in epochs) at which embedding layers will be visualized (we don’t have embedding layers, so it’s disabled </span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">by default).</span></span></li></ul></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.457.1">Finally, we’ll run the training with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.458.1">model.fit</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.459.1"> method:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.460.1">
steps_per_epoch=metadata.splits['train'].num_examples // BATCH_SIZE
validation_steps=metadata.splits['test'].num_examples // BATCH_SIZE
model.fit(
    train_batches,
    epochs=epochs,
    validation_data=test_batches,
    </span><strong class="bold"><span class="koboSpan" id="kobo.461.1">callbacks=[tensorboard_callback]</span></strong><span class="koboSpan" id="kobo.462.1">,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.463.1">We add </span><strong class="source-inline"><span class="koboSpan" id="kobo.464.1">tensorboard_callback</span></strong><span class="koboSpan" id="kobo.465.1"> to the list of </span><strong class="source-inline"><span class="koboSpan" id="kobo.466.1">model</span></strong> <strong class="source-inline"><span class="koboSpan" id="kobo.467.1">callbacks</span></strong><span class="koboSpan" id="kobo.468.1">. </span><span class="koboSpan" id="kobo.468.2">The training process notifies each callback for various training events: start of training, end of training, start of testing, end of testing, start of epoch, end of epoch, start of batch, and end of batch. </span><span class="koboSpan" id="kobo.468.3">In turn, </span><strong class="source-inline"><span class="koboSpan" id="kobo.469.1">tensorboard_callback</span></strong><span class="koboSpan" id="kobo.470.1"> updates the log file according to its configuration and the </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">current event.</span></span></p><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.472.1">The TB UI displays all</span><a id="_idIndexMarker1455"/><span class="koboSpan" id="kobo.473.1"> the information in the log file. </span><span class="koboSpan" id="kobo.473.2">Although it’s too complex to include here, we can still show a snippet </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">with accuracy:</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer1088">
<span class="koboSpan" id="kobo.475.1"><img alt="Figure 10.3 – Accuracy in the TB UI" src="image/B19627_10_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.476.1">Figure 10.3 – Accuracy in the TB UI</span></p>
<p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.477.1">Here, TB displays the accuracy for four different experiments – train/test for feature engineering and train/test </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">for fine-tuning.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.479.1">Next, let’s see how PyTorch integrates with TB. </span><span class="koboSpan" id="kobo.479.2">It provides a special </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">torch.utils.tensorboard.SummaryWriter</span></strong><span class="koboSpan" id="kobo.481.1"> class, which writes entries directly to event log files in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">log_dir</span></strong><span class="koboSpan" id="kobo.483.1"> folder to be consumed by TB. </span><span class="koboSpan" id="kobo.483.2">It follows the same principle as in Keras. </span><span class="koboSpan" id="kobo.483.3">The high-level API of </span><strong class="source-inline"><span class="koboSpan" id="kobo.484.1">SummaryWriter</span></strong><span class="koboSpan" id="kobo.485.1"> allows us to create an event file in </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1">log_dir</span></strong><span class="koboSpan" id="kobo.487.1"> and asynchronously add content to it. </span><span class="koboSpan" id="kobo.487.2">The main difference with Keras is that we’re responsible for adding the content, instead of an automated event listener doing it. </span><span class="koboSpan" id="kobo.487.3">Let’s see how that works in practice. </span><span class="koboSpan" id="kobo.487.4">As with Keras, we’ll use the computer vision transfer learning example from </span><a href="B19627_05.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.488.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.489.1">. </span><span class="koboSpan" id="kobo.489.2">We’ll only focus on the relevant parts, but you can see the full example in the Jupyter Notebook in this book’s </span><span class="No-Break"><span class="koboSpan" id="kobo.490.1">GitHub repository.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.491.1">First, we’ll initialize two </span><strong class="source-inline"><span class="koboSpan" id="kobo.492.1">SummaryWriter</span></strong><span class="koboSpan" id="kobo.493.1"> instances for the feature extractor fine-tuning modes. </span><span class="koboSpan" id="kobo.493.2">It doesn’t matter where we do it, so long as it happens before we start using them. </span><span class="koboSpan" id="kobo.493.3">As with Keras, each</span><a id="_idIndexMarker1456"/><span class="koboSpan" id="kobo.494.1"> training instance has a unique time-stamped folder under </span><strong class="source-inline"><span class="koboSpan" id="kobo.495.1">'logs/tb/'</span></strong><span class="koboSpan" id="kobo.496.1"> (we’re only showing one initialization because they </span><span class="No-Break"><span class="koboSpan" id="kobo.497.1">are identical):</span></span></p>
<pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.498.1">
import datetime
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter(
</span><strong class="bold"><span class="koboSpan" id="kobo.499.1">log_dir='logs/tb/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')</span></strong><span class="koboSpan" id="kobo.500.1">)</span></pre>
<p lang="en-GB"><span class="koboSpan" id="kobo.501.1">For the sake of clarity, we’ll include the initialization of the MobileNetV3 </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">pre-trained model:</span></span></p>
<pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.503.1">
from torchvision.models import (
    MobileNet_V3_Small_Weights, mobilenet_v3_small)
model = mobilenet_v3_small(
    weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)</span></pre>
<p lang="en-GB"><span class="koboSpan" id="kobo.504.1">Next, we’ll jump to the training (or testing) loop, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.505.1">train_loader</span></strong><span class="koboSpan" id="kobo.506.1">, an instance of </span><strong class="source-inline"><span class="koboSpan" id="kobo.507.1">torch.utils.data.DataLoader</span></strong><span class="koboSpan" id="kobo.508.1">, yields pairs of </span><strong class="source-inline"><span class="koboSpan" id="kobo.509.1">inputs</span></strong><span class="koboSpan" id="kobo.510.1"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.511.1">labels</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.512.1"> mini-batches:</span></span></p>
<pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.513.1">
for i, (inputs, labels) in enumerate(data_loader):
    # Training loop goes here</span></pre>
<p lang="en-GB"><span class="koboSpan" id="kobo.514.1">Within the loop, we can add the model graph to the log file. </span><span class="koboSpan" id="kobo.514.2">It takes the model and the input tensor as parameters to generate the visualization (hence the need to call </span><strong class="source-inline"><span class="koboSpan" id="kobo.515.1">add_graph</span></strong><span class="koboSpan" id="kobo.516.1"> in the </span><span class="No-Break"><span class="koboSpan" id="kobo.517.1">training loop):</span></span></p>
<pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.518.1">
writer.add_graph(model, inputs)</span></pre>
<p lang="en-GB"><span class="koboSpan" id="kobo.519.1">Finally, at the end of the training loop, we’ll add the loss and the accuracy for the current </span><strong class="source-inline"><span class="koboSpan" id="kobo.520.1">epoch</span></strong><span class="koboSpan" id="kobo.521.1"> as </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">scalar values:</span></span></p>
<pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.523.1">
writer.add_scalar(
    tag='train/accuracy',
    scalar_value=total_acc,
    global_step=epoch)
writer.add_scalar(
    tag='train/loss',
    scalar_value=total_loss,
    global_step=epoch)</span></pre>
<p lang="en-GB"><span class="koboSpan" id="kobo.524.1">Each scalar value has a unique </span><strong class="source-inline"><span class="koboSpan" id="kobo.525.1">tag</span></strong><span class="koboSpan" id="kobo.526.1"> (besides the two tags in the code, we also have </span><strong class="source-inline"><span class="koboSpan" id="kobo.527.1">tag='validation/loss'</span></strong><span class="koboSpan" id="kobo.528.1">). </span><span class="koboSpan" id="kobo.528.2">Note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.529.1">global_step</span></strong><span class="koboSpan" id="kobo.530.1"> (equal to the epoch) stores </span><strong class="source-inline"><span class="koboSpan" id="kobo.531.1">scalar_value</span></strong><span class="koboSpan" id="kobo.532.1"> as a sequence </span><a id="_idIndexMarker1457"/><span class="koboSpan" id="kobo.533.1">within the same </span><strong class="source-inline"><span class="koboSpan" id="kobo.534.1">tag</span></strong><span class="koboSpan" id="kobo.535.1">. </span><span class="koboSpan" id="kobo.535.2">In addition to graphs and scalars, </span><strong class="source-inline"><span class="koboSpan" id="kobo.536.1">SummaryWriter</span></strong><span class="koboSpan" id="kobo.537.1"> can add images, tensors, histograms, and embeddings, </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1">among others.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.539.1">This concludes our introduction to TB. </span><span class="koboSpan" id="kobo.539.2">Next, we’ll learn how to develop NN models for </span><span class="No-Break"><span class="koboSpan" id="kobo.540.1">edge devices.</span></span></p>
<h2 id="_idParaDest-187" lang="en-GB"><a id="_idTextAnchor262"/><span class="koboSpan" id="kobo.541.1">Developing NN models for edge devices with TF Lite</span></h2>
<p lang="en-GB"><span class="koboSpan" id="kobo.542.1">TF Lite is a TF-derived set </span><a id="_idIndexMarker1458"/><span class="koboSpan" id="kobo.543.1">of tools that allows us to run models</span><a id="_idIndexMarker1459"/><span class="koboSpan" id="kobo.544.1"> on mobile, embedded, and edge devices. </span><span class="koboSpan" id="kobo.544.2">Its versatility is part of TF’s appeal for industrial applications (as opposed to research applications, where </span><a id="_idIndexMarker1460"/><span class="koboSpan" id="kobo.545.1">PyTorch dominates). </span><span class="koboSpan" id="kobo.545.2">The key paradigm of TF Lite is that the models run on-device, contrary to client-server architecture, where the model is deployed on remote, more powerful, hardware. </span><span class="koboSpan" id="kobo.545.3">This organization has the following implications (both good </span><span class="No-Break"><span class="koboSpan" id="kobo.546.1">and bad):</span></span></p>
<ul>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.547.1">Low-latency execution</span></strong><span class="koboSpan" id="kobo.548.1">: The lack of server-round trip significantly reduces the model inference time and allows us to run </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">real-time applications.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.550.1">Privacy</span></strong><span class="koboSpan" id="kobo.551.1">: The user data never leaves </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">the device.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.553.1">Internet connectivity</span></strong><span class="koboSpan" id="kobo.554.1">: Internet connectivity is </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">not required.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.556.1">Small model size</span></strong><span class="koboSpan" id="kobo.557.1">: The devices have limited computational ability, hence the need for small and computationally efficient models. </span><span class="koboSpan" id="kobo.557.2">More specifically, TF Lite models are stored in the FlatBuffers (</span><a href="https://flatbuffers.dev/"><span class="koboSpan" id="kobo.558.1">https://flatbuffers.dev/</span></a><span class="koboSpan" id="kobo.559.1">) special efficient portable format, identified by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.560.1">.tflite</span></strong><span class="koboSpan" id="kobo.561.1"> file extension. </span><span class="koboSpan" id="kobo.561.2">Besides its small size, it allows us to access data directly without parsing/unpacking </span><span class="No-Break"><span class="koboSpan" id="kobo.562.1">it first.</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.563.1">TF Lite models support a subset </span><a id="_idIndexMarker1461"/><span class="koboSpan" id="kobo.564.1">of the TF Core operations and allow us to define </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">custom ones:</span></span></p>
<ul>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.566.1">Low power consumption</span></strong><span class="koboSpan" id="kobo.567.1">: The devices often run </span><span class="No-Break"><span class="koboSpan" id="kobo.568.1">on battery.</span></span></li>
<li lang="en-GB"><strong class="bold"><span class="koboSpan" id="kobo.569.1">Divergent training and inference</span></strong><span class="koboSpan" id="kobo.570.1">: NN training is a lot more computationally intensive compared to</span><a id="_idIndexMarker1462"/><span class="koboSpan" id="kobo.571.1"> inference. </span><span class="koboSpan" id="kobo.571.2">Because of this, the model training runs on a different, more powerful, piece of hardware than the actual devices, where the models will </span><span class="No-Break"><span class="koboSpan" id="kobo.572.1">run inference.</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.573.1">In addition, TF Lite has the following </span><span class="No-Break"><span class="koboSpan" id="kobo.574.1">key features:</span></span></p>
<ul>
<li lang="en-GB"><span class="koboSpan" id="kobo.575.1">Multi-platform and multi-language support, including Android (Java), iOS (Objective-C and Swift) devices, web (JavaScript), and Python for all other environments. </span><span class="koboSpan" id="kobo.575.2">Google provides a TF Lite </span><a id="_idIndexMarker1463"/><span class="koboSpan" id="kobo.576.1">wrapper API called </span><strong class="bold"><span class="koboSpan" id="kobo.577.1">MediaPipe Solutions</span></strong><span class="koboSpan" id="kobo.578.1"> (</span><a href="https://developers.google.com/mediapipe"><span class="koboSpan" id="kobo.579.1">https://developers.google.com/mediapipe</span></a><span class="koboSpan" id="kobo.580.1">, </span><a href="https://github.com/google/mediapipe/"><span class="koboSpan" id="kobo.581.1">https://github.com/google/mediapipe/</span></a><span class="koboSpan" id="kobo.582.1">), which supersedes the previous TF </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">Lite API.</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.584.1">Optimized </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">for performance.</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.586.1">It has end-to-end </span><a id="_idIndexMarker1464"/><span class="koboSpan" id="kobo.587.1">solution pipelines. </span><span class="koboSpan" id="kobo.587.2">TF Lite is oriented toward practical applications, rather than research. </span><span class="koboSpan" id="kobo.587.3">Because of this, it includes different pipelines for common ML tasks such as image classification, object detection, text classification, and question answering among others. </span><span class="koboSpan" id="kobo.587.4">The computer vision pipelines use modified versions of EfficientNet or MobileNet (</span><a href="B19627_04.xhtml#_idTextAnchor107"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.588.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.589.1">), and the natural language processing pipelines use BERT-based (</span><a href="B19627_07.xhtml#_idTextAnchor202"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.590.1">Chapter </span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.591.1">7</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.592.1">) models.</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.593.1">So, how does TF Lite model development work? </span><span class="koboSpan" id="kobo.593.2">First, we’ll select a model in one of the </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">following ways:</span></span></p>
<ul>
<li lang="en-GB"><span class="koboSpan" id="kobo.595.1">An existing pre-trained </span><strong class="source-inline"><span class="koboSpan" id="kobo.596.1">.tflite</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.597.1">model (</span></span><a href="https://tfhub.dev/s?deployment-format=lite"><span class="No-Break"><span class="koboSpan" id="kobo.598.1">https://tfhub.dev/s?deployment-format=lite</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.599.1">).</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.600.1">Use </span><strong class="bold"><span class="koboSpan" id="kobo.601.1">MediaPipe Model Maker</span></strong><span class="koboSpan" id="kobo.602.1"> (</span><a href="https://developers.google.com/mediapipe/solutions/model_maker"><span class="koboSpan" id="kobo.603.1">https://developers.google.com/mediapipe/solutions/model_maker</span></a><span class="koboSpan" id="kobo.604.1">) to apply feature engineering transfer learning on an existing </span><strong class="source-inline"><span class="koboSpan" id="kobo.605.1">.tflite</span></strong><span class="koboSpan" id="kobo.606.1"> model with a custom training dataset. </span><span class="koboSpan" id="kobo.606.2">Model Maker only works </span><span class="No-Break"><span class="koboSpan" id="kobo.607.1">with </span></span><span class="No-Break"><a id="_idIndexMarker1465"/></span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">Python.</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.609.1">Convert a</span><a id="_idIndexMarker1466"/><span class="koboSpan" id="kobo.610.1"> full-fledged TF model into </span><strong class="source-inline"><span class="koboSpan" id="kobo.611.1">.</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">tflite</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.613.1"> format.</span></span></li>
</ul>
<p class="callout-heading" lang="en-GB"><span class="koboSpan" id="kobo.614.1">TFLite model metadata</span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.615.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.616.1">.tflite</span></strong><span class="koboSpan" id="kobo.617.1"> models may include optional </span><a id="_idIndexMarker1467"/><span class="koboSpan" id="kobo.618.1">metadata with </span><span class="No-Break"><span class="koboSpan" id="kobo.619.1">three components:</span></span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.620.1">-- </span><strong class="bold"><span class="koboSpan" id="kobo.621.1">Human-readable part</span></strong><span class="koboSpan" id="kobo.622.1">: Provides additional information for </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">the model.</span></span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.624.1">-- </span><strong class="bold"><span class="koboSpan" id="kobo.625.1">Input information</span></strong><span class="koboSpan" id="kobo.626.1">: Describes the input data format and the necessary </span><span class="No-Break"><span class="koboSpan" id="kobo.627.1">pre-processing steps</span></span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.628.1">-- </span><strong class="bold"><span class="koboSpan" id="kobo.629.1">Output information</span></strong><span class="koboSpan" id="kobo.630.1">: Describes the output data format and the necessary </span><span class="No-Break"><span class="koboSpan" id="kobo.631.1">post-processing steps.</span></span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.632.1">The last two parts can be leveraged by code generators (for example, Android code generator) to create ready-to-use model wrappers in the </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1">target platform.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.634.1">Next, let’s see how to use </span><a id="_idIndexMarker1468"/><span class="koboSpan" id="kobo.635.1">Model Maker to train a </span><strong class="source-inline"><span class="koboSpan" id="kobo.636.1">.tflite</span></strong><span class="koboSpan" id="kobo.637.1"> model and then use it to classify images. </span><span class="koboSpan" id="kobo.637.2">We’re only going to show relevant parts of the code, but the full example is available as a Jupyter Notebook in this book’s GitHub repository. </span><span class="No-Break"><span class="koboSpan" id="kobo.638.1">Let’s start:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.639.1">First, we’ll create training and </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">validation datasets:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.641.1">
from mediapipe_model_maker import image_classifier
dataset = image_classifier.Dataset.from_folder(</span><strong class="bold"><span class="koboSpan" id="kobo.642.1">dataset_path</span></strong><span class="koboSpan" id="kobo.643.1">)
train_data, validation_data = dataset.split(0.9)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.644.1">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1">dataset_path</span></strong><span class="koboSpan" id="kobo.646.1"> is a path to the Flowers dataset (</span><a href="https://www.tensorflow.org/datasets/catalog/tf_flowers"><span class="koboSpan" id="kobo.647.1">https://www.tensorflow.org/datasets/catalog/tf_flowers</span></a><span class="koboSpan" id="kobo.648.1">), which contains 3,670 RGB low-resolution images of flowers, distributed in five classes (one subfolder per class). </span><strong class="source-inline"><span class="koboSpan" id="kobo.649.1">data.split(0.9)</span></strong><span class="koboSpan" id="kobo.650.1"> splits the dataset (instances of </span><strong class="source-inline"><span class="koboSpan" id="kobo.651.1">image_classifier.Dataset</span></strong><span class="koboSpan" id="kobo.652.1">) into </span><strong class="source-inline"><span class="koboSpan" id="kobo.653.1">train_data</span></strong><span class="koboSpan" id="kobo.654.1"> (90% of the images) and </span><strong class="source-inline"><span class="koboSpan" id="kobo.655.1">validation_data</span></strong><span class="koboSpan" id="kobo.656.1"> (10% of the </span><span class="No-Break"><span class="koboSpan" id="kobo.657.1">images) parts.</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.658.1">Next, we’ll define</span><a id="_idIndexMarker1469"/><span class="koboSpan" id="kobo.659.1"> the training hyperparameters – train for three epochs with a mini-batch size </span><a id="_idIndexMarker1470"/><span class="koboSpan" id="kobo.660.1">of 16 and export the trained model in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.661.1">export_dir</span></strong><span class="koboSpan" id="kobo.662.1"> folder (other parameters are available </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">as well):</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.664.1">
hparams = image_classifier.HParams(
    export_dir='tflite_model',
    epochs=3,
    batch_size=16)</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.665.1">Then, we’ll define the model parameters (we’ll </span><span class="No-Break"><span class="koboSpan" id="kobo.666.1">use </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.667.1">EfficientNet</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.668.1">):</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.669.1">
options = image_classifier.ImageClassifierOptions(    supported_model=image_classifier.SupportedModels.EFFICIENTNET_LITE4,
    hparams=hparams)</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.670.1">Finally, we’ll create a </span><a id="_idIndexMarker1471"/><span class="koboSpan" id="kobo.671.1">new model and we’ll run </span><span class="No-Break"><span class="koboSpan" id="kobo.672.1">the training:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.673.1">
model = image_classifier.ImageClassifier.create(
    train_data=train_data,
    validation_data=validation_data,
    options=options,
)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.674.1">This model achieves around 92% accuracy in three epochs. </span><span class="koboSpan" id="kobo.674.2">The training process creates a TB-compatible log file, so</span><a id="_idIndexMarker1472"/><span class="koboSpan" id="kobo.675.1"> we’ll be able to track the progress with TB (available in the </span><span class="No-Break"><span class="koboSpan" id="kobo.676.1">Jupyter Notebook).</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.677.1">Next, we’ll export the model in </span><strong class="source-inline"><span class="koboSpan" id="kobo.678.1">.tflite</span></strong><span class="koboSpan" id="kobo.679.1"> format for the next phase of </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">our example:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.681.1">
model.export_model('model.tflite')</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.682.1">Now that we have a trained </span><a id="_idIndexMarker1473"/><span class="koboSpan" id="kobo.683.1">model, we can use it to classify images. </span><span class="koboSpan" id="kobo.683.2">We’re going to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.684.1">MediaPipe</span></strong><span class="koboSpan" id="kobo.685.1"> Python API (which is different than </span><span class="No-Break"><span class="koboSpan" id="kobo.686.1">Model Maker):</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.687.1">
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
generic_options = python.BaseOptions(
    model_asset_path='/content/tflite_model/model.tflite')
cls_options = vision.ImageClassifierOptions(
    base_options=generic_options)
classifier = vision.ImageClassifier.create_from_options(cls_options)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.688.1">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.689.1">classifier</span></strong><span class="koboSpan" id="kobo.690.1"> is the pre-trained model, </span><strong class="source-inline"><span class="koboSpan" id="kobo.691.1">generic_options</span></strong><span class="koboSpan" id="kobo.692.1"> contains the file path to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.693.1">.tflite</span></strong><span class="koboSpan" id="kobo.694.1"> model, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.695.1">cls_options</span></strong><span class="koboSpan" id="kobo.696.1"> contains classification-specific options (we </span><a id="_idIndexMarker1474"/><span class="koboSpan" id="kobo.697.1">use the </span><span class="No-Break"><span class="koboSpan" id="kobo.698.1">default values).</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.699.1">We’ll load five random flower images (one for each flower class, listed in </span><strong class="source-inline"><span class="koboSpan" id="kobo.700.1">labels</span></strong><span class="koboSpan" id="kobo.701.1">) in a list called </span><strong class="source-inline"><span class="koboSpan" id="kobo.702.1">image_paths</span></strong><span class="koboSpan" id="kobo.703.1"> (not displayed here). </span><span class="koboSpan" id="kobo.703.2">We’ll classify each image, and we’ll </span><a id="_idIndexMarker1475"/><span class="koboSpan" id="kobo.704.1">compare its predicted</span><a id="_idIndexMarker1476"/><span class="koboSpan" id="kobo.705.1"> label to the </span><span class="No-Break"><span class="koboSpan" id="kobo.706.1">real one:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.707.1">
for image_path, label in zip(image_paths, labels):
  image = mp.Image.create_from_file(image_path)
  result = </span><strong class="bold"><span class="koboSpan" id="kobo.708.1">classifier.classify(image)</span></strong><span class="koboSpan" id="kobo.709.1">
  top_1 = result.classifications[0].categories[0]
  print(f'Label: {label}; Prediction: {top_1.category_name}')</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.710.1">Predictably, the model classifies all </span><span class="No-Break"><span class="koboSpan" id="kobo.711.1">images correctly.</span></span></p></li>
</ol>
<p lang="en-GB"><span class="koboSpan" id="kobo.712.1">Next, we’ll learn how to optimize the training with </span><span class="No-Break"><span class="koboSpan" id="kobo.713.1">mixed-precision computations.</span></span></p>
<h2 id="_idParaDest-188" lang="en-GB"><a id="_idTextAnchor263"/><span class="koboSpan" id="kobo.714.1">Mixed-precision training with PyTorch</span></h2>
<p lang="en-GB"><span class="koboSpan" id="kobo.715.1">We discussed mixed-precision </span><a id="_idIndexMarker1477"/><span class="koboSpan" id="kobo.716.1">training in the context of LLMs in </span><a href="B19627_08.xhtml#_idTextAnchor220"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.717.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.718.1">. </span><span class="koboSpan" id="kobo.718.2">In this section, we’ll see how to use</span><a id="_idIndexMarker1478"/><span class="koboSpan" id="kobo.719.1"> it in practice with PyTorch. </span><span class="koboSpan" id="kobo.719.2">Once again, we’ll use the transfer learning PyTorch example from </span><a href="B19627_05.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.720.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.721.1"> as a base for our implementation. </span><span class="koboSpan" id="kobo.721.2">All the code modifications are concentrated in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.722.1">train_model</span></strong><span class="koboSpan" id="kobo.723.1"> function. </span><span class="koboSpan" id="kobo.723.2">We’ll only include </span><strong class="source-inline"><span class="koboSpan" id="kobo.724.1">train_model</span></strong><span class="koboSpan" id="kobo.725.1"> here, but the full example is available as a Jupyter Notebook in this book’s GitHub repository. </span><span class="koboSpan" id="kobo.725.2">The following is a shortened version of the </span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">function definition:</span></span></p>
<pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.727.1">
def train_model(model, loss_fn, optimizer, data_loader):
    </span><strong class="bold"><span class="koboSpan" id="kobo.728.1">scaler = torch.cuda.amp.GradScaler()</span></strong><span class="koboSpan" id="kobo.729.1">
    for i, (inputs, labels) in enumerate(data_loader):
        optimizer.zero_grad()
        with </span><strong class="bold"><span class="koboSpan" id="kobo.730.1">torch.autocast(</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.731.1">            device_type=device,</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.732.1">            dtype=torch.float16)</span></strong><span class="koboSpan" id="kobo.733.1">:
            # send the input/labels to the GPU
            inputs = inputs.to(device)
            labels = labels.to(device)
            # forward
            outputs = model(inputs)
            loss = loss_fn(outputs, labels)
        # backward with scaler
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()</span></pre>
<p lang="en-GB"><span class="koboSpan" id="kobo.734.1">We use a combination of two</span><a id="_idIndexMarker1479"/><span class="koboSpan" id="kobo.735.1"> separate and unrelated mechanisms for </span><span class="No-Break"><span class="koboSpan" id="kobo.736.1">mixed-precision </span></span><span class="No-Break"><a id="_idIndexMarker1480"/></span><span class="No-Break"><span class="koboSpan" id="kobo.737.1">training:</span></span></p>
<ul>
<li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.738.1">torch.autocast</span></strong><span class="koboSpan" id="kobo.739.1">: This acts as a context manager (or decorator) and allows a region of the code to run in mixed precision. </span><strong class="source-inline"><span class="koboSpan" id="kobo.740.1">device_type</span></strong><span class="koboSpan" id="kobo.741.1"> specifies the device that </span><strong class="source-inline"><span class="koboSpan" id="kobo.742.1">autocast</span></strong><span class="koboSpan" id="kobo.743.1"> applies to. </span><strong class="source-inline"><span class="koboSpan" id="kobo.744.1">dtype</span></strong><span class="koboSpan" id="kobo.745.1"> specifies the data type with which the CUDA operations work. </span><span class="koboSpan" id="kobo.745.2">The PyTorch documentation suggests only wrapping the forward and loss computation with </span><strong class="source-inline"><span class="koboSpan" id="kobo.746.1">torch.autocast</span></strong><span class="koboSpan" id="kobo.747.1">. </span><span class="koboSpan" id="kobo.747.2">The backward operations automatically run with the same data type as the </span><span class="No-Break"><span class="koboSpan" id="kobo.748.1">forward ones.</span></span></li>
<li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.749.1">torch.cuda.amp.GradScaler</span></strong><span class="koboSpan" id="kobo.750.1">: When the forward pass uses </span><strong class="source-inline"><span class="koboSpan" id="kobo.751.1">float16</span></strong><span class="koboSpan" id="kobo.752.1"> precision operations, so does the backward pass, which computes the gradients. </span><span class="koboSpan" id="kobo.752.2">However, due to</span><a id="_idIndexMarker1481"/><span class="koboSpan" id="kobo.753.1"> the lower precision, some gradient values will flush to zero. </span><span class="koboSpan" id="kobo.753.2">To prevent this, </span><strong class="bold"><span class="koboSpan" id="kobo.754.1">gradient scaling</span></strong><span class="koboSpan" id="kobo.755.1"> multiplies the</span><a id="_idIndexMarker1482"/><span class="koboSpan" id="kobo.756.1"> NN’s loss by a scale factor and invokes a backward pass with the scaled value. </span><span class="koboSpan" id="kobo.756.2">Gradients flowing backward through the network are also scaled by the same factor. </span><span class="koboSpan" id="kobo.756.3">In this way, the entire backward pass uses a larger magnitude to prevent flushing to zero. </span><span class="koboSpan" id="kobo.756.4">Before the weight updates, the </span><a id="_idIndexMarker1483"/><span class="koboSpan" id="kobo.757.1">mechanism </span><em class="italic"><span class="koboSpan" id="kobo.758.1">unscales</span></em><span class="koboSpan" id="kobo.759.1"> the scaled gradient values, so the weight updates work with the </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">actual values.</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.761.1">This concludes our introduction to the model development tools. </span><span class="koboSpan" id="kobo.761.2">Next, we’ll discuss some model </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">deployment mechanisms.</span></span></p>
<h1 id="_idParaDest-189" lang="en-GB"><a id="_idTextAnchor264"/><span class="koboSpan" id="kobo.763.1">Exploring model deployment</span></h1>
<p lang="en-GB"><span class="koboSpan" id="kobo.764.1">In this section, we’ll </span><a id="_idIndexMarker1484"/><span class="koboSpan" id="kobo.765.1">discuss two basic model deployment examples. </span><span class="koboSpan" id="kobo.765.2">They’ll help you create simple, yet functional, proof-of-concept apps for your experiments. </span><span class="No-Break"><span class="koboSpan" id="kobo.766.1">Let’s start.</span></span></p>
<h2 id="_idParaDest-190" lang="en-GB"><a id="_idTextAnchor265"/><span class="koboSpan" id="kobo.767.1">Deploying NN models with Flask</span></h2>
<p lang="en-GB"><span class="koboSpan" id="kobo.768.1">In our first example, we’ll use Google</span><a id="_idIndexMarker1485"/><span class="koboSpan" id="kobo.769.1"> Colab in</span><a id="_idIndexMarker1486"/><span class="koboSpan" id="kobo.770.1"> combination with </span><strong class="bold"><span class="koboSpan" id="kobo.771.1">Flask</span></strong><span class="koboSpan" id="kobo.772.1"> (</span><a href="https://github.com/pallets/flask"><span class="koboSpan" id="kobo.773.1">https://github.com/pallets/flask</span></a><span class="koboSpan" id="kobo.774.1">) to create a simple hosted REST API service, which will expose our model to the outside world. </span><span class="koboSpan" id="kobo.774.2">For the sake of </span><a id="_idIndexMarker1487"/><span class="koboSpan" id="kobo.775.1">simplicity, we’ll use a </span><strong class="bold"><span class="koboSpan" id="kobo.776.1">stable diffusion</span></strong><span class="koboSpan" id="kobo.777.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.778.1">SD</span></strong><span class="koboSpan" id="kobo.779.1">) model: it will accept a textual </span><strong class="source-inline"><span class="koboSpan" id="kobo.780.1">prompt</span></strong><span class="koboSpan" id="kobo.781.1"> parameter, generate </span><a id="_idIndexMarker1488"/><span class="koboSpan" id="kobo.782.1">an image with it, and return the image as</span><a id="_idIndexMarker1489"/> <span class="No-Break"><span class="koboSpan" id="kobo.783.1">a result.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.784.1">According to its home</span><a id="_idIndexMarker1490"/><span class="koboSpan" id="kobo.785.1"> page, Flask is a lightweight </span><strong class="bold"><span class="koboSpan" id="kobo.786.1">WSGI</span></strong><span class="koboSpan" id="kobo.787.1"> (</span><a href="https://wsgi.readthedocs.io/"><span class="koboSpan" id="kobo.788.1">https://wsgi.readthedocs.io/</span></a><span class="koboSpan" id="kobo.789.1">) web application framework. </span><span class="koboSpan" id="kobo.789.2">It is designed to make getting started quick and easy, with the ability to scale up to complex applications. </span><span class="koboSpan" id="kobo.789.3">In our case, it will start a development web server, which will process the requests for the SD model. </span><span class="koboSpan" id="kobo.789.4">Although this server will run in the Google Colab environment (think of it as </span><strong class="source-inline"><span class="koboSpan" id="kobo.790.1">localhost</span></strong><span class="koboSpan" id="kobo.791.1">), we won’t be able to access it. </span><span class="koboSpan" id="kobo.791.2">To solve this, we’ll need </span><strong class="source-inline"><span class="koboSpan" id="kobo.792.1">flask-ngrok</span></strong><span class="koboSpan" id="kobo.793.1"> (</span><a href="https://ngrok.com/docs/using-ngrok-with/flask/"><span class="koboSpan" id="kobo.794.1">https://ngrok.com/docs/using-ngrok-with/flask/</span></a><span class="koboSpan" id="kobo.795.1">), which will expose the server to the outside world (you’ll need </span><a id="_idIndexMarker1491"/><span class="koboSpan" id="kobo.796.1">a free </span><strong class="source-inline"><span class="koboSpan" id="kobo.797.1">ngrok</span></strong><span class="koboSpan" id="kobo.798.1"> registration and authentication token to run </span><span class="No-Break"><span class="koboSpan" id="kobo.799.1">this example).</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.800.1">To satisfy all </span><a id="_idIndexMarker1492"/><span class="koboSpan" id="kobo.801.1">dependencies, we’ll need the </span><strong class="source-inline"><span class="koboSpan" id="kobo.802.1">transformers</span></strong><span class="koboSpan" id="kobo.803.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.804.1">diffusers</span></strong><span class="koboSpan" id="kobo.805.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.806.1">accelerate</span></strong><span class="koboSpan" id="kobo.807.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.808.1">flask-ngrok</span></strong><span class="koboSpan" id="kobo.809.1"> packages. </span><span class="No-Break"><span class="koboSpan" id="kobo.810.1">Let’s start:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.811.1">First, we’ll initialize the SD HF</span><a id="_idIndexMarker1493"/><span class="koboSpan" id="kobo.812.1"> pipeline (</span><strong class="source-inline"><span class="koboSpan" id="kobo.813.1">sd_pipe</span></strong><span class="koboSpan" id="kobo.814.1">) in the same way as we did in </span><a href="B19627_09.xhtml#_idTextAnchor236"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.815.1">Chapter 9</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.816.1">:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.817.1">
import torch
from diffusers import StableDiffusionPipeline
</span><strong class="bold"><span class="koboSpan" id="kobo.818.1">sd_pipe</span></strong><span class="koboSpan" id="kobo.819.1"> = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1",
    torch_dtype=torch.float16)
sd_pipe.to('cuda')</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.820.1">Next, we’ll initialize our </span><span class="No-Break"><span class="koboSpan" id="kobo.821.1">Flask </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.822.1">app</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.823.1">:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.824.1">
from flask import Flask
from flask_ngrok import run_with_ngrok
app = Flask(__name__)
run_with_ngrok(app)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.825.1">Here, </span><strong class="source-inline"><span class="koboSpan" id="kobo.826.1">run_with_ngrok</span></strong><span class="koboSpan" id="kobo.827.1"> indicates that the app will run with </span><strong class="source-inline"><span class="koboSpan" id="kobo.828.1">ngrok</span></strong><span class="koboSpan" id="kobo.829.1">, but the actual </span><strong class="source-inline"><span class="koboSpan" id="kobo.830.1">app</span></strong><span class="koboSpan" id="kobo.831.1"> is not running yet (this will come at the end of this example). </span><span class="koboSpan" id="kobo.831.2">Since we don’t have access to Colab’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.832.1">localhost</span></strong><span class="koboSpan" id="kobo.833.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.834.1">ngrok</span></strong><span class="koboSpan" id="kobo.835.1"> will make it possible to access it from our </span><span class="No-Break"><span class="koboSpan" id="kobo.836.1">test client.</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.837.1">Then, we’ll implement </span><a id="_idIndexMarker1494"/><span class="koboSpan" id="kobo.838.1">our </span><strong class="source-inline"><span class="koboSpan" id="kobo.839.1">text-to-image</span></strong><span class="koboSpan" id="kobo.840.1"> endpoint, which</span><a id="_idIndexMarker1495"/><span class="koboSpan" id="kobo.841.1"> will process the prompts, which</span><a id="_idIndexMarker1496"/><span class="koboSpan" id="kobo.842.1"> are coming in as web requests, and generate images based </span><span class="No-Break"><span class="koboSpan" id="kobo.843.1">on them:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.844.1">
import io
from flask import Flask, request, send_file, abort
@app.route('</span><strong class="bold"><span class="koboSpan" id="kobo.845.1">/text-to-image</span></strong><span class="koboSpan" id="kobo.846.1">', methods=[</span><strong class="bold"><span class="koboSpan" id="kobo.847.1">'POST', 'GET'</span></strong><span class="koboSpan" id="kobo.848.1">])
def predict():
    if request.method in ('POST', 'GET'):
        </span><strong class="bold"><span class="koboSpan" id="kobo.849.1">prompt</span></strong><span class="koboSpan" id="kobo.850.1"> = request.get_json().get('prompt')
        if prompt and prompt.strip():
            </span><strong class="bold"><span class="koboSpan" id="kobo.851.1">image = sd_pipe(</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.852.1">                prompt,</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.853.1">                num_inference_steps=100).images[0]</span></strong><span class="koboSpan" id="kobo.854.1">
            image_io = io.BytesIO()
            image.save(image_io, format='PNG')
            image_io.seek(0)
            return </span><strong class="bold"><span class="koboSpan" id="kobo.855.1">send_file</span></strong><span class="koboSpan" id="kobo.856.1">(
                image_io,
                as_attachment=False,
                mimetype='image/png'
            )
        else:
            abort(500, description='Invalid prompt')</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.857.1">The endpoint’s name is </span><strong class="source-inline"><span class="koboSpan" id="kobo.858.1">/text-to-image</span></strong><span class="koboSpan" id="kobo.859.1"> and it will process both </span><strong class="source-inline"><span class="koboSpan" id="kobo.860.1">POST</span></strong><span class="koboSpan" id="kobo.861.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.862.1">GET</span></strong><span class="koboSpan" id="kobo.863.1"> requests (the processing pipeline is the same). </span><span class="koboSpan" id="kobo.863.2">The function will parse the textual </span><strong class="source-inline"><span class="koboSpan" id="kobo.864.1">prompt</span></strong><span class="koboSpan" id="kobo.865.1"> parameter and it will feed it to </span><strong class="source-inline"><span class="koboSpan" id="kobo.866.1">sd_pipe</span></strong><span class="koboSpan" id="kobo.867.1"> to generate an </span><strong class="source-inline"><span class="koboSpan" id="kobo.868.1">image</span></strong><span class="koboSpan" id="kobo.869.1"> parameter (in the same way as in the </span><a href="B19627_09.xhtml#_idTextAnchor236"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.870.1">Chapter 9</span></em></span></a><span class="koboSpan" id="kobo.871.1"> example). </span><span class="koboSpan" id="kobo.871.2">Finally, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.872.1">send_file</span></strong><span class="koboSpan" id="kobo.873.1"> function will</span><a id="_idIndexMarker1497"/><span class="koboSpan" id="kobo.874.1"> return the result of </span><strong class="source-inline"><span class="koboSpan" id="kobo.875.1">image</span></strong><span class="koboSpan" id="kobo.876.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.877.1">the client.</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.878.1">We can now start </span><a id="_idIndexMarker1498"/><span class="koboSpan" id="kobo.879.1">the Flask app with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.880.1">app.run()</span></strong><span class="koboSpan" id="kobo.881.1"> command. </span><span class="koboSpan" id="kobo.881.2">It will initialize the Flask development server so that </span><a id="_idIndexMarker1499"/><span class="koboSpan" id="kobo.882.1">our endpoint will be ready to process requests. </span><span class="koboSpan" id="kobo.882.2">In addition, </span><strong class="source-inline"><span class="koboSpan" id="kobo.883.1">ngrok</span></strong><span class="koboSpan" id="kobo.884.1"> will expose the app to the outside world with a URL of the </span><a href="http://RANDOM-SEQUENCE.ngrok.io/"><span class="No-Break"><span class="koboSpan" id="kobo.885.1">http://RANDOM-SEQUENCE.ngrok.io/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.886.1"> type.</span></span></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.887.1">We can use this URL to initiate a test request to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.888.1">text-to-image</span></strong><span class="koboSpan" id="kobo.889.1"> endpoint (this is outside the </span><span class="No-Break"><span class="koboSpan" id="kobo.890.1">Colab notebook):</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.891.1">
import requests
</span><strong class="bold"><span class="koboSpan" id="kobo.892.1">response</span></strong><span class="koboSpan" id="kobo.893.1"> = requests.post(
    url='</span><a href="http://RANDOM-SEQUENCE.ngrok.io/text-to-image'"><span class="koboSpan" id="kobo.894.1">http://RANDOM-SEQUENCE.ngrok.io/text-to-image'</span></a><span class="koboSpan" id="kobo.895.1">,
    json={'prompt': 'High quality photo of a racing car on a track'})</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.896.1">We can display the image with the </span><span class="No-Break"><span class="koboSpan" id="kobo.897.1">following code:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.898.1">
from PIL import Image
import io
image = Image.open(io.BytesIO(</span><strong class="bold"><span class="koboSpan" id="kobo.899.1">response.content</span></strong><span class="koboSpan" id="kobo.900.1">))
image.show()</span></pre></li>
</ol>
<p lang="en-GB"><span class="koboSpan" id="kobo.901.1">This concludes our </span><a id="_idIndexMarker1500"/><span class="koboSpan" id="kobo.902.1">REST API example. </span><span class="koboSpan" id="kobo.902.2">Next, we’ll deploy a model in a web environment with </span><span class="No-Break"><span class="koboSpan" id="kobo.903.1">a UI.</span></span></p>
<h2 id="_idParaDest-191" lang="en-GB"><a id="_idTextAnchor266"/><span class="koboSpan" id="kobo.904.1">Building ML web apps with Gradio</span></h2>
<p lang="en-GB"><span class="koboSpan" id="kobo.905.1">Gradio (</span><a href="https://www.gradio.app/"><span class="koboSpan" id="kobo.906.1">https://www.gradio.app/</span></a><span class="koboSpan" id="kobo.907.1">) is an open source Python library that allows us to build interactive </span><a id="_idIndexMarker1501"/><span class="koboSpan" id="kobo.908.1">web-based demos for our ML models. </span><span class="koboSpan" id="kobo.908.2">HF Spaces (</span><a href="https://huggingface.co/spaces"><span class="koboSpan" id="kobo.909.1">https://huggingface.co/spaces</span></a><span class="koboSpan" id="kobo.910.1">) supports </span><a id="_idIndexMarker1502"/><span class="koboSpan" id="kobo.911.1">hosting Gradio apps. </span><span class="koboSpan" id="kobo.911.2">So, we can build a Gradio app on top of the HF infrastructure, which includes not only hosting but also has access to all available HF </span><span class="No-Break"><span class="koboSpan" id="kobo.912.1">models (</span></span><a href="https://huggingface.co/models"><span class="No-Break"><span class="koboSpan" id="kobo.913.1">https://huggingface.co/models</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.914.1">).</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.915.1">We can create an </span><a id="_idIndexMarker1503"/><span class="koboSpan" id="kobo.916.1">HF space at </span><a href="https://huggingface.co/new-space"><span class="koboSpan" id="kobo.917.1">https://huggingface.co/new-space</span></a><span class="koboSpan" id="kobo.918.1">. </span><span class="koboSpan" id="kobo.918.2">The space has a name (which will be its URL as well), a license, and an SDK. </span><span class="koboSpan" id="kobo.918.3">At the time of writing, HF Spaces supports Streamlit-based (</span><a href="https://streamlit.io/"><span class="koboSpan" id="kobo.919.1">https://streamlit.io/</span></a><span class="koboSpan" id="kobo.920.1">), Gradio-based, and </span><a id="_idIndexMarker1504"/><span class="koboSpan" id="kobo.921.1">Static instances. </span><span class="koboSpan" id="kobo.921.2">However, you can also deploy custom Docker containers for </span><span class="No-Break"><span class="koboSpan" id="kobo.922.1">more flexibility.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.923.1">Each new HF space has an associated Git repository. </span><span class="koboSpan" id="kobo.923.2">For example, the space of this example is located at </span><a href="https://huggingface.co/spaces/ivan-vasilev/gradio-demo"><span class="koboSpan" id="kobo.924.1">https://huggingface.co/spaces/ivan-vasilev/gradio-demo</span></a><span class="koboSpan" id="kobo.925.1">, which is also the URL of its corresponding Git repository. </span><span class="koboSpan" id="kobo.925.2">The Gradio-based space expects a Python module called </span><strong class="source-inline"><span class="koboSpan" id="kobo.926.1">app.py</span></strong><span class="koboSpan" id="kobo.927.1"> in its root (in our case, the whole example will reside in </span><strong class="source-inline"><span class="koboSpan" id="kobo.928.1">app.py</span></strong><span class="koboSpan" id="kobo.929.1">) and a </span><strong class="source-inline"><span class="koboSpan" id="kobo.930.1">requirements.txt</span></strong><span class="koboSpan" id="kobo.931.1"> file. </span><span class="koboSpan" id="kobo.931.2">Every time you push changes to the repository, the app will automatically pick them up and </span><span class="No-Break"><span class="koboSpan" id="kobo.932.1">restart itself.</span></span></p>
<p class="callout-heading" lang="en-GB"><span class="koboSpan" id="kobo.933.1">Note</span></p>
<p class="callout" lang="en-GB"><span class="koboSpan" id="kobo.934.1">To replicate this example, you’ll need an HF account. </span><span class="koboSpan" id="kobo.934.2">HF Spaces has different hardware tiers. </span><span class="koboSpan" id="kobo.934.3">The basic one is free, but this particular example requires the GPU-enabled tier, which has an hourly cost. </span><span class="koboSpan" id="kobo.934.4">Therefore, if you want to run this example, you can duplicate it in your own account and enable the </span><span class="No-Break"><span class="koboSpan" id="kobo.935.1">GPU tier.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.936.1">Gradio starts with a central high-level class called </span><strong class="source-inline"><span class="koboSpan" id="kobo.937.1">gradio.Interface</span></strong><span class="koboSpan" id="kobo.938.1">. </span><span class="koboSpan" id="kobo.938.2">Its constructor takes three </span><span class="No-Break"><span class="koboSpan" id="kobo.939.1">main parameters:</span></span></p>
<ul>
<li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.940.1">fn</span></strong><span class="koboSpan" id="kobo.941.1">: The main function, which will process the inputs and </span><span class="No-Break"><span class="koboSpan" id="kobo.942.1">return outputs.</span></span></li>
<li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.943.1">inputs</span></strong><span class="koboSpan" id="kobo.944.1">: One or more Gradio input components. </span><span class="koboSpan" id="kobo.944.2">These could be textual inputs, file uploads, or combo boxes, among others. </span><span class="koboSpan" id="kobo.944.3">You can specify the component as a class instance or via its string label. </span><span class="koboSpan" id="kobo.944.4">The number of inputs should match the number of </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.945.1">fn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.946.1"> parameters.</span></span></li>
<li lang="en-GB"><strong class="source-inline"><span class="koboSpan" id="kobo.947.1">outputs</span></strong><span class="koboSpan" id="kobo.948.1">: One or more Gradio components, which will represent the result of the execution of </span><strong class="source-inline"><span class="koboSpan" id="kobo.949.1">fn</span></strong><span class="koboSpan" id="kobo.950.1">. </span><span class="koboSpan" id="kobo.950.2">The number of outputs should match the number of values returned </span><span class="No-Break"><span class="koboSpan" id="kobo.951.1">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.952.1">fn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.953.1">.</span></span></li>
</ul>
<p lang="en-GB"><span class="koboSpan" id="kobo.954.1">Gradio will automatically instantiate and arrange the UI components based on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.955.1">input</span></strong><span class="koboSpan" id="kobo.956.1"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.957.1">output</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.958.1"> parameters.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.959.1">Next, we’ll implement our </span><a id="_idIndexMarker1505"/><span class="koboSpan" id="kobo.960.1">example. </span><span class="koboSpan" id="kobo.960.2">We’ll use the same text-to-image SD scenario that we used in the </span><em class="italic"><span class="koboSpan" id="kobo.961.1">Deploying NN models with Flask</span></em><span class="koboSpan" id="kobo.962.1"> section. </span><span class="koboSpan" id="kobo.962.2">To avoid </span><a id="_idIndexMarker1506"/><span class="koboSpan" id="kobo.963.1">duplication, we’ll assume that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.964.1">sd_pipe</span></strong><span class="koboSpan" id="kobo.965.1"> pipeline has already been initialized. </span><span class="No-Break"><span class="koboSpan" id="kobo.966.1">Let’s start:</span></span></p>
<ol>
<li lang="en-GB"><span class="koboSpan" id="kobo.967.1">First, we’ll implement the </span><strong class="source-inline"><span class="koboSpan" id="kobo.968.1">generate_image</span></strong><span class="koboSpan" id="kobo.969.1"> function, which uses </span><strong class="source-inline"><span class="koboSpan" id="kobo.970.1">prompt</span></strong><span class="koboSpan" id="kobo.971.1"> to synthesize an image in a total of </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.972.1">inf_steps</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.973.1"> steps:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.974.1">
def generate_image(
        prompt: str,
        inf_steps: int = 100):
    return </span><strong class="bold"><span class="koboSpan" id="kobo.975.1">sd_pipe</span></strong><span class="koboSpan" id="kobo.976.1">(
        prompt=prompt,
        num_inference_steps=inf_steps).images[0]</span></pre></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.977.1">Next, we’ll initialize the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.978.1">gradio.Interface</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.979.1"> class:</span></span><pre class="source-code" lang="en-GB"><span class="koboSpan" id="kobo.980.1">
import gradio as gr
interface = gr.Interface(
    </span><strong class="bold"><span class="koboSpan" id="kobo.981.1">fn</span></strong><span class="koboSpan" id="kobo.982.1">=generate_image,
    </span><strong class="bold"><span class="koboSpan" id="kobo.983.1">inputs</span></strong><span class="koboSpan" id="kobo.984.1">=[
        gr.components.Textbox(label='Prompt'),
        gr.components.Slider(
            minimum=0,
            maximum=100,
            label='Inference Steps')],
    </span><strong class="bold"><span class="koboSpan" id="kobo.985.1">outputs</span></strong><span class="koboSpan" id="kobo.986.1">=gr.components.Image(),
    title='Stable Diffusion',
)</span></pre><p class="list-inset" lang="en-GB"><span class="koboSpan" id="kobo.987.1">As we discussed, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.988.1">inputs</span></strong><span class="koboSpan" id="kobo.989.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.990.1">outputs</span></strong> <strong class="source-inline"><span class="koboSpan" id="kobo.991.1">gr.Interface</span></strong><span class="koboSpan" id="kobo.992.1"> parameters match the input/output </span><a id="_idIndexMarker1507"/><span class="koboSpan" id="kobo.993.1">signature of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.994.1">generate_image</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.995.1"> function.</span></span></p></li>
<li lang="en-GB"><span class="koboSpan" id="kobo.996.1">Finally, we can run the </span><a id="_idIndexMarker1508"/><span class="koboSpan" id="kobo.997.1">app with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.998.1">interface.launch()</span></strong><span class="koboSpan" id="kobo.999.1"> command. </span><span class="koboSpan" id="kobo.999.2">Here is what the responsive UI of the app </span><span class="No-Break"><span class="koboSpan" id="kobo.1000.1">looks like:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer1089">
<span class="koboSpan" id="kobo.1001.1"><img alt="Figure 10.4 – The SD Gradio app’s responsive UI, hosted on HF Spaces. Top: input components; bottom: generated image" src="image/B19627_10_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1002.1">Figure 10.4 – The SD Gradio app’s responsive UI, hosted on HF Spaces. </span><span class="koboSpan" id="kobo.1002.2">Top: input components; bottom: generated image</span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.1003.1">This concludes</span><a id="_idIndexMarker1509"/><span class="koboSpan" id="kobo.1004.1"> our introduction to Gradio and </span><span class="No-Break"><span class="koboSpan" id="kobo.1005.1">model </span></span><span class="No-Break"><a id="_idIndexMarker1510"/></span><span class="No-Break"><span class="koboSpan" id="kobo.1006.1">deployment.</span></span></p>
<h1 id="_idParaDest-192" lang="en-GB"><a id="_idTextAnchor267"/><span class="koboSpan" id="kobo.1007.1">Summary</span></h1>
<p lang="en-GB"><span class="koboSpan" id="kobo.1008.1">In this chapter, we outlined three major components of the ML development life cycle – training dataset creation, model development, and model deployment. </span><span class="koboSpan" id="kobo.1008.2">We focused on the latter two, starting with development. </span><span class="koboSpan" id="kobo.1008.3">First, we discussed the popularity of the foundational NN frameworks. </span><span class="koboSpan" id="kobo.1008.4">Then, we focused on several model development topics – the ONNX universal model representation format, the TB monitoring platform, the TF Lite mobile development library, and mixed precision PyTorch training. </span><span class="koboSpan" id="kobo.1008.5">Next, we discussed two basic scenarios for model deployment – a REST service as a Flask app and an interactive web app </span><span class="No-Break"><span class="koboSpan" id="kobo.1009.1">with Gradio.</span></span></p>
<p lang="en-GB"><span class="koboSpan" id="kobo.1010.1">This concludes this chapter and this book. </span><span class="koboSpan" id="kobo.1010.2">I hope you’ve enjoyed </span><span class="No-Break"><span class="koboSpan" id="kobo.1011.1">the journey!</span></span></p>
</div>
</body></html>