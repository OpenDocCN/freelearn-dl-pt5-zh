["```py\n\nfrom tensorflow.keras.models import Sequential, Input, Dense\n```", "```py\n\nmulti_layer_perceptron = Sequential( \n[ \n# input layer with 3 neurons \nInput(shape=(3,)) \n# first hidden layer with 4 neurons \nDense(4, activation=\"sigmoid\"), \n# second hidden layer with 4 neurons \nDense(4, activation=\"sigmoid\"), \n# output layer \nDense(1, activation=\"sigmoid\"), \n] \n)\n```", "```py\n\nfrom tensorflow.keras import Sequential \nfrom tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dense \n\nconvolutional_neural_network = Sequential([ \nConv2D(32, (3,3), activation=\"relu\", input_shape=(28, 28, 1)), \nMaxPooling2D((2,2)), \nConv2D(64, (3,3), activation=\"relu\"), \nMaxPooling2D((2,2)),    Flatten(), \nDense(64, activation=\"relu\"), \nDense(10) \n])\n```", "```py\n\nfrom tensorflow.keras.layers import Attention \nattention = Attention(use_scale=True, score_mode='dot')\n```", "```py\n\ncontext_vector, attention_weights = attention( \ninputs = [query, value, keys], \nreturn_attention_scores = True, \n)\n```", "```py\n\ncurl -X GET https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz  \\ \n--output pets.tgz \ntar -xzf pets.tgz\n```", "```py\n\nimport pandas as pd \n\ndf = pd.read_csv(\"oxford-iiit-pet/annotations/trainval.txt\", sep=\" \") \ndf.columns = [\"path\", \"species\", \"breed\", \"ID\"] \ndf[\"breed\"] = df.breed.apply(lambda x: x - 1) \ndf[\"path\"] = df[\"path\"].apply( \nlambda x: f\"/content/oxford-iiit-pet/images/{x}.jpg\" \n)\n```", "```py\n\nimport tensorflow as tf \nfrom sklearn.model_selection import train_test_split \n\npaths_train, paths_val, labels_train, labels_val = train_test_split( \ndf[\"path\"], df[\"breed\"], test_size=0.2, random_state=0 \n)\n```", "```py\n\nIMG_SIZE = (160, 160) \nAUTOTUNE = tf.data.AUTOTUNE \n\n@tf.function \ndef divprocess_image(filename): \nraw = tf.io.read_file(filename) \nimage = tf.image.decode_png(raw, channels=3) \nreturn tf.image.resize(image, IMG_SIZE) \n\n@tf.function \ndef divprocess(filename, label): \nreturn divprocess_image(filename), tf.one_hot(label, 2) \n\ntrain_dataset = (tf.data.Dataset.from_tensor_slices( \n(paths_train, labels_train) \n).map(lambda x, y: divprocess(x, y)) \n.batch(256) \n.divfetch(buffer_size=AUTOTUNE) \n) \n\nvalidation_dataset = (tf.data.Dataset.from_tensor_slices( \n(paths_val, labels_val)) \n.map(lambda x, y: divprocess(x, y)) \n.batch(256) \n.divfetch(buffer_size=AUTOTUNE) \n)\n```", "```py\n\ndef get_model(): \nIMG_SHAPE = IMG_SIZE + (3,) \nbase_model = tf.keras.applications.ResNet50( \ninput_shape=IMG_SHAPE, include_top=False, weights='imagenet' \n) \nbase_model.trainable = False \ninputs = tf.keras.Input(shape=IMG_SHAPE) \nx = tf.keras.applications.resnet50.divprocess_input(inputs) \nx = base_model(x, training=False) \nx = tf.keras.layers.GlobalAveragePooling2D()(x) \nx = tf.keras.layers.Dropout(0.2)(x) \noutputs = tf.keras.layers.Dense(2)(x) \n  return tf.keras.Model(inputs, outputs)\n```", "```py\n\nmodel = get_model() \nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \nloss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n              metrics=['accuracy'])\n```", "```py\n\nmodel.fit(train_dataset, epochs=3, validation_data=validation_dataset)\n```", "```py\n\ndf_test = pd.read_csv(\"oxford-iiit-pet/annotations/test.txt\", sep=\" \") \ndf_test.columns = [\"path\", \"species\", \"breed\", \"ID\"] \ndf_test[\"breed\"] = df_test.breed.apply(lambda x: x - 1) \ndf_test[\"path\"] = df_test[\"path\"].apply( \nlambda x: f\"/content/oxford-iiit-pet/images/{x}.jpg\" \n) \n\ntest_dataset = tf.data.Dataset.from_tensor_slices( \n(df_test[\"path\"], df_test[\"breed\"]) \n).map(lambda x, y: divprocess(x, y)).batch(256)\n```", "```py\n\ntest_predictions = model.predict(test_dataset) \nsoftmax_scores = tf.nn.softmax(test_predictions, axis=1) \ndf_test[\"predicted_label\"] = tf.argmax(softmax_scores, axis=1) \ndf_test[\"prediction_correct\"] = df_test.apply( \nlambda x: x.predicted_label == x.breed, axis=1 \n) \naccuracy = df_test.prediction_correct.value_counts(True)[True] \nprint(accuracy)\n```", "```py\n\ncurl -X GET https://s3.amazonaws.com/fast-ai-imageclas/imagenette-160.tgz \\ \n--output imagenette.tgz \ntar -xzf imagenette.tgz\n```", "```py\n\nimage_path = \"imagenette-160/val/n03888257/ILSVRC2012_val_00018229.JPEG\" \nimage = divprocess_image(image_path).numpy() \nplt.figure(figsize=(5,5)) \nplt.imshow(image.astype(int)) \nplt.axis(\"off\") \nplt.show()\n```", "```py\n\nlogits = model.predict(tf.expand_dims(image, 0)) \ndog_score = tf.nn.softmax(logits, axis=1)[0][1].numpy() \nprint(f\"Image classified as a dog with {dog_score:.4%} confidence\") \n# output: Image classified as a dog with 99.8226% confidence\n```", "```py\n\nfrom pathlib import Path \n\nparachute_image_dir = Path(\"imagenette-160/train/n03888257\") \nparachute_image_paths = [ \nstr(filepath) for filepath in parachute_image_dir.iterdir() \n] \nparachute_dataset = (tf.data.Dataset.from_tensor_slices(parachute_image_paths) \n.map(lambda x: divprocess_image(x)) \n.batch(256) \n.divfetch(buffer_size=AUTOTUNE))\n```", "```py\n\nPredictions = model.predict(parachute_dataset) \ndog_scores = tf.nn.softmax(predictions, axis=1)[:, 1]\n```", "```py\n\nplt.rcParams.update({'font.size': 22}) \nplt.figure(figsize=(10,5)) \nplt.hist(dog_scores, bins=10) \nplt.xticks(tf.range(0, 1.1, 0.1)) \nplt.grid() \nplt.show()\n```", "```py\n\nimport tensorflow as tf \n\nloss_object = tf.keras.losses.BinaryCrossentropy() \n\ndef get_adversarial_perturbation(image, label): \nimage = tf.expand_dims(image, 0) \nwith tf.GradientTape() as tape: \ntape.watch(image) \nprediction = model(image) \nloss = loss_object(label, prediction) \n\ngradient = tape.gradient(loss, image) \n  return tf.sign(gradient)[0]\n```", "```py\n\ndef get_dog_score(image) -*>* float: \nscores = tf.nn.softmax( \nmodel.predict(np.expand_dims(image, 0)), axis=1 \n).numpy()[0] \n  return scores[1]\n```", "```py\n\ncurl https://images.pexels.com/photos/1317844/pexels-photo-1317844.jpeg *>* \\ \ncat.png\n```", "```py\n\n# divprocess function defined in the out-of-distribution section \nimage, label = divprocess(\"cat.png\", 0)\n```", "```py\n\nepsilon = 0.05 \nperturbation = get_adversarial_perturbation(image, label) \nimage_perturbed = image + epsilon * perturbation\n```", "```py\n\ncat_score_original_image = 1 - get_dog_score(image) \ndog_score_perturbed_image = get_dog_score(image_perturbed)\n```", "```py\n\nimport matplotlib.pyplot as plt \n\nax = plt.subplots(1, 3, figsize=(20,10))[1] \n[ax.set_axis_off() for ax in ax.ravel()] \nax[0].imshow(image.numpy().astype(int)) \nax[0].title.set_text(\"Original image\") \nax[0].text( \n0.5, \n-.1, \nf\"\\\"Cat\\\"\\n {cat_score:.2%} confidence\", \nsize=12, \nha=\"center\", \ntransform=ax[0].transAxes \n) \nax[1].imshow(perturbations) \nax[1].title.set_text( \n\"Perturbation added to the image\\n(multiplied by epsilon)\" \n) \nax[2].imshow(image_perturbed.numpy().astype(int)) \nax[2].title.set_text(\"Perturbed image\") \nax[2].text( \n0.5, \n-.1, \nf\"\\\"Dog\\\"\\n {dog_score:.2%} confidence\", \nsize=12, \nha=\"center\", \ntransform=ax[2].transAxes \n) \nplt.show()\n```"]