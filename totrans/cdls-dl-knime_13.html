<html><head></head><body>
		<div id="_idContainer874">
			<p>­</p>
			<h1 id="_idParaDest-182"><em class="italic"><a id="_idTextAnchor367"/>Chapter 10: </em>Deploying a Deep Learning Network</h1>
			<p>In the previous sections of this book, we covered the training of deep neural networks for many different use cases, starting with an autoencoder for fraud detection, through <strong class="bold">Long Short-Term Memory</strong> (<strong class="bold">LSTM</strong>) networks for energy consumption prediction and free text generation, all the way to cancer cell classification. But training the network is not the only part of a project. Once a deep learning network is trained, the next step is to deploy it.</p>
			<p>During the exploration of some of the use cases, a second workflow has already been introduced, to deploy the network to work on real-world data. So, you have already seen some deployment examples. In this last section of the book, however, we focus on the many deployment options for machine learning models in general, and for trained deep learning networks in particular.</p>
			<p>Usually, a second workflow is built and dedicated to deployment. This workflow reads the trained model and the new real-world data, it preprocesses this data in exactly the same way as for the training data, then it applies the trained deep learning network on is transformed data and produces the results according to the project's requirements.</p>
			<p>This chapter focuses on the reading, writing, and preprocessing of the data in a deployment workflow. </p>
			<p>This chapter starts with a review of the features for saving, reading, and converting a trained network. This is followed by two examples of how the preprocessing for our sentiment analysis use case can also be implemented in a deployment workflow. Finally, the chapter shows how to improve execution speed by enabling GPU support.</p>
			<p>The chapter consists of the following sections:</p>
			<p>Conversion of the Network Structure </p>
			<p>Building a Simple Deployment Workflow</p>
			<p>Improving Scalability – GPU Execution</p>
			<h1 id="_idParaDest-183"><a id="_idTextAnchor368"/>Conversion of the Network Structure </h1>
			<p>The<a id="_idIndexMarker936"/> goal of a deployment workflow is to apply a trained network to new real-world data. Therefore, the last step of the training workflow must be to save the trained network.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor369"/>Saving a Trained Network</h2>
			<p>All <a id="_idIndexMarker937"/>networks described in this book have been trained using the Keras libraries, relying on TensorFlow as the backend. So, the most natural way to save a network is to continue using the Keras libraries and therefore to use the <strong class="bold">Keras Network Writer</strong> node. The Keras Network Writer node<a id="_idIndexMarker938"/> writes the network, including its weights, in Keras format into a <strong class="source-inline">.h5</strong> file.</p>
			<p>However, Keras-formatted networks can only be interpreted and executed via the Keras libraries. This is already one level on top of the TensorFlow libraries. Executing the network application on the TensorFlow Java API directly, rather than on a Python kernel via the Keras Python API, makes execution faster. The good news is that KNIME Analytics Platform also has nodes for TensorFlow execution in addition to the nodes based on Keras libraries. </p>
			<p>Thus, if faster execution is needed, the Keras network should be converted into a TensorFlow network <a id="_idIndexMarker939"/>using the <strong class="bold">Keras to TensorFlow Network Converter</strong> node. After conversion, the network can be saved using the <strong class="bold">TensorFlow Network Writer</strong> node as a <strong class="source-inline">SavedModel</strong> file, a compressed <strong class="source-inline">zip</strong> file. A <strong class="source-inline">SavedModel</strong> file contains a complete TensorFlow program, including weights and<a id="_idIndexMarker940"/> computation. It does not require the original model building code to run, which makes it useful for sharing or deploying.</p>
			<p>The first step in a deployment network is to read a trained network.</p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor370"/>Reading a Trained Network</h2>
			<p>KNIME Analytics<a id="_idIndexMarker941"/> Platform provides many nodes for reading a trained neural network, such as the following:</p>
			<ul>
				<li>Keras Network Reader </li>
				<li>TensorFlow Network Reader (and TensorFlow 2 Network Reader)</li>
				<li>DL Python Network Creator </li>
				<li>ONNX Network Reader </li>
			</ul>
			<p>The <strong class="bold">Keras Network Reader</strong> node reads a <a id="_idIndexMarker942"/>Keras deep learning network from a file. The file <a id="_idIndexMarker943"/>can either contain a full, pre-trained network (<strong class="source-inline">.h5</strong> file) or just a network architecture definition without weights (a <strong class="source-inline">.json</strong> or <strong class="source-inline">.yaml</strong> file). You can use the node to read networks trained with KNIME Analytics Platform or networks trained directly with Keras, such as pretrained Keras networks.</p>
			<p>The <strong class="bold">TensorFlow Network Reader</strong> (or TensorFlow 2 Network Reader) node reads a TensorFlow (or TensorFlow 2) deep learning <a id="_idIndexMarker944"/>network from a directory or from a <strong class="source-inline">zip</strong> file. If reading from a directory, it has to be a valid <strong class="source-inline">SavedModel</strong> folder. If reading from a <strong class="source-inline">zip</strong> file, it must contain a valid <strong class="source-inline">SavedModel</strong> folder.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The TensorFlow Network Reader node allows us to select a tag and a signature in its configuration window. Tags are used to identify the meta graph definition to load. Signatures are <strong class="bold">concrete functions</strong> specifying the expected input and output. A <strong class="source-inline">SavedModel</strong> can have multiple tags <a id="_idIndexMarker945"/>as well as multiple signatures per tag. A network saved with KNIME Analytics Platform has only one tag and one signature. In the <strong class="bold">Advanced</strong> tab of the configuration window, you can define your own signature by defining the input and output of the model by selecting one of the hidden layers as output, for example. </p>
			<p>Another node, which<a id="_idIndexMarker946"/> allows you to read pretrained networks without writing a single line of code, is the <strong class="bold">ONNX Network Reader</strong> node. <strong class="bold">ONNX</strong> stands for <strong class="bold">Open Neural Network Exchange</strong> and is a standard format for neural networks developed by <a id="_idIndexMarker947"/>Microsoft and Facebook. Since it is a standard format, it is portable across machine learning frameworks such as PyTorch, Caffe2, TensorFlow, and more. You can download pretrained networks from the ONNX Model Zoo (<a href="https://github.com/onnx/models#vision">https://github.com/onnx/models#vision</a>) and read them with the ONNX Network Reader node. The ONNX networks can also be converted into TensorFlow networks using the <strong class="bold">ONNX to TensorFlow Network Converter</strong> node, and then<a id="_idIndexMarker948"/> executed with the TensorFlow <a id="_idIndexMarker949"/>Network Executor node.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">To use the ONNX nodes, you need to install the <strong class="bold">KNIME Deep Learning – ONNX Integration</strong> extension.</p>
			<p>Another option for reading a network using Python code is the <strong class="bold">DL Python Network Creator</strong> node, which can be<a id="_idIndexMarker950"/> used to read pretrained neural networks using a few lines of Python code.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The DL Python Network Creator node can also be used in training workflows to define the network architecture using Python code instead of layer nodes.</p>
			<p>So far, we have used Keras-based nodes with TensorFlow 1 as the backend. There are also nodes that use TensorFlow 2 as the backend to implement similar operations.</p>
			<h2 id="_idParaDest-186"><a id="_idTextAnchor371"/>Using TensorFlow 2</h2>
			<p>For all the <a id="_idIndexMarker951"/>examples in this book, we have used Keras-based nodes that run TensorFlow 1 as the backend. TensorFlow 2 is also supported since the release of KNIME Analytics Platform 4.2. On the KNIME Hub, you can find many examples of how to use TensorFlow 2 integration.</p>
			<p>The TensorFlow 2 integration<a id="_idIndexMarker952"/> comes with three nodes:</p>
			<ul>
				<li><strong class="bold">The TensorFlow 2 Network Executor</strong> node</li>
				<li><strong class="bold">The TensorFlow 2 Network Reader</strong> node</li>
				<li><strong class="bold">The TensorFlow 2 Network Writer</strong> node</li>
			</ul>
			<p>To train a deep learning model using TensorFlow 2 you can<a id="_idIndexMarker953"/> use the <strong class="bold">DL Python Network Learner</strong> node. </p>
			<p>Now that we have reviewed the many options to save and read neural networks, let's focus on building a simple deployment workflow.</p>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor372"/>Building a Simple Deployment Workflow</h1>
			<p>So far, in all the <a id="_idIndexMarker954"/>case studies we have explored, we have always performed some kind of preprocessing of the input data, such as encoding categorical features, encoding text, or normalizing data, to name just some of the adopted preprocessing steps. During deployment, the new incoming data must be prepared with the exact same preprocessing as the training data in order to be consistent with the task and with the input that the network expects.</p>
			<p>In this section, we use the sentiment analysis case study shown in <a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 7</em></a>, <em class="italic">Implementing NLP Applications</em>, as an example, and we build two deployment workflows for it. The goal of both workflows is to read new movie reviews from a database, predict the sentiment, and write the prediction into the database.</p>
			<p>In the first example, the preprocessing steps are implemented manually into the deployment workflow. In the second example, the <strong class="bold">Integrated Deployment</strong> feature is used.</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor373"/>Building a Deployment Workflow Manually, without Integrated Deployment</h2>
			<p>The deployment workflow<a id="_idIndexMarker955"/> should access new reviews from a table in a database, apply the trained network, write the reviews with the corresponding predictions into another table in the database, and delete the reviews from the first table.</p>
			<p>These steps are performed by the workflow in <em class="italic">Figure 10.1</em>, which you can download from the KNIME Hub at <a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/">https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/lat<span id="_idTextAnchor374"/>est/Chapter_10/</a>:</p>
			<div>
				<div id="_idContainer865" class="IMG---Figure">
					<img src="image/B16391_10_001.jpg" alt="Figure 10.1 – Deployment workflow for the sentiment analysis case study from Chapter 7, Implementing NLP Applications"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – Deployment workflow for the sentiment analysis case study from <a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 7</em></a>, Implementing NLP Applications</p>
			<p>The workflow first <a id="_idIndexMarker956"/>connects to a SQLite database, where<a id="_idIndexMarker957"/> the new movie reviews are stored, using the <strong class="bold">SQLite Connector</strong> node.</p>
			<p>Next, the <strong class="bold">SELECT</strong> SQL statement to read the new reviews from the table named <strong class="bold">new_reviews </strong>is implemented <a id="_idIndexMarker958"/>by the <strong class="bold">DB Table Selector</strong> node. </p>
			<p>The SQL statement is then executed <a id="_idIndexMarker959"/>through the <strong class="bold">DB Reader</strong> node. As a result, we have the new reviews in a data table at the output port of the node.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">In <a href="B16391_02_Final_SK_ePUB.xhtml#_idTextAnchor051"><em class="italic">Chapter 2</em></a>, <em class="italic">Data Access and Preprocessing with KNIME Analytics Platform</em>, the database extension was introduced in detail. Remember that the database nodes create a SQL statement at their output brown-squared port.</p>
			<p>Before applying the network to these new reviews, we need to perform the same transformations as in the training workflow. In the training workflow, reported in <a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 7</em></a>, <em class="italic">Implementing NLP Applications</em>, there was a metanode named <strong class="bold">Preprocess test set</strong> where all the required preprocessing steps were applied to the test data. We used this metanode as the basis for creating the preprocessing steps for the incoming data in the deployment workflow.</p>
			<p><em class="italic">Figure 10.2</em> shows the content of this<a id="_idIndexMarker960"/> metanode, which is dedicated to the preprocess<a id="_idTextAnchor375"/>ing of the test set:</p>
			<div>
				<div id="_idContainer866" class="IMG---Figure">
					<img src="image/B16391_10_002.jpg" alt="Figure 10.2 – Preprocessing of the test data in the training workflow of the sentiment analysis case study from Chapter 7, Implementing NLP Applications"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – Preprocessing of the test data in the training workflow of the sentiment analysis case study from <a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 7</em></a>, Implementing NLP Applications</p>
			<p>In the deployment workflow in <em class="italic">Figure 10.1</em>, the dictionary, created during training is read first; then the preprocessing steps are implemented in the <strong class="bold">Preprocessing</strong> metanode. </p>
			<p><em class="italic">Figure 10.3</em> shows you the workflow snippet in<a id="_idTextAnchor376"/>side this metanode:</p>
			<div>
				<div id="_idContainer867" class="IMG---Figure">
					<img src="image/B16391_10_003.jpg" alt="Figure 10.3 – Workflow snippet inside the Preprocessing metanode of the deployment workflow"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – Workflow snippet inside the Preprocessing metanode of the deployment workflow</p>
			<p>If we compare the <a id="_idIndexMarker961"/>workflow snippets in <em class="italic">Figure 10.2</em> and <em class="italic">Figure 10.3</em>, you can see that they contain the same preprocessing steps, as was expected.</p>
			<p>Now that the same preprocessing as for the training data has been applied to the deployment data, the trained network can be introduced <a id="_idIndexMarker962"/>through the <strong class="bold">Keras Network Reader</strong> node (<em class="italic">Figure 10.1</em>).</p>
			<p>Next, the trained network runs on the preprocessed deployment reviews using the <strong class="bold">Keras Network Executor</strong> node. The<a id="_idIndexMarker963"/> output of the network is the probability of the sentiment being equal to 1, where 1 encodes a positive movie review. The same threshold as during training is also applied here through the <strong class="bold">Rule Engine</strong> node: a threshold of <img src="image/Formula_B16391_10_001.png" alt=""/>.</p>
			<p>In the last step, the tables in the database are updated. First, the <strong class="bold">DB Delete</strong> node deletes the reviews we just analyzed from the <strong class="bold">new_reviews</strong> table. Then, the <strong class="bold">DB Writer</strong> node appends the new movie reviews with their predictions to another table in the database, named <strong class="bold">review-with-sentiment</strong>.</p>
			<p>This is the first example of the deployment of a neural network using KNIME Analytics Platform. This workflow should be executed on a regular basis to predict the sentiment for all new incoming movie reviews.</p>
			<p class="callout-heading">Tip </p>
			<p class="callout">KNIME Server can schedule the execution of workflows, so you can trigger their execution automatically on a regular schedule.</p>
			<p>This <a id="_idIndexMarker964"/>approach has one disadvantage. If the model is retrained on more data or with different settings (for example, if more or fewer terms are taken into account during training or the threshold for the Rule Engine node is changed) we need to remember to also update the preprocessing steps in the deployment workflow. And since we are forgetful humans, we might forget or make mistakes.</p>
			<p>A solution to overcome this issue is the concept of <strong class="bold">Integrated Deployment</strong>.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor377"/>Building a Deployment Workflow Automatically with Integrated Deployment</h2>
			<p>Until KNIME Analytics<a id="_idIndexMarker965"/> Platform 4.2, as well as in other tools, a common approach was to implement data blending, data transformation, and network execution manually in the deployment workflow. This means that you need to copy the different preprocessing snippets, parameters, and network executor nodes from the training workflow to the deployment workflow, making sure that all settings remain unaltered. </p>
			<p>This manual step slows down the process and can easily lead to mistakes. Automating the construction of parts of the deployment workflow can be a safer option, especially if the models are changed often, for example, every day or even every hour.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Other common names for the training process are data science creation or modeling workflow.</p>
			<p>The nodes from the Integrated Deployment extension close the gap between creating and deploying data science.</p>
			<h3>The Integrated Deployment Extension</h3>
			<p>The Integrated Deployment extension allows data scientists to combine the model training <a id="_idIndexMarker966"/>and deployment into one single workflow. The idea is to capture parts of the training workflow and to automatically write them into the deployment workflow during the execution of the training workflow.</p>
			<p>Instead of copying the<a id="_idIndexMarker967"/> preprocessing parts manually, one by one, the required parts from the training workflow are<a id="_idIndexMarker968"/> captured in between the <strong class="bold">Capture Workflow Start</strong> and <strong class="bold">Capture Workflow End</strong> nodes. The captured workflow part in the middle can then be written into a new workflow <a id="_idIndexMarker969"/>with a <strong class="bold">Workflow Writer</strong> node. </p>
			<h3>Using the Integrated Deployment Extension in the Training Workflow</h3>
			<p>Let's consider <a id="_idIndexMarker970"/>again the deployment workflow for the sentiment analysis case study described in <a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 7</em></a>, <em class="italic">Implementing NLP Applications</em>. In the training workflow, we have introduced the <strong class="bold">Capture Workflow Start</strong> node and the <strong class="bold">Capture Workflow End</strong> node to isolate the workflow snippet that we want to reproduce exactly in the deployment workflow.</p>
			<p>This includes the following:</p>
			<ul>
				<li>The metanode named <strong class="bold">Preprocessing test set</strong>, including all required preprocessing steps</li>
				<li>The <strong class="bold">Keras Network Executor</strong> node<a id="_idIndexMarker971"/> to apply the trained network on the deployment transformed data</li>
				<li>The <strong class="bold">Rule Engine</strong> node, which <a id="_idIndexMarker972"/>decides on the positive or the negative class based on a threshold applied to the output class' probability</li>
			</ul>
			<p>The workflow in <em class="italic">Figure 10.4</em> shows you this example based on the sentiment analysis case study. You can download the workflow from the KNIME Hub at <a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/">https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with<span id="_idTextAnchor378"/>%20KNIME/latest/Chapter_10/</a>:</p>
			<div>
				<div id="_idContainer869" class="IMG---Figure">
					<img src="image/B16391_10_004.jpg" alt="Figure 10.4 – Training workflow that automatically creates a deployment workflow using Integrated Deployment"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – Training workflow that automatically creates a deployment workflow using Integrated Deployment</p>
			<p>The part in the <a id="_idIndexMarker973"/>thick box is the captured workflow snippet. The <strong class="bold">Capture Workflow Start</strong> node defines the beginning and the <strong class="bold">Capture Workflow End</strong> node defines the end of the workflow snippet to capture.</p>
			<p>The start node doesn't need any configuration. <em class="italic">Figure 10.5</em> shows the configuration window of th<a id="_idTextAnchor379"/>e <strong class="bold">Capture Workflow End</strong> node:</p>
			<div>
				<div id="_idContainer870" class="IMG---Figure">
					<img src="image/B16391_10_005.jpg" alt="Figure 10.5 – Configuration window of the Capture Workflow End node"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – Configuration window of the Capture Workflow End node</p>
			<p>In the <a id="_idIndexMarker974"/>configuration window, you can set the name of the captured workflow snippet. You can also set whether the captured snippet should be stored with the data and, if yes, the maximum number of data rows to include. We will see in a second why it can be helpful to store some data in the captured workflow snippet.</p>
			<p>The captured workflow snippet, with or without data, is then exported via the output port (the black square) of the <strong class="bold">Capture Workflow End</strong> node. In the workflow in <em class="italic">Figure 10.4</em>, the workflow snippet is then collected by<a id="_idIndexMarker975"/> the <strong class="bold">Workflow Writer</strong> node and written into the deployment workflow, with unaltered settings and configuration. </p>
			<p><em class="italic">Figure 10.6</em> shows the configuration window<a id="_idTextAnchor380"/> of the <strong class="bold">Workflow Writer</strong> node:</p>
			<div>
				<div id="_idContainer871" class="IMG---Figure">
					<img src="image/B16391_10_006.jpg" alt="Figure 10.6 – The Workflow Writer node and its configuration window"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6 – The Workflow Writer node and its configuration window</p>
			<p>At the top, you can <a id="_idIndexMarker976"/>set the location of the folder of the destination workflow (<strong class="bold">Output location</strong>). </p>
			<p>Next, you need to set the name of the destination workflow. The node automatically proposes a default name, which you can customize via the <strong class="bold">Use custom workflow name</strong> option. If the name you choose refers to a workflow that already exists, you can let the writer node fail or overwrite.</p>
			<p>At the bottom, you can select the deployment option for the destination workflow: just create it, create it and open it, or save it as a <strong class="source-inline">.knwf</strong> file to export.</p>
			<p>The next figure, <em class="italic">Figure 10.7</em>, shows you the automatically generated deployment workflow<a id="_idTextAnchor381"/> by the <strong class="bold">Workflow Writer</strong> node:</p>
			<div>
				<div id="_idContainer872" class="IMG---Figure">
					<img src="image/B16391_10_007.jpg" alt="Figure 10.7 – Automatically created deployment workflow from the workflow snippet captured via Integrated Deployment"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7 – Automatically created deployment workflow from the workflow snippet captured via Integrated Deployment</p>
			<p>In the captured <a id="_idIndexMarker977"/>workflow you can see the <strong class="bold">Preprocessing test set</strong> metanode, as well as the <strong class="bold">Keras Network Executor</strong>, <strong class="bold">Rule Engine</strong>, and <strong class="bold">Column Filter</strong> nodes. Additionally, the whole Integrated Deployment process has added the following: </p>
			<ul>
				<li>Two <strong class="bold">Reference Reader</strong> nodes. They are generic reader nodes, loading the connection information of static parameters not found in the captured workflow snippet.</li>
				<li>A <strong class="bold">Container Input (Table)</strong> and a <strong class="bold">Container Output (Table)</strong> node in order to accept input data and to <a id="_idIndexMarker978"/>send output data respectively <a id="_idIndexMarker979"/>from and to other applications.</li>
			</ul>
			<p>The execution of this deployment workflow can be triggered either by another workflow using the <strong class="bold">Call Workflow (Table)</strong> node <a id="_idIndexMarker980"/>or via a REST service if the workflow has been deployed on a KNIMEs Server. In the next chapter, we will talk about the REST calls and REST services in detail.</p>
			<p>In <em class="italic">Figure 10.7</em>, the example deployment workflow reads two entities at the top of the workflow using the two reader nodes without an icon inside them. The left one provides the dictionary table based on the training data, and the right one provides the trained neural network.</p>
			<p>In addition, you can see two more new nodes, which are the <strong class="bold">Container Input (Table)</strong> and <strong class="bold">Container Output (Table)</strong> nodes.</p>
			<p>The <strong class="bold">Container Input (Table)</strong> node receives a data table from an external caller (that is, the <strong class="bold">Call Workflow (Table Based)</strong> node) and makes it available on the output port. A configuration parameter enables the external caller to send a data table to the <strong class="bold">Container Input (Table)</strong> node.</p>
			<p>The <strong class="bold">Container Input (Table)</strong> node also has an optional input port (represented by an unfilled input port). If a data table is connected to the optional input, the node will simply forward this table to the next node; if a table is supplied via a REST API, then the supplied table <a id="_idIndexMarker981"/>will be available on the output port.</p>
			<p>If no input is given, a default template table will be provided on the output of the node. Here, the <strong class="bold">Store input tables</strong> setting from the <strong class="bold">Capture Workflow End</strong> node comes in. If you select to store some data rows, they are used to define this default template table.</p>
			<p>The <strong class="bold">Container Output (Table)</strong> node sends a KNIME data table to an external caller.</p>
			<p>Let's now find out how the automatically created workflow can be used to predict the sentiment of new reviews during deployment.</p>
			<h3>Using the Automatically Created Workflow</h3>
			<p>Let's have a look now at how the deployment workflow can be consumed.</p>
			<p><em class="italic">Figure 10.8</em> shows you an example of how the automatically created deployment workflow<a id="_idIndexMarker982"/> can be consumed to classify the sentiment of new movie reviews, and you can download it from the KNIME Hub to try it out, at <a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/">https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/</a> :</p>
			<p class="figure-caption">:<a id="_idTextAnchor382"/>
Figure 10.8 – Workflow calling the automatically created deployment workflow</p>
			<div>
				<div id="_idContainer873" class="IMG---Figure">
					<img src="image/B16391_10_008.jpg" alt="Figure 10.8 – Workflow calling the automatically created deployment workflow"/>
				</div>
			</div>
			<p>The workflow<a id="_idIndexMarker983"/> connects to the database and reads the incoming new movie reviews. </p>
			<p>Then, the <strong class="bold">Call Workflow (Table Based)</strong> node calls the deployment workflow (<em class="italic">Figure 10.7</em>), the one that was automatically built. The <strong class="bold">Call Workflow (Table Based)</strong> node indeed calls other workflows residing on your local workspace or on a mounted KNIME server. The called workflow must contain at least one Container Input node and one Container Output node to define the interface between the two workflows: the called and the caller workflows.</p>
			<p>Via the <strong class="bold">Call Workflow (Table Based)</strong> node, we send the new movie reviews to the deployment workflow to feed the <strong class="bold">Container Input (Table)</strong> node. The deployment workflow is then executed, and the predictions are sent back to the caller workflow and made available via the output port of the <strong class="bold">Call Workflow (Table Based)</strong> node. </p>
			<p>A great advantage of this strategy is the ensured consistency between the data operations in the training workflow and the data operations in the deployment workflow. If we now change any settings in the data operations in the training workflow, for example, the value of the threshold in the <strong class="bold">Rule Engine</strong> node (<em class="italic">Figure 10.4</em>), and we re-execute the training workflow, these changes are automatically imported into the new version of the deployment workflow (<em class="italic">Figure 10.7</em>) and used by any workflow relying on it (<em class="italic">Figure 10.8</em>).</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Another great node of the <strong class="bold">Integrated Deployment </strong>extension is the <strong class="bold">Workflow Combiner</strong> node, which allows us to combine workflow snippets from different original workflows.</p>
			<p>We have reached the last section of this chapter, which is on scalability and GPU execution.</p>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor383"/>Improving Scalability – GPU Execution</h1>
			<p>For the case studies<a id="_idIndexMarker984"/> described in this book, we have used relatively small datasets and small networks. This allowed us to train the networks within hours using only CPU-based execution. However, training tasks that take minutes or hours on small datasets can easily take days or weeks on larger datasets; small network architectures can <a id="_idIndexMarker985"/>quickly increase in size and execution times can quickly become prohibitive. In general, when working with deep neural networks, the training phase is the most resource-intensive task.</p>
			<p>GPUs have been designed to handle multiple computations simultaneously. This paradigm suits the intensive computations required to train a deep learning network. Hence, GPUs are an alternative option to train large deep learning networks efficiently and effectively on large datasets.</p>
			<p>Some Keras libraries can exploit the computational power of NVIDIA®-compatible GPUs via the TensorFlow paradigms. As a consequence, <strong class="bold">KNIME Keras integration</strong> can also exploit the computational power of GPUs to train deep learning networks more quickly. </p>
			<p>In <a href="B16391_01_Final_NM_ePUB.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Deep Learning with KNIME Analytics Platform</em>, we introduced how to set up Python for KNIME Keras integration and KNIME TensorFlow integration. In order to run the KNIME Keras integration on the GPU rather than on the CPU, you do not need to take many extra steps.</p>
			<p>Of course, you need a GPU-enabled computer. TensorFlow 1.12 requires an NVIDIA GPU card with a CUDA compute capability of 3.5 or higher.</p>
			<p>Besides that, most of the required dependencies (that is, CUDA® and cuDNN) will be automatically installed by Anaconda when installing the conda <strong class="source-inline">tensorflow=1.12</strong> and <strong class="source-inline">keras-gpu=2.2.4</strong>. packages</p>
			<p>The only extra step at installation is the latest version of the NVIDIA® GPU driver, to be installed manually. </p>
			<p>At installation time, by selecting <strong class="bold">Create new GPU environment</strong> instead of <strong class="bold">Create new CPU environment</strong>, an environment with <strong class="source-inline">keras-gpu=2.2.4</strong> is created.</p>
			<p>When using the TensorFlow integration, it is also <a id="_idIndexMarker986"/>possible to execute on the GPU to read and execute <a id="_idIndexMarker987"/>TensorFlow's SavedModel. </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The GPU support for the <strong class="bold">KNIME TensorFlow integration</strong> (which uses the TensorFlow Java API) is generally independent of the GPU support for the <strong class="bold">KNIME Keras integration</strong> (which uses Python). Hence, the two GPU supports must be set up individually. Due to the limitations of TensorFlow, the GPU support for the KNIME TensorFlow integration can only run on Windows and Linux, and not on Mac.</p>
			<p>At the time of writing, the following GPU configuration is recommended by KNIME.</p>
			<p>The KNIME TensorFlow integration uses TensorFlow version 1.13.1, which requires the following NVIDIA® software to be installed on your system: </p>
			<ul>
				<li>NVIDIA® GPU drivers: CUDA® 10.0 requires 410.x or higher. </li>
				<li>CUDA® Toolkit: TensorFlow (≥ 1.13.0) supports CUDA® 10.0. </li>
				<li>cuDNN (version ≥ 7.4.1): Select cuDNN v7.6.0 (May 20, 2019) for CUDA® 10.0.</li>
			</ul>
			<p>For detailed instructions and the most recent updates, please check the KNIME documentation (<a href="https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#tensorflow-integration">https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#tensorflow-integration</a>).</p>
			<h1 id="_idParaDest-191"><a id="_idTextAnchor384"/>Summary</h1>
			<p>In this chapter, we have covered three different topics. We started with a summary of the many options for reading, converting, and writing neural networks.</p>
			<p>We then moved on to the deployment of neural networks, using the sentiment analysis case study from <a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"><em class="italic">Chapter 7</em></a>, <em class="italic">Implementing NLP Applications</em>, as an example. The goal here was to build a workflow that uses the trained neural network to predict the sentiment of new reviews stored in the database. We have shown that a deployment workflow can be assembled in two ways: manually or automatically with Integrated Deployment.</p>
			<p>The last section of the chapter dealt with the scalability of network training and execution. In particular, it showed how to exploit the computational power of GPUs when training a neural network.</p>
			<p>In the next and last chapter of this book, we will explore further deployment options and best practices when working with deep learning.</p>
			<h1 id="_idParaDest-192"><a id="_idTextAnchor385"/>Questions and Exercises</h1>
			<ol>
				<li>Which network conversions are available in KNIME Analytics Platform?<p>a) Keras to TensorFlow network conversion</p><p>b) TensorFlow to Keras network conversion</p><p>c) ONNX to Keras network conversion</p><p>d) Keras to ONNX network conversion</p></li>
				<li>Which statements regarding Integrated Deployment are true (two statements are correct)?<p>a) Integrated Deployment allows us to retrain a model during execution.</p><p>b) The execution of the automatically generated workflow can be triggered by another workflow.</p><p>c) The execution of the training workflow is triggered by the deployment workflow.</p><p>d) Integrated Deployment closes the gap between training and deployment.</p></li>
			</ol>
		</div>
	</body></html>