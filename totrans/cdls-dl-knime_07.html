<html><head></head><body>
		<div id="_idContainer427">
			<h1 id="_idParaDest-81"><em class="italic"><a id="_idTextAnchor152"/>Chapter 5: </em>Autoencoder for Fraud Detection</h1>
			<p>At this point in the book, you should already know the basic math and concepts behind neural networks and some deep learning paradigms, as well as the most useful KNIME nodes for data preparation, how to build a neural network, how to train it and test it, and finally, how to evaluate it. We have built together, in <a href="B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a>, <em class="italic">Building and Training a Feedforward Neural Network</em>, two examples of fully connected feedforward neural networks: one to solve a multiclass classification problem on the Iris dataset and one to solve a binary classification problem on the Adult dataset.</p>
			<p>Those were two simple examples using quite small datasets, in which all the classes were adequately represented, with just a few hidden layers in the network and a straightforward encoding of the output classes. However, they served their purpose: to teach you how to assemble, train, and apply a neural network in KNIME Analytics Platform.</p>
			<p>Now, the time has come to explore more realistic examples and apply more complex neural architectures and more advanced deep learning paradigms in order to solve more complicated problems based sometimes on ill-conditioned datasets. In the following chapters, you will look at some of these more realistic case studies, requiring some more creative solutions than just a fully connected feedforward network for classification.</p>
			<p>We will start with a binary classification problem with a dataset that has data from only one of the two classes. Here, the classic classification approach cannot work, since one of the two classes is missing from the training set. There are many problems of this kind, such as anomaly detection to predict mechanical failures or fraud detection to distinguish legitimate from fraudulent credit card transactions.</p>
			<p>This chapter investigates an alternative neural approach to design a solution for this extreme situation in fraud detection: the <strong class="bold">autoencoder</strong> architecture.</p>
			<p>We will cover the following topics:</p>
			<ul>
				<li>Introducing Autoencoders</li>
				<li>Why is Fraud Detection so hard?</li>
				<li>Building and Training the Autoencoder</li>
				<li>Optimizing the Autoencoder Strategy</li>
				<li>Deploying the Fraud Detector</li>
			</ul>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor153"/>Introducing Autoencoders</h1>
			<p>In <a id="_idIndexMarker400"/>previous chapters, we have seen that neural networks are very powerful algorithms. The power of each network lies in its architecture, activation functions, and regularization terms, plus a few other features. Among the varieties of neural architectures, there is a very versatile one, especially useful for three tasks: detecting unknown events, detecting unexpected events, and reducing the dimensionality of the input space. This neural network is the <strong class="bold">autoencoder</strong>.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor154"/>Architecture of the Autoencoder</h2>
			<p>The <a id="_idIndexMarker401"/>autoencoder (or <strong class="bold">autoassociator</strong>) is a multilayer feedforward neural network, trained to reproduce the <a id="_idIndexMarker402"/>input vector onto the output layer. Like many neural networks, it is trained using the gradient descent algorithm, or one of its modern variations, against<a href="https://keras.io/losses/"> a loss funct</a>ion, such as the <strong class="bold">Mean Squared Error</strong> (<strong class="bold">MSE</strong>). It can <a id="_idIndexMarker403"/>have as many hidden layers as desired. Regularization terms and other general parameters that are useful for avoiding overfitting or for improving the learning process can be applied here as well.</p>
			<p>The only constraint on the architecture is that the number of input units must be the same as the number of output units, as the goal is to train the autoencoder to reproduce the input vector onto the output layer.</p>
			<p>The simplest autoencoder has only three layers: one input layer, one hidden layer, and one output layer. More complex structured autoencoders might include additional hidden layers:</p>
			<div>
				<div id="_idContainer353" class="IMG---Figure">
					<img src="image/B16391_05_001.jpg" alt="Figure 5.1 – A simple autoencoder"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – A simple autoencoder</p>
			<p>Autoencoders can <a id="_idIndexMarker404"/>be used for many different tasks. Let's first see how an autoencoder can be used for dimensionality reduction.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor155"/>Reducing the Input Dimensionality with an Autoencoder</h2>
			<p>Let's <a id="_idIndexMarker405"/>consider an <a id="_idIndexMarker406"/>autoencoder with a very simple architecture: one input layer with <img src="image/Formula_B16391_03_252.png" alt=""/> units; one output layer, also with <img src="image/Formula_B16391_05_002.png" alt=""/> units; and one hidden layer with <img src="image/Formula_B16391_03_042.png" alt=""/> units. If <img src="image/Formula_B16391_05_004.png" alt=""/>, the autoencoder produces a compression of the input vector onto the hidden layer, reducing its dimensionality from <img src="image/Formula_B16391_05_005.png" alt=""/> to <img src="image/Formula_B16391_03_044.png" alt=""/>.</p>
			<p>In this case, the first part of the network, moving the data from a vector with size <img src="image/Formula_B16391_05_007.png" alt=""/> to a vector with size <img src="image/Formula_B16391_05_008.png" alt=""/>, plays the role of the encoder. The second part of the network, reconstructing the input vector from a <img src="image/Formula_B16391_05_009.png" alt=""/> space back into a <img src="image/Formula_B16391_05_010.png" alt=""/> space, is the <a id="_idIndexMarker407"/>decoder. The compression rate is<a id="_idIndexMarker408"/> then <img src="image/Formula_B16391_05_011.png" alt=""/>. The larger the value of <img src="image/Formula_B16391_03_029.png" alt=""/> and the smaller the value of <img src="image/Formula_B16391_05_013.png" alt=""/>, the higher the compression rate:</p>
			<div>
				<div id="_idContainer367" class="IMG---Figure">
					<img src="image/B16391_05_002.jpg" alt="Figure 5.2 – Encoder and decoder subnetworks in a three-layer autoencoder"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.2 – Encode<a id="_idTextAnchor156"/>r and decoder subnetworks in a three-layer autoencoder</p>
			<p>When using the autoencoder for <strong class="bold">dimensionality reduction</strong>, the full network is first trained to reproduce<a id="_idIndexMarker409"/> the input vector onto the output layer. Then, before<a id="_idIndexMarker410"/> deployment, it is split into<a id="_idIndexMarker411"/> two parts: the <strong class="bold">encoder</strong> (input layer and hidden layer) and the <strong class="bold">decoder</strong> (hidden layer and output layer). The two subnetworks are stored separately.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If you are interested in the output of the bottleneck layer, you can configure the <strong class="bold">Keras Network Executor</strong> node to output<a id="_idIndexMarker412"/> the middle layer. Alternatively, you can split the network within the <strong class="bold">DL Python Network Editor</strong> node by writing a <a id="_idIndexMarker413"/>few lines of Python code.</p>
			<p>During the<a id="_idIndexMarker414"/> deployment phase, in order to<a id="_idIndexMarker415"/> compress an input record, we just pass it through the encoder and save the output of the hidden layer as the compressed record. Then, in order to reconstruct the original vector, we pass the compressed record through the decoder and save the output values of the output layer as the reconstructed vector.</p>
			<p>If a more complex structure is used for the autoencoder – for example, with more than one hidden layer – one of the hidden layers must work as the compressor output, producing the compressed record and separating the encoder from the decoder subnetwork.</p>
			<p>Now, the question when we talk about data compression is how faithfully can the original record be reconstructed? How much information is lost by using the output of the hidden layer instead of the original data vector? Of course, this all depends on how well the autoencoder performs and how large our error tolerance is.</p>
			<p>During testing, when<a id="_idIndexMarker416"/> we apply the network to new data, we denormalize the output values and we calculate the chosen error metric – for example, the <strong class="bold">Root Mean Square Error</strong> (<strong class="bold">RMSE</strong>) – between the original input <a id="_idIndexMarker417"/>data and the reconstructed data on the whole<a id="_idIndexMarker418"/> test set. This error value gives us a measure of the quality of the reconstructed data. Of course, the higher the compression rate, the higher the reconstruction error. The problem thus becomes to train the network to achieve acceptable performance, as per our error tolerance.</p>
			<p>Let's move on to the next application field of autoencoders: anomaly detection.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor157"/>Detecting Anomalies Using an Autoencoder</h2>
			<p>In most classification/prediction problems, we have a set of examples covering all event classes and<a id="_idIndexMarker419"/> based on this dataset, we train a model to classify events. However, sometimes, the event class we want to predict is so rare and unexpected that no (or almost no) examples are available at all. In this case, we do not talk about classification or<a id="_idIndexMarker420"/> prediction but about <strong class="bold">anomaly detection</strong>.</p>
			<p>An anomaly can be any rare, unexpected, unknown event: a cardiac arrhythmia, a mechanical breakdown, a fraudulent transaction, or other rare, unexpected, unknown events. In this case, since no examples of anomalies are available in the training set, we need to use neural networks in a more creative way than for conventional, standard classification. The autoencoder structure lends itself to such creative usage, as required for the solution of an anomaly detection problem (see, for example, A.G. Gebresilassie, <em class="italic">Neural Networks for Anomaly (Outliers) Detection</em>, <a href="https://blog.goodaudience.com/neural-networks-for-anomaly-outliers-detection-a454e3fdaae8">https://blog.goodaudience.com/neural-networks-for-anomaly-outliers-detection-a454e3fdaae8</a>).</p>
			<p>Since no anomaly examples are available, the autoencoder is trained only on non-anomaly examples. Let's call these examples of the "normal" class. On a training set full of "normal" data, the autoencoder network is trained to reproduce the input feature vector onto the output layer.</p>
			<p>The idea is<a id="_idIndexMarker421"/> that, when required to reproduce a vector of the "normal" class, the autoencoder is likely to perform a decent job because that is what it was trained to do. However, when required to reproduce an anomaly on the output layer, it will hopefully fail because it won't have seen this kind of vector throughout the whole training phase. Therefore, if we calculate the distance – any distance – between the original vector and the reproduced vector, we see a small distance for input vectors of the "normal" class and a much larger distance for input vectors representing an anomaly.</p>
			<p>Thus, by setting a threshold, <img src="image/Formula_B16391_05_052.png" alt=""/>, we should be able to detect anomalies with the following rule:</p>
			<p>IF <img src="image/Formula_B16391_05_015.png" alt=""/> THEN <img src="image/Formula_B16391_05_016.png" alt=""/> -&gt; "normal"</p>
			<p>IF <img src="image/Formula_B16391_05_017.png" alt=""/> THEN <img src="image/Formula_B16391_05_018.png" alt=""/> -&gt; "anomaly"</p>
			<p>Here, <img src="image/Formula_B16391_05_019.png" alt=""/> is the reconstruction error for the input vector, <img src="image/Formula_B16391_05_018.png" alt=""/>, and <img src="image/Formula_B16391_05_021.png" alt=""/> is the set threshold.</p>
			<p>This sort of<a id="_idIndexMarker422"/> solution has already been implemented successfully for fraud detection, as described in a blog post, <em class="italic">Credit Card Fraud Detection using Autoencoders in Keras  -- TensorFlow for Hackers (Part VI</em><a href="https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd"><em class="italic">I)</em>, by Venelin Valkov (https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hacker</a>s-part-vii-20e0c85301bd). In this chapter, we will use the same idea to build a similar solution using a different autoencoder structure.</p>
			<p>Let's find out how the idea of an autoencoder can be used to detect fraudulent transactions.</p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor158"/>Why is Detecting Fraud so Hard?</h1>
			<p><strong class="bold">Fraud detection</strong> is<a id="_idIndexMarker423"/> a set of activities undertaken to prevent money or property from being obtained through false pretenses. Fraud detection is applied in many industries, such as banking or insurance. In banking, fraud may include forging checks or using stolen credit cards. For this example, we will focus on fraud in credit card transactions.</p>
			<p>This kind of fraud, in credit card transactions, is a huge problem for credit card issuers as well as for the final payers. The European Central Bank reported that in 2016, the total number of card fraud cases using cards <a id="_idIndexMarker424"/>issued in the <strong class="bold">Single Euro Payments Area</strong> (<strong class="bold">SEPA</strong>) amounted to 17.3 million, and the total number of card transactions using cards issued in SEPA amounted to 74.9 billion (<a href="https://www.ecb.europa.eu/pub/cardfraud/html/ecb.cardfraudreport201809.en.html#toc1">https://www.ecb.europa.eu/pub/cardfraud/html/ecb.cardfraudreport201809.en.html#toc1</a>).</p>
			<p>However, the amount of<a id="_idTextAnchor159"/> fraud is not the only problem. From a data science perspective, fraud detection is also a very hard task to solve, because of the small amount of data available on fraudulent transactions. That is, often we have tons of data on legitimate credit card transactions and just a handful on fraudulent transactions. A classic approach (training, then applying a model) is not possible in this case since the examples for one of the two classes are missing.</p>
			<p>Fraud detection, however, can also be seen as anomaly detection. Anomaly detection is any event that is unexpected within a dataset. A fraudulent transaction is indeed an unexpected event and therefore we can consider it an anomaly in a dataset of legitimate <em class="italic">normal</em> credit card transactions.</p>
			<p>There are a few different <a id="_idIndexMarker425"/>approaches to fraud detection.</p>
			<p>One option is the discriminative approach. Based on a training set with both classes, legitimate and fraudulent transactions, we build a model that distinguishes between data from the two classes. This could be a simple threshold-based rule or a supervised machine learning model. This is the classic approach based on a training set including enough examples from both classes.</p>
			<p>Alternatively, you can treat a fraud detection problem as outlier detection. In this case, you can use a clustering <a id="_idIndexMarker426"/>algorithm that leaves space for outliers (noise), such as <strong class="bold">DBSCAN</strong>; or you can use the <strong class="bold">isolation forest technique</strong>, which isolates outliers with just a few cuts with<a id="_idIndexMarker427"/> respect to legitimate data. Fraudulent transactions, though, must belong to the original dataset, to be isolated as outliers.</p>
			<p>A<a href="https://en.wikipedia.org/wiki/Generative_model">nother app</a>roach, called the <strong class="bold">generative approach</strong>, involves using only legitimate transactions during the training<a id="_idIndexMarker428"/> phase. This allows us to reproduce the input vector onto the output layer. Once the model for the autoencoder has been trained, we use it during deployment to reproduce the input transaction. We then calculate the distance (or error) between the input values and the output values. If that distance falls below a given threshold, the transaction is likely to be legitimate; otherwise, it is flagged as a fraud candidate.</p>
			<p>In this example, we will us<a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">e the </a>credit card dataset by Kaggle. This dataset contains credit card transactions from European cardholders in September 2013. Fraudulent transactions have been labeled with <strong class="source-inline">1</strong>, while legitimate transactions are labeled with <strong class="source-inline">0</strong>. The dataset contains 284,807 transactions, but only 492 (0.2%) of them are fraudulent. Due to privacy reasons, principal components are used instead of the original transaction features. Thus, each credit card transaction is re<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">presented by 30 featu</a>res: 28 principal components extracted from the original credit card data, the transaction time, and the transaction amount.</p>
			<p>Let's proceed with the building, training, and testing of the autoencoder.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor160"/>Building and Training the Autoencoder</h1>
			<p>Let's go into <a id="_idIndexMarker429"/>detail about the particular application we will build to tackle <a id="_idIndexMarker430"/>fraud detection with a neural autoencoder. Like all data science projects, it includes two separate applications: one to train and optimize the whole strategy on dedicated datasets, and one to set it in action to analyze real-world credit card transactions. The first application is implemented with the <strong class="bold">training workflow</strong>; the second application is implemented with the <strong class="bold">deployment workflow</strong>.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Often, training and deployment are separate applications since they work on different data and have different goals.</p>
			<p>The training workflow uses a lab dataset to produce an acceptable model to implement the task, sometimes requiring a few different trials. The deployment workflow does not change the model or the strategy anymore; it just applies it to real-world transactions to get fraud alarms.</p>
			<p>In this section, we will focus on <a id="_idIndexMarker431"/>the training phase, including the following steps:</p>
			<ul>
				<li><strong class="bold">Data Access</strong>: Here, we read the lab data from the file, including all 28 principal components, the transaction amount, and the corresponding time.</li>
				<li><strong class="bold">Data Preparation</strong>: The data comes already clean and transformed via <strong class="bold">Principal Component Analysis</strong> (<strong class="bold">PCA</strong>). What remains doing in this phase is to create all the data subsets required for the training, optimization, and testing of the neural autoencoder and the whole strategy.</li>
				<li><strong class="bold">Building the Neural Network</strong>: An autoencoder is a feedforward neural network with as many inputs as outputs. Let's then decide the number of hidden layers, the number of hidden neurons, and the activation functions in each layer, and then build it accordingly.</li>
				<li><strong class="bold">Training the Neural Autoencoder</strong>: In this part, the autoencoder is trained on a training set of just legitimate transactions with one of the training algorithms (the optimizers), according to the selected training parameters, such as, at least, the loss function, the number of epochs, and the batch size.</li>
				<li><strong class="bold">Rule for Fraud Alarms</strong>: After the network has been trained and it is able to reproduce legitimate transactions on the output layer, we need to complete the strategy by calculating the distance between the input and output layers and by setting a threshold-based rule to trigger fraud alarms.</li>
				<li><strong class="bold">Testing the whole Strategy</strong>: The<a id="_idIndexMarker432"/> last step is to test the whole strategy performance. How many legitimate transactions are correctly recognized? How many fraud alarms are correctly triggered and how many are false alarms?</li>
			</ul>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor161"/>Data Access and Data Preparation</h2>
			<p>The credit card dataset from<a id="_idIndexMarker433"/> Kaggle comes already clean and transformed. We <a id="_idIndexMarker434"/>now need to create all the data subsets. Specifically, we need a training and a validation set for the training of the autoencoder. They must consist of only legitimate transactions. The training set is used to train the network and the validation set is used to monitor the performance of the autoencoder on unseen data during training.</p>
			<p>Then, we need an additional data subset, the threshold optimization set, to optimize the threshold, <img src="image/Formula_B16391_05_052.png" alt=""/>, in the rule-based fraud alarm generator. This last subset should include all fraudulent transactions, in addition to a number of legitimate transactions, as follows:</p>
			<ul>
				<li>2/3 of all legitimate transactions are dedicated to the autoencoder.</li>
				<li>90% of those legitimate transactions<a id="_idIndexMarker435"/> form the <strong class="bold">training set</strong>.</li>
				<li>10% form<a id="_idIndexMarker436"/> the <strong class="bold">validation set</strong>.</li>
				<li>1/3 (96K) of all legitimate transactions and all 492 fraudulent transactions form the <strong class="bold">threshold optimization set</strong>, used to<a id="_idIndexMarker437"/> optimize the value of threshold <img src="image/Formula_B16391_05_023.png" alt=""/>.</li>
			</ul>
			<p>This all translates into one <strong class="bold">Row Splitter</strong> node<a id="_idIndexMarker438"/> to separate legitimate transactions from fraudulent transactions, one <strong class="bold">Concatenate</strong> node<a id="_idIndexMarker439"/> to add back the fraudulent transactions into the threshold optimization set, and a number of <strong class="bold">Partitioning</strong> nodes. All data extraction in the Partitioning nodes is performed at random:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer378" class="IMG---Figure">
					<img src="image/B16391_05_003.jpg" alt="Figure 5.3 – The datasets used in the fraud detection process "/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.3 –<a id="_idTextAnchor162"/> The datasets used in the fraud detection process </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The training set, validation set, and threshold optimization set must be completely separated. No records can be shared across any of the subsets. This is to ensure a meaningful performance measure during evaluation and an independent optimization procedure.</p>
			<p>Next, all data in each subset must be normalized to fall in <img src="image/Formula_B16391_05_024.png" alt=""/>. Normalization is defined on the training set and applied to the other two subsets. The normalization parameters are also saved for the deployment workflow <a id="_idIndexMarker440"/>using the <strong class="bold">Model Writer</strong> node:</p>
			<div>
				<div id="_idContainer380" class="IMG---Figure">
					<img src="image/B16391_05_004.jpg" alt="Figure 5.4 – The workflow implementing data preparation for fraud detection"/>
				</div>
			</div>
			<p class="figure-caption">Fi<a id="_idTextAnchor163"/>gure 5.4 – The workflow implementing data preparation for fraud detection</p>
			<p>The workflow in <em class="italic">Figure 5.4</em> shows how the creation of the different datasets and the normalization can be performed in KNIME Analytics Platform.</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor164"/>Building the Autoencoder</h2>
			<p>For this case study, we <a id="_idIndexMarker441"/>built an autoencoder with five hidden layers, with <strong class="source-inline">30-40-20-8-20-40-30</strong> units, and sigmoid as the activation function.</p>
			<p>The neural network was built using the following (see <em class="italic">Figure 5.5</em>):</p>
			<ul>
				<li>The <strong class="bold">Keras Input Layer</strong> node <a id="_idIndexMarker442"/>with <strong class="source-inline">Shape = 30</strong></li>
				<li>Five <strong class="bold">Keras Dense Layer</strong> nodes<a id="_idIndexMarker443"/> to implement the hidden layers, using sigmoid as the activation function and 40, 20, 8, 20, and 40 units, respectively</li>
				<li>The <strong class="bold">Keras Dense Layer</strong> node<a id="_idIndexMarker444"/> for the<a id="_idIndexMarker445"/> output layer, with 30 units and sigmoid as the activation function:</li>
			</ul>
			<p class="figure-caption"><a id="_idTextAnchor165"/></p>
			<div>
				<div id="_idContainer381" class="IMG---Figure">
					<img src="image/B16391_05_005.jpg" alt="Figure 5.5 – Structure of the neural autoencoder trained to reproduce credit card transactions from the input layer onto the output layer"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.5 – Structure of the neural autoencoder trained to reproduce credit card transactions from the input layer onto the output layer</p>
			<p>Now that we've built the autoencoder, let's train and test it using the data.</p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor166"/>Training and Testing the Autoencoder</h2>
			<p>To train and<a id="_idIndexMarker446"/> validate the network, we use the <strong class="bold">Keras Network Learner</strong> node, with the<a id="_idIndexMarker447"/> training set and the<a id="_idIndexMarker448"/> validation set at the input ports, and the following settings (<em class="italic">Figure 5.6</em>):</p>
			<ul>
				<li>The number of epochs is set to <strong class="source-inline">50</strong>, the batch size for the training and validation set is set to <strong class="source-inline">300</strong>,<a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/"> and</a> the <strong class="bold">Adam</strong> (an optimized ve<a href="https://en.wikipedia.org/wiki/Backpropagation">rsion of backpr</a>opagation) training algorithm is used, in the <strong class="bold">Options</strong> tab.</li>
				<li>The loss function is set to be the MSE in the <strong class="bold">Target</strong> tab.</li>
				<li>The target and input features are the same in the <strong class="bold">Input</strong> tab and in the <strong class="bold">Target</strong> tab and are accepted as simple <strong class="bold">Double</strong> numbers.</li>
			</ul>
			<p>In the <strong class="bold">Loss</strong> tab of the <strong class="bold">Learning Monitor</strong> view of the Keras Network Learner node, you can see two curves now: one is the mean loss (or error) per training sample in a batch (in red) and the other one is the mean loss per sample on the validation data (in blue). </p>
			<p>At the end of the training phase, the final mean loss value fell in around [0.0012, 0016] for batches from the training set and in [0.0013, 0.0018] for batches from the validation set. The calculated loss is the mean reconstruction error for one batch, calculated by the following formula:</p>
			<p><img src="image/Formula_B16391_05_025.png" alt=""/></p>
			<p>Here, <img src="image/Formula_B16391_05_026.png" alt=""/> is the batch size, <img src="image/Formula_B16391_05_002.png" alt=""/> is the <a id="_idIndexMarker449"/>number of units on the output layer, <img src="image/Formula_B16391_05_028.png" alt=""/> is the output value of neuron <em class="italic">i</em> in the output layer for training sample <em class="italic">k</em>, and <img src="image/Formula_B16391_05_029.png" alt=""/> is the corresponding target answer. </p>
			<p>After training, the <a id="_idIndexMarker450"/>network is applied to the optimization set, using the <strong class="bold">Keras Network Executor</strong> node, and it is saved for deployment as a Keras file using the <strong class="bold">Keras Network Writer</strong> node.</p>
			<p><em class="italic">Figure 5.6</em> shows the<a id="_idIndexMarker451"/> configuration for the <strong class="bold">Options</strong> tab in the Keras Network Executor node: all 30 input features are passed as <strong class="bold">Double</strong> numbers and the input columns are kept so that the reconstruction error can be calculated later on. The last layer is selected as the output and the values are exported as simple <strong class="bold">Double</strong> numbers:</p>
			<div>
				<div id="_idContainer387" class="IMG---Figure">
					<img src="image/B16391_05_006.jpg" alt="Figure 5.6 – The Keras Network Executor node and its configuration window"/>
				</div>
			</div>
			<p class="figure-caption">Fi<a id="_idTextAnchor167"/>gure 5.6 – The Keras Network Executor node and its configuration window</p>
			<p>The next step is to calculate the distance between the original feature vector and the reproduced feature vector, and to apply a threshold, <img src="image/Formula_B16391_05_030.png" alt=""/>, to discover fraud candidates.</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor168"/>Detecting Fraudulent Transactions</h2>
			<p>When the <a id="_idIndexMarker452"/>model training is finished, the autoencoder has learned how to reproduce feature vectors representing legitimate transactions onto the output layer. How can we now spot suspicious transactions? If we have a new transaction, <img src="image/Formula_B16391_05_016.png" alt=""/>, how can we tell whether it is a suspicious or a legitimate one?</p>
			<p>First, we run this new transaction, <img src="image/Formula_B16391_05_032.png" alt=""/>, through the autoencoder via the Keras Network Executor node. The reproduction of the original transaction is generated at the output layer. Now, a reconstruction error, <img src="image/Formula_B16391_05_033.png" alt=""/>, is calculated, as the distance between the original transaction vector and the reproduced one. A transaction is then considered a fraud candidate according to the following rule:</p>
			<p>IF <img src="image/Formula_B16391_05_034.png" alt=""/> THEN <img src="image/Formula_B16391_05_018.png" alt=""/> -&gt;    "legitimate trx"</p>
			<p>IF <img src="image/Formula_B16391_05_036.png" alt=""/> THEN <img src="image/Formula_B16391_05_016.png" alt=""/> -&gt; "fraud candidate trx"</p>
			<p>Here, <img src="image/Formula_B16391_05_019.png" alt=""/> is the <a id="_idIndexMarker453"/>reconstruction error value for transaction <img src="image/Formula_B16391_05_039.png" alt=""/> and <em class="italic">K</em> is a threshold. The MSE was also adopted for the reconstruction error:</p>
			<p><img src="image/Formula_B16391_05_040.png" alt=""/></p>
			<p>Here, <img src="image/Formula_B16391_05_041.png" alt=""/> is the <em class="italic">i</em>th feature of transaction <img src="image/Formula_B16391_05_042.png" alt=""/>, and <img src="image/Formula_B16391_05_043.png" alt=""/> is the corresponding value on the output layer of the network.</p>
			<p><img src="image/Formula_B16391_05_044.png" alt=""/> is calculated via a <strong class="bold">Math Formula</strong> node, and the <a id="_idIndexMarker454"/>previous rule is implemented<a id="_idIndexMarker455"/> via a <strong class="bold">Rule Engine</strong> node, assuming, for now, threshold <img src="image/Formula_B16391_05_030.png" alt=""/> to be <img src="image/Formula_B16391_05_046.png" alt=""/>. <strong class="source-inline">1</strong> is the fraud candidate class and <strong class="source-inline">0</strong> is the<a id="_idIndexMarker456"/> legitimate transaction <a id="_idIndexMarker457"/>class. A <strong class="bold">Scorer (Javascript)</strong> node finally calculates some performance metrics for the whole approach: 83.64% accuracy, with 83.60% specificity and 99.95% sensitivity on class <strong class="source-inline">1</strong>. Specificity is the ratio between the number of true legitimate transactions and all transactions that did not raise any alarm. Sensitivity, on the opposite side, measures the ratio of fraud alarms that actually hit a fraudulent transaction.</p>
			<p>Specificity produces a measure of the frauds we might have missed, while sensitivity produces a measure of the frauds we hit:</p>
			<div>
				<div id="_idContainer405" class="IMG---Figure">
					<img src="image/B16391_05_007.jpg" alt="Figure 5.7 – The rule implemented in the Rule Engine node, comparing reconstruction error with threshold"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.7 – The rule implemented in the Rule Engine node, comparing reconstruction error with threshold</p>
			<p>Now that our model is trained and tested, it needs to be optimized.</p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor169"/>Optimizing the Autoencoder Strategy</h1>
			<p>What is the <a id="_idIndexMarker458"/>best value to use for threshold <img src="image/Formula_B16391_05_023.png" alt=""/>? In the last section, we adopted <img src="image/Formula_B16391_05_048.png" alt=""/> based on our experience. However, is this the best value for <img src="image/Formula_B16391_05_052.png" alt=""/>? Threshold <img src="image/Formula_B16391_05_052.png" alt=""/>, in this case, is not automatically optimized via the training procedure. It is just a static parameter external to the training algorithm. In KNIME Analytics Platform, it is also possible to optimize static parameters outside of the <strong class="bold">Learner</strong> nodes.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor170"/>Optimizing Threshold <img src="image/Formula_B16391_05_051.png" alt=""/></h2>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor171"/>Threshold <img src="image/Formula_B16391_05_052.png" alt=""/> is defined <a id="_idIndexMarker459"/>on a separate subset of data, called <a id="_idIndexMarker460"/>the <strong class="bold">optimization set</strong>. There are two options here:</h2>
			<ul>
				<li>If an optimization set with labeled fraudulent transactions is available, the value of threshold <img src="image/Formula_B16391_05_052.png" alt=""/> is optimized against any accuracy measure for fraud detection.</li>
				<li>If no labeled fraudulent transactions are available in the dataset, the value of threshold <img src="image/Formula_B16391_05_052.png" alt=""/> is defined as a high percentile of the reconstruction errors on the optimization set.</li>
			</ul>
			<p>During the data preparation phase, we generated three data subsets: the training set and validation set for the Keras Network Learner node to train and validate the autoencoder, and one last subset, which we called the threshold optimization set. This final subset includes 1/3 of all the legitimate transactions and the handful of fraudulent transactions. We can use this subset to optimize the value of threshold <img src="image/Formula_B16391_05_023.png" alt=""/> against the accuracy of the whole fraud detection strategy.</p>
			<p>To optimize a parameter means to find the value within a range that maximizes or minimizes a given measure. Based on our experience, we assume the value of <em class="italic">K</em> to be a positive number (&gt; 0) and <a id="_idIndexMarker461"/>to lie below 0.02. So, to optimize the value of threshold <img src="image/Formula_B16391_05_023.png" alt=""/> means to find the value in <img src="image/Formula_B16391_05_057.png" alt=""/> that maximizes the accuracy of the whole application.</p>
			<p>The accuracy of the application is calculated via a Scorer (JavaScript) node, considering the results of the Rule Engine node as the predictions and comparing them with the original class (<strong class="source-inline">0</strong> = legitimate transaction, <strong class="source-inline">1</strong> = fraudulent transaction) in the optimization set.</p>
			<p>The spanning of the value interval and the identification of the threshold value for the maximum accuracy is performed by <a id="_idIndexMarker462"/>an <strong class="bold">optimization loop</strong>. Every loop in KNIME Analytics Platform is implemented via two nodes: a <strong class="source-inline">loop start</strong> node and a <strong class="source-inline">loop end</strong> node. In the optimization <a id="_idIndexMarker463"/>loop, these two nodes are the <strong class="bold">Parameter Optimization Loop Start</strong> node<a id="_idIndexMarker464"/> and the <strong class="bold">Parameter Optimization Loop End</strong> node. </p>
			<p>The <strong class="bold">Parameter Optimization Loop Start</strong> node<a id="_idIndexMarker465"/> spans parameter values in a given interval with a given step size. Interval <img src="image/Formula_B16391_05_058.png" alt=""/> and step size <img src="image/Formula_B16391_05_059.png" alt=""/> have been chosen here based on the range of the reconstruction error feature, as shown in the <strong class="bold">Lower Bound</strong> and <strong class="bold">Upper Bound</strong> cells in the <strong class="bold">Spec</strong> tab of the data table at the output port of the Math Formula node, named <strong class="bold">MSE input-output distance</strong>, after the Keras Network Executor node.</p>
			<p>The <strong class="bold">Parameter Optimization Loop End</strong> node collects all results as flow variables, detects<a id="_idIndexMarker466"/> the best (maximum or minimum) value for the target measure, and exports it together with the<a id="_idIndexMarker467"/> parameter that generated it. In our case, the target measure is the accuracy, measured on the predictions from the Rule Engine node, which must be maximized against values for threshold <img src="image/Formula_B16391_05_052.png" alt=""/>.</p>
			<p>All nodes in between the loop start and the loop end make the body of the loop – that is, the part that gets repeated as many times as needed until the input interval of parameter values has all been covered. In the loop body, we add the additional constraint that the optimal accuracy should be found only for those parameters where the specificity and sensitivity are close in value. This is the goal of the metanode named <strong class="source-inline">Coefficient 0/1</strong>. Here, if the specificity and sensitivity are more than 10% apart, the coefficient is set to <strong class="source-inline">0</strong>, otherwise to <strong class="source-inline">1</strong>. This coefficient then multiplies the overall accuracy coming from the Scorer (JavaScript) node. In this way, the maximum accuracy is detected only for those cases where the specificity and sensitivity are close to each other:</p>
			<div>
				<div id="_idContainer420" class="IMG---Figure">
					<img src="image/B16391_05_008.jpg" alt="Figure 5.8 – The optimization loop"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.8 – The optimization loop</p>
			<p>After extracting the optimal threshold, we transform it into a flow variable and pass it to the final rule implementation.</p>
			<h3>Wrapping up into a Component</h3>
			<p>Now, this whole threshold optimization part seems to be a logical self-contained block. To keep our workflow clean and proper, we could wrap this block inside a metanode. Even better, we could<a id="_idIndexMarker468"/> make sure that the wrapping is close and tight via a stronger type of metanode: the <strong class="bold">component</strong>.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">A metanode<a id="_idIndexMarker469"/> just collects and packages nodes. A component, on the other hand, collects and packages nodes together and, in addition, inherits the views of contained Widget and JavaScript nodes and the configuration windows of contained Configuration nodes. Even further, a component does not allow external flow variables to enter or internal flow variables to exit unless specifically defined.</p>
			<p>A component is created in a similar way to a metanode. Just select the nodes to group together, right-click, and select <strong class="bold">Create Component…</strong>. When a component is created, its context (right-click) menu offers a number of commands to open, expand, modify via setup, and share it. To inspect the content of a component, just <em class="italic">Ctrl</em> + double-click the component. Once inside, you can see two nodes: <strong class="bold">Component Input</strong> and <strong class="bold">Component Output</strong>. In the configuration<a id="_idIndexMarker470"/> window of these two nodes, you can set the flow variables to import inside and export outside of the component, respectively.</p>
			<p>In the component we created, we set up <a id="_idIndexMarker471"/>the <strong class="bold">Component Output</strong> node to export the flow variable containing the value for the optimal threshold. This flow variable needs to exit the component to be used in the final rule for fraud detection. The final rule is implemented in a new Rule Engine node and the final predictions are evaluated against the original classes in a new Scorer (JavaScript) node.</p>
			<p>The final workflow to train and test the neural autoencoder using credit card transaction data and to implement the fraud detection rule with the optimal threshold is shown in <em class="italic">Figure 5.9</em>. The workflow, named <strong class="source-inline">01_Autoencoder_for_Fraud_Detection_Training</strong>, is downloadable from the KNIME Hub: <a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/">https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/</a>:</p>
			<div>
				<div id="_idContainer421" class="IMG---Figure">
					<img src="image/B16391_05_009.jpg" alt="Figure 5.9 – The workflow to train and test the autoencoder and to find the optimal threshold, K"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.9 – The workflow to train and test th<a id="_idTextAnchor172"/>e autoencoder and to find the optimal threshold, K</p>
			<p>Now that we have found the best threshold, let's have a look at the performance of the autoencoder.</p>
			<h3>Performance Metrics</h3>
			<p>In this section, we report the<a id="_idIndexMarker472"/> performance measures of this approach on the threshold optimization set after applying the fraud detection rule. The optimal threshold value was found to be <img src="image/Formula_B16391_05_061.png" alt=""/> for an accuracy of 93.52%.</p>
			<p>In <em class="italic">Figure 5.10</em>, you can see the <strong class="bold">confusion matrix</strong>, the class statistics based on it, and the general performance measures, all of<a id="_idIndexMarker473"/> them describing how well the fraud detector is performing on the optimization set: </p>
			<div>
				<div id="_idContainer423" class="IMG---Figure">
					<img src="image/B16391_05_010.jpg" alt="Figure 5.10 – Performance metrics of the final fraud detector with optimized threshold K"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.10 – Performance metrics of the final <a id="_idTextAnchor173"/>fraud detector with optimized threshold K</p>
			<p>Let's consider class 1 (fraud) as the positive class. The high number of false positives (6,236) shows the weakness of this approach: it is prone to generating false positives. In other words, it tends to label perfectly legitimate transactions as fraud candidates. Now, there are case studies where false positives are not a huge problem, and this is one of those. In the case of a false positive, the price to pay is to send a message to the credit card owner about the current transaction. If the message turns out to be useless, the damage is not much compared to the possible risk. Of course, this tolerance does not apply to all case studies. A false positive in medical diagnosis carries a much heavier responsibility than a wrong fraud alarm in a credit card transaction. </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The whole process could also be forced to lean more toward fraud candidates or legitimate transactions, by introducing an expertise-based bias in the definition of threshold <em class="italic">K</em>.</p>
			<p>In general, the autoencoder captures 87% of the fraudulent transactions and 93% of the legitimate transactions in the validation set, for an overall accuracy of 85% and a Cohen's kappa of 0.112. Considering the high imbalance between the number of normal and fraudulent transactions in the validation set (96,668 versus 492), the results are still promising.</p>
			<p>Notice that this false <a id="_idIndexMarker474"/>positive-prone approach is a desperate solution for a case study where no, or almost no, examples from one of the classes exist. A supervised classifier on a training set with labeled examples would probably reach better performances. But this is the data we have to deal with!</p>
			<p>We have now trained the autoencoder and found the best threshold for our rule system. We will see, in the next section, how to deploy it in the real world on real data.</p>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor174"/>Deploying the Fraud Detector</h1>
			<p>At this point, we have an<a id="_idIndexMarker475"/> autoencoder network<a id="_idTextAnchor175"/> and a rule with acceptable performance for fraud detection. In this section, we will implement the <strong class="bold">deployment</strong> workflow.</p>
			<p>The deployment workflow (<em class="italic">Figure 5.11</em>), like all deployment workflows, takes in new transaction data, passes it through the autoencoder, calculates the distance, applies the fraud detection rule, and finally, flags the input transaction as fraud or legitimate.</p>
			<p>This workflow, named <strong class="source-inline">02_Autoencoder_for_Fraud_Detection_Deployment</strong>, is downloadable from the KNIME Hub: <a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/">https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/</a>:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer424" class="IMG---Figure">
					<img src="image/B16391_05_011.jpg" alt="Figure 5.11 – The deployment workflow"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.11 – The deployment workflow</p>
			<p>Let's have a look at the different parts of the workflow in detail.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor176"/>Reading Network, New Transactions, and Normalization Parameters</h2>
			<p>In this workflow, first the autoencoder model is read from the previously saved Keras file, using<a id="_idIndexMarker476"/> the <strong class="bold">Keras Network Reader</strong> node. </p>
			<p>At the same time, data from some new credit card transactions are read from the file using the <strong class="bold">File Reader</strong> node. This <a id="_idIndexMarker477"/>particular file contains two new transactions.</p>
			<p>The transactions are normalized with the same parameters built on the training data and previously saved in the file named <strong class="source-inline">normalizer model</strong>. These normalization parameters are read from the file <a id="_idIndexMarker478"/>using the <strong class="bold">Model Reader</strong> node.</p>
			<p>The last file to read contains the value of the optimized threshold, <em class="italic">K</em>.</p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor177"/>Applying the Fraud Detector</h2>
			<p>Transaction data is<a id="_idIndexMarker479"/> fed into the autoencoder network and reproduced on the output layer with the Keras Network Executor node.</p>
			<p>Afterward, the MSEs between the original features and the reconstructed features for each transaction are calculated<a id="_idIndexMarker480"/> using the <strong class="bold">Math Formula</strong> node.</p>
			<p>The Rule Engine node applies the threshold, <img src="image/Formula_B16391_05_052.png" alt=""/>, as defined during the optimization phase, to detect possible fraud candidates.</p>
			<p>The following table shows the reconstruction errors for the two transactions and the consequent class assignment. The application (autoencoder and distance rule) defines the first transaction as legitimate and the second transaction as a fraud candidate:</p>
			<div>
				<div id="_idContainer426" class="IMG---Figure">
					<img src="image/B16391_05_012.jpg" alt=""/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.12 – Reconstruction errors and fraud class assignment for credit card transactions in the dataset used for deployment</p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor178"/>Taking Actions</h2>
			<p>In the last part of the workflow, we need to take action:</p>
			<ul>
				<li>IF transaction is legitimate (class 0) =&gt; do nothing</li>
				<li>IF transaction is fraud candidate (class 1) =&gt; send message to owner to confirm</li>
			</ul>
			<p><strong class="bold">IF-THEN</strong> conditions involving<a id="_idIndexMarker481"/> actions are implemented in KNIME Analytics Platform via switch blocks. Similar to loops, switch blocks have a start node and an end node. The end node in switch blocks is optional, however. The switch start node activates only one of the output ports, enabling de facto only one possible further path for the data flow. The switch end node collects the results from the different branches. The most versatile switch <a id="_idIndexMarker482"/>block is the <strong class="bold">CASE switch</strong> in all its declinations: for data, flow variables, or models. </p>
			<p>The active port, and then the active branch, is controlled via the configuration window of the <strong class="bold">Switch CASE Start</strong> node. This <a id="_idIndexMarker483"/>configuration setting is usually controlled via a flow variable, whose values enable one or the other output each time.</p>
			<p>In our case, we have two branches. The upper branch is connected to port <strong class="source-inline">0</strong>, activated by class <strong class="source-inline">0</strong>, and performs nothing. The second branch is connected to port <strong class="source-inline">1</strong>, activated by class <strong class="source-inline">1</strong>, and sends an email to the owner of the credit card.</p>
			<p>We conclude here the section on the implementation of the autoencoder-based strategy for fraud detection.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor179"/>Summary</h1>
			<p>In this chapter, we discussed approaches for building a fraud detector for credit card transactions in the desperate case when no, or almost no, examples of the fraud class are available. This solution trains a neural autoencoder to reproduce legitimate transactions from the input onto the output layer. Some postprocessing is necessary to set an alarm for the fraud candidate based on the reconstruction error.</p>
			<p>In describing this solution, we have introduced the concept of training and deployment applications, components, optimization loops, and switch blocks.</p>
			<p>In the next chapter, we will discuss a special family of neural networks, so-called recurrent neural networks, and how they can be used to train neural networks for sequential data.</p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor180"/>Questions and Exercises</h2>
			<p>Check your level of understanding of the concepts presented in this chapter by answering the following questions:</p>
			<ol>
				<li>What is the goal of an autoencoder during training?<p>a) To reproduce the input to the output</p><p>b) To learn an automatic encoding</p><p>c) To encode the training data</p><p>d) To train a network that can distinguish between two classes</p></li>
				<li>What are common use cases for autoencoders?<p>a) Time series prediction</p><p>b) Anomaly detection</p><p>c) Multiclass classification problems</p><p>d) Regression problems</p></li>
				<li>How can an autoencoder be used for dimensionality reduction?<p>a) By training a network with an output layer with less number than input layers</p><p>b) By training an autoencoder and extracting only the encoder</p><p>c) By building an autoencoder and extracting only the decoder</p><p>d) By building a network with more hidden neurons than the input and output layers</p></li>
			</ol>
		</div>
	</body></html>