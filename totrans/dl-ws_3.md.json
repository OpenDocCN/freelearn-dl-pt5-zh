["```py\n    import tensorflow as tf\n    ```", "```py\n    A = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    A\n    ```", "```py\n    <tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, \n    numpy=array([[1, 2, 3],\n                 [4, 5, 6],\n                 [7, 8, 9]])>\n    ```", "```py\n    B = tf.Variable([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n    B\n    ```", "```py\n    <tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, \n    numpy=array([[ 1,  0, -1],\n                 [ 1,  0, -1],\n                 [ 1,  0, -1]])>\n    ```", "```py\n    mult_out = tf.math.multiply(A, B)\n    mult_out\n    ```", "```py\n    <tf.Tensor: id=19, shape=(3, 3), dtype=int32, \n    numpy=array([[ 1,  0, -3],\n                 [ 4,  0, -6],\n                 [ 7,  0, -9]])>\n    ```", "```py\n    conv_out = tf.math.reduce_sum(mult_out)\n    conv_out\n    ```", "```py\n    <tf.Tensor: id=21, shape=(), dtype=int32, numpy=-6>\n    ```", "```py\nfrom tensorflow.keras import layers\nlayers.Conv2D(64, kernel_size=(3, 3), stride=(2,2), \\\n              padding=\"same\", activation=\"relu\")\n```", "```py\nfrom tensorflow.keras import layers\nlayers.MaxPool2D(pool_size=(3, 3), strides=1)\n```", "```py\nfrom tensorflow.keras import layers\nlayers.Dense(units=1, activation='sigmoid')\n```", "```py\nfeatures_train.reshape(60000, 28, 28, 1)\n```", "```py\nfrom tensorflow.keras import layers\nlayers.Reshape((60000, 28, 28, 1))\n```", "```py\n    import tensorflow.keras.datasets.mnist as mnist\n    ```", "```py\n    (features_train, label_train), (features_test, label_test) = \\\n    mnist.load_data()\n    ```", "```py\n    label_train\n    ```", "```py\n    array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)\n    ```", "```py\n    features_train.shape\n    ```", "```py\n    (60000, 28, 28)\n    ```", "```py\n    features_test.shape\n    ```", "```py\n    (10000, 28, 28)\n    ```", "```py\n    features_train = features_train.reshape(60000, 28, 28, 1)\n    features_test = features_test.reshape(10000, 28, 28, 1)\n    ```", "```py\n    features_train = features_train / 255.0\n    features_test = features_test / 255.0\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential()\n    ```", "```py\n    conv_layer1 = layers.Conv2D(64, (3,3), activation='relu', \\\n                                input_shape=(28, 28, 1))\n    ```", "```py\n    conv_layer2 = layers.Conv2D(64, (3,3), activation='relu')\n    ```", "```py\n    fc_layer1 = layers.Dense(128, activation='relu')\n    ```", "```py\n    fc_layer2 = layers.Dense(10, activation='softmax')\n    ```", "```py\n    model.add(conv_layer1)\n    model.add(layers.MaxPooling2D(2, 2))\n    model.add(conv_layer2)\n    model.add(layers.MaxPooling2D(2, 2))\n    model.add(layers.Flatten())\n    model.add(fc_layer1)\n    model.add(fc_layer2)\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(features_train, label_train, epochs=5,\\\n              validation_split = 0.2, verbose=2)\n    ```", "```py\n    model.evaluate(features_test, label_test)\n    ```", "```py\n    10000/10000 [==============================] - 1s 86us/sample - \n    loss: 0.0312 - accuracy: 0.9903 [0.03115778577708088, 0.9903]\n    ```", "```py\nfrom tensorflow.keras.preprocessing.image \\\nimport ImageDataGenerator\n```", "```py\ntrain_imggen = ImageDataGenerator(rescale=1./255)\n```", "```py\ntrain_datagen = train_imggen.\\\n                flow_from_directory(batch_size=32, \\\n                                    directory=train_dir, \\\n                                    shuffle=True, \\\n                                    target_size=(100, 100), \\\n                                    class_mode='binary')\n```", "```py\nmodel.fit_generator(train_data_gen, \\\n                    steps_per_epoch=total_train // batch_size, \\\n                    epochs=5, validation_data=val_data_gen, \\\n                    validation_steps=total_val // batch_size)\n```", "```py\n    import tensorflow as tf\n    ```", "```py\n    file_url = 'https://github.com/PacktWorkshops'\\\n               '/The-Deep-Learning-Workshop/raw/master'\\\n               '/Chapter03/Datasets/Exercise3.03'\\\n               '/cats_and_dogs_filtered.zip'\n    ```", "```py\n    zip_dir = tf.keras.utils.get_file('cats_and_dogs.zip', \\\n                                       origin=file_url, extract=True)\n    ```", "```py\n    import pathlib\n    ```", "```py\n    path = pathlib.Path(zip_dir).parent / 'cats_and_dogs_filtered'\n    ```", "```py\n    train_dir = path / 'train'\n    validation_dir = path / 'validation'\n    ```", "```py\n    train_cats_dir = train_dir / 'cats'\n    train_dogs_dir = train_dir /'dogs'\n    validation_cats_dir = validation_dir / 'cats'\n    validation_dogs_dir = validation_dir / 'dogs'\n    ```", "```py\n    import os\n    ```", "```py\n    total_train = len(os.listdir(train_cats_dir)) \\\n                      + len(os.listdir(train_dogs_dir))\n    total_val = len(os.listdir(validation_cats_dir)) \\\n                    + len(os.listdir(validation_dogs_dir))\n    ```", "```py\n    from tensorflow.keras.preprocessing.image\\\n    import ImageDataGenerator\n    ```", "```py\n    train_image_generator = ImageDataGenerator(rescale=1./255)\n    validation_image_generator = ImageDataGenerator(rescale=1./255)\n    ```", "```py\n    batch_size = 16\n    img_height = 100\n    img_width = 100\n    ```", "```py\n    train_data_gen = train_image_generator.flow_from_directory\\\n                     (batch_size=batch_size, directory=train_dir, \\\n                      shuffle=True, \\\n                      target_size=(img_height, img_width), \\\n                      class_mode='binary')\n    ```", "```py\n    val_data_gen = validation_image_generator.flow_from_directory\\\n                  (batch_size=batch_size, \\\n                   directory=validation_dir, \\\n                   target_size=(img_height, img_width), \\\n                   class_mode='binary')\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential([\n        layers.Conv2D(64, 3, activation='relu', \\\n                      input_shape=(img_height, img_width ,3)),\\\n        layers.MaxPooling2D(),\\\n        layers.Conv2D(128, 3, activation='relu'),\\\n        layers.MaxPooling2D(),\\\n        layers.Flatten(),\\\n        layers.Dense(128, activation='relu'),\\\n        layers.Dense(1, activation='sigmoid')])\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='binary_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit_generator(train_data_gen, \\\n                        steps_per_epoch=total_train // batch_size, \\\n                        epochs=5, \\\n                        validation_data=val_data_gen,\\\n                        validation_steps=total_val // batch_size)\n    ```", "```py\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nImageDataGenerator(rescale=1./255, \\\n                   horizontal_flip=True, zoom_range=0.2, \\\n                   width_shift_range=0.2, \\\n                   height_shift_range=0.2, \\\n                   shear_range=0.2, rotation_range=40, \\\n                   fill_mode='nearest')\n```", "```py\n    from tensorflow.keras.datasets import cifar10\n    ```", "```py\n    (features_train, label_train), (features_test, label_test) = \\\n    cifar10.load_data()\n    ```", "```py\n    features_train.shape\n    ```", "```py\n     (50000, 32, 32, 3)\n    ```", "```py\n    batch_size = 16\n    img_height = 32\n    img_width = 32\n    ```", "```py\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    ```", "```py\n    train_img_gen = ImageDataGenerator\\\n                    (rescale=1./255, width_shift_range=0.1, \\\n                     height_shift_range=0.1, horizontal_flip=True)\n    ```", "```py\n    val_img_gen = ImageDataGenerator(rescale=1./255)\n    ```", "```py\n    train_data_gen = train_img_gen.flow\\\n                     (features_train, label_train, \\\n                     batch_size=batch_size)\n    ```", "```py\n    val_data_gen = train_img_gen.flow\\\n                   (features_test, label_test, \\\n                    batch_size=batch_size)\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential([\n            layers.Conv2D(64, 3, activation='relu', \\\n                          input_shape=(img_height, img_width ,3)), \\\n            layers.MaxPooling2D(), \\\n            layers.Conv2D(128, 3, activation='relu'), \\\n            layers.MaxPooling2D(), \\\n            layers.Flatten(), \\\n            layers.Dense(128, activation='relu'), \\\n            layers.Dense(10, activation='softmax')])\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\n    ```", "```py\n    model.fit_generator(train_data_gen, \\\n                        steps_per_epoch=len(features_train) \\\n                                        // batch_size, \\\n                        epochs=5, \\\n                        validation_data=val_data_gen, \\\n                        validation_steps=len(features_test) \\\n                                         // batch_size)\n    ```", "```py\n    rescale=1./255, \n    rotation_range=40, \n    width_shift_range=0.1, \n    height_shift_range=0.1, \n    shear_range=0.2, \n    zoom_range=0.2, \n    horizontal_flip=True, \n    fill_mode='nearest'\n    ```", "```py\nmodel.save_model(filepath='path_to_model/cnn_model')\n```", "```py\nloaded_model = tf.keras.models.load_model\\\n              (filepath='path_to_model/cnn_model')\n```", "```py\nimport json\nconfig_json = model.to_json()\nwith open('config.json', 'w') as outfile:\n    json.dump(config_json, outfile)\n```", "```py\nimport json\nwith open('config.json') as json_file:\n    config_data = json.load(json_file)\nloaded_model = tf.keras.models.model_from_json(config_data)\n```", "```py\nmodel.save_weights('path_to_weights/weights.h5')\n```", "```py\nnew_model.load_weights('path_to_weights/weights.h5')\n```", "```py\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\n```", "```py\nimg_dim = (100, 100, 3)\n```", "```py\nbase_model = VGG16(input_shape=img_dim, \\\n                   weights='imagenet', include_top=True)\n```", "```py\nbase_model.predict(input_img)\n```", "```py\nbase_model = VGG16(input_shape=img_dim, \\\n                   weights='imagenet', include_top=False)\n```", "```py\nbase_model.trainable = False\n```", "```py\nprediction_layer = tf.keras.layers.Dense(20, activation='softmax')\n```", "```py\nnew_model = tf.keras.Sequential([base_model, prediction_layer])\n```", "```py\noptimizer = tf.keras.optimizers.Adam(0.001)\nnew_model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\nnew_model.fit(features_train, label_train, epochs=5, \\\n              validation_split = 0.2, verbose=2)\n```", "```py\nbase_model = VGG16(input_shape=img_dim, \\\n                   weights='imagenet', include_top=False)\n```", "```py\nfrozen_layers = 10\n```", "```py\nfor layer in base_model.layers[:frozen_layers]:\n  layer.trainable = False\n```", "```py\nprediction_layer = tf.keras.layers.Dense(20, activation='softmax')\nnew_model = tf.keras.Sequential([base_model, prediction_layer])\n```", "```py\noptimizer = tf.keras.optimizers.Adam(0.001)\nnew_model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\nnew_model.fit(features_train, label_train, epochs=5, \\\n              validation_split = 0.2, verbose=2)\n```", "```py\n    rescale=1./255, \n    rotation_range=40, \n    width_shift_range=0.1, \n    height_shift_range=0.1, \n    shear_range=0.2, \n    zoom_range=0.2, \n    horizontal_flip=True, \n    fill_mode='nearest'\n    ```"]