["```py\nfrom sagemaker.pytorch.estimator import PyTorch\nfrom sagemaker.pytorch.model import PyTorchModel, PyTorchPredictor\n```", "```py\n    from sagemaker.pytorch.estimator import PyTorch\n    ```", "```py\nestimator = PyTorch(\n    entry_point=\"training_script.py\",\n    framework_version=\"1.8\",\n    py_version=\"py3\",\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.p2.xlarge\"\n)\n```", "```py\n    estimator.fit()\n    ```", "```py\nRUN pip install sagemaker-training\n```", "```py\nCOPY train_scipt.py /opt/ml/code/train_script.py\nENV SAGEMAKER_PROGRAM train_scipt.py\n```", "```py\ntransformers >= 4.10\n```", "```py\n    if __name__ == \"__main__\":\n         parser = argparse.ArgumentParser()\n         parser.add_argument(\"--epochs\", type=int, default=1)\n         parser.add_argument(\"--per-device-train-batch-size\", type=int, default=16)\n         parser.add_argument(\"--per-device-eval-batch-size\", type=int, default=64)\n         parser.add_argument(\"--warmup-steps\", type=int, default=100)\n         parser.add_argument(\"--logging-steps\", type=float, default=100)\n         parser.add_argument(\"--weight-decay\", type=float, default=0.01)\n         args, _ = parser.parse_known_args()\n         train(args)\n    ```", "```py\n        def train(args):\n            train_enc_dataset, test_enc_dataset = _get_tokenized_data()\n            training_args = TrainingArguments(\n                output_dir=os.getenv(\n                    \"SM_OUTPUT_DIR\", \"./\"\n                ),  # output directory, if runtime is not\n                num_train_epochs=args.epochs,\n                per_device_train_batch_size=args.per_device_train_batch_size,\n                per_device_eval_batch_size=args.per_device_eval_batch_size,\n                warmup_steps=args.warmup_steps,\n                weight_decay=args.weight_decay,\n                logging_steps=args.logging_steps,\n            )\n            config = DistilBertConfig()\n            config.num_labels = NUM_LABELS\n            model = DistilBertForSequenceClassification.from_pretrained(\n                MODEL_NAME, config=config\n            )\n            trainer = Trainer(\n                model=model,  # model to be trained\n                args=training_args,  # training arguments, defined above\n                train_dataset=train_enc_dataset,  # training dataset\n                eval_dataset=test_enc_dataset,  # evaluation dataset\n            )\n            trainer.train()\n            model.save_pretrained(os.environ[\"SM_MODEL_DIR\"])\n        ```", "```py\nfrom sagemaker.huggingface.estimator import HuggingFace\nfrom sagemaker import get_execution_role\nrole=get_execution_role()\n```", "```py\nhyperparameters = {\n    \"epochs\":1,\n    \"per-device-train-batch-size\":16, \n    \"per-device-eval-batch-size\":64,\n    \"warmup-steps\":100,\n    \"logging-steps\":100,\n    \"weight-decay\":0.01    \n}\nestimator = HuggingFace(\n    py_version=\"py36\",\n    entry_point=\"train.py\",\n    source_dir=\"1_sources\",\n    pytorch_version=\"1.7.1\",\n    transformers_version=\"4.6.1\",\n    hyperparameters=hyperparameters,\n    instance_type=\"ml.p2.xlarge\",\n    instance_count=1,\n    role=role\n)\nestimator.fit({\n    \"train\":train_dataset_uri,\n    \"test\":test_dataset_uri\n})\n```", "```py\n    MODEL_NAME = \"distilbert-base-uncased\"\n    NUM_LABELS = 6 # number of categories\n    MAX_LENGTH = 512 # max number of tokens model can handle\n    def model_fn(model_dir):\n        device_id = 0 if torch.cuda.is_available() else -1\n        tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n        config = DistilBertConfig()\n        config.num_labels = NUM_LABELS\n        model = DistilBertForSequenceClassification.from_pretrained(\n            model_dir, config=config\n        )\n        inference_pipeline = pipeline(\n            model=model,\n            task=\"text-classification\",\n            tokenizer=tokenizer,\n            framework=\"pt\",\n            device=device_id,\n            max_length=MAX_LENGTH,\n            truncation=True\n        )\n        return inference_pipeline\n    ```", "```py\n    def transform_fn(inference_pipeline, data, content_type, accept_type):\n        # Deserialize payload\n        if \"json\" in content_type:\n            deser_data = json.loads(data)\n        else:\n            raise NotImplemented(\"Only 'application/json' content type is implemented.\")\n\n        # Run inference\n        predictions = inference_pipeline(deser_data)\n\n        # Serialize response\n        if \"json\" in accept_type:\n            return json.dumps(predictions)\n        else:\n            raise NotImplemented(\"Only 'application/json' accept type is implemented.\")\n    ```", "```py\n    from sagemaker.huggingface.estimator import HuggingFaceModel\n    model = estimator.create_model(role=role, \n                                   entry_point=\"inference.py\", \n                                   source_dir=\"1_sources\",\n                                   py_version=\"py36\",\n                                   transformers_version=\"4.6.1\",\n                                   pytorch_version=\"1.7.1\"\n                                  )\n    ```", "```py\n    predictor = model.deploy(\n        initial_instance_count=1,\n        instance_type=\"ml.m5.xlarge\"\n    )\n    ```", "```py\n    FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.9.0-gpu-py38-cu111-ubuntu20.04\n    RUN pip3 install git+https://github.com/huggingface/transformers \n    ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code \n    ENV SAGEMAKER_PROGRAM train.py \n    COPY 1_sources/train.py $SAGEMAKER_SUBMIT_DIRECTORY/$SAGEMAKER_PROGRAM\n    ```", "```py\nfrom sagemaker.estimator import Estimator\nestimator = Estimator(\n    image_uri=\"<UPDATE WITH YOUR IMAGE URI FROM ECR>\",\n    hyperparameters=hyperparameters,\n    instance_type=\"ml.p2.xlarge\",\n    instance_count=1,\n    role=role\n)\nestimator.fit({\n    \"train\":train_dataset_uri,\n    \"test\":test_dataset_uri\n})\n```", "```py\ndocker run <YOUR BYO IMAGE> serve\n```", "```py\n    FROM tensorflow/tensorflow:latest\n    ```", "```py\n    COPY 3_sources/src/dockerd_entrypoint.py /usr/local/bin/dockerd-entrypoint.py\n    RUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n    ```", "```py\n    COPY 3_sources/src/model_handler.py /opt/ml/model/model_handler.py\n    COPY 3_sources/src/keras_model_loader.py /opt/ml/model/keras_model_loader.py\n    ```", "```py\n    ENTRYPOINT [\"python3\", \"/usr/local/bin/dockerd-entrypoint.py\"]\n    CMD [\"serve\"]\n    ```", "```py\nfrom sagemaker import Model\nmms_model = Model(\n    image_uri=image_uri,\n    model_data=None,\n    role=role,\n    name=model_name,\n    sagemaker_session=session\n)\nmms_model.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.m5.xlarge\", \n    endpoint_name=endpoint_name\n)\n```", "```py\nimport boto3\nclient = boto3.client('sagemaker-runtime')\naccept_type = \"application/json\"\ncontent_type = 'image/jpeg'\nheaders = {'content-type': content_type}\npayload = open(test_image, 'rb')\nresponse = client.invoke_endpoint(\n    EndpointName=endpoint_name,\n    Body=payload,\n    ContentType=content_type,\n    Accept = accept_type\n)\nmost_likely_label = response['Body'].read()\nprint(most_likely_label)\n```"]