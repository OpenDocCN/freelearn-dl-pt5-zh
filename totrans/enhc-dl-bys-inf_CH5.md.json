["```py\n\nimport tensorflow as tf \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport tensorflow_probability as tfp \n\nNUM_INFERENCES = 7\n```", "```py\n\n# download MNIST fashion data set \nfashion_mnist = tf.keras.datasets.fashion_mnist \n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() \n\n# set class names \nCLASS_NAMES = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', \n'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] \n\n# derive number training examples and classes \nNUM_TRAIN_EXAMPLES = len(train_images) \nNUM_CLASSES = len(CLASS_NAMES)\n```", "```py\n\ndef define_bayesian_model(): \n# define a function for computing the KL divergence \nkl_divergence_function = lambda q, p, _: tfp.distributions.kl_divergence( \nq, p \n) / tf.cast(NUM_TRAIN_EXAMPLES, dtype=tf.float32) \n\n# define our model \nmodel = tf.keras.models.Sequential([ \ntfp.layers.Convolution2DReparameterization( \n64, kernel_size=5, padding='SAME', \nkernel_divergence_fn=kl_divergence_function, \nactivation=tf.nn.relu), \ntf.keras.layers.MaxPooling2D( \npool_size=[2, 2], strides=[2, 2], \npadding='SAME'), \ntf.keras.layers.Flatten(), \ntfp.layers.DenseReparameterization( \nNUM_CLASSES, kernel_divergence_fn=kl_divergence_function, \nactivation=tf.nn.softmax) \n]) \n  return model\n```", "```py\n\ndef compile_bayesian_model(model): \n# define the optimizer \noptimizer = tf.keras.optimizers.Adam() \n# compile the model \nmodel.compile(optimizer, loss='categorical_crossentropy', \nmetrics=['accuracy'], experimental_run_tf_function=False) \n# build the model \nmodel.build(input_shape=[None, 28, 28, 1]) \n  return model\n```", "```py\n\ntrain_labels_dense = tf.one_hot(train_labels, NUM_CLASSES)\n```", "```py\n\n# use helper function to define the model architecture \nbayesian_model = define_bayesian_model() \n# use helper function to compile the model \nbayesian_model = compile_bayesian_model(bayesian_model) \n# initiate model training \nbayesian_model.fit(train_images, train_labels_dense, epochs=10)\n```", "```py\n\nNUM_SAMPLES_INFERENCE = 50 \nsoftmax_predictions = tf.stack( \n[bayesian_model.predict(test_images[:NUM_SAMPLES_INFERENCE]) \n     for _ in range(NUM_INFERENCES)],axis=0)\n```", "```py\n\n# get the class predictions for the first image in the test set \nimage_ind = 0 \n# collect class predictions \nclass_predictions = [] \nfor ind in range(NUM_INFERENCES): \nprediction_this_inference = np.argmax(softmax_predictions[ind][image_ind]) \nclass_predictions.append(prediction_this_inference) \n# get class predictions in human-readable form \npredicted_classes = [CLASS_NAMES[ind] for ind in class_predictions]\n```", "```py\n\n# define image caption \nimage_caption = [] \nfor caption in range(NUM_INFERENCES): \nimage_caption.append(f\"Sample {caption+1}: {predicted_classes[caption]}\\n\") \nimage_caption = ' '.join(image_caption) \n# visualise image and predictions \nplt.figure(dpi=300) \nplt.title(f\"Correct class: {CLASS_NAMES[test_labels[image_ind]]}\") \nplt.imshow(test_images[image_ind], cmap=plt.cm.binary) \nplt.xlabel(image_caption) \nplt.show()\n```", "```py\n\n# calculate variance across model predictions \nvar_predictions = tf.reduce_mean( \ntf.math.reduce_variance(softmax_predictions, axis=0), \n    axis=1)\n```", "```py\n\n# load regular MNIST data set \n(train_images_mnist, train_labels_mnist), \n(test_images_mnist, test_labels_mnist) = \ntf.keras.datasets.mnist.load_data() \n\n# get model predictions in MNIST data \nsoftmax_predictions_mnist = \ntf.stack([bayesian_model.predict( \ntest_images_mnist[:NUM_SAMPLES_INFERENCE]) \nfor _ in range(NUM_INFERENCES)], axis=0) \n\n# calculate variance across model predictions in MNIST data \nvar_predictions_mnist = tf.reduce_mean( \ntf.math.reduce_variance(softmax_predictions_mnist, axis=0), \n    axis=1)\n```", "```py\n\nfrom typing import List, Union, Iterable \nimport math \nfrom sklearn import datasets \nfrom sklearn.model_selection import train_test_split \nimport tensorflow as tf \nimport numpy as np \nfrom tensorflow.python.framework import tensor_shape \nimport tensorflow_probability as tfp\n```", "```py\n\nRANDOM_SEED = 0 \nnp.random.seed(RANDOM_SEED) \ntf.random.set_seed(RANDOM_SEED)\n```", "```py\n\n# load the California Housing dataset \nX, y = datasets.fetch_california_housing(return_X_y=True) \n# split the data (X) and targets (y) into train and test sets \nX_train, X_test, y_train, y_test = train_test_split( \nX, y, test_size=0.1, random_state=0 \n)\n```", "```py\n\ndef ensure_input(x, dtype, input_shape): \n# a function to ensure that our input is of the correct shape \nx = tf.constant(x, dtype=dtype) \ncall_rank = tf.rank(tf.constant(0, shape=input_shape, dtype=dtype)) + 1 \nif tf.rank(x) *<* call_rank: \nx = tf.reshape(x, [-1, * input_shape.as_list()]) \nreturn x \n\ndef ensure_output(y, dtype, output_dim): \n# a function to ensure that our output is of the correct shape \noutput_rank = 2 \ny = tf.constant(y, dtype=dtype) \nif tf.rank(y) *<* output_rank: \ny = tf.reshape(y, [-1, output_dim]) \n    return y\n```", "```py\n\nclass ReciprocalGammaInitializer: \ndef __init__(self, alpha, beta): \nself.Gamma = tfp.distributions.Gamma(concentration=alpha, rate=beta) \n\ndef __call__(self, shape: Iterable, dtype=None): \ng = 1.0 / self.Gamma.sample(shape) \nif dtype: \ng = tf.cast(g, dtype=dtype) \n\n        return g\n```", "```py\n\ndef get_mean_std_x_y(x, y): \n# compute the means and standard deviations of our inputs and targets \nstd_X_train = np.std(x, 0) \nstd_X_train[std_X_train == 0] = 1 \nmean_X_train = np.mean(x, 0) \nstd_y_train = np.std(y) \nif std_y_train == 0.0: \nstd_y_train = 1.0 \nmean_y_train = np.mean(y) \nreturn mean_X_train, mean_y_train, std_X_train, std_y_train \n\ndef normalize(x, y, output_shape): \n# use the means and standard deviations to normalize our inputs and targets \nx = ensure_input(x, tf.float32, x.shape[1]) \ny = ensure_output(y, tf.float32, output_shape) \nmean_X_train, mean_y_train, std_X_train, std_y_train = get_mean_std_x_y(x, y) \nx = (x - np.full(x.shape, mean_X_train)) / np.full(x.shape, std_X_train) \ny = (y - mean_y_train) / std_y_train \nreturn x, y \n\n# run our normalize() function on our data \nx, y = normalize(X_train, y_train, 1)\n```", "```py\n\nfrom tensorflow.keras.initializers import HeNormal \n\n# a class to handle our PBP layers \nclass PBPLayer(tf.keras.layers.Layer): \ndef __init__(self, units: int, dtype=tf.float32, *args, **kwargs): \nsuper().__init__(dtype=tf.as_dtype(dtype), *args, **kwargs) \nself.units = units \n    ...\n```", "```py\n\n... \ndef build(self, input_shape): \ninput_shape = tensor_shape.TensorShape(input_shape) \nlast_dim = tensor_shape.dimension_value(input_shape[-1]) \nself.input_spec = tf.keras.layers.InputSpec( \nmin_ndim=2, axes={-1: last_dim} \n) \nself.inv_sqrtV1 = tf.cast( \n1.0 / tf.math.sqrt(1.0 * last_dim + 1), dtype=self.dtype \n) \nself.inv_V1 = tf.math.square(self.inv_sqrtV1) \n\nover_gamma = ReciprocalGammaInitializer(6.0, 6.0) \nself.weights_m = self.add_weight( \n\"weights_mean\", shape=[last_dim, self.units], \ninitializer=HeNormal(), dtype=self.dtype, trainable=True, \n) \nself.weights_v = self.add_weight( \n\"weights_variance\", shape=[last_dim, self.units], \ninitializer=over_gamma, dtype=self.dtype, trainable=True, \n) \nself.bias_m = self.add_weight( \n\"bias_mean\", shape=[self.units], \ninitializer=HeNormal(), dtype=self.dtype, trainable=True, \n) \nself.bias_v = self.add_weight( \n\"bias_variance\", shape=[self.units], \ninitializer=over_gamma, dtype=self.dtype, trainable=True, \n) \nself.Normal = tfp.distributions.Normal( \nloc=tf.constant(0.0, dtype=self.dtype), \nscale=tf.constant(1.0, dtype=self.dtype), \n) \nself.built = True \n    ...\n```", "```py\n\nclass PBdivLULayer(PBPLayer): \n@tf.function \ndef call(self, x: tf.Tensor): \n\"\"\"Calculate deterministic output\"\"\" \n# x is of shape [batch, divv_units] \nx = super().call(x) \nz = tf.maximum(x, tf.zeros_like(x))  # [batch, units] \nreturn z \n\n@tf.function \ndef predict(self, previous_mean: tf.Tensor, previous_variance: tf.Tensor): \nma, va = super().predict(previous_mean, previous_variance) \nmb, vb = get_bias_mean_variance(ma, va, self.Normal) \n        return mb, vb\n```", "```py\n\ndef get_bias_mean_variance(ma, va, normal): \nvariance_sqrt = tf.math.sqrt(tf.maximum(va, tf.zeros_like(va))) \nalpha = safe_div(ma, variance_sqrt) \nalpha_inv = safe_div(tf.constant(1.0, dtype=alpha.dtype), alpha) \nalpha_cdf = normal.cdf(alpha) \ngamma = tf.where( \nalpha *<* -30, \n-alpha + alpha_inv * (-1 + 2 * tf.math.square(alpha_inv)), \nsafe_div(normal.prob(-alpha), alpha_cdf), \n) \nvp = ma + variance_sqrt * gamma \nbias_mean = alpha_cdf * vp \nbias_variance = bias_mean * vp * normal.cdf(-alpha) + alpha_cdf * va * ( \n1 - gamma * (gamma + alpha) \n) \n    return bias_mean, bias_variance\n```", "```py\n\nunits = [50, 50, 1] \nlayers = [] \nlast_shape = X_train.shape[1] \n\nfor unit in units[:-1]: \nlayer = PBdivLULayer(unit) \nlayer.build(last_shape) \nlayers.append(layer) \nlast_shape = unit \nlayer = PBPLayer(units[-1]) \nlayer.build(last_shape) \nlayers.append(layer)\n```", "```py\n\nclass PBP: \ndef __init__( \nself, \nlayers: List[tf.keras.layers.Layer], \ndtype: Union[tf.dtypes.DType, np.dtype, str] = tf.float32 \n): \nself.alpha = tf.Variable(6.0, trainable=True, dtype=dtype) \nself.beta = tf.Variable(6.0, trainable=True, dtype=dtype) \nself.layers = layers \nself.Normal = tfp.distributions.Normal( \nloc=tf.constant(0.0, dtype=dtype), \nscale=tf.constant(1.0, dtype=dtype), \n) \nself.Gamma = tfp.distributions.Gamma( \nconcentration=self.alpha, rate=self.beta \n) \n\ndef fit(self, x, y, batch_size: int = 16, n_epochs: int = 1): \ndata = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size) \nfor epoch_index in range(n_epochs): \nprint(f\"{epoch_index=}\") \nfor x_batch, y_batch in data: \ndiff_square, v, v0 = self.update_gradients(x_batch, y_batch) \nalpha, beta = update_alpha_beta( \nself.alpha, self.beta, diff_square, v, v0 \n) \nself.alpha.assign(alpha) \nself.beta.assign(beta) \n\n@tf.function \ndef predict(self, x: tf.Tensor): \nm, v = x, tf.zeros_like(x) \nfor layer in self.layers: \nm, v = layer.predict(m, v) \nreturn m, v \n    ...\n```", "```py\n\n... \n@tf.function \ndef update_gradients(self, x, y): \ntrainables = [layer.trainable_weights for layer in self.layers] \nwith tf.GradientTape() as tape: \ntape.watch(trainables) \nm, v = self.predict(x) \nv0 = v + safe_div(self.beta, self.alpha - 1) \ndiff_square = tf.math.square(y - m) \nlogZ0 = logZ(diff_square, v0) \ngrad = tape.gradient(logZ0, trainables) \nfor l, g in zip(self.layers, grad): \nl.apply_gradient(g) \n        return diff_square, v, v0\n```", "```py\n\n# ... PBPLayer continued \n\n@tf.function \ndef predict(self, previous_mean: tf.Tensor, previous_variance: tf.Tensor): \nmean = ( \ntf.tensordot(previous_mean, self.weights_m, axes=[1, 0]) \n+ tf.expand_dims(self.bias_m, axis=0) \n) * self.inv_sqrtV1 \n\nvariance = ( \ntf.tensordot( \nprevious_variance, tf.math.square(self.weights_m), axes=[1, 0] \n) \n+ tf.tensordot( \ntf.math.square(previous_mean), self.weights_v, axes=[1, 0] \n) \n+ tf.expand_dims(self.bias_v, axis=0) \n+ tf.tensordot(previous_variance, self.weights_v, axes=[1, 0]) \n) * self.inv_V1 \n\n        return mean, variance\n```", "```py\n\npi = tf.math.atan(tf.constant(1.0, dtype=tf.float32)) * 4 \nLOG_INV_SQRT2PI = -0.5 * tf.math.log(2.0 * pi) \n\n@tf.function \ndef logZ(diff_square: tf.Tensor, v: tf.Tensor): \nv0 = v + 1e-6 \nreturn tf.reduce_sum( \n-0.5 * (diff_square / v0) + LOG_INV_SQRT2PI - 0.5 * tf.math.log(v0) \n) \n\n@tf.function \ndef logZ1_minus_logZ2(diff_square: tf.Tensor, v1: tf.Tensor, v2: tf.Tensor): \nreturn tf.reduce_sum( \n-0.5 * diff_square * safe_div(v2 - v1, v1 * v2) \n- 0.5 * tf.math.log(safe_div(v1, v2) + 1e-6) \n    )\n```", "```py\n\n# ... PBPLayer continued \n\n@tf.function \ndef apply_gradient(self, gradient): \ndlogZ_dwm, dlogZ_dwv, dlogZ_dbm, dlogZ_dbv = gradient \n\n# Weights \nself.weights_m.assign_add(self.weights_v * dlogZ_dwm) \nnew_mean_variance = self.weights_v - ( \ntf.math.square(self.weights_v) \n* (tf.math.square(dlogZ_dwm) - 2 * dlogZ_dwv) \n) \nself.weights_v.assign(non_negative_constraint(new_mean_variance)) \n\n# Bias \nself.bias_m.assign_add(self.bias_v * dlogZ_dbm) \nnew_bias_variance = self.bias_v - ( \ntf.math.square(self.bias_v) \n* (tf.math.square(dlogZ_dbm) - 2 * dlogZ_dbv) \n) \n        self.bias_v.assign(non_negative_constraint(new_bias_variance))\n```", "```py\n\ndef update_alpha_beta(alpha, beta, diff_square, v, v0): \nalpha1 = alpha + 1 \nv1 = v + safe_div(beta, alpha) \nv2 = v + beta / alpha1 \nlogZ2_logZ1 = logZ1_minus_logZ2(diff_square, v1=v2, v2=v1) \nlogZ1_logZ0 = logZ1_minus_logZ2(diff_square, v1=v1, v2=v0) \nlogZ_diff = logZ2_logZ1 - logZ1_logZ0 \nZ0Z2_Z1Z1 = safe_exp(logZ_diff) \npos_where = safe_exp(logZ2_logZ1) * (alpha1 - safe_exp(-logZ_diff) * alpha) \nneg_where = safe_exp(logZ1_logZ0) * (Z0Z2_Z1Z1 * alpha1 - alpha) \nbeta_denomi = tf.where(logZ_diff *>*= 0, pos_where, neg_where) \nbeta = safe_div(beta, tf.maximum(beta_denomi, tf.zeros_like(beta))) \n\nalpha_denomi = Z0Z2_Z1Z1 * safe_div(alpha1, alpha) - 1.0 \n\nalpha = safe_div( \ntf.constant(1.0, dtype=alpha_denomi.dtype), \ntf.maximum(alpha_denomi, tf.zeros_like(alpha)), \n) \n\n    return alpha, beta\n```", "```py\n\n@tf.function \ndef safe_div(x: tf.Tensor, y: tf.Tensor, eps: tf.Tensor = tf.constant(1e-6)): \n_eps = tf.cast(eps, dtype=y.dtype) \nreturn x / (tf.where(y *>*= 0, y + _eps, y - _eps)) \n\n@tf.function \ndef safe_exp(x: tf.Tensor, BIG: tf.Tensor = tf.constant(20)): \nreturn tf.math.exp(tf.math.minimum(x, tf.cast(BIG, dtype=x.dtype))) \n\n@tf.function \ndef non_negative_constraint(x: tf.Tensor): \n    return tf.maximum(x, tf.zeros_like(x))\n```", "```py\n\nmodel = PBP(layers) \nmodel.fit(x, y, batch_size=1, n_epochs=1)\n```", "```py\n\n# Compute our means and standard deviations \nmean_X_train, mean_y_train, std_X_train, std_y_train = get_mean_std_x_y( \nX_train, y_train \n) \n\n# Normalize our inputs \nX_test = (X_test - np.full(X_test.shape, mean_X_train)) / \nnp.full(X_test.shape, std_X_train) \n\n# Ensure that our inputs are of the correct shape \nX_test = ensure_input(X_test, tf.float32, X_test.shape[1])\n```", "```py\n\nm, v = model.predict(X_test)\n```", "```py\n\n# Compute our variance noise - the baseline variation we observe in our targets \nv_noise = (model.beta / (model.alpha - 1) * std_y_train**2) \n\n# Rescale our mean values \nm = m * std_y_train + mean_y_train \n\n# Rescale our variance values \nv = v * std_y_train**2 \n\n# Reshape our variables \nm = np.squeeze(m.numpy()) \nv = np.squeeze(v.numpy()) \nv_noise = np.squeeze(v_noise.numpy().reshape(-1, 1))\n```", "```py\n\nrmse = np.sqrt(np.mean((y_test - m) ** 2)) \ntest_log_likelihood = np.mean( \n-0.5 * np.log(2 * math.pi * v) \n- 0.5 * (y_test - m) ** 2 / v \n) \ntest_log_likelihood_with_vnoise = np.mean( \n-0.5 * np.log(2 * math.pi * (v + v_noise)) \n- 0.5 * (y_test - m) ** 2 / (v + v_noise) \n)\n```"]