<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Preface
                </header>
            
            <article>
                
<p class="mce-root">For years, those who have been faithfully working on machine learning have seen the field grow and flourish, yielding amazing technology and even promising radical societal changes. However, for those who want to join us in studying this area, it might seem a little bit intimidating. Certainly, there is so much stuff out there on the web and it has become very difficult to navigate through all the papers, and the code, to find reliable introductory content for those who want to join us in the field of deep learning. While there are many introductory books on machine learning, most are inadequate in addressing the needs of those who specifically want to work on deep learning and have the minimum necessary mathematical, algorithmic, and programming skills.</p>
<p class="mce-root">This book aims to reach out to those beginners in deep learning who are looking for a strong foundation in the basic concepts required to build deep learning models using well-known methodologies. If that sounds like you, then this book might be what you need. The book assumes no prior extensive exposure to neural networks and deep learning and starts by reviewing the machine learning fundamentals needed for deep learning. Then, it explains how to prepare data by cleaning and preprocessing it for deep learning and gradually goes on to introduce neural networks and the popular supervised neural network architectures, such as <strong>convolutional neural networks</strong> (<strong>CNNs</strong>), <strong>recurrent neural networks</strong> (<strong>RNNs</strong>), and <strong>generative adversarial networks</strong> (<strong>GANs</strong>), and unsupervised architectures, such as <strong>autoencoders</strong> (<strong>AEs</strong>), <strong>variational autoencoders</strong> (<strong>VAEs</strong>), and <strong>restricted Boltzmann machines</strong> (<strong>RBMs</strong>). At the end of each chapter, you will have a chance to test your understanding of the concepts and reflect on your own growth.</p>
<p class="mce-root">By the end of the book, you will have an understanding of deep learning concepts and recipes and will be able to distinguish which algorithms are appropriate for different tasks.</p>
<h1 id="uuid-ceba4151-e7a6-41ee-a5ad-5f3ce116b187">Who this book is for</h1>
<p>This book is for aspiring data scientists and deep learning engineers who want to get started with the absolute fundamentals of deep learning and neural networks. Now, about requirements:</p>
<ul>
<li>No prior exposure to deep learning or machine learning is necessary, but it would be a plus.</li>
<li>Some familiarity with linear algebra and Python programming is all you need to get started.</li>
</ul>
<p>This book is for people who value their time and want to get to the point and learn the deep learning recipes needed to <em>do things.</em> </p>
<p>Deep learning can be intimidating if you don’t know the basics. Many people are discouraged because they cannot follow the terminology or sample programs they see on the web. This causes people to make poor decisions about the selection of deep learning algorithms and renders them unable to foresee the consequences of such choices. Therefore, this book is for people who do the following:</p>
<ul>
<li>Value access to good definitions of deep learning concepts</li>
<li>Want a structured method to learn deep learning from scratch</li>
<li>Desire to know the fundamental concepts and really understand them</li>
<li>Want to know how to preprocess data for usage in deep learning algorithms</li>
<li>Are curious about some advanced deep learning algorithms</li>
</ul>
<p>For details about the contents of each chapter, read the next section.</p>
<h1 id="uuid-6a14d01a-16ee-4b2b-935a-8928027f73ea">What this book covers</h1>
<p><a href="e3181710-1bb7-4069-825a-a235355bc116.xhtml">Chapter 1</a>, <em>Introduction to Machine Learning</em>, gives an overview of machine learning. It introduces the motivation behind machine learning and the terminology that is commonly used in the field. It also introduces deep learning and how it fits in the realm of artificial intelligence.</p>
<p><a href="0b6e1f9c-280c-4107-aa1b-862b99f991c8.xhtml">Chapter 2</a><span>, <em>Setup and Introduction to Deep Learning Frameworks</em></span><span>, helps you in the process of setting up TensorFlow and Keras and introduces their usefulness and purpose in deep learning. This chapter also briefly introduces other deep learning libraries to get you acquainted with them in some small way.</span></p>
<p><a href="8300fba9-620e-4bc3-8d81-3b02c5043a0d.xhtml">Chapter 3</a><span>, <em>Preparing Data</em></span><span>, introduces you to the main concepts behind data processing to make it useful in deep learning. It will cover essential concepts of formatting outputs and inputs that are categorical or real-valued, as well as exploring techniques for augmenting data or reducing the dimensions of data.</span></p>
<p><a href="7f55e68e-2e9f-486f-9337-5b2ea7bdb504.xhtml">Chapter 4</a><span>, <em>Learning from Data</em></span><span>, introduces the most elementary concepts around the theory of deep learning, including measuring performance on regression and classification as well as the identification of overfitting. It also offers some warnings about optimizing hyperparameters.</span></p>
<p><a href="4e4b45a6-1924-4918-b2cd-81f0448fb213.xhtml">Chapter 5</a><span>, <em>Training a Single Neuron</em></span><span>, introduces the concept of a neuron and connects it to the perceptron model, which learns from data in a simple manner. The perceptron model is key to understanding basic neural models that learn from data. It also exposes the problem of non-linearly separable data.</span></p>
<p><a href="a6dd89cc-54bd-454d-8bea-7dd4518e85b0.xhtml">Chapter 6</a><span>, <em>Training Multiple Layers of Neurons</em></span><span>, brings you face to face with the first challenges of deep learning using the multi-layer perceptron algorithm, such as gradient descent techniques for error minimization, and hyperparameter optimization to achieve generalization.</span></p>
<p><a href="480521d9-845c-4c0a-b82b-be5f15da0171.xhtml">Chapter 7</a><span>, <em>Autoencoders</em></span><span>, describes the AE model by explaining the necessity of both encoding and decoding layers. It explores the loss functions associated with the autoencoder problem and it applies it to the dimensionality reduction problem and data visualization.</span></p>
<p><a href="6677b8b1-806c-4c39-8c1e-371e83501acf.xhtml">Chapter 8</a><span>, <em>Deep Autoencoders</em></span><span>, introduces the idea of deep belief networks and the significance of this type of deep unsupervised learning. It explains such concepts by introducing deep AEs and contrasting them with shallow AEs. </span></p>
<p><a href="c7b8496e-70e6-47ab-8746-d5893a10493d.xhtml">Chapter 9</a><span>, <em>Variational Autoencoders</em></span><span>, introduces the philosophy behind generative models in the unsupervised deep learning field and their importance in the production of models that are robust against noise. It presents the VAE as a better alternative to a deep AE when working with perturbed data. </span></p>
<p><span><a href="6ec46669-c8d3-4003-ba28-47114f1515df.xhtml">Chapter 10</a>, <em>Restricted Boltzmann Machines</em></span><span>, complements the book's coverage of deep belief models by presenting RBMs. The backward-forward nature of RBMs is introduced and contrasted with the forward-only nature of AEs. The chapter compares RBMs and AEs on the problem of data dimensionality reduction using visual representations of the reduced data.</span></p>
<p><span><a href="03e9a734-fb56-485d-ae90-66fb98ecd4d1.xhtml">Chapter 11</a>, <em>Deep and Wide Neural Networks</em></span><span>, explains the difference in performance and complexities of deep versus wide neural networks. It introduces the concept of dense networks and sparse networks in terms of the connections between neurons. </span></p>
<p><span><a href="c36bdee9-51f3-4283-8f15-6dd603d071a1.xhtml">Chapter 12</a>, <em>Convolutional Neural Networks</em></span><span>, introduces CNNs, starting with the convolution operation and moving forward to ensemble layers of convolutional operations aiming to learn filters that operate over data. The chapter concludes by showing how to visualize the learned filters.</span></p>
<p><span><a href="a6e892c5-e890-4c0a-ad92-c5442328a64a.xhtml"/><a href="a6e892c5-e890-4c0a-ad92-c5442328a64a.xhtml">Chapter 13</a>, <em>Recurrent Neural Networks</em></span><span>, presents the most fundamental concepts of recurrent networks, exposing their shortcomings to justify the existence and success of long short-term memory models. Sequential models are explored with applications for image processing and natural language processing.</span></p>
<p><span><a href="7b09fe4b-078e-4c57-8a81-dc0863eba43d.xhtml">Chapter 14</a>, <em>Generative Adversarial Networks</em></span><span>, introduces the semi-supervised learning approach of GANs, which belong to the family of adversarial learning. The chapter explains the concepts of generator and discriminator and talks about why having good approximations to the distribution of the training data can lead to the success of a model in, for example, the production of data from random noise.</span></p>
<p><span><a href="216a275e-ae7e-451c-a8c6-f31eac314d3f.xhtml">Chapter 15</a>, <em>Final Remarks on the Future of Deep Learning</em></span><span>, briefly exposes you to the new exciting topics and opportunities in deep learning. Should you want to continue your learning, you will find here other resources from Packt Publishing that you can use to move forward in this field.</span></p>
<h1 id="uuid-50c81af6-1cd0-4601-8064-243ba6cb3823">To get the most out of this book</h1>
<p>You will need to make sure that you have an internet browser and access to Google Colabs at the following site: <a href="http://colab.research.google.com/">http://colab.research.google.com/</a>.</p>
<p>Although this book assumes no prior exposure to deep learning or machine learning, you have to have some familiarity with linear algebra and Python programming in order to get the most out of this book. </p>
<p>In order to ensure compatibility with future releases of Python libraries for machine and deep learning, we have included a list of current versions produced with the <kbd>!pip freeze</kbd> <span>command </span>in the code bundle and on the GitHub repository of this book; however, these are only for reference and future compatibility – remember that Google Colabs already has all the necessary setup.  </p>
<p><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/" target="_blank">https://github.com/PacktPublishing/</a></span></strong><span>. Check them out! </span><span>Again, the list of libraries is for reference, but Google Colabs has the latest setup.</span></p>
<p><strong>If you are using the digital version of this book, we advise you to type the code yourself or access the code via the GitHub repository (link available in the next section). Doing so will help you avoid any potential errors related to <span>the copying and pasting of code</span>.</strong></p>
<p>Once you reach the end of your learning journey using this book, celebrate, and pay close attention to the last chapter of the book, which will point you in new directions. Remember to always keep learning: it is one of the keys to success in life.</p>
<h2 id="uuid-b42e0e7f-0cf5-42a9-81d3-a13347de9f8a">Download the example code files</h2>
<p>You can download the example code files for this book from your account at <a href="http://www.packt.com" target="_blank">www.packt.com</a>. If you purchased this book elsewhere, you can visit <a href="https://www.packtpub.com/support" target="_blank">www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packt.com" target="_blank">www.packt.com</a>.</li>
<li>Select the <span class="packt_screen">Support</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for Mac</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at</span><span> <a href="https://github.com/PacktPublishing/Deep-Learning-for-Beginners">https://github.com/PacktPublishing/Deep-Learning-for-Beginners</a></span><span>. </span><span>In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p> </p>
<h2 id="uuid-529df78d-5a72-48b3-81a9-0d84f4b22208">Download the color images</h2>
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here:<span> <a href="https://static.packt-cdn.com/downloads/9781838640859_ColorImages.pdf">https://static.packt-cdn.com/downloads/9781838640859_ColorImages.pdf</a></span>.</p>
<h2 id="uuid-555af648-791c-459d-937c-f8cac77876eb">Conventions used</h2>
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>:<span> </span><span>Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.<span> </span><span>Here is an example:</span><span> </span>"The <kbd>predict()</kbd> methods in the latent encoder model, <kbd>latent_ncdr</kbd>, and the <kbd>autoencoder</kbd> model produce the output at the specified layers."</p>
<p>A block of code is set as follows:</p>
<pre>x = np.array([[1., 1., 0., 1., 1., 0., 0., 0.]]) #216<br/><br/>encdd = latent_ncdr.predict(x)<br/>x_hat = autoencoder.predict(x)<br/><br/>print(encdd)<br/>print(x_hat)<br/>print(np.mean(np.square(x-x_hat))) </pre>
<p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre>import matplotlib.pyplot as plt<br/><br/>plt.plot(<strong>hist.history['loss']</strong>)<br/>plt.title('Model reconstruction loss')<br/>plt.ylabel('MSE')<br/>plt.xlabel('Epoch')<br/>plt.show()</pre>
<p>Any command-line input or output is written as follows:</p>
<pre><strong>$ pip install tensorflow-gpu</strong></pre>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "The first important thing is a new activation function called the <strong>hyperbolic tangent</strong>.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>
<h1 id="uuid-ca58bbbf-f13e-40e3-8af4-aefe5bf8fcb1">Get in touch</h1>
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: If you have questions about any aspect of this book,<span> </span><span>mention the book title in the subject of your message and</span> email us at<span> </span><kbd><span>customercare@packtpub.com</span></kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit<span> </span><a href="https://www.packtpub.com/support/errata" target="_blank">www.packtpub.com/support/errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at<span> </span><kbd>copyright@packt.com</kbd><span> </span>with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit<span> </span><a href="http://authors.packtpub.com/" target="_blank">authors.packtpub.com</a>.</p>
<h2 id="uuid-bb61d049-5348-422e-bff8-746b0d3e5877">Reviews</h2>
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="http://www.packt.com/" target="_blank">packt.com</a>.</p>


            </article>

            
        </section>
    </body></html>