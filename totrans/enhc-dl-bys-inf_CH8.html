<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
  <meta charset="utf-8"/>
  <meta name="generator" content="pandoc"/>
  <title>ch013.xhtml</title>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
</head>
<body epub:type="bodymatter">
<section id="chapter-8-applying-bayesian-deep-learning" class="level1 chapterHead" data-number="13">
<h1 class="chapterHead" data-number="13"><span class="titlemark">ChapterÂ 8</span><br/>
<span id="x1-1320008"></span>Applying Bayesian Deep Learning</h1>
<p>This chapter will guide you through a variety of applications of Bayesian deep learning (BDL). These will include the use of BDL in standard classification tasks, as well as demonstrating how it can be used in more sophisticated ways for out-of-distribution detection, data selection, and reinforcement learning.</p>
<p>We will cover these topics in the following sections:</p>
<ul>
<li><p>Detecting out-of-distribution data</p></li>
<li><p>Being robust against dataset drift</p></li>
<li><p>Using data selection via uncertainty to keep models fresh</p></li>
<li><p>Using uncertainty estimates for smarter reinforcement learning</p></li>
<li><p>Susceptibility to adversarial input</p></li>
</ul>
<p><span id="x1-132001r213"></span></p>
<section id="technical-requirements-6" class="level2 sectionHead" data-number="13.1">
<h2 class="sectionHead" data-number="13.1" id="sigil_toc_id_87"><span class="titlemark">8.1 </span> <span id="x1-1330001"></span>Technical requirements</h2>
<p>All of the code for this book can be found on the GitHub repository for the book: <a href="https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference" class="url"><span class="No-Break">https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference</span></a>. <span id="x1-133001r215"></span></p>
</section>
<section id="detecting-out-of-distribution-data" class="level2 sectionHead" data-number="13.2">
<h2 class="sectionHead" data-number="13.2" id="sigil_toc_id_88"><span class="titlemark">8.2 </span> <span id="x1-1340002"></span>Detecting out-of-distribution data</h2>
<p>Typical neural networks do<span id="dx1-134001"></span> not handle out-of-distribution data well. We saw in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a> that a cat-dog classifier classified an image of a parachute as a dog with more than 99% confidence. In this section, we will look into what we can do about this vulnerability of neural networks. We will do the following:</p>
<ul>
<li><p>Explore the problem visually by perturbing a digit of the <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> dataset</p></li>
<li><p>Explain the typical way out-of-distribution detection performance is reported in the literature</p></li>
<li><p>Review the out-of-distribution detection performance of some of the standard practical BDL methods we look at in this chapter</p></li>
<li><p>Explore even more practical methods that are specifically tailored to detect out-of-distribution detection</p></li>
</ul>
<p><span id="x1-134002r209"></span></p>
<section id="exploring-the-problem-of-out-of-distribution-detection" class="level3 subsectionHead" data-number="13.2.1">
<h3 class="subsectionHead" data-number="13.2.1" id="sigil_toc_id_89"><span class="titlemark">8.2.1 </span> <span id="x1-1350001"></span>Exploring the problem of out-of-distribution detection</h3>
<p>To give you a better understanding of what out-of-distribution <span id="dx1-135001"></span>performance is like, we will start with a visual example. Here is what we will do:</p>
<ul>
<li><p>We will train a standard network on the <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> digit dataset</p></li>
<li><p>We will then perturb a digit and gradually make it more out-of-distribution</p></li>
<li><p>We will report the confidence score of a standard model and MC dropout</p></li>
</ul>
<p>With this visual example, we can see how simple Bayesian methods can improve the out-of-distribution detection performance over a standard deep learning model. We start by training a simple model on the <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> dataset.</p>
<div class="IMG---Figure">
<img src="../media/file160.png" alt="PIC"/> <span id="x1-135002r1"></span> <span id="x1-135003"></span></div>
<p class="IMG---Caption">FigureÂ 8.1: The classes of the MNIST dataset: 28x28 pixel images of the digits zero to nine 
</p>
<p>We use <code>TensorFlow</code> to train our model, <code>numpy</code> to make our images more out-of-distribution, and <code>Matplotlib</code> to visualize our data.</p>
<pre id="fancyvrb151" class="fancyvrb"><span id="x1-135012r1"></span> 
<code><span id="textcolor3668"><span>import</span></span><span>Â </span><span id="textcolor3669"><span>tensorflow</span></span><span>Â </span><span id="textcolor3670"><span>as</span></span><span>Â </span><span id="textcolor3671"><span>tf</span></span> <span id="x1-135014r2"></span> </code>
<code><span id="textcolor3672"><span>from</span></span><span>Â </span><span id="textcolor3673"><span>tensorflow.keras</span></span><span>Â </span><span id="textcolor3674"><span>import</span></span><span>Â datasets,</span><span>Â layers,</span><span>Â models</span> <span id="x1-135016r3"></span> </code>
<code><span id="textcolor3675"><span>import</span></span><span>Â </span><span id="textcolor3676"><span>numpy</span></span><span>Â </span><span id="textcolor3677"><span>as</span></span><span>Â </span><span id="textcolor3678"><span>np</span></span> <span id="x1-135018r4"></span> </code>
<code><span id="textcolor3679"><span>import</span></span><span>Â </span><span id="textcolor3680"><span>matplotlib.pyplot</span></span><span>Â </span><span id="textcolor3681"><span>as</span></span><span>Â </span><span id="textcolor3682"><span>plt</span></span></code></pre>
<p>The <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> dataset is available in TensorFlow, so we can just load it:</p>
<pre id="fancyvrb152" class="fancyvrb"><span id="x1-135025r1"></span> 
<code><span>(train_images,</span><span>Â train_labels),</span><span>Â (</span> <span id="x1-135027r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_images,</span> <span id="x1-135029r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels,</span> <span id="x1-135031r4"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor3683"><span>=</span></span><span>Â datasets</span><span id="textcolor3684"><span>.</span></span><span>mnist</span><span id="textcolor3685"><span>.</span></span><span>load_data()</span> <span id="x1-135033r5"></span> </code>
<code><span>train_images,</span><span>Â test_images</span><span>Â </span><span id="textcolor3686"><span>=</span></span><span>Â train_images</span><span>Â </span><span id="textcolor3687"><span>/</span></span><span>Â </span><span id="textcolor3688"><span>255.0</span></span><span>,</span><span>Â test_images</span><span>Â </span><span id="textcolor3689"><span>/</span></span><span>Â </span><span id="textcolor3690"><span>255.0</span></span></code></pre>
<p><span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> is a simple dataset, so a simple model allows us to achieve a test accuracy of more than 99%. We use a standard CNN with three convolutional layers:</p>
<pre id="fancyvrb153" class="fancyvrb"><span id="x1-135051r1"></span> 
<code><span id="textcolor3691"><span>def</span></span><span>Â </span><span id="textcolor3692"><span>get_model</span></span><span>():</span> <span id="x1-135053r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor3693"><span>=</span></span><span>Â models</span><span id="textcolor3694"><span>.</span></span><span>Sequential()</span> <span id="x1-135055r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3695"><span>.</span></span><span>add(</span> <span id="x1-135057r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor3696"><span>.</span></span><span>Conv2D(</span><span id="textcolor3697"><span>32</span></span><span>,</span><span>Â (</span><span id="textcolor3698"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3699"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor3700"><span>=</span></span><span id="textcolor3701"><span>"relu"</span></span><span>,</span><span>Â input_shape</span><span id="textcolor3702"><span>=</span></span><span>(</span><span id="textcolor3703"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor3704"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor3705"><span>1</span></span><span>))</span> <span id="x1-135059r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-135061r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3706"><span>.</span></span><span>add(layers</span><span id="textcolor3707"><span>.</span></span><span>MaxPooling2D((</span><span id="textcolor3708"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor3709"><span>2</span></span><span>)))</span> <span id="x1-135063r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3710"><span>.</span></span><span>add(layers</span><span id="textcolor3711"><span>.</span></span><span>Conv2D(</span><span id="textcolor3712"><span>64</span></span><span>,</span><span>Â (</span><span id="textcolor3713"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3714"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor3715"><span>=</span></span><span id="textcolor3716"><span>"relu"</span></span><span>))</span> <span id="x1-135065r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3717"><span>.</span></span><span>add(layers</span><span id="textcolor3718"><span>.</span></span><span>MaxPooling2D((</span><span id="textcolor3719"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor3720"><span>2</span></span><span>)))</span> <span id="x1-135067r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3721"><span>.</span></span><span>add(layers</span><span id="textcolor3722"><span>.</span></span><span>Conv2D(</span><span id="textcolor3723"><span>64</span></span><span>,</span><span>Â (</span><span id="textcolor3724"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3725"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor3726"><span>=</span></span><span id="textcolor3727"><span>"relu"</span></span><span>))</span> <span id="x1-135069r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3728"><span>.</span></span><span>add(layers</span><span id="textcolor3729"><span>.</span></span><span>Flatten())</span> <span id="x1-135071r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3730"><span>.</span></span><span>add(layers</span><span id="textcolor3731"><span>.</span></span><span>Dense(</span><span id="textcolor3732"><span>64</span></span><span>,</span><span>Â activation</span><span id="textcolor3733"><span>=</span></span><span id="textcolor3734"><span>"relu"</span></span><span>))</span> <span id="x1-135073r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3735"><span>.</span></span><span>add(layers</span><span id="textcolor3736"><span>.</span></span><span>Dense(</span><span id="textcolor3737"><span>10</span></span><span>))</span> <span id="x1-135075r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3738"><span>return</span></span><span>Â model</span> <span id="x1-135077r14"></span> </code>
<code><span id="x1-135079r15"></span></code>
<code><span id="x1-135081r16"></span></code>
<code><span>model</span><span>Â </span><span id="textcolor3739"><span>=</span></span><span>Â get_model()</span></code></pre>
<p>We can then compile and train our model. We obtain a validation<span id="dx1-135082"></span> accuracy of over 99% after just 5 epochs.</p>
<pre id="fancyvrb154" class="fancyvrb"><span id="x1-135101r1"></span> 
<code><span id="textcolor3740"><span>def</span></span><span>Â </span><span id="textcolor3741"><span>fit_model</span></span><span>(model):</span> <span id="x1-135103r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3742"><span>.</span></span><span>compile(</span> <span id="x1-135105r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â optimizer</span><span id="textcolor3743"><span>=</span></span><span id="textcolor3744"><span>"adam"</span></span><span>,</span> <span id="x1-135107r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor3745"><span>=</span></span><span>tf</span><span id="textcolor3746"><span>.</span></span><span>keras</span><span id="textcolor3747"><span>.</span></span><span>losses</span><span id="textcolor3748"><span>.</span></span><span>SparseCategoricalCrossentropy(from_logits</span><span id="textcolor3749"><span>=</span></span><span id="textcolor3750"><span>True</span></span><span>),</span> <span id="x1-135109r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor3751"><span>=</span></span><span>[</span><span id="textcolor3752"><span>"accuracy"</span></span><span>],</span> <span id="x1-135111r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-135113r7"></span> </code>
<code><span id="x1-135115r8"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3753"><span>.</span></span><span>fit(</span> <span id="x1-135117r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â train_images,</span> <span id="x1-135119r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â train_labels,</span> <span id="x1-135121r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epochs</span><span id="textcolor3754"><span>=</span></span><span id="textcolor3755"><span>5</span></span><span>,</span> <span id="x1-135123r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â validation_data</span><span id="textcolor3756"><span>=</span></span><span>(test_images,</span><span>Â test_labels),</span> <span id="x1-135125r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-135127r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3757"><span>return</span></span><span>Â model</span> <span id="x1-135129r15"></span> </code>
<code><span id="x1-135131r16"></span></code>
<code><span id="x1-135133r17"></span></code>
<code><span>model</span><span>Â </span><span id="textcolor3758"><span>=</span></span><span>Â fit_model(model)</span></code></pre>
<p>Now, letâ€™s see how this model handles out-of-distribution data. Imagine we deploy this model to recognize digits, but users sometimes fail to write down the entire digit. What happens when users do not write down the entire digit? We can get an answer to this<span id="dx1-135134"></span> question by gradually removing more and more information from a digit, and seeing how our model handles the perturbed inputs. We can define our function to remove <code>signal</code> as follows:</p>
<pre id="fancyvrb155" class="fancyvrb"><span id="x1-135141r1"></span> 
<code><span id="textcolor3759"><span>def</span></span><span>Â </span><span id="textcolor3760"><span>remove_signal</span></span><span>(img:</span><span>Â np</span><span id="textcolor3761"><span>.</span></span><span>ndarray,</span><span>Â num_lines:</span><span>Â </span><span id="textcolor3762"><span>int</span></span><span>)</span><span>Â </span><span id="textcolor3763"><span>-</span><em>&gt;</em></span><span>Â np</span><span id="textcolor3764"><span>.</span></span><span>ndarray:</span> <span id="x1-135143r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â img</span><span>Â </span><span id="textcolor3765"><span>=</span></span><span>Â img</span><span id="textcolor3766"><span>.</span></span><span>copy()</span> <span id="x1-135145r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â img[:num_lines]</span><span>Â </span><span id="textcolor3767"><span>=</span></span><span>Â </span><span id="textcolor3768"><span>0</span></span> <span id="x1-135147r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3769"><span>return</span></span><span>Â img</span></code></pre>
<p>And then we perturb our images:</p>
<pre id="fancyvrb156" class="fancyvrb"><span id="x1-135157r1"></span> 
<code><span>imgs</span><span>Â </span><span id="textcolor3770"><span>=</span></span><span>Â []</span> <span id="x1-135159r2"></span> </code>
<code><span id="textcolor3771"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor3772"><span>in</span></span><span>Â </span><span id="textcolor3773"><span>range</span></span><span>(</span><span id="textcolor3774"><span>28</span></span><span>):</span> <span id="x1-135161r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â img_perturbed</span><span>Â </span><span id="textcolor3775"><span>=</span></span><span>Â remove_signal(img,</span><span>Â i)</span> <span id="x1-135163r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3776"><span>if</span></span><span>Â np</span><span id="textcolor3777"><span>.</span></span><span>array_equal(img,</span><span>Â img_perturbed):</span> <span id="x1-135165r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3778"><span>continue</span></span> <span id="x1-135167r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â imgs</span><span id="textcolor3779"><span>.</span></span><span>append(img_perturbed)</span> <span id="x1-135169r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3780"><span>if</span></span><span>Â img_perturbed</span><span id="textcolor3781"><span>.</span></span><span>sum()</span><span>Â </span><span id="textcolor3782"><span>==</span></span><span>Â </span><span id="textcolor3783"><span>0</span></span><span>:</span> <span id="x1-135171r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3784"><span>break</span></span></code></pre>
<p>We only add perturbed images to our list of images if setting a row to 0 actually changes the original image ( <code>ifÂ np.array_equal(img,Â img_perturbed))</code> and stop once the image is completely black, meaning it just contains pixels with a value of 0. We run inference on these images:</p>
<pre id="fancyvrb157" class="fancyvrb"><span id="x1-135175r1"></span> 
<code><span>softmax_predictions</span><span>Â </span><span id="textcolor3787"><span>=</span></span><span>Â tf</span><span id="textcolor3788"><span>.</span></span><span>nn</span><span id="textcolor3789"><span>.</span></span><span>softmax(model(np</span><span id="textcolor3790"><span>.</span></span><span>expand_dims(imgs,</span><span>Â </span><span id="textcolor3791"><span>-</span></span><span id="textcolor3792"><span>1</span></span><span>)),</span><span>Â axis</span><span id="textcolor3793"><span>=</span></span><span id="textcolor3794"><span>1</span></span><span>)</span></code></pre>
<p>We can then plot all images with their predicted labels and confidence scores:</p>
<pre id="fancyvrb158" class="fancyvrb"><span id="x1-135192r1"></span> 
<code><span>plt</span><span id="textcolor3795"><span>.</span></span><span>figure(figsize</span><span id="textcolor3796"><span>=</span></span><span>(</span><span id="textcolor3797"><span>10</span></span><span>,</span><span>Â </span><span id="textcolor3798"><span>10</span></span><span>))</span> <span id="x1-135194r2"></span> </code>
<code><span>bbox_dict</span><span>Â </span><span id="textcolor3799"><span>=</span></span><span>Â </span><span id="textcolor3800"><span>dict</span></span><span>(</span> <span id="x1-135196r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â fill</span><span id="textcolor3801"><span>=</span></span><span id="textcolor3802"><span>True</span></span><span>,</span><span>Â facecolor</span><span id="textcolor3803"><span>=</span></span><span id="textcolor3804"><span>"white"</span></span><span>,</span><span>Â alpha</span><span id="textcolor3805"><span>=</span></span><span id="textcolor3806"><span>0.5</span></span><span>,</span><span>Â edgecolor</span><span id="textcolor3807"><span>=</span></span><span id="textcolor3808"><span>"white"</span></span><span>,</span><span>Â linewidth</span><span id="textcolor3809"><span>=</span></span><span id="textcolor3810"><span>0</span></span> <span id="x1-135198r4"></span> </code>
<code><span>)</span> <span id="x1-135200r5"></span> </code>
<code><span id="textcolor3811"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor3812"><span>in</span></span><span>Â </span><span id="textcolor3813"><span>range</span></span><span>(</span><span id="textcolor3814"><span>len</span></span><span>(imgs)):</span> <span id="x1-135202r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3815"><span>.</span></span><span>subplot(</span><span id="textcolor3816"><span>5</span></span><span>,</span><span>Â </span><span id="textcolor3817"><span>5</span></span><span>,</span><span>Â i</span><span>Â </span><span id="textcolor3818"><span>+</span></span><span>Â </span><span id="textcolor3819"><span>1</span></span><span>)</span> <span id="x1-135204r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3820"><span>.</span></span><span>xticks([])</span> <span id="x1-135206r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3821"><span>.</span></span><span>yticks([])</span> <span id="x1-135208r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3822"><span>.</span></span><span>grid(</span><span id="textcolor3823"><span>False</span></span><span>)</span> <span id="x1-135210r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3824"><span>.</span></span><span>imshow(imgs[i],</span><span>Â cmap</span><span id="textcolor3825"><span>=</span></span><span id="textcolor3826"><span>"gray"</span></span><span>)</span> <span id="x1-135212r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â prediction</span><span>Â </span><span id="textcolor3827"><span>=</span></span><span>Â softmax_predictions[i]</span><span id="textcolor3828"><span>.</span></span><span>numpy()</span><span id="textcolor3829"><span>.</span></span><span>max()</span> <span id="x1-135214r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â label</span><span>Â </span><span id="textcolor3830"><span>=</span></span><span>Â np</span><span id="textcolor3831"><span>.</span></span><span>argmax(softmax_predictions[i])</span> <span id="x1-135216r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3832"><span>.</span></span><span>xlabel(</span><span id="textcolor3833"><span>f</span></span><span id="textcolor3834"><span>"</span></span><span id="textcolor3835"><span>{</span></span><span>label</span><span id="textcolor3836"><span>}</span></span><span id="textcolor3837"><span>Â -</span><span>Â </span></span><span id="textcolor3838"><span>{</span></span><span>prediction</span><span id="textcolor3839"><span>:</span></span><span id="textcolor3840"><span>.2%</span></span><span id="textcolor3841"><span>}</span></span><span id="textcolor3842"><span>"</span></span><span>)</span> <span id="x1-135218r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â plt</span><span id="textcolor3843"><span>.</span></span><span>text(</span><span id="textcolor3844"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor3845"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3846"><span>f</span></span><span id="textcolor3847"><span>"</span><span>Â </span></span><span id="textcolor3848"><span>{</span></span><span>i</span><span id="textcolor3849"><span>+</span></span><span id="textcolor3850"><span>1</span></span><span id="textcolor3851"><span>}</span></span><span id="textcolor3852"><span>"</span></span><span>,</span><span>Â bbox</span><span id="textcolor3853"><span>=</span></span><span>bbox_dict)</span> <span id="x1-135220r15"></span> </code>
<code><span>plt</span><span id="textcolor3854"><span>.</span></span><span>show()</span></code></pre>
<p>This produces the following<span id="dx1-135221"></span> figure:</p>
<div class="IMG---Figure">
<img src="../media/file161.png" alt="PIC"/> <span id="x1-135222r2"></span> <span id="x1-135223"></span></div>
<p class="IMG---Caption">FigureÂ 8.2: Predicted label and corresponding softmax score of a standard neural network for an image that is more and more out-of-distribution 
</p>
<p>We can see in <em>Figure</em> <a href="#x1-135222r2"><em>8.2</em></a> that, initially, our model confidently classifies the image as a <strong>2</strong>. Remarkably, this confidence persists even when it seems unreasonable to do so. For example, the model still classifies image 14 as a <strong>2</strong> with 97.83% confidence. Moreover, the model predicts with 92.32% confidence that a completely horizontal line is a <strong>1</strong>, as we can see in image 17. It looks like our model is overconfident in its predictions.</p>
<p>Letâ€™s see what a slightly different model would predict on these images. Weâ€™ll now use MC dropout as our model. By sampling, we should be able to increase the modelsâ€™ uncertainty compared to a standard NN. Letâ€™s first define our model:</p>
<pre id="fancyvrb159" class="fancyvrb"><span id="x1-135242r1"></span> 
<code><span id="textcolor3855"><span>def</span></span><span>Â </span><span id="textcolor3856"><span>get_dropout_model</span></span><span>():</span> <span id="x1-135244r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor3857"><span>=</span></span><span>Â models</span><span id="textcolor3858"><span>.</span></span><span>Sequential()</span> <span id="x1-135246r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3859"><span>.</span></span><span>add(</span> <span id="x1-135248r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor3860"><span>.</span></span><span>Conv2D(</span><span id="textcolor3861"><span>32</span></span><span>,</span><span>Â (</span><span id="textcolor3862"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3863"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor3864"><span>=</span></span><span id="textcolor3865"><span>"relu"</span></span><span>,</span><span>Â input_shape</span><span id="textcolor3866"><span>=</span></span><span>(</span><span id="textcolor3867"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor3868"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor3869"><span>1</span></span><span>))</span> <span id="x1-135250r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-135252r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3870"><span>.</span></span><span>add(layers</span><span id="textcolor3871"><span>.</span></span><span>Dropout(</span><span id="textcolor3872"><span>0.2</span></span><span>))</span> <span id="x1-135254r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3873"><span>.</span></span><span>add(layers</span><span id="textcolor3874"><span>.</span></span><span>MaxPooling2D((</span><span id="textcolor3875"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor3876"><span>2</span></span><span>)))</span> <span id="x1-135256r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3877"><span>.</span></span><span>add(layers</span><span id="textcolor3878"><span>.</span></span><span>Conv2D(</span><span id="textcolor3879"><span>64</span></span><span>,</span><span>Â (</span><span id="textcolor3880"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3881"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor3882"><span>=</span></span><span id="textcolor3883"><span>"relu"</span></span><span>))</span> <span id="x1-135258r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3884"><span>.</span></span><span>add(layers</span><span id="textcolor3885"><span>.</span></span><span>MaxPooling2D((</span><span id="textcolor3886"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor3887"><span>2</span></span><span>)))</span> <span id="x1-135260r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3888"><span>.</span></span><span>add(layers</span><span id="textcolor3889"><span>.</span></span><span>Dropout(</span><span id="textcolor3890"><span>0.5</span></span><span>))</span> <span id="x1-135262r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3891"><span>.</span></span><span>add(layers</span><span id="textcolor3892"><span>.</span></span><span>Conv2D(</span><span id="textcolor3893"><span>64</span></span><span>,</span><span>Â (</span><span id="textcolor3894"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor3895"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor3896"><span>=</span></span><span id="textcolor3897"><span>"relu"</span></span><span>))</span> <span id="x1-135264r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3898"><span>.</span></span><span>add(layers</span><span id="textcolor3899"><span>.</span></span><span>Dropout(</span><span id="textcolor3900"><span>0.5</span></span><span>))</span> <span id="x1-135266r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3901"><span>.</span></span><span>add(layers</span><span id="textcolor3902"><span>.</span></span><span>Flatten())</span> <span id="x1-135268r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3903"><span>.</span></span><span>add(layers</span><span id="textcolor3904"><span>.</span></span><span>Dense(</span><span id="textcolor3905"><span>64</span></span><span>,</span><span>Â activation</span><span id="textcolor3906"><span>=</span></span><span id="textcolor3907"><span>"relu"</span></span><span>))</span> <span id="x1-135270r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3908"><span>.</span></span><span>add(layers</span><span id="textcolor3909"><span>.</span></span><span>Dropout(</span><span id="textcolor3910"><span>0.5</span></span><span>))</span> <span id="x1-135272r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor3911"><span>.</span></span><span>add(layers</span><span id="textcolor3912"><span>.</span></span><span>Dense(</span><span id="textcolor3913"><span>10</span></span><span>))</span> <span id="x1-135274r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3914"><span>return</span></span><span>Â model</span></code></pre>
<p>Then letâ€™s instantiate it:</p>
<pre id="fancyvrb160" class="fancyvrb"><span id="x1-135278r1"></span> 
<code><span>dropout_model</span><span>Â </span><span id="textcolor3915"><span>=</span></span><span>Â get_dropout_model()</span> <span id="x1-135280r2"></span> </code>
<code><span>dropout_model</span><span>Â </span><span id="textcolor3916"><span>=</span></span><span>Â fit_model(dropout_model)</span></code></pre>
<p>Our model with dropout will achieve a similar accuracy as our vanilla<span id="dx1-135281"></span> model. Letâ€™s now run inference with dropout and plot the mean confidence score of MC dropout:</p>
<pre id="fancyvrb161" class="fancyvrb"><span id="x1-135291r1"></span> 
<code><span>Predictions</span><span>Â </span><span id="textcolor3917"><span>=</span></span><span>Â np</span><span id="textcolor3918"><span>.</span></span><span>array(</span> <span id="x1-135293r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-135295r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor3919"><span>.</span></span><span>nn</span><span id="textcolor3920"><span>.</span></span><span>softmax(dropout_model(imgs_np,</span><span>Â training</span><span id="textcolor3921"><span>=</span></span><span id="textcolor3922"><span>True</span></span><span>),</span><span>Â axis</span><span id="textcolor3923"><span>=</span></span><span id="textcolor3924"><span>1</span></span><span>)</span> <span id="x1-135297r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor3925"><span>for</span></span><span>Â _</span><span>Â </span><span id="textcolor3926"><span>in</span></span><span>Â </span><span id="textcolor3927"><span>range</span></span><span>(</span><span id="textcolor3928"><span>100</span></span><span>)</span> <span id="x1-135299r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-135301r6"></span> </code>
<code><span>)</span> <span id="x1-135303r7"></span> </code>
<code><span>Predictions_mean</span><span>Â </span><span id="textcolor3929"><span>=</span></span><span>Â np</span><span id="textcolor3930"><span>.</span></span><span>mean(predictions,</span><span>Â axis</span><span id="textcolor3931"><span>=</span></span><span id="textcolor3932"><span>0</span></span><span>)</span> <span id="x1-135305r8"></span> </code>
<code><span>plot_predictions(predictions_mean)</span></code></pre>
<p>This again produces a figure showing the predicted labels and their associated confidence scores:</p>
<div class="IMG---Figure">
<img src="../media/file162.png" alt="PIC"/> <span id="x1-135306r3"></span> <span id="x1-135307"></span></div>
<p class="IMG---Caption">FigureÂ 8.3: Predicted label and corresponding softmax score of an MC dropout network for an image that is more and more out-of-distribution 
</p>
<p>We can see in <em>Figure</em> <a href="#x1-135306r3"><em>8.3</em></a> that the model is less certain<span id="dx1-135308"></span> on average. The modelâ€™s confidence decreases a lot when we remove rows from our image. That is desired behaviour: our model does not know the input, so it should be uncertain. However, we can also see that the model is not perfect:</p>
<ul>
<li><p>It maintains a pretty high confidence for images that do not really look like a <strong>2</strong>.</p></li>
<li><p>The modelâ€™s confidence can change a lot when we delete one more row from our images. For example, the modelâ€™s confidence jumps from 61.72% to 37.20% between image 14 and 15.</p></li>
<li><p>The model seems to be more confident that image 20, without any white pixels, is a <strong>1</strong>.</p></li>
</ul>
<p>MC dropout is, in this case, a step in the right direction, but is not handling the out-of-distribution data perfectly. <span id="x1-135309r217"></span></p>
</section>
<section id="systematically-evaluating-ood-detection-performance" class="level3 subsectionHead" data-number="13.2.2">
<h3 class="subsectionHead" data-number="13.2.2" id="sigil_toc_id_90"><span class="titlemark">8.2.2 </span> <span id="x1-1360002"></span>Systematically evaluating OOD detection performance</h3>
<p>The preceding example suggests that MC dropout<span id="dx1-136001"></span> gives out-of-distribution images a lower confidence score on average. But we only evaluated 20 images with a limited variety â€“ we simply removed a single row. This change moved the image more out-of-distribution, but all images shown in the previous section are relatively similar to the training distribution of <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> if you compare it to, letâ€™s say, natural images of objects. Images of airplanes, cars, or birds will definitely be much more out-of-distribution than an image of <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> with a few black rows. So it seems to be reasonable that, if we want to evaluate the OOD detection performance of our model, we should also test it on images that are even more OOD, that is, from a completely different dataset. This is the approach that is typically taken in the literature to evaluate out-of-distribution detection performance. The procedure is as follows:</p>
<ol>
<li><div id="x1-136003x1">
<p>We train a model on in-distribution (ID) images.</p>
</div></li>
<li><div id="x1-136005x2">
<p>We take one or more completely different OOD datasets and feed these to our model.</p>
</div></li>
<li><div id="x1-136007x3">
<p>We now treat the predictions of the model on the ID and OOD test datasets as a binary problem and compute a single score for every image.</p>
<ul>
<li><p>In the case of evaluation of the softmax score, this means that we take the modelâ€™s maximum softmax score for every ID and OOD image.</p></li>
</ul>
</div></li>
<li><div id="x1-136009x4">
<p>With these scores, we can compute binary metrics, such as the area under the receiver operating characteristic (AUROC).<span id="dx1-136010"></span></p>
</div></li>
</ol>
<p>The better the model performs on these binary metrics, the better the modelâ€™s OOD detection performance. <span id="x1-136011r221"></span></p>
</section>
<section id="simple-out-of-distribution-detection-without-retraining" class="level3 subsectionHead" data-number="13.2.3">
<h3 class="subsectionHead" data-number="13.2.3" id="sigil_toc_id_91"><span class="titlemark">8.2.3 </span> <span id="x1-1370003"></span>Simple out-of-distribution detection without retraining</h3>
<p>Although MC dropout can be an effective method<span id="dx1-137001"></span> to detect out-of-distribution data, it comes with a major disadvantage at inference time: we need to run inference five, or maybe even a hundred, times instead of just once. Something similar can be said for certain other Bayesian deep learning methods: although they are principled, they are not always the most practical way to obtain a good OOD detection performance. The main downside is that they often require retraining of your network, which can be expensive to do if you have a lot of data. This is why there is an entire field of OOD detection methods that are not explicitly grounded on Bayesian theory, but can provide a good, simple, or even excellent baseline. These methods often do not require any retraining and can be applied out of the box on a standard neural network. Two methods that are often used in the OOD detection literature are worth mentioning:</p>
<ul>
<li><p><strong>ODIN</strong>: OOD detection with preprocessing and scaling</p></li>
<li><p><strong>Mahalanobis</strong>: OOD detection with intermediate features</p></li>
</ul>
<section id="odin-ood-detection-with-preprocessing-and-scaling" class="level4 likesubsubsectionHead" data-number="13.2.3.1">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.2.3.1"><span id="x1-1380003"></span>ODIN: OOD detection with preprocessing and scaling</h4>
<p><em>O</em>ut-of-<em>DI</em>stribution detector for <em>N</em>eural networks (ODIN) <span id="dx1-138001"></span>is one of the standard methods in practical out-of-distribution detection because of its simplicity and effectiveness. Although the method was introduced in 2017, it is still frequently used as a comparison method in papers that propose out-of-distribution detection methods.</p>
<p>ODIN consists of two key ideas:</p>
<ul>
<li><p><strong>Temperature scaling</strong> of the logit scores before applying the softmax operation to improve the ability of the softmax score to distinguish between in- and out-of-distribution images</p></li>
<li><p><strong>Input preprocessing</strong> to make in-distribution images more in-distribution</p></li>
</ul>
<p>Letâ€™s look at both ideas in a bit more detail.</p>
<p><span class="likeparagraphHead"><span id="x1-1390003"></span>Temperature scaling</span> ODIN works for classification models. <span id="dx1-139001"></span>Given our softmax score computed as</p>
<div class="math-display">
<img src="../media/file163.jpg" class="math-display" alt="pi(x) = âˆ‘--exp(fi(x))--- Nj=1 exp(fj(x)) "/>
</div>
<p>Here, <em>f</em><sub><em>i</em></sub>(<em>x</em>) is a single logit output and <em>f</em><sub><em>j</em></sub>(<em>x</em>) are the logits for all classes for a single example, temperature scaling means that we divide these logit outputs by a constant <em>T</em>:</p>
<div class="math-display">
<img src="../media/file164.jpg" class="math-display" alt=" exp(f (x)âˆ•T) pi(x; T) = âˆ‘N------i---------- j=1 exp (fj(x)âˆ•T) "/>
</div>
<p>For large values of <em>T</em>, temperature scaling causes the softmax scores to be closer to a uniform distribution, which helps to reduce overconfident predictions.</p>
<p>We can apply temperature scaling in Python, given a simple model that outputs the logits:</p>
<pre id="fancyvrb162" class="fancyvrb"><span id="x1-139006r1"></span> 
<code><span>logits</span><span>Â </span><span id="textcolor3933"><span>=</span></span><span>Â model</span><span id="textcolor3934"><span>.</span></span><span>predict(images)</span> <span id="x1-139008r2"></span> </code>
<code><span>logits_scaled</span><span>Â </span><span id="textcolor3935"><span>=</span></span><span>Â logits</span><span>Â </span><span id="textcolor3936"><span>/</span></span><span>Â temperature</span> <span id="x1-139010r3"></span> </code>
<code><span>softmax</span><span>Â </span><span id="textcolor3937"><span>=</span></span><span>Â tf</span><span id="textcolor3938"><span>.</span></span><span>nn</span><span id="textcolor3939"><span>.</span></span><span>softmax(logits,</span><span>Â axis</span><span id="textcolor3940"><span>=</span></span><span id="textcolor3941"><span>1</span></span><span>)</span></code></pre>
<p><span class="likeparagraphHead"><span id="x1-1400003"></span>Input preprocessing</span> We saw in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a> that the <strong>Fast-Gradient</strong> <strong>Sign Method</strong> (<strong>FGSM</strong>)<span id="dx1-140001"></span> allowed us to fool a neural network. By slightly changing an image of a cat, we could make the model predict â€dogâ€ with 99.41% confidence. The idea here was that we could take the sign of the gradient of the loss with respect to the input, multiply it by a small value and add that noise to our image â€“ this moved our image away from our in-distribution class<span id="dx1-140002"></span>. By doing the opposite, that is, subtracting the noise from our image, we make the image more in-distribution. The authors of the ODIN paper show that this causes in-distribution images to have an even higher softmax score compared to out-of-distribution images. This means that we increase the difference between OOD and ID softmax scores, leading to a better OOD detection performance.</p>
<div class="math-display">
<img src="../media/file165.jpg" class="math-display" alt="Ëœx = x âˆ’ ğœ€sign(âˆ’ âˆ‡x log SË†y(x;T)) "/>
</div>
<p>Where <em>x</em> is an input image of which we subtract the perturbation magnitude <em>ğœ–</em> times the sign of the gradient of the cross-entropy loss with respect to the input. See <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a> for the TensorFlow implementation of this technique.</p>
<p>Although input preprocessing and temperature scaling are simple to implement, ODIN now requires two more hyperparameters to be tuned: the temperature for scaling the logits and <em>ğœ–</em> of the inverse of the fast gradient sign method. ODIN uses a separate out-of-distribution dataset to tune these hyperparameters (the validation set of the iSUN dataset: 8925 images).</p>
</section>
<section id="mahalanobis-ood-detection-with-intermediate-features" class="level4 likesubsubsectionHead" data-number="13.2.3.2">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.2.3.2"><span id="x1-1410003"></span>Mahalanobis: OOD Detection with intermediate features</h4>
<p>In <em>A Simple Unified Framework for Detecting Out-of-Distribution Samples and</em> <em>Adversarial Attacks</em>, Kimin Lee et al. propose a different method to detect OOD input<span id="dx1-141001"></span>. The core of their method is the idea that each class of a classifier follows a multivariate Gaussian distribution in the feature space of a network. Given this idea, we can define <em>C</em> class-conditional Gaussian distributions with a tied covariance <em>Ïƒ</em>:</p>
<div class="math-display">
<img src="../media/file166.jpg" class="math-display" alt="P(f(x) | y = c) = ğ’© (f(x) | Î¼c,Ïƒ ) "/>
</div>
<p>Where <em>Î¼</em><sub><em>c</em></sub> is the mean of the multivariate Gaussian distribution for each class <em>c</em>. This allows us to compute the empirical mean and covariance of each of these distributions for a given output of an intermediate layer, one for each class of our network. Based on the mean and covariance, we can compute the Mahalanobis distance of a single test image compared to our in-distribution data. We compute this for the class that is closest to the input image:</p>
<div class="math-display">
<img src="../media/file167.jpg" class="math-display" alt="M (x) = max âˆ’ (f(x)âˆ’ ^Î¼c)âŠ¤ ^Ïƒâˆ’ 1(f(x)âˆ’ ^Î¼c) c "/>
</div>
<p>This distance should be small for in-distribution images and large for out-of-distribution images.</p>
<p><code>numpy</code> has convenient functions to compute the mean and covariance of an array:</p>
<pre id="fancyvrb163" class="fancyvrb"><span id="x1-141006r1"></span> 
<code><span>mean</span><span>Â </span><span id="textcolor3942"><span>=</span></span><span>Â np</span><span id="textcolor3943"><span>.</span></span><span>mean(features_of_class,</span><span>Â axis</span><span id="textcolor3944"><span>=</span></span><span id="textcolor3945"><span>0</span></span><span>)</span> <span id="x1-141008r2"></span> </code>
<code><span>covariance</span><span>Â </span><span id="textcolor3946"><span>=</span></span><span>Â np</span><span id="textcolor3947"><span>.</span></span><span>cov(features_of_class</span><span id="textcolor3948"><span>.</span></span><span>T)</span></code></pre>
<p>Given these, we can compute the Mahalanobis distance as such:</p>
<pre id="fancyvrb164" class="fancyvrb"><span id="x1-141014r1"></span> 
<code><span>covariance_inverse</span><span>Â </span><span id="textcolor3949"><span>=</span></span><span>Â np</span><span id="textcolor3950"><span>.</span></span><span>linalg</span><span id="textcolor3951"><span>.</span></span><span>pinv(covariance)</span> <span id="x1-141016r2"></span> </code>
<code><span>x_minus_mu</span><span>Â </span><span id="textcolor3952"><span>=</span></span><span>Â features_of_class</span><span>Â </span><span id="textcolor3953"><span>-</span></span><span>Â mean</span> <span id="x1-141018r3"></span> </code>
<code><span>mahalanobis</span><span>Â </span><span id="textcolor3954"><span>=</span></span><span>Â np</span><span id="textcolor3955"><span>.</span></span><span>dot(x_minus_mu,</span><span>Â covariance_inverse)</span><span id="textcolor3956"><span>.</span></span><span>dot(x_minus_mu</span><span id="textcolor3957"><span>.</span></span><span>T)</span> <span id="x1-141020r4"></span> </code>
<code><span>mahalanobis</span><span>Â </span><span id="textcolor3958"><span>=</span></span><span>Â np</span><span id="textcolor3959"><span>.</span></span><span>sqrt(mahalanobis)</span><span id="textcolor3960"><span>.</span></span><span>diagonal()</span></code></pre>
<p>The Mahalanobis distance computation does not require any retraining and is a relatively cheap operation to perform once you have stored the mean and (inverse of the) covariance of the classes for the features of a layer of your network.</p>
<p>To improve the performance of the method, the authors show that we can also apply the input preprocessing as mentioned in the ODIN paper, or compute and then average the Mahalanobis distances extracted from multiple layers of the network. <span id="x1-141021r216"></span></p>
</section>
</section>
</section>
<section id="being-robust-against-dataset-shift" class="level2 sectionHead" data-number="13.3">
<h2 class="sectionHead" data-number="13.3" id="sigil_toc_id_92"><span class="titlemark">8.3 </span> <span id="x1-1420003"></span>Being robust against dataset shift</h2>
<p>We already encountered dataset shift<span id="dx1-142001"></span> in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep</em> <em>Learning</em></a>. As a reminder, dataset shift is a common problem in machine learning that happens when the joint distribution <em>P</em>(<em>X,Y</em> ) of inputs <em>X</em> and outputs <em>Y</em> differs between the model training stage and model inference stage (for example, when testing the model or when running it in a production environment). Covariate shift is a specific case of dataset shift where only the distribution of the inputs changes but the conditional distribution <em>P</em>(<em>Y</em> <span class="cmsy-10x-x-109">|</span><em>X</em>) stays constant.</p>
<p>Dataset shift is present in most production environments because of the difficulty of including all possible inference conditions during training and because most data is not static but changes over time. The input data can shift along many different dimensions in a production environment. Geographic and temporal dataset shift are two common forms of shift. Imagine, for example, you have trained your model on data taken from one geographical region (for example, Europe) and then apply the model in a different geographical region (for example, Latin America). Similarly, a model could be trained on data from the years between 2010 and 2020 and then applied on production data taken from today.</p>
<p>We will see that in such data shift scenarios, models often perform worse on the new shifted data than on their original training distribution<span id="dx1-142002"></span>. We will also see how vanilla neural networks usually do not indicate when the input data deviates from the training distribution. Finally, we will explore how various methods introduced in this book can be used to indicate dataset shift via uncertainty estimates and how these methods can make the models more robust. The following code example will be focused on an image classification problem. It should be noted, however, that the insights tend to generalize to other domains (such as natural language processing) and tasks (such as regression). <span id="x1-142003r222"></span></p>
<section id="measuring-a-models-response-to-dataset-shift" class="level3 subsectionHead" data-number="13.3.1">
<h3 class="subsectionHead" data-number="13.3.1" id="sigil_toc_id_93"><span class="titlemark">8.3.1 </span> <span id="x1-1430001"></span>Measuring a modelâ€™s response to dataset shift</h3>
<p>Assuming that we have a training dataset and a separate test set, how can we measure a modelâ€™s ability to signal to us when the data has shifted<span id="dx1-143001"></span>? In order to do so, it would be necessary to have an additional test set where the data has been shifted to check how the model reacts to the dataset shift. One commonly applied way to create such a data shift test set for images was originally suggested by Dan Hendrycks and Thomas Dietterich in 2019 and others. The idea is straightforward: take the images from your initial test set, then apply different image quality corruptions at different severity levels to them. Hendrycks and Dietterich proposed a set of 15 different types of image quality corruptions, ranging from image noise, blur, weather corruptions (such as fog and snow), and digital corruption. Each corruption type has five levels of severity, ranging from 1 (mild corruption) to 5 (severe corruption). <em>Figure</em> <a href="#x1-143002r4"><em>8.4</em></a> shows what the image of a kitty looks like initially (left) and after applying shot noise corruption to the image, either at severity level 1 (middle) or severity level 5 (right).</p>
<div class="IMG---Figure">
<img src="../media/file168.png" alt="PIC"/> <span id="x1-143002r4"></span> <span id="x1-143003"></span></div>
<p class="IMG---Caption">FigureÂ 8.4: Generating artificial dataset shift by applying image quality corruptions at different levels of corruption severity 
</p>
<p>All these image quality corruptions can be generated conveniently using the <code>imgaug</code> Python package. The following code assumes that we have an image called â€kitty.pngâ€ on disk. We load the image using the PIL package. We then specify the corruption type (for example, <code>ShotNoise</code>) via the name of the corruption function, and then apply the corruption function to the image, using either severity level 1 or 5 by passing the corresponding integer to the key-worded <span class="obeylines-h"><span class="verb"><code>severity</code></span></span> argument.</p>
<pre id="fancyvrb165" class="fancyvrb"><span id="x1-143015r1"></span> 
<code><span id="textcolor3961"><span>from</span></span><span>Â </span><span id="textcolor3962"><span>PIL</span></span><span>Â </span><span id="textcolor3963"><span>import</span></span><span>Â Image</span> <span id="x1-143017r2"></span> </code>
<code><span id="textcolor3964"><span>import</span></span><span>Â </span><span id="textcolor3965"><span>numpy</span></span><span>Â </span><span id="textcolor3966"><span>as</span></span><span>Â </span><span id="textcolor3967"><span>np</span></span> <span id="x1-143019r3"></span> </code>
<code><span id="textcolor3968"><span>import</span></span><span>Â </span><span id="textcolor3969"><span>imgaug.augmenters.imgcorruptlike</span></span><span>Â </span><span id="textcolor3970"><span>as</span></span><span>Â </span><span id="textcolor3971"><span>icl</span></span> <span id="x1-143021r4"></span> </code>
<code><span id="x1-143023r5"></span></code>
<code><span>image</span><span>Â </span><span id="textcolor3972"><span>=</span></span><span>Â np</span><span id="textcolor3973"><span>.</span></span><span>asarray(Image</span><span id="textcolor3974"><span>.</span></span><span>open(</span><span id="textcolor3975"><span>"./kitty.png"</span></span><span>)</span><span id="textcolor3976"><span>.</span></span><span>convert(</span><span id="textcolor3977"><span>"RGB"</span></span><span>))</span> <span id="x1-143025r6"></span> </code>
<code><span>corruption_function</span><span>Â </span><span id="textcolor3978"><span>=</span></span><span>Â icl</span><span id="textcolor3979"><span>.</span></span><span>ShotNoise</span> <span id="x1-143027r7"></span> </code>
<code><span>image_noise_level_01</span><span>Â </span><span id="textcolor3980"><span>=</span></span><span>Â corruption_function(severity</span><span id="textcolor3981"><span>=</span></span><span id="textcolor3982"><span>1</span></span><span>,</span><span>Â seed</span><span id="textcolor3983"><span>=</span></span><span id="textcolor3984"><span>0</span></span><span>)(image</span><span id="textcolor3985"><span>=</span></span><span>image)</span> <span id="x1-143029r8"></span> </code>
<code><span>image_noise_level_05</span><span>Â </span><span id="textcolor3986"><span>=</span></span><span>Â corruption_function(severity</span><span id="textcolor3987"><span>=</span></span><span id="textcolor3988"><span>5</span></span><span>,</span><span>Â seed</span><span id="textcolor3989"><span>=</span></span><span id="textcolor3990"><span>0</span></span><span>)(image</span><span id="textcolor3991"><span>=</span></span><span>image)</span></code></pre>
<p>The advantage of generating data shift this way is that it can be applied to a wide range of computer vision problems and datasets. Some of the few prerequisites for applying this method are that the data consists of images and that these image quality corruptions have not been used during training, for example, for data augmentation. Furthermore, by setting the severity of the image quality corruption, we gain control over the degree of the dataset shift.<span id="dx1-143030"></span> This allows us to measure how the model reacts to different degrees of dataset shift. We can measure both how performance changes in response to dataset shift and how calibration (introduced in <a href="CH2.xhtml#x1-250002"><em>ChapterÂ 2</em></a>, <a href="CH2.xhtml#x1-250002"><em>Fundamentals of Bayesian Inference</em></a>) changes. We would expect that models trained with Bayesian methods or extensions should be better calibrated, which means that they are able to indicate to us that the data has shifted in comparison to training and they are thus less certain in their output. <span id="x1-143031r228"></span></p>
</section>
<section id="revealing-dataset-shift-with-bayesian-methods" class="level3 subsectionHead" data-number="13.3.2">
<h3 class="subsectionHead" data-number="13.3.2" id="sigil_toc_id_94"><span class="titlemark">8.3.2 </span> <span id="x1-1440002"></span>Revealing dataset shift with Bayesian methods</h3>
<p>In the following code example, we will look at two of the BDL methods (Bayes by backprop and deep ensembles) that we have encountered in the book so far and see how they perform during the kind of artificial dataset shift described previously.<span id="dx1-144001"></span> We will compare their performance against a vanilla neural network.</p>
<section id="step-1-preparing-the-environment" class="level4 likesubsubsectionHead" data-number="13.3.2.1">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.3.2.1"><span id="x1-1450002"></span>Step 1: Preparing the environment</h4>
<p>We start the example by importing a list of packages.<span id="dx1-145001"></span> This includes TensorFlow and TensorFlow Probability, which we will use for building and training the neural networks; <code>numpy</code> for manipulating numerical arrays (such as calculating the mean); <code>Seaborn</code>, <code>Matplotlib</code>, and <code>pandas</code> for plotting; <code>cv2</code> and <code>imgaug</code> for loading and manipulating images; as well as <code>scikit-learn</code> for calculating the accuracy of our models.</p>
<pre id="fancyvrb166" class="fancyvrb"><span id="x1-145020r1"></span> 
<code><span id="textcolor3993"><span>import</span></span><span>Â </span><span id="textcolor3994"><span>cv2</span></span> <span id="x1-145022r2"></span> </code>
<code><span id="textcolor3995"><span>import</span></span><span>Â </span><span id="textcolor3996"><span>imgaug.augmenters</span></span><span>Â </span><span id="textcolor3997"><span>as</span></span><span>Â </span><span id="textcolor3998"><span>iaa</span></span> <span id="x1-145024r3"></span> </code>
<code><span id="textcolor3999"><span>import</span></span><span>Â </span><span id="textcolor4000"><span>imgaug.augmenters.imgcorruptlike</span></span><span>Â </span><span id="textcolor4001"><span>as</span></span><span>Â </span><span id="textcolor4002"><span>icl</span></span> <span id="x1-145026r4"></span> </code>
<code><span id="textcolor4003"><span>import</span></span><span>Â </span><span id="textcolor4004"><span>matplotlib.pyplot</span></span><span>Â </span><span id="textcolor4005"><span>as</span></span><span>Â </span><span id="textcolor4006"><span>plt</span></span> <span id="x1-145028r5"></span> </code>
<code><span id="textcolor4007"><span>import</span></span><span>Â </span><span id="textcolor4008"><span>numpy</span></span><span>Â </span><span id="textcolor4009"><span>as</span></span><span>Â </span><span id="textcolor4010"><span>np</span></span> <span id="x1-145030r6"></span> </code>
<code><span id="textcolor4011"><span>import</span></span><span>Â </span><span id="textcolor4012"><span>pandas</span></span><span>Â </span><span id="textcolor4013"><span>as</span></span><span>Â </span><span id="textcolor4014"><span>pd</span></span> <span id="x1-145032r7"></span> </code>
<code><span id="textcolor4015"><span>import</span></span><span>Â </span><span id="textcolor4016"><span>seaborn</span></span><span>Â </span><span id="textcolor4017"><span>as</span></span><span>Â </span><span id="textcolor4018"><span>sns</span></span> <span id="x1-145034r8"></span> </code>
<code><span id="textcolor4019"><span>import</span></span><span>Â </span><span id="textcolor4020"><span>tensorflow</span></span><span>Â </span><span id="textcolor4021"><span>as</span></span><span>Â </span><span id="textcolor4022"><span>tf</span></span> <span id="x1-145036r9"></span> </code>
<code><span id="textcolor4023"><span>import</span></span><span>Â </span><span id="textcolor4024"><span>tensorflow_probability</span></span><span>Â </span><span id="textcolor4025"><span>as</span></span><span>Â </span><span id="textcolor4026"><span>tfp</span></span> <span id="x1-145038r10"></span> </code>
<code><span id="textcolor4027"><span>from</span></span><span>Â </span><span id="textcolor4028"><span>sklearn.metrics</span></span><span>Â </span><span id="textcolor4029"><span>import</span></span><span>Â accuracy_score</span></code></pre>
<p>In preparation for the training, we will load the <span class="obeylines-h"><span class="verb"><code>CIFAR10</code></span></span> dataset, which is an image classification dataset, and specify the names of the different classes. The dataset consists of 10 different classes, the names of which we specify in the following code, and provides 50,000 training images as well as 10,000 test images. Weâ€™ll also save the number of training images, which will be needed to train the model with the reparameterization trick later.<span id="dx1-145039"></span></p>
<pre id="fancyvrb167" class="fancyvrb"><span id="x1-145050r1"></span> 
<code><span>cifar</span><span>Â </span><span id="textcolor4030"><span>=</span></span><span>Â tf</span><span id="textcolor4031"><span>.</span></span><span>keras</span><span id="textcolor4032"><span>.</span></span><span>datasets</span><span id="textcolor4033"><span>.</span></span><span>cifar10</span> <span id="x1-145052r2"></span> </code>
<code><span>(train_images,</span><span>Â train_labels),</span><span>Â (test_images,</span><span>Â test_labels)</span><span>Â </span><span id="textcolor4034"><span>=</span></span><span>Â cifar</span><span id="textcolor4035"><span>.</span></span><span>load_data()</span> <span id="x1-145054r3"></span> </code>
<code><span id="x1-145056r4"></span></code>
<code><span>CLASS_NAMES</span><span>Â </span><span id="textcolor4036"><span>=</span></span><span>Â [</span> <span id="x1-145058r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4037"><span>"airplane"</span></span><span>,</span><span id="textcolor4038"><span>"automobile"</span></span><span>,</span><span>Â </span><span id="textcolor4039"><span>"bird"</span></span><span>,</span><span>Â </span><span id="textcolor4040"><span>"cat"</span></span><span>,</span><span>Â </span><span id="textcolor4041"><span>"deer"</span></span><span>,</span> <span id="x1-145060r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4042"><span>"dog"</span></span><span>,</span><span>Â </span><span id="textcolor4043"><span>"frog"</span></span><span>,</span><span>Â </span><span id="textcolor4044"><span>"horse"</span></span><span>,</span><span>Â </span><span id="textcolor4045"><span>"ship"</span></span><span>,</span><span>Â </span><span id="textcolor4046"><span>"truck"</span></span> <span id="x1-145062r7"></span> </code>
<code><span>]</span> <span id="x1-145064r8"></span> </code>
<code><span id="x1-145066r9"></span></code>
<code><span>NUM_TRAIN_EXAMPLES</span><span>Â </span><span id="textcolor4047"><span>=</span></span><span>Â train_images</span><span id="textcolor4048"><span>.</span></span><span>shape[</span><span id="textcolor4049"><span>0</span></span><span>]</span></code></pre>
</section>
<section id="step-2-defining-and-training-the-models" class="level4 likesubsubsectionHead" data-number="13.3.2.2">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.3.2.2"><span id="x1-1460002"></span>Step 2: Defining and training the models</h4>
<p>After this prep work, we can define and train our models.<span id="dx1-146001"></span> We start by creating two functions to define and build the CNN. We will use these functions both for the vanilla neural network and the deep ensemble. The first function simply combines a convolutional layer with a max-pooling layer â€“ a common approach that we introduced in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep</em> <em>Learning</em></a>.</p>
<pre id="fancyvrb168" class="fancyvrb"><span id="x1-146012r1"></span> 
<code><span id="textcolor4050"><span>def</span></span><span>Â </span><span id="textcolor4051"><span>cnn_building_block</span></span><span>(num_filters):</span> <span id="x1-146014r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4052"><span>return</span></span><span>Â tf</span><span id="textcolor4053"><span>.</span></span><span>keras</span><span id="textcolor4054"><span>.</span></span><span>Sequential(</span> <span id="x1-146016r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-146018r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4055"><span>.</span></span><span>keras</span><span id="textcolor4056"><span>.</span></span><span>layers</span><span id="textcolor4057"><span>.</span></span><span>Conv2D(</span> <span id="x1-146020r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â filters</span><span id="textcolor4058"><span>=</span></span><span>num_filters,</span><span>Â kernel_size</span><span id="textcolor4059"><span>=</span></span><span>(</span><span id="textcolor4060"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor4061"><span>3</span></span><span>),</span><span>Â activation</span><span id="textcolor4062"><span>=</span></span><span id="textcolor4063"><span>"relu"</span></span> <span id="x1-146022r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-146024r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4064"><span>.</span></span><span>keras</span><span id="textcolor4065"><span>.</span></span><span>layers</span><span id="textcolor4066"><span>.</span></span><span>MaxPool2D(strides</span><span id="textcolor4067"><span>=</span></span><span id="textcolor4068"><span>2</span></span><span>),</span> <span id="x1-146026r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-146028r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
<p>The second function then uses several convolutional/max-pooling blocks in sequence and follows this sequence with a final dense layer:</p>
<pre id="fancyvrb169" class="fancyvrb"><span id="x1-146049r1"></span> 
<code><span id="textcolor4069"><span>def</span></span><span>Â </span><span id="textcolor4070"><span>build_and_compile_model</span></span><span>():</span> <span id="x1-146051r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor4071"><span>=</span></span><span>Â tf</span><span id="textcolor4072"><span>.</span></span><span>keras</span><span id="textcolor4073"><span>.</span></span><span>Sequential(</span> <span id="x1-146053r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-146055r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4074"><span>.</span></span><span>keras</span><span id="textcolor4075"><span>.</span></span><span>layers</span><span id="textcolor4076"><span>.</span></span><span>Rescaling(</span><span id="textcolor4077"><span>1.0</span></span><span>Â </span><span id="textcolor4078"><span>/</span></span><span>Â </span><span id="textcolor4079"><span>255</span></span><span>,</span><span>Â input_shape</span><span id="textcolor4080"><span>=</span></span><span>(</span><span id="textcolor4081"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4082"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4083"><span>3</span></span><span>)),</span> <span id="x1-146057r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cnn_building_block(</span><span id="textcolor4084"><span>16</span></span><span>),</span> <span id="x1-146059r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cnn_building_block(</span><span id="textcolor4085"><span>32</span></span><span>),</span> <span id="x1-146061r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cnn_building_block(</span><span id="textcolor4086"><span>64</span></span><span>),</span> <span id="x1-146063r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4087"><span>.</span></span><span>keras</span><span id="textcolor4088"><span>.</span></span><span>layers</span><span id="textcolor4089"><span>.</span></span><span>MaxPool2D(strides</span><span id="textcolor4090"><span>=</span></span><span id="textcolor4091"><span>2</span></span><span>),</span> <span id="x1-146065r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4092"><span>.</span></span><span>keras</span><span id="textcolor4093"><span>.</span></span><span>layers</span><span id="textcolor4094"><span>.</span></span><span>Flatten(),</span> <span id="x1-146067r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4095"><span>.</span></span><span>keras</span><span id="textcolor4096"><span>.</span></span><span>layers</span><span id="textcolor4097"><span>.</span></span><span>Dense(</span><span id="textcolor4098"><span>64</span></span><span>,</span><span>Â activation</span><span id="textcolor4099"><span>=</span></span><span id="textcolor4100"><span>"relu"</span></span><span>),</span> <span id="x1-146069r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4101"><span>.</span></span><span>keras</span><span id="textcolor4102"><span>.</span></span><span>layers</span><span id="textcolor4103"><span>.</span></span><span>Dense(</span><span id="textcolor4104"><span>10</span></span><span>,</span><span>Â activation</span><span id="textcolor4105"><span>=</span></span><span id="textcolor4106"><span>"softmax"</span></span><span>),</span> <span id="x1-146071r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-146073r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-146075r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor4107"><span>.</span></span><span>compile(</span> <span id="x1-146077r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â optimizer</span><span id="textcolor4108"><span>=</span></span><span id="textcolor4109"><span>"adam"</span></span><span>,</span> <span id="x1-146079r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor4110"><span>=</span></span><span id="textcolor4111"><span>"sparse_categorical_crossentropy"</span></span><span>,</span> <span id="x1-146081r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor4112"><span>=</span></span><span>[</span><span id="textcolor4113"><span>"accuracy"</span></span><span>],</span> <span id="x1-146083r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-146085r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4114"><span>return</span></span><span>Â model</span></code></pre>
<p>We also create two analogous functions to define and build the network using Bayes By Backprop (BBB) based on the reparameterization trick. The strategy is the same as for the vanilla neural network, just that weâ€™ll now use the convolutional and dense layers from the TensorFlow Probability package instead of the TensorFlow package.<span id="dx1-146086"></span> The convolutional/max-pooling blocks are then defined as follows:</p>
<pre id="fancyvrb170" class="fancyvrb"><span id="x1-146100r1"></span> 
<code><span id="textcolor4115"><span>def</span></span><span>Â </span><span id="textcolor4116"><span>cnn_building_block_bbb</span></span><span>(num_filters,</span><span>Â kl_divergence_function):</span> <span id="x1-146102r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4117"><span>return</span></span><span>Â tf</span><span id="textcolor4118"><span>.</span></span><span>keras</span><span id="textcolor4119"><span>.</span></span><span>Sequential(</span> <span id="x1-146104r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-146106r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tfp</span><span id="textcolor4120"><span>.</span></span><span>layers</span><span id="textcolor4121"><span>.</span></span><span>Convolution2DReparameterization(</span> <span id="x1-146108r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â num_filters,</span> <span id="x1-146110r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_size</span><span id="textcolor4122"><span>=</span></span><span>(</span><span id="textcolor4123"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor4124"><span>3</span></span><span>),</span> <span id="x1-146112r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_divergence_fn</span><span id="textcolor4125"><span>=</span></span><span>kl_divergence_function,</span> <span id="x1-146114r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â activation</span><span id="textcolor4126"><span>=</span></span><span>tf</span><span id="textcolor4127"><span>.</span></span><span>nn</span><span id="textcolor4128"><span>.</span></span><span>relu,</span> <span id="x1-146116r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-146118r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4129"><span>.</span></span><span>keras</span><span id="textcolor4130"><span>.</span></span><span>layers</span><span id="textcolor4131"><span>.</span></span><span>MaxPool2D(strides</span><span id="textcolor4132"><span>=</span></span><span id="textcolor4133"><span>2</span></span><span>),</span> <span id="x1-146120r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-146122r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
<p>And the final network is defined like this:<span id="dx1-146123"></span></p>
<pre id="fancyvrb171" class="fancyvrb"><span id="x1-146160r1"></span> 
<code><span id="textcolor4134"><span>def</span></span><span>Â </span><span id="textcolor4135"><span>build_and_compile_model_bbb</span></span><span>():</span> <span id="x1-146162r2"></span> </code>
<code><span id="x1-146164r3"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â kl_divergence_function</span><span>Â </span><span id="textcolor4136"><span>=</span></span><span>Â </span><span id="textcolor4137"><span>lambda</span></span><span>Â q,</span><span>Â p,</span><span>Â _:</span><span>Â tfp</span><span id="textcolor4138"><span>.</span></span><span>distributions</span><span id="textcolor4139"><span>.</span></span><span>kl_divergence(</span> <span id="x1-146166r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â q,</span><span>Â p</span> <span id="x1-146168r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span><span>Â </span><span id="textcolor4140"><span>/</span></span><span>Â tf</span><span id="textcolor4141"><span>.</span></span><span>cast(NUM_TRAIN_EXAMPLES,</span><span>Â dtype</span><span id="textcolor4142"><span>=</span></span><span>tf</span><span id="textcolor4143"><span>.</span></span><span>float32)</span> <span id="x1-146170r6"></span> </code>
<code><span id="x1-146172r7"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor4144"><span>=</span></span><span>Â tf</span><span id="textcolor4145"><span>.</span></span><span>keras</span><span id="textcolor4146"><span>.</span></span><span>models</span><span id="textcolor4147"><span>.</span></span><span>Sequential(</span> <span id="x1-146174r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-146176r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4148"><span>.</span></span><span>keras</span><span id="textcolor4149"><span>.</span></span><span>layers</span><span id="textcolor4150"><span>.</span></span><span>Rescaling(</span><span id="textcolor4151"><span>1.0</span></span><span>Â </span><span id="textcolor4152"><span>/</span></span><span>Â </span><span id="textcolor4153"><span>255</span></span><span>,</span><span>Â input_shape</span><span id="textcolor4154"><span>=</span></span><span>(</span><span id="textcolor4155"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4156"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4157"><span>3</span></span><span>)),</span> <span id="x1-146178r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cnn_building_block_bbb(</span><span id="textcolor4158"><span>16</span></span><span>,</span><span>Â kl_divergence_function),</span> <span id="x1-146180r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cnn_building_block_bbb(</span><span id="textcolor4159"><span>32</span></span><span>,</span><span>Â kl_divergence_function),</span> <span id="x1-146182r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cnn_building_block_bbb(</span><span id="textcolor4160"><span>64</span></span><span>,</span><span>Â kl_divergence_function),</span> <span id="x1-146184r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4161"><span>.</span></span><span>keras</span><span id="textcolor4162"><span>.</span></span><span>layers</span><span id="textcolor4163"><span>.</span></span><span>Flatten(),</span> <span id="x1-146186r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tfp</span><span id="textcolor4164"><span>.</span></span><span>layers</span><span id="textcolor4165"><span>.</span></span><span>DenseReparameterization(</span> <span id="x1-146188r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4166"><span>64</span></span><span>,</span> <span id="x1-146190r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_divergence_fn</span><span id="textcolor4167"><span>=</span></span><span>kl_divergence_function,</span> <span id="x1-146192r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â activation</span><span id="textcolor4168"><span>=</span></span><span>tf</span><span id="textcolor4169"><span>.</span></span><span>nn</span><span id="textcolor4170"><span>.</span></span><span>relu,</span> <span id="x1-146194r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-146196r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tfp</span><span id="textcolor4171"><span>.</span></span><span>layers</span><span id="textcolor4172"><span>.</span></span><span>DenseReparameterization(</span> <span id="x1-146198r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4173"><span>10</span></span><span>,</span> <span id="x1-146200r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_divergence_fn</span><span id="textcolor4174"><span>=</span></span><span>kl_divergence_function,</span> <span id="x1-146202r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â activation</span><span id="textcolor4175"><span>=</span></span><span>tf</span><span id="textcolor4176"><span>.</span></span><span>nn</span><span id="textcolor4177"><span>.</span></span><span>softmax,</span> <span id="x1-146204r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-146206r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-146208r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-146210r26"></span> </code>
<code><span id="x1-146212r27"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor4178"><span>.</span></span><span>compile(</span> <span id="x1-146214r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â optimizer</span><span id="textcolor4179"><span>=</span></span><span id="textcolor4180"><span>"adam"</span></span><span>,</span> <span id="x1-146216r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor4181"><span>=</span></span><span id="textcolor4182"><span>"sparse_categorical_crossentropy"</span></span><span>,</span> <span id="x1-146218r30"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor4183"><span>=</span></span><span>[</span><span id="textcolor4184"><span>"accuracy"</span></span><span>],</span> <span id="x1-146220r31"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â experimental_run_tf_function</span><span id="textcolor4185"><span>=</span></span><span id="textcolor4186"><span>False</span></span><span>,</span> <span id="x1-146222r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-146224r33"></span> </code>
<code><span id="x1-146226r34"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor4187"><span>.</span></span><span>build(input_shape</span><span id="textcolor4188"><span>=</span></span><span>[</span><span id="textcolor4189"><span>None</span></span><span>,</span><span>Â </span><span id="textcolor4190"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4191"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4192"><span>3</span></span><span>])</span> <span id="x1-146228r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4193"><span>return</span></span><span>Â model</span></code></pre>
<p>We can then train the vanilla neural network:</p>
<pre id="fancyvrb172" class="fancyvrb"><span id="x1-146232r1"></span> 
<code><span>vanilla_model</span><span>Â </span><span id="textcolor4194"><span>=</span></span><span>Â build_and_compile_model()</span> <span id="x1-146234r2"></span> </code>
<code><span>vanilla_model</span><span id="textcolor4195"><span>.</span></span><span>fit(train_images,</span><span>Â train_labels,</span><span>Â epochs</span><span id="textcolor4196"><span>=</span></span><span id="textcolor4197"><span>10</span></span><span>)</span></code></pre>
<p>We can also train the ensemble, with five ensemble members:<span id="dx1-146235"></span></p>
<pre id="fancyvrb173" class="fancyvrb"><span id="x1-146244r1"></span> 
<code><span>NUM_ENSEMBLE_MEMBERS</span><span>Â </span><span id="textcolor4198"><span>=</span></span><span>Â </span><span id="textcolor4199"><span>5</span></span> <span id="x1-146246r2"></span> </code>
<code><span>ensemble_model</span><span>Â </span><span id="textcolor4200"><span>=</span></span><span>Â []</span> <span id="x1-146248r3"></span> </code>
<code><span id="textcolor4201"><span>for</span></span><span>Â ind</span><span>Â </span><span id="textcolor4202"><span>in</span></span><span>Â </span><span id="textcolor4203"><span>range</span></span><span>(NUM_ENSEMBLE_MEMBERS):</span> <span id="x1-146250r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â member</span><span>Â </span><span id="textcolor4204"><span>=</span></span><span>Â build_and_compile_model()</span> <span id="x1-146252r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4205"><span>print</span></span><span>(</span><span id="textcolor4206"><span>f</span></span><span id="textcolor4207"><span>"Train</span><span>Â model</span><span>Â </span></span><span id="textcolor4208"><span>{</span></span><span>ind</span><span id="textcolor4209"><span>:</span></span><span id="textcolor4210"><span>02</span></span><span id="textcolor4211"><span>}</span></span><span id="textcolor4212"><span>"</span></span><span>)</span> <span id="x1-146254r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â member</span><span id="textcolor4213"><span>.</span></span><span>fit(train_images,</span><span>Â train_labels,</span><span>Â epochs</span><span id="textcolor4214"><span>=</span></span><span id="textcolor4215"><span>10</span></span><span>)</span> <span id="x1-146256r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_model</span><span id="textcolor4216"><span>.</span></span><span>append(member)</span></code></pre>
<p>And finally, we train the BBB model. Note that we train the BBB model for 15 instead of 10 epochs, given that it takes a little longer to converge.</p>
<pre id="fancyvrb174" class="fancyvrb"><span id="x1-146260r1"></span> 
<code><span>bbb_model</span><span>Â </span><span id="textcolor4217"><span>=</span></span><span>Â build_and_compile_model_bbb()</span> <span id="x1-146262r2"></span> </code>
<code><span>bbb_model</span><span id="textcolor4218"><span>.</span></span><span>fit(train_images,</span><span>Â train_labels,</span><span>Â epochs</span><span id="textcolor4219"><span>=</span></span><span id="textcolor4220"><span>15</span></span><span>)</span></code></pre>
</section>
<section id="step-3-obtaining-predictions" class="level4 likesubsubsectionHead" data-number="13.3.2.3">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.3.2.3"><span id="x1-1470002"></span>Step 3: Obtaining predictions</h4>
<p>Now that we have three trained models, we can use them for predictions on the hold-out test set.<span id="dx1-147001"></span> To keep computations at a manageable degree, in this example, we will focus on the first 1,000 images in the test set:</p>
<pre id="fancyvrb175" class="fancyvrb"><span id="x1-147006r1"></span> 
<code><span>NUM_SUBSET</span><span>Â </span><span id="textcolor4221"><span>=</span></span><span>Â </span><span id="textcolor4222"><span>1000</span></span> <span id="x1-147008r2"></span> </code>
<code><span>test_images_subset</span><span>Â </span><span id="textcolor4223"><span>=</span></span><span>Â test_images[:NUM_SUBSET]</span> <span id="x1-147010r3"></span> </code>
<code><span>test_labels_subset</span><span>Â </span><span id="textcolor4224"><span>=</span></span><span>Â test_labels[:NUM_SUBSET]</span></code></pre>
<p>If we want to measure the response to dataset shift, we first need to apply the artificial image corruptions to the dataset. To do that, we first specify a set of functions from the <code>imgaug</code> package. From their names, one can infer what type of corruption each of these functions implements: for example, the function <code>icl.GaussianNoise</code> corrupts an image by applying Gaussian noise to it. We also infer the number of corruption types from the number of functions and save it in the <code>NUM_TYPES</code> variable. Finally, we set the number of corruption levels to 5.<span id="dx1-147014"></span></p>
<pre id="fancyvrb176" class="fancyvrb"><span id="x1-147035r1"></span> 
<code><span>corruption_functions</span><span>Â </span><span id="textcolor4226"><span>=</span></span><span>Â [</span> <span id="x1-147037r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4227"><span>.</span></span><span>GaussianNoise,</span> <span id="x1-147039r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4228"><span>.</span></span><span>ShotNoise,</span> <span id="x1-147041r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4229"><span>.</span></span><span>ImpulseNoise,</span> <span id="x1-147043r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4230"><span>.</span></span><span>DefocusBlur,</span> <span id="x1-147045r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4231"><span>.</span></span><span>GlassBlur,</span> <span id="x1-147047r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4232"><span>.</span></span><span>MotionBlur,</span> <span id="x1-147049r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4233"><span>.</span></span><span>ZoomBlur,</span> <span id="x1-147051r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4234"><span>.</span></span><span>Snow,</span> <span id="x1-147053r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4235"><span>.</span></span><span>Frost,</span> <span id="x1-147055r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4236"><span>.</span></span><span>Fog,</span> <span id="x1-147057r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4237"><span>.</span></span><span>Brightness,</span> <span id="x1-147059r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4238"><span>.</span></span><span>Contrast,</span> <span id="x1-147061r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4239"><span>.</span></span><span>ElasticTransform,</span> <span id="x1-147063r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4240"><span>.</span></span><span>Pixelate,</span> <span id="x1-147065r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â icl</span><span id="textcolor4241"><span>.</span></span><span>JpegComdivssion,</span> <span id="x1-147067r17"></span> </code>
<code><span>]</span> <span id="x1-147069r18"></span> </code>
<code><span>NUM_TYPES</span><span>Â </span><span id="textcolor4242"><span>=</span></span><span>Â </span><span id="textcolor4243"><span>len</span></span><span>(corruption_functions)</span> <span id="x1-147071r19"></span> </code>
<code><span>NUM_LEVELS</span><span>Â </span><span id="textcolor4244"><span>=</span></span><span>Â </span><span id="textcolor4245"><span>5</span></span></code></pre>
<p>Equipped with these functions, let us now corrupt images.<span id="dx1-147072"></span> In the next code block, we loop over the different corruption levels and types. We collect all corrupted images in the aptly named <code>corrupted_images</code> variable.</p>
<pre id="fancyvrb177" class="fancyvrb"><span id="x1-147088r1"></span> 
<code><span>corrupted_images</span><span>Â </span><span id="textcolor4246"><span>=</span></span><span>Â []</span> <span id="x1-147090r2"></span> </code>
<code><span id="textcolor4247"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â loop</span><span class="cmitt-10x-x-109">Â over</span><span class="cmitt-10x-x-109">Â different</span><span class="cmitt-10x-x-109">Â corruption</span><span class="cmitt-10x-x-109">Â severities</span></span> <span id="x1-147092r3"></span> </code>
<code><span id="textcolor4248"><span>for</span></span><span>Â corruption_severity</span><span>Â </span><span id="textcolor4249"><span>in</span></span><span>Â </span><span id="textcolor4250"><span>range</span></span><span>(</span><span id="textcolor4251"><span>1</span></span><span>,</span><span>Â NUM_LEVELS</span><span id="textcolor4252"><span>+</span></span><span id="textcolor4253"><span>1</span></span><span>):</span> <span id="x1-147094r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â corruption_type_batch</span><span>Â </span><span id="textcolor4254"><span>=</span></span><span>Â []</span> <span id="x1-147096r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4255"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â loop</span><span class="cmitt-10x-x-109">Â over</span><span class="cmitt-10x-x-109">Â different</span><span class="cmitt-10x-x-109">Â corruption</span><span class="cmitt-10x-x-109">Â types</span></span> <span id="x1-147098r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4256"><span>for</span></span><span>Â corruption_type</span><span>Â </span><span id="textcolor4257"><span>in</span></span><span>Â corruption_functions:</span> <span id="x1-147100r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â corrupted_image_batch</span><span>Â </span><span id="textcolor4258"><span>=</span></span><span>Â corruption_type(</span> <span id="x1-147102r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â severity</span><span id="textcolor4259"><span>=</span></span><span>corruption_severity,</span><span>Â seed</span><span id="textcolor4260"><span>=</span></span><span id="textcolor4261"><span>0</span></span> <span id="x1-147104r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )(images</span><span id="textcolor4262"><span>=</span></span><span>test_images_subset)</span> <span id="x1-147106r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â corruption_type_batch</span><span id="textcolor4263"><span>.</span></span><span>append(corrupted_image_batch)</span> <span id="x1-147108r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â corruption_type_batch</span><span>Â </span><span id="textcolor4264"><span>=</span></span><span>Â np</span><span id="textcolor4265"><span>.</span></span><span>stack(corruption_type_batch,</span><span>Â axis</span><span id="textcolor4266"><span>=</span></span><span id="textcolor4267"><span>0</span></span><span>)</span> <span id="x1-147110r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â corrupted_images</span><span id="textcolor4268"><span>.</span></span><span>append(corruption_type_batch)</span> <span id="x1-147112r13"></span> </code>
<code><span>corrupted_images</span><span>Â </span><span id="textcolor4269"><span>=</span></span><span>Â np</span><span id="textcolor4270"><span>.</span></span><span>stack(corrupted_images,</span><span>Â axis</span><span id="textcolor4271"><span>=</span></span><span id="textcolor4272"><span>0</span></span><span>)</span></code></pre>
<p>With the three models trained and the corrupted images at hand, we can now see how our models react to dataset shift of different levels. We will first obtain predictions on the corrupted images from the three models. To run inference, we need to reshape the corrupted images to an input shape that is accepted by the models for inferences. At the moment, the images are still stored on different axes for the corruption types and levels. We change this by reshaping the <code>corrupted_images</code> array:</p>
<pre id="fancyvrb178" class="fancyvrb"><span id="x1-147116r1"></span> 
<code><span>corrupted_images</span><span>Â </span><span id="textcolor4273"><span>=</span></span><span>Â corrupted_images</span><span id="textcolor4274"><span>.</span></span><span>reshape((</span><span id="textcolor4275"><span>-</span></span><span id="textcolor4276"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor4277"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4278"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4279"><span>3</span></span><span>))</span></code></pre>
<p>Then we can perform inference with the vanilla CNN model, both on the original images and the corrupted images.<span id="dx1-147117"></span> After we have inferred the model predictions, we reshape the predictions in order to separate predictions for the corruption types and levels:</p>
<pre id="fancyvrb179" class="fancyvrb"><span id="x1-147126r1"></span> 
<code><span id="textcolor4280"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â on</span><span class="cmitt-10x-x-109">Â original</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147128r2"></span> </code>
<code><span>vanilla_predictions</span><span>Â </span><span id="textcolor4281"><span>=</span></span><span>Â vanilla_model</span><span id="textcolor4282"><span>.</span></span><span>predict(test_images_subset)</span> <span id="x1-147130r3"></span> </code>
<code><span id="textcolor4283"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â on</span><span class="cmitt-10x-x-109">Â corrupted</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147132r4"></span> </code>
<code><span>vanilla_predictions_on_corrupted</span><span>Â </span><span id="textcolor4284"><span>=</span></span><span>Â vanilla_model</span><span id="textcolor4285"><span>.</span></span><span>predict(corrupted_images)</span> <span id="x1-147134r5"></span> </code>
<code><span>vanilla_predictions_on_corrupted</span><span>Â </span><span id="textcolor4286"><span>=</span></span><span>Â vanilla_predictions_on_corrupted</span><span id="textcolor4287"><span>.</span></span><span>reshape(</span> <span id="x1-147136r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â (NUM_LEVELS,</span><span>Â NUM_TYPES,</span><span>Â NUM_SUBSET,</span><span>Â </span><span id="textcolor4288"><span>-</span></span><span id="textcolor4289"><span>1</span></span><span>)</span> <span id="x1-147138r7"></span> </code>
<code><span>)</span></code></pre>
<p>To run inference with the ensemble model, we first define a prediction function to avoid code duplication. This function handles the looping over the different member models of the ensemble and combines the different predictions in the end via averaging:</p>
<pre id="fancyvrb180" class="fancyvrb"><span id="x1-147149r1"></span> 
<code><span id="textcolor4290"><span>def</span></span><span>Â </span><span id="textcolor4291"><span>get_ensemble_predictions</span></span><span>(images,</span><span>Â num_inferences):</span> <span id="x1-147151r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_predictions</span><span>Â </span><span id="textcolor4292"><span>=</span></span><span>Â tf</span><span id="textcolor4293"><span>.</span></span><span>stack(</span> <span id="x1-147153r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-147155r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_model[ensemble_ind]</span><span id="textcolor4294"><span>.</span></span><span>predict(images)</span> <span id="x1-147157r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4295"><span>for</span></span><span>Â ensemble_ind</span><span>Â </span><span id="textcolor4296"><span>in</span></span><span>Â </span><span id="textcolor4297"><span>range</span></span><span>(num_inferences)</span> <span id="x1-147159r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ],</span> <span id="x1-147161r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â axis</span><span id="textcolor4298"><span>=</span></span><span id="textcolor4299"><span>0</span></span><span>,</span> <span id="x1-147163r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-147165r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4300"><span>return</span></span><span>Â np</span><span id="textcolor4301"><span>.</span></span><span>mean(ensemble_predictions,</span><span>Â axis</span><span id="textcolor4302"><span>=</span></span><span id="textcolor4303"><span>0</span></span><span>)</span></code></pre>
<p>Equipped with this function, we can perform inference with the ensemble model on both the original and corrupted images:</p>
<pre id="fancyvrb181" class="fancyvrb"><span id="x1-147178r1"></span> 
<code><span id="textcolor4304"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â on</span><span class="cmitt-10x-x-109">Â original</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147180r2"></span> </code>
<code><span>ensemble_predictions</span><span>Â </span><span id="textcolor4305"><span>=</span></span><span>Â get_ensemble_predictions(</span> <span id="x1-147182r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_images_subset,</span><span>Â NUM_ENSEMBLE_MEMBERS</span> <span id="x1-147184r4"></span> </code>
<code><span>)</span> <span id="x1-147186r5"></span> </code>
<code><span id="textcolor4306"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â on</span><span class="cmitt-10x-x-109">Â corrupted</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147188r6"></span> </code>
<code><span>ensemble_predictions_on_corrupted</span><span>Â </span><span id="textcolor4307"><span>=</span></span><span>Â get_ensemble_predictions(</span> <span id="x1-147190r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â corrupted_images,</span><span>Â NUM_ENSEMBLE_MEMBERS</span> <span id="x1-147192r8"></span> </code>
<code><span>)</span> <span id="x1-147194r9"></span> </code>
<code><span>ensemble_predictions_on_corrupted</span><span>Â </span><span id="textcolor4308"><span>=</span></span><span>Â ensemble_predictions_on_corrupted</span><span id="textcolor4309"><span>.</span></span><span>reshape(</span> <span id="x1-147196r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â (NUM_LEVELS,</span><span>Â NUM_TYPES,</span><span>Â NUM_SUBSET,</span><span>Â </span><span id="textcolor4310"><span>-</span></span><span id="textcolor4311"><span>1</span></span><span>)</span> <span id="x1-147198r11"></span> </code>
<code><span>)</span></code></pre>
<p>Just as for the ensemble model, we write an inference function for the BBB model<span id="dx1-147199"></span>, which handles the iteration over different sampling loops and collects and combines the results:</p>
<pre id="fancyvrb182" class="fancyvrb"><span id="x1-147207r1"></span> 
<code><span id="textcolor4312"><span>def</span></span><span>Â </span><span id="textcolor4313"><span>get_bbb_predictions</span></span><span>(images,</span><span>Â num_inferences):</span> <span id="x1-147209r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_predictions</span><span>Â </span><span id="textcolor4314"><span>=</span></span><span>Â tf</span><span id="textcolor4315"><span>.</span></span><span>stack(</span> <span id="x1-147211r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [bbb_model</span><span id="textcolor4316"><span>.</span></span><span>predict(images)</span><span>Â </span><span id="textcolor4317"><span>for</span></span><span>Â _</span><span>Â </span><span id="textcolor4318"><span>in</span></span><span>Â </span><span id="textcolor4319"><span>range</span></span><span>(num_inferences)],</span> <span id="x1-147213r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â axis</span><span id="textcolor4320"><span>=</span></span><span id="textcolor4321"><span>0</span></span><span>,</span> <span id="x1-147215r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-147217r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4322"><span>return</span></span><span>Â np</span><span id="textcolor4323"><span>.</span></span><span>mean(bbb_predictions,</span><span>Â axis</span><span id="textcolor4324"><span>=</span></span><span id="textcolor4325"><span>0</span></span><span>)</span></code></pre>
<p>We then put this function to use to obtain the BBB model predictions on the original and corrupted images. We sample from the BBB model 20 times:</p>
<pre id="fancyvrb183" class="fancyvrb"><span id="x1-147231r1"></span> 
<code><span>NUM_INFERENCES_BBB</span><span>Â </span><span id="textcolor4326"><span>=</span></span><span>Â </span><span id="textcolor4327"><span>20</span></span> <span id="x1-147233r2"></span> </code>
<code><span id="textcolor4328"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â on</span><span class="cmitt-10x-x-109">Â original</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147235r3"></span> </code>
<code><span>bbb_predictions</span><span>Â </span><span id="textcolor4329"><span>=</span></span><span>Â get_bbb_predictions(</span> <span id="x1-147237r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_images_subset,</span><span>Â NUM_INFERENCES_BBB</span> <span id="x1-147239r5"></span> </code>
<code><span>)</span> <span id="x1-147241r6"></span> </code>
<code><span id="textcolor4330"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â on</span><span class="cmitt-10x-x-109">Â corrupted</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147243r7"></span> </code>
<code><span>bbb_predictions_on_corrupted</span><span>Â </span><span id="textcolor4331"><span>=</span></span><span>Â get_bbb_predictions(</span> <span id="x1-147245r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â corrupted_images,</span><span>Â NUM_INFERENCES_BBB</span> <span id="x1-147247r9"></span> </code>
<code><span>)</span> <span id="x1-147249r10"></span> </code>
<code><span>bbb_predictions_on_corrupted</span><span>Â </span><span id="textcolor4332"><span>=</span></span><span>Â bbb_predictions_on_corrupted</span><span id="textcolor4333"><span>.</span></span><span>reshape(</span> <span id="x1-147251r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â (NUM_LEVELS,</span><span>Â NUM_TYPES,</span><span>Â NUM_SUBSET,</span><span>Â </span><span id="textcolor4334"><span>-</span></span><span id="textcolor4335"><span>1</span></span><span>)</span> <span id="x1-147253r12"></span> </code>
<code><span>)</span></code></pre>
<p>We can convert the predictions of the three models to predicted classes and associated confidence scores by returning the index of the class with the maximum softmax score and the maximum softmax score, respectively:<span id="dx1-147254"></span></p>
<pre id="fancyvrb184" class="fancyvrb"><span id="x1-147260r1"></span> 
<code><span id="textcolor4336"><span>def</span></span><span>Â </span><span id="textcolor4337"><span>get_classes_and_scores</span></span><span>(model_predictions):</span> <span id="x1-147262r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model_predicted_classes</span><span>Â </span><span id="textcolor4338"><span>=</span></span><span>Â np</span><span id="textcolor4339"><span>.</span></span><span>argmax(model_predictions,</span><span>Â axis</span><span id="textcolor4340"><span>=-</span></span><span id="textcolor4341"><span>1</span></span><span>)</span> <span id="x1-147264r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model_scores</span><span>Â </span><span id="textcolor4342"><span>=</span></span><span>Â np</span><span id="textcolor4343"><span>.</span></span><span>max(model_predictions,</span><span>Â axis</span><span id="textcolor4344"><span>=-</span></span><span id="textcolor4345"><span>1</span></span><span>)</span> <span id="x1-147266r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4346"><span>return</span></span><span>Â model_predicted_classes,</span><span>Â model_scores</span></code></pre>
<p>This function can then be applied to get the predicted classes and confidence scores for our three models:</p>
<pre id="fancyvrb185" class="fancyvrb"><span id="x1-147296r1"></span> 
<code><span id="textcolor4347"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Vanilla</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-147298r2"></span> </code>
<code><span>vanilla_predicted_classes,</span><span>Â vanilla_scores</span><span>Â </span><span id="textcolor4348"><span>=</span></span><span>Â get_classes_and_scores(</span> <span id="x1-147300r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_predictions</span> <span id="x1-147302r4"></span> </code>
<code><span>)</span> <span id="x1-147304r5"></span> </code>
<code><span>(</span> <span id="x1-147306r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_predicted_classes_on_corrupted,</span> <span id="x1-147308r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_scores_on_corrupted,</span> <span id="x1-147310r8"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4349"><span>=</span></span><span>Â get_classes_and_scores(vanilla_predictions_on_corrupted)</span> <span id="x1-147312r9"></span> </code>
<code><span id="x1-147314r10"></span></code>
<code><span id="textcolor4350"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Ensemble</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-147316r11"></span> </code>
<code><span>(</span> <span id="x1-147318r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_predicted_classes,</span> <span id="x1-147320r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_scores,</span> <span id="x1-147322r14"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4351"><span>=</span></span><span>Â get_classes_and_scores(ensemble_predictions)</span> <span id="x1-147324r15"></span> </code>
<code><span>(</span> <span id="x1-147326r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_predicted_classes_on_corrupted,</span> <span id="x1-147328r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_scores_on_corrupted,</span> <span id="x1-147330r18"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4352"><span>=</span></span><span>Â get_classes_and_scores(ensemble_predictions_on_corrupted)</span> <span id="x1-147332r19"></span> </code>
<code><span id="x1-147334r20"></span></code>
<code><span id="textcolor4353"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â BBB</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-147336r21"></span> </code>
<code><span>(</span> <span id="x1-147338r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_predicted_classes,</span> <span id="x1-147340r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_scores,</span> <span id="x1-147342r24"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4354"><span>=</span></span><span>Â get_classes_and_scores(bbb_predictions)</span> <span id="x1-147344r25"></span> </code>
<code><span>(</span> <span id="x1-147346r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_predicted_classes_on_corrupted,</span> <span id="x1-147348r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_scores_on_corrupted,</span> <span id="x1-147350r28"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4355"><span>=</span></span><span>Â get_classes_and_scores(bbb_predictions_on_corrupted)</span></code></pre>
<p>Let us visualize what these predicted classes and confidence scores look like for the three models on a selected image showing an automobile.<span id="dx1-147351"></span> For plotting, we first reshape the array that contains the corrupted images to a more convenient format:</p>
<pre id="fancyvrb186" class="fancyvrb"><span id="x1-147356r1"></span> 
<code><span>plot_images</span><span>Â </span><span id="textcolor4356"><span>=</span></span><span>Â corrupted_images</span><span id="textcolor4357"><span>.</span></span><span>reshape(</span> <span id="x1-147358r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â (NUM_LEVELS,</span><span>Â NUM_TYPES,</span><span>Â NUM_SUBSET,</span><span>Â </span><span id="textcolor4358"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4359"><span>32</span></span><span>,</span><span>Â </span><span id="textcolor4360"><span>3</span></span><span>)</span> <span id="x1-147360r3"></span> </code>
<code><span>)</span></code></pre>
<p>We then plot the selected automobile image with the first three corruption types in the list across all five corruption levels. For each combination, we display in the image title the predicted score of each model and in squared parentheses the predicted class. The plot is shown in <em>FigureÂ </em><a href="#x1-147361r5"><em>8.5</em></a>.</p>
<div class="IMG---Figure">
<img src="../media/file169.png" alt="PIC"/> <span id="x1-147361r5"></span> <span id="x1-147362"></span></div>
<p class="IMG---Caption">FigureÂ 8.5: An automobile image has been corrupted with different corruption types (rows) and levels (columns, severity increases from left to right) 
</p>
<p>The code continues:</p>
<pre id="fancyvrb187" class="fancyvrb"><span id="x1-147411r1"></span> 
<code><span id="textcolor4361"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Index</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â selected</span><span class="cmitt-10x-x-109">Â images</span></span> <span id="x1-147413r2"></span> </code>
<code><span>ind_image</span><span>Â </span><span id="textcolor4362"><span>=</span></span><span>Â </span><span id="textcolor4363"><span>9</span></span> <span id="x1-147415r3"></span> </code>
<code><span id="textcolor4364"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Define</span><span class="cmitt-10x-x-109">Â figure</span></span> <span id="x1-147417r4"></span> </code>
<code><span>fig,</span><span>Â axes</span><span>Â </span><span id="textcolor4365"><span>=</span></span><span>Â plt</span><span id="textcolor4366"><span>.</span></span><span>subplots(nrows</span><span id="textcolor4367"><span>=</span></span><span id="textcolor4368"><span>3</span></span><span>,</span><span>Â ncols</span><span id="textcolor4369"><span>=</span></span><span id="textcolor4370"><span>5</span></span><span>,</span><span>Â figsize</span><span id="textcolor4371"><span>=</span></span><span>(</span><span id="textcolor4372"><span>16</span></span><span>,</span><span>Â </span><span id="textcolor4373"><span>10</span></span><span>))</span> <span id="x1-147419r5"></span> </code>
<code><span id="textcolor4374"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Loop</span><span class="cmitt-10x-x-109">Â over</span><span class="cmitt-10x-x-109">Â corruption</span><span class="cmitt-10x-x-109">Â levels</span></span> <span id="x1-147421r6"></span> </code>
<code><span id="textcolor4375"><span>for</span></span><span>Â ind_level</span><span>Â </span><span id="textcolor4376"><span>in</span></span><span>Â </span><span id="textcolor4377"><span>range</span></span><span>(NUM_LEVELS):</span> <span id="x1-147423r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4378"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Loop</span><span class="cmitt-10x-x-109">Â over</span><span class="cmitt-10x-x-109">Â corruption</span><span class="cmitt-10x-x-109">Â types</span></span> <span id="x1-147425r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4379"><span>for</span></span><span>Â ind_type</span><span>Â </span><span id="textcolor4380"><span>in</span></span><span>Â </span><span id="textcolor4381"><span>range</span></span><span>(</span><span id="textcolor4382"><span>3</span></span><span>):</span> <span id="x1-147427r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4383"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Plot</span><span class="cmitt-10x-x-109">Â slightly</span><span class="cmitt-10x-x-109">Â upscaled</span><span class="cmitt-10x-x-109">Â image</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â easier</span><span class="cmitt-10x-x-109">Â inspection</span></span> <span id="x1-147429r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â image</span><span>Â </span><span id="textcolor4384"><span>=</span></span><span>Â plot_images[ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4385"><span>...</span></span><span>]</span> <span id="x1-147431r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â image_upscaled</span><span>Â </span><span id="textcolor4386"><span>=</span></span><span>Â cv2</span><span id="textcolor4387"><span>.</span></span><span>resize(</span> <span id="x1-147433r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â image,</span><span>Â dsize</span><span id="textcolor4388"><span>=</span></span><span>(</span><span id="textcolor4389"><span>150</span></span><span>,</span><span>Â </span><span id="textcolor4390"><span>150</span></span><span>),</span><span>Â interpolation</span><span id="textcolor4391"><span>=</span></span><span>cv2</span><span id="textcolor4392"><span>.</span></span><span>INTER_CUBIC</span> <span id="x1-147435r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-147437r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â axes[ind_type,</span><span>Â ind_level]</span><span id="textcolor4393"><span>.</span></span><span>imshow(image_upscaled)</span> <span id="x1-147439r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4394"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â score</span><span class="cmitt-10x-x-109">Â and</span><span class="cmitt-10x-x-109">Â class</span><span class="cmitt-10x-x-109">Â predicted</span><span class="cmitt-10x-x-109">Â by</span><span class="cmitt-10x-x-109">Â vanilla</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-147441r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_score</span><span>Â </span><span id="textcolor4395"><span>=</span></span><span>Â vanilla_scores_on_corrupted[</span> <span id="x1-147443r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4396"><span>...</span></span> <span id="x1-147445r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-147447r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_prediction</span><span>Â </span><span id="textcolor4397"><span>=</span></span><span>Â vanilla_predicted_classes_on_corrupted[</span> <span id="x1-147449r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4398"><span>...</span></span> <span id="x1-147451r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-147453r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4399"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â score</span><span class="cmitt-10x-x-109">Â and</span><span class="cmitt-10x-x-109">Â class</span><span class="cmitt-10x-x-109">Â predicted</span><span class="cmitt-10x-x-109">Â by</span><span class="cmitt-10x-x-109">Â ensemble</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-147455r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_score</span><span>Â </span><span id="textcolor4400"><span>=</span></span><span>Â ensemble_scores_on_corrupted[</span> <span id="x1-147457r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4401"><span>...</span></span> <span id="x1-147459r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-147461r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_prediction</span><span>Â </span><span id="textcolor4402"><span>=</span></span><span>Â ensemble_predicted_classes_on_corrupted[</span> <span id="x1-147463r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4403"><span>...</span></span> <span id="x1-147465r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-147467r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4404"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Get</span><span class="cmitt-10x-x-109">Â score</span><span class="cmitt-10x-x-109">Â and</span><span class="cmitt-10x-x-109">Â class</span><span class="cmitt-10x-x-109">Â predicted</span><span class="cmitt-10x-x-109">Â by</span><span class="cmitt-10x-x-109">Â BBB</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-147469r30"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_score</span><span>Â </span><span id="textcolor4405"><span>=</span></span><span>Â bbb_scores_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4406"><span>...</span></span><span>]</span> <span id="x1-147471r31"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_prediction</span><span>Â </span><span id="textcolor4407"><span>=</span></span><span>Â bbb_predicted_classes_on_corrupted[</span> <span id="x1-147473r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ind_level,</span><span>Â ind_type,</span><span>Â ind_image,</span><span>Â </span><span id="textcolor4408"><span>...</span></span> <span id="x1-147475r33"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-147477r34"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4409"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Plot</span><span class="cmitt-10x-x-109">Â prediction</span><span class="cmitt-10x-x-109">Â info</span><span class="cmitt-10x-x-109">Â in</span><span class="cmitt-10x-x-109">Â title</span></span> <span id="x1-147479r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â title_text</span><span>Â </span><span id="textcolor4410"><span>=</span></span><span>Â (</span> <span id="x1-147481r36"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4411"><span>f</span></span><span id="textcolor4412"><span>"Vanilla:</span><span>Â </span></span><span id="textcolor4413"><span>{</span></span><span>vanilla_score</span><span id="textcolor4414"><span>:</span></span><span id="textcolor4415"><span>.3f</span></span><span id="textcolor4416"><span>}</span></span><span id="textcolor4417"><span>Â "</span></span> <span id="x1-147483r37"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4418"><span>+</span></span><span>Â </span><span id="textcolor4419"><span>f</span></span><span id="textcolor4420"><span>"[</span></span><span id="textcolor4421"><span>{</span></span><span>CLASS_NAMES[vanilla_prediction]</span><span id="textcolor4422"><span>}</span></span><span id="textcolor4423"><span>]</span><span>Â </span></span><span id="textcolor4424"><span>\n</span></span><span id="textcolor4425"><span>"</span></span> <span id="x1-147485r38"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4426"><span>+</span></span><span>Â </span><span id="textcolor4427"><span>f</span></span><span id="textcolor4428"><span>"Ensemble:</span><span>Â </span></span><span id="textcolor4429"><span>{</span></span><span>ensemble_score</span><span id="textcolor4430"><span>:</span></span><span id="textcolor4431"><span>.3f</span></span><span id="textcolor4432"><span>}</span></span><span id="textcolor4433"><span>Â "</span></span> <span id="x1-147487r39"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4434"><span>+</span></span><span>Â </span><span id="textcolor4435"><span>f</span></span><span id="textcolor4436"><span>"[</span></span><span id="textcolor4437"><span>{</span></span><span>CLASS_NAMES[ensemble_prediction]</span><span id="textcolor4438"><span>}</span></span><span id="textcolor4439"><span>]</span><span>Â </span></span><span id="textcolor4440"><span>\n</span></span><span id="textcolor4441"><span>"</span></span> <span id="x1-147489r40"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4442"><span>+</span></span><span>Â </span><span id="textcolor4443"><span>f</span></span><span id="textcolor4444"><span>"BBB:</span><span>Â </span></span><span id="textcolor4445"><span>{</span></span><span>bbb_score</span><span id="textcolor4446"><span>:</span></span><span id="textcolor4447"><span>.3f</span></span><span id="textcolor4448"><span>}</span></span><span id="textcolor4449"><span>Â "</span></span> <span id="x1-147491r41"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4450"><span>+</span></span><span>Â </span><span id="textcolor4451"><span>f</span></span><span id="textcolor4452"><span>"[</span></span><span id="textcolor4453"><span>{</span></span><span>CLASS_NAMES[bbb_prediction]</span><span id="textcolor4454"><span>}</span></span><span id="textcolor4455"><span>]"</span></span> <span id="x1-147493r42"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-147495r43"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â axes[ind_type,</span><span>Â ind_level]</span><span id="textcolor4456"><span>.</span></span><span>set_title(title_text,</span><span>Â fontsize</span><span id="textcolor4457"><span>=</span></span><span id="textcolor4458"><span>14</span></span><span>)</span> <span id="x1-147497r44"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4459"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Remove</span><span class="cmitt-10x-x-109">Â axes</span><span class="cmitt-10x-x-109">Â ticks</span><span class="cmitt-10x-x-109">Â and</span><span class="cmitt-10x-x-109">Â labels</span></span> <span id="x1-147499r45"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â axes[ind_type,</span><span>Â ind_level]</span><span id="textcolor4460"><span>.</span></span><span>axis(</span><span id="textcolor4461"><span>"off"</span></span><span>)</span> <span id="x1-147501r46"></span> </code>
<code><span>fig</span><span id="textcolor4462"><span>.</span></span><span>tight_layout()</span> <span id="x1-147503r47"></span> </code>
<code><span>plt</span><span id="textcolor4463"><span>.</span></span><span>show()</span></code></pre>
<p><em>FigureÂ </em><a href="#x1-147361r5"><em>8.5</em></a> only shows results for a single image, so we should not read too much into these results.<span id="dx1-147504"></span> However, we can already observe that the prediction scores for the two Bayesian methods (and especially the ensemble method) tend to be less extreme than for the vanilla neural network, which has predicted scores as high as 0.95. Furthermore, we see that, for all three models, prediction scores usually decrease as the corruption level increases. This is expected: given that the car in the image becomes less discernible with more corruption, we would want the model to become less confident as well. In particular, the ensemble method shows a nice and consistent decrease in predicted<span id="dx1-147505"></span> scores with increased corruption levels.</p>
</section>
<section id="step-4-measuring-accuracy" class="level4 likesubsubsectionHead" data-number="13.3.2.4">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.3.2.4"><span id="x1-1480002"></span>Step 4: Measuring accuracy</h4>
<p>Are some models more robust to dataset shift than<span id="dx1-148001"></span> other models? We can answer this question by looking at the accuracy of the three models at different corruptions levels. It is expected that all models will show lower accuracy as the input image becomes more and more corrupted. However, more robust models should lose less in accuracy as the corruptions become more severe.</p>
<p>First, we can calculate the accuracy of the three models on the original test images:</p>
<pre id="fancyvrb188" class="fancyvrb"><span id="x1-148012r1"></span> 
<code><span>vanilla_acc</span><span>Â </span><span id="textcolor4464"><span>=</span></span><span>Â accuracy_score(</span> <span id="x1-148014r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4465"><span>.</span></span><span>flatten(),</span><span>Â vanilla_predicted_classes</span> <span id="x1-148016r3"></span> </code>
<code><span>)</span> <span id="x1-148018r4"></span> </code>
<code><span>ensemble_acc</span><span>Â </span><span id="textcolor4466"><span>=</span></span><span>Â accuracy_score(</span> <span id="x1-148020r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4467"><span>.</span></span><span>flatten(),</span><span>Â ensemble_predicted_classes</span> <span id="x1-148022r6"></span> </code>
<code><span>)</span> <span id="x1-148024r7"></span> </code>
<code><span>bbb_acc</span><span>Â </span><span id="textcolor4468"><span>=</span></span><span>Â accuracy_score(</span> <span id="x1-148026r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4469"><span>.</span></span><span>flatten(),</span><span>Â bbb_predicted_classes</span> <span id="x1-148028r9"></span> </code>
<code><span>)</span></code></pre>
<p>We can store these accuracies in a list of dictionaries, which will make it easier to plot them systematically. We pass the respective name of the models. For corruption <span class="obeylines-h"><span class="verb"><code>type</code></span></span> and <span class="obeylines-h"><span class="verb"><code>level</code></span></span>, we pass <span class="obeylines-h"><span class="verb"><code>0</code></span></span> because these are the accuracies on the original images.</p>
<pre id="fancyvrb189" class="fancyvrb"><span id="x1-148035r1"></span> 
<code><span>accuracies</span><span>Â </span><span id="textcolor4470"><span>=</span></span><span>Â [</span> <span id="x1-148037r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â {</span><span id="textcolor4471"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4472"><span>"vanilla"</span></span><span>,</span><span>Â </span><span id="textcolor4473"><span>"type"</span></span><span>:</span><span>Â </span><span id="textcolor4474"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor4475"><span>"level"</span></span><span>:</span><span>Â </span><span id="textcolor4476"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor4477"><span>"accuracy"</span></span><span>:</span><span>Â vanilla_acc},</span> <span id="x1-148039r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â {</span><span id="textcolor4478"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4479"><span>"ensemble"</span></span><span>,</span><span>Â </span><span id="textcolor4480"><span>"type"</span></span><span>:</span><span>Â </span><span id="textcolor4481"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor4482"><span>"level"</span></span><span>:</span><span>Â </span><span id="textcolor4483"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor4484"><span>"accuracy"</span></span><span>:</span><span>Â ensemble_acc},</span> <span id="x1-148041r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â {</span><span id="textcolor4485"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4486"><span>"bbb"</span></span><span>,</span><span>Â </span><span id="textcolor4487"><span>"type"</span></span><span>:</span><span>Â </span><span id="textcolor4488"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor4489"><span>"level"</span></span><span>:</span><span>Â </span><span id="textcolor4490"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor4491"><span>"accuracy"</span></span><span>:</span><span>Â bbb_acc},</span> <span id="x1-148043r5"></span> </code>
<code><span>]</span></code></pre>
<p>Next, we calculate the accuracy of the three models on the different corruption type by corruption level combinations.<span id="dx1-148044"></span> We also append the results to the list of accuracies that we started previously:</p>
<pre id="fancyvrb190" class="fancyvrb"><span id="x1-148089r1"></span> 
<code><span id="textcolor4492"><span>for</span></span><span>Â ind_type</span><span>Â </span><span id="textcolor4493"><span>in</span></span><span>Â </span><span id="textcolor4494"><span>range</span></span><span>(NUM_TYPES):</span> <span id="x1-148091r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4495"><span>for</span></span><span>Â ind_level</span><span>Â </span><span id="textcolor4496"><span>in</span></span><span>Â </span><span id="textcolor4497"><span>range</span></span><span>(NUM_LEVELS):</span> <span id="x1-148093r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4498"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â accuracy</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â vanilla</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-148095r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_acc_on_corrupted</span><span>Â </span><span id="textcolor4499"><span>=</span></span><span>Â accuracy_score(</span> <span id="x1-148097r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4500"><span>.</span></span><span>flatten(),</span> <span id="x1-148099r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_predicted_classes_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-148101r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-148103r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â accuracies</span><span id="textcolor4501"><span>.</span></span><span>append(</span> <span id="x1-148105r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-148107r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4502"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4503"><span>"vanilla"</span></span><span>,</span> <span id="x1-148109r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4504"><span>"type"</span></span><span>:</span><span>Â ind_type</span><span>Â </span><span id="textcolor4505"><span>+</span></span><span>Â </span><span id="textcolor4506"><span>1</span></span><span>,</span> <span id="x1-148111r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4507"><span>"level"</span></span><span>:</span><span>Â ind_level</span><span>Â </span><span id="textcolor4508"><span>+</span></span><span>Â </span><span id="textcolor4509"><span>1</span></span><span>,</span> <span id="x1-148113r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4510"><span>"accuracy"</span></span><span>:</span><span>Â vanilla_acc_on_corrupted,</span> <span id="x1-148115r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-148117r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-148119r16"></span> </code>
<code><span id="x1-148121r17"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4511"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â accuracy</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â ensemble</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-148123r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_acc_on_corrupted</span><span>Â </span><span id="textcolor4512"><span>=</span></span><span>Â accuracy_score(</span> <span id="x1-148125r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4513"><span>.</span></span><span>flatten(),</span> <span id="x1-148127r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_predicted_classes_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-148129r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-148131r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â accuracies</span><span id="textcolor4514"><span>.</span></span><span>append(</span> <span id="x1-148133r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-148135r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4515"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4516"><span>"ensemble"</span></span><span>,</span> <span id="x1-148137r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4517"><span>"type"</span></span><span>:</span><span>Â ind_type</span><span>Â </span><span id="textcolor4518"><span>+</span></span><span>Â </span><span id="textcolor4519"><span>1</span></span><span>,</span> <span id="x1-148139r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4520"><span>"level"</span></span><span>:</span><span>Â ind_level</span><span>Â </span><span id="textcolor4521"><span>+</span></span><span>Â </span><span id="textcolor4522"><span>1</span></span><span>,</span> <span id="x1-148141r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4523"><span>"accuracy"</span></span><span>:</span><span>Â ensemble_acc_on_corrupted,</span> <span id="x1-148143r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-148145r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-148147r30"></span> </code>
<code><span id="x1-148149r31"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4524"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â accuracy</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â BBB</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-148151r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_acc_on_corrupted</span><span>Â </span><span id="textcolor4525"><span>=</span></span><span>Â accuracy_score(</span> <span id="x1-148153r33"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4526"><span>.</span></span><span>flatten(),</span> <span id="x1-148155r34"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_predicted_classes_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-148157r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-148159r36"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â accuracies</span><span id="textcolor4527"><span>.</span></span><span>append(</span> <span id="x1-148161r37"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-148163r38"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4528"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4529"><span>"bbb"</span></span><span>,</span> <span id="x1-148165r39"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4530"><span>"type"</span></span><span>:</span><span>Â ind_type</span><span>Â </span><span id="textcolor4531"><span>+</span></span><span>Â </span><span id="textcolor4532"><span>1</span></span><span>,</span> <span id="x1-148167r40"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4533"><span>"level"</span></span><span>:</span><span>Â ind_level</span><span>Â </span><span id="textcolor4534"><span>+</span></span><span>Â </span><span id="textcolor4535"><span>1</span></span><span>,</span> <span id="x1-148169r41"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4536"><span>"accuracy"</span></span><span>:</span><span>Â bbb_acc_on_corrupted,</span> <span id="x1-148171r42"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-148173r43"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
<p>We can then plot the distributions of accuracies for the original images and the increasingly corrupted images. We first convert the list of dictionaries to a pandas dataframe.<span id="dx1-148174"></span> This has the advantage that the dataframe can be directly passed to the plotting package <code>seaborn</code>. This allows us to specify that we want to plot the different modelsâ€™ results in different hues.</p>
<pre id="fancyvrb191" class="fancyvrb"><span id="x1-148183r1"></span> 
<code><span>df</span><span>Â </span><span id="textcolor4537"><span>=</span></span><span>Â pd</span><span id="textcolor4538"><span>.</span></span><span>DataFrame(accuracies)</span> <span id="x1-148185r2"></span> </code>
<code><span>plt</span><span id="textcolor4539"><span>.</span></span><span>figure(dpi</span><span id="textcolor4540"><span>=</span></span><span id="textcolor4541"><span>100</span></span><span>)</span> <span id="x1-148187r3"></span> </code>
<code><span>sns</span><span id="textcolor4542"><span>.</span></span><span>boxplot(data</span><span id="textcolor4543"><span>=</span></span><span>df,</span><span>Â x</span><span id="textcolor4544"><span>=</span></span><span id="textcolor4545"><span>"level"</span></span><span>,</span><span>Â y</span><span id="textcolor4546"><span>=</span></span><span id="textcolor4547"><span>"accuracy"</span></span><span>,</span><span>Â hue</span><span id="textcolor4548"><span>=</span></span><span id="textcolor4549"><span>"model_name"</span></span><span>)</span> <span id="x1-148189r4"></span> </code>
<code><span>plt</span><span id="textcolor4550"><span>.</span></span><span>legend(loc</span><span id="textcolor4551"><span>=</span></span><span id="textcolor4552"><span>"center</span><span>Â left"</span></span><span>,</span><span>Â bbox_to_anchor</span><span id="textcolor4553"><span>=</span></span><span>(</span><span id="textcolor4554"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor4555"><span>0.5</span></span><span>))</span> <span id="x1-148191r5"></span> </code>
<code><span>plt</span><span id="textcolor4556"><span>.</span></span><span>tight_layout</span> <span id="x1-148193r6"></span> </code>
<code><span>plt</span><span id="textcolor4557"><span>.</span></span><span>show()</span></code></pre>
<p>This produces the following output:</p>
<div class="IMG---Figure">
<img src="../media/file170.png" alt="PIC"/> <span id="x1-148194r6"></span> <span id="x1-148195"></span></div>
<p class="IMG---Caption">FigureÂ 8.6: Accuracy for the three different models (different hues) for the original test images (level 0) as well as for increasing levels of corruption (level 1-5) 
</p>
<p><span id="dx1-148196"></span>The resulting plot is shown in <em>FigureÂ </em><a href="#x1-148194r6"><em>8.6</em></a>. We can see that, on the original test images, the vanilla and BBB model have comparable accuracy, while the ensemble model has slightly higher accuracy. As corruption is introduced, we see that the performance of the vanilla neural network is worse (often significantly) than the performance of the ensemble or BBB. This relative improvement in performance of the BDL models demonstrates the regularization effect of Bayesian methods: these methods are able to capture the distribution of the data more effectively, making them more robust to perturbations. BBB exhibits particular resilience to increasing amounts of data corruption, demonstrating a key benefit of variational learning.</p>
</section>
<section id="step-5-measuring-calibration" class="level4 likesubsubsectionHead" data-number="13.3.2.5">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.3.2.5"><span id="x1-1490002"></span>Step 5: Measuring calibration</h4>
<p>Looking at accuracy is a good way to determine how robust a model is against dataset shift.<span id="dx1-149001"></span> But it does not really tell us whether the models are capable of signalling to us (via lower confidence scores) when the dataset has shifted and the models have become less confident in their output. This question can be answered by looking at how well models remain calibrated under dataset shift. We introduced calibration and expected calibration errors on a conceptual level back in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a>. We are now going to put these concepts into practice to understand whether models adjust their confidence appropriately as the images become increasingly corrupted and hard to predict.</p>
<p>First, we will implement the Expected Calibration Error (ECE) introduced in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a> as a scalar measure of calibration:</p>
<pre id="fancyvrb192" class="fancyvrb"><span id="x1-149041r1"></span> 
<code><span id="textcolor4558"><span>def</span></span><span>Â </span><span id="textcolor4559"><span>expected_calibration_error</span></span><span>(</span> <span id="x1-149043r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divd_correct,</span> <span id="x1-149045r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divd_score,</span> <span id="x1-149047r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_bins</span><span id="textcolor4560"><span>=</span></span><span id="textcolor4561"><span>5</span></span><span>,</span> <span id="x1-149049r5"></span> </code>
<code><span>):</span> <span id="x1-149051r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4562"><span class="cmitt-10x-x-109">"""Compute</span><span class="cmitt-10x-x-109">Â expected</span><span class="cmitt-10x-x-109">Â calibration</span><span class="cmitt-10x-x-109">Â error.</span></span> <span id="x1-149053r7"></span> </code>
<code><span id="textcolor4563"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â ----------</span></span> <span id="x1-149055r8"></span> </code>
<code><span id="textcolor4564"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â divd_correct</span><span class="cmitt-10x-x-109">Â :</span><span class="cmitt-10x-x-109">Â np.ndarray</span><span class="cmitt-10x-x-109">Â (n_samples,)</span></span> <span id="x1-149057r9"></span> </code>
<code><span id="textcolor4565"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â Whether</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â prediction</span><span class="cmitt-10x-x-109">Â is</span><span class="cmitt-10x-x-109">Â correct</span><span class="cmitt-10x-x-109">Â or</span><span class="cmitt-10x-x-109">Â not</span></span> <span id="x1-149059r10"></span> </code>
<code><span id="textcolor4566"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â divd_score</span><span class="cmitt-10x-x-109">Â :</span><span class="cmitt-10x-x-109">Â np.ndarray</span><span class="cmitt-10x-x-109">Â (n_samples,)</span></span> <span id="x1-149061r11"></span> </code>
<code><span id="textcolor4567"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â Confidence</span><span class="cmitt-10x-x-109">Â in</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â prediction</span></span> <span id="x1-149063r12"></span> </code>
<code><span id="textcolor4568"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â n_bins</span><span class="cmitt-10x-x-109">Â :</span><span class="cmitt-10x-x-109">Â int,</span><span class="cmitt-10x-x-109">Â default=5</span></span> <span id="x1-149065r13"></span> </code>
<code><span id="textcolor4569"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â Number</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â bins</span><span class="cmitt-10x-x-109">Â to</span><span class="cmitt-10x-x-109">Â discretize</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â [0,</span><span class="cmitt-10x-x-109">Â 1]</span><span class="cmitt-10x-x-109">Â interval.</span></span> <span id="x1-149067r14"></span> </code>
<code><span id="textcolor4570"><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â </span><span class="cmitt-10x-x-109">Â """</span></span> <span id="x1-149069r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4571"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Convert</span><span class="cmitt-10x-x-109">Â from</span><span class="cmitt-10x-x-109">Â bool</span><span class="cmitt-10x-x-109">Â to</span><span class="cmitt-10x-x-109">Â integer</span><span class="cmitt-10x-x-109">Â (makes</span><span class="cmitt-10x-x-109">Â counting</span><span class="cmitt-10x-x-109">Â easier)</span></span> <span id="x1-149071r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divd_correct</span><span>Â </span><span id="textcolor4572"><span>=</span></span><span>Â divd_correct</span><span id="textcolor4573"><span>.</span></span><span>astype(np</span><span id="textcolor4574"><span>.</span></span><span>int32)</span> <span id="x1-149073r17"></span> </code>
<code><span id="x1-149075r18"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4575"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Create</span><span class="cmitt-10x-x-109">Â bins</span><span class="cmitt-10x-x-109">Â and</span><span class="cmitt-10x-x-109">Â assign</span><span class="cmitt-10x-x-109">Â prediction</span><span class="cmitt-10x-x-109">Â scores</span><span class="cmitt-10x-x-109">Â to</span><span class="cmitt-10x-x-109">Â bins</span></span> <span id="x1-149077r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bins</span><span>Â </span><span id="textcolor4576"><span>=</span></span><span>Â np</span><span id="textcolor4577"><span>.</span></span><span>linspace(</span><span id="textcolor4578"><span>0.0</span></span><span>,</span><span>Â </span><span id="textcolor4579"><span>1.0</span></span><span>,</span><span>Â n_bins</span><span>Â </span><span id="textcolor4580"><span>+</span></span><span>Â </span><span id="textcolor4581"><span>1</span></span><span>)</span> <span id="x1-149079r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â binids</span><span>Â </span><span id="textcolor4582"><span>=</span></span><span>Â np</span><span id="textcolor4583"><span>.</span></span><span>searchsorted(bins[</span><span id="textcolor4584"><span>1</span></span><span>:</span><span id="textcolor4585"><span>-</span></span><span id="textcolor4586"><span>1</span></span><span>],</span><span>Â divd_score)</span> <span id="x1-149081r21"></span> </code>
<code><span id="x1-149083r22"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4587"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Count</span><span class="cmitt-10x-x-109">Â number</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â samples</span><span class="cmitt-10x-x-109">Â and</span><span class="cmitt-10x-x-109">Â correct</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â per</span><span class="cmitt-10x-x-109">Â bin</span></span> <span id="x1-149085r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bin_true_counts</span><span>Â </span><span id="textcolor4588"><span>=</span></span><span>Â np</span><span id="textcolor4589"><span>.</span></span><span>bincount(</span> <span id="x1-149087r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â binids,</span><span>Â weights</span><span id="textcolor4590"><span>=</span></span><span>divd_correct,</span><span>Â minlength</span><span id="textcolor4591"><span>=</span></span><span id="textcolor4592"><span>len</span></span><span>(bins)</span> <span id="x1-149089r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-149091r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bin_counts</span><span>Â </span><span id="textcolor4593"><span>=</span></span><span>Â np</span><span id="textcolor4594"><span>.</span></span><span>bincount(binids,</span><span>Â minlength</span><span id="textcolor4595"><span>=</span></span><span id="textcolor4596"><span>len</span></span><span>(bins))</span> <span id="x1-149093r27"></span> </code>
<code><span id="x1-149095r28"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4597"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â sum</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â confidence</span><span class="cmitt-10x-x-109">Â scores</span><span class="cmitt-10x-x-109">Â per</span><span class="cmitt-10x-x-109">Â bin</span></span> <span id="x1-149097r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bin_probs</span><span>Â </span><span id="textcolor4598"><span>=</span></span><span>Â np</span><span id="textcolor4599"><span>.</span></span><span>bincount(binids,</span><span>Â weights</span><span id="textcolor4600"><span>=</span></span><span>divd_score,</span><span>Â minlength</span><span id="textcolor4601"><span>=</span></span><span id="textcolor4602"><span>len</span></span><span>(bins))</span> <span id="x1-149099r30"></span> </code>
<code><span id="x1-149101r31"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4603"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Identify</span><span class="cmitt-10x-x-109">Â bins</span><span class="cmitt-10x-x-109">Â that</span><span class="cmitt-10x-x-109">Â contain</span><span class="cmitt-10x-x-109">Â samples</span></span> <span id="x1-149103r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â nonzero</span><span>Â </span><span id="textcolor4604"><span>=</span></span><span>Â bin_counts</span><span>Â </span><span id="textcolor4605"><span>!=</span></span><span>Â </span><span id="textcolor4606"><span>0</span></span> <span id="x1-149105r33"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4607"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â accuracy</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â every</span><span class="cmitt-10x-x-109">Â bin</span></span> <span id="x1-149107r34"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bin_acc</span><span>Â </span><span id="textcolor4608"><span>=</span></span><span>Â bin_true_counts[nonzero]</span><span>Â </span><span id="textcolor4609"><span>/</span></span><span>Â bin_counts[nonzero]</span> <span id="x1-149109r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4610"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â average</span><span class="cmitt-10x-x-109">Â confidence</span><span class="cmitt-10x-x-109">Â scores</span><span class="cmitt-10x-x-109">Â per</span><span class="cmitt-10x-x-109">Â bin</span></span> <span id="x1-149111r36"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bin_conf</span><span>Â </span><span id="textcolor4611"><span>=</span></span><span>Â bin_probs[nonzero]</span><span>Â </span><span id="textcolor4612"><span>/</span></span><span>Â bin_counts[nonzero]</span> <span id="x1-149113r37"></span> </code>
<code><span id="x1-149115r38"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4613"><span>return</span></span><span>Â np</span><span id="textcolor4614"><span>.</span></span><span>average(np</span><span id="textcolor4615"><span>.</span></span><span>abs(bin_acc</span><span>Â </span><span id="textcolor4616"><span>-</span></span><span>Â bin_conf),</span><span>Â weights</span><span id="textcolor4617"><span>=</span></span><span>bin_counts[nonzero])</span></code></pre>
<p>We can then calculate ECE for the three models on the original test images.<span id="dx1-149116"></span> We set the number of bins to <span class="obeylines-h"><span class="verb"><code>10</code></span></span>, which is a common choice for calculating ECE:</p>
<pre id="fancyvrb193" class="fancyvrb"><span id="x1-149137r1"></span> 
<code><span>NUM_BINS</span><span>Â </span><span id="textcolor4618"><span>=</span></span><span>Â </span><span id="textcolor4619"><span>10</span></span> <span id="x1-149139r2"></span> </code>
<code><span id="x1-149141r3"></span></code>
<code><span>vanilla_cal</span><span>Â </span><span id="textcolor4620"><span>=</span></span><span>Â expected_calibration_error(</span> <span id="x1-149143r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4621"><span>.</span></span><span>flatten()</span><span>Â </span><span id="textcolor4622"><span>==</span></span><span>Â vanilla_predicted_classes,</span> <span id="x1-149145r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_scores,</span> <span id="x1-149147r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_bins</span><span id="textcolor4623"><span>=</span></span><span>NUM_BINS,</span> <span id="x1-149149r7"></span> </code>
<code><span>)</span> <span id="x1-149151r8"></span> </code>
<code><span id="x1-149153r9"></span></code>
<code><span>ensemble_cal</span><span>Â </span><span id="textcolor4624"><span>=</span></span><span>Â expected_calibration_error(</span> <span id="x1-149155r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4625"><span>.</span></span><span>flatten()</span><span>Â </span><span id="textcolor4626"><span>==</span></span><span>Â ensemble_predicted_classes,</span> <span id="x1-149157r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_scores,</span> <span id="x1-149159r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_bins</span><span id="textcolor4627"><span>=</span></span><span>NUM_BINS,</span> <span id="x1-149161r13"></span> </code>
<code><span>)</span> <span id="x1-149163r14"></span> </code>
<code><span id="x1-149165r15"></span></code>
<code><span>bbb_cal</span><span>Â </span><span id="textcolor4628"><span>=</span></span><span>Â expected_calibration_error(</span> <span id="x1-149167r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4629"><span>.</span></span><span>flatten()</span><span>Â </span><span id="textcolor4630"><span>==</span></span><span>Â bbb_predicted_classes,</span> <span id="x1-149169r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_scores,</span> <span id="x1-149171r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_bins</span><span id="textcolor4631"><span>=</span></span><span>NUM_BINS,</span> <span id="x1-149173r19"></span> </code>
<code><span>)</span></code></pre>
<p>Just as we did for the accuracies earlier, we will store the calibration results in a list of dictionaries, which will make it easier to plot them:</p>
<pre id="fancyvrb194" class="fancyvrb"><span id="x1-149195r1"></span> 
<code><span>calibration</span><span>Â </span><span id="textcolor4632"><span>=</span></span><span>Â [</span> <span id="x1-149197r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-149199r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4633"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4634"><span>"vanilla"</span></span><span>,</span> <span id="x1-149201r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4635"><span>"type"</span></span><span>:</span><span>Â </span><span id="textcolor4636"><span>0</span></span><span>,</span> <span id="x1-149203r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4637"><span>"level"</span></span><span>:</span><span>Â </span><span id="textcolor4638"><span>0</span></span><span>,</span> <span id="x1-149205r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4639"><span>"calibration_error"</span></span><span>:</span><span>Â vanilla_cal,</span> <span id="x1-149207r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â },</span> <span id="x1-149209r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-149211r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4640"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4641"><span>"ensemble"</span></span><span>,</span> <span id="x1-149213r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4642"><span>"type"</span></span><span>:</span><span>Â </span><span id="textcolor4643"><span>0</span></span><span>,</span> <span id="x1-149215r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4644"><span>"level"</span></span><span>:</span><span>Â </span><span id="textcolor4645"><span>0</span></span><span>,</span> <span id="x1-149217r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4646"><span>"calibration_error"</span></span><span>:</span><span>Â ensemble_cal,</span> <span id="x1-149219r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â },</span> <span id="x1-149221r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-149223r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4647"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4648"><span>"bbb"</span></span><span>,</span> <span id="x1-149225r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4649"><span>"type"</span></span><span>:</span><span>Â </span><span id="textcolor4650"><span>0</span></span><span>,</span> <span id="x1-149227r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4651"><span>"level"</span></span><span>:</span><span>Â </span><span id="textcolor4652"><span>0</span></span><span>,</span> <span id="x1-149229r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4653"><span>"calibration_error"</span></span><span>:</span><span>Â bbb_cal,</span> <span id="x1-149231r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â },</span> <span id="x1-149233r20"></span> </code>
<code><span>]</span></code></pre>
<p>Next, we calculate the expected calibration error of the three models on the different corruption types by corruption level combinations.<span id="dx1-149234"></span> We also append the results to the list of calibration results that we started previously:</p>
<pre id="fancyvrb195" class="fancyvrb"><span id="x1-149282r1"></span> 
<code><span id="textcolor4654"><span>for</span></span><span>Â ind_type</span><span>Â </span><span id="textcolor4655"><span>in</span></span><span>Â </span><span id="textcolor4656"><span>range</span></span><span>(NUM_TYPES):</span> <span id="x1-149284r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4657"><span>for</span></span><span>Â ind_level</span><span>Â </span><span id="textcolor4658"><span>in</span></span><span>Â </span><span id="textcolor4659"><span>range</span></span><span>(NUM_LEVELS):</span> <span id="x1-149286r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4660"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â calibration</span><span class="cmitt-10x-x-109">Â error</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â vanilla</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-149288r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_cal_on_corrupted</span><span>Â </span><span id="textcolor4661"><span>=</span></span><span>Â expected_calibration_error(</span> <span id="x1-149290r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4662"><span>.</span></span><span>flatten()</span> <span id="x1-149292r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4663"><span>==</span></span><span>Â vanilla_predicted_classes_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-149294r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â vanilla_scores_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-149296r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-149298r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â calibration</span><span id="textcolor4664"><span>.</span></span><span>append(</span> <span id="x1-149300r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-149302r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4665"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4666"><span>"vanilla"</span></span><span>,</span> <span id="x1-149304r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4667"><span>"type"</span></span><span>:</span><span>Â ind_type</span><span>Â </span><span id="textcolor4668"><span>+</span></span><span>Â </span><span id="textcolor4669"><span>1</span></span><span>,</span> <span id="x1-149306r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4670"><span>"level"</span></span><span>:</span><span>Â ind_level</span><span>Â </span><span id="textcolor4671"><span>+</span></span><span>Â </span><span id="textcolor4672"><span>1</span></span><span>,</span> <span id="x1-149308r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4673"><span>"calibration_error"</span></span><span>:</span><span>Â vanilla_cal_on_corrupted,</span> <span id="x1-149310r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-149312r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-149314r17"></span> </code>
<code><span id="x1-149316r18"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4674"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â calibration</span><span class="cmitt-10x-x-109">Â error</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â ensemble</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-149318r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_cal_on_corrupted</span><span>Â </span><span id="textcolor4675"><span>=</span></span><span>Â expected_calibration_error(</span> <span id="x1-149320r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4676"><span>.</span></span><span>flatten()</span> <span id="x1-149322r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4677"><span>==</span></span><span>Â ensemble_predicted_classes_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-149324r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ensemble_scores_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-149326r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-149328r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â calibration</span><span id="textcolor4678"><span>.</span></span><span>append(</span> <span id="x1-149330r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-149332r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4679"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4680"><span>"ensemble"</span></span><span>,</span> <span id="x1-149334r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4681"><span>"type"</span></span><span>:</span><span>Â ind_type</span><span>Â </span><span id="textcolor4682"><span>+</span></span><span>Â </span><span id="textcolor4683"><span>1</span></span><span>,</span> <span id="x1-149336r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4684"><span>"level"</span></span><span>:</span><span>Â ind_level</span><span>Â </span><span id="textcolor4685"><span>+</span></span><span>Â </span><span id="textcolor4686"><span>1</span></span><span>,</span> <span id="x1-149338r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4687"><span>"calibration_error"</span></span><span>:</span><span>Â ensemble_cal_on_corrupted,</span> <span id="x1-149340r30"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-149342r31"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-149344r32"></span> </code>
<code><span id="x1-149346r33"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4688"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Calculate</span><span class="cmitt-10x-x-109">Â calibration</span><span class="cmitt-10x-x-109">Â error</span><span class="cmitt-10x-x-109">Â for</span><span class="cmitt-10x-x-109">Â BBB</span><span class="cmitt-10x-x-109">Â model</span></span> <span id="x1-149348r34"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_cal_on_corrupted</span><span>Â </span><span id="textcolor4689"><span>=</span></span><span>Â expected_calibration_error(</span> <span id="x1-149350r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â test_labels_subset</span><span id="textcolor4690"><span>.</span></span><span>flatten()</span> <span id="x1-149352r36"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4691"><span>==</span></span><span>Â bbb_predicted_classes_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-149354r37"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â bbb_scores_on_corrupted[ind_level,</span><span>Â ind_type,</span><span>Â :],</span> <span id="x1-149356r38"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-149358r39"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â calibration</span><span id="textcolor4692"><span>.</span></span><span>append(</span> <span id="x1-149360r40"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â {</span> <span id="x1-149362r41"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4693"><span>"model_name"</span></span><span>:</span><span>Â </span><span id="textcolor4694"><span>"bbb"</span></span><span>,</span> <span id="x1-149364r42"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4695"><span>"type"</span></span><span>:</span><span>Â ind_type</span><span>Â </span><span id="textcolor4696"><span>+</span></span><span>Â </span><span id="textcolor4697"><span>1</span></span><span>,</span> <span id="x1-149366r43"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4698"><span>"level"</span></span><span>:</span><span>Â ind_level</span><span>Â </span><span id="textcolor4699"><span>+</span></span><span>Â </span><span id="textcolor4700"><span>1</span></span><span>,</span> <span id="x1-149368r44"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4701"><span>"calibration_error"</span></span><span>:</span><span>Â bbb_cal_on_corrupted,</span> <span id="x1-149370r45"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-149372r46"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
<p>Finally, we plot the calibration results in a boxplot,<span id="dx1-149373"></span> again using <span class="obeylines-h"><span class="verb"><code>pandas</code></span></span> and <code>seaborn</code>:</p>
<pre id="fancyvrb196" class="fancyvrb"><span id="x1-149382r1"></span> 
<code><span>df</span><span>Â </span><span id="textcolor4702"><span>=</span></span><span>Â pd</span><span id="textcolor4703"><span>.</span></span><span>DataFrame(calibration)</span> <span id="x1-149384r2"></span> </code>
<code><span>plt</span><span id="textcolor4704"><span>.</span></span><span>figure(dpi</span><span id="textcolor4705"><span>=</span></span><span id="textcolor4706"><span>100</span></span><span>)</span> <span id="x1-149386r3"></span> </code>
<code><span>sns</span><span id="textcolor4707"><span>.</span></span><span>boxplot(data</span><span id="textcolor4708"><span>=</span></span><span>df,</span><span>Â x</span><span id="textcolor4709"><span>=</span></span><span id="textcolor4710"><span>"level"</span></span><span>,</span><span>Â y</span><span id="textcolor4711"><span>=</span></span><span id="textcolor4712"><span>"calibration_error"</span></span><span>,</span><span>Â hue</span><span id="textcolor4713"><span>=</span></span><span id="textcolor4714"><span>"model_name"</span></span><span>)</span> <span id="x1-149388r4"></span> </code>
<code><span>plt</span><span id="textcolor4715"><span>.</span></span><span>legend(loc</span><span id="textcolor4716"><span>=</span></span><span id="textcolor4717"><span>"center</span><span>Â left"</span></span><span>,</span><span>Â bbox_to_anchor</span><span id="textcolor4718"><span>=</span></span><span>(</span><span id="textcolor4719"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor4720"><span>0.5</span></span><span>))</span> <span id="x1-149390r5"></span> </code>
<code><span>plt</span><span id="textcolor4721"><span>.</span></span><span>tight_layout</span> <span id="x1-149392r6"></span> </code>
<code><span>plt</span><span id="textcolor4722"><span>.</span></span><span>show()</span></code></pre>
<p>The calibration results are shown in <em>FigureÂ </em><a href="#x1-149394r7"><em>8.7</em></a>. We can see that, on the original test images, all three models have relatively low calibration error, with the ensemble model performing slightly worse than the two other models. As we apply increasing levels of dataset shift, we can see that calibration error increases by a lot for the vanilla model. For the two Bayesian methods, calibration error also increases but by much less than for the vanilla model. This means that the Bayesian methods are better at indicating (via lower confidence scores) when the dataset has shifted and that the Bayesian models become relatively less confident in their output with increased corruption (as they should).<span id="dx1-149393"></span></p>
<div class="IMG---Figure">
<img src="../media/file171.png" alt="PIC"/> <span id="x1-149394r7"></span> <span id="x1-149395"></span></div>
<p class="IMG---Caption">FigureÂ 8.7: Expected calibration error for the three different models for the original test images (level 0) as well as for increasing levels of corruption (level 1-5) 
</p>
<p>In the next section, we will look into data selection. <span id="x1-149396r227"></span></p>
</section>
</section>
</section>
<section id="using-data-selection-via-uncertainty-to-keep-models-fresh" class="level2 sectionHead" data-number="13.4">
<h2 class="sectionHead" data-number="13.4" id="sigil_toc_id_95"><span class="titlemark">8.4 </span> <span id="x1-1500004"></span>Using data selection via uncertainty to keep models fresh</h2>
<p>We saw at the beginning of the chapter that we can use uncertainties to figure out whether data is part of the training data or not.<span id="dx1-150001"></span> We can expand on this idea in the context of an area of machine learning called <strong>active learning</strong>.<span id="dx1-150002"></span> The promise of active learning is that a model can learn more effectively on less data if we have a way to control the type of data it is trained on. Conceptually, this makes sense: if we train a model on data that is not of sufficient quality, it will also not perform well. Active learning is a way to guide the learning process and data a model is trained on by providing functions that can acquire data from a pool of data that is not part of the training data. By iteratively selecting the right data from the pool, we can train a model that performs better than if we had chosen the data from the pool at random.</p>
<p>Active learning can be used in many modern-day systems where there is a ton of unlabeled data available and we need to carefully select the amount of data we want to label. An example is an autonomous driving system: the camera on the car records a lot of data, but there is typically no budget to label all of it. By carefully choosing the most informative data points, we can improve the model performance at a lower cost than when we would have randomly selected the data to label. In the context of active learning, estimating uncertainties plays an important role. A model will typically learn more from areas of the data distribution that were predicted with low confidence. Letâ€™s look at a case study to see how we can use uncertainty in the context of active learning.</p>
<p>In this case study, we will reproduce the results from a fundamental active learning paper: <em>Deep Bayesian Active Learning with Image Data</em> (2017). We will use the <span class="obeylines-h"><span class="verb"><code>MNIST</code></span></span> dataset and train a model on more and more data, where we select the data points to add to our training set via an uncertainty method. In this case, we will use epistemic uncertainty to select the most informative data points. Images with high epistemic uncertainty should be images that the model did not see before; the uncertainty can be reduced by adding more of them. As a comparison, we will also select data points at random.</p>
<section id="step-1-preparing-our-dataset" class="level4 likesubsubsectionHead" data-number="13.4.0.1">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.4.0.1"><span id="x1-1510004"></span>Step 1: Preparing our dataset</h4>
<p>We will start by creating our functions to load the dataset.<span id="dx1-151001"></span> The dataset functions need the following library imports:</p>
<pre id="fancyvrb197" class="fancyvrb"><span id="x1-151011r1"></span> 
<code><span id="textcolor4723"><span>import</span></span><span>Â </span><span id="textcolor4724"><span>dataclasses</span></span> <span id="x1-151013r2"></span> </code>
<code><span id="textcolor4725"><span>from</span></span><span>Â </span><span id="textcolor4726"><span>pathlib</span></span><span>Â </span><span id="textcolor4727"><span>import</span></span><span>Â Path</span> <span id="x1-151015r3"></span> </code>
<code><span id="textcolor4728"><span>import</span></span><span>Â </span><span id="textcolor4729"><span>uuid</span></span> <span id="x1-151017r4"></span> </code>
<code><span id="textcolor4730"><span>from</span></span><span>Â </span><span id="textcolor4731"><span>typing</span></span><span>Â </span><span id="textcolor4732"><span>import</span></span><span>Â Optional,</span><span>Â Tuple</span> <span id="x1-151019r5"></span> </code>
<code><span id="x1-151021r6"></span></code>
<code><span id="textcolor4733"><span>import</span></span><span>Â </span><span id="textcolor4734"><span>numpy</span></span><span>Â </span><span id="textcolor4735"><span>as</span></span><span>Â </span><span id="textcolor4736"><span>np</span></span> <span id="x1-151023r7"></span> </code>
<code><span id="textcolor4737"><span>import</span></span><span>Â </span><span id="textcolor4738"><span>tensorflow</span></span><span>Â </span><span id="textcolor4739"><span>as</span></span><span>Â </span><span id="textcolor4740"><span>tf</span></span> <span id="x1-151025r8"></span> </code>
<code><span id="textcolor4741"><span>from</span></span><span>Â </span><span id="textcolor4742"><span>sklearn.utils</span></span><span>Â </span><span id="textcolor4743"><span>import</span></span><span>Â shuffle</span></code></pre>
<p>As our total dataset will have quite a few components, we will create a small dataclass to easily access all the different parts of our dataset. We will also modify the <code>__repr__</code> function of the dataclass. This allows us to print the content of the dataset in a more readable format.</p>
<pre id="fancyvrb198" class="fancyvrb"><span id="x1-151042r1"></span> 
<code><span id="textcolor4745"><span>@dataclasses</span></span><span id="textcolor4746"><span>.</span></span><span>dataclass</span> <span id="x1-151044r2"></span> </code>
<code><span id="textcolor4747"><span>class</span></span><span>Â </span><span id="textcolor4748"><span>Data</span></span><span>:</span> <span id="x1-151046r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train:</span><span>Â np</span><span id="textcolor4749"><span>.</span></span><span>ndarray</span> <span id="x1-151048r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â y_train:</span><span>Â np</span><span id="textcolor4750"><span>.</span></span><span>ndarray</span> <span id="x1-151050r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_test:</span><span>Â np</span><span id="textcolor4751"><span>.</span></span><span>ndarray</span> <span id="x1-151052r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â y_test:</span><span>Â np</span><span id="textcolor4752"><span>.</span></span><span>ndarray</span> <span id="x1-151054r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train_al:</span><span>Â Optional[np</span><span id="textcolor4753"><span>.</span></span><span>ndarray]</span><span>Â </span><span id="textcolor4754"><span>=</span></span><span>Â </span><span id="textcolor4755"><span>None</span></span> <span id="x1-151056r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â y_train_al:</span><span>Â Optional[np</span><span id="textcolor4756"><span>.</span></span><span>ndarray]</span><span>Â </span><span id="textcolor4757"><span>=</span></span><span>Â </span><span id="textcolor4758"><span>None</span></span> <span id="x1-151058r9"></span> </code>
<code><span id="x1-151060r10"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4759"><span>def</span></span><span>Â </span><span id="textcolor4760"><span>__repr__</span></span><span>(</span><span id="textcolor4761"><span>self</span></span><span>)</span><span>Â </span><span id="textcolor4762"><span>-</span><em>&gt;</em></span><span>Â </span><span id="textcolor4763"><span>str</span></span><span>:</span> <span id="x1-151062r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â repr_str</span><span>Â </span><span id="textcolor4764"><span>=</span></span><span>Â </span><span id="textcolor4765"><span>""</span></span> <span id="x1-151064r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4766"><span>for</span></span><span>Â field</span><span>Â </span><span id="textcolor4767"><span>in</span></span><span>Â dataclasses</span><span id="textcolor4768"><span>.</span></span><span>fields(</span><span id="textcolor4769"><span>self</span></span><span>):</span> <span id="x1-151066r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â repr_str</span><span>Â </span><span id="textcolor4770"><span>+=</span></span><span>Â </span><span id="textcolor4771"><span>f</span></span><span id="textcolor4772"><span>"</span></span><span id="textcolor4773"><span>{</span></span><span>field</span><span id="textcolor4774"><span>.</span></span><span>name</span><span id="textcolor4775"><span>}</span></span><span id="textcolor4776"><span>:</span><span>Â </span></span><span id="textcolor4777"><span>{</span></span><span id="textcolor4778"><span>getattr</span></span><span>(</span><span id="textcolor4779"><span>self</span></span><span>,</span><span>Â field</span><span id="textcolor4780"><span>.</span></span><span>name)</span><span id="textcolor4781"><span>.</span></span><span>shape</span><span id="textcolor4782"><span>}</span></span><span id="textcolor4783"><span>Â </span></span><span id="textcolor4784"><span>\n</span></span><span id="textcolor4785"><span>"</span></span> <span id="x1-151068r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4786"><span>return</span></span><span>Â repr_str</span></code></pre>
<p>We can then define our function to load our standard dataset.<span id="dx1-151069"></span></p>
<pre id="fancyvrb199" class="fancyvrb"><span id="x1-151083r1"></span> 
<code><span id="textcolor4787"><span>def</span></span><span>Â </span><span id="textcolor4788"><span>get_data</span></span><span>()</span><span>Â </span><span id="textcolor4789"><span>-</span><em>&gt;</em></span><span>Â Data:</span> <span id="x1-151085r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â num_classes</span><span>Â </span><span id="textcolor4790"><span>=</span></span><span>Â </span><span id="textcolor4791"><span>10</span></span> <span id="x1-151087r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â (x_train,</span><span>Â y_train),</span><span>Â (x_test,</span><span>Â y_test)</span><span>Â </span><span id="textcolor4792"><span>=</span></span><span>Â tf</span><span id="textcolor4793"><span>.</span></span><span>keras</span><span id="textcolor4794"><span>.</span></span><span>datasets</span><span id="textcolor4795"><span>.</span></span><span>mnist</span><span id="textcolor4796"><span>.</span></span><span>load_data()</span> <span id="x1-151089r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4797"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Scale</span><span class="cmitt-10x-x-109">Â images</span><span class="cmitt-10x-x-109">Â to</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â [0,</span><span class="cmitt-10x-x-109">Â 1]</span><span class="cmitt-10x-x-109">Â range</span></span> <span id="x1-151091r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train</span><span>Â </span><span id="textcolor4798"><span>=</span></span><span>Â x_train</span><span id="textcolor4799"><span>.</span></span><span>astype(</span><span id="textcolor4800"><span>"float32"</span></span><span>)</span><span>Â </span><span id="textcolor4801"><span>/</span></span><span>Â </span><span id="textcolor4802"><span>255</span></span> <span id="x1-151093r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_test</span><span>Â </span><span id="textcolor4803"><span>=</span></span><span>Â x_test</span><span id="textcolor4804"><span>.</span></span><span>astype(</span><span id="textcolor4805"><span>"float32"</span></span><span>)</span><span>Â </span><span id="textcolor4806"><span>/</span></span><span>Â </span><span id="textcolor4807"><span>255</span></span> <span id="x1-151095r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4808"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â Make</span><span class="cmitt-10x-x-109">Â sure</span><span class="cmitt-10x-x-109">Â images</span><span class="cmitt-10x-x-109">Â have</span><span class="cmitt-10x-x-109">Â shape</span><span class="cmitt-10x-x-109">Â (28,</span><span class="cmitt-10x-x-109">Â 28,</span><span class="cmitt-10x-x-109">Â 1)</span></span> <span id="x1-151097r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train</span><span>Â </span><span id="textcolor4809"><span>=</span></span><span>Â np</span><span id="textcolor4810"><span>.</span></span><span>expand_dims(x_train,</span><span>Â </span><span id="textcolor4811"><span>-</span></span><span id="textcolor4812"><span>1</span></span><span>)</span> <span id="x1-151099r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_test</span><span>Â </span><span id="textcolor4813"><span>=</span></span><span>Â np</span><span id="textcolor4814"><span>.</span></span><span>expand_dims(x_test,</span><span>Â </span><span id="textcolor4815"><span>-</span></span><span id="textcolor4816"><span>1</span></span><span>)</span> <span id="x1-151101r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â y_train</span><span>Â </span><span id="textcolor4817"><span>=</span></span><span>Â tf</span><span id="textcolor4818"><span>.</span></span><span>keras</span><span id="textcolor4819"><span>.</span></span><span>utils</span><span id="textcolor4820"><span>.</span></span><span>to_categorical(y_train,</span><span>Â num_classes)</span> <span id="x1-151103r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â y_test</span><span>Â </span><span id="textcolor4821"><span>=</span></span><span>Â tf</span><span id="textcolor4822"><span>.</span></span><span>keras</span><span id="textcolor4823"><span>.</span></span><span>utils</span><span id="textcolor4824"><span>.</span></span><span>to_categorical(y_test,</span><span>Â num_classes)</span> <span id="x1-151105r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4825"><span>return</span></span><span>Â Data(x_train,</span><span>Â y_train,</span><span>Â x_test,</span><span>Â y_test)</span></code></pre>
<p>Initially, we will start training on just 20 samples from the <em>MNIST</em> dataset. We will then acquire 10 data points at a time, and retrain our model again. To help our model a little bit in the beginning, we will make sure that the 20 data points are balanced across the different classes of the dataset. The following function gives us the indices that we can use to create the initial 20 samples, 2 samples of each class:</p>
<pre id="fancyvrb200" class="fancyvrb"><span id="x1-151123r1"></span> 
<code><span id="textcolor4826"><span>def</span></span><span>Â </span><span id="textcolor4827"><span>get_random_balanced_indices</span></span><span>(</span> <span id="x1-151125r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â data:</span><span>Â Data,</span><span>Â initial_n_samples:</span><span>Â </span><span id="textcolor4828"><span>int</span></span> <span id="x1-151127r3"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4829"><span>-</span><em>&gt;</em></span><span>Â np</span><span id="textcolor4830"><span>.</span></span><span>ndarray:</span> <span id="x1-151129r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â labels</span><span>Â </span><span id="textcolor4831"><span>=</span></span><span>Â np</span><span id="textcolor4832"><span>.</span></span><span>argmax(data</span><span id="textcolor4833"><span>.</span></span><span>y_train,</span><span>Â axis</span><span id="textcolor4834"><span>=</span></span><span id="textcolor4835"><span>1</span></span><span>)</span> <span id="x1-151131r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â indices</span><span>Â </span><span id="textcolor4836"><span>=</span></span><span>Â []</span> <span id="x1-151133r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â label_list</span><span>Â </span><span id="textcolor4837"><span>=</span></span><span>Â np</span><span id="textcolor4838"><span>.</span></span><span>unique(labels)</span> <span id="x1-151135r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4839"><span>for</span></span><span>Â label</span><span>Â </span><span id="textcolor4840"><span>in</span></span><span>Â label_list:</span> <span id="x1-151137r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â indices_label</span><span>Â </span><span id="textcolor4841"><span>=</span></span><span>Â np</span><span id="textcolor4842"><span>.</span></span><span>random</span><span id="textcolor4843"><span>.</span></span><span>choice(</span> <span id="x1-151139r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor4844"><span>.</span></span><span>argwhere(labels</span><span>Â </span><span id="textcolor4845"><span>==</span></span><span>Â label)</span><span id="textcolor4846"><span>.</span></span><span>flatten(),</span> <span id="x1-151141r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â size</span><span id="textcolor4847"><span>=</span></span><span>initial_n_samples</span><span>Â </span><span id="textcolor4848"><span>//</span></span><span>Â </span><span id="textcolor4849"><span>len</span></span><span>(label_list),</span> <span id="x1-151143r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â replace</span><span id="textcolor4850"><span>=</span></span><span id="textcolor4851"><span>False</span></span> <span id="x1-151145r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-151147r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â indices</span><span id="textcolor4852"><span>.</span></span><span>extend(indices_label)</span> <span id="x1-151149r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â indices</span><span>Â </span><span id="textcolor4853"><span>=</span></span><span>Â np</span><span id="textcolor4854"><span>.</span></span><span>array(indices)</span> <span id="x1-151151r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor4855"><span>.</span></span><span>random</span><span id="textcolor4856"><span>.</span></span><span>shuffle(indices)</span> <span id="x1-151153r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4857"><span>return</span></span><span>Â indices</span></code></pre>
<p>We can then define a small function to actually get our initial dataset:<span id="dx1-151154"></span></p>
<pre id="fancyvrb201" class="fancyvrb"><span id="x1-151164r1"></span> 
<code><span id="textcolor4858"><span>def</span></span><span>Â </span><span id="textcolor4859"><span>get_initial_ds</span></span><span>(data:</span><span>Â Data,</span><span>Â initial_n_samples:</span><span>Â </span><span id="textcolor4860"><span>int</span></span><span>)</span><span>Â </span><span id="textcolor4861"><span>-</span><em>&gt;</em></span><span>Â Data:</span> <span id="x1-151166r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â indices</span><span>Â </span><span id="textcolor4862"><span>=</span></span><span>Â get_random_balanced_indices(data,</span><span>Â initial_n_samples)</span> <span id="x1-151168r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train_al,</span><span>Â y_train_al</span><span>Â </span><span id="textcolor4863"><span>=</span></span><span>Â data</span><span id="textcolor4864"><span>.</span></span><span>x_train[indices],</span><span>Â data</span><span id="textcolor4865"><span>.</span></span><span>y_train[indices]</span> <span id="x1-151170r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train</span><span>Â </span><span id="textcolor4866"><span>=</span></span><span>Â np</span><span id="textcolor4867"><span>.</span></span><span>delete(data</span><span id="textcolor4868"><span>.</span></span><span>x_train,</span><span>Â indices,</span><span>Â axis</span><span id="textcolor4869"><span>=</span></span><span id="textcolor4870"><span>0</span></span><span>)</span> <span id="x1-151172r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â y_train</span><span>Â </span><span id="textcolor4871"><span>=</span></span><span>Â np</span><span id="textcolor4872"><span>.</span></span><span>delete(data</span><span id="textcolor4873"><span>.</span></span><span>y_train,</span><span>Â indices,</span><span>Â axis</span><span id="textcolor4874"><span>=</span></span><span id="textcolor4875"><span>0</span></span><span>)</span> <span id="x1-151174r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4876"><span>return</span></span><span>Â Data(</span> <span id="x1-151176r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â x_train,</span><span>Â y_train,</span><span>Â data</span><span id="textcolor4877"><span>.</span></span><span>x_test,</span><span>Â data</span><span id="textcolor4878"><span>.</span></span><span>y_test,</span><span>Â x_train_al,</span><span>Â y_train_al</span> <span id="x1-151178r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
</section>
<section id="step-2-setting-up-our-configuration" class="level4 likesubsubsectionHead" data-number="13.4.0.2">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.4.0.2"><span id="x1-1520004"></span>Step 2: Setting up our configuration</h4>
<p>Before we start to build our model and create the active learning loop<span id="dx1-152001"></span>, we define a small configuration <code>dataclass</code> to store some main variables we might want to play around with when running our active learning script. Creating configuration classes such as these allows you to play around with different parameters.</p>
<pre id="fancyvrb202" class="fancyvrb"><span id="x1-152014r1"></span> 
<code><span id="textcolor4879"><span>@dataclasses</span></span><span id="textcolor4880"><span>.</span></span><span>dataclass</span> <span id="x1-152016r2"></span> </code>
<code><span id="textcolor4881"><span>class</span></span><span>Â </span><span id="textcolor4882"><span>Config</span></span><span>:</span> <span id="x1-152018r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â initial_n_samples:</span><span>Â </span><span id="textcolor4883"><span>int</span></span> <span id="x1-152020r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_total_samples:</span><span>Â </span><span id="textcolor4884"><span>int</span></span> <span id="x1-152022r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_epochs:</span><span>Â </span><span id="textcolor4885"><span>int</span></span> <span id="x1-152024r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_samples_per_iter:</span><span>Â </span><span id="textcolor4886"><span>int</span></span> <span id="x1-152026r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4887"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â string</span><span class="cmitt-10x-x-109">Â representation</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â acquisition</span><span class="cmitt-10x-x-109">Â function</span></span> <span id="x1-152028r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â acquisition_type:</span><span>Â </span><span id="textcolor4888"><span>str</span></span> <span id="x1-152030r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4889"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â number</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â mc_dropout</span><span class="cmitt-10x-x-109">Â iterations</span></span> <span id="x1-152032r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_iter:</span><span>Â </span><span id="textcolor4890"><span>int</span></span></code></pre>
</section>
<section id="step-3-defining-the-model" class="level4 likesubsubsectionHead" data-number="13.4.0.3">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.4.0.3"><span id="x1-1530004"></span>Step 3: Defining the model</h4>
<p>We can now define our model. We will use a small, simple CNN with dropout.<span id="dx1-153001"></span></p>
<pre id="fancyvrb203" class="fancyvrb"><span id="x1-153022r1"></span> 
<code><span id="textcolor4891"><span>def</span></span><span>Â </span><span id="textcolor4892"><span>build_model</span></span><span>():</span> <span id="x1-153024r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor4893"><span>=</span></span><span>Â tf</span><span id="textcolor4894"><span>.</span></span><span>keras</span><span id="textcolor4895"><span>.</span></span><span>models</span><span id="textcolor4896"><span>.</span></span><span>Sequential([</span> <span id="x1-153026r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â Input(shape</span><span id="textcolor4897"><span>=</span></span><span>(</span><span id="textcolor4898"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor4899"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor4900"><span>1</span></span><span>)),</span> <span id="x1-153028r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4901"><span>.</span></span><span>Conv2D(</span><span id="textcolor4902"><span>32</span></span><span>,</span><span>Â kernel_size</span><span id="textcolor4903"><span>=</span></span><span>(</span><span id="textcolor4904"><span>4</span></span><span>,</span><span>Â </span><span id="textcolor4905"><span>4</span></span><span>),</span><span>Â activation</span><span id="textcolor4906"><span>=</span></span><span id="textcolor4907"><span>"relu"</span></span><span>),</span> <span id="x1-153030r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4908"><span>.</span></span><span>Conv2D(</span><span id="textcolor4909"><span>32</span></span><span>,</span><span>Â kernel_size</span><span id="textcolor4910"><span>=</span></span><span>(</span><span id="textcolor4911"><span>4</span></span><span>,</span><span>Â </span><span id="textcolor4912"><span>4</span></span><span>),</span><span>Â activation</span><span id="textcolor4913"><span>=</span></span><span id="textcolor4914"><span>"relu"</span></span><span>),</span> <span id="x1-153032r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4915"><span>.</span></span><span>MaxPooling2D(pool_size</span><span id="textcolor4916"><span>=</span></span><span>(</span><span id="textcolor4917"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor4918"><span>2</span></span><span>)),</span> <span id="x1-153034r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4919"><span>.</span></span><span>Dropout(</span><span id="textcolor4920"><span>0.25</span></span><span>),</span> <span id="x1-153036r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4921"><span>.</span></span><span>Flatten(),</span> <span id="x1-153038r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4922"><span>.</span></span><span>Dense(</span><span id="textcolor4923"><span>128</span></span><span>,</span><span>Â activation</span><span id="textcolor4924"><span>=</span></span><span id="textcolor4925"><span>"relu"</span></span><span>),</span> <span id="x1-153040r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4926"><span>.</span></span><span>Dropout(</span><span id="textcolor4927"><span>0.5</span></span><span>),</span> <span id="x1-153042r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor4928"><span>.</span></span><span>Dense(</span><span id="textcolor4929"><span>10</span></span><span>,</span><span>Â activation</span><span id="textcolor4930"><span>=</span></span><span id="textcolor4931"><span>"softmax"</span></span><span>),</span> <span id="x1-153044r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ])</span> <span id="x1-153046r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor4932"><span>.</span></span><span>compile(</span> <span id="x1-153048r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor4933"><span>.</span></span><span>keras</span><span id="textcolor4934"><span>.</span></span><span>optimizers</span><span id="textcolor4935"><span>.</span></span><span>Adam(),</span> <span id="x1-153050r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor4936"><span>=</span></span><span id="textcolor4937"><span>"categorical_crossentropy"</span></span><span>,</span> <span id="x1-153052r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor4938"><span>=</span></span><span>[</span><span id="textcolor4939"><span>"accuracy"</span></span><span>],</span> <span id="x1-153054r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â experimental_run_tf_function</span><span id="textcolor4940"><span>=</span></span><span id="textcolor4941"><span>False</span></span><span>,</span> <span id="x1-153056r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-153058r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4942"><span>return</span></span><span>Â model</span></code></pre>
</section>
<section id="step-4-defining-the-uncertainty-functions" class="level4 likesubsubsectionHead" data-number="13.4.0.4">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.4.0.4"><span id="x1-1540004"></span>Step 4: Defining the uncertainty functions</h4>
<p>As indicated, we will use epistemic uncertainty (also knowledge uncertainty) as our main uncertainty function to acquire new samples.<span id="dx1-154001"></span> Letâ€™s define the function to compute epistemic uncertainty over our predictions. We assume that the input predictions (<code>divds</code>) are of shape <code>n_images</code>, <code>n_predictions</code>, <code>n_classes</code>. We first define a function to compute total uncertainty. Given an ensemble of model predictions, this can be defined as the entropy of the averaged predictions of the ensemble.</p>
<pre id="fancyvrb204" class="fancyvrb"><span id="x1-154013r1"></span> 
<code><span id="textcolor4943"><span>def</span></span><span>Â </span><span id="textcolor4944"><span>total_uncertainty</span></span><span>(</span> <span id="x1-154015r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divds:</span><span>Â np</span><span id="textcolor4945"><span>.</span></span><span>ndarray,</span><span>Â epsilon:</span><span>Â </span><span id="textcolor4946"><span>float</span></span><span>Â </span><span id="textcolor4947"><span>=</span></span><span>Â </span><span id="textcolor4948"><span>1e-10</span></span> <span id="x1-154017r3"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4949"><span>-</span><em>&gt;</em></span><span>Â np</span><span id="textcolor4950"><span>.</span></span><span>ndarray:</span> <span id="x1-154019r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â mean_divds</span><span>Â </span><span id="textcolor4951"><span>=</span></span><span>Â np</span><span id="textcolor4952"><span>.</span></span><span>mean(divds,</span><span>Â axis</span><span id="textcolor4953"><span>=</span></span><span id="textcolor4954"><span>1</span></span><span>)</span> <span id="x1-154021r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â log_divds</span><span>Â </span><span id="textcolor4955"><span>=</span></span><span>Â </span><span id="textcolor4956"><span>-</span></span><span>np</span><span id="textcolor4957"><span>.</span></span><span>log(mean_divds</span><span>Â </span><span id="textcolor4958"><span>+</span></span><span>Â epsilon)</span> <span id="x1-154023r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4959"><span>return</span></span><span>Â np</span><span id="textcolor4960"><span>.</span></span><span>sum(mean_divds</span><span>Â </span><span id="textcolor4961"><span>*</span></span><span>Â log_divds,</span><span>Â axis</span><span id="textcolor4962"><span>=</span></span><span id="textcolor4963"><span>1</span></span><span>)</span></code></pre>
<p>We then define data uncertainty (or aleatoric uncertainty), which for an ensemble is the average of the entropy of each ensemble member.<span id="dx1-154024"></span></p>
<pre id="fancyvrb205" class="fancyvrb"><span id="x1-154029r1"></span> 
<code><span id="textcolor4964"><span>def</span></span><span>Â </span><span id="textcolor4965"><span>data_uncertainty</span></span><span>(divds:</span><span>Â np</span><span id="textcolor4966"><span>.</span></span><span>ndarray,</span><span>Â epsilon:</span><span>Â </span><span id="textcolor4967"><span>float</span></span><span>Â </span><span id="textcolor4968"><span>=</span></span><span>Â </span><span id="textcolor4969"><span>1e-10</span></span><span>)</span><span>Â </span><span id="textcolor4970"><span>-</span><em>&gt;</em></span><span>Â np</span><span id="textcolor4971"><span>.</span></span><span>ndarray:</span> <span id="x1-154031r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â log_divds</span><span>Â </span><span id="textcolor4972"><span>=</span></span><span>Â </span><span id="textcolor4973"><span>-</span></span><span>np</span><span id="textcolor4974"><span>.</span></span><span>log(divds</span><span>Â </span><span id="textcolor4975"><span>+</span></span><span>Â epsilon)</span> <span id="x1-154033r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4976"><span>return</span></span><span>Â np</span><span id="textcolor4977"><span>.</span></span><span>mean(np</span><span id="textcolor4978"><span>.</span></span><span>sum(divds</span><span>Â </span><span id="textcolor4979"><span>*</span></span><span>Â log_divds,</span><span>Â axis</span><span id="textcolor4980"><span>=</span></span><span id="textcolor4981"><span>2</span></span><span>),</span><span>Â axis</span><span id="textcolor4982"><span>=</span></span><span id="textcolor4983"><span>1</span></span><span>)</span></code></pre>
<p>Finally, we have our knowledge (or epistemic) uncertainty, which is simply subtracting data uncertainty from the total uncertainty of the predictions.</p>
<pre id="fancyvrb206" class="fancyvrb"><span id="x1-154039r1"></span> 
<code><span id="textcolor4984"><span>def</span></span><span>Â </span><span id="textcolor4985"><span>knowledge_uncertainty</span></span><span>(</span> <span id="x1-154041r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divds:</span><span>Â np</span><span id="textcolor4986"><span>.</span></span><span>ndarray,</span><span>Â epsilon:</span><span>Â </span><span id="textcolor4987"><span>float</span></span><span>Â </span><span id="textcolor4988"><span>=</span></span><span>Â </span><span id="textcolor4989"><span>1e-10</span></span> <span id="x1-154043r3"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor4990"><span>-</span><em>&gt;</em></span><span>Â np</span><span id="textcolor4991"><span>.</span></span><span>ndarray:</span> <span id="x1-154045r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor4992"><span>return</span></span><span>Â total_uncertainty(divds,</span><span>Â epsilon)</span><span>Â </span><span id="textcolor4993"><span>-</span></span><span>Â data_uncertainty(divds,</span><span>Â epsilon)</span></code></pre>
<p>With these uncertainty functions defined, we can define the actual acquisition functions that take as main input our training data and our model. To acquire samples via knowledge uncertainty, we do the following:</p>
<ol>
<li><div id="x1-154047x1">
<p>Obtain our ensemble of predictions via MC dropout.</p>
</div></li>
<li><div id="x1-154049x2">
<p>Compute the knowledge uncertainty values over this ensemble.</p>
</div></li>
<li><div id="x1-154051x3">
<p>Sort the uncertainty values, get their index and return the indices of our training data with the highest epistemic uncertainty.</p>
</div></li>
</ol>
<p>We can then, later on, reuse these indices to index into our training data and actually acquire the training samples we want to add.</p>
<pre id="fancyvrb207" class="fancyvrb"><span id="x1-154070r1"></span> 
<code><span id="textcolor4994"><span>from</span></span><span>Â </span><span id="textcolor4995"><span>typing</span></span><span>Â </span><span id="textcolor4996"><span>import</span></span><span>Â Callable</span> <span id="x1-154072r2"></span> </code>
<code><span id="textcolor4997"><span>from</span></span><span>Â </span><span id="textcolor4998"><span>keras</span></span><span>Â </span><span id="textcolor4999"><span>import</span></span><span>Â Model</span> <span id="x1-154074r3"></span> </code>
<code><span id="textcolor5000"><span>from</span></span><span>Â </span><span id="textcolor5001"><span>tqdm</span></span><span>Â </span><span id="textcolor5002"><span>import</span></span><span>Â tqdm</span> <span id="x1-154076r4"></span> </code>
<code><span id="x1-154078r5"></span></code>
<code><span id="textcolor5003"><span>import</span></span><span>Â </span><span id="textcolor5004"><span>numpy</span></span><span>Â </span><span id="textcolor5005"><span>as</span></span><span>Â </span><span id="textcolor5006"><span>np</span></span> <span id="x1-154080r6"></span> </code>
<code><span id="x1-154082r7"></span></code>
<code><span id="textcolor5007"><span>def</span></span><span>Â </span><span id="textcolor5008"><span>acquire_knowledge_uncertainty</span></span><span>(</span> <span id="x1-154084r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â x_train:</span><span>Â np</span><span id="textcolor5009"><span>.</span></span><span>ndarray,</span> <span id="x1-154086r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_samples:</span><span>Â </span><span id="textcolor5010"><span>int</span></span><span>,</span> <span id="x1-154088r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model:</span><span>Â Model,</span> <span id="x1-154090r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_iter:</span><span>Â </span><span id="textcolor5011"><span>int</span></span><span>,</span> <span id="x1-154092r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5012"><span>*</span></span><span>args,</span> <span id="x1-154094r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5013"><span>**</span></span><span>kwargs</span> <span id="x1-154096r14"></span> </code>
<code><span>):</span> <span id="x1-154098r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divds</span><span>Â </span><span id="textcolor5014"><span>=</span></span><span>Â get_mc_predictions(model,</span><span>Â n_iter,</span><span>Â x_train)</span> <span id="x1-154100r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ku</span><span>Â </span><span id="textcolor5015"><span>=</span></span><span>Â knowledge_uncertainty(divds)</span> <span id="x1-154102r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5016"><span>return</span></span><span>Â np</span><span id="textcolor5017"><span>.</span></span><span>argsort(ku,</span><span>Â axis</span><span id="textcolor5018"><span>=-</span></span><span id="textcolor5019"><span>1</span></span><span>)[</span><span id="textcolor5020"><span>-</span></span><span>n_samples:]</span></code></pre>
<p>We obtain our MC dropout predictions<span id="dx1-154103"></span> as follows:</p>
<pre id="fancyvrb208" class="fancyvrb"><span id="x1-154118r1"></span> 
<code><span id="textcolor5021"><span>def</span></span><span>Â </span><span id="textcolor5022"><span>get_mc_predictions</span></span><span>(</span> <span id="x1-154120r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model:</span><span>Â Model,</span><span>Â n_iter:</span><span>Â </span><span id="textcolor5023"><span>int</span></span><span>,</span><span>Â x_train:</span><span>Â np</span><span id="textcolor5024"><span>.</span></span><span>ndarray</span> <span id="x1-154122r3"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor5025"><span>-</span><em>&gt;</em></span><span>Â np</span><span id="textcolor5026"><span>.</span></span><span>ndarray:</span> <span id="x1-154124r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divds</span><span>Â </span><span id="textcolor5027"><span>=</span></span><span>Â []</span> <span id="x1-154126r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5028"><span>for</span></span><span>Â _</span><span>Â </span><span id="textcolor5029"><span>in</span></span><span>Â tqdm(</span><span id="textcolor5030"><span>range</span></span><span>(n_iter)):</span> <span id="x1-154128r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â divds_iter</span><span>Â </span><span id="textcolor5031"><span>=</span></span><span>Â [</span> <span id="x1-154130r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â model(batch,</span><span>Â training</span><span id="textcolor5032"><span>=</span></span><span id="textcolor5033"><span>True</span></span><span>)</span> <span id="x1-154132r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5034"><span>for</span></span><span>Â batch</span><span>Â </span><span id="textcolor5035"><span>in</span></span><span>Â np</span><span id="textcolor5036"><span>.</span></span><span>array_split(x_train,</span><span>Â </span><span id="textcolor5037"><span>6</span></span><span>)</span> <span id="x1-154134r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-154136r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â divds</span><span id="textcolor5038"><span>.</span></span><span>append(np</span><span id="textcolor5039"><span>.</span></span><span>concatenate(divds_iter))</span> <span id="x1-154138r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5040"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â format</span><span class="cmitt-10x-x-109">Â data</span><span class="cmitt-10x-x-109">Â such</span><span class="cmitt-10x-x-109">Â that</span><span class="cmitt-10x-x-109">Â we</span><span class="cmitt-10x-x-109">Â have</span><span class="cmitt-10x-x-109">Â n_images,</span><span class="cmitt-10x-x-109">Â n_predictions,</span><span class="cmitt-10x-x-109">Â n_classes</span></span> <span id="x1-154140r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divds</span><span>Â </span><span id="textcolor5041"><span>=</span></span><span>Â np</span><span id="textcolor5042"><span>.</span></span><span>moveaxis(np</span><span id="textcolor5043"><span>.</span></span><span>stack(divds),</span><span>Â </span><span id="textcolor5044"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5045"><span>1</span></span><span>)</span> <span id="x1-154142r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5046"><span>return</span></span><span>Â divds</span></code></pre>
<p>To avoid running out of memory, we iterate over our training data in batches of six, where for every batch we compute our predictions <code>n_iter</code> times. To make sure that our predictions are varied, we set the modelâ€™s <code>training</code> parameter to <code>True</code>.</p>
<p>For our comparison, we define an acquisition function that returns a random number of indices as well:</p>
<pre id="fancyvrb209" class="fancyvrb"><span id="x1-154149r1"></span> 
<code><span id="textcolor5048"><span>def</span></span><span>Â </span><span id="textcolor5049"><span>acquire_random</span></span><span>(x_train:</span><span>Â np</span><span id="textcolor5050"><span>.</span></span><span>ndarray,</span><span>Â n_samples:</span><span>Â </span><span id="textcolor5051"><span>int</span></span><span>,</span><span>Â </span><span id="textcolor5052"><span>*</span></span><span>args,</span><span>Â </span><span id="textcolor5053"><span>**</span></span><span>kwargs):</span> <span id="x1-154151r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5054"><span>return</span></span><span>Â np</span><span id="textcolor5055"><span>.</span></span><span>random</span><span id="textcolor5056"><span>.</span></span><span>randint(low</span><span id="textcolor5057"><span>=</span></span><span id="textcolor5058"><span>0</span></span><span>,</span><span>Â high</span><span id="textcolor5059"><span>=</span></span><span id="textcolor5060"><span>len</span></span><span>(x_train),</span><span>Â size</span><span id="textcolor5061"><span>=</span></span><span>n_samples)</span></code></pre>
<p>Finally, we define a small function according to the <em>factory method pattern</em> to make sure that we can use the same function in our loop to use either the random acquisition function or knowledge uncertainty<span id="dx1-154152"></span>. Small factory functions such as these help to keep your code modular when you want to run the same code with different configurations.</p>
<pre id="fancyvrb210" class="fancyvrb"><span id="x1-154159r1"></span> 
<code><span id="textcolor5062"><span>def</span></span><span>Â </span><span id="textcolor5063"><span>acquisition_factory</span></span><span>(acquisition_type:</span><span>Â </span><span id="textcolor5064"><span>str</span></span><span>)</span><span>Â </span><span id="textcolor5065"><span>-</span><em>&gt;</em></span><span>Â Callable:</span> <span id="x1-154161r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5066"><span>if</span></span><span>Â acquisition_type</span><span>Â </span><span id="textcolor5067"><span>==</span></span><span>Â </span><span id="textcolor5068"><span>"knowledge_uncertainty"</span></span><span>:</span> <span id="x1-154163r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5069"><span>return</span></span><span>Â acquire_knowledge_uncertainty</span> <span id="x1-154165r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5070"><span>if</span></span><span>Â acquisition_type</span><span>Â </span><span id="textcolor5071"><span>==</span></span><span>Â </span><span id="textcolor5072"><span>"random"</span></span><span>:</span> <span id="x1-154167r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5073"><span>return</span></span><span>Â acquire_random</span></code></pre>
<p>Now that we have defined our acquisition functions, we are ready to actually define the loop that runs our active learning iterations.</p>
</section>
<section id="step-5-defining-the-loop" class="level4 likesubsubsectionHead" data-number="13.4.0.5">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.4.0.5"><span id="x1-1550004"></span>Step 5: Defining the loop</h4>
<p>Letâ€™s start by defining our configuration.<span id="dx1-155001"></span> In this case, we are using knowledge uncertainty as our uncertainty function. In a different loop, we will use a random acquisition function to compare the results of the loop we are about to define. We will start our dataset with 20 samples until we reach a total of 1,000 samples. Each model will be trained for 50 epochs and per iteration, we acquire 10 samples. To obtain our MC dropout predictions, we will run over our full training set (minus the already acquired samples) 100 times.</p>
<pre id="fancyvrb211" class="fancyvrb"><span id="x1-155011r1"></span> 
<code><span>cfg</span><span>Â </span><span id="textcolor5074"><span>=</span></span><span>Â Config(</span> <span id="x1-155013r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â initial_n_samples</span><span id="textcolor5075"><span>=</span></span><span id="textcolor5076"><span>20</span></span><span>,</span> <span id="x1-155015r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_total_samples</span><span id="textcolor5077"><span>=</span></span><span id="textcolor5078"><span>1000</span></span><span>,</span> <span id="x1-155017r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_epochs</span><span id="textcolor5079"><span>=</span></span><span id="textcolor5080"><span>50</span></span><span>,</span> <span id="x1-155019r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_samples_per_iteration</span><span id="textcolor5081"><span>=</span></span><span id="textcolor5082"><span>10</span></span><span>,</span> <span id="x1-155021r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â acquisition_type</span><span id="textcolor5083"><span>=</span></span><span id="textcolor5084"><span>"knowledge_uncertainty"</span></span><span>,</span> <span id="x1-155023r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â n_iter</span><span id="textcolor5085"><span>=</span></span><span id="textcolor5086"><span>100</span></span><span>,</span> <span id="x1-155025r8"></span> </code>
<code><span>)</span></code></pre>
<p>We can then get our data and define an empty dictionary to keep track of the test accuracy per iteration. We also create an empty list to keep track of the full list of indices we added to our training data.</p>
<pre id="fancyvrb212" class="fancyvrb"><span id="x1-155030r1"></span> 
<code><span>data:</span><span>Â Data</span><span>Â </span><span id="textcolor5087"><span>=</span></span><span>Â get_initial_ds(get_data(),</span><span>Â cfg</span><span id="textcolor5088"><span>.</span></span><span>initial_n_samples)</span> <span id="x1-155032r2"></span> </code>
<code><span>accuracies</span><span>Â </span><span id="textcolor5089"><span>=</span></span><span>Â {}</span> <span id="x1-155034r3"></span> </code>
<code><span>added_indices</span><span>Â </span><span id="textcolor5090"><span>=</span></span><span>Â []</span></code></pre>
<p>We also assign a <strong>universally unique identifier</strong> (<strong>UUID</strong>)<span id="dx1-155035"></span> to our run to make sure we can discover it easily and do not overwrite the outcomes we save as part of our loop. We create the directory where we will save our data and save our configuration in that directory to ensure that we always know with what kind of configuration the data in our <code>model_dir</code> was created.</p>
<pre id="fancyvrb213" class="fancyvrb"><span id="x1-155041r1"></span> 
<code><span>run_uuid</span><span>Â </span><span id="textcolor5091"><span>=</span></span><span>Â </span><span id="textcolor5092"><span>str</span></span><span>(uuid</span><span id="textcolor5093"><span>.</span></span><span>uuid4())</span> <span id="x1-155043r2"></span> </code>
<code><span>model_dir</span><span>Â </span><span id="textcolor5094"><span>=</span></span><span>Â Path(</span><span id="textcolor5095"><span>"./models"</span></span><span>)</span><span>Â </span><span id="textcolor5096"><span>/</span></span><span>Â cfg</span><span id="textcolor5097"><span>.</span></span><span>acquisition_type</span><span>Â </span><span id="textcolor5098"><span>/</span></span><span>Â run_uuid</span> <span id="x1-155045r3"></span> </code>
<code><span>model_dir</span><span id="textcolor5099"><span>.</span></span><span>mkdir(parents</span><span id="textcolor5100"><span>=</span></span><span id="textcolor5101"><span>True</span></span><span>,</span><span>Â exist_ok</span><span id="textcolor5102"><span>=</span></span><span id="textcolor5103"><span>True</span></span><span>)</span></code></pre>
<p>We can now actually run our active learning loop. <span id="dx1-155046"></span>We will break this loop into three sections:</p>
<ol>
<li><div id="x1-155048x1">
<p>We define the loop and fit a model on the acquired samples:</p>
<pre id="fancyvrb214" class="fancyvrb"><span id="x1-155061r1"></span> 
<code><span id="textcolor5104"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor5105"><span>in</span></span><span>Â </span><span id="textcolor5106"><span>range</span></span><span>(cfg</span><span id="textcolor5107"><span>.</span></span><span>n_total_samples</span><span>Â </span><span id="textcolor5108"><span>//</span></span><span>Â cfg</span><span id="textcolor5109"><span>.</span></span><span>n_samples_per_iter):</span> <span id="x1-155063r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â iter_dir</span><span>Â </span><span id="textcolor5110"><span>=</span></span><span>Â model_dir</span><span>Â </span><span id="textcolor5111"><span>/</span></span><span>Â </span><span id="textcolor5112"><span>str</span></span><span>(i)</span> <span id="x1-155065r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor5113"><span>=</span></span><span>Â build_model()</span> <span id="x1-155067r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor5114"><span>.</span></span><span>fit(</span> <span id="x1-155069r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â x</span><span id="textcolor5115"><span>=</span></span><span>data</span><span id="textcolor5116"><span>.</span></span><span>x_train_al,</span> <span id="x1-155071r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â y</span><span id="textcolor5117"><span>=</span></span><span>data</span><span id="textcolor5118"><span>.</span></span><span>y_train_al,</span> <span id="x1-155073r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â validation_data</span><span id="textcolor5119"><span>=</span></span><span>(data</span><span id="textcolor5120"><span>.</span></span><span>x_test,</span><span>Â data</span><span id="textcolor5121"><span>.</span></span><span>y_test),</span> <span id="x1-155075r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epochs</span><span id="textcolor5122"><span>=</span></span><span>cfg</span><span id="textcolor5123"><span>.</span></span><span>n_epochs,</span> <span id="x1-155077r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â callbacks</span><span id="textcolor5124"><span>=</span></span><span>[get_callback(iter_dir)],</span> <span id="x1-155079r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â verbose</span><span id="textcolor5125"><span>=</span></span><span id="textcolor5126"><span>2</span></span><span>,</span> <span id="x1-155081r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
</div></li>
<li><div id="x1-155083x2">
<p>We then load the model with the best validation accuracy and update our dataset based on the acquisition function:</p>
<pre id="fancyvrb215" class="fancyvrb"><span id="x1-155094r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span>Â </span><span id="textcolor5127"><span>=</span></span><span>Â tf</span><span id="textcolor5128"><span>.</span></span><span>keras</span><span id="textcolor5129"><span>.</span></span><span>models</span><span id="textcolor5130"><span>.</span></span><span>load_model(iter_dir)</span> <span id="x1-155096r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â indices_to_add</span><span>Â </span><span id="textcolor5131"><span>=</span></span><span>Â acquisition_factory(cfg</span><span id="textcolor5132"><span>.</span></span><span>acquisition_type)(</span> <span id="x1-155098r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â data</span><span id="textcolor5133"><span>.</span></span><span>x_train,</span> <span id="x1-155100r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â cfg</span><span id="textcolor5134"><span>.</span></span><span>n_samples_per_iter,</span> <span id="x1-155102r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â n_iter</span><span id="textcolor5135"><span>=</span></span><span>cfg</span><span id="textcolor5136"><span>.</span></span><span>n_iter,</span> <span id="x1-155104r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor5137"><span>=</span></span><span>model,</span> <span id="x1-155106r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-155108r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â added_indices</span><span id="textcolor5138"><span>.</span></span><span>append(indices_to_add)</span> <span id="x1-155110r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â data,</span><span>Â (iter_x,</span><span>Â iter_y)</span><span>Â </span><span id="textcolor5139"><span>=</span></span><span>Â update_ds(data,</span><span>Â indices_to_add)</span></code></pre>
</div></li>
<li><div id="x1-155112x3">
<p>We finally save the added images, compute the test accuracy, and save the results:</p>
<pre id="fancyvrb216" class="fancyvrb"><span id="x1-155119r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â save_images_and_labels_added(iter_dir,</span><span>Â iter_x,</span><span>Â iter_y)</span> <span id="x1-155121r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â divds</span><span>Â </span><span id="textcolor5140"><span>=</span></span><span>Â model(data</span><span id="textcolor5141"><span>.</span></span><span>x_test)</span> <span id="x1-155123r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â accuracy</span><span>Â </span><span id="textcolor5142"><span>=</span></span><span>Â get_accuracy(data</span><span id="textcolor5143"><span>.</span></span><span>y_test,</span><span>Â divds)</span> <span id="x1-155125r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â accuracies[i]</span><span>Â </span><span id="textcolor5144"><span>=</span></span><span>Â accuracy</span> <span id="x1-155127r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â save_results(accuracies,</span><span>Â added_indices,</span><span>Â model_dir)</span></code></pre>
</div></li>
</ol>
<p>In this loop, we defined a few small helper functions.<span id="dx1-155128"></span> First of all, we defined a callback for our model to save the model with the highest validation accuracy to our model directory:</p>
<pre id="fancyvrb217" class="fancyvrb"><span id="x1-155138r1"></span> 
<code><span id="textcolor5145"><span>def</span></span><span>Â </span><span id="textcolor5146"><span>get_callback</span></span><span>(model_dir:</span><span>Â Path):</span> <span id="x1-155140r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model_checkpoint_callback</span><span>Â </span><span id="textcolor5147"><span>=</span></span><span>Â tf</span><span id="textcolor5148"><span>.</span></span><span>keras</span><span id="textcolor5149"><span>.</span></span><span>callbacks</span><span id="textcolor5150"><span>.</span></span><span>ModelCheckpoint(</span> <span id="x1-155142r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5151"><span>str</span></span><span>(model_dir),</span> <span id="x1-155144r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â monitor</span><span id="textcolor5152"><span>=</span></span><span id="textcolor5153"><span>"val_accuracy"</span></span><span>,</span> <span id="x1-155146r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â verbose</span><span id="textcolor5154"><span>=</span></span><span id="textcolor5155"><span>0</span></span><span>,</span> <span id="x1-155148r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â save_best_only</span><span id="textcolor5156"><span>=</span></span><span id="textcolor5157"><span>True</span></span><span>,</span> <span id="x1-155150r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-155152r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5158"><span>return</span></span><span>Â model_checkpoint_callback</span></code></pre>
<p>We also defined a function to compute the accuracy of our test set:</p>
<pre id="fancyvrb218" class="fancyvrb"><span id="x1-155158r1"></span> 
<code><span id="textcolor5159"><span>def</span></span><span>Â </span><span id="textcolor5160"><span>get_accuracy</span></span><span>(y_test:</span><span>Â np</span><span id="textcolor5161"><span>.</span></span><span>ndarray,</span><span>Â divds:</span><span>Â np</span><span id="textcolor5162"><span>.</span></span><span>ndarray)</span><span>Â </span><span id="textcolor5163"><span>-</span><em>&gt;</em></span><span>Â </span><span id="textcolor5164"><span>float</span></span><span>:</span> <span id="x1-155160r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â acc</span><span>Â </span><span id="textcolor5165"><span>=</span></span><span>Â tf</span><span id="textcolor5166"><span>.</span></span><span>keras</span><span id="textcolor5167"><span>.</span></span><span>metrics</span><span id="textcolor5168"><span>.</span></span><span>CategoricalAccuracy()</span> <span id="x1-155162r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â acc</span><span id="textcolor5169"><span>.</span></span><span>update_state(divds,</span><span>Â y_test)</span> <span id="x1-155164r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5170"><span>return</span></span><span>Â acc</span><span id="textcolor5171"><span>.</span></span><span>result()</span><span id="textcolor5172"><span>.</span></span><span>numpy()</span><span>Â </span><span id="textcolor5173"><span>*</span></span><span>Â </span><span id="textcolor5174"><span>100</span></span></code></pre>
<p>And we defined two small functions to save the results per iteration:</p>
<pre id="fancyvrb219" class="fancyvrb"><span id="x1-155181r1"></span> 
<code><span id="textcolor5175"><span>def</span></span><span>Â </span><span id="textcolor5176"><span>save_images_and_labels_added</span></span><span>(</span> <span id="x1-155183r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â output_path:</span><span>Â Path,</span><span>Â iter_x:</span><span>Â np</span><span id="textcolor5177"><span>.</span></span><span>ndarray,</span><span>Â iter_y:</span><span>Â np</span><span id="textcolor5178"><span>.</span></span><span>ndarray</span> <span id="x1-155185r3"></span> </code>
<code><span>):</span> <span id="x1-155187r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span>Â </span><span id="textcolor5179"><span>=</span></span><span>Â pd</span><span id="textcolor5180"><span>.</span></span><span>DataFrame()</span> <span id="x1-155189r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df[</span><span id="textcolor5181"><span>"label"</span></span><span>]</span><span>Â </span><span id="textcolor5182"><span>=</span></span><span>Â np</span><span id="textcolor5183"><span>.</span></span><span>argmax(iter_y,</span><span>Â axis</span><span id="textcolor5184"><span>=</span></span><span id="textcolor5185"><span>1</span></span><span>)</span> <span id="x1-155191r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â iter_x_normalised</span><span>Â </span><span id="textcolor5186"><span>=</span></span><span>Â (np</span><span id="textcolor5187"><span>.</span></span><span>squeeze(iter_x,</span><span>Â axis</span><span id="textcolor5188"><span>=-</span></span><span id="textcolor5189"><span>1</span></span><span>)</span><span>Â </span><span id="textcolor5190"><span>*</span></span><span>Â </span><span id="textcolor5191"><span>255</span></span><span>)</span><span id="textcolor5192"><span>.</span></span><span>astype(np</span><span id="textcolor5193"><span>.</span></span><span>uint8)</span> <span id="x1-155193r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df[</span><span id="textcolor5194"><span>"image"</span></span><span>]</span><span>Â </span><span id="textcolor5195"><span>=</span></span><span>Â iter_x_normalised</span><span id="textcolor5196"><span>.</span></span><span>reshape(</span><span id="textcolor5197"><span>10</span></span><span>,</span><span>Â </span><span id="textcolor5198"><span>28</span></span><span id="textcolor5199"><span>*</span></span><span id="textcolor5200"><span>28</span></span><span>)</span><span id="textcolor5201"><span>.</span></span><span>tolist()</span> <span id="x1-155195r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span id="textcolor5202"><span>.</span></span><span>to_parquet(output_path</span><span>Â </span><span id="textcolor5203"><span>/</span></span><span>Â </span><span id="textcolor5204"><span>"added.parquet"</span></span><span>,</span><span>Â index</span><span id="textcolor5205"><span>=</span></span><span id="textcolor5206"><span>False</span></span><span>)</span> <span id="x1-155197r9"></span> </code>
<code><span id="x1-155199r10"></span></code>
<code><span id="textcolor5207"><span>def</span></span><span>Â </span><span id="textcolor5208"><span>save_results</span></span><span>(</span> <span id="x1-155201r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â accuracies:</span><span>Â Dict[</span><span id="textcolor5209"><span>int</span></span><span>,</span><span>Â </span><span id="textcolor5210"><span>float</span></span><span>],</span><span>Â added_indices:</span><span>Â List[</span><span id="textcolor5211"><span>int</span></span><span>],</span><span>Â model_dir:</span><span>Â Path</span> <span id="x1-155203r12"></span> </code>
<code><span>):</span> <span id="x1-155205r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span>Â </span><span id="textcolor5212"><span>=</span></span><span>Â pd</span><span id="textcolor5213"><span>.</span></span><span>DataFrame(accuracies</span><span id="textcolor5214"><span>.</span></span><span>items(),</span><span>Â columns</span><span id="textcolor5215"><span>=</span></span><span>[</span><span id="textcolor5216"><span>"i"</span></span><span>,</span><span>Â </span><span id="textcolor5217"><span>"accuracy"</span></span><span>])</span> <span id="x1-155207r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df[</span><span id="textcolor5218"><span>"added"</span></span><span>]</span><span>Â </span><span id="textcolor5219"><span>=</span></span><span>Â added_indices</span> <span id="x1-155209r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span id="textcolor5220"><span>.</span></span><span>to_parquet(</span><span id="textcolor5221"><span>f</span></span><span id="textcolor5222"><span>"</span></span><span id="textcolor5223"><span>{</span></span><span>model_dir</span><span id="textcolor5224"><span>}</span></span><span id="textcolor5225"><span>/results.parquet"</span></span><span>,</span><span>Â index</span><span id="textcolor5226"><span>=</span></span><span id="textcolor5227"><span>False</span></span><span>)</span></code></pre>
<p>Note that running the active learning loop takes quite a long time: for every iteration, we train and evaluate our model for 50 epochs, and then run through our pool set (the full training dataset minus the acquired samples) 100 times. When using a random acquisition function, we avoid the last step but still run our validation data through our model 50 times per iteration,<span id="dx1-155210"></span> just to make sure that we use the model with the best validation accuracy. This takes time, but picking the model with just the best <em>training</em> accuracy would be risky: our model sees the same few images many times during training and is therefore likely to overfit to the training data.</p>
</section>
<section id="step-6-inspecting-the-results" class="level4 likesubsubsectionHead" data-number="13.4.0.6">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.4.0.6"><span id="x1-1560004"></span>Step 6: Inspecting the results</h4>
<p>Now that we have our loop, we can inspect the results of this process.<span id="dx1-156001"></span> We will use <code>seaborn</code> and <code>matplotlib</code> to visualize our results:</p>
<pre id="fancyvrb220" class="fancyvrb"><span id="x1-156011r1"></span> 
<code><span id="textcolor5228"><span>import</span></span><span>Â </span><span id="textcolor5229"><span>seaborn</span></span><span>Â </span><span id="textcolor5230"><span>as</span></span><span>Â </span><span id="textcolor5231"><span>sns</span></span> <span id="x1-156013r2"></span> </code>
<code><span id="textcolor5232"><span>import</span></span><span>Â </span><span id="textcolor5233"><span>matplotlib.pyplot</span></span><span>Â </span><span id="textcolor5234"><span>as</span></span><span>Â </span><span id="textcolor5235"><span>plt</span></span> <span id="x1-156015r3"></span> </code>
<code><span id="textcolor5236"><span>import</span></span><span>Â </span><span id="textcolor5237"><span>pandas</span></span><span>Â </span><span id="textcolor5238"><span>as</span></span><span>Â </span><span id="textcolor5239"><span>pd</span></span> <span id="x1-156017r4"></span> </code>
<code><span id="textcolor5240"><span>import</span></span><span>Â </span><span id="textcolor5241"><span>numpy</span></span><span>Â </span><span id="textcolor5242"><span>as</span></span><span>Â </span><span id="textcolor5243"><span>np</span></span> <span id="x1-156019r5"></span> </code>
<code><span>sns</span><span id="textcolor5244"><span>.</span></span><span>set_style(</span><span id="textcolor5245"><span>"darkgrid"</span></span><span>)</span> <span id="x1-156021r6"></span> </code>
<code><span>sns</span><span id="textcolor5246"><span>.</span></span><span>set_context(</span><span id="textcolor5247"><span>"paper"</span></span><span>)</span></code></pre>
<p>The main result we are interested in is the test accuracy over time for both the models trained with a random acquisition function and the models trained with data acquired via knowledge uncertainty. To visualize this, we define a function that loads the results and then returns a plot that shows the accuracy per active learning iteration cycle:</p>
<pre id="fancyvrb221" class="fancyvrb"><span id="x1-156031r1"></span> 
<code><span id="textcolor5248"><span>def</span></span><span>Â </span><span id="textcolor5249"><span>plot</span></span><span>(uuid:</span><span>Â </span><span id="textcolor5250"><span>str</span></span><span>,</span><span>Â acquisition:</span><span>Â </span><span id="textcolor5251"><span>str</span></span><span>,</span><span>Â ax</span><span id="textcolor5252"><span>=</span></span><span id="textcolor5253"><span>None</span></span><span>):</span> <span id="x1-156033r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â acq_name</span><span>Â </span><span id="textcolor5254"><span>=</span></span><span>Â acquisition</span><span id="textcolor5255"><span>.</span></span><span>replace(</span><span id="textcolor5256"><span>"_"</span></span><span>,</span><span>Â </span><span id="textcolor5257"><span>"</span><span>Â "</span></span><span>)</span> <span id="x1-156035r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span>Â </span><span id="textcolor5258"><span>=</span></span><span>Â pd</span><span id="textcolor5259"><span>.</span></span><span>read_parquet(</span><span id="textcolor5260"><span>f</span></span><span id="textcolor5261"><span>"./models/</span></span><span id="textcolor5262"><span>{</span></span><span>acquisition</span><span id="textcolor5263"><span>}</span></span><span id="textcolor5264"><span>/</span></span><span id="textcolor5265"><span>{</span></span><span>uuid</span><span id="textcolor5266"><span>}</span></span><span id="textcolor5267"><span>/results.parquet"</span></span><span>)[:</span><span id="textcolor5268"><span>-</span></span><span id="textcolor5269"><span>1</span></span><span>]</span> <span id="x1-156037r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span>Â </span><span id="textcolor5270"><span>=</span></span><span>Â df</span><span id="textcolor5271"><span>.</span></span><span>rename(columns</span><span id="textcolor5272"><span>=</span></span><span>{</span><span id="textcolor5273"><span>"accuracy"</span></span><span>:</span><span>Â acq_name})</span> <span id="x1-156039r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â df[</span><span id="textcolor5274"><span>"n_samples"</span></span><span>]</span><span>Â </span><span id="textcolor5275"><span>=</span></span><span>Â df[</span><span id="textcolor5276"><span>"i"</span></span><span>]</span><span id="textcolor5277"><span>.</span></span><span>apply(</span><span id="textcolor5278"><span>lambda</span></span><span>Â x:</span><span>Â x</span><span id="textcolor5279"><span>*</span></span><span id="textcolor5280"><span>10</span></span><span>Â </span><span id="textcolor5281"><span>+</span></span><span>Â </span><span id="textcolor5282"><span>20</span></span><span>)</span> <span id="x1-156041r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5283"><span>return</span></span><span>Â df</span><span id="textcolor5284"><span>.</span></span><span>plot</span><span id="textcolor5285"><span>.</span></span><span>line(</span> <span id="x1-156043r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â x</span><span id="textcolor5286"><span>=</span></span><span id="textcolor5287"><span>"n_samples"</span></span><span>,</span><span>Â y</span><span id="textcolor5288"><span>=</span></span><span>acq_name,</span><span>Â style</span><span id="textcolor5289"><span>=</span></span><span id="textcolor5290"><span>'.-'</span></span><span>,</span><span>Â figsize</span><span id="textcolor5291"><span>=</span></span><span>(</span><span id="textcolor5292"><span>8</span></span><span>,</span><span id="textcolor5293"><span>5</span></span><span>),</span><span>Â ax</span><span id="textcolor5294"><span>=</span></span><span>ax</span> <span id="x1-156045r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
<p>We can then use this function to plot the results for both<span id="dx1-156046"></span> acquisition functions:</p>
<pre id="fancyvrb222" class="fancyvrb"><span id="x1-156057r1"></span> 
<code><span>ax</span><span>Â </span><span id="textcolor5295"><span>=</span></span><span>Â plot(</span><span id="textcolor5296"><span>"bc1adec5-bc34-44a6-a0eb-fa7cb67854e4"</span></span><span>,</span><span>Â </span><span id="textcolor5297"><span>"random"</span></span><span>)</span> <span id="x1-156059r2"></span> </code>
<code><span>ax</span><span>Â </span><span id="textcolor5298"><span>=</span></span><span>Â plot(</span> <span id="x1-156061r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5299"><span>"5c8d6001-a5fb-45d3-a7cb-2a8a46b93d18"</span></span><span>,</span><span>Â </span><span id="textcolor5300"><span>"knowledge_uncertainty"</span></span><span>,</span><span>Â ax</span><span id="textcolor5301"><span>=</span></span><span>ax</span> <span id="x1-156063r4"></span> </code>
<code><span>)</span> <span id="x1-156065r5"></span> </code>
<code><span>plt</span><span id="textcolor5302"><span>.</span></span><span>xticks(np</span><span id="textcolor5303"><span>.</span></span><span>arange(</span><span id="textcolor5304"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5305"><span>1050</span></span><span>,</span><span>Â </span><span id="textcolor5306"><span>50</span></span><span>))</span> <span id="x1-156067r6"></span> </code>
<code><span>plt</span><span id="textcolor5307"><span>.</span></span><span>yticks(np</span><span id="textcolor5308"><span>.</span></span><span>arange(</span><span id="textcolor5309"><span>54</span></span><span>,</span><span>Â </span><span id="textcolor5310"><span>102</span></span><span>,</span><span>Â </span><span id="textcolor5311"><span>2</span></span><span>))</span> <span id="x1-156069r7"></span> </code>
<code><span>plt</span><span id="textcolor5312"><span>.</span></span><span>ylabel(</span><span id="textcolor5313"><span>"Accuracy"</span></span><span>)</span> <span id="x1-156071r8"></span> </code>
<code><span>plt</span><span id="textcolor5314"><span>.</span></span><span>xlabel(</span><span id="textcolor5315"><span>"Number</span><span>Â of</span><span>Â acquired</span><span>Â samples"</span></span><span>)</span> <span id="x1-156073r9"></span> </code>
<code><span>plt</span><span id="textcolor5316"><span>.</span></span><span>show()</span></code></pre>
<p>This produces the following output:</p>
<div class="IMG---Figure">
<img src="../media/file172.png" alt="PIC"/> <span id="x1-156074r8"></span> <span id="x1-156075"></span></div>
<p class="IMG---Caption">FigureÂ 8.8: Active learning results 
</p>
<p><em>Figure</em> <a href="#x1-156074r8"><em>8.8</em></a> shows that acquiring samples via knowledge uncertainty starts to improve the modelâ€™s accuracy significantly after around 300 acquired samples. The final accuracy of this model is about two percentage points higher than the accuracy of the model trained on random samples. This might not look like a lot, but we can also look at the data in another way: how many samples were needed to achieve a particular accuracy? If we inspect the plot, we can see that the knowledge uncertainty line achieves an accuracy of 96% with 400 training samples. The model trained on random samples required at least 750 samples to achieve the same accuracy. Thatâ€™s almost double the amount of data for the same accuracy. This shows that active learning with the right acquisition function can be very useful, specifically in cases where compute resources are available, but labeling is expensive: with the right samples, we might be able to decrease our labeling cost by a factor of two to achieve the same accuracy.<span id="dx1-156076"></span></p>
<p>Because we saved the acquired samples for every iteration, we can also inspect the type of images selected by both models. To make our visualization easier to interpret, we will visualize the last five acquired images for every method for every label. To do this, we first define a function that returns the images per label for a set of model directories:</p>
<pre id="fancyvrb223" class="fancyvrb"><span id="x1-156091r1"></span> 
<code><span id="textcolor5317"><span>def</span></span><span>Â </span><span id="textcolor5318"><span>get_imgs_per_label</span></span><span>(model_dirs)</span><span>Â </span><span id="textcolor5319"><span>-</span><em>&gt;</em></span><span>Â Dict[</span><span id="textcolor5320"><span>int</span></span><span>,</span><span>Â np</span><span id="textcolor5321"><span>.</span></span><span>ndarray]:</span> <span id="x1-156093r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â imgs_per_label</span><span>Â </span><span id="textcolor5322"><span>=</span></span><span>Â {i:</span><span>Â []</span><span>Â </span><span id="textcolor5323"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor5324"><span>in</span></span><span>Â </span><span id="textcolor5325"><span>range</span></span><span>(</span><span id="textcolor5326"><span>10</span></span><span>)}</span> <span id="x1-156095r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5327"><span>for</span></span><span>Â model_dir</span><span>Â </span><span id="textcolor5328"><span>in</span></span><span>Â model_dirs:</span> <span id="x1-156097r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span>Â </span><span id="textcolor5329"><span>=</span></span><span>Â pd</span><span id="textcolor5330"><span>.</span></span><span>read_parquet(model_dir</span><span>Â </span><span id="textcolor5331"><span>/</span></span><span>Â </span><span id="textcolor5332"><span>"images_added.parquet"</span></span><span>)</span> <span id="x1-156099r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â df</span><span id="textcolor5333"><span>.</span></span><span>image</span><span>Â </span><span id="textcolor5334"><span>=</span></span><span>Â df</span><span id="textcolor5335"><span>.</span></span><span>image</span><span id="textcolor5336"><span>.</span></span><span>apply(</span> <span id="x1-156101r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5337"><span>lambda</span></span><span>Â x:</span><span>Â x</span><span id="textcolor5338"><span>.</span></span><span>reshape(</span><span id="textcolor5339"><span>28</span></span><span>,</span><span>Â </span><span id="textcolor5340"><span>28</span></span><span>)</span><span id="textcolor5341"><span>.</span></span><span>astype(np</span><span id="textcolor5342"><span>.</span></span><span>uint8)</span> <span id="x1-156103r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-156105r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5343"><span>for</span></span><span>Â label</span><span>Â </span><span id="textcolor5344"><span>in</span></span><span>Â df</span><span id="textcolor5345"><span>.</span></span><span>label</span><span id="textcolor5346"><span>.</span></span><span>unique():</span> <span id="x1-156107r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â dff</span><span>Â </span><span id="textcolor5347"><span>=</span></span><span>Â df[df</span><span id="textcolor5348"><span>.</span></span><span>label</span><span>Â </span><span id="textcolor5349"><span>==</span></span><span>Â label]</span> <span id="x1-156109r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5350"><span>if</span></span><span>Â </span><span id="textcolor5351"><span>len</span></span><span>(dff)</span><span>Â </span><span id="textcolor5352"><span>==</span></span><span>Â </span><span id="textcolor5353"><span>0</span></span><span>:</span> <span id="x1-156111r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5354"><span>continue</span></span> <span id="x1-156113r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â imgs_per_label[label]</span><span id="textcolor5355"><span>.</span></span><span>append(np</span><span id="textcolor5356"><span>.</span></span><span>hstack(dff</span><span id="textcolor5357"><span>.</span></span><span>image))</span> <span id="x1-156115r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5358"><span>return</span></span><span>Â imgs_per_label</span></code></pre>
<p>We then define a function that creates a <code>PILÂ Image</code> where we concatenate the images per label for a particular acquisition function:</p>
<pre id="fancyvrb224" class="fancyvrb"><span id="x1-156133r1"></span> 
<code><span id="textcolor5359"><span>from</span></span><span>Â </span><span id="textcolor5360"><span>PIL</span></span><span>Â </span><span id="textcolor5361"><span>import</span></span><span>Â Image</span> <span id="x1-156135r2"></span> </code>
<code><span id="textcolor5362"><span>from</span></span><span>Â </span><span id="textcolor5363"><span>pathlib</span></span><span>Â </span><span id="textcolor5364"><span>import</span></span><span>Â Path</span> <span id="x1-156137r3"></span> </code>
<code><span id="x1-156139r4"></span></code>
<code><span id="textcolor5365"><span>def</span></span><span>Â </span><span id="textcolor5366"><span>get_added_images</span></span><span>(</span> <span id="x1-156141r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â acquisition:</span><span>Â </span><span id="textcolor5367"><span>str</span></span><span>,</span><span>Â uuid:</span><span>Â </span><span id="textcolor5368"><span>str</span></span><span>,</span><span>Â n_iter:</span><span>Â </span><span id="textcolor5369"><span>int</span></span><span>Â </span><span id="textcolor5370"><span>=</span></span><span>Â </span><span id="textcolor5371"><span>5</span></span> <span id="x1-156143r6"></span> </code>
<code><span>)</span><span>Â </span><span id="textcolor5372"><span>-</span><em>&gt;</em></span><span>Â Image:</span> <span id="x1-156145r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â base_dir</span><span>Â </span><span id="textcolor5373"><span>=</span></span><span>Â Path(</span><span id="textcolor5374"><span>"./models"</span></span><span>)</span><span>Â </span><span id="textcolor5375"><span>/</span></span><span>Â acquisition</span><span>Â </span><span id="textcolor5376"><span>/</span></span><span>Â uuid</span> <span id="x1-156147r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model_dirs</span><span>Â </span><span id="textcolor5377"><span>=</span></span><span>Â </span><span id="textcolor5378"><span>filter</span></span><span>(</span><span id="textcolor5379"><span>lambda</span></span><span>Â x:</span><span>Â x</span><span id="textcolor5380"><span>.</span></span><span>is_dir(),</span><span>Â base_dir</span><span id="textcolor5381"><span>.</span></span><span>iterdir())</span> <span id="x1-156149r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model_dirs</span><span>Â </span><span id="textcolor5382"><span>=</span></span><span>Â </span><span id="textcolor5383"><span>sorted</span></span><span>(model_dirs,</span><span>Â key</span><span id="textcolor5384"><span>=</span></span><span id="textcolor5385"><span>lambda</span></span><span>Â x:</span><span>Â </span><span id="textcolor5386"><span>int</span></span><span>(x</span><span id="textcolor5387"><span>.</span></span><span>stem))</span> <span id="x1-156151r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â imgs_per_label</span><span>Â </span><span id="textcolor5388"><span>=</span></span><span>Â get_imgs_per_label(model_dirs)</span> <span id="x1-156153r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â imgs</span><span>Â </span><span id="textcolor5389"><span>=</span></span><span>Â []</span> <span id="x1-156155r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5390"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor5391"><span>in</span></span><span>Â </span><span id="textcolor5392"><span>range</span></span><span>(</span><span id="textcolor5393"><span>10</span></span><span>):</span> <span id="x1-156157r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â label_img</span><span>Â </span><span id="textcolor5394"><span>=</span></span><span>Â np</span><span id="textcolor5395"><span>.</span></span><span>hstack(imgs_per_label[i])[:,</span><span>Â </span><span id="textcolor5396"><span>-</span></span><span>(</span><span id="textcolor5397"><span>28</span></span><span>Â </span><span id="textcolor5398"><span>*</span></span><span>Â n_iter):]</span> <span id="x1-156159r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â imgs</span><span id="textcolor5399"><span>.</span></span><span>append(label_img)</span> <span id="x1-156161r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5400"><span>return</span></span><span>Â Image</span><span id="textcolor5401"><span>.</span></span><span>fromarray(np</span><span id="textcolor5402"><span>.</span></span><span>vstack(imgs))</span></code></pre>
<p>We can then call these functions,<span id="dx1-156162"></span> in our case with the following setup and <em>UUID</em>s:</p>
<pre id="fancyvrb225" class="fancyvrb"><span id="x1-156168r1"></span> 
<code><span>uuid</span><span>Â </span><span id="textcolor5403"><span>=</span></span><span>Â </span><span id="textcolor5404"><span>"bc1adec5-bc34-44a6-a0eb-fa7cb67854e4"</span></span> <span id="x1-156170r2"></span> </code>
<code><span>img_random</span><span>Â </span><span id="textcolor5405"><span>=</span></span><span>Â get_added_images(</span><span id="textcolor5406"><span>"random"</span></span><span>,</span><span>Â uuid)</span> <span id="x1-156172r3"></span> </code>
<code><span>uuid</span><span>Â </span><span id="textcolor5407"><span>=</span></span><span>Â </span><span id="textcolor5408"><span>"5c8d6001-a5fb-45d3-a7cb-2a8a46b93d18"</span></span> <span id="x1-156174r4"></span> </code>
<code><span>img_ku</span><span>Â </span><span id="textcolor5409"><span>=</span></span><span>Â get_added_images(</span><span id="textcolor5410"><span>"knowledge_uncertainty"</span></span><span>,</span><span>Â uuid)</span></code></pre>
<p>Letâ€™s compare the output.</p>
<div class="IMG---Figure">
<div class="IMG---Figure">
<img src="../media/file173.png" alt="PIC"/>
</div>
<div class="IMG---Figure">
<img src="../media/file174.png" alt="PIC"/>
</div>
<span id="x1-156175r9"></span> <span id="x1-156176"></span></div>
<p class="IMG---Caption">FigureÂ 8.9: Images randomly selected (left) and images selected via knowledge uncertainty with MC dropout (right). Every row shows the last five images selected for the label 
</p>
<p>We can see in <em>Figure</em> <a href="#x1-156175r9"><em>8.9</em></a> that the images selected by the knowledge uncertainty acquisition function are probably more difficult to classify compared to the randomly selected images.<span id="dx1-156177"></span> The uncertainty acquisition function selects quite a few unusual representations of the digits in the dataset. Because our acquisition function was able to select these images, the model was better able to understand the full distribution of the dataset, which resulted in better accuracy over time. <span id="x1-156178r239"></span></p>
</section>
</section>
<section id="using-uncertainty-estimates-for-smarter-reinforcement-learning" class="level2 sectionHead" data-number="13.5">
<h2 class="sectionHead" data-number="13.5" id="sigil_toc_id_96"><span class="titlemark">8.5 </span> <span id="x1-1570005"></span>Using uncertainty estimates for smarter reinforcement learning</h2>
<p><strong>Reinforcement learning</strong> aims to develop machine learning techniques capable of learning from their environment.<span id="dx1-157001"></span> Thereâ€™s a clue to the fundamental principle behind reinforcement learning in its name: the aim is to reinforce successful behaviour. Generally speaking, in reinforcement learning, we have an agent capable of executing a number of actions in an environment. Following these actions, the agent receives feedback from the environment, and this feedback is used to allow the agent to build a better understanding of which actions are more likely to lead to a positive outcome given the current state of the environment.</p>
<p>Formally, we can describe this using a set of states, <em>S</em>, a set of actions <em>A</em>, which map from a current state <em>s</em> to a new state <em>s</em><sup><span class="cmsy-8">â€²</span></sup>, and a reward function, <em>R</em>(<em>s,s</em><sup><span class="cmsy-8">â€²</span></sup>), describing the reward for the transition between the current state, <em>s</em>, and the new state, <em>s</em><sup><span class="cmsy-8">â€²</span></sup>. The set of states comprises a set of environment states, <em>S</em><sub><em>e</em></sub>, and a set of agent states, <em>S</em><sub><em>a</em></sub>, which together describe the state of the entire system.</p>
<p>We can think of this in terms of a game of Marco Polo, wherein call and response is used by one player in order to find another player.<span id="dx1-157002"></span> When the seeking player calls â€Marco,â€ the other player replies â€Polo,â€ giving the seeking player an estimate of their location based on the direction and amplitude of the sound. If we simplify this to consider it in terms of distance, a closer state would be one for which the distance reduces, such as <em>Î´</em> = <em>d</em> <span class="cmsy-10x-x-109">âˆ’ </span><em>d</em><sup><span class="cmsy-8">â€²</span></sup> <em>&gt;</em> 0, where <em>d</em> is the distance at state <em>s</em> and <em>d</em><sup><span class="cmsy-8">â€²</span></sup> is the distance for state <em>s</em><sup><span class="cmsy-8">â€²</span></sup>. Conversely, a further state would be one for which <em>Î´</em> = <em>d</em> <span class="cmsy-10x-x-109">âˆ’ </span><em>d</em><sup><span class="cmsy-8">â€²</span></sup> <em>&lt;</em> 0. Thus, for this example, we can use our <em>Î´</em> values as feedback for our model, making our reward function <em>Î´</em> = <em>R</em>(<em>s,s</em><sup><span class="cmsy-8">â€²</span></sup>) = <em>d</em> <span class="cmsy-10x-x-109">âˆ’ </span><em>d</em><sup><span class="cmsy-8">â€²</span></sup>.</p>
<div class="IMG---Figure">
<img src="../media/file175.jpg" class="graphics" alt="PIC"/> <span id="x1-157003r10"></span> <span id="x1-157004"></span></div>
<p class="IMG---Caption">FigureÂ 8.10: Illustration of a Marco Polo reinforcement learning scenario 
</p>
<p>Letâ€™s consider our agent as the seeking player and its target as the hiding player. At each step, our agent collects more information about its environment, enabling it to better model the relationship between its actions <em>A</em>(<em>s</em>) and the reward function <em>R</em>(<em>s,s</em><sup><span class="cmsy-8">â€²</span></sup>) (in other words, itâ€™s learning which general direction it needs to move in to get closer to the target). At each step, we need to predict the reward function given the set of possible actions at the current state, <em>A</em><sub><em>s</em></sub>, so that we can choose the action that is most likely to maximize this reward function. In this case, the set of actions could be a set of directions we can move in, for example: forward, back, left, and right.</p>
<p>Traditional reinforcement learning uses a method called <strong>Q Learning</strong> to learn the relationship between the state, action, and reward.<span id="dx1-157005"></span> Q Learning doesnâ€™t involve neural network models, and instead accumulates state, action, and reward information in a table â€“ the Q table â€“ which is then used to determine the action most likely to produce the highest reward given the current state. While Q Learning is powerful, it becomes computationally prohibitive for large numbers of states and actions. To address this, researchers introduced the concept of <strong>Deep Q Learning</strong><span id="dx1-157006"></span>, wherein the Q table is replaced by a neural network. Over a (usually large) number of iterations, the neural network learns which actions are likely to produce a higher reward given the current state.</p>
<p>To predict which action is likely to yield the highest reward value, we use a model trained on all historical actions, <em>A</em><sub><em>h</em></sub>, states <em>S</em><sub><em>h</em></sub>, and rewards, <em>R</em><sub><em>h</em></sub>. Our training input <em>X</em> comprises the actions <em>A</em><sub><em>h</em></sub> and states <em>S</em><sub><em>h</em></sub>, while our target output <em>y</em> comprises the reward values <em>R</em><sub><em>h</em></sub>. We can then use the model as part of a <strong>Model predictive Controller</strong>, or <strong>MPC</strong>, which will select the action depending<span id="dx1-157007"></span> on which action is associated with the highest predicted reward:</p>
<div class="math-display">
<img src="../media/file176.jpg" class="math-display" alt="anext = argmax yiâˆ€ai âˆˆ As "/>
</div>
<p>Here, <em>y</em><sub><em>i</em></sub> is the reward prediction produced by our model, <em>f</em>(<em>a</em><sub><em>i</em></sub><em>,s</em>), which maps the current state <em>s</em> and possible actions <em>a</em><sub><em>i</em></sub> <span class="cmsy-10x-x-109">âˆˆ </span><em>A</em><sub><em>s</em></sub> to reward values. However, before our model is of any use, weâ€™ll need to gather data to train on. Weâ€™ll accrue data over a number of episodes, wherein each episode comprises a set of actions taken by the agent until some termination criteria are met. The ideal termination criterion would be the agent finding the target, but we can set other criteria, such as the agent encountering an obstacle,<span id="dx1-157008"></span> or the agent exhausting a maximum number of actions. Because the model has no information to start off with, we use a greedy policy commonly used in reinforcement learning, called an <em>ğœ–greedy</em> policy,<span id="dx1-157009"></span> to allow the agent to start by randomly sampling from its environment. The idea here is that our agent will perform a random action with probability <em>ğœ–</em>, and will otherwise use model predictions to select the action. After each episode, we will decrease <em>ğœ–</em>, such that the agent will eventually be selecting actions based solely on the model. Letâ€™s put together a simple reinforcement learning example to see all of this in action.</p>
<section id="step-1-initializing-our-environment" class="level4 likesubsubsectionHead" data-number="13.5.0.1">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.0.1"><span id="x1-1580005"></span>Step 1: Initializing our environment</h4>
<p>Our reinforcement learning example will be centred<span id="dx1-158001"></span> around our environment: this defines the space in which everything happens. Weâ€™ll handle this with the <code>Environment</code> class. First, we set up our environment parameters:</p>
<pre id="fancyvrb226" class="fancyvrb"><span id="x1-158037r1"></span> 
<code><span id="textcolor5411"><span>import</span></span><span>Â </span><span id="textcolor5412"><span>numpy</span></span><span>Â </span><span id="textcolor5413"><span>as</span></span><span>Â </span><span id="textcolor5414"><span>np</span></span> <span id="x1-158039r2"></span> </code>
<code><span id="textcolor5415"><span>import</span></span><span>Â </span><span id="textcolor5416"><span>tensorflow</span></span><span>Â </span><span id="textcolor5417"><span>as</span></span><span>Â </span><span id="textcolor5418"><span>tf</span></span> <span id="x1-158041r3"></span> </code>
<code><span id="textcolor5419"><span>from</span></span><span>Â </span><span id="textcolor5420"><span>scipy.spatial.distance</span></span><span>Â </span><span id="textcolor5421"><span>import</span></span><span>Â euclidean</span> <span id="x1-158043r4"></span> </code>
<code><span id="textcolor5422"><span>from</span></span><span>Â </span><span id="textcolor5423"><span>tensorflow.keras</span></span><span>Â </span><span id="textcolor5424"><span>import</span></span><span>Â (</span> <span id="x1-158045r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â Model,</span> <span id="x1-158047r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â Sequential,</span> <span id="x1-158049r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â layers,</span> <span id="x1-158051r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â optimizers,</span> <span id="x1-158053r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â metrics,</span> <span id="x1-158055r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â losses,</span> <span id="x1-158057r11"></span> </code>
<code><span>)</span> <span id="x1-158059r12"></span> </code>
<code><span id="textcolor5425"><span>import</span></span><span>Â </span><span id="textcolor5426"><span>pandas</span></span><span>Â </span><span id="textcolor5427"><span>as</span></span><span>Â </span><span id="textcolor5428"><span>pd</span></span> <span id="x1-158061r13"></span> </code>
<code><span id="textcolor5429"><span>from</span></span><span>Â </span><span id="textcolor5430"><span>sklearn.preprocessing</span></span><span>Â </span><span id="textcolor5431"><span>import</span></span><span>Â StandardScaler</span> <span id="x1-158063r14"></span> </code>
<code><span id="textcolor5432"><span>import</span></span><span>Â </span><span id="textcolor5433"><span>copy</span></span> <span id="x1-158065r15"></span> </code>
<code><span id="x1-158067r16"></span></code>
<code><span id="x1-158069r17"></span></code>
<code><span id="textcolor5434"><span>class</span></span><span>Â </span><span id="textcolor5435"><span>Environment</span></span><span>:</span> <span id="x1-158071r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5436"><span>def</span></span><span>Â </span><span id="textcolor5437"><span>__init__</span></span><span>(</span><span id="textcolor5438"><span>self</span></span><span>,</span><span>Â env_size</span><span id="textcolor5439"><span>=</span></span><span id="textcolor5440"><span>8</span></span><span>,</span><span>Â max_steps</span><span id="textcolor5441"><span>=</span></span><span id="textcolor5442"><span>2000</span></span><span>):</span> <span id="x1-158073r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5443"><span>self</span></span><span id="textcolor5444"><span>.</span></span><span>env_size</span><span>Â </span><span id="textcolor5445"><span>=</span></span><span>Â env_size</span> <span id="x1-158075r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5446"><span>self</span></span><span id="textcolor5447"><span>.</span></span><span>max_steps</span><span>Â </span><span id="textcolor5448"><span>=</span></span><span>Â max_steps</span> <span id="x1-158077r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5449"><span>self</span></span><span id="textcolor5450"><span>.</span></span><span>agent_location</span><span>Â </span><span id="textcolor5451"><span>=</span></span><span>Â np</span><span id="textcolor5452"><span>.</span></span><span>zeros(</span><span id="textcolor5453"><span>2</span></span><span>)</span> <span id="x1-158079r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5454"><span>self</span></span><span id="textcolor5455"><span>.</span></span><span>target_location</span><span>Â </span><span id="textcolor5456"><span>=</span></span><span>Â np</span><span id="textcolor5457"><span>.</span></span><span>random</span><span id="textcolor5458"><span>.</span></span><span>randint(</span><span id="textcolor5459"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5460"><span>self</span></span><span id="textcolor5461"><span>.</span></span><span>env_size,</span><span>Â </span><span id="textcolor5462"><span>2</span></span><span>)</span> <span id="x1-158081r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5463"><span>self</span></span><span id="textcolor5464"><span>.</span></span><span>action_space</span><span>Â </span><span id="textcolor5465"><span>=</span></span><span>Â {</span> <span id="x1-158083r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5466"><span>0</span></span><span>:</span><span>Â np</span><span id="textcolor5467"><span>.</span></span><span>array([</span><span id="textcolor5468"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5469"><span>1</span></span><span>]),</span> <span id="x1-158085r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5470"><span>1</span></span><span>:</span><span>Â np</span><span id="textcolor5471"><span>.</span></span><span>array([</span><span id="textcolor5472"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5473"><span>-</span></span><span id="textcolor5474"><span>1</span></span><span>]),</span> <span id="x1-158087r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5475"><span>2</span></span><span>:</span><span>Â np</span><span id="textcolor5476"><span>.</span></span><span>array([</span><span id="textcolor5477"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor5478"><span>0</span></span><span>]),</span> <span id="x1-158089r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5479"><span>3</span></span><span>:</span><span>Â np</span><span id="textcolor5480"><span>.</span></span><span>array([</span><span id="textcolor5481"><span>-</span></span><span id="textcolor5482"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor5483"><span>0</span></span><span>]),</span> <span id="x1-158091r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-158093r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5484"><span>self</span></span><span id="textcolor5485"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor5486"><span>=</span></span><span>Â </span><span id="textcolor5487"><span>self</span></span><span id="textcolor5488"><span>.</span></span><span>compute_distance()</span> <span id="x1-158095r30"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5489"><span>self</span></span><span id="textcolor5490"><span>.</span></span><span>is_done</span><span>Â </span><span id="textcolor5491"><span>=</span></span><span>Â </span><span id="textcolor5492"><span>False</span></span> <span id="x1-158097r31"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5493"><span>self</span></span><span id="textcolor5494"><span>.</span></span><span>total_steps</span><span>Â </span><span id="textcolor5495"><span>=</span></span><span>Â </span><span id="textcolor5496"><span>0</span></span> <span id="x1-158099r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5497"><span>self</span></span><span id="textcolor5498"><span>.</span></span><span>ideal_steps</span><span>Â </span><span id="textcolor5499"><span>=</span></span><span>Â </span><span id="textcolor5500"><span>self</span></span><span id="textcolor5501"><span>.</span></span><span>calculate_ideal_steps()</span> <span id="x1-158101r33"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5502"><span>...</span></span></code></pre>
<p>Here, notice our environment size, denoted by <code>env_size</code>, which defines the number of
rows and columns in our environment â€“ in this case, weâ€™ll have an environment of size 8 <span class="cmsy-10x-x-109">Ã— </span>8, resulting in 64 locations (for simplicity, weâ€™ll stick with a square environment). Weâ€™ll also set a <code>max_steps</code> limit so that episodes donâ€™t go on too long while our agent is randomly selecting actions.</p>
<p>We also set the <code>agent_location</code> and <code>target_location</code> variables â€“ the agent always starts at point [0, 0], while the target location is randomly allocated.</p>
<p>Next, we create a dictionary to map an integer value to an action. Going from 0 to 3, these actions are: forward, backward, right, left. We also set the <code>delta</code> variable â€“ this is the initial distance between the agent and the target (weâ€™ll see how <code>compute_distance()</code> is implemented in a moment).</p>
<p>Finally, we initialize a few variables for tracking whether the termination criteria have been met (<code>is_done</code>), the total number of steps (<code>total_steps</code>), and the ideal number of steps (<code>ideal_steps</code>). The latter of these variables is the minimum number of steps required for the agent to get to the target from its starting position. Weâ€™ll use this to calculate the regret, which is a useful indicator of performance for reinforcement learning and optimization algorithms. To calculate this, weâ€™ll add the following two functions to our class:</p>
<pre id="fancyvrb227" class="fancyvrb"><span id="x1-158140r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5503"><span>...</span></span> <span id="x1-158142r2"></span> </code>
<code><span id="x1-158144r3"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5504"><span>def</span></span><span>Â </span><span id="textcolor5505"><span>calculate_ideal_action</span></span><span>(</span><span id="textcolor5506"><span>self</span></span><span>,</span><span>Â agent_location,</span><span>Â target_location):</span> <span id="x1-158146r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â min_delta</span><span>Â </span><span id="textcolor5507"><span>=</span></span><span>Â </span><span id="textcolor5508"><span>1e1000</span></span> <span id="x1-158148r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ideal_action</span><span>Â </span><span id="textcolor5509"><span>=</span></span><span>Â </span><span id="textcolor5510"><span>-</span></span><span id="textcolor5511"><span>1</span></span> <span id="x1-158150r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5512"><span>for</span></span><span>Â k</span><span>Â </span><span id="textcolor5513"><span>in</span></span><span>Â </span><span id="textcolor5514"><span>self</span></span><span id="textcolor5515"><span>.</span></span><span>action_space</span><span id="textcolor5516"><span>.</span></span><span>keys():</span> <span id="x1-158152r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â delta</span><span>Â </span><span id="textcolor5517"><span>=</span></span><span>Â euclidean(</span> <span id="x1-158154r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location</span><span>Â </span><span id="textcolor5518"><span>+</span></span><span>Â </span><span id="textcolor5519"><span>self</span></span><span id="textcolor5520"><span>.</span></span><span>action_space[k],</span><span>Â target_location</span> <span id="x1-158156r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-158158r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5521"><span>if</span></span><span>Â delta</span><span>Â </span><span id="textcolor5522"><em>&lt;</em><span>=</span></span><span>Â min_delta:</span> <span id="x1-158160r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â min_delta</span><span>Â </span><span id="textcolor5523"><span>=</span></span><span>Â delta</span> <span id="x1-158162r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ideal_action</span><span>Â </span><span id="textcolor5524"><span>=</span></span><span>Â k</span> <span id="x1-158164r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5525"><span>return</span></span><span>Â ideal_action,</span><span>Â min_delta</span> <span id="x1-158166r14"></span> </code>
<code><span id="x1-158168r15"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5526"><span>def</span></span><span>Â </span><span id="textcolor5527"><span>calculate_ideal_steps</span></span><span>(</span><span id="textcolor5528"><span>self</span></span><span>):</span> <span id="x1-158170r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location</span><span>Â </span><span id="textcolor5529"><span>=</span></span><span>Â copy</span><span id="textcolor5530"><span>.</span></span><span>deepcopy(</span><span id="textcolor5531"><span>self</span></span><span id="textcolor5532"><span>.</span></span><span>agent_location)</span> <span id="x1-158172r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â target_location</span><span>Â </span><span id="textcolor5533"><span>=</span></span><span>Â copy</span><span id="textcolor5534"><span>.</span></span><span>deepcopy(</span><span id="textcolor5535"><span>self</span></span><span id="textcolor5536"><span>.</span></span><span>target_location)</span> <span id="x1-158174r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â delta</span><span>Â </span><span id="textcolor5537"><span>=</span></span><span>Â </span><span id="textcolor5538"><span>1e1000</span></span> <span id="x1-158176r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â i</span><span>Â </span><span id="textcolor5539"><span>=</span></span><span>Â </span><span id="textcolor5540"><span>0</span></span> <span id="x1-158178r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5541"><span>while</span></span><span>Â delta</span><span>Â </span><span id="textcolor5542"><em>&gt;</em></span><span>Â </span><span id="textcolor5543"><span>0</span></span><span>:</span> <span id="x1-158180r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ideal_action,</span><span>Â delta</span><span>Â </span><span id="textcolor5544"><span>=</span></span><span>Â </span><span id="textcolor5545"><span>self</span></span><span id="textcolor5546"><span>.</span></span><span>calculate_ideal_action(</span> <span id="x1-158182r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location,</span><span>Â target_location</span> <span id="x1-158184r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-158186r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location</span><span>Â </span><span id="textcolor5547"><span>+=</span></span><span>Â </span><span id="textcolor5548"><span>self</span></span><span id="textcolor5549"><span>.</span></span><span>action_space[ideal_action]</span> <span id="x1-158188r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â i</span><span>Â </span><span id="textcolor5550"><span>+=</span></span><span>Â </span><span id="textcolor5551"><span>1</span></span> <span id="x1-158190r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5552"><span>return</span></span><span>Â i</span> <span id="x1-158192r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5553"><span>...</span></span></code></pre>
<p>Here, <code>calculate_ideal_steps()</code> will run until the distance (<code>delta</code>) between the agent and the target is zero. At each iteration, it uses <code>calculate_ideal_action()</code> to select the action that will move the agent closest to the target.<span id="dx1-158196"></span></p>
</section>
<section id="step-2-updating-the-state-of-our-environment" class="level4 likesubsubsectionHead" data-number="13.5.0.2">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.0.2"><span id="x1-1590005"></span>Step 2: Updating the state of our environment</h4>
<p>Now that weâ€™ve initialized our environment, we need to add one of the most crucial pieces of our class: the <code>update</code> method.<span id="dx1-159002"></span> This controls what happens to our environment when the agent takes a new action:</p>
<pre id="fancyvrb228" class="fancyvrb"><span id="x1-159018r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5554"><span>...</span></span> <span id="x1-159020r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5555"><span>def</span></span><span>Â </span><span id="textcolor5556"><span>update</span></span><span>(</span><span id="textcolor5557"><span>self</span></span><span>,</span><span>Â action_int):</span> <span id="x1-159022r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5558"><span>self</span></span><span id="textcolor5559"><span>.</span></span><span>agent_location</span><span>Â </span><span id="textcolor5560"><span>=</span></span><span>Â (</span> <span id="x1-159024r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5561"><span>self</span></span><span id="textcolor5562"><span>.</span></span><span>agent_location</span><span>Â </span><span id="textcolor5563"><span>+</span></span><span>Â </span><span id="textcolor5564"><span>self</span></span><span id="textcolor5565"><span>.</span></span><span>action_space[action_int]</span> <span id="x1-159026r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-159028r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5566"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â prevent</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â agent</span><span class="cmitt-10x-x-109">Â from</span><span class="cmitt-10x-x-109">Â moving</span><span class="cmitt-10x-x-109">Â outside</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â bounds</span><span class="cmitt-10x-x-109">Â of</span><span class="cmitt-10x-x-109">Â the</span><span class="cmitt-10x-x-109">Â environment</span></span> <span id="x1-159030r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5567"><span>self</span></span><span id="textcolor5568"><span>.</span></span><span>agent_location[</span><span id="textcolor5569"><span>self</span></span><span id="textcolor5570"><span>.</span></span><span>agent_location</span><span>Â </span><span id="textcolor5571"><em>&gt;</em></span><span>Â (</span><span id="textcolor5572"><span>self</span></span><span id="textcolor5573"><span>.</span></span><span>env_size</span><span>Â </span><span id="textcolor5574"><span>-</span></span><span>Â </span><span id="textcolor5575"><span>1</span></span><span>)]</span><span>Â </span><span id="textcolor5576"><span>=</span></span><span>Â (</span> <span id="x1-159032r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5577"><span>self</span></span><span id="textcolor5578"><span>.</span></span><span>env_size</span><span>Â </span><span id="textcolor5579"><span>-</span></span><span>Â </span><span id="textcolor5580"><span>1</span></span> <span id="x1-159034r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-159036r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5581"><span>self</span></span><span id="textcolor5582"><span>.</span></span><span>compute_reward()</span> <span id="x1-159038r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5583"><span>self</span></span><span id="textcolor5584"><span>.</span></span><span>total_steps</span><span>Â </span><span id="textcolor5585"><span>+=</span></span><span>Â </span><span id="textcolor5586"><span>1</span></span> <span id="x1-159040r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5587"><span>self</span></span><span id="textcolor5588"><span>.</span></span><span>is_done</span><span>Â </span><span id="textcolor5589"><span>=</span></span><span>Â (</span><span id="textcolor5590"><span>self</span></span><span id="textcolor5591"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor5592"><span>==</span></span><span>Â </span><span id="textcolor5593"><span>0</span></span><span>)</span><span>Â </span><span id="textcolor5594"><span>or</span></span><span>Â (</span><span id="textcolor5595"><span>self</span></span><span id="textcolor5596"><span>.</span></span><span>total_steps</span><span>Â </span><span id="textcolor5597"><em>&gt;</em><span>=</span></span><span>Â </span><span id="textcolor5598"><span>self</span></span><span id="textcolor5599"><span>.</span></span><span>max_steps)</span> <span id="x1-159042r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5600"><span>return</span></span><span>Â </span><span id="textcolor5601"><span>self</span></span><span id="textcolor5602"><span>.</span></span><span>reward</span> <span id="x1-159044r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5603"><span>...</span></span></code></pre>
<p>The method receives an action integer, and uses this to access the corresponding action in the <code>action_space</code> dictionary we defined earlier. It then updates the agent location. Because both the agent location and action are vectors, we can simply use vector addition to do this. Next, we check whether the agent has moved out of bounds of our environment â€“ if it has, we simply<span id="dx1-159046"></span> adjust its location so that it remains within our environment boundary.</p>
<p>The next line is another crucial piece of code: computing the reward with <code>compute_reward()</code> â€“ weâ€™ll take a look at this in just a moment. Once weâ€™ve computed the reward, we increment the <code>total_steps</code> counter, check our termination criteria, and return the reward value for the action.</p>
<p>We determine the reward using the following function. This will return a low reward (<span class="obeylines-h"><span class="verb"><code>1</code></span></span>) if the distance between the agent and the target increases, and a high reward (<span class="obeylines-h"><span class="verb"><code>10</code></span></span>) if the distance between the agent and target decreases:</p>
<pre id="fancyvrb229" class="fancyvrb"><span id="x1-159059r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5604"><span>...</span></span> <span id="x1-159061r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5605"><span>def</span></span><span>Â </span><span id="textcolor5606"><span>compute_reward</span></span><span>(</span><span id="textcolor5607"><span>self</span></span><span>):</span> <span id="x1-159063r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â d1</span><span>Â </span><span id="textcolor5608"><span>=</span></span><span>Â </span><span id="textcolor5609"><span>self</span></span><span id="textcolor5610"><span>.</span></span><span>delta</span> <span id="x1-159065r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5611"><span>self</span></span><span id="textcolor5612"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor5613"><span>=</span></span><span>Â </span><span id="textcolor5614"><span>self</span></span><span id="textcolor5615"><span>.</span></span><span>compute_distance()</span> <span id="x1-159067r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5616"><span>if</span></span><span>Â </span><span id="textcolor5617"><span>self</span></span><span id="textcolor5618"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor5619"><em>&lt;</em></span><span>Â d1:</span> <span id="x1-159069r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5620"><span>self</span></span><span id="textcolor5621"><span>.</span></span><span>reward</span><span>Â </span><span id="textcolor5622"><span>=</span></span><span>Â </span><span id="textcolor5623"><span>10</span></span> <span id="x1-159071r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5624"><span>else</span></span><span>:</span> <span id="x1-159073r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5625"><span>self</span></span><span id="textcolor5626"><span>.</span></span><span>reward</span><span>Â </span><span id="textcolor5627"><span>=</span></span><span>Â </span><span id="textcolor5628"><span>1</span></span> <span id="x1-159075r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5629"><span>...</span></span></code></pre>
<p>This uses the <code>compute_distance()</code> function, which calculates the Euclidean distance between the agent and the target:</p>
<pre id="fancyvrb230" class="fancyvrb"><span id="x1-159082r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5630"><span>...</span></span> <span id="x1-159084r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5631"><span>def</span></span><span>Â </span><span id="textcolor5632"><span>compute_distance</span></span><span>(</span><span id="textcolor5633"><span>self</span></span><span>):</span> <span id="x1-159086r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5634"><span>return</span></span><span>Â euclidean(</span><span id="textcolor5635"><span>self</span></span><span id="textcolor5636"><span>.</span></span><span>agent_location,</span><span>Â </span><span id="textcolor5637"><span>self</span></span><span id="textcolor5638"><span>.</span></span><span>target_location)</span> <span id="x1-159088r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5639"><span>...</span></span></code></pre>
<p>Lastly, we need a function to allow us to fetch the state of the environment,<span id="dx1-159089"></span> so that we can associate this with the reward values. We define this as follows:</p>
<pre id="fancyvrb231" class="fancyvrb"><span id="x1-159095r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5640"><span>...</span></span> <span id="x1-159097r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5641"><span>def</span></span><span>Â </span><span id="textcolor5642"><span>get_state</span></span><span>(</span><span id="textcolor5643"><span>self</span></span><span>):</span> <span id="x1-159099r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5644"><span>return</span></span><span>Â np</span><span id="textcolor5645"><span>.</span></span><span>concatenate([</span><span id="textcolor5646"><span>self</span></span><span id="textcolor5647"><span>.</span></span><span>agent_location,</span><span>Â </span><span id="textcolor5648"><span>self</span></span><span id="textcolor5649"><span>.</span></span><span>target_location])</span> <span id="x1-159101r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5650"><span>...</span></span></code></pre>
</section>
<section id="step-3-defining-our-model" class="level4 likesubsubsectionHead" data-number="13.5.0.3">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.0.3"><span id="x1-1600005"></span>Step 3: Defining our model</h4>
<p>Now that weâ€™ve set up our environment, weâ€™ll create a model class.<span id="dx1-160001"></span> This class will handle model training and inference, as well as selecting the best action according to the modelâ€™s predictions. As always, we start with the <code>__init__()</code> method:</p>
<pre id="fancyvrb232" class="fancyvrb"><span id="x1-160023r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5652"><span>class</span></span><span>Â </span><span id="textcolor5653"><span>RLModel</span></span><span>:</span> <span id="x1-160025r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5654"><span>def</span></span><span>Â </span><span id="textcolor5655"><span>__init__</span></span><span>(</span><span id="textcolor5656"><span>self</span></span><span>,</span><span>Â state_size,</span><span>Â n_actions,</span><span>Â num_epochs</span><span id="textcolor5657"><span>=</span></span><span id="textcolor5658"><span>500</span></span><span>):</span> <span id="x1-160027r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5659"><span>self</span></span><span id="textcolor5660"><span>.</span></span><span>state_size</span><span>Â </span><span id="textcolor5661"><span>=</span></span><span>Â state_size</span> <span id="x1-160029r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5662"><span>self</span></span><span id="textcolor5663"><span>.</span></span><span>n_actions</span><span>Â </span><span id="textcolor5664"><span>=</span></span><span>Â n_actions</span> <span id="x1-160031r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5665"><span>self</span></span><span id="textcolor5666"><span>.</span></span><span>num_epochs</span><span>Â </span><span id="textcolor5667"><span>=</span></span><span>Â </span><span id="textcolor5668"><span>200</span></span> <span id="x1-160033r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5669"><span>self</span></span><span id="textcolor5670"><span>.</span></span><span>model</span><span>Â </span><span id="textcolor5671"><span>=</span></span><span>Â Sequential()</span> <span id="x1-160035r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5672"><span>self</span></span><span id="textcolor5673"><span>.</span></span><span>model</span><span id="textcolor5674"><span>.</span></span><span>add(</span> <span id="x1-160037r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor5675"><span>.</span></span><span>Dense(</span> <span id="x1-160039r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5676"><span>20</span></span><span>,</span><span>Â input_dim</span><span id="textcolor5677"><span>=</span></span><span id="textcolor5678"><span>self</span></span><span id="textcolor5679"><span>.</span></span><span>state_size,</span><span>Â activation</span><span id="textcolor5680"><span>=</span></span><span id="textcolor5681"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor5682"><span>=</span></span><span id="textcolor5683"><span>"layer_1"</span></span> <span id="x1-160041r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-160043r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-160045r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5684"><span>self</span></span><span id="textcolor5685"><span>.</span></span><span>model</span><span id="textcolor5686"><span>.</span></span><span>add(layers</span><span id="textcolor5687"><span>.</span></span><span>Dense(</span><span id="textcolor5688"><span>8</span></span><span>,</span><span>Â activation</span><span id="textcolor5689"><span>=</span></span><span id="textcolor5690"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor5691"><span>=</span></span><span id="textcolor5692"><span>"layer_2"</span></span><span>))</span> <span id="x1-160047r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5693"><span>self</span></span><span id="textcolor5694"><span>.</span></span><span>model</span><span id="textcolor5695"><span>.</span></span><span>add(layers</span><span id="textcolor5696"><span>.</span></span><span>Dense(</span><span id="textcolor5697"><span>1</span></span><span>,</span><span>Â activation</span><span id="textcolor5698"><span>=</span></span><span id="textcolor5699"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor5700"><span>=</span></span><span id="textcolor5701"><span>"layer_3"</span></span><span>))</span> <span id="x1-160049r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5702"><span>self</span></span><span id="textcolor5703"><span>.</span></span><span>model</span><span id="textcolor5704"><span>.</span></span><span>compile(</span> <span id="x1-160051r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â optimizer</span><span id="textcolor5705"><span>=</span></span><span>optimizers</span><span id="textcolor5706"><span>.</span></span><span>Adam(),</span> <span id="x1-160053r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor5707"><span>=</span></span><span>losses</span><span id="textcolor5708"><span>.</span></span><span>Huber(),</span> <span id="x1-160055r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor5709"><span>=</span></span><span>[metrics</span><span id="textcolor5710"><span>.</span></span><span>RootMeanSquaredError()],</span> <span id="x1-160057r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-160059r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5711"><span>...</span></span></code></pre>
<p>Here, we pass a few variables related to our environment, such as the state size and number of actions. The code relating to the model definition should be familiar â€“ weâ€™re simply instantiating a neural network using Keras. One point to note is that weâ€™re using the Huber loss here, instead of something more common such as the mean squared error. This is a common choice in robust regression tasks and in reinforcement learning. The reason for this is that the Huber loss dynamically switches between mean squared error and mean absolute error. The former is very good at penalizing small errors, while the latter is more robust to outliers. Through the Huber loss, we arrive at a loss function that is both robust to outliers and penalizes small errors. <span id="dx1-160060"></span></p>
<p>This is particularly important in reinforcement learning because of the exploratory nature of the algorithms: we will often encounter some examples that are very exploratory, deviating significantly from the rest of the data, and thus causing large errors during training.</p>
<p>With our class initialization out of the way, we move on to our <code>fit()</code> and <code>predict()</code> functions:</p>
<pre id="fancyvrb233" class="fancyvrb"><span id="x1-160085r1"></span> 
<code><span id="textcolor5712"><span>...</span></span> <span id="x1-160087r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5713"><span>def</span></span><span>Â </span><span id="textcolor5714"><span>fit</span></span><span>(</span><span id="textcolor5715"><span>self</span></span><span>,</span><span>Â X_train,</span><span>Â y_train,</span><span>Â batch_size</span><span id="textcolor5716"><span>=</span></span><span id="textcolor5717"><span>16</span></span><span>):</span> <span id="x1-160089r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5718"><span>self</span></span><span id="textcolor5719"><span>.</span></span><span>scaler</span><span>Â </span><span id="textcolor5720"><span>=</span></span><span>Â StandardScaler()</span> <span id="x1-160091r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X_train</span><span>Â </span><span id="textcolor5721"><span>=</span></span><span>Â </span><span id="textcolor5722"><span>self</span></span><span id="textcolor5723"><span>.</span></span><span>scaler</span><span id="textcolor5724"><span>.</span></span><span>fit_transform(X_train)</span> <span id="x1-160093r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5725"><span>self</span></span><span id="textcolor5726"><span>.</span></span><span>model</span><span id="textcolor5727"><span>.</span></span><span>fit(</span> <span id="x1-160095r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X_train,</span> <span id="x1-160097r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â y_train,</span> <span id="x1-160099r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epochs</span><span id="textcolor5728"><span>=</span></span><span id="textcolor5729"><span>self</span></span><span id="textcolor5730"><span>.</span></span><span>num_epochs,</span> <span id="x1-160101r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â verbose</span><span id="textcolor5731"><span>=</span></span><span id="textcolor5732"><span>0</span></span><span>,</span> <span id="x1-160103r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â batch_size</span><span id="textcolor5733"><span>=</span></span><span>batch_size,</span> <span id="x1-160105r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-160107r12"></span> </code>
<code><span id="x1-160109r13"></span></code>
<code><span id="x1-160111r14"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5734"><span>def</span></span><span>Â </span><span id="textcolor5735"><span>predict</span></span><span>(</span><span id="textcolor5736"><span>self</span></span><span>,</span><span>Â state):</span> <span id="x1-160113r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards</span><span>Â </span><span id="textcolor5737"><span>=</span></span><span>Â []</span> <span id="x1-160115r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X</span><span>Â </span><span id="textcolor5738"><span>=</span></span><span>Â np</span><span id="textcolor5739"><span>.</span></span><span>zeros((</span><span id="textcolor5740"><span>self</span></span><span id="textcolor5741"><span>.</span></span><span>n_actions,</span><span>Â </span><span id="textcolor5742"><span>self</span></span><span id="textcolor5743"><span>.</span></span><span>state_size))</span> <span id="x1-160117r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5744"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor5745"><span>in</span></span><span>Â </span><span id="textcolor5746"><span>range</span></span><span>(</span><span id="textcolor5747"><span>self</span></span><span id="textcolor5748"><span>.</span></span><span>n_actions):</span> <span id="x1-160119r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X[i]</span><span>Â </span><span id="textcolor5749"><span>=</span></span><span>Â np</span><span id="textcolor5750"><span>.</span></span><span>concatenate([state,</span><span>Â [i]])</span> <span id="x1-160121r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X</span><span>Â </span><span id="textcolor5751"><span>=</span></span><span>Â </span><span id="textcolor5752"><span>self</span></span><span id="textcolor5753"><span>.</span></span><span>scaler</span><span id="textcolor5754"><span>.</span></span><span>transform(X)</span> <span id="x1-160123r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards</span><span>Â </span><span id="textcolor5755"><span>=</span></span><span>Â </span><span id="textcolor5756"><span>self</span></span><span id="textcolor5757"><span>.</span></span><span>model</span><span id="textcolor5758"><span>.</span></span><span>predict(X)</span> <span id="x1-160125r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5759"><span>return</span></span><span>Â np</span><span id="textcolor5760"><span>.</span></span><span>argmax(rewards)</span></code></pre>
<p>The <code>fit()</code> function should look very familiar â€“ weâ€™re just scaling our inputs before fitting our Keras model. The <code>predict()</code> function has a little more going on. Because we need predictions for each of our possible actions (forward, backward, right, left), we need to generate inputs for these. We do so by concatenating the integer value associated with the action to the state, producing our complete state-action vector as we see on line 11. Doing this for all actions results in our input matrix, <em>X</em>, for which each row is associated with a specific action. We then scale <em>X</em> and run inference on this to obtain our predicted reward values. To select an action, we simply use <code>np.argmax()</code> to obtain the index associated with the highest predicted reward.</p>
</section>
<section id="step-4-running-our-reinforcement-learning" class="level4 likesubsubsectionHead" data-number="13.5.0.4">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.0.4"><span id="x1-1610005"></span>Step 4: Running our reinforcement learning</h4>
<p>Now that weâ€™ve defined our <code>Environment</code> and <code>RLModel</code> classes, weâ€™re ready to do some reinforcement learning!<span id="dx1-161003"></span> Letâ€™s first set up some important variables and instantiate our model:</p>
<pre id="fancyvrb234" class="fancyvrb"><span id="x1-161015r1"></span> 
<code><span>env_size</span><span>Â </span><span id="textcolor5762"><span>=</span></span><span>Â </span><span id="textcolor5763"><span>8</span></span> <span id="x1-161017r2"></span> </code>
<code><span>state_size</span><span>Â </span><span id="textcolor5764"><span>=</span></span><span>Â </span><span id="textcolor5765"><span>5</span></span> <span id="x1-161019r3"></span> </code>
<code><span>n_actions</span><span>Â </span><span id="textcolor5766"><span>=</span></span><span>Â </span><span id="textcolor5767"><span>4</span></span> <span id="x1-161021r4"></span> </code>
<code><span>epsilon</span><span>Â </span><span id="textcolor5768"><span>=</span></span><span>Â </span><span id="textcolor5769"><span>1.0</span></span> <span id="x1-161023r5"></span> </code>
<code><span>history</span><span>Â </span><span id="textcolor5770"><span>=</span></span><span>Â {</span><span id="textcolor5771"><span>"state"</span></span><span>:</span><span>Â [],</span><span>Â </span><span id="textcolor5772"><span>"reward"</span></span><span>:</span><span>Â []}</span> <span id="x1-161025r6"></span> </code>
<code><span>n_samples</span><span>Â </span><span id="textcolor5773"><span>=</span></span><span>Â </span><span id="textcolor5774"><span>1000</span></span> <span id="x1-161027r7"></span> </code>
<code><span>max_steps</span><span>Â </span><span id="textcolor5775"><span>=</span></span><span>Â </span><span id="textcolor5776"><span>500</span></span> <span id="x1-161029r8"></span> </code>
<code><span>regrets</span><span>Â </span><span id="textcolor5777"><span>=</span></span><span>Â []</span> <span id="x1-161031r9"></span> </code>
<code><span id="x1-161033r10"></span></code>
<code><span>model</span><span>Â </span><span id="textcolor5778"><span>=</span></span><span>Â RLModel(state_size,</span><span>Â n_actions)</span></code></pre>
<p>Most of these should be familiar by now, but weâ€™ll go over a few that weâ€™ve not yet covered. The <code>history</code> dictionary is where weâ€™ll store our state and reward information as we progress through each step in each episode. Weâ€™ll then use this information to train our model. Another unfamiliar variable here is <code>n_samples</code> â€“ weâ€™re setting this because, rather than using all available data each time we train our model, weâ€™ll sample 1,000 data points from our data. This helps to avoid our training time exploding as we accrue more and more data. The last new variable here is <code>regrets</code>. This list will store our regret values for each episode. In our case, regret is defined simply as the difference between the number of steps taken by the model and the minimum number of steps required for the agent to reach the target:</p>
<div class="math-display">
<img src="../media/file177.jpg" class="math-display" alt="regret = steps âˆ’ steps model ideal "/>
</div>
<p>As such, regret is zero <em>â‡”</em> <em>steps</em><sub><em>model</em></sub> == <em>steps</em><sub><em>ideal</em></sub>. Regret is useful for measuring performance as our model learns, as weâ€™ll see in a moment. All thatâ€™s left is the main loop of our reinforcement learning process:</p>
<pre id="fancyvrb235" class="fancyvrb"><span id="x1-161061r1"></span> 
<code><span id="textcolor5779"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor5780"><span>in</span></span><span>Â </span><span id="textcolor5781"><span>range</span></span><span>(</span><span id="textcolor5782"><span>100</span></span><span>):</span> <span id="x1-161063r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â env</span><span>Â </span><span id="textcolor5783"><span>=</span></span><span>Â Environment(env_size,</span><span>Â max_steps</span><span id="textcolor5784"><span>=</span></span><span>max_steps)</span> <span id="x1-161065r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5785"><span>while</span></span><span>Â </span><span id="textcolor5786"><span>not</span></span><span>Â env</span><span id="textcolor5787"><span>.</span></span><span>is_done:</span> <span id="x1-161067r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â state</span><span>Â </span><span id="textcolor5788"><span>=</span></span><span>Â env</span><span id="textcolor5789"><span>.</span></span><span>get_state()</span> <span id="x1-161069r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5790"><span>if</span></span><span>Â np</span><span id="textcolor5791"><span>.</span></span><span>random</span><span id="textcolor5792"><span>.</span></span><span>rand()</span><span>Â </span><span id="textcolor5793"><em>&lt;</em></span><span>Â epsilon:</span> <span id="x1-161071r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â action</span><span>Â </span><span id="textcolor5794"><span>=</span></span><span>Â np</span><span id="textcolor5795"><span>.</span></span><span>random</span><span id="textcolor5796"><span>.</span></span><span>randint(n_actions)</span> <span id="x1-161073r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5797"><span>else</span></span><span>:</span> <span id="x1-161075r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â action</span><span>Â </span><span id="textcolor5798"><span>=</span></span><span>Â model</span><span id="textcolor5799"><span>.</span></span><span>predict(state)</span> <span id="x1-161077r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â reward</span><span>Â </span><span id="textcolor5800"><span>=</span></span><span>Â env</span><span id="textcolor5801"><span>.</span></span><span>update(action)</span> <span id="x1-161079r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â history[</span><span id="textcolor5802"><span>"state"</span></span><span>]</span><span id="textcolor5803"><span>.</span></span><span>append(np</span><span id="textcolor5804"><span>.</span></span><span>concatenate([state,</span><span>Â [action]]))</span> <span id="x1-161081r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â history[</span><span id="textcolor5805"><span>"reward"</span></span><span>]</span><span id="textcolor5806"><span>.</span></span><span>append(reward)</span> <span id="x1-161083r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5807"><span>print</span></span><span>(</span> <span id="x1-161085r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5808"><span>f</span></span><span id="textcolor5809"><span>"Completed</span><span>Â episode</span><span>Â </span></span><span id="textcolor5810"><span>{</span></span><span>i</span><span id="textcolor5811"><span>}</span></span><span id="textcolor5812"><span>Â in</span><span>Â </span></span><span id="textcolor5813"><span>{</span></span><span>env</span><span id="textcolor5814"><span>.</span></span><span>total_steps</span><span id="textcolor5815"><span>}</span></span><span id="textcolor5816"><span>Â steps."</span></span> <span id="x1-161087r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5817"><span>f</span></span><span id="textcolor5818"><span>"Ideal</span><span>Â steps:</span><span>Â </span></span><span id="textcolor5819"><span>{</span></span><span>env</span><span id="textcolor5820"><span>.</span></span><span>ideal_steps</span><span id="textcolor5821"><span>}</span></span><span id="textcolor5822"><span>."</span></span> <span id="x1-161089r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5823"><span>f</span></span><span id="textcolor5824"><span>"Epsilon:</span><span>Â </span></span><span id="textcolor5825"><span>{</span></span><span>epsilon</span><span id="textcolor5826"><span>}</span></span><span id="textcolor5827"><span>"</span></span> <span id="x1-161091r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-161093r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â regrets</span><span id="textcolor5828"><span>.</span></span><span>append(np</span><span id="textcolor5829"><span>.</span></span><span>abs(env</span><span id="textcolor5830"><span>.</span></span><span>total_steps</span><span id="textcolor5831"><span>-</span></span><span>env</span><span id="textcolor5832"><span>.</span></span><span>ideal_steps))</span> <span id="x1-161095r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â idxs</span><span>Â </span><span id="textcolor5833"><span>=</span></span><span>Â np</span><span id="textcolor5834"><span>.</span></span><span>random</span><span id="textcolor5835"><span>.</span></span><span>choice(</span><span id="textcolor5836"><span>len</span></span><span>(history[</span><span id="textcolor5837"><span>"state"</span></span><span>]),</span><span>Â n_samples)</span> <span id="x1-161097r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor5838"><span>.</span></span><span>fit(</span> <span id="x1-161099r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor5839"><span>.</span></span><span>array(history[</span><span id="textcolor5840"><span>"state"</span></span><span>])[idxs],</span> <span id="x1-161101r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor5841"><span>.</span></span><span>array(history[</span><span id="textcolor5842"><span>"reward"</span></span><span>])[idxs]</span> <span id="x1-161103r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-161105r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â epsilon</span><span id="textcolor5843"><span>-=</span></span><span>epsilon</span><span id="textcolor5844"><span>/</span></span><span id="textcolor5845"><span>10</span></span></code></pre>
<p>Here, we have our reinforcement learning process run from 100 episodes, reinitializing the environment each time. As we can see from the internal <code>while</code> loop, we will continue iterating â€“ updating our agent and measuring our reward â€“ until one of the termination criteria is met (either the agent reaches the target, or we run for the maximum allowed number of iterations). <span id="dx1-161107"></span></p>
<p>After each episode, a <span class="obeylines-h"><span class="verb"><code>print</code></span></span> statement lets us know that the episode completed without error, and tells us how our agent did compared to the ideal number of steps. We then calculate the regret and append this to our <code>regrets</code> list, sample from our data in <code>history</code> and fit our model on the sampled data. Lastly, we finish each iteration of the outer loop by reducing epsilon.</p>
<p>After running this, we can additionally plot our regret values to see how we did:</p>
<pre id="fancyvrb236" class="fancyvrb"><span id="x1-161119r1"></span> 
<code><span id="textcolor5847"><span>import</span></span><span>Â </span><span id="textcolor5848"><span>matplotlib.pyplot</span></span><span>Â </span><span id="textcolor5849"><span>as</span></span><span>Â </span><span id="textcolor5850"><span>plt</span></span> <span id="x1-161121r2"></span> </code>
<code><span id="textcolor5851"><span>import</span></span><span>Â </span><span id="textcolor5852"><span>seaborn</span></span><span>Â </span><span id="textcolor5853"><span>as</span></span><span>Â </span><span id="textcolor5854"><span>sns</span></span> <span id="x1-161123r3"></span> </code>
<code><span id="x1-161125r4"></span></code>
<code><span>df_plot</span><span>Â </span><span id="textcolor5855"><span>=</span></span><span>Â pd</span><span id="textcolor5856"><span>.</span></span><span>DataFrame({</span><span id="textcolor5857"><span>"regret"</span></span><span>:</span><span>Â regrets,</span><span>Â </span><span id="textcolor5858"><span>"episode"</span></span><span>:</span><span>Â np</span><span id="textcolor5859"><span>.</span></span><span>arange(</span><span id="textcolor5860"><span>len</span></span><span>(regrets))})</span> <span id="x1-161127r5"></span> </code>
<code><span>sns</span><span id="textcolor5861"><span>.</span></span><span>lineplot(x</span><span id="textcolor5862"><span>=</span></span><span id="textcolor5863"><span>"episode"</span></span><span>,</span><span>Â y</span><span id="textcolor5864"><span>=</span></span><span id="textcolor5865"><span>"regret"</span></span><span>,</span><span>Â data</span><span id="textcolor5866"><span>=</span></span><span>df_plot)</span> <span id="x1-161129r6"></span> </code>
<code><span>fig</span><span>Â </span><span id="textcolor5867"><span>=</span></span><span>Â plt</span><span id="textcolor5868"><span>.</span></span><span>gcf()</span> <span id="x1-161131r7"></span> </code>
<code><span>fig</span><span id="textcolor5869"><span>.</span></span><span>set_size_inches(</span><span id="textcolor5870"><span>5</span></span><span>,</span><span>Â </span><span id="textcolor5871"><span>10</span></span><span>)</span> <span id="x1-161133r8"></span> </code>
<code><span>plt</span><span id="textcolor5872"><span>.</span></span><span>show()</span></code></pre>
<p>This produces the following plot, showing how our model did over the 100 episodes:</p>
<div class="IMG---Figure">
<img src="../media/file178.png" alt="PIC"/> <span id="x1-161134r11"></span> <span id="x1-161135"></span></div>
<p class="IMG---Caption">FigureÂ 8.11: Plot of regret values following 100 episodes of reinforcement learning 
</p>
<p>As we can see here, it did poorly to begin with, but the model quickly learned to predict reward values, allowing it to predict optimal actions, and reducing regret to 0.</p>
<p>So far, things are pretty simple. In fact, you may be wondering why we need a model at all â€“ why not just calculate the distance between the target and the proposed positions, and select an action accordingly? Well, firstly, the aim of reinforcement learning is for an agent to discover how to interact in a given setting without any prior knowledge â€“ so while our agent can execute actions, it has no concept of distance. This is something that is learned through interacting with the environment. Secondly, it may not be that simple: what if there are obstacles in the environment? In this case, our agent needs to be more intelligent than simply moving toward the sound.</p>
<p>While this is just an illustrative example, real-world applications of reinforcement learning involve scenarios for which we have very limited knowledge, and thus designing an agent that can explore its environment and learn how to interact optimally allows us to develop models for applications for which supervised methods arenâ€™t an option.</p>
<p>Another factor to consider in real-world scenarios is risk: we want our agent to make <em>sensible</em> decisions, not just decisions that maximize the reward: we need it to build some understanding of the risk/reward trade-off. This is where uncertainty estimates come in. <span id="x1-161136r230"></span></p>
</section>
<section id="navigating-obstacles-with-uncertainty" class="level3 subsectionHead" data-number="13.5.1">
<h3 class="subsectionHead" data-number="13.5.1" id="sigil_toc_id_97"><span class="titlemark">8.5.1 </span> <span id="x1-1620001"></span>Navigating obstacles with uncertainty</h3>
<p>With uncertainty estimates, we can balance the reward against the modelâ€™s confidence in its prediction.<span id="dx1-162001"></span> If its confidence is low (meaning that uncertainty is high), then we may want to be cautious about how we incorporate our modelâ€™s predictions. For example, letâ€™s take the reinforcement learning scenario weâ€™ve just explored. For each episode, our model is predicting which action will yield the highest reward, and our agent then chooses this action. In the real world, things arenâ€™t so predictable â€“ our environment can change, leading to unexpected consequences. What if an obstacle appears in our environment, and colliding with that obstacle prevents our agent from completing its task? Well, clearly if our agent hasnâ€™t yet encountered the obstacle, itâ€™s doomed to fail. Fortunately, in the case of Bayesian Deep Learning, this isnâ€™t the case. As long as we have some way of sensing the obstacle, our agent can detect the obstacle and take a different route â€“ even if the obstacle wasnâ€™t encountered in previous episodes.</p>
<div class="IMG---Figure">
<img src="../media/file179.jpg" class="graphics" alt="PIC"/> <span id="x1-162002r12"></span> <span id="x1-162003"></span></div>
<p class="IMG---Caption">FigureÂ 8.12: Illustration of how uncertainty affects the actions of a reinforcement learning agent 
</p>
<p>This is possible thanks to our uncertainty estimates. When the model encounters something unusual, its uncertainty estimate for that prediction will be high.<span id="dx1-162004"></span> Thus, if we incorporate this into our MPC equation, we can balance reward with uncertainty, ensuring that we prioritize lower risk over higher reward. To do so, we modify our MPC equation as follows:</p>
<div class="math-display">
<img src="../media/file180.jpg" class="math-display" alt="anext = argmax (yi âˆ’ Î»Ïƒi)âˆ€ai âˆˆ As "/>
</div>
<p>Here, we see that weâ€™re now subtracting a value, <em>Î»Ïƒ</em><sub><em>i</em></sub>, from our reward prediction <em>y</em><sub><em>i</em></sub>. This is because <em>Ïƒ</em><sub><em>i</em></sub> is our uncertainty associated with the <em>i</em>th prediction. We use <em>Î»</em> to scale the uncertainty so that it appropriately penalizes uncertain actions; this is a parameter we can tune depending on the application. With a sufficiently well calibrated method, weâ€™ll see larger values for <em>Ïƒ</em><sub><em>i</em></sub> in cases where the model is uncertain about its predictions. Letâ€™s build on our earlier code example to see this in action.</p>
<section id="step-1-introducing-obstacles" class="level4 likesubsubsectionHead" data-number="13.5.1.1">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.1"><span id="x1-1630001"></span>Step 1: Introducing obstacles</h4>
<p>To create a challenge for our agent, weâ€™re going to introduce obstacles to our environment.<span id="dx1-163001"></span> To test how our agent responds to unfamiliar input, weâ€™re going to change the policy that our obstacle follows - it will either follow a static policy or a dynamic policy depending on our environment settings. Weâ€™ll change the <code>__init__()</code> function for our <code>Environment</code> class to incorporate these changes:</p>
<pre id="fancyvrb237" class="fancyvrb"><span id="x1-163029r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5874"><span>def</span></span><span>Â </span><span id="textcolor5875"><span>__init__</span></span><span>(</span><span id="textcolor5876"><span>self</span></span><span>,</span><span>Â env_size</span><span id="textcolor5877"><span>=</span></span><span id="textcolor5878"><span>8</span></span><span>,</span><span>Â max_steps</span><span id="textcolor5879"><span>=</span></span><span id="textcolor5880"><span>2000</span></span><span>,</span><span>Â dynamic_obstacle</span><span id="textcolor5881"><span>=</span></span><span id="textcolor5882"><span>False</span></span><span>,</span><span>Â lambda_val</span><span id="textcolor5883"><span>=</span></span><span id="textcolor5884"><span>2</span></span><span>):</span> <span id="x1-163031r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5885"><span>self</span></span><span id="textcolor5886"><span>.</span></span><span>env_size</span><span>Â </span><span id="textcolor5887"><span>=</span></span><span>Â env_size</span> <span id="x1-163033r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5888"><span>self</span></span><span id="textcolor5889"><span>.</span></span><span>max_steps</span><span>Â </span><span id="textcolor5890"><span>=</span></span><span>Â max_steps</span> <span id="x1-163035r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5891"><span>self</span></span><span id="textcolor5892"><span>.</span></span><span>agent_location</span><span>Â </span><span id="textcolor5893"><span>=</span></span><span>Â np</span><span id="textcolor5894"><span>.</span></span><span>zeros(</span><span id="textcolor5895"><span>2</span></span><span>)</span> <span id="x1-163037r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5896"><span>self</span></span><span id="textcolor5897"><span>.</span></span><span>dynamic_obstacle</span><span>Â </span><span id="textcolor5898"><span>=</span></span><span>Â dynamic_obstacle</span> <span id="x1-163039r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5899"><span>self</span></span><span id="textcolor5900"><span>.</span></span><span>lambda_val</span><span>Â </span><span id="textcolor5901"><span>=</span></span><span>Â lambda_val</span> <span id="x1-163041r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5902"><span>self</span></span><span id="textcolor5903"><span>.</span></span><span>target_location</span><span>Â </span><span id="textcolor5904"><span>=</span></span><span>Â np</span><span id="textcolor5905"><span>.</span></span><span>random</span><span id="textcolor5906"><span>.</span></span><span>randint(</span><span id="textcolor5907"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5908"><span>self</span></span><span id="textcolor5909"><span>.</span></span><span>env_size,</span><span>Â </span><span id="textcolor5910"><span>2</span></span><span>)</span> <span id="x1-163043r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5911"><span>while</span></span><span>Â euclidean(</span><span id="textcolor5912"><span>self</span></span><span id="textcolor5913"><span>.</span></span><span>agent_location,</span><span>Â </span><span id="textcolor5914"><span>self</span></span><span id="textcolor5915"><span>.</span></span><span>target_location)</span><span>Â </span><span id="textcolor5916"><em>&lt;</em></span><span>Â </span><span id="textcolor5917"><span>4</span></span><span>:</span> <span id="x1-163045r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5918"><span>self</span></span><span id="textcolor5919"><span>.</span></span><span>target_location</span><span>Â </span><span id="textcolor5920"><span>=</span></span><span>Â np</span><span id="textcolor5921"><span>.</span></span><span>random</span><span id="textcolor5922"><span>.</span></span><span>randint(</span><span id="textcolor5923"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5924"><span>self</span></span><span id="textcolor5925"><span>.</span></span><span>env_size,</span><span>Â </span><span id="textcolor5926"><span>2</span></span><span>)</span> <span id="x1-163047r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5927"><span>self</span></span><span id="textcolor5928"><span>.</span></span><span>action_space</span><span>Â </span><span id="textcolor5929"><span>=</span></span><span>Â {</span> <span id="x1-163049r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5930"><span>0</span></span><span>:</span><span>Â np</span><span id="textcolor5931"><span>.</span></span><span>array([</span><span id="textcolor5932"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5933"><span>1</span></span><span>]),</span> <span id="x1-163051r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5934"><span>1</span></span><span>:</span><span>Â np</span><span id="textcolor5935"><span>.</span></span><span>array([</span><span id="textcolor5936"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor5937"><span>-</span></span><span id="textcolor5938"><span>1</span></span><span>]),</span> <span id="x1-163053r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5939"><span>2</span></span><span>:</span><span>Â np</span><span id="textcolor5940"><span>.</span></span><span>array([</span><span id="textcolor5941"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor5942"><span>0</span></span><span>]),</span> <span id="x1-163055r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5943"><span>3</span></span><span>:</span><span>Â np</span><span id="textcolor5944"><span>.</span></span><span>array([</span><span id="textcolor5945"><span>-</span></span><span id="textcolor5946"><span>1</span></span><span>,</span><span>Â </span><span id="textcolor5947"><span>0</span></span><span>]),</span> <span id="x1-163057r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â }</span> <span id="x1-163059r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5948"><span>self</span></span><span id="textcolor5949"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor5950"><span>=</span></span><span>Â </span><span id="textcolor5951"><span>self</span></span><span id="textcolor5952"><span>.</span></span><span>compute_distance()</span> <span id="x1-163061r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5953"><span>self</span></span><span id="textcolor5954"><span>.</span></span><span>is_done</span><span>Â </span><span id="textcolor5955"><span>=</span></span><span>Â </span><span id="textcolor5956"><span>False</span></span> <span id="x1-163063r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5957"><span>self</span></span><span id="textcolor5958"><span>.</span></span><span>total_steps</span><span>Â </span><span id="textcolor5959"><span>=</span></span><span>Â </span><span id="textcolor5960"><span>0</span></span> <span id="x1-163065r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5961"><span>self</span></span><span id="textcolor5962"><span>.</span></span><span>obstacle_location</span><span>Â </span><span id="textcolor5963"><span>=</span></span><span>Â np</span><span id="textcolor5964"><span>.</span></span><span>array(</span> <span id="x1-163067r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span><span id="textcolor5965"><span>self</span></span><span id="textcolor5966"><span>.</span></span><span>env_size</span><span>Â </span><span id="textcolor5967"><span>/</span></span><span>Â </span><span id="textcolor5968"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor5969"><span>self</span></span><span id="textcolor5970"><span>.</span></span><span>env_size</span><span>Â </span><span id="textcolor5971"><span>/</span></span><span>Â </span><span id="textcolor5972"><span>2</span></span><span>],</span><span>Â dtype</span><span id="textcolor5973"><span>=</span></span><span id="textcolor5974"><span>int</span></span> <span id="x1-163069r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-163071r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5975"><span>self</span></span><span id="textcolor5976"><span>.</span></span><span>ideal_steps</span><span>Â </span><span id="textcolor5977"><span>=</span></span><span>Â </span><span id="textcolor5978"><span>self</span></span><span id="textcolor5979"><span>.</span></span><span>calculate_ideal_steps()</span> <span id="x1-163073r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5980"><span>self</span></span><span id="textcolor5981"><span>.</span></span><span>collision</span><span>Â </span><span id="textcolor5982"><span>=</span></span><span>Â </span><span id="textcolor5983"><span>False</span></span> <span id="x1-163075r24"></span> </code>
<code></code></pre>
<p>Thereâ€™s quite a lot going on here, so weâ€™ll go through each of the changes. First, to determine whether the obstacle is static or dynamic, we set the <code>dynamic_obstacle</code> variable. If this is <code>True</code>, then weâ€™ll randomly set the obstacle location. If itâ€™s <code>False</code>, then our object will sit in the middle of our environment. Weâ€™re also setting our <code>lambda</code> (<em>Î»</em>) parameter here, which defaults to 2.</p>
<p>Weâ€™ve also introduced a <code>while</code> loop here when setting <code>target_location</code>: weâ€™ve done this to ensure that thereâ€™s some distance between the agent and the target. We need to do this to ensure thereâ€™s space between our agent and our target to drop in our dynamic obstacle â€“ otherwise our agent may never encounter the obstacle (which would somewhat defeat the point of this example).</p>
<p>Lastly, we compute the obstacle location on line 17: youâ€™ll note that this just sets it to the middle of the environment.<span id="dx1-163082"></span> This is because we use the <code>dynamic_obstacle</code> flag later on to place the obstacle between the agent and the target â€“ we do this during the <code>calculate_ideal_steps()</code> function, as this way we know the obstacle will lie along the agentâ€™s ideal path (and is thus more likely to be encountered).</p>
</section>
<section id="step-2-placing-our-dynamic-obstacle" class="level4 likesubsubsectionHead" data-number="13.5.1.2">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.2"><span id="x1-1640001"></span>Step 2: Placing our dynamic obstacle</h4>
<p>When <code>dynamic_obstacle</code> is <code>True</code>, we want to place our obstacle somewhere different each episode, thus posing more of a challenge for our agent. To do so, we add a modification to the <code>calculate_ideal_steps()</code> function, as mentioned previously:</p>
<pre id="fancyvrb238" class="fancyvrb"><span id="x1-164020r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor5989"><span>def</span></span><span>Â </span><span id="textcolor5990"><span>calculate_ideal_steps</span></span><span>(</span><span id="textcolor5991"><span>self</span></span><span>):</span> <span id="x1-164022r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location</span><span>Â </span><span id="textcolor5992"><span>=</span></span><span>Â copy</span><span id="textcolor5993"><span>.</span></span><span>deepcopy(</span><span id="textcolor5994"><span>self</span></span><span id="textcolor5995"><span>.</span></span><span>agent_location)</span> <span id="x1-164024r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â target_location</span><span>Â </span><span id="textcolor5996"><span>=</span></span><span>Â copy</span><span id="textcolor5997"><span>.</span></span><span>deepcopy(</span><span id="textcolor5998"><span>self</span></span><span id="textcolor5999"><span>.</span></span><span>target_location)</span> <span id="x1-164026r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â delta</span><span>Â </span><span id="textcolor6000"><span>=</span></span><span>Â </span><span id="textcolor6001"><span>1e1000</span></span> <span id="x1-164028r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â i</span><span>Â </span><span id="textcolor6002"><span>=</span></span><span>Â </span><span id="textcolor6003"><span>0</span></span> <span id="x1-164030r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6004"><span>while</span></span><span>Â delta</span><span>Â </span><span id="textcolor6005"><em>&gt;</em></span><span>Â </span><span id="textcolor6006"><span>0</span></span><span>:</span> <span id="x1-164032r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ideal_action,</span><span>Â delta</span><span>Â </span><span id="textcolor6007"><span>=</span></span><span>Â </span><span id="textcolor6008"><span>self</span></span><span id="textcolor6009"><span>.</span></span><span>calculate_ideal_action(</span> <span id="x1-164034r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location,</span><span>Â target_location</span> <span id="x1-164036r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-164038r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â agent_location</span><span>Â </span><span id="textcolor6010"><span>+=</span></span><span>Â </span><span id="textcolor6011"><span>self</span></span><span id="textcolor6012"><span>.</span></span><span>action_space[ideal_action]</span> <span id="x1-164040r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6013"><span>if</span></span><span>Â np</span><span id="textcolor6014"><span>.</span></span><span>random</span><span id="textcolor6015"><span>.</span></span><span>randint(</span><span id="textcolor6016"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor6017"><span>2</span></span><span>)</span><span>Â </span><span id="textcolor6018"><span>and</span></span><span>Â </span><span id="textcolor6019"><span>self</span></span><span id="textcolor6020"><span>.</span></span><span>dynamic_obstacle:</span> <span id="x1-164042r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6021"><span>self</span></span><span id="textcolor6022"><span>.</span></span><span>obstacle_location</span><span>Â </span><span id="textcolor6023"><span>=</span></span><span>Â copy</span><span id="textcolor6024"><span>.</span></span><span>deepcopy(agent_location)</span> <span id="x1-164044r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â i</span><span>Â </span><span id="textcolor6025"><span>+=</span></span><span>Â </span><span id="textcolor6026"><span>1</span></span> <span id="x1-164046r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6027"><span>return</span></span><span>Â i</span></code></pre>
<p>Here, we see that we call <code>np.random.randint(0,Â 2)</code> on each iteration of the <code>while</code> loop. This is to randomize in which position the obstacle is placed along the ideal path.<span id="dx1-164049"></span></p>
</section>
<section id="step-3-adding-sensing" class="level4 likesubsubsectionHead" data-number="13.5.1.3">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.3"><span id="x1-1650001"></span>Step 3: Adding sensing</h4>
<p>Our agent will have no hope of avoiding the object introduced into our environment if it canâ€™t sense the object. As such, weâ€™ll add a function to simulate a sensor: <code>get_obstacle_proximity()</code>. This sensor will give our agent information on how close it would get to an object were it to take a certain action.<span id="dx1-165002"></span> Weâ€™ll have this return progressively higher values depending on how close to the object a given action would place our agent. If the action places our agent sufficiently far from the object (in this case, at least 4.5 spaces), then our sensor will return zero. This sensing function allows our agent to effectively see one step ahead, so we can think of the sensor as having a range of one step.</p>
<pre id="fancyvrb239" class="fancyvrb"><span id="x1-165019r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6033"><span>def</span></span><span>Â </span><span id="textcolor6034"><span>get_obstacle_proximity</span></span><span>(</span><span id="textcolor6035"><span>self</span></span><span>):</span> <span id="x1-165021r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â obstacle_action_dists</span><span>Â </span><span id="textcolor6036"><span>=</span></span><span>Â np</span><span id="textcolor6037"><span>.</span></span><span>array(</span> <span id="x1-165023r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-165025r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â euclidean(</span> <span id="x1-165027r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6038"><span>self</span></span><span id="textcolor6039"><span>.</span></span><span>agent_location</span><span>Â </span><span id="textcolor6040"><span>+</span></span><span>Â </span><span id="textcolor6041"><span>self</span></span><span id="textcolor6042"><span>.</span></span><span>action_space[k],</span> <span id="x1-165029r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6043"><span>self</span></span><span id="textcolor6044"><span>.</span></span><span>obstacle_location,</span> <span id="x1-165031r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-165033r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6045"><span>for</span></span><span>Â k</span><span>Â </span><span id="textcolor6046"><span>in</span></span><span>Â </span><span id="textcolor6047"><span>self</span></span><span id="textcolor6048"><span>.</span></span><span>action_space</span><span id="textcolor6049"><span>.</span></span><span>keys()</span> <span id="x1-165035r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-165037r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-165039r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6050"><span>return</span></span><span>Â </span><span id="textcolor6051"><span>self</span></span><span id="textcolor6052"><span>.</span></span><span>lambda_val</span><span>Â </span><span id="textcolor6053"><span>*</span></span><span>Â (</span> <span id="x1-165041r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor6054"><span>.</span></span><span>array(obstacle_action_dists</span><span>Â </span><span id="textcolor6055"><em>&lt;</em></span><span>Â </span><span id="textcolor6056"><span>2.5</span></span><span>,</span><span>Â dtype</span><span id="textcolor6057"><span>=</span></span><span id="textcolor6058"><span>float</span></span><span>)</span> <span id="x1-165043r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6059"><span>+</span></span><span>Â np</span><span id="textcolor6060"><span>.</span></span><span>array(obstacle_action_dists</span><span>Â </span><span id="textcolor6061"><em>&lt;</em></span><span>Â </span><span id="textcolor6062"><span>3.5</span></span><span>,</span><span>Â dtype</span><span id="textcolor6063"><span>=</span></span><span id="textcolor6064"><span>float</span></span><span>)</span> <span id="x1-165045r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6065"><span>+</span></span><span>Â np</span><span id="textcolor6066"><span>.</span></span><span>array(obstacle_action_dists</span><span>Â </span><span id="textcolor6067"><em>&lt;</em></span><span>Â </span><span id="textcolor6068"><span>4.5</span></span><span>,</span><span>Â dtype</span><span id="textcolor6069"><span>=</span></span><span id="textcolor6070"><span>float</span></span><span>)</span> <span id="x1-165047r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span></code></pre>
<p>Here, we first compute the future proximity for the agent given each action, after which we compute integer â€proximityâ€ values. These are computed by first constructing Boolean arrays for each proximity condition, in this case being <em>Î´</em><sub><em>o</em></sub> <em>&lt;</em> 2<em>.</em>5, <em>Î´</em><sub><em>o</em></sub> <em>&lt;</em> 3<em>.</em>5, and <em>Î´</em><sub><em>o</em></sub> <em>&lt;</em> 4<em>.</em>5, where <em>Î´</em><sub><em>o</em></sub> is the distance to the obstacle. We then sum these such that the proximity score has integer values of 3, 2, or 1 depending on how many of the criteria are met. This gives us a sensor that returns some basic information about the obstacleâ€™s future proximity for each of the proposed actions.<span id="dx1-165048"></span></p>
</section>
<section id="step-4-modifying-our-reward-function" class="level4 likesubsubsectionHead" data-number="13.5.1.4">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.4"><span id="x1-1660001"></span>Step 4: Modifying our reward function</h4>
<p>The last thing we need to do to prepare our environment is to update our reward function:<span id="dx1-166001"></span></p>
<pre id="fancyvrb240" class="fancyvrb"><span id="x1-166014r1"></span> 
<code><span id="textcolor6071"><span>def</span></span><span>Â </span><span id="textcolor6072"><span>compute_reward</span></span><span>(</span><span id="textcolor6073"><span>self</span></span><span>):</span> <span id="x1-166016r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â d1</span><span>Â </span><span id="textcolor6074"><span>=</span></span><span>Â </span><span id="textcolor6075"><span>self</span></span><span id="textcolor6076"><span>.</span></span><span>delta</span> <span id="x1-166018r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6077"><span>self</span></span><span id="textcolor6078"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor6079"><span>=</span></span><span>Â </span><span id="textcolor6080"><span>self</span></span><span id="textcolor6081"><span>.</span></span><span>compute_distance()</span> <span id="x1-166020r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6082"><span>if</span></span><span>Â euclidean(</span><span id="textcolor6083"><span>self</span></span><span id="textcolor6084"><span>.</span></span><span>agent_location,</span><span>Â </span><span id="textcolor6085"><span>self</span></span><span id="textcolor6086"><span>.</span></span><span>obstacle_location)</span><span>Â </span><span id="textcolor6087"><span>==</span></span><span>Â </span><span id="textcolor6088"><span>0</span></span><span>:</span> <span id="x1-166022r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6089"><span>self</span></span><span id="textcolor6090"><span>.</span></span><span>reward</span><span>Â </span><span id="textcolor6091"><span>=</span></span><span>Â </span><span id="textcolor6092"><span>0</span></span> <span id="x1-166024r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6093"><span>self</span></span><span id="textcolor6094"><span>.</span></span><span>collision</span><span>Â </span><span id="textcolor6095"><span>=</span></span><span>Â </span><span id="textcolor6096"><span>True</span></span> <span id="x1-166026r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6097"><span>self</span></span><span id="textcolor6098"><span>.</span></span><span>is_done</span><span>Â </span><span id="textcolor6099"><span>=</span></span><span>Â </span><span id="textcolor6100"><span>True</span></span> <span id="x1-166028r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6101"><span>elif</span></span><span>Â </span><span id="textcolor6102"><span>self</span></span><span id="textcolor6103"><span>.</span></span><span>delta</span><span>Â </span><span id="textcolor6104"><em>&lt;</em></span><span>Â d1:</span> <span id="x1-166030r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6105"><span>self</span></span><span id="textcolor6106"><span>.</span></span><span>reward</span><span>Â </span><span id="textcolor6107"><span>=</span></span><span>Â </span><span id="textcolor6108"><span>10</span></span> <span id="x1-166032r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6109"><span>else</span></span><span>:</span> <span id="x1-166034r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6110"><span>self</span></span><span id="textcolor6111"><span>.</span></span><span>reward</span><span>Â </span><span id="textcolor6112"><span>=</span></span><span>Â </span><span id="textcolor6113"><span>1</span></span></code></pre>
<p>Here, weâ€™ve added a statement to check whether the agent and obstacle have collided (checking whether the distance between the two is zero). If so, weâ€™ll return a reward of 0, and set both the <code>collision</code> and <code>is_done</code> variables to <code>True</code>. This introduces a new termination criteria, <strong>collision</strong>, and will allow our agent to learn that collisions are bad, as these receive the lowest reward.</p>
</section>
<section id="step-5-initializing-our-uncertainty-aware-model" class="level4 likesubsubsectionHead" data-number="13.5.1.5">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.5"><span id="x1-1670001"></span>Step 5: Initializing our uncertainty-aware model</h4>
<p>Now that our environment is ready, we need a new model â€“ one capable of producing uncertainty estimates.<span id="dx1-167001"></span> For this model, weâ€™ll use an MC dropout network with a single hidden layer:</p>
<pre id="fancyvrb241" class="fancyvrb"><span id="x1-167027r1"></span> 
<code><span id="textcolor6115"><span>class</span></span><span>Â </span><span id="textcolor6116"><span>RLModelDropout</span></span><span>:</span> <span id="x1-167029r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6117"><span>def</span></span><span>Â </span><span id="textcolor6118"><span>__init__</span></span><span>(</span><span id="textcolor6119"><span>self</span></span><span>,</span><span>Â state_size,</span><span>Â n_actions,</span><span>Â num_epochs</span><span id="textcolor6120"><span>=</span></span><span id="textcolor6121"><span>200</span></span><span>,</span><span>Â nb_inference</span><span id="textcolor6122"><span>=</span></span><span id="textcolor6123"><span>10</span></span><span>):</span> <span id="x1-167031r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6124"><span>self</span></span><span id="textcolor6125"><span>.</span></span><span>state_size</span><span>Â </span><span id="textcolor6126"><span>=</span></span><span>Â state_size</span> <span id="x1-167033r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6127"><span>self</span></span><span id="textcolor6128"><span>.</span></span><span>n_actions</span><span>Â </span><span id="textcolor6129"><span>=</span></span><span>Â n_actions</span> <span id="x1-167035r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6130"><span>self</span></span><span id="textcolor6131"><span>.</span></span><span>num_epochs</span><span>Â </span><span id="textcolor6132"><span>=</span></span><span>Â num_epochs</span> <span id="x1-167037r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6133"><span>self</span></span><span id="textcolor6134"><span>.</span></span><span>nb_inference</span><span>Â </span><span id="textcolor6135"><span>=</span></span><span>Â nb_inference</span> <span id="x1-167039r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6136"><span>self</span></span><span id="textcolor6137"><span>.</span></span><span>model</span><span>Â </span><span id="textcolor6138"><span>=</span></span><span>Â Sequential()</span> <span id="x1-167041r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6139"><span>self</span></span><span id="textcolor6140"><span>.</span></span><span>model</span><span id="textcolor6141"><span>.</span></span><span>add(</span> <span id="x1-167043r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor6142"><span>.</span></span><span>Dense(</span> <span id="x1-167045r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6143"><span>10</span></span><span>,</span><span>Â input_dim</span><span id="textcolor6144"><span>=</span></span><span id="textcolor6145"><span>self</span></span><span id="textcolor6146"><span>.</span></span><span>state_size,</span><span>Â activation</span><span id="textcolor6147"><span>=</span></span><span id="textcolor6148"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor6149"><span>=</span></span><span id="textcolor6150"><span>"layer_1"</span></span> <span id="x1-167047r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-167049r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-167051r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6151"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â self.model.add(layers.Dropout(0.15))</span></span> <span id="x1-167053r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6152"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â self.model.add(layers.Dense(8,</span><span class="cmitt-10x-x-109">Â activation='relu',</span><span class="cmitt-10x-x-109">Â name='layer_2'))</span></span> <span id="x1-167055r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6153"><span>self</span></span><span id="textcolor6154"><span>.</span></span><span>model</span><span id="textcolor6155"><span>.</span></span><span>add(layers</span><span id="textcolor6156"><span>.</span></span><span>Dropout(</span><span id="textcolor6157"><span>0.15</span></span><span>))</span> <span id="x1-167057r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6158"><span>self</span></span><span id="textcolor6159"><span>.</span></span><span>model</span><span id="textcolor6160"><span>.</span></span><span>add(layers</span><span id="textcolor6161"><span>.</span></span><span>Dense(</span><span id="textcolor6162"><span>1</span></span><span>,</span><span>Â activation</span><span id="textcolor6163"><span>=</span></span><span id="textcolor6164"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor6165"><span>=</span></span><span id="textcolor6166"><span>"layer_2"</span></span><span>))</span> <span id="x1-167059r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6167"><span>self</span></span><span id="textcolor6168"><span>.</span></span><span>model</span><span id="textcolor6169"><span>.</span></span><span>compile(</span> <span id="x1-167061r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â optimizer</span><span id="textcolor6170"><span>=</span></span><span>optimizers</span><span id="textcolor6171"><span>.</span></span><span>Adam(),</span> <span id="x1-167063r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor6172"><span>=</span></span><span>losses</span><span id="textcolor6173"><span>.</span></span><span>Huber(),</span> <span id="x1-167065r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor6174"><span>=</span></span><span>[metrics</span><span id="textcolor6175"><span>.</span></span><span>RootMeanSquaredError()],</span> <span id="x1-167067r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-167069r22"></span> </code>
<code><span id="x1-167071r23"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6176"><span>self</span></span><span id="textcolor6177"><span>.</span></span><span>proximity_dict</span><span>Â </span><span id="textcolor6178"><span>=</span></span><span>Â {</span><span id="textcolor6179"><span>"proximity</span><span>Â sensor</span><span>Â value"</span></span><span>:</span><span>Â [],</span><span>Â </span><span id="textcolor6180"><span>"uncertainty"</span></span><span>:</span><span>Â []}</span> <span id="x1-167073r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6181"><span>...</span></span></code></pre>
<p>This should look pretty familiar, but youâ€™ll notice a few key differences. First, weâ€™re again using the Huber loss. Secondly, weâ€™ve introduced a dictionary, <code>proximity_dict</code>, which will record the proximity values received from the sensor and the associated model uncertainties.<span id="dx1-167075"></span> This will allow us to evaluate our modelâ€™s sensitivity to anomalous proximity values later on.</p>
</section>
<section id="step-6-fitting-our-mc-dropout-network" class="level4 likesubsubsectionHead" data-number="13.5.1.6">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.6"><span id="x1-1680001"></span>Step 6: Fitting our MC dropout network</h4>
<p>Next, we need the following lines:</p>
<pre id="fancyvrb242" class="fancyvrb"><span id="x1-168014r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6182"><span>...</span></span> <span id="x1-168016r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6183"><span>def</span></span><span>Â </span><span id="textcolor6184"><span>fit</span></span><span>(</span><span id="textcolor6185"><span>self</span></span><span>,</span><span>Â X_train,</span><span>Â y_train,</span><span>Â batch_size</span><span id="textcolor6186"><span>=</span></span><span id="textcolor6187"><span>16</span></span><span>):</span> <span id="x1-168018r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6188"><span>self</span></span><span id="textcolor6189"><span>.</span></span><span>scaler</span><span>Â </span><span id="textcolor6190"><span>=</span></span><span>Â StandardScaler()</span> <span id="x1-168020r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X_train</span><span>Â </span><span id="textcolor6191"><span>=</span></span><span>Â </span><span id="textcolor6192"><span>self</span></span><span id="textcolor6193"><span>.</span></span><span>scaler</span><span id="textcolor6194"><span>.</span></span><span>fit_transform(X_train)</span> <span id="x1-168022r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6195"><span>self</span></span><span id="textcolor6196"><span>.</span></span><span>model</span><span id="textcolor6197"><span>.</span></span><span>fit(</span> <span id="x1-168024r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X_train,</span> <span id="x1-168026r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â y_train,</span> <span id="x1-168028r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epochs</span><span id="textcolor6198"><span>=</span></span><span id="textcolor6199"><span>self</span></span><span id="textcolor6200"><span>.</span></span><span>num_epochs,</span> <span id="x1-168030r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â verbose</span><span id="textcolor6201"><span>=</span></span><span id="textcolor6202"><span>0</span></span><span>,</span> <span id="x1-168032r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â batch_size</span><span id="textcolor6203"><span>=</span></span><span>batch_size,</span> <span id="x1-168034r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-168036r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6204"><span>...</span></span></code></pre>
<p>This should again look very familiar â€“ weâ€™re simply preparing our data by first scaling our inputs before fitting our model.<span id="dx1-168037"></span></p>
</section>
<section id="step-7-making-predictions" class="level4 likesubsubsectionHead" data-number="13.5.1.7">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.7"><span id="x1-1690001"></span>Step 7: Making predictions</h4>
<p>Here, we see that weâ€™ve slightly modified our <code>predict()</code> function:<span id="dx1-169002"></span></p>
<pre id="fancyvrb243" class="fancyvrb"><span id="x1-169023r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6205"><span>...</span></span> <span id="x1-169025r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6206"><span>def</span></span><span>Â </span><span id="textcolor6207"><span>predict</span></span><span>(</span><span id="textcolor6208"><span>self</span></span><span>,</span><span>Â state,</span><span>Â obstacle_proximity,</span><span>Â dynamic_obstacle</span><span id="textcolor6209"><span>=</span></span><span id="textcolor6210"><span>False</span></span><span>):</span> <span id="x1-169027r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards</span><span>Â </span><span id="textcolor6211"><span>=</span></span><span>Â []</span> <span id="x1-169029r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X</span><span>Â </span><span id="textcolor6212"><span>=</span></span><span>Â np</span><span id="textcolor6213"><span>.</span></span><span>zeros((</span><span id="textcolor6214"><span>self</span></span><span id="textcolor6215"><span>.</span></span><span>n_actions,</span><span>Â </span><span id="textcolor6216"><span>self</span></span><span id="textcolor6217"><span>.</span></span><span>state_size))</span> <span id="x1-169031r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6218"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor6219"><span>in</span></span><span>Â </span><span id="textcolor6220"><span>range</span></span><span>(</span><span id="textcolor6221"><span>self</span></span><span id="textcolor6222"><span>.</span></span><span>n_actions):</span> <span id="x1-169033r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X[i]</span><span>Â </span><span id="textcolor6223"><span>=</span></span><span>Â np</span><span id="textcolor6224"><span>.</span></span><span>concatenate([state,</span><span>Â [i],</span><span>Â [obstacle_proximity[i]]])</span> <span id="x1-169035r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X</span><span>Â </span><span id="textcolor6225"><span>=</span></span><span>Â </span><span id="textcolor6226"><span>self</span></span><span id="textcolor6227"><span>.</span></span><span>scaler</span><span id="textcolor6228"><span>.</span></span><span>transform(X)</span> <span id="x1-169037r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards,</span><span>Â y_std</span><span>Â </span><span id="textcolor6229"><span>=</span></span><span>Â </span><span id="textcolor6230"><span>self</span></span><span id="textcolor6231"><span>.</span></span><span>predict_ll_dropout(X)</span> <span id="x1-169039r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6232"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â we</span><span class="cmitt-10x-x-109">Â subtract</span><span class="cmitt-10x-x-109">Â our</span><span class="cmitt-10x-x-109">Â standard</span><span class="cmitt-10x-x-109">Â deviations</span><span class="cmitt-10x-x-109">Â from</span><span class="cmitt-10x-x-109">Â our</span><span class="cmitt-10x-x-109">Â predicted</span><span class="cmitt-10x-x-109">Â reward</span><span class="cmitt-10x-x-109">Â values,</span></span> <span id="x1-169041r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6233"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â this</span><span class="cmitt-10x-x-109">Â way</span><span class="cmitt-10x-x-109">Â uncertain</span><span class="cmitt-10x-x-109">Â predictions</span><span class="cmitt-10x-x-109">Â are</span><span class="cmitt-10x-x-109">Â penalised</span></span> <span id="x1-169043r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards</span><span>Â </span><span id="textcolor6234"><span>=</span></span><span>Â rewards</span><span>Â </span><span id="textcolor6235"><span>-</span></span><span>Â (y_std</span><span>Â </span><span id="textcolor6236"><span>*</span></span><span>Â </span><span id="textcolor6237"><span>2</span></span><span>)</span> <span id="x1-169045r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â best_action</span><span>Â </span><span id="textcolor6238"><span>=</span></span><span>Â np</span><span id="textcolor6239"><span>.</span></span><span>argmax(rewards)</span> <span id="x1-169047r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6240"><span>if</span></span><span>Â dynamic_obstacle:</span> <span id="x1-169049r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6241"><span>self</span></span><span id="textcolor6242"><span>.</span></span><span>proximity_dict[</span><span id="textcolor6243"><span>"proximity</span><span>Â sensor</span><span>Â value"</span></span><span>]</span><span id="textcolor6244"><span>.</span></span><span>append(</span> <span id="x1-169051r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â obstacle_proximity[best_action]</span> <span id="x1-169053r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-169055r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6245"><span>self</span></span><span id="textcolor6246"><span>.</span></span><span>proximity_dict[</span><span id="textcolor6247"><span>"uncertainty"</span></span><span>]</span><span id="textcolor6248"><span>.</span></span><span>append(y_std[best_action][</span><span id="textcolor6249"><span>0</span></span><span>])</span> <span id="x1-169057r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6250"><span>return</span></span><span>Â best_action</span> <span id="x1-169059r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6251"><span>...</span></span></code></pre>
<p>More specifically, weâ€™ve added the <code>obstacle_proximity</code> and <code>dynamic_obstacle</code> variables. The former allows us to receive the sensor information and incorporate this in the inputs we pass to our model. The latter is a flag telling us whether weâ€™re in the dynamic obstacle phase â€“ if so, we want to record information about the sensor values and uncertainties in our <code>proximity_dict</code> dictionary.</p>
<p>The next block of prediction code should again look very familiar:</p>
<pre id="fancyvrb244" class="fancyvrb"><span id="x1-169071r1"></span> 
<code><span id="textcolor6252"><span>...</span></span> <span id="x1-169073r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6253"><span>def</span></span><span>Â </span><span id="textcolor6254"><span>predict_ll_dropout</span></span><span>(</span><span id="textcolor6255"><span>self</span></span><span>,</span><span>Â X):</span> <span id="x1-169075r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ll_divd</span><span>Â </span><span id="textcolor6256"><span>=</span></span><span>Â [</span> <span id="x1-169077r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6257"><span>self</span></span><span id="textcolor6258"><span>.</span></span><span>model(X,</span><span>Â training</span><span id="textcolor6259"><span>=</span></span><span id="textcolor6260"><span>True</span></span><span>)</span><span>Â </span><span id="textcolor6261"><span>for</span></span><span>Â _</span><span>Â </span><span id="textcolor6262"><span>in</span></span><span>Â </span><span id="textcolor6263"><span>range</span></span><span>(</span><span id="textcolor6264"><span>self</span></span><span id="textcolor6265"><span>.</span></span><span>nb_inference)</span> <span id="x1-169079r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-169081r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ll_divd</span><span>Â </span><span id="textcolor6266"><span>=</span></span><span>Â np</span><span id="textcolor6267"><span>.</span></span><span>stack(ll_divd)</span> <span id="x1-169083r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6268"><span>return</span></span><span>Â ll_divd</span><span id="textcolor6269"><span>.</span></span><span>mean(axis</span><span id="textcolor6270"><span>=</span></span><span id="textcolor6271"><span>0</span></span><span>),</span><span>Â ll_divd</span><span id="textcolor6272"><span>.</span></span><span>std(axis</span><span id="textcolor6273"><span>=</span></span><span id="textcolor6274"><span>0</span></span><span>)</span></code></pre>
<p>This function simply implements the MC dropout inference, obtaining predictions for <code>nb_inference</code> forward passes, and returns the means and standard deviations associated with our predictive distributions.<span id="dx1-169085"></span></p>
</section>
<section id="step-8-adapting-our-standard-model" class="level4 likesubsubsectionHead" data-number="13.5.1.8">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.8"><span id="x1-1700001"></span>Step 8: Adapting our standard model</h4>
<p>To understand the difference that our Bayesian model makes, weâ€™ll need to compare it with a non-Bayesian model.<span id="dx1-170001"></span> As such, weâ€™ll update our <code>RLModel</code> class from earlier, adding the ability to incorporate proximity information from our proximity sensor:</p>
<pre id="fancyvrb245" class="fancyvrb"><span id="x1-170043r1"></span> 
<code><span id="textcolor6275"><span>class</span></span><span>Â </span><span id="textcolor6276"><span>RLModel</span></span><span>:</span> <span id="x1-170045r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6277"><span>def</span></span><span>Â </span><span id="textcolor6278"><span>__init__</span></span><span>(</span><span id="textcolor6279"><span>self</span></span><span>,</span><span>Â state_size,</span><span>Â n_actions,</span><span>Â num_epochs</span><span id="textcolor6280"><span>=</span></span><span id="textcolor6281"><span>500</span></span><span>):</span> <span id="x1-170047r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6282"><span>self</span></span><span id="textcolor6283"><span>.</span></span><span>state_size</span><span>Â </span><span id="textcolor6284"><span>=</span></span><span>Â state_size</span> <span id="x1-170049r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6285"><span>self</span></span><span id="textcolor6286"><span>.</span></span><span>n_actions</span><span>Â </span><span id="textcolor6287"><span>=</span></span><span>Â n_actions</span> <span id="x1-170051r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6288"><span>self</span></span><span id="textcolor6289"><span>.</span></span><span>num_epochs</span><span>Â </span><span id="textcolor6290"><span>=</span></span><span>Â </span><span id="textcolor6291"><span>200</span></span> <span id="x1-170053r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6292"><span>self</span></span><span id="textcolor6293"><span>.</span></span><span>model</span><span>Â </span><span id="textcolor6294"><span>=</span></span><span>Â Sequential()</span> <span id="x1-170055r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6295"><span>self</span></span><span id="textcolor6296"><span>.</span></span><span>model</span><span id="textcolor6297"><span>.</span></span><span>add(</span> <span id="x1-170057r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â layers</span><span id="textcolor6298"><span>.</span></span><span>Dense(</span> <span id="x1-170059r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6299"><span>20</span></span><span>,</span><span>Â input_dim</span><span id="textcolor6300"><span>=</span></span><span id="textcolor6301"><span>self</span></span><span id="textcolor6302"><span>.</span></span><span>state_size,</span><span>Â activation</span><span id="textcolor6303"><span>=</span></span><span id="textcolor6304"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor6305"><span>=</span></span><span id="textcolor6306"><span>"layer_1"</span></span> <span id="x1-170061r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-170063r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-170065r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6307"><span>self</span></span><span id="textcolor6308"><span>.</span></span><span>model</span><span id="textcolor6309"><span>.</span></span><span>add(layers</span><span id="textcolor6310"><span>.</span></span><span>Dense(</span><span id="textcolor6311"><span>8</span></span><span>,</span><span>Â activation</span><span id="textcolor6312"><span>=</span></span><span id="textcolor6313"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor6314"><span>=</span></span><span id="textcolor6315"><span>"layer_2"</span></span><span>))</span> <span id="x1-170067r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6316"><span>self</span></span><span id="textcolor6317"><span>.</span></span><span>model</span><span id="textcolor6318"><span>.</span></span><span>add(layers</span><span id="textcolor6319"><span>.</span></span><span>Dense(</span><span id="textcolor6320"><span>1</span></span><span>,</span><span>Â activation</span><span id="textcolor6321"><span>=</span></span><span id="textcolor6322"><span>"relu"</span></span><span>,</span><span>Â name</span><span id="textcolor6323"><span>=</span></span><span id="textcolor6324"><span>"layer_3"</span></span><span>))</span> <span id="x1-170069r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6325"><span>self</span></span><span id="textcolor6326"><span>.</span></span><span>model</span><span id="textcolor6327"><span>.</span></span><span>compile(</span> <span id="x1-170071r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â optimizer</span><span id="textcolor6328"><span>=</span></span><span>optimizers</span><span id="textcolor6329"><span>.</span></span><span>Adam(),</span> <span id="x1-170073r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor6330"><span>=</span></span><span>losses</span><span id="textcolor6331"><span>.</span></span><span>Huber(),</span> <span id="x1-170075r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor6332"><span>=</span></span><span>[metrics</span><span id="textcolor6333"><span>.</span></span><span>RootMeanSquaredError()],</span> <span id="x1-170077r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-170079r19"></span> </code>
<code><span id="x1-170081r20"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6334"><span>def</span></span><span>Â </span><span id="textcolor6335"><span>fit</span></span><span>(</span><span id="textcolor6336"><span>self</span></span><span>,</span><span>Â X_train,</span><span>Â y_train,</span><span>Â batch_size</span><span id="textcolor6337"><span>=</span></span><span id="textcolor6338"><span>16</span></span><span>):</span> <span id="x1-170083r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6339"><span>self</span></span><span id="textcolor6340"><span>.</span></span><span>scaler</span><span>Â </span><span id="textcolor6341"><span>=</span></span><span>Â StandardScaler()</span> <span id="x1-170085r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X_train</span><span>Â </span><span id="textcolor6342"><span>=</span></span><span>Â </span><span id="textcolor6343"><span>self</span></span><span id="textcolor6344"><span>.</span></span><span>scaler</span><span id="textcolor6345"><span>.</span></span><span>fit_transform(X_train)</span> <span id="x1-170087r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6346"><span>self</span></span><span id="textcolor6347"><span>.</span></span><span>model</span><span id="textcolor6348"><span>.</span></span><span>fit(</span> <span id="x1-170089r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X_train,</span> <span id="x1-170091r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â y_train,</span> <span id="x1-170093r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epochs</span><span id="textcolor6349"><span>=</span></span><span id="textcolor6350"><span>self</span></span><span id="textcolor6351"><span>.</span></span><span>num_epochs,</span> <span id="x1-170095r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â verbose</span><span id="textcolor6352"><span>=</span></span><span id="textcolor6353"><span>0</span></span><span>,</span> <span id="x1-170097r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â batch_size</span><span id="textcolor6354"><span>=</span></span><span>batch_size,</span> <span id="x1-170099r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-170101r30"></span> </code>
<code><span id="x1-170103r31"></span></code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6355"><span>def</span></span><span>Â </span><span id="textcolor6356"><span>predict</span></span><span>(</span><span id="textcolor6357"><span>self</span></span><span>,</span><span>Â state,</span><span>Â obstacle_proximity,</span><span>Â obstacle</span><span id="textcolor6358"><span>=</span></span><span id="textcolor6359"><span>False</span></span><span>):</span> <span id="x1-170105r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards</span><span>Â </span><span id="textcolor6360"><span>=</span></span><span>Â []</span> <span id="x1-170107r33"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X</span><span>Â </span><span id="textcolor6361"><span>=</span></span><span>Â np</span><span id="textcolor6362"><span>.</span></span><span>zeros((</span><span id="textcolor6363"><span>self</span></span><span id="textcolor6364"><span>.</span></span><span>n_actions,</span><span>Â </span><span id="textcolor6365"><span>self</span></span><span id="textcolor6366"><span>.</span></span><span>state_size))</span> <span id="x1-170109r34"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6367"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor6368"><span>in</span></span><span>Â </span><span id="textcolor6369"><span>range</span></span><span>(</span><span id="textcolor6370"><span>self</span></span><span id="textcolor6371"><span>.</span></span><span>n_actions):</span> <span id="x1-170111r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X[i]</span><span>Â </span><span id="textcolor6372"><span>=</span></span><span>Â np</span><span id="textcolor6373"><span>.</span></span><span>concatenate([state,</span><span>Â [i],</span><span>Â [obstacle_proximity[i]]])</span> <span id="x1-170113r36"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â X</span><span>Â </span><span id="textcolor6374"><span>=</span></span><span>Â </span><span id="textcolor6375"><span>self</span></span><span id="textcolor6376"><span>.</span></span><span>scaler</span><span id="textcolor6377"><span>.</span></span><span>transform(X)</span> <span id="x1-170115r37"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â rewards</span><span>Â </span><span id="textcolor6378"><span>=</span></span><span>Â </span><span id="textcolor6379"><span>self</span></span><span id="textcolor6380"><span>.</span></span><span>model</span><span id="textcolor6381"><span>.</span></span><span>predict(X)</span> <span id="x1-170117r38"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6382"><span>return</span></span><span>Â np</span><span id="textcolor6383"><span>.</span></span><span>argmax(rewards)</span> <span id="x1-170119r39"></span> </code>
<code></code></pre>
<p>Crucially, we see here that our decision function has not changed: because we donâ€™t have model uncertainties, our modelâ€™s <code>predict()</code> function is choosing actions based only on the predicted reward.<span id="dx1-170121"></span></p>
</section>
<section id="step-9-preparing-to-run-our-new-reinforcement-learning-experiment" class="level4 likesubsubsectionHead" data-number="13.5.1.9">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.9"><span id="x1-1710001"></span>Step 9: Preparing to run our new reinforcement learning experiment</h4>
<p>Now weâ€™re ready to set up our new experiment. <span id="dx1-171001"></span>Weâ€™ll initialize the variables we used previously, and will introduce a few more:</p>
<pre id="fancyvrb246" class="fancyvrb"><span id="x1-171014r1"></span> 
<code><span>env_size</span><span>Â </span><span id="textcolor6384"><span>=</span></span><span>Â </span><span id="textcolor6385"><span>8</span></span> <span id="x1-171016r2"></span> </code>
<code><span>state_size</span><span>Â </span><span id="textcolor6386"><span>=</span></span><span>Â </span><span id="textcolor6387"><span>6</span></span> <span id="x1-171018r3"></span> </code>
<code><span>n_actions</span><span>Â </span><span id="textcolor6388"><span>=</span></span><span>Â </span><span id="textcolor6389"><span>4</span></span> <span id="x1-171020r4"></span> </code>
<code><span>epsilon</span><span>Â </span><span id="textcolor6390"><span>=</span></span><span>Â </span><span id="textcolor6391"><span>1.0</span></span> <span id="x1-171022r5"></span> </code>
<code><span>history</span><span>Â </span><span id="textcolor6392"><span>=</span></span><span>Â {</span><span id="textcolor6393"><span>"state"</span></span><span>:</span><span>Â [],</span><span>Â </span><span id="textcolor6394"><span>"reward"</span></span><span>:</span><span>Â []}</span> <span id="x1-171024r6"></span> </code>
<code><span>model</span><span>Â </span><span id="textcolor6395"><span>=</span></span><span>Â RLModelDropout(state_size,</span><span>Â n_actions,</span><span>Â num_epochs</span><span id="textcolor6396"><span>=</span></span><span id="textcolor6397"><span>400</span></span><span>)</span> <span id="x1-171026r7"></span> </code>
<code><span>n_samples</span><span>Â </span><span id="textcolor6398"><span>=</span></span><span>Â </span><span id="textcolor6399"><span>1000</span></span> <span id="x1-171028r8"></span> </code>
<code><span>max_steps</span><span>Â </span><span id="textcolor6400"><span>=</span></span><span>Â </span><span id="textcolor6401"><span>500</span></span> <span id="x1-171030r9"></span> </code>
<code><span>regrets</span><span>Â </span><span id="textcolor6402"><span>=</span></span><span>Â []</span> <span id="x1-171032r10"></span> </code>
<code><span>collisions</span><span>Â </span><span id="textcolor6403"><span>=</span></span><span>Â </span><span id="textcolor6404"><span>0</span></span> <span id="x1-171034r11"></span> </code>
<code><span>failed</span><span>Â </span><span id="textcolor6405"><span>=</span></span><span>Â </span><span id="textcolor6406"><span>0</span></span></code></pre>
<p>Here, we see that weâ€™ve introduced a <code>collisions</code> variable and a <code>failed</code> variable. These will keep track of the number of collisions and the number of failed episodes so that we can compare the performance of our Bayesian model with that of our non-Bayesian model. Weâ€™re now ready to run our experiment!</p>
</section>
<section id="step-10-running-our-bdl-reinforcement-experiment" class="level4 likesubsubsectionHead" data-number="13.5.1.10">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.5.1.10"><span id="x1-1720001"></span>Step 10: Running our BDL reinforcement experiment</h4>
<p>As before, weâ€™re going to run our experiment for 100 episodes. However, this time, weâ€™re only going to run training on our model for the first 50 episodes.<span id="dx1-172001"></span> After that, weâ€™ll stop training, and evaluate how well our model is able to find a safe path to the target. During these last 50 episodes, weâ€™ll set <code>dynamic_obstacle</code> to <code>True</code>, meaning our environment will now randomly choose a different position for our obstacle for each episode. Importantly, these random positions will be <em>along the</em> <em>ideal path</em> between the agent and its target.</p>
<p>Letâ€™s take a look at the code:</p>
<pre id="fancyvrb247" class="fancyvrb"><span id="x1-172016r1"></span> 
<code><span id="textcolor6408"><span>for</span></span><span>Â i</span><span>Â </span><span id="textcolor6409"><span>in</span></span><span>Â </span><span id="textcolor6410"><span>range</span></span><span>(</span><span id="textcolor6411"><span>100</span></span><span>):</span> <span id="x1-172018r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6412"><span>if</span></span><span>Â i</span><span>Â </span><span id="textcolor6413"><em>&lt;</em></span><span>Â </span><span id="textcolor6414"><span>50</span></span><span>:</span> <span id="x1-172020r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â env</span><span>Â </span><span id="textcolor6415"><span>=</span></span><span>Â Environment(env_size,</span><span>Â max_steps</span><span id="textcolor6416"><span>=</span></span><span>max_steps)</span> <span id="x1-172022r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â dynamic_obstacle</span><span>Â </span><span id="textcolor6417"><span>=</span></span><span>Â </span><span id="textcolor6418"><span>False</span></span> <span id="x1-172024r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6419"><span>else</span></span><span>:</span> <span id="x1-172026r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â dynamic_obstacle</span><span>Â </span><span id="textcolor6420"><span>=</span></span><span>Â </span><span id="textcolor6421"><span>True</span></span> <span id="x1-172028r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epsilon</span><span>Â </span><span id="textcolor6422"><span>=</span></span><span>Â </span><span id="textcolor6423"><span>0</span></span> <span id="x1-172030r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â env</span><span>Â </span><span id="textcolor6424"><span>=</span></span><span>Â Environment(</span> <span id="x1-172032r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â env_size,</span><span>Â max_steps</span><span id="textcolor6425"><span>=</span></span><span>max_steps,</span><span>Â dynamic_obstacle</span><span id="textcolor6426"><span>=</span></span><span id="textcolor6427"><span>True</span></span> <span id="x1-172034r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-172036r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6428"><span>...</span></span></code></pre>
<p>First, we check whether the episode is within the first 50 episodes. If so, we instantiate our environment with <code>dynamic_obstacle=False</code>, and also set our global <code>dynamic_obstacle</code> variable to <code>False</code>.</p>
<p>If the episode is one of the last 50 episodes, we create an environment with a randomly placed obstacle, and also set <code>epsilon</code> to 0, to ensure weâ€™re always using our model predictions when selecting actions.</p>
<p>Next, we enter our <code>while</code> loop, setting our agent in motion. This is very similar to the loop we saw in the last example, except this time weâ€™re calling <code>env.get_obstacle_proximity()</code>, using the returned obstacle proximity information in our predictions, and also storing this information in our episode history:<span id="dx1-172043"></span></p>
<pre id="fancyvrb248" class="fancyvrb"><span id="x1-172060r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6434"><span>...</span></span> <span id="x1-172062r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6435"><span>while</span></span><span>Â </span><span id="textcolor6436"><span>not</span></span><span>Â env</span><span id="textcolor6437"><span>.</span></span><span>is_done:</span> <span id="x1-172064r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â state</span><span>Â </span><span id="textcolor6438"><span>=</span></span><span>Â env</span><span id="textcolor6439"><span>.</span></span><span>get_state()</span> <span id="x1-172066r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â obstacle_proximity</span><span>Â </span><span id="textcolor6440"><span>=</span></span><span>Â env</span><span id="textcolor6441"><span>.</span></span><span>get_obstacle_proximity()</span> <span id="x1-172068r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6442"><span>if</span></span><span>Â np</span><span id="textcolor6443"><span>.</span></span><span>random</span><span id="textcolor6444"><span>.</span></span><span>rand()</span><span>Â </span><span id="textcolor6445"><em>&lt;</em></span><span>Â epsilon:</span> <span id="x1-172070r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â action</span><span>Â </span><span id="textcolor6446"><span>=</span></span><span>Â np</span><span id="textcolor6447"><span>.</span></span><span>random</span><span id="textcolor6448"><span>.</span></span><span>randint(n_actions)</span> <span id="x1-172072r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6449"><span>else</span></span><span>:</span> <span id="x1-172074r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â action</span><span>Â </span><span id="textcolor6450"><span>=</span></span><span>Â model</span><span id="textcolor6451"><span>.</span></span><span>predict(state,</span><span>Â obstacle_proximity,</span><span>Â dynamic_obstacle)</span> <span id="x1-172076r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â reward</span><span>Â </span><span id="textcolor6452"><span>=</span></span><span>Â env</span><span id="textcolor6453"><span>.</span></span><span>update(action)</span> <span id="x1-172078r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â history[</span><span id="textcolor6454"><span>"state"</span></span><span>]</span><span id="textcolor6455"><span>.</span></span><span>append(</span> <span id="x1-172080r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor6456"><span>.</span></span><span>concatenate([state,</span><span>Â [action],</span> <span id="x1-172082r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â [obstacle_proximity[action]]])</span> <span id="x1-172084r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-172086r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â history[</span><span id="textcolor6457"><span>"reward"</span></span><span>]</span><span id="textcolor6458"><span>.</span></span><span>append(reward)</span> <span id="x1-172088r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6459"><span>...</span></span></code></pre>
<p>Lastly, weâ€™ll record some information about completed episodes and print the outcome of the most recent episode to our terminal. We update our <code>failed</code> and <code>collisions</code> variables and print whether the episode was complete successfully, the agent failed to find the target, or the agent collided with the obstacle:<span id="dx1-172091"></span></p>
<pre id="fancyvrb249" class="fancyvrb"><span id="x1-172113r1"></span> 
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6460"><span>if</span></span><span>Â env</span><span id="textcolor6461"><span>.</span></span><span>total_steps</span><span>Â </span><span id="textcolor6462"><span>==</span></span><span>Â max_steps:</span> <span id="x1-172115r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6463"><span>print</span></span><span>(</span><span id="textcolor6464"><span>f</span></span><span id="textcolor6465"><span>"Failed</span><span>Â to</span><span>Â find</span><span>Â target</span><span>Â for</span><span>Â episode</span><span>Â </span></span><span id="textcolor6466"><span>{</span></span><span>i</span><span id="textcolor6467"><span>}</span></span><span id="textcolor6468"><span>.</span><span>Â Epsilon:</span><span>Â </span></span><span id="textcolor6469"><span>{</span></span><span>epsilon</span><span id="textcolor6470"><span>}</span></span><span id="textcolor6471"><span>"</span></span><span>)</span> <span id="x1-172117r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â failed</span><span>Â </span><span id="textcolor6472"><span>+=</span></span><span>Â </span><span id="textcolor6473"><span>1</span></span> <span id="x1-172119r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6474"><span>elif</span></span><span>Â env</span><span id="textcolor6475"><span>.</span></span><span>total_steps</span><span>Â </span><span id="textcolor6476"><em>&lt;</em></span><span>Â env</span><span id="textcolor6477"><span>.</span></span><span>ideal_steps:</span> <span id="x1-172121r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6478"><span>print</span></span><span>(</span><span id="textcolor6479"><span>f</span></span><span id="textcolor6480"><span>"Collided</span><span>Â with</span><span>Â obstacle</span><span>Â during</span><span>Â episode</span><span>Â </span></span><span id="textcolor6481"><span>{</span></span><span>i</span><span id="textcolor6482"><span>}</span></span><span id="textcolor6483"><span>.</span><span>Â Epsilon:</span><span>Â </span></span><span id="textcolor6484"><span>{</span></span><span>epsilon</span><span id="textcolor6485"><span>}</span></span><span id="textcolor6486"><span>"</span></span><span>)</span> <span id="x1-172123r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â collisions</span><span>Â </span><span id="textcolor6487"><span>+=</span></span><span>Â </span><span id="textcolor6488"><span>1</span></span> <span id="x1-172125r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6489"><span>else</span></span><span>:</span> <span id="x1-172127r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6490"><span>print</span></span><span>(</span> <span id="x1-172129r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6491"><span>f</span></span><span id="textcolor6492"><span>"Completed</span><span>Â episode</span><span>Â </span></span><span id="textcolor6493"><span>{</span></span><span>i</span><span id="textcolor6494"><span>}</span></span><span id="textcolor6495"><span>Â in</span><span>Â </span></span><span id="textcolor6496"><span>{</span></span><span>env</span><span id="textcolor6497"><span>.</span></span><span>total_steps</span><span id="textcolor6498"><span>}</span></span><span id="textcolor6499"><span>Â steps."</span></span> <span id="x1-172131r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6500"><span>f</span></span><span id="textcolor6501"><span>"Ideal</span><span>Â steps:</span><span>Â </span></span><span id="textcolor6502"><span>{</span></span><span>env</span><span id="textcolor6503"><span>.</span></span><span>ideal_steps</span><span id="textcolor6504"><span>}</span></span><span id="textcolor6505"><span>."</span></span> <span id="x1-172133r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6506"><span>f</span></span><span id="textcolor6507"><span>"Epsilon:</span><span>Â </span></span><span id="textcolor6508"><span>{</span></span><span>epsilon</span><span id="textcolor6509"><span>}</span></span><span id="textcolor6510"><span>"</span></span> <span id="x1-172135r12"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-172137r13"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â regrets</span><span id="textcolor6511"><span>.</span></span><span>append(np</span><span id="textcolor6512"><span>.</span></span><span>abs(env</span><span id="textcolor6513"><span>.</span></span><span>total_steps</span><span id="textcolor6514"><span>-</span></span><span>env</span><span id="textcolor6515"><span>.</span></span><span>ideal_steps))</span> <span id="x1-172139r14"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6516"><span>if</span></span><span>Â </span><span id="textcolor6517"><span>not</span></span><span>Â dynamic_obstacle:</span> <span id="x1-172141r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â idxs</span><span>Â </span><span id="textcolor6518"><span>=</span></span><span>Â np</span><span id="textcolor6519"><span>.</span></span><span>random</span><span id="textcolor6520"><span>.</span></span><span>choice(</span><span id="textcolor6521"><span>len</span></span><span>(history[</span><span id="textcolor6522"><span>"state"</span></span><span>]),</span><span>Â n_samples)</span> <span id="x1-172143r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â model</span><span id="textcolor6523"><span>.</span></span><span>fit(</span> <span id="x1-172145r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor6524"><span>.</span></span><span>array(history[</span><span id="textcolor6525"><span>"state"</span></span><span>])[idxs],</span> <span id="x1-172147r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â np</span><span id="textcolor6526"><span>.</span></span><span>array(history[</span><span id="textcolor6527"><span>"reward"</span></span><span>])[idxs]</span> <span id="x1-172149r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â )</span> <span id="x1-172151r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â epsilon</span><span id="textcolor6528"><span>-=</span></span><span>epsilon</span><span id="textcolor6529"><span>/</span></span><span id="textcolor6530"><span>10</span></span></code></pre>
<p>The last statement here also checks whether weâ€™re in the dynamic obstacle phase, and if not, runs a round of training and decrements our epsilon value (as with the last example).</p>
<p>So, how did we do? Repeating the above 100 episodes for both the <code>RLModel</code> and <code>RLModelDropout</code> models, we obtain the following results:</p>
<div class="IMG---Figure">
<div class="tabular">
<table id="TBL-3" class="tabular">
<tbody>
<tr class="odd hline">
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
</tr>
<tr id="TBL-3-1-" class="even" style="vertical-align:baseline;">
<td id="TBL-3-1-1" class="td11" style="text-align: left; white-space: nowrap;"><strong>Model</strong></td>
<td id="TBL-3-1-2" class="td11" style="text-align: center; white-space: nowrap;"><strong>Failed episodes</strong></td>
<td id="TBL-3-1-3" class="td11" style="text-align: center; white-space: nowrap;"><strong>Collisions</strong></td>
<td id="TBL-3-1-4" class="td11" style="text-align: center; white-space: nowrap;"><strong>Successful episodes</strong></td>
</tr>
<tr class="odd hline">
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
</tr>
<tr id="TBL-3-2-" class="even" style="vertical-align:baseline;">
<td id="TBL-3-2-1" class="td11" style="text-align: left; white-space: nowrap;"><strong>RLModelDropout</strong></td>
<td id="TBL-3-2-2" class="td11" style="text-align: center; white-space: nowrap;">19</td>
<td id="TBL-3-2-3" class="td11" style="text-align: center; white-space: nowrap;">3</td>
<td id="TBL-3-2-4" class="td11" style="text-align: center; white-space: nowrap;">31</td>
</tr>
<tr class="odd hline">
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
</tr>
<tr id="TBL-3-3-" class="even" style="vertical-align:baseline;">
<td id="TBL-3-3-1" class="td11" style="text-align: left; white-space: nowrap;"><strong>RLModel</strong></td>
<td id="TBL-3-3-2" class="td11" style="text-align: center; white-space: nowrap;">16</td>
<td id="TBL-3-3-3" class="td11" style="text-align: center; white-space: nowrap;">10</td>
<td id="TBL-3-3-4" class="td11" style="text-align: center; white-space: nowrap;">34</td>
</tr>
<tr class="odd hline">
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
<td><hr/>
</td>
</tr>
<tr id="TBL-3-4-" class="even" style="vertical-align:baseline;">
<td id="TBL-3-4-1" class="td11" style="text-align: left; white-space: nowrap;"></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<span id="x1-172154r13"></span> <span id="x1-172155"></span></div>
<p class="IMG---Caption">FigureÂ 8.13: A table showing collision predictions 
</p>
<p>As we see here, there are advantages and disadvantages to consider when choosing whether to use a standard neural network or a Bayesian neural network â€“ the standard neural network achieves a greater number of successfully completed episodes. <span id="dx1-172156"></span>However, crucially, the agent using the Bayesian neural network only collided with the obstacle three times, compared to the standard methodâ€™s 10 times â€“ thatâ€™s a 70% reduction in collisions!</p>
<p>Note that as the experiment is stochastic, your results may differ, but on the GitHub repository we have included the experiment complete with the seed used to produce these results.</p>
<p>We can get a better idea of why this is by looking at the data we recorded in <code>RLModelDropout</code>â€™s <code>proximity_dict</code> dictionary:</p>
<pre id="fancyvrb250" class="fancyvrb"><span id="x1-172165r1"></span> 
<code><span id="textcolor6531"><span>import</span></span><span>Â </span><span id="textcolor6532"><span>matplotlib.pyplot</span></span><span>Â </span><span id="textcolor6533"><span>as</span></span><span>Â </span><span id="textcolor6534"><span>plt</span></span> <span id="x1-172167r2"></span> </code>
<code><span id="textcolor6535"><span>import</span></span><span>Â </span><span id="textcolor6536"><span>seaborn</span></span><span>Â </span><span id="textcolor6537"><span>as</span></span><span>Â </span><span id="textcolor6538"><span>sns</span></span> <span id="x1-172169r3"></span> </code>
<code><span id="x1-172171r4"></span></code>
<code><span>df_plot</span><span>Â </span><span id="textcolor6539"><span>=</span></span><span>Â pd</span><span id="textcolor6540"><span>.</span></span><span>DataFrame(model</span><span id="textcolor6541"><span>.</span></span><span>proximity_dict)</span> <span id="x1-172173r5"></span> </code>
<code><span>sns</span><span id="textcolor6542"><span>.</span></span><span>boxplot(x</span><span id="textcolor6543"><span>=</span></span><span id="textcolor6544"><span>"proximity</span><span>Â sensor</span><span>Â value"</span></span><span>,</span><span>Â y</span><span id="textcolor6545"><span>=</span></span><span id="textcolor6546"><span>"uncertainty"</span></span><span>,</span><span>Â data</span><span id="textcolor6547"><span>=</span></span><span>df_plot)</span></code></pre>
<p>This produces the following plot:</p>
<div class="IMG---Figure">
<img src="../media/file181.png" alt="PIC"/> <span id="x1-172174r14"></span> <span id="x1-172175"></span></div>
<p class="IMG---Caption">FigureÂ 8.14: Distribution of uncertainty estimates associated with increasing proximity sensor values 
</p>
<p>As we see here, the model uncertainty estimates increase as the sensor values increase. This is because, during the first 50 episodes, our agent learns to avoid the centre of the environment (as this is where the obstacle is) â€“ thus it gets used to low (or zero) proximity sensor values. This means that higher sensor values are anomalous, and are thus able to be picked up by the modelâ€™s uncertainty estimates. Our agent then successfully accounts for this uncertainty using the uncertainty-aware MPC equation.</p>
<p>In this example, we saw how BDL can be applied to reinforcement learning to facilitate more cautious behaviour on the part of our reinforcement learning agents. While the example here was fairly basic, the implications are pretty significant: imagine this being applied to safety-critical applications. In these settings, weâ€™re often happy to accept poorer overall model performance if it meets better safety requirements. Thus, BDL has an important place within the field of safe reinforcement learning, allowing the development of reinforcement learning methods suitable for safety-critical scenarios.<span id="dx1-172176"></span></p>
<p>In the next section, weâ€™ll see how BDL can be used to create models that are robust to another key consideration for real-world applications: adversarial inputs. <span id="x1-172177r248"></span></p>
</section>
</section>
</section>
<section id="susceptibility-to-adversarial-input" class="level2 sectionHead" data-number="13.6">
<h2 class="sectionHead" data-number="13.6" id="sigil_toc_id_98"><span class="titlemark">8.6 </span> <span id="x1-1730006"></span>Susceptibility to adversarial input</h2>
<p>In <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a>, we saw that we could fool a CNN by slightly perturbing the input pixels of an image. A picture that clearly looked like a cat was predicted as a dog with high confidence.<span id="dx1-173001"></span> The adversarial attack that we created (<em>FSGM</em>) is one of the many adversarial attacks that exist, and BDL might offer some protection against these attacks. Letâ€™s see how that works in practice.</p>
<section id="step-1-model-training" class="level4 likesubsubsectionHead" data-number="13.6.0.1">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.6.0.1"><span id="x1-1740006"></span>Step 1: Model training</h4>
<p>Instead of using a pre-trained model, as in <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep</em> <em>Learning</em></a>, we train a model from scratch. We use the same train and test data from <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a> â€“ see that chapter for instructions on how to load the dataset.<span id="dx1-174001"></span> As a reminder, the dataset is a relatively small dataset of cats and dogs. We first define our model. We use a VGG-like architecture but add dropout after every <code>MaxPooling2D</code> layer:</p>
<pre id="fancyvrb251" class="fancyvrb"><span id="x1-174046r1"></span> 
<code><span id="textcolor6548"><span>def</span></span><span>Â </span><span id="textcolor6549"><span>conv_block</span></span><span>(filters):</span> <span id="x1-174048r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6550"><span>return</span></span><span>Â [</span> <span id="x1-174050r3"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6551"><span>.</span></span><span>keras</span><span id="textcolor6552"><span>.</span></span><span>layers</span><span id="textcolor6553"><span>.</span></span><span>Conv2D(</span> <span id="x1-174052r4"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â filters,</span> <span id="x1-174054r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â (</span><span id="textcolor6554"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor6555"><span>3</span></span><span>),</span> <span id="x1-174056r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â activation</span><span id="textcolor6556"><span>=</span></span><span id="textcolor6557"><span>"relu"</span></span><span>,</span> <span id="x1-174058r7"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_initializer</span><span id="textcolor6558"><span>=</span></span><span id="textcolor6559"><span>"he_uniform"</span></span><span>,</span> <span id="x1-174060r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-174062r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6560"><span>.</span></span><span>keras</span><span id="textcolor6561"><span>.</span></span><span>layers</span><span id="textcolor6562"><span>.</span></span><span>MaxPooling2D((</span><span id="textcolor6563"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor6564"><span>2</span></span><span>)),</span> <span id="x1-174064r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6565"><span>.</span></span><span>keras</span><span id="textcolor6566"><span>.</span></span><span>layers</span><span id="textcolor6567"><span>.</span></span><span>Dropout(</span><span id="textcolor6568"><span>0.5</span></span><span>),</span> <span id="x1-174066r11"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-174068r12"></span> </code>
<code><span id="x1-174070r13"></span></code>
<code><span id="x1-174072r14"></span></code>
<code><span>model</span><span>Â </span><span id="textcolor6569"><span>=</span></span><span>Â tf</span><span id="textcolor6570"><span>.</span></span><span>keras</span><span id="textcolor6571"><span>.</span></span><span>models</span><span id="textcolor6572"><span>.</span></span><span>Sequential(</span> <span id="x1-174074r15"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â [</span> <span id="x1-174076r16"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6573"><span>.</span></span><span>keras</span><span id="textcolor6574"><span>.</span></span><span>layers</span><span id="textcolor6575"><span>.</span></span><span>Conv2D(</span> <span id="x1-174078r17"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6576"><span>32</span></span><span>,</span> <span id="x1-174080r18"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â (</span><span id="textcolor6577"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor6578"><span>3</span></span><span>),</span> <span id="x1-174082r19"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â activation</span><span id="textcolor6579"><span>=</span></span><span id="textcolor6580"><span>"relu"</span></span><span>,</span> <span id="x1-174084r20"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â input_shape</span><span id="textcolor6581"><span>=</span></span><span>(</span><span id="textcolor6582"><span>160</span></span><span>,</span><span>Â </span><span id="textcolor6583"><span>160</span></span><span>,</span><span>Â </span><span id="textcolor6584"><span>3</span></span><span>),</span> <span id="x1-174086r21"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_initializer</span><span id="textcolor6585"><span>=</span></span><span id="textcolor6586"><span>"he_uniform"</span></span><span>,</span> <span id="x1-174088r22"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-174090r23"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6587"><span>.</span></span><span>keras</span><span id="textcolor6588"><span>.</span></span><span>layers</span><span id="textcolor6589"><span>.</span></span><span>MaxPooling2D((</span><span id="textcolor6590"><span>2</span></span><span>,</span><span>Â </span><span id="textcolor6591"><span>2</span></span><span>)),</span> <span id="x1-174092r24"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6592"><span>.</span></span><span>keras</span><span id="textcolor6593"><span>.</span></span><span>layers</span><span id="textcolor6594"><span>.</span></span><span>Dropout(</span><span id="textcolor6595"><span>0.2</span></span><span>),</span> <span id="x1-174094r25"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6596"><span>*</span></span><span>conv_block(</span><span id="textcolor6597"><span>64</span></span><span>),</span> <span id="x1-174096r26"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6598"><span>*</span></span><span>conv_block(</span><span id="textcolor6599"><span>128</span></span><span>),</span> <span id="x1-174098r27"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6600"><span>*</span></span><span>conv_block(</span><span id="textcolor6601"><span>256</span></span><span>),</span> <span id="x1-174100r28"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6602"><span>*</span></span><span>conv_block(</span><span id="textcolor6603"><span>128</span></span><span>),</span> <span id="x1-174102r29"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6604"><span>.</span></span><span>keras</span><span id="textcolor6605"><span>.</span></span><span>layers</span><span id="textcolor6606"><span>.</span></span><span>Conv2D(</span> <span id="x1-174104r30"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span id="textcolor6607"><span>64</span></span><span>,</span> <span id="x1-174106r31"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â (</span><span id="textcolor6608"><span>3</span></span><span>,</span><span>Â </span><span id="textcolor6609"><span>3</span></span><span>),</span> <span id="x1-174108r32"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â activation</span><span id="textcolor6610"><span>=</span></span><span id="textcolor6611"><span>"relu"</span></span><span>,</span> <span id="x1-174110r33"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â kernel_initializer</span><span id="textcolor6612"><span>=</span></span><span id="textcolor6613"><span>"he_uniform"</span></span><span>,</span> <span id="x1-174112r34"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â ),</span> <span id="x1-174114r35"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6614"><span>.</span></span><span>keras</span><span id="textcolor6615"><span>.</span></span><span>layers</span><span id="textcolor6616"><span>.</span></span><span>Flatten(),</span> <span id="x1-174116r36"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6617"><span>.</span></span><span>keras</span><span id="textcolor6618"><span>.</span></span><span>layers</span><span id="textcolor6619"><span>.</span></span><span>Dense(</span><span id="textcolor6620"><span>64</span></span><span>,</span><span>Â activation</span><span id="textcolor6621"><span>=</span></span><span id="textcolor6622"><span>"relu"</span></span><span>),</span> <span id="x1-174118r37"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6623"><span>.</span></span><span>keras</span><span id="textcolor6624"><span>.</span></span><span>layers</span><span id="textcolor6625"><span>.</span></span><span>Dropout(</span><span id="textcolor6626"><span>0.5</span></span><span>),</span> <span id="x1-174120r38"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â tf</span><span id="textcolor6627"><span>.</span></span><span>keras</span><span id="textcolor6628"><span>.</span></span><span>layers</span><span id="textcolor6629"><span>.</span></span><span>Dense(</span><span id="textcolor6630"><span>2</span></span><span>),</span> <span id="x1-174122r39"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â ]</span> <span id="x1-174124r40"></span> </code>
<code><span>)</span> <span id="x1-174126r41"></span> </code>
<code><span id="x1-174128r42"></span></code>
<code></code></pre>
<p>We then normalize our data, and compile and train our model:<span id="dx1-174129"></span></p>
<pre id="fancyvrb252" class="fancyvrb"><span id="x1-174142r1"></span> 
<code><span>train_dataset_divprocessed</span><span>Â </span><span id="textcolor6631"><span>=</span></span><span>Â train_dataset</span><span id="textcolor6632"><span>.</span></span><span>map(</span><span id="textcolor6633"><span>lambda</span></span><span>Â x,</span><span>Â y:</span><span>Â (x</span><span>Â </span><span id="textcolor6634"><span>/</span></span><span>Â </span><span id="textcolor6635"><span>255.</span></span><span>,</span><span>Â y))</span> <span id="x1-174144r2"></span> </code>
<code><span>val_dataset_divprocessed</span><span>Â </span><span id="textcolor6636"><span>=</span></span><span>Â validation_dataset</span><span id="textcolor6637"><span>.</span></span><span>map(</span><span id="textcolor6638"><span>lambda</span></span><span>Â x,</span><span>Â y:</span><span>Â (x</span><span>Â </span><span id="textcolor6639"><span>/</span></span><span>Â </span><span id="textcolor6640"><span>255.</span></span><span>,</span><span>Â y))</span> <span id="x1-174146r3"></span> </code>
<code><span id="x1-174148r4"></span></code>
<code><span>model</span><span id="textcolor6641"><span>.</span></span><span>compile(optimizer</span><span id="textcolor6642"><span>=</span></span><span>tf</span><span id="textcolor6643"><span>.</span></span><span>keras</span><span id="textcolor6644"><span>.</span></span><span>optimizers</span><span id="textcolor6645"><span>.</span></span><span>Adam(learning_rate</span><span id="textcolor6646"><span>=</span></span><span id="textcolor6647"><span>0.001</span></span><span>),</span> <span id="x1-174150r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â loss</span><span id="textcolor6648"><span>=</span></span><span>tf</span><span id="textcolor6649"><span>.</span></span><span>keras</span><span id="textcolor6650"><span>.</span></span><span>losses</span><span id="textcolor6651"><span>.</span></span><span>CategoricalCrossentropy(from_logits</span><span id="textcolor6652"><span>=</span></span><span id="textcolor6653"><span>True</span></span><span>),</span> <span id="x1-174152r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â metrics</span><span id="textcolor6654"><span>=</span></span><span>[</span><span id="textcolor6655"><span>'accuracy'</span></span><span>])</span> <span id="x1-174154r7"></span> </code>
<code><span>model</span><span id="textcolor6656"><span>.</span></span><span>fit(</span> <span id="x1-174156r8"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â train_dataset_divprocessed,</span> <span id="x1-174158r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â epochs</span><span id="textcolor6657"><span>=</span></span><span id="textcolor6658"><span>200</span></span><span>,</span> <span id="x1-174160r10"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â validation_data</span><span id="textcolor6659"><span>=</span></span><span>val_dataset_divprocessed,</span> <span id="x1-174162r11"></span> </code>
<code><span>)</span></code></pre>
<p>This will give us a model accuracy of about 85%.</p>
</section>
<section id="step-2-running-inference-and-evaluating-our-standard-model" class="level4 likesubsubsectionHead" data-number="13.6.0.2">
<h4 class="likesubsubsectionHead sigil_not_in_toc" data-number="13.6.0.2"><span id="x1-1750006"></span>Step 2: Running inference and evaluating our standard model</h4>
<p>Now that we have trained our model, letâ€™s see how much protection it offers against an adversarial attack.<span id="dx1-175001"></span> In <a href="CH3.xhtml#x1-350003"><em>ChapterÂ 3</em></a>, <a href="CH3.xhtml#x1-350003"><em>Fundamentals of Deep Learning</em></a>, we created an adversarial attack from scratch. In this chapter, weâ€™ll use the <code>cleverhans</code> library to create the same attack in one line for multiple images at once:</p>
<pre id="fancyvrb253" class="fancyvrb"><span id="x1-175007r1"></span> 
<code><span id="textcolor6660"><span>from</span></span><span>Â </span><span id="textcolor6661"><span>cleverhans.tf2.attacks.fast_gradient_method</span></span><span>Â </span><span id="textcolor6662"><span>import</span></span><span>Â (</span> <span id="x1-175009r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â fast_gradient_method</span><span>Â </span><span id="textcolor6663"><span>as</span></span><span>Â fgsm,</span> <span id="x1-175011r3"></span> </code>
<code><span>)</span></code></pre>
<p>Letâ€™s first measure the accuracy of our deterministic model on the original images and the adversarial images:</p>
<pre id="fancyvrb254" class="fancyvrb"><span id="x1-175020r1"></span> 
<code><span>Predictions_standard,</span><span>Â predictions_fgsm,</span><span>Â labels</span><span>Â </span><span id="textcolor6664"><span>=</span></span><span>Â [],</span><span>Â [],</span><span>Â []</span> <span id="x1-175022r2"></span> </code>
<code><span id="textcolor6665"><span>for</span></span><span>Â imgs,</span><span>Â labels_batch</span><span>Â </span><span id="textcolor6666"><span>in</span></span><span>Â test_dataset:</span> <span id="x1-175024r3"></span> </code>
<code><span>Â </span><span>Â imgs</span><span>Â </span><span id="textcolor6667"><span>/=</span></span><span>Â </span><span id="textcolor6668"><span>255.</span></span> <span id="x1-175026r4"></span> </code>
<code><span>Â </span><span>Â predictions_standard</span><span id="textcolor6669"><span>.</span></span><span>extend(model</span><span id="textcolor6670"><span>.</span></span><span>predict(imgs))</span> <span id="x1-175028r5"></span> </code>
<code><span>Â </span><span>Â imgs_adv</span><span>Â </span><span id="textcolor6671"><span>=</span></span><span>Â fgsm(model,</span><span>Â imgs,</span><span>Â </span><span id="textcolor6672"><span>0.01</span></span><span>,</span><span>Â np</span><span id="textcolor6673"><span>.</span></span><span>inf)</span> <span id="x1-175030r6"></span> </code>
<code><span>Â </span><span>Â predictions_fgsm</span><span id="textcolor6674"><span>.</span></span><span>extend(model</span><span id="textcolor6675"><span>.</span></span><span>predict(imgs_adv))</span> <span id="x1-175032r7"></span> </code>
<code><span>Â </span><span>Â labels</span><span id="textcolor6676"><span>.</span></span><span>extend(labels_batch)</span></code></pre>
<p>Now that we have our predictions, we can print the accuracy:</p>
<pre id="fancyvrb255" class="fancyvrb"><span id="x1-175042r1"></span> 
<code><span>accuracy_standard</span><span>Â </span><span id="textcolor6677"><span>=</span></span><span>Â CategoricalAccuracy()(</span> <span id="x1-175044r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â labels,</span><span>Â predictions_standard</span> <span id="x1-175046r3"></span> </code>
<code><span>)</span><span id="textcolor6678"><span>.</span></span><span>numpy()</span> <span id="x1-175048r4"></span> </code>
<code><span>accuracy_fgsm</span><span>Â </span><span id="textcolor6679"><span>=</span></span><span>Â CategoricalAccuracy()(</span> <span id="x1-175050r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â labels,</span><span>Â predictions_fgsm</span> <span id="x1-175052r6"></span> </code>
<code><span>)</span><span id="textcolor6680"><span>.</span></span><span>numpy()</span> <span id="x1-175054r7"></span> </code>
<code><span id="textcolor6681"><span>print</span></span><span>(</span><span id="textcolor6682"><span>f</span></span><span id="textcolor6683"><span>"</span></span><span id="textcolor6684"><span>{</span></span><span>accuracy_standard</span><span id="textcolor6685"><span>=</span></span><span id="textcolor6686"><span>.2</span></span><span id="textcolor6687"><span>%</span></span><span id="textcolor6688"><span>}</span></span><span id="textcolor6689"><span>,</span><span>Â </span></span><span id="textcolor6690"><span>{</span></span><span>accuracy_fsgm</span><span id="textcolor6691"><span>=:</span></span><span id="textcolor6692"><span>.2%</span></span><span id="textcolor6693"><span>}</span></span><span id="textcolor6694"><span>"</span></span><span>)</span> <span id="x1-175056r8"></span> </code>
<code><span id="textcolor6695"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â accuracy_standard=83.67%,</span><span class="cmitt-10x-x-109">Â accuracy_fsgm=30.70%</span></span></code></pre>
<p>We can see that our standard model offers little protection against this adversarial attack. Although it performs pretty well on standard images, it has an accuracy of 30.70% on adversarial images! Letâ€™s see if a Bayesian model can do better. Because we trained our model with dropout, we can easily make it an MC dropout model. We create an inference function where we keep dropout at inference, as indicated by the <code>training=True</code> parameter:</p>
<pre id="fancyvrb256" class="fancyvrb"><span id="x1-175066r1"></span> 
<code><span id="textcolor6698"><span>import</span></span><span>Â </span><span id="textcolor6699"><span>numpy</span></span><span>Â </span><span id="textcolor6700"><span>as</span></span><span>Â </span><span id="textcolor6701"><span>np</span></span> <span id="x1-175068r2"></span> </code>
<code><span id="x1-175070r3"></span></code>
<code><span id="x1-175072r4"></span></code>
<code><span id="textcolor6702"><span>def</span></span><span>Â </span><span id="textcolor6703"><span>mc_dropout</span></span><span>(model,</span><span>Â images,</span><span>Â n_inference:</span><span>Â </span><span id="textcolor6704"><span>int</span></span><span>Â </span><span id="textcolor6705"><span>=</span></span><span>Â </span><span id="textcolor6706"><span>50</span></span><span>):</span> <span id="x1-175074r5"></span> </code>
<code><span>Â </span><span>Â </span><span id="textcolor6707"><span>return</span></span><span>Â np</span><span id="textcolor6708"><span>.</span></span><span>swapaxes(np</span><span id="textcolor6709"><span>.</span></span><span>stack([</span> <span id="x1-175076r6"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â model(images,</span><span>Â training</span><span id="textcolor6710"><span>=</span></span><span id="textcolor6711"><span>True</span></span><span>)</span><span>Â </span><span id="textcolor6712"><span>for</span></span><span>Â _</span><span>Â </span><span id="textcolor6713"><span>in</span></span><span>Â </span><span id="textcolor6714"><span>range</span></span><span>(n_inference)</span> <span id="x1-175078r7"></span> </code>
<code><span>Â </span><span>Â ]),</span><span>Â </span><span id="textcolor6715"><span>0</span></span><span>,</span><span>Â </span><span id="textcolor6716"><span>1</span></span><span>)</span></code></pre>
<p>With this function in place, we can replace the standard loop with MC dropout inference.<span id="dx1-175079"></span> We keep track of all our predictions again and run inference on our standard images and the adversarial images:</p>
<pre id="fancyvrb257" class="fancyvrb"><span id="x1-175092r1"></span> 
<code><span>Predictions_standard_mc,</span><span>Â predictions_fgsm_mc,</span><span>Â labels</span><span>Â </span><span id="textcolor6717"><span>=</span></span><span>Â [],</span><span>Â [],</span><span>Â []</span> <span id="x1-175094r2"></span> </code>
<code><span id="textcolor6718"><span>for</span></span><span>Â imgs,</span><span>Â labels_batch</span><span>Â </span><span id="textcolor6719"><span>in</span></span><span>Â test_dataset:</span> <span id="x1-175096r3"></span> </code>
<code><span>Â </span><span>Â imgs</span><span>Â </span><span id="textcolor6720"><span>/=</span></span><span>Â </span><span id="textcolor6721"><span>255.</span></span> <span id="x1-175098r4"></span> </code>
<code><span>Â </span><span>Â predictions_standard_mc</span><span id="textcolor6722"><span>.</span></span><span>extend(</span> <span id="x1-175100r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â mc_dropout(model,</span><span>Â imgs,</span><span>Â </span><span id="textcolor6723"><span>50</span></span><span>)</span> <span id="x1-175102r6"></span> </code>
<code><span>Â </span><span>Â )</span> <span id="x1-175104r7"></span> </code>
<code><span>Â </span><span>Â imgs_adv</span><span>Â </span><span id="textcolor6724"><span>=</span></span><span>Â fgsm(model,</span><span>Â imgs,</span><span>Â </span><span id="textcolor6725"><span>0.01</span></span><span>,</span><span>Â np</span><span id="textcolor6726"><span>.</span></span><span>inf)</span> <span id="x1-175106r8"></span> </code>
<code><span>Â </span><span>Â predictions_fgsm_mc</span><span id="textcolor6727"><span>.</span></span><span>extend(</span> <span id="x1-175108r9"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â </span><span>Â mc_dropout(model,</span><span>Â imgs_adv,</span><span>Â </span><span id="textcolor6728"><span>50</span></span><span>)</span> <span id="x1-175110r10"></span> </code>
<code><span>Â </span><span>Â )</span> <span id="x1-175112r11"></span> </code>
<code><span>Â </span><span>Â labels</span><span id="textcolor6729"><span>.</span></span><span>extend(labels_batch)</span></code></pre>
<p>And we can again print our accuracy:</p>
<pre id="fancyvrb258" class="fancyvrb"><span id="x1-175122r1"></span> 
<code><span>accuracy_standard_mc</span><span>Â </span><span id="textcolor6730"><span>=</span></span><span>Â CategoricalAccuracy()(</span> <span id="x1-175124r2"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â labels,</span><span>Â np</span><span id="textcolor6731"><span>.</span></span><span>stack(predictions_standard_mc)</span><span id="textcolor6732"><span>.</span></span><span>mean(axis</span><span id="textcolor6733"><span>=</span></span><span id="textcolor6734"><span>1</span></span><span>)</span> <span id="x1-175126r3"></span> </code>
<code><span>)</span><span id="textcolor6735"><span>.</span></span><span>numpy()</span> <span id="x1-175128r4"></span> </code>
<code><span>accuracy_fgsm_mc</span><span>Â </span><span id="textcolor6736"><span>=</span></span><span>Â CategoricalAccuracy()(</span> <span id="x1-175130r5"></span> </code>
<code><span>Â </span><span>Â </span><span>Â </span><span>Â labels,</span><span>Â np</span><span id="textcolor6737"><span>.</span></span><span>stack(predictions_fgsm_mc)</span><span id="textcolor6738"><span>.</span></span><span>mean(axis</span><span id="textcolor6739"><span>=</span></span><span id="textcolor6740"><span>1</span></span><span>)</span> <span id="x1-175132r6"></span> </code>
<code><span>)</span><span id="textcolor6741"><span>.</span></span><span>numpy()</span> <span id="x1-175134r7"></span> </code>
<code><span id="textcolor6742"><span>print</span></span><span>(</span><span id="textcolor6743"><span>f</span></span><span id="textcolor6744"><span>"</span></span><span id="textcolor6745"><span>{</span></span><span>accuracy_standard_mc</span><span id="textcolor6746"><span>=</span></span><span id="textcolor6747"><span>.2</span></span><span id="textcolor6748"><span>%</span></span><span id="textcolor6749"><span>}</span></span><span id="textcolor6750"><span>,</span><span>Â </span></span><span id="textcolor6751"><span>{</span></span><span>accuracy_fgsm_mc</span><span id="textcolor6752"><span>=:</span></span><span id="textcolor6753"><span>.2%</span></span><span id="textcolor6754"><span>}</span></span><span id="textcolor6755"><span>"</span></span><span>)</span> <span id="x1-175136r8"></span> </code>
<code><span id="textcolor6756"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â accuracy_standard_mc=86.60%,</span><span class="cmitt-10x-x-109">Â accuracy_fgsm_mc=80.75%</span></span></code></pre>
<p>We can see that our simple modification made the model setup much more robust to adversarial examples. Instead of an accuracy of around 30%, we now obtain accuracy of more than 80%, pretty close to the accuracy of 83% of the deterministic model on the non-perturbed images. Moreover, we can see that MC dropout also improves the accuracy on our standard images by a few percentage points, from 83% to 86%. Almost no method offers perfect robustness to adversarial examples, so the fact that we can get so close to our modelâ€™s standard accuracy is a great achievement.</p>
<p>Because our model has not seen the adversarial images before, a model with good uncertainty values should also have a lower confidence on average on the adversarial images compared to a standard model<span id="dx1-175137"></span>. Letâ€™s see if this is the case. We create a function to compute the average softmax value of the predictions of our deterministic model and create a similar function for our MC dropout predictions:</p>
<pre id="fancyvrb259" class="fancyvrb"><span id="x1-175150r1"></span> 
<code><span id="textcolor6757"><span>def</span></span><span>Â </span><span id="textcolor6758"><span>get_mean_softmax_value</span></span><span>(predictions)</span><span>Â </span><span id="textcolor6759"><span>-</span><em>&gt;</em></span><span>Â </span><span id="textcolor6760"><span>float</span></span><span>:</span> <span id="x1-175152r2"></span> </code>
<code><span>Â </span><span>Â mean_softmax</span><span>Â </span><span id="textcolor6761"><span>=</span></span><span>Â tf</span><span id="textcolor6762"><span>.</span></span><span>nn</span><span id="textcolor6763"><span>.</span></span><span>softmax(predictions,</span><span>Â axis</span><span id="textcolor6764"><span>=</span></span><span id="textcolor6765"><span>1</span></span><span>)</span> <span id="x1-175154r3"></span> </code>
<code><span>Â </span><span>Â max_softmax</span><span>Â </span><span id="textcolor6766"><span>=</span></span><span>Â np</span><span id="textcolor6767"><span>.</span></span><span>max(mean_softmax,</span><span>Â axis</span><span id="textcolor6768"><span>=</span></span><span id="textcolor6769"><span>1</span></span><span>)</span> <span id="x1-175156r4"></span> </code>
<code><span>Â </span><span>Â mean_max_softmax</span><span>Â </span><span id="textcolor6770"><span>=</span></span><span>Â max_softmax</span><span id="textcolor6771"><span>.</span></span><span>mean()</span> <span id="x1-175158r5"></span> </code>
<code><span>Â </span><span>Â </span><span id="textcolor6772"><span>return</span></span><span>Â mean_max_softmax</span> <span id="x1-175160r6"></span> </code>
<code><span id="x1-175162r7"></span></code>
<code><span id="x1-175164r8"></span></code>
<code><span id="textcolor6773"><span>def</span></span><span>Â </span><span id="textcolor6774"><span>get_mean_softmax_value_mc</span></span><span>(predictions)</span><span>Â </span><span id="textcolor6775"><span>-</span><em>&gt;</em></span><span>Â </span><span id="textcolor6776"><span>float</span></span><span>:</span> <span id="x1-175166r9"></span> </code>
<code><span>Â </span><span>Â predictions_np</span><span>Â </span><span id="textcolor6777"><span>=</span></span><span>Â np</span><span id="textcolor6778"><span>.</span></span><span>stack(predictions)</span> <span id="x1-175168r10"></span> </code>
<code><span>Â </span><span>Â predictions_np_mean</span><span>Â </span><span id="textcolor6779"><span>=</span></span><span>Â predictions_np</span><span id="textcolor6780"><span>.</span></span><span>mean(axis</span><span id="textcolor6781"><span>=</span></span><span id="textcolor6782"><span>1</span></span><span>)</span> <span id="x1-175170r11"></span> </code>
<code><span>Â </span><span>Â </span><span id="textcolor6783"><span>return</span></span><span>Â get_mean_softmax_value(predictions_np_mean)</span></code></pre>
<p>We can then print the mean softmax score for both models:</p>
<pre id="fancyvrb260" class="fancyvrb"><span id="x1-175180r1"></span> 
<code><span>mean_standard</span><span>Â </span><span id="textcolor6784"><span>=</span></span><span>Â get_mean_softmax_value(predictions_standard)</span> <span id="x1-175182r2"></span> </code>
<code><span>mean_fgsm</span><span>Â </span><span id="textcolor6785"><span>=</span></span><span>Â get_mean_softmax_value(predictions_fgsm)</span> <span id="x1-175184r3"></span> </code>
<code><span>mean_standard_mc</span><span>Â </span><span id="textcolor6786"><span>=</span></span><span>Â get_mean_softmax_value_mc(predictions_standard_mc)</span> <span id="x1-175186r4"></span> </code>
<code><span>mean_fgsm_mc</span><span>Â </span><span id="textcolor6787"><span>=</span></span><span>Â get_mean_softmax_value_mc(predictions_fgsm_mc)</span> <span id="x1-175188r5"></span> </code>
<code><span id="textcolor6788"><span>print</span></span><span>(</span><span id="textcolor6789"><span>f</span></span><span id="textcolor6790"><span>"</span></span><span id="textcolor6791"><span>{</span></span><span>mean_standard</span><span id="textcolor6792"><span>=:</span></span><span id="textcolor6793"><span>.2%</span></span><span id="textcolor6794"><span>}</span></span><span id="textcolor6795"><span>,</span><span>Â </span></span><span id="textcolor6796"><span>{</span></span><span>mean_fgsm</span><span id="textcolor6797"><span>=:</span></span><span id="textcolor6798"><span>.2%</span></span><span id="textcolor6799"><span>}</span></span><span id="textcolor6800"><span>"</span></span><span>)</span> <span id="x1-175190r6"></span> </code>
<code><span id="textcolor6801"><span>print</span></span><span>(</span><span id="textcolor6802"><span>f</span></span><span id="textcolor6803"><span>"</span></span><span id="textcolor6804"><span>{</span></span><span>mean_standard_mc</span><span id="textcolor6805"><span>=:</span></span><span id="textcolor6806"><span>.2%</span></span><span id="textcolor6807"><span>}</span></span><span id="textcolor6808"><span>,</span><span>Â </span></span><span id="textcolor6809"><span>{</span></span><span>mean_fgsm_mc</span><span id="textcolor6810"><span>=:</span></span><span id="textcolor6811"><span>.2%</span></span><span id="textcolor6812"><span>}</span></span><span id="textcolor6813"><span>"</span></span><span>)</span> <span id="x1-175192r7"></span> </code>
<code><span id="textcolor6814"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â mean_standard=89.58%,</span><span class="cmitt-10x-x-109">Â mean_fgsm=89.91%</span></span> <span id="x1-175194r8"></span> </code>
<code><span id="textcolor6815"><span class="cmitt-10x-x-109">#</span><span class="cmitt-10x-x-109">Â mean_standard_mc=89.48%,</span><span class="cmitt-10x-x-109">Â mean_fgsm_mc=85.25%</span></span></code></pre>
<p>We can see that our standard model is actually slightly more confident on adversarial images compared to standard images, although its accuracy dropped significantly. However, our MC dropout model shows a lower confidence on the adversarial images compared to the standard images. Although the drop in confidence is not very large, it is good to see that the model is dropping its mean confidence on adversarial images, while keeping a reasonable accuracy. <span id="x1-175195r269"></span></p>
</section>
</section>
<section id="summary-7" class="level2 sectionHead" data-number="13.7">
<h2 class="sectionHead" data-number="13.7" id="sigil_toc_id_99"><span class="titlemark">8.7 </span> <span id="x1-1760007"></span>Summary</h2>
<p>In this chapter, we have illustrated the various applications of modern BDL in five different case studies. Each case study used code examples to highlight a particular strength of BDL in response to various, common problems in applied machine learning practice. First, we saw how BDL can be used to detect out-of-distribution images in a classification task. We then looked at how BDL methods can be used to make models more robust to dataset shift, which is a very common problem in production environments. Next, we learned how BDL can help us to select the most informative data points for training and updating our machine learning models. We then turned to reinforcement learning and saw how BDL can be used to facilitate more cautious behaviour in reinforcement learning agents. Finally, we saw how BDL can help us in the face of adversarial attacks.</p>
<p>In the next chapter, we will have a look at the future of BDL by reviewing current trends and the latest methods. <span id="x1-176001r272"></span></p>
</section>
<section id="further-reading-5" class="level2 sectionHead" data-number="13.8">
<h2 class="sectionHead" data-number="13.8" id="sigil_toc_id_100"><span class="titlemark">8.8 </span> <span id="x1-1770008"></span>Further reading</h2>
<p>The following reading list will offer a greater understanding of some of the topics we touched on in this chapter:</p>
<ul>
<li><p><em>Benchmarking neural network robustness to common corruptions and</em> <em>perturbations</em>, Dan Hendrycks and Thomas Dietterich, 2019: this is the paper that introduced the image quality perturbations to benchmark model robustness, which we saw in the robustness case study.</p></li>
<li><p><em>Can You Trust Your Modelâ€™s Uncertainty? Evaluating predictive</em> <em>Uncertainty Under Dataset Shift</em>, Yaniv Ovadia, Emily Fertig <em>et</em> <em>al.</em>, 2019: this comparison paper uses image quality perturbations to introduce artificial dataset shift at different severity levels and measures how different deep neural networks respond to dataset shift in terms of accuracy and calibration.</p></li>
<li><p><em>A Baseline for Detecting Misclassified and Out-of-Distribution</em> <em>Examples in Neural Networks</em>, Dan Hendrycks and Kevin Gimpel, 2016: this fundamental out-of-distribution detection paper introduces the concept and shows that softmax values are not perfect when it comes to OOD detection.</p></li>
<li><p><em>Enhancing The Reliability of Out-of-distribution Image Detection in</em> <em>Neural Networks</em>, Shiyu Liang, Yixuan Li and R. Srikant, 2017: shows that input perturbation and temperature scaling can improve the softmax baseline for out-of-distribution detection.</p></li>
<li><p><em>A Simple Unified Framework for Detecting Out-of-Distribution</em> <em>Samples and Adversarial Attacks</em>, Kimin Lee, Kibok Lee, Honglak Lee and Jinwoo Shin, 2018: shows that using the Mahalanobis distance can be effective for out-of-distribution detection.</p></li>
</ul>
<p><span id="x1-177001r214"></span></p>
</section>
</section>
</body>
</html>