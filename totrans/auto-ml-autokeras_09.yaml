- en: '*Chapter 7*: Sentiment Analysis Using AutoKeras'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by defining the unusual term in the title. **Sentiment analysis**
    is a term that's widely used in text classification and it is basically about
    using **natural language processing** (**NLP**) in conjunction with **machine
    learning** (**ML**) to interpret and classify emotions in text.
  prefs: []
  type: TYPE_NORMAL
- en: To get an idea of this, let's imagine the task of determining whether a review
    for a film is positive or negative. You could do this yourself just by reading
    it, right? However, if our boss sends us a list of 1,000 movie reviews for tomorrow,
    things become complicated. That's where sentiment analysis becomes an interesting
    option.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will use a text classifier to extract sentiments from text
    data. Most of the concepts of text classification were already explained in [*Chapter
    4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063), *Image Classification and
    Regression Using AutoKeras*, so in this chapter, we will apply them in a practical
    way by implementing a sentiment predictor. However, before we do that, we will
    look at the technical requirements we'll need to start working on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, the following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a sentiment analyzer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing the sentiment in specific sentences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the code examples in this book are available as Jupyter notebooks that can
    be downloaded from [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras).
  prefs: []
  type: TYPE_NORMAL
- en: Since code cells can be executed, each notebook can be self-installed; you just
    need to add the code snippet with the requirements you need. For this reason,
    at the beginning of each notebook, there is a code cell for environment setup
    that installs AutoKeras and its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to run the code examples for this chapter, you only need a computer with
    Ubuntu Linux as your OS and install the Jupyter Notebook with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, you can also run these notebooks using Google Colaboratory, in
    which case you will only need a web browser. See the *AutoKeras with Google Colaboratory*
    section of [*Chapter 2*](B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029), *Getting
    Started with AutoKeras*, for more details. Furthermore, in the *Installing AutoKeras*
    section of that chapter, you will find other installation options.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's put what we've learned into practice by looking at some practical
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a sentiment analyzer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The model we are going to create will be a binary classifier for sentiments
    (1=Positive/0=Negative) from the IMDb sentiments dataset. This is a dataset for
    binary sentiment classification that contains a set of 25,000 sentiment labeled
    movie reviews for training and 25,000 for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Example of sentiment analysis being used on two samples](img/B16953_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Example of sentiment analysis being used on two samples
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the Reuters example from [*Chapter 4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063),
    *Image Classification and Regression Using AutoKeras*, each review is encoded
    as a list of word indexes (integers). For convenience, words are indexed by their
    overall frequency in the dataset. So, for instance, the integer *3* encodes the
    third most frequent word in the data.
  prefs: []
  type: TYPE_NORMAL
- en: The notebook that contains the complete source code can be found at [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s have a look at the relevant cells of the notebook in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Installing AutoKeras**: As we''ve mentioned in other examples, this snippet
    at the top of the notebook is responsible for installing AutoKeras and its dependencies
    using the pip package manager:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Importing the necessary packages**: The following lines load TensorFlow,
    the built-in Keras Reuters dataset, NumPy, and AutoKeras as needed dependencies
    for this project:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`imdb_sentiment_raw` function. Have a look at the code in the notebook for
    more details:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Showing some samples**: Next, we can print some words from the first sample
    to get an idea of what it contains:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To see this more clearly, let''s render a word cloud with the most frequent
    words. A word cloud (also known as a tag cloud) is a text-based data visualization
    technique, in which words are displayed in different sizes based on how often
    they appear in the text:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – A word cloud containing the most frequent words of the dataset](img/B16953_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – A word cloud containing the most frequent words of the dataset
  prefs: []
  type: TYPE_NORMAL
- en: Now, it's time to create the classifier model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the sentiment predictor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we will use the AutoKeras `TextClassifier` to find the best classification
    model. Just for this example, we will set `max_trials` (the maximum number of
    different Keras models to try) to `2`; we do not need to set the epochs parameter;
    instead, we must define an `EarlyStopping` callback of `2` epochs so that the
    training process stops if the validation loss does not improve in two consecutive
    epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run the training process and search for the optimal classifier for the
    training dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Notebook output of text classifier training](img/B16953_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Notebook output of text classifier training
  prefs: []
  type: TYPE_NORMAL
- en: The previous output shows that the accuracy of the training dataset is increasing.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, we are getting a loss of `0.28` in the validation set. This isn't
    bad just for a few minutes of training. We have limited the search to two architectures
    (`max_trials = 2`). As with the rest of the examples, increasing this number would
    give us a more accurate model, although it would also take longer to finish.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, it''s time to evaluate the best model with the testing dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, `0.8724` is a really good final prediction accuracy for the time
    we've invested.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we can view a little summary of the architecture for the best generated
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Best model architecture summary](img/B16953_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Best model architecture summary
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, AutoKeras, as we did in the classification example in [*Chapter
    4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063), *Image Classification and
    Regression Using AutoKeras*, has chosen a convolution model (Conv1D) for this
    task. As we explained in the beginning of that chapter, this kind of architecture
    works really well when the order of the input sentences is not important for the
    prediction; there are no correlations between the different movie reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a visual representation of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Best model architecture visualization graph](img/B16953_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Best model architecture visualization graph
  prefs: []
  type: TYPE_NORMAL
- en: As you already know, generating the models and choosing the best one is done
    by AutoKeras automatically, but let's explain these blocks in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Each block represents a layer and the output of each is connected to the input
    of the next except for the first block, whose input is the text, and the last
    block, whose output is the predicted number. The blocks before Conv1D are all
    data preprocessing blocks and they are in charge of vectorizing the text generating
    embeddings to feed this Conv1D block, as well as reducing the dimension of the
    filters through the max pooling layer. Notice that AutoKeras has also added several
    dropout blocks to reduce overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the sentiment in specific sentences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at some predicted samples from the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Some predictions based on the first 10 sentences of the test
    dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_07_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.6 – Some predictions based on the first 10 sentences of the test dataset
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the model predictions match every label for the first 10 samples
    in the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the importance of sentiment analysis in the
    real world, as well as how to extract sentiments from text data and how to implement
    a sentiment predictor in just a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will cover a very interesting topic: we will use AutoKeras
    to classify news topics based on their content by using a text classifier.'
  prefs: []
  type: TYPE_NORMAL
