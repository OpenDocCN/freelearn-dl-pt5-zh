<html><head></head><body>
  <div id="_idContainer380">
    <h1 class="chapterNumber">15</h1>
    <h1 id="_idParaDest-291" class="chapterTitle">Setting Up a Cognitive NLP UI/CUI Chatbot</h1>
    <p class="normal">There are 300,000+ chatbots on Facebook alone. Adding another brick in that wall means next to nothing unless you give your chatbot a purpose and provide it with real content. Cognitive content represents the core goal of attracting more attention than your hundreds of thousands of competitors and SEO experts. We will put RBM-PCA chained algorithms to work in this chapter to bring a chatbot to another level. We will use the information provided by the RBM-PCA to design our dialog.</p>
    <p class="normal">As you will discover in this first section, creating an agent with Dialogflow and beginning a dialog represents no effort at all. Google Dialogflow provides the intuitive features to get a chatbot running in no time. The Dialogflow tutorial can guide you to reach this simple goal in a few minutes. Understanding what an agent is, teaching it to ask a question, and providing an answer can be done by a 10-year-old child. I experimented with this by letting a 5-year-old and a 9-year-old child loose on this software. They both did not even realize it was work. They were having fun!</p>
    <p class="normal">On Dialogflow, you don't need to know how to program, and you don't need to be a linguist or any other kind of expert. So, what will your market differentiation be? <em class="italics">Content</em>. Your chatbot needs to have a purpose, with well-prepared content beyond asking and answering simple questions.</p>
    <p class="normal">Beyond creating your first dialog, the goal of this chapter will provide you with a sense of purpose and content that will help you produce meaningful chatbots.</p>
    <p class="normal">That being said, let's create an agent together and a short dialog to illustrate both how to create a chatbot and also to provide meaningful content.</p>
    <p class="normal">The following topics will be covered in this chapter:</p>
    <ul>
      <li class="list">Creating a cognitive agent based on the preparation of <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em></li>
      <li class="list">Learning the basic concepts of Dialogflow and chatbots in general</li>
      <li class="list">Deploying the chatbot on your website</li>
    </ul>
    <p class="normal">We will start with basic concepts and then create an agent with entities, intents, dialogs, and a fulfillment function. We will be using the preparation established in the previous chapter. We will test its UI with spelling correction and dialogs. Then, we will test the chatbot's <strong class="bold">conversational user interface</strong> (<strong class="bold">CUI</strong>) capability by setting up machine learning speech recognition and speech functions.</p>
    <h1 id="_idParaDest-292" class="title">Basic concepts</h1>
    <p class="normal">Before creating an agent, we'll want to have an understanding of the basic concepts.</p>
    <p class="normal">This is not a Dialogflow course, but rather an introductory chapter to get us started on making our own NLP CUI chatbot. We'll begin by defining some key terms.</p>
    <h2 id="_idParaDest-293" class="title">Defining NLU</h2>
    <p class="normal"><strong class="bold">NLU</strong> means <strong class="bold">natural language understanding</strong>. NLU <a id="_idIndexMarker715"/>is a subset of <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>). Natural<a id="_idIndexMarker716"/> language refers to the everyday language we use without having to force ourselves to learn precise words in order to obtain information from a machine.</p>
    <p class="normal">If we had to learn a dictionary of the only words that would work with a system, it would be easier just to read a text. NLP encompasses all forms of natural language processing including NLU. Through AI, NLU has become more involved in trying to understand what a given sentence means.</p>
    <h2 id="_idParaDest-294" class="title">Why do we call chatbots "agents"?</h2>
    <p class="normal">A chatbot entails a chat <a id="_idIndexMarker717"/>between at least two parties. In our case, the bot is an NLU module. That's not a very nice marketing way to put it. It sounds like: "you are now talking to an NLU module." You cannot pretend a bot is a person. The word <em class="italics">agent</em> conveys the impression of a business agent, a sports agent, or a secret agent, which is mysterious! It came to mean a computer system that gathers information. Now it's an NLP agent with NLU capability.</p>
    <h2 id="_idParaDest-295" class="title">Creating an agent to understand Dialogflow</h2>
    <p class="normal">The fastest way to <a id="_idIndexMarker718"/>learn Dialogflow<a id="_idIndexMarker719"/> is to create a dialog from scratch. Log into Dialogflow and go to the console. The following is part of a screenshot of Dialogflow's dashboard. You can see the link to the console on the top right:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.1: Accessing Dialogflow's console</p>
    <p class="normal">Once you click on <strong class="screen-text">Go to console</strong>, you will be asked to sign in if you haven't signed in yet. A Google account is a prerequisite:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_02.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.2: Signing in with a Google account</p>
    <p class="normal">Once you have followed the sign in instructions and are signed in, you will reach the Dialogflow console.</p>
    <p class="normal">Click on the drop-down list in the top-right corner, irrespective of which default agent is displayed. A list of existing or default agents will be displayed:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_03.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.3: The list of agents</p>
    <p class="normal">Scroll down the list until you reach <strong class="screen-text">Create new agent</strong> (if none, click on the <strong class="screen-text">Create agent</strong> option). Click on <strong class="screen-text">Create new agent</strong>, and you will reach the following window:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_04.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.4: Entering the agent's name</p>
    <p class="normal">Call the <a id="_idIndexMarker720"/>agent <code class="Code-In-Text--PACKT-">Agent + &lt;your name or initials&gt;</code> to make sure you <a id="_idIndexMarker721"/>will have a unique name. I will call the one for this chapter <code class="Code-In-Text--PACKT-">cogfilmdr</code>. The agent in the chapter will thus be referred to as <code class="Code-In-Text--PACKT-">cogfilmdr</code>. Let Google create a default agent structure with English as the main language.</p>
    <p class="normal">Once that is done, click on the settings button in the top left:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_05.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.5: The settings button</p>
    <p class="normal">You will reach the configuration window of your agent.</p>
    <p class="normal">For the moment, we just have one important option to check. The version of the API must be V2 API. V1 API will shut down on March 2020:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_06.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.6: Using the V2 API</p>
    <p class="normal">The agent is now created, and we can create entities.</p>
    <h2 id="_idParaDest-296" class="title">Entities</h2>
    <p class="normal">Most chatbot<a id="_idIndexMarker722"/> tutorials explain intents first. I do not agree. Once you know where you're going, in this case, choosing a movie based on <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>, it makes sense to build some bricks before building your structure.</p>
    <p class="normal">Dialogflow (or any chatbot) uses entities to extract useful information in a user's utterance (not necessarily a sentence) to understand their motivation.</p>
    <p class="normal">We will use the entities created in <em class="italics">Chapter 14</em>. We will first create an entity named <code class="Code-In-Text--PACKT-">movies</code> that will contain the 10 target movies used in <em class="italics">Chapter 14</em>.</p>
    <pre class="programlisting"><code class="hljs ebnf"><span class="hljs-attribute">    titles</span>=[<span class="hljs-string">"24H in Kamba"</span>,<span class="hljs-string">"Lost"</span>,<span class="hljs-string">"Cube Adventures"</span>,
            <span class="hljs-string">"A Holiday"</span>,<span class="hljs-string">"Jonathan Brooks"</span>,
            <span class="hljs-string">"The Melbourne File"</span>, <span class="hljs-string">"WNC Detectives"</span>,
            <span class="hljs-string">"Stars"</span>,<span class="hljs-string">"Space L"</span>,<span class="hljs-string">"Zone 77"</span>]
</code></pre>
    <p class="normal">Click on <strong class="screen-text">Entities</strong> on the left-hand side of the window:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_07.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.7: Dialogflow menu</p>
    <p class="normal">Then, click <a id="_idIndexMarker723"/>on <strong class="screen-text">CREATE ENTITY</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.8: Creating an entity</p>
    <p class="normal">You will be asked to provide an entity name:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_09.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.9: Entering the name of entity</p>
    <p class="normal">Enter <code class="Code-In-Text--PACKT-">movies</code>. Before saving the entity, we must enter the movies we have chosen:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_10.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.10: Entity list</p>
    <p class="normal">You will notice that once you add a movie, a default synonym is filled in automatically. You can add other synonyms if you wish.</p>
    <p class="normal">Once the titles are <a id="_idIndexMarker724"/>entered, click on the <strong class="screen-text">SAVE</strong> button, which is mandatory (it is not an auto-save interface):</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_11.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.11: Saving an entity</p>
    <p class="normal">We will now create the feature entity. The features in the <code class="Code-In-Text--PACKT-">RBM.py</code> program in <em class="italics">Chapter 14</em> were as follows:</p>
    <pre class="programlisting"><code class="hljs pgsql"># <span class="hljs-keyword">Each</span> <span class="hljs-keyword">column</span> <span class="hljs-keyword">is</span> a feature. There are <span class="hljs-number">6</span> features: [<span class="hljs-string">'love'</span>, <span class="hljs-string">'happiness'</span>, <span class="hljs-string">'family'</span>, <span class="hljs-string">'horizons'</span>, <span class="hljs-string">'action'</span>, <span class="hljs-string">'violence'</span>]
</code></pre>
    <p class="normal">We will name it <code class="Code-In-Text--PACKT-">features</code>, follow the same process as for the <code class="Code-In-Text--PACKT-">movies</code> entity, and then click on <strong class="screen-text">SAVE</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_12.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.12: Creating a feature entity</p>
    <p class="normal">Click on <strong class="screen-text">Entities</strong> under <a id="_idIndexMarker725"/>your agent, and you will see a list of entities for the agent, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_13.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.13: List of entities</p>
    <p class="normal">If you click an entity, a list of possible choices will appear.</p>
    <p class="normal">Now that your agent knows the movie and feature entities, creating the intents makes sense.</p>
    <h2 id="_idParaDest-297" class="title">Intents</h2>
    <p class="normal">An intent<a id="_idIndexMarker726"/> is a clear formulation intention to do something. I named the agent <code class="Code-In-Text--PACKT-">cogfilmdr</code>. For the agent, the user's intention may be to ask for a movie to watch.</p>
    <p class="normal">To trigger a response, we must enter training phrases.</p>
    <p class="normal"><strong class="bold">Training phrases</strong> are groups<a id="_idIndexMarker727"/> of words that the user will enter through text or speech. The more sentences you enter, the better your chatbot will become. This is why starting with a ready-to-use Dialogflow makes sense if an existing agent satisfies your needs.</p>
    <p class="normal">To create our sample dialog, we will use the dataset results supplied on GitHub for <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>. The main terms have been extracted with their features that we displayed with TensorBoard. When we extracted the data from the RBM, we sorted the features as follows:</p>
    <pre class="programlisting"><code class="hljs yaml"><span class="hljs-attr">Love:</span> <span class="hljs-number">643</span>
<span class="hljs-attr">Happiness:</span> <span class="hljs-number">2267</span>
<span class="hljs-attr">Family:</span> <span class="hljs-number">0</span>
<span class="hljs-attr">Horizons:</span> <span class="hljs-number">1521</span>
<span class="hljs-attr">Action:</span> <span class="hljs-number">2976</span>
<span class="hljs-attr">Violence:</span> <span class="hljs-number">4594</span>
</code></pre>
    <p class="normal">We displayed the feature space in a PCA:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_14.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.14: TensorBoard representation of features</p>
    <div class="note">
      <p class="Information-Box--PACKT-"><strong class="bold">Reminder</strong>: This<a id="_idIndexMarker728"/> result will naturally change if <code class="Code-In-Text--PACKT-">RBM_launcher.py</code> runs again since it's a random viewer-movie choice process.</p>
    </div>
    <p class="normal">When starting a chatbot project, it is best to be very careful with going straight to generating dialogs automatically. It is much better to start with a simple, well-structured chatbot that works on a limited amount of tasks. I call this a "closed chatbot" meaning that we control every aspect of dialog. An "open chatbot" means that information flows in automatically to create automatic dialogs. That can be a goal after getting the chatbot to run as a "closed chatbot" for some time using the information prepared with AI algorithms.</p>
    <p class="normal">The results of the work we did in <em class="italics">Chapter 14</em> provide interesting information on the marketing segment we are targeting for the chatbot.</p>
    <p class="normal">Violence and action point to action movies. Family=0 points to younger viewers, teenagers, for example, more interested in action than creating a family. Discovering happiness and love is part of the horizons they are looking for. This is typical of superhero series and movies. Superheroes are often solitary individuals.</p>
    <p class="normal">We will now create an<a id="_idIndexMarker729"/> intent by entering the <strong class="screen-text">Intents</strong> window:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_15.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.15: Choosing the Intents option</p>
    <p class="normal">The <strong class="screen-text">Intents</strong> window appears. Click on <strong class="screen-text">CREATE INTENT</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_16.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.16: Creating an intent</p>
    <p class="normal">The intent window will appear to create a question-and-answer dialog in a few steps:</p>
    <ul>
      <li class="list">First, enter <code class="Code-In-Text--PACKT-">choose_movie</code> as the name of the intent.</li>
      <li class="list">Then, in the training phrases section, enter: "I would like to watch one of your movies."</li>
    </ul>
    <p class="normal">At this point, we have an intent name and a possible user question:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_17.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.17: Entering intent information</p>
    <p class="normal">Now, we need to provide a<a id="_idIndexMarker730"/> response based on the statistics for this market segment we drew from <em class="italics">Chapter 14</em>. We will use the word <em class="italics">action</em> to encompass a movie that contains violence and a happy ending as in the typical superhero movies. To do that, scroll down to the <strong class="screen-text">Text Response</strong> section to add a response and enter "Would you like to watch an action movie?", as shown in the following screenshot:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_18.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.18: Entering the text response</p>
    <p class="normal">Now that we have a basic dialog, let's save and test it. To do that, go to the test console in the top right of the console window:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_19.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.19: Test console</p>
    <p class="normal">We can use a CUI or text:</p>
    <ul>
      <li class="list"><strong class="bold">Text dialog</strong>: Enter the <a id="_idIndexMarker731"/>user phrase: "I would like to watch one of your movies."<p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">The user will be surprised to see the agent's answer, which is, "Would you like to watch an action movie?"</p>
      </li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B15438_15_20.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.20: Responses</p>
    <p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">This suggestion comes as a surprise for the user and might seem strange. This is because the RBM-PCA approach we used to prepare the dialog targets a market segment.</p>
    <p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">Advanced machine learning shortens the path of a user request to a satisfactory response. It constitutes both a time saving and an energy saving process for the user.</p>
    <ul>
      <li class="list"><strong class="bold">CUI</strong>: Click on <a id="_idIndexMarker732"/>the microphone icon in the test console. Make sure that this microphone is authorized, or it will not work:</li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B15438_15_21.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.21: Microphone</p>
    <p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">When you click on the microphone, this will trigger a recording of your request. Say, "I would like to watch one of your movies." Then, click on the stop button to stop the recording. The response to the request will appear:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_22.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.22: Text responses</p>
    <p class="normal">To answer the question, we will need to use the context functionality of Dialogflow.</p>
    <h2 id="_idParaDest-298" class="title">Context</h2>
    <p class="normal">Context <a id="_idIndexMarker733"/>means that Dialogflow is going to remember a dialog and use follow-up exchanges without starting from scratch each time.</p>
    <p class="normal">The user has asked to watch a movie, and the bot suggested an action movie. The bot will remember this through context as it continues the dialog.</p>
    <p class="normal">Click on the agent's <strong class="screen-text">Intent</strong> in the menu and hover over <strong class="screen-text">choose_movie</strong>. You will see <strong class="screen-text">Add follow-up intent</strong> appear. This means that all of the variables of the main intent can be stored, and a follow-up intent added that would remember what was said previously, just like us in a conversation.</p>
    <p class="normal">Click on <strong class="screen-text">Add follow-up intent</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_23.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.23: Add follow-up intent button</p>
    <p class="normal">In this case, the <a id="_idIndexMarker734"/>agent has planned two cases, <em class="italics">yes</em> or <em class="italics">no</em>. We will explore the <em class="italics">yes</em> answers in this chapter, and the more complex <em class="italics">no</em> answers in <em class="italics">Chapter 16</em>, <em class="italics">Improving the Emotional Intelligence Deficiencies of Chatbots</em>.</p>
    <p class="normal">In <em class="italics">Chapter 14</em>, we created a movie feature matrix with the movie titles and features:</p>
    <pre class="programlisting"><code class="hljs angelscript">    # Part I Feature extractions <span class="hljs-keyword">from</span> data sources
    # The titles of <span class="hljs-number">10</span> movies
    titles=[<span class="hljs-string">"24H in Kamba"</span>,<span class="hljs-string">"Lost"</span>,<span class="hljs-string">"Cube Adventures"</span>,
            <span class="hljs-string">"A Holiday"</span>,<span class="hljs-string">"Jonathan Brooks"</span>,
            <span class="hljs-string">"The Melbourne File"</span>, <span class="hljs-string">"WNC Detectives"</span>,
            <span class="hljs-string">"Stars"</span>,<span class="hljs-string">"Space L"</span>,<span class="hljs-string">"Zone 77"</span>]
    # The feature map of each of the <span class="hljs-number">10</span> movies. Each line <span class="hljs-keyword">is</span> a movie.
    # Each column <span class="hljs-keyword">is</span> a feature. There are <span class="hljs-number">6</span> features: [<span class="hljs-string">'love'</span>, <span class="hljs-string">'happiness'</span>, <span class="hljs-string">'family'</span>, <span class="hljs-string">'horizons'</span>, <span class="hljs-string">'action'</span>, <span class="hljs-string">'violence'</span>]
    # <span class="hljs-number">1</span>= the feature <span class="hljs-keyword">is</span> activated, <span class="hljs-number">0</span>= the feature <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> activated
    movies_feature_map = np.<span class="hljs-built_in">array</span>([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
                                   [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])
</code></pre>
    <p class="normal">We now need to transpose this information in a chart we can use to add content depth to the dialog:</p>
    <table id="table001-9" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">MOVIE/FEATURE</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">LOVE</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">HAPPINESS</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">FAMILY</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">HORIZONS</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">ACTION</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">VIOLENCE</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">24H in Kamba</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Lost</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Cube Adventures</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">A Holiday</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Jonathan Brooks</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">The Melbourne File</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">WNC Detectives</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Stars</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Space L</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <p class="content">Zone 77</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">0</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">We have already surprised the user a bit by proposing an action movie directly without going through tedious lists. We are using all of the information we obtained through inputs, intermediate AI outputs, and final outputs.</p>
    <p class="normal">Now, we are going even further by filtering the movies that fit the action-violence-happiness features extracted with the RBM-PCA chained algorithms.</p>
    <p class="normal">Only the following <a id="_idIndexMarker735"/>movies in the chart match action-violence-happiness:</p>
    <ul>
      <li class="list">24H in Kamba</li>
      <li class="list">Lost</li>
      <li class="list">A Holiday</li>
      <li class="list">Zone 77</li>
    </ul>
    <p class="normal">At random, we will choose "Zone 77." Once we have entered many possibilities, a random choice can be suggested either in the response area or with scripts. This development is beyond the scope of this chapter. For this example, we suppose it is probable that the viewer will be satisfied with this suggestion we make. We are in a <em class="italics">yes</em> scenario of the dialog. In <em class="italics">Chapter 16</em>, <em class="italics">Improving the Emotional Intelligence Deficiencies of Chatbots</em>, we will explore the <em class="italics">no</em> scenarios of this dialog, which requires more cognitive designing to keep the satisfaction path short.</p>
    <p class="normal">For the moment, let's suggest "Zone 77." To do this:</p>
    <ol>
      <li class="list">Click on <strong class="screen-text">Add follow-up intent</strong>.</li>
      <li class="list">Select <strong class="screen-text">yes</strong>.</li>
    </ol>
    <p class="normal">You now have a follow-up intent linked to the dialog:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_24.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.24: Follow-up intents</p>
    <p class="normal">Click on <strong class="screen-text">choose_movie - yes</strong>. The intent will appear. You will notice that Dialogflow has already filled in several <a id="_idIndexMarker736"/>forms of <em class="italics">yes</em> in the <strong class="screen-text">Training phrases</strong> section, as shown in the following screenshot:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_25.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.25: Training phrases</p>
    <p class="normal">All that is left to do in this scenario is to scroll down to the <strong class="screen-text">Responses</strong> section and add our answer:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_26.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.26: Text response</p>
    <p class="normal">Now, we go back to <a id="_idIndexMarker737"/>the intent and add a <em class="italics">yes</em> follow-up to this follow-up to process the viewer's <em class="italics">yes</em> answer, just as we did previously:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_27.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.27: Follow-up intents</p>
    <p class="normal">Now, we click on <strong class="screen-text">choose_movie - yes - yes</strong>, and we will see the <em class="italics">yes</em> answers that Dialogflow prepared for us:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_28.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.28: Training phrases for a follow-up intent</p>
    <p class="normal">However, this time, we would like to answer with a script and not an answer we type in.</p>
    <p class="normal">To do that, we can use fulfillment.</p>
    <h1 id="_idParaDest-299" class="title">Adding fulfillment functionality to an agent</h1>
    <p class="normal">A dialog can quickly <a id="_idIndexMarker738"/>become boring in everyday life and even<a id="_idIndexMarker739"/> more so in a chatbot. When we begin to guess everything that an interlocutor has to say, our mind slowly drifts away. We cannot help it. Humans are a curious species. <strong class="bold">Fulfillment</strong> will change the perspective of dialog. That is what I call <em class="italics">purpose</em> beyond the pragmatic approach that says fulfillment adds business logic to a dialog. </p>
    <p class="normal">To make the dialog sustainable, even from a practical point of view, it has to excite the user enough to want it to come back and discover more about your chatbot beyond obtaining business information from it.</p>
    <p class="normal">If you look <strong class="bold">fulfilling</strong> up in a dictionary, you will find that it means providing happiness or satisfaction, which is exactly the feeling of purpose you want your chatbot to convey.</p>
    <p class="normal">That being said, there <a id="_idIndexMarker740"/>is work to do in order to reach that goal. Dialogflow<a id="_idIndexMarker741"/> provides a wide array of tools to reach fulfillment for the user, the designer, and the developers.</p>
    <p class="normal">To start with, Dialogflow uses an inbuilt, seamless version of Node.js for fulfilling functions.</p>
    <h2 id="_idParaDest-300" class="title">Defining fulfillment</h2>
    <p class="normal">Various fulfillment or<a id="_idIndexMarker742"/> additional dialog functions are available:</p>
    <ul>
      <li class="list"><strong class="bold">Webhook</strong>: A webhook<a id="_idIndexMarker743"/> is an event transmitted via HTTP. It is sent as a <code class="Code-In-Text--PACKT-">POST</code>, which contains data posted to a predetermined URL. It works as an HTTP callback. The data sent to the URL will be parsed by a script on the server side. Once the service has processed the information, it will perform an action and send data back as a response.<p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">We will not use the webhook for this example. However, it is important to note that you can use a webhook to create dialogs of your own in another environment. You can even generate automatic dialogs and call them from Dialogflow.</p>
        <p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">If you are interested in preparing dialogs and uploading them, you can go to the <strong class="screen-text">Training</strong> page of the agent on the left-hand side of the screen and upload phrases:</p>
      </li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B15438_15_29.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.29: Training window</p>
    <p class="Bullet-Without-Bullet-Within-Bullet--PACKT-">You can also upload an agent or even a prebuilt agent designed by Google Dialogflow. For our example, we will use the inline editor.</p>
    <ul>
      <li class="list"><strong class="bold">Fulfillment with the inline Node.js editor</strong>: Defining a webhook URL can be the simplest approach. However, using the<a id="_idIndexMarker744"/> inline editor provides Node.js functionality for even more potential.</li>
      <li class="list"><strong class="bold">Fulfillment with the inline Node.js editor and Cloud Functions for Firebase</strong>: The inline Node.js can call a large variety of Cloud Functions for Firebase in a few time-saving lines of code.</li>
    </ul>
    <h2 id="_idParaDest-301" class="title">Enhancing the cogfilmdr agent with a fulfillment webhook</h2>
    <p class="normal">When the user <a id="_idIndexMarker745"/>answers <em class="italics">yes</em> to watch "Zone 77," we <a id="_idIndexMarker746"/>can answer with a response or a link to a website. To use a response, go to the yes - yes follow-up of our dialog in the <strong class="screen-text">Intents</strong> window:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_30.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.30: Intents and follow-up intents</p>
    <p class="normal">Click on <strong class="screen-text">choose_movie - yes - yes</strong> and scroll down to <strong class="screen-text">Text Response</strong> and add a response such as "Sure, click on the movie and watch it," as shown in the following screenshot:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_31.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.31: Text response</p>
    <p class="normal">We would also decide that this is final and that it is the end of the conversation by activating the <strong class="screen-text">Set this intent as end of conversation</strong> option:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_32.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.32: End of conversation option</p>
    <p class="normal">But we will not do this <a id="_idIndexMarker747"/>for the moment; let's scroll <a id="_idIndexMarker748"/>down further to activate the inline webhook functionality:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_33.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.33: Enabling the webhook functionality</p>
    <p class="normal">Now we will go to the <strong class="screen-text">Fulfillment</strong> window:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_34.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.34: Access to the Fulfillment interface</p>
    <p class="normal">First, enable the<a id="_idIndexMarker749"/> inline editor:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_35.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.35: Inline editor</p>
    <p class="normal">To add some fun to the <a id="_idIndexMarker750"/>dialog, let's suppose that chatbot is in a cool start-up coffee shop and that watching movies on individual screens is a service to attract customers. You can watch the movie with headsets (you, friends, family), for example. We add this service to our dialog.</p>
    <p class="normal">We go to the <code class="Code-In-Text--PACKT-">intentMap</code> of the script and add a <code class="Code-In-Text--PACKT-">gotomovie</code> function:</p>
    <pre class="programlisting"><code class="hljs gams">let intentMap = new Map();
intentMap.<span class="hljs-keyword">set</span>(<span class="hljs-string">'Default Welcome Intent'</span>, welcome);
intentMap.<span class="hljs-keyword">set</span>(<span class="hljs-string">'Default Fallback Intent'</span>, fallback);
<span class="hljs-comment">// intentMap.set('your intent name here', yourFunctionHandler);</span>
<span class="hljs-comment">// intentMap.set('your intent name here', googleAssistantHandler);</span>
<span class="highlight">intentMap.<span class="hljs-keyword">set</span>(<span class="hljs-string">'choose_movie-yes-yes'</span>, gotomovie)</span>;
</code></pre>
    <p class="normal">The recommended format is <code class="Code-In-Text--PACKT-">intentMap.set(&lt;Intent&gt;,&lt;function&gt;)</code>.</p>
    <p class="normal">That done, we now write the function with our own text and website link:</p>
    <pre class="programlisting"><code class="hljs less"><span class="hljs-selector-tag">function</span> <span class="hljs-selector-tag">gotomovie</span>(agent) {
    <span class="hljs-selector-tag">agent</span><span class="hljs-selector-class">.add</span>(<span class="hljs-string">'This message is from Coffee Shop movie fans!'</span>);
    <span class="hljs-selector-tag">agent</span><span class="hljs-selector-class">.add</span>(new Card({
    <span class="hljs-attribute">title</span>: <span class="hljs-string">'A blog for Coffee Shops with movies to watch with friends and family'</span>,
    <span class="hljs-attribute">imageUrl</span>: <span class="hljs-string">'https://www.eco-ai-horizons.com/coffeeshop.jpg'</span>,
    <span class="hljs-attribute">text</span>: <span class="hljs-string">'The button takes you to the movie selection we have\n  Great to have you here! :-)'</span>,
    <span class="hljs-attribute">buttonText</span>: <span class="hljs-string">'Click here'</span>,
    <span class="hljs-attribute">buttonUrl</span>: <span class="hljs-string">'https://www.primevideo.com/'</span>
    })
    );
}
</code></pre>
    <p class="normal">All we have to do now is click on <strong class="screen-text">DEPLOY</strong>, and that's it!</p>
    <p class="normal">I added a link to <a id="_idIndexMarker751"/>Amazon Prime Video to show that <a id="_idIndexMarker752"/>you can use IBM Watson, Google, Microsoft, Amazon services, and more to enhance your chatbots!</p>
    <div class="note">
      <p class="Information-Box--PACKT-"><strong class="bold">Important</strong>: You can customize all the dialogs you wish in this editor and use a range of Google Cloud functions. The sky is not even the limit. You can go to Mars!</p>
    </div>
    <p class="normal">For our example, once the script has been deployed, we go back to the beginning of our dialog until we reach this point, which will take us to the movie we wish to watch. In this case, I just displayed a streaming site.</p>
    <p class="normal">You can obtain the full script of <code class="Code-In-Text--PACKT-">index.js</code> in the <code class="Code-In-Text--PACKT-">dialogflowFulfillment.zip</code> on GitHub in <code class="Code-In-Text--PACKT-">CH15</code> and copy it into the editor without importing the whole package.</p>
    <h2 id="_idParaDest-302" class="title">Getting the bot to work on your website</h2>
    <p class="normal">Let's get a bot<a id="_idIndexMarker753"/> running on your website in a few clicks.</p>
    <ol>
      <li class="list">Scroll down to <strong class="screen-text">Integrations</strong> for the agent you wish to deploy: either your own agent or the coffee shop agent.</li>
      <li class="list">Activate the <strong class="screen-text">Web Demo</strong> option.</li>
      <li class="list">An embedded code will appear along the lines of the following:
        <pre class="programlisting"><code class="hljs routeros">&lt;iframe <span class="hljs-attribute">height</span>=<span class="hljs-string">"430"</span> <span class="hljs-attribute">width</span>=<span class="hljs-string">"350"</span> <span class="hljs-attribute">src</span>=<span class="hljs-string">"https://bot.dialogflow.com/81298e0c-1acb-44bb-9c68-89666805342a"</span>&gt;&lt;/iframe&gt;
</code></pre>
      </li>
    </ol>
    <p class="normal">Copy the code on the page of the website you wish to implement it on.</p>
    <p class="normal">To test it first, you<a id="_idIndexMarker754"/> can copy the URL in your browser and test it.</p>
    <div class="note">
      <p class="Information-Box--PACKT-"><strong class="bold">Note</strong>: You can use a speech dialog if you activate your microphone for this site on your browser. Don't forget to access the page using <code class="Code-In-Text--PACKT-">https</code>, otherwise the microphone might be blocked. Also, fulfillment cannot be activated in this HTML page without some additional development.</p>
      <p class="Information-Box--PACKT-">However, you can also click on Google Assistant in the console and create an application in a few clicks, and then deploy it on smartphones and Google Home, for example. If you create a nice chatbot, you can have the whole world use it in a few clicks!</p>
    </div>
    <h1 id="_idParaDest-303" class="title">Machine learning agents</h1>
    <p class="normal">An NLP chatbot cannot <a id="_idIndexMarker755"/>function without machine learning for text recognition, utterances, sentences, speech, entities, intents, and many other aspects of a dialog.</p>
    <p class="normal">In this section, we will explore the following:</p>
    <ul>
      <li class="list">Speech-to-text</li>
      <li class="list">Text-to-speech</li>
      <li class="list">Spelling correction</li>
    </ul>
    <p class="normal">Let's see how we can apply machine learning in each of these contexts.</p>
    <h2 id="_idParaDest-304" class="title">Using machine learning in a chatbot</h2>
    <p class="normal">Generally, when we <a id="_idIndexMarker756"/>hear of machine learning in a chatbot, we think of a <a id="_idIndexMarker757"/>machine learning program running during a dialog as a response.</p>
    <p class="normal">In this section, we will focus on how machine learning is used to improve a chatbot and to make it work.</p>
    <h2 id="_idParaDest-305" class="title">Speech-to-text</h2>
    <p class="normal">Without a<a id="_idIndexMarker758"/> speech-to-text function, there is no<a id="_idIndexMarker759"/> way you can implement a chatbot or any speech application on a smart speaker such as Google Home or Amazon Echo. Smart speakers are going to play an increasing part in our lives in the years to come.</p>
    <p class="normal">Click on the settings button next to the name of the agent and then on <strong class="screen-text">Speech</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_36.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.36: Speech options</p>
    <p class="normal">We will focus on <a id="_idIndexMarker760"/>the main settings of the <a id="_idIndexMarker761"/>speech recognition functions:</p>
    <ul>
      <li class="list"><strong class="bold">Enhanced Speech Models</strong>: This is an<a id="_idIndexMarker762"/> advanced machine learning<a id="_idIndexMarker763"/> option that comes with the Enterprise Edition. It shows how far speech recognition has come. In the standard version, the system already works fairly well. In the advanced version, it uses data logging functionality to enhance speech recognition.</li>
      <li class="list"><strong class="bold">Auto Speech Adaptation</strong>: This<a id="_idIndexMarker764"/> is interesting because this function<a id="_idIndexMarker765"/> uses the intents and entities created to train and adapt to speech recognition of the agent's dialog. It can be activated in the free version as follows:</li>
    </ul>
    <figure class="mediaobject"><img src="../Images/B15438_15_37.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.37: Enabling Auto Speech Adaptation</p>
    <p class="normal">Save the settings before leaving this interface.</p>
    <h2 id="_idParaDest-306" class="title">Text-to-speech</h2>
    <p class="normal">Now, we can go to the <strong class="screen-text">Speech</strong> tab and<a id="_idIndexMarker766"/> enable the <strong class="bold">Automatic Text to Speech</strong> function. I<a id="_idIndexMarker767"/> have a cloud account. If you cannot activate this in the lab, we will use the free online site to test the<a id="_idIndexMarker768"/> possibilities and limits of the machine learning algorithm.</p>
    <div class="note">
      <p class="Information-Box--PACKT-"><strong class="bold">Note</strong>: There is an enhanced speech recognition model option, but you have to upgrade to the enterprise version.</p>
    </div>
    <p class="normal">Click on the settings button next to the name of the agent and then on <strong class="screen-text">Speech</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_38.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.38: Speech options</p>
    <p class="normal">We will first configure <a id="_idIndexMarker769"/>the main settings of text-to-speech:</p>
    <ul>
      <li class="list"><strong class="bold">Agent language</strong>: Start with <code class="Code-In-Text--PACKT-">en(English)</code> to reach the largest audience. However, bear in mind that Dialogflow produces good voice results in several languages.</li>
      <li class="list"><strong class="bold">Voice</strong>: Start with <code class="Code-In-Text--PACKT-">Automatic</code> before trying the different WaveNet model variations. WaveNet models build voices from scratch with neural networks.</li>
      <li class="list"><strong class="bold">Speaking rate</strong>: You can leave it at <code class="Code-In-Text--PACKT-">1</code>, or accelerate the rate or slow it down. For sports commentaries, for example, it could be faster.</li>
      <li class="list"><strong class="bold">Pitch</strong>: You can make the voice higher or lower in semitones.</li>
      <li class="list"><strong class="bold">Volume gain</strong>: You can reduce or increase the volume. The best is to leave it at <code class="Code-In-Text--PACKT-">0</code> to start. Then, while testing the agent, see if it needs to be changed.</li>
    </ul>
    <p class="normal">Once these <a id="_idIndexMarker770"/>parameters are set, save the model:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_39.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.39: Voice configuration</p>
    <p class="normal">Now, test your configuration or experiment with different settings by entering a sentence and clicking on the <strong class="screen-text">PLAY</strong> button:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_40.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.40: Experimenting with different voice settings</p>
    <p class="normal">Once we have finished setting up the voice parameters, we need to set up the spelling machine learning features.</p>
    <h2 id="_idParaDest-307" class="title">Spelling</h2>
    <p class="normal">We have one<a id="_idIndexMarker771"/> step left before we explore the possibilities and limits of the machine learning<a id="_idIndexMarker772"/> algorithms provided by Google. The machine learning spelling feature needs to be activated.</p>
    <p class="normal">For that, we are going to click on the <strong class="screen-text">ML Settings</strong> tab, activate <strong class="screen-text">AUTOMATIC SPELL CORRECTION</strong>, and define an acceptable threshold below which our agent will refuse to recognize errors.</p>
    <p class="normal">Click on the settings button next to the name of the agent and then on <strong class="screen-text">ML Settings</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_41.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.41: ML Settings tab</p>
    <p class="normal">You will have <a id="_idIndexMarker773"/>access to a variety of options to work around a user's spelling mistakes. It <a id="_idIndexMarker774"/>works like the spelling corrector of a search engine when we mistype our request and Google, for example, suggests the correct spelling.</p>
    <p class="normal">The options are as follows:</p>
    <ul>
      <li class="list"><strong class="screen-text">ML CLASSIFICATION THRESHOLD</strong> determines a confidence score below which an intent will not be triggered unless there is a fallback intent (a general response).</li>
      <li class="list"><strong class="screen-text">AUTOMATIC SPELL CORRECTION</strong> uses machine learning to correct user spelling mistakes. It should be activated.</li>
      <li class="list"><strong class="screen-text">AUTOMATIC TRAINING</strong> may slow the dialog down, so careful use of this function is recommended.</li>
      <li class="list"><strong class="screen-text">AGENT VALIDATION</strong> automatically validates an agent during the training process. Notice that training is triggered every time you save an intent, for example.</li>
    </ul>
    <p class="normal">The following screenshot shows default values you might want to start with:</p>
    <figure class="mediaobject"><img src="../Images/B15438_15_42.png" alt=""/></figure>
    <p class="packt_figref">Figure 15.42: ML Settings options</p>
    <p class="normal">Click on the <strong class="screen-text">TRAIN</strong> button every time you change an option.</p>
    <h2 id="_idParaDest-308" class="title">Why are these machine learning algorithms important?</h2>
    <p class="normal">If it's just an educational <a id="_idIndexMarker775"/>chatbot like the <code class="Code-In-Text--PACKT-">cogfilmdr</code> agent example, mistakes are acceptable. It's unpleasant, but acceptable. As we are going to see in <em class="italics">Chapter 16</em>, <em class="italics">Improving the Emotional Intelligence Deficiencies of Chatbots</em>, if a chatbot is going to be used by a large number of people, this means many days of training, tests, and creating workarounds to the machine learning limits of these functions. And that's just for one language!</p>
    <p class="normal">If we are deploying in several languages, this means many days times the number of languages! Even with machine learning, it's tough work. Without machine learning, it's impossible.</p>
    <p class="normal">Machine learning is not merely important; it is vital:</p>
    <ul>
      <li class="list">If the chatbot cannot recognize a written utterance because of a simple spelling mistake, we will get complaints, bad comments, and the SEO ship will sink.</li>
      <li class="list">If the chatbot cannot recognize what you are saying on Google Home or any smart speaker, then that means a lot of trouble, maybe even a refund.</li>
      <li class="list">If the <a id="_idIndexMarker776"/>chatbot's answer comes out in a phony voice that sounds like a 20th century robot, then nobody will want to use it.</li>
    </ul>
    <p class="normal">Machine learning in chatbots is here to stay, but there are improvements to make in terms of emotional intelligence, like we must now explore in the next chapter.</p>
    <h1 id="_idParaDest-309" class="title">Summary</h1>
    <p class="normal">Google Dialogflow provides a complete set of tools on Google Cloud to build a chatbot, add services to it, and customize it with your cognitive programs.</p>
    <p class="normal">A good chatbot fits the requirements. Thinking the architecture through before starting development avoids underfitting (not enough functionality) or overfitting (functions that will not be used) of the model.</p>
    <p class="normal">Careful AI preparation, as accomplished in <em class="italics">Chapter 14</em>, <em class="italics">Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)</em>, provides a solid basis for a chatbot by making the path from the start of the dialog to the goal of the dialog much shorter and efficient.</p>
    <p class="normal">Determining the right intent (what is expected of the chatbot), determining the entities to describe the intent (the subsets of phrases and words), and creating a proper dialog will take quite some time.</p>
    <p class="normal">If necessary, adding services and specially customized machine learning functions will enhance the quality of the system. CUI with speech recognition, voice dialogs, and spelling correction features makes a chatbot frictionless to use.</p>
    <p class="normal">The dialog we built in this chapter was based on <em class="italics">yes</em> answers. We supposed that the probabilities generated with the RBM and PCA in <em class="italics">Chapter 14</em> were correct. However, humans are not easily confined to stereotypes.</p>
    <p class="normal">The <em class="italics">Chapter 16</em>, <em class="italics">Improving the Emotional Intelligence Deficiencies of Chatbots</em>, explores emotional intelligence through basic concepts, Dialogflow functions, and a cognitive approach to improve the content of a chatbot.</p>
    <h1 id="_idParaDest-310" class="title">Questions</h1>
    <ol>
      <li class="list">Can a chatbot communicate like a human? (Yes | No)</li>
      <li class="list">Are chatbots necessarily AI programs? (Yes | No)</li>
      <li class="list">Chatbots only need words to communicate. (Yes | No)</li>
      <li class="list">Do humans only chat with words? (Yes | No)</li>
      <li class="list">Humans only think in words and numbers. (Yes | No)</li>
      <li class="list">Careful machine learning preparation is necessary to build a cognitive chatbot. (Yes | No)</li>
      <li class="list">For a chatbot to function, a dialog flow needs to be planned. (Yes | No)</li>
      <li class="list">A chatbot possesses general AI, so no prior development is required. (Yes | No)</li>
      <li class="list">A chatbot translates fine without any function other than a translation API. (Yes | No)</li>
      <li class="list">Chatbots can already chat like humans in most cases. (Yes | No)</li>
    </ol>
    <h1 id="_idParaDest-311" class="title">Further reading</h1>
    <ul>
      <li class="list">For more on Google Dialogflow, refer to this link: <a href="https://dialogflow.com/"><span class="url">https://dialogflow.com/</span></a></li>
      <li class="list">For more on chatbots and UI development, refer to this link: <a href="https://www.packtpub.com/application-development/hands-chatbots-and-conversational-ui-development"><span class="url">https://www.packtpub.com/application-development/hands-chatbots-and-conversational-ui-development</span></a></li>
    </ul>
  </div>
</body></html>