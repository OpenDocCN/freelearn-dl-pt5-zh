["```py\n    bash start_mlflow.sh\n    ```", "```py\nbash stop_mlflow.sh\n```", "```py\n    export MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n    export AWS_ACCESS_KEY_ID=minio\n    export AWS_SECRET_ACCESS_KEY=minio123\n    ```", "```py\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n```", "```py\nconda create -n dl_model python==3.8.10\nconda activate dl_model\npip install -r requirements.txt\n```", "```py\nEXPERIMENT_NAME = \"dl_model_chapter03\"\nmlflow.set_tracking_uri('http://localhost')\n```", "```py\n    mlflow.pytorch.autolog()\n    with mlflow.start_run(experiment_id=experiment.experiment_id, run_name=\"chapter03\") as dl_model_tracking_run:\n        trainer.finetune(classifier_model, datamodule=datamodule, strategy=\"freeze\")\n        trainer.test()\n    ```", "```py\n    run_id = dl_model_tracking_run.info.run_id\n    print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n        mlflow.get_run(run_id).info.lifecycle_stage))\n    ```", "```py\nrun_id: 37a3fe9b6faf41d89001eca13ad6ca47; lifecycle_stage: active\n```", "```py\n    logged_model = f'runs:/{run_id}/model'\n    ```", "```py\n    model = mlflow.pytorch.load_model(logged_model)\n    model.predict({'This is great news'})\n    ```", "```py\n['positive']\n```", "```py\n    model_registry_version = mlflow.register_model(logged_model, 'nlp_dl_model')\n    print(f'Model Name: {model_registry_version.name}')\n    print(f'Model Version: {model_registry_version.version}')\n    ```", "```py\nmlflow.pytorch.log_model(pytorch_model=trainer.model, artifact_path='dl_model', registered_model_name='nlp_dl_model')\n```", "```py\n    classifier_model = TextClassifier(backbone=\"prajjwal1/bert-tiny\", num_classes=datamodule.num_classes, metrics=torchmetrics.F1(datamodule.num_classes))\n    ```", "```py\n{'test_cross_entropy': 0.785443127155304, 'test_f1': 0.5343999862670898}\n```", "```py\n        cur_metrics = trainer.callback_metrics\n    ```", "```py\n    metrics = dict(map(lambda x: (x[0], float(x[1])), cur_metrics.items()))\n```", "```py\n        mlflow.log_metrics(metrics)\n    ```", "```py\n{'train_f1': 0.5838666558265686, \n'train_f1_step': 0.75, \n'train_cross_entropy': 0.7465656399726868, \n'train_cross_entropy_step': 0.30964696407318115, \n'val_f1': 0.5203999876976013, \n'val_cross_entropy': 0.8168156743049622, \n'train_f1_epoch': 0.5838666558265686, \n'train_cross_entropy_epoch': 0.7465656399726868, \n'test_f1': 0.5343999862670898, \n'test_cross_entropy': 0.785443127155304}\n```", "```py\n    list_of_metrics = [torchmetrics.Accuracy(),\n       torchmetrics.F1(num_classes=datamodule.num_classes),\n       torchmetrics.Precision(num_classes=datamodule.num_classes),\n       torchmetrics.Recall(num_classes=datamodule.num_classes)]\n    ```", "```py\nclassifier_model = TextClassifier(backbone=\"prajjwal1/bert-tiny\", num_classes=datamodule.num_classes, metrics=list_of_metrics)\n```", "```py\nclassifier_model = TextClassifier(backbone=\"prajjwal1/bert-tiny\", num_classes=datamodule.num_classes, metrics=torchmetrics.F1(datamodule.num_classes))\n```", "```py\n{'test_accuracy': 0.6424000263214111, 'test_cross_entropy': 0.6315688490867615, 'test_f1': 0.6424000263214111, 'test_precision': 0.6424000263214111, 'test_recall': 0.6424000263214111}\n```", "```py\n    params = {\"epochs\": trainer.max_epochs}\n```", "```py\n    if hasattr(trainer, \"optimizers\"):\n```", "```py\n        optimizer = trainer.optimizers[0]\n```", "```py\n        params[\"optimizer_name\"] = optimizer.__class__.__name__\n```", "```py\n    if hasattr(optimizer, \"defaults\"):\n```", "```py\n        params.update(optimizer.defaults)\n```", "```py\n    params.update(classifier_model.hparams)\n```", "```py\n    mlflow.log_params(params)\n```"]