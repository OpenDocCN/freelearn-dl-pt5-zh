- en: Learning from Data
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据中学习
- en: Data preparation takes a great deal of time for complex datasets, as we saw
    in the previous chapter. However, time spent on data preparation is time well
    invested... this I can guarantee! In the same way, investing time in understanding
    the basic theory of learning from data is super important for any person that
    wants to join the field of deep learning. Understanding the fundamentals of learning
    theory will pay off whenever you read new algorithms or evaluate your own models.
    It will also make your life much easier when you get to the later chapters in
    this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备对于复杂数据集来说花费大量时间，正如我们在上一章中所见。然而，花时间准备数据是值得的……这一点我可以保证！同样，花时间理解从数据中学习的基本理论对于任何想进入深度学习领域的人来说都非常重要。理解学习理论的基础，将在你阅读新算法或评估自己模型时带来回报。当你阅读本书后面的章节时，这也会让你的学习过程变得更加轻松。
- en: More specifically, this chapter introduces the most elementary concepts around
    the theory of deep learning, including measuring performance on regression and
    classification as well as the identification of overfitting. It also offers some
    warnings about the sensibility of—and the need to optimize—model hyperparameters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，本章介绍了深度学习理论中最基础的概念，包括回归和分类的性能衡量，以及过拟合的识别。它还提供了一些关于模型超参数的合理性以及优化需求的警告。
- en: 'The outline of this chapter is as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的结构如下：
- en: Learning for a purpose
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有目的的学习
- en: Measuring success and error
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 衡量成功与错误
- en: Identifying overfitting and generalization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别过拟合和泛化
- en: The art behind learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习的艺术
- en: Ethical implications of training deep learning algorithms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习算法训练的伦理影响
- en: Learning for a purpose
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有目的的学习
- en: In [Chapter 3](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=26&action=edit),
    *Preparing Data*, we discussed how to prepare data for two major types of problems: **regression**
    and **classification**. In this section, we will cover the technical differences
    between classification and regression in more detail. These differences are important
    because they will limit the type of machine learning algorithms you can use to
    solve your problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=26&action=edit)《准备数据》中，我们讨论了如何为两种主要问题类型准备数据：**回归**和**分类**。在这一节中，我们将更详细地讨论分类和回归的技术差异。这些差异很重要，因为它们会限制你可以使用的机器学习算法类型，以解决你的问题。
- en: Classification
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类
- en: 'How do you know whether your problem is classification? The answer depends
    on two major factors: the **problem** you are trying to solve and the **data**
    you have to solve your problem. There might be other factors, for sure, but these
    two are by far the most significant.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如何判断你的问题是否属于分类问题？答案取决于两个主要因素：你要解决的**问题**和你用于解决问题的**数据**。当然可能还有其他因素，但这两个因素无疑是最为重要的。
- en: 'If your purpose is to make a model that, given some input, will determine whether
    the response or output of the model is to distinguish between two or more distinct
    categories, then you have a classification problem. Here is a non-exhaustive list
    of examples of classification problems:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的目标是建立一个模型，给定某些输入，模型将确定输出是否属于两个或更多的不同类别，那么你遇到的是一个分类问题。以下是分类问题的一些非详尽例子：
- en: 'Given an image, indicate what number it contains (distinguish between 10 categories:
    0-9 digits).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一张图片，标出其包含的数字（区分10个类别：0-9数字）。
- en: 'Given an image, indicate whether it contains a cat or not (distinguish between
    two categories: yes or no).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一张图片，确定其中是否包含猫（区分两个类别：是或否）。
- en: 'Given a sequence of readings about temperature, determine the season (distinguish
    between four categories: the four seasons).'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一系列温度读数，确定其季节（区分四个类别：四季）。
- en: 'Given the text of a tweet, determine the sentiment (distinguish between two
    categories: positive or negative).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一条推文的文本，确定其情感（区分两个类别：正面或负面）。
- en: 'Given an image of a person, determine the age group (distinguish between five
    categories: <18, 18-25, 26-35, 35-50, >50).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一张人的图片，确定其年龄段（区分五个类别：<18，18-25，26-35，35-50，>50）。
- en: 'Given an image of a dog, determine its breed (distinguish between 120 categories:
    those breeds that are internationally recognized).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一张狗的图片，确定其品种（区分120个类别：国际公认的犬种）。
- en: 'Given an entire document, determine whether it has been tampered with (distinguish between
    categories: authentic or altered).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定整个文档，确定它是否被篡改（区分类别：真实或被更改）。
- en: 'Given satellite readings of a spectroradiometer, determine whether the geolocation
    matches the spectral signature of vegetation or not (distinguish between two categories:
    yes or no).'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据光谱辐射计的卫星读数，确定地理位置是否与植被的光谱特征匹配（区分两个类别：是或否）。
- en: As you can see from the examples in the list, there are different types of data
    for different types of problems. The data that we are seeing in these examples
    is known as **labeled data**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在列表中的示例中所见，不同类型的问题具有不同类型的数据。在这些示例中看到的数据称为**标记数据**。
- en: Unlabeled data is very common but is rarely used for classification problems
    without some type of processing that allows the matching of data samples to a
    category. For example, unsupervised clustering can be used on unlabeled data to
    assign the data to specific clusters (such as groups or categories); at which
    point, the data technically becomes "labeled data."
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 未标记数据非常常见，但在没有某种允许将数据样本匹配到类别的处理的情况下，很少用于分类问题。例如，可以对未标记数据使用无监督聚类，将数据分配给特定的聚类（例如组或类别），此时，数据在技术上成为“标记数据”。
- en: 'The other important thing to notice from the list is that we can categorize
    the classification problems into two major groups:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中另一个需要注意的重要事项是，我们可以将分类问题分为两大类：
- en: '**Binary classification**: For classification between any two classes only'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二元分类**：仅用于任意两个类别之间的分类'
- en: '**Multi-class classification**: For classification between more than just two
    classes'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多类分类**：用于对超过两个类别进行分类'
- en: This distinction may seem arbitrary but it is not; in fact, the type of classification
    will limit the type of learning algorithm you can use and the performance you
    can expect. To understand this a little better, let's discuss each classification
    separately.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区别可能看起来是任意的，但实际上并非如此；事实上，分类的类型将限制您可以使用的学习算法类型和您可以期望的性能。为了更好地理解这一点，让我们分别讨论每种分类。
- en: Binary classification
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二元分类
- en: This type of classification is usually regarded as a much simpler problem than
    multiple classes. In fact, if we can solve the binary classification problem,
    we could, technically, solve the problem of multiple classes by deciding on a
    strategy to break down the problem into several binary classification problems
    (*Lorena, A. C.* et al., *2008*).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的分类通常被认为比多类别问题简单得多。实际上，如果我们能解决二元分类问题，我们可以通过决定将问题分解为几个二元分类问题的策略，从技术上讲解决多类问题（*Lorena,
    A. C.* 等，*2008*）。
- en: 'One of the reasons why this is considered a simpler problem is because of the
    algorithmic and mathematical foundations behind binary classification learning
    algorithms. Let''s say that we have a binary classification problem, such as the
    Cleveland dataset explained in [Chapter 3](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=26&action=edit), *Preparing
    Data*. This dataset consists of 13 medical observations for each patient—we can
    call that ![](img/4ae6e047-6db7-4cea-89a7-d59b4577f989.png). For each of these
    patient records, there is an associated label that indicates whether the patient
    has some type of heart disease (+1) or not (-1)—we will call that ![](img/0f347d74-fa0b-4e7f-8523-3b84761dae43.png).
    So, an entire dataset, ![](img/fbdaf353-eb1c-4455-a3f5-cbebb2f0d6e7.png), with *N *samples
    can be defined as a set of data and labels:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这被认为是一个较简单的问题之一，是因为二元分类学习算法背后的算法和数学基础。假设我们有一个二元分类问题，比如在[第三章](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=26&action=edit)，《准备数据》中解释的克利夫兰数据集。该数据集包含每个患者的13个医学观察结果
    — 我们可以称之为 ![](img/4ae6e047-6db7-4cea-89a7-d59b4577f989.png)。对于每个患者记录，都有一个相关的标签，指示患者是否患有某种心脏疾病（+1）或没有（-1）
    — 我们将称之为 ![](img/0f347d74-fa0b-4e7f-8523-3b84761dae43.png)。因此，一个完整的数据集 ![](img/fbdaf353-eb1c-4455-a3f5-cbebb2f0d6e7.png)，包含 *N *个样本，可以被定义为一组数据和标签：
- en: '![](img/dff30c72-c9b3-4a6f-a20a-e3a3017c59e7.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dff30c72-c9b3-4a6f-a20a-e3a3017c59e7.png)'
- en: 'Then, as discussed in [Chapter 1](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=24&action=edit), *Introduction
    to Machine Learning*, the whole point of learning is to use an algorithm that
    will find a way to map input data, **x**, to label the *y* correctly for all samples
    in [![](img/fbdaf353-eb1c-4455-a3f5-cbebb2f0d6e7.png)] and to be able to further
    do so (hopefully) for samples outside of the known dataset, ![](img/fbdaf353-eb1c-4455-a3f5-cbebb2f0d6e7.png).
    Using a perceptron and a corresponding **Perceptron Learning Algorithm** (**PLA**),
    what we want is to find the parameters [![](img/72310c26-8d2e-4d7b-8b0e-2694ac960fbf.png)] that
    can satisfy the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8cba13d-2fa4-48ee-907a-23d24d12ba66.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: For all samples, *i* = 1, 2, ..., *N.* However, as we discussed in [Chapter
    1](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=24&action=edit),
    *Introduction to Machine Learning*, the equation cannot be satisfied if the data
    is non-linearly separable. In that case, we can obtain an approximation, or a
    prediction, that is not necessarily the desired outcome; we will call such a prediction ![](img/ca21520f-7620-4ce7-8ba6-ef31faaed1e9.png).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The whole point of a learning algorithm, then, becomes to reduce the differences
    between the desired target label, ![](img/67f2f764-f8f9-4e62-abfd-5c9dddfe4114.png),
    and the prediction, ![](img/dda3ec0e-9026-4af0-abb5-71bf7486e83c.png). In an ideal
    world, we want ![](img/46139ee6-41db-420e-a2e9-95cc864cda3a.png) for all cases
    of *i* = 1, 2, ..., *N.* In cases of *i *where ![](img/7f1182f2-7155-4ec8-aca1-50a4033f4c85.png),
    the learning algorithm must make adjustments (that is, train itself) to avoid
    making such mistakes in the future by finding new parameters ![](img/2be5be4c-924d-462b-b31e-0dd3771de027.png) that
    are hopefully better.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'The science behind such algorithms varies from model to model, but the ultimate
    goals are usually the same:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the number of errors, ![](img/dc0b01b2-c4f3-499b-8a4d-302e1d8fa01b.png),
    in every learning iteration.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn the model parameters in as few iterations (steps) as possible.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn the model parameters as fast as possible.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since most datasets deal with non-separable problems, the PLA is disregarded
    in favor of other algorithms that will converge faster and in fewer iterations.
    Many learning algorithms like this learn to adjust the parameters ![](img/10030282-7398-4858-8911-a2f401ae5315.png) by
    taking specific steps to reduce the error, ![](img/fa1abe60-b158-4da2-b57c-73f2a10d40cf.png),
    based on derivatives with respect to the variability of the error and the choice
    of parameters. So, the most successful algorithms (in deep learning, at least)
    are those based on some type of gradient descent strategy (Hochreiter, S., et.al.
    2001).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's go over the most basic iterative gradient strategy. Say that we want
    to learn the parameters ![](img/293a24a9-8122-473a-b0e9-3f3c1f5f62e0.png) given
    the dataset, ![](img/66b34a6d-fe6c-42c0-b839-75629dd44781.png). We will have to
    make a small adjustment to the problem formulation to make things a little easier.
    What we want is for ![](img/4e82d5bd-8068-4b93-8586-84592a77fc05.png) to be implied
    in the expression ![](img/4e4b289f-920a-4351-9622-14e68b8cacce.png). The only
    way this could work is if we set ![](img/f1ff6cd9-db78-495b-b8ed-23cf890c12cb.png)and ![](img/357ebb91-cfb5-4c22-b82d-49ddbb38b5f2.png).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'With this simplification, we can simply search for **w**, which implies a search
    for **b** as well. Gradient descent with a fixed *learning rate* is as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the weights to zero ( ![](img/1f4e3960-c78b-45c9-90e2-3921c8452c3a.png)) and
    the iteration counter to zero (![](img/6ce01007-2b63-4bc4-8db8-4f1d0f7c33a1.png)).
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When ![](img/429a3278-fffb-4640-8730-c1c103a64135.png), do the following:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the gradient with respect to ![](img/23cda490-47ff-4f78-b5fc-195f6d6b2d0a.png) and
    store it in ![](img/99c1192e-4889-40ad-9e1b-34a8ad598d5f.png).
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update ![](img/8074e322-e8f8-4e22-828c-06357c3902b8.png) so that it looks like
    this: ![](img/1dfaa02c-ed8e-4bd1-aa7a-4ebd9003ccc8.png).
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increase the iteration counter and repeat.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are a couple of things that need to be explained here:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: The gradient calculation, ![](img/d6ee9c14-1d4a-4ce7-92eb-66e6f7639c98.png),
    is not trivial. For some specific machine learning models, it can be determined
    analytically; but in most cases, it must be determined numerically by using some
    of the latest algorithms.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We still need to define how the error,![](img/497c3550-a1d6-4dae-bbf2-c38fce7e4fe8.png),
    is calculated; but this will be covered in the next section of this chapter.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A learning rate, ![](img/1553a1e5-b84e-433e-8a44-39ec9c0a72ae.png), needs to
    be specified as well, which is a problem in itself.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One way of looking at this last issue is that in order to find the parameter, ![](img/de1605e4-2c5a-4802-919c-f70cf201ca77.png),
    that minimizes the error, we need parameter ![](img/68663c10-bdf9-4cd2-8f73-e5c381771b62.png).
    Now, we could, when applying gradient descent, think about finding the ![](img/10ee9ff7-c459-40a1-ae7e-e9f5d4fdfbe5.png) parameter, but
    we will then fall into an infinite cycle. We will not go into more detail about
    gradient descent and its learning rate since, nowadays, algorithms for gradient
    descent often include automatic calculations of it or adaptive ways of adjusting
    it (Ruder, S. 2016).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Multi-class classification
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Classifying into multiple categories can have an important effect on the performance
    of learning algorithms. In a general sense, the performance of a model will decrease
    with the number of classes it is required to recognize. The exception is if you
    have plenty of data and access to lots of computing power because if you do, you
    can overcome the limitations of poor datasets that have class imbalance problems
    and you can estimate massive gradients and make large calculations and updates
    to the model. Computing power may not be a limitation in the future, but at the
    moment it is.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: The multiple classes problem can be solved by using strategies such as **one
    versus one** or **one versus all**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'In one versus all, you essentially have an expert binary classifier that is
    really good at recognizing one pattern from all the others and the implementation
    strategy is typically cascaded. An example is shown here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is a graphical explanation of this strategy. Suppose we have two-dimensional
    data that tells us something about the four seasons of the year, as shown:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6ea29b49-ff32-4be0-a0cc-40d19d1896f6.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 - Randomized two-dimensional data that could tell us something about
    the four seasons of the year
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case of randomized two-dimensional data, we have four categories corresponding
    to the seasons of the year. Binary classification will not work directly. However,
    we could train expert binary classifiers that specialize in *one* specific category
    *versus all* the rest. If we train one binary classifier to determine whether
    data points belong to the Summer category, using a simple perceptron, we could
    get the separating hyperplane shown here:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac4f8026-284f-43eb-89d9-1c25844ee256.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: A PLA that is an expert in distinguishing from the Summer season
    data versus all the rest of the other seasons'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can train the rest of the experts until we have enough to test
    our entire hypothesis; that is, until we are able to distinguish all the classes
    from each other.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Another alternative is to use classifiers that can handle multiple outputs;
    for example, decision trees or ensemble methods. But in the case of deep learning
    and neural networks, this refers to networks that can have multiple neurons in
    the output layer, such as the one depicted in *Figure 1.6* and *Figure 1.9* in [Chapter
    1](https://cdp.packtpub.com/deep_learning_for_beginners/wp-admin/post.php?post=24&action=edit), *Introduction
    to Machine Learning*.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'The mathematical formulation of a multi-output neural network only changes
    slightly from a single-output one in that the output is no longer within a binary
    set of values, such as ![](img/0f347d74-fa0b-4e7f-8523-3b84761dae43.png), but
    is now a vector of one-hot encoded values, such as ![](img/3476b823-1083-4257-a7e0-71949ade683a.png).
    In this case, |*C*| denotes the size of the set *C*, which contains all the different
    class labels. For the previous example, *C *would contain the following: *C* =
    {''*Summer*'', ''*Fall*'', ''*Winter*'', ''*Spring*''}. Here is what each one-hot
    encoding would look like:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '**Summer**: ![](img/383c2835-581b-49ae-b2d7-745c43d5ed09.png)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fall**: ![](img/08a54e98-f381-4fd1-8834-8ae7c8c6a885.png)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Winter**: ![](img/1688ddb7-c3c5-48eb-9514-54e26474bb93.png)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spring**: ![](img/6f45ab24-f3c6-45f1-b841-636832c00cf0.png)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Every element in the target vector will correspond to the desired output of
    the four neurons. We should also point out that the dataset definition should now reflect
    that both the sample input data and the labels are vectors:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/556fdbd7-1f5b-4934-8441-d7a4d5a260d4.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: Another way of dealing with the problem of multiple-class classification is
    by using **regression**.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previously, we specified that for binary classification, the target variable
    could take on a set of binary values; for example, ![](img/0f347d74-fa0b-4e7f-8523-3b84761dae43.png).
    We also said that for multiple classification, we could modify the target variable
    to be a vector whose size depends on the number of classes, ![](img/a5246959-0c32-4040-aa86-b99a914f8c09.png).
    Well, regression problems deal with cases where the target variable is any real
    value, ![](img/8dbf0dcb-9e08-48c6-888e-9e62c7d77f96.png).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'The implications here are very interesting because with a regression model
    and algorithm, we could *technically* do binary classification since the set of
    real numbers contains any binary set of numbers:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aeaca13b-8358-4c7e-8bf1-e50fae3e3f72.png).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'Further, if we change *C* = {''*Summer*'', ''*Fall*'', ''*Winter*'', ''*Spring*''}
    to a numerical representation instead, such as C = {0,1,2,3}, then *technically*,
    we would again use regression due to the same property:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c06b709f-7343-4fe6-9e3b-712fac9177ae.png).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Although regression models can solve classification problems, it is recommended
    that you use models that are specialized in classification specifically and leave
    the regression models only for regression tasks.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Even if regression models can be used for classification (Tan, X., et.al. 2012),
    they are ideal for when the target variable is a real number. Here is a sample
    list of regression problems:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: When given an image, indicate how many people are in it (the output can be any
    integer >=0).
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given an image, indicate the probability of it containing a cat (the output
    can be any real number between 0 and 1).
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given a sequence of readings about temperature, determine what the temperature
    actually feels like (the output can be any integer whose range depends on the
    units).
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given the text of a tweet, determine the probability of it being offensive (the
    output can be any real number between 0 and 1).
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given an image of a person, determine their age (the output can be any
    positive integer, usually less than 100).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given an entire document, determine the probable compression rate (the
    output can be any real number between 0 and 1).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given satellite readings of a spectroradiometer, determine the corresponding
    infrared value (the output can be any real number).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When given the headlines of some major newspapers, determine the price of oil
    (the output can be any real number >=0).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see from this list, there are many possibilities due to the fact
    that the range of real numbers encompasses all integers and all positive and negative
    numbers, and even if the range is too broad for specific applications, the regression
    model can be scaled up or down to meet the range specifications.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: To explain the potential of regression models, let's start with a basic **linear
    regression** model and in later chapters, we will cover more complex regression
    models based on deep learning.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: 'The linear regression model tries to solve the following problem:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/970566f0-b7ac-4868-81dc-6b18e0b0fc2b.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'The problem is solved for *i* = 1, 2, ..., *N.* We could, however, use the
    same trick as before and include the calculation of *b *in the same equation.
    So, we can say that we are trying to solve the following problem:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c802c25e-40e3-46c3-92bc-22fc0113e952.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
- en: Once again, we are trying to learn the parameters, ![](img/d59f4bf8-7872-4734-8050-abd4ec68ecab.png),
    that yield ![](img/562075f4-c6a5-4f29-a6e4-84f8c4f329c3.png) for all cases of *i.*
    In the case of linear regression, the prediction, ![](img/ca21520f-7620-4ce7-8ba6-ef31faaed1e9.png),
    should ideally be equal to the true target value, ![](img/2a654437-6c4b-4da0-a2ad-8d800b7847ac.png),
    if the input data, ![](img/5a5aa15c-23cf-45b3-801f-b4d8ca5449b8.png), somehow
    describes a perfect straight line. But because this is very unlikely, there has
    to be a way of learning the parameters, ![](img/d1d74b08-42ed-48ee-b896-c39e9f170034.png),
    even if ![](img/95a975fe-111d-454d-b981-b65ab5053683.png). To achieve this, the
    linear regression learning algorithm begins by describing a low penalty for small
    mistakes and a larger penalty for big mistakes. This does make sense, right? It
    is very intuitive.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'A natural way of penalizing mistakes in proportion to their size is by squaring
    the difference between the prediction and the target. Here is an example of when
    the difference is small:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f4c1827-d243-4724-b234-61abbeae95c8.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: 'Here is an example of when the difference is large:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/879e3b84-a279-419f-bb57-1d71b48c3f14.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: In both of these examples, the desired target value is `1`. In the first case,
    the predicted value of `0.98` is very close to the target and the squared difference
    is `0.0004`, which is small compared to the second case. The second prediction
    is off by `14.8`, which yields a squared difference of `219.4`. This seems reasonable
    and intuitive for building up a learning algorithm; that is, one that penalizes
    mistakes in proportion to how big or small they are.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'We can formally define the overall average error in function of the choice
    of parameters **w** as the averaged sum of all squared errors, which is also known
    as the **mean squared error (MSE)**:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b88425f-07b8-4cf1-8c8c-5e15ad59dcc4.png).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'If we define the prediction in terms of the current choice of ![](img/1d7cd898-6ee9-4952-9d43-b441c2412c88.png) as ![](img/2aa011c3-c882-4e20-a5b0-99e710545353.png),
    then we can rewrite the error function as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b5a94efc-3f8c-47bc-8b0e-67bbf7851798.png).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be simplified in terms of the ![](img/3f0e57b4-ce39-452d-ad17-78002c082199.png)-norm
    (also known as the Euclidean norm, ![](img/da7143d1-c3d3-4a85-aef9-2dd8b3aff0b3.png))
    by first defining a matrix of data ![](img/15a5e1a8-a00b-478c-bd88-29ffbcd6374e.png),
    whose elements are data vector ![](img/a0383757-b717-41b7-8e94-64b4fc666f00.png),
    and a vector of corresponding targets, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bdd9cc28-d833-4f38-b123-f42e24649ef5.png).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplification of the error is then as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8f14b75-d5fd-42ed-8486-9a0c2d91df10.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: 'This can then be expanded into the following important equation:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/56c796c0-55f6-447a-b116-0a44e5b47bcf.png).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'This is important because it facilitates the calculation of the derivative
    of the error, ![](img/53799600-8705-4a59-ba5e-55275c4b2c2c.png), which is necessary
    for adjusting the parameters, ![](img/04db5ca2-e2be-4220-8c6d-e87905762461.png),
    in the direction of the derivative and in proportion to the error. Now, following
    the basic properties of linear algebra, we can say that the derivative of the
    error (which is called a gradient since it yields a matrix) is the following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ffea4ee4-25f6-4e04-be3f-e846f88d33f2.png).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we want to find the parameters that yield the smallest error, we can
    set the gradient to `0` and solve for ![](img/c50dc76b-19c9-43bb-818a-a8a9f7c6ee3d.png).By
    setting the gradient to `0` and ignoring constant values, we arrive at the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5eb81dc2-15b3-4822-a5ae-a533d265eb0c.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: '![](img/7e5c5343-31fc-429b-8511-bc9a1c84fd1c.png).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'These are called **normal**** equations**(Krejn, S. G. E. 1982). Then, if we
    simply use the term ![](img/aa319bc1-8e1a-4349-8dc1-72a4206a1995.png), we arrive
    at the definition of a **pseudo-inverse** (Golub, G., and Kahan, W. 1965). The
    beauty of this is that we do not need to calculate the gradient iteratively to
    choose the best parameters, ![](img/0c2d89de-6794-45ef-9e8d-537d24518945.png). As
    a matter of fact, because the gradient is analytic and direct, we can calculate ![](img/b59769c0-1de8-4212-a587-0e18479a6b73.png)in
    one shot, as explained in this linear regression algorithm:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: From ![](img/f94f1b86-f92e-4f64-99e2-2b8cd4d9a7e0.png), construct the pair, ![](img/29abe296-f275-4635-a806-55a85636b84d.png).
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Estimate the pseudo-inverse ![](img/aa319bc1-8e1a-4349-8dc1-72a4206a1995.png).
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate and return ![](img/1905d8ba-cdea-4768-af8c-e0528aec4962.png).
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To show this graphically, let''s say that we have a system that sends a signal
    that follows a linear function; however, the signal, when it is transmitted, becomes
    contaminated with normal noise with a `0` mean and unit variance and we are only
    able to observe the noisy data, as shown:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0aaa35da-96e2-4872-9d97-880766124f97.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 - Data readings that are contaminated with random noise
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'If, say, a hacker reads this data and runs linear regression to attempt to
    determine the true function that produced this data before it was contaminated,
    then the data hacker would obtain the solution shown here:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb38549f-33ef-47a1-a783-777e0249d647.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 - A linear regression solution to the problem of finding the true
    function given noisy data readings
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Clearly, as the previous figure shows, the linear regression solution is very
    close to the true original linear function. In this particular example, a high
    degree of closeness can be observed since the data was contaminated with noise
    that follows a pattern of **white noise**; however, for different types of noise,
    the model may not perform as well as in this example. Furthermore, most regression
    problems are not linear at all; in fact, the most interesting regression problems
    are highly non-linear. Nonetheless, the basic learning principle is the same:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the number of errors,![](img/53799600-8705-4a59-ba5e-55275c4b2c2c.png),
    in every learning iteration (or directly in one shot, such as in linear regression).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn the model parameters in as few iterations (steps) as possible.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn the model parameters as fast as possible.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other major component that guides the learning process is the way the success
    or error is calculated with respect to a choice of parameters, ![](img/53799600-8705-4a59-ba5e-55275c4b2c2c.png).
    In the case of the PLA, it simply found a mistake and adjusted with respect to
    it. For multiple classes, this was through a process of gradient descent over
    some measure of error and in linear regression, this was through direct gradient
    calculation using the MSE. But now, let's dive deeper into other types of error
    measures and successes that can be quantitative and qualitative.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Measuring success and error
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There is a wide variety of performance metrics that people use in deep learning
    models, such as accuracy, balanced error rate, mean squared error, and many others.
    To keep things organized, we will divide them into three groups: for binary classification,
    for multiple classes, and for regression.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is one essential tool used when analyzing and measuring the success of
    our models. It is known as a **c****onfusion matrix**. A confusion matrix is not
    only helpful in visually displaying how a model makes predictions, but we can
    also retrieve other interesting information from it. The following diagram shows
    a template of a confusion matrix:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e700456f-66b7-4e67-91cc-b5cfa91d005d.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 - A confusion matrix and the performance metrics derived from it
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: A confusion matrix and all the metrics derived from it are a very important
    way of conveying how good your models are. You should bookmark this page and come
    back to it whenever you need it.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding confusion matrix, you will notice that it has two columns in
    the vertical axis that indicate the true target values, while in the horizontal
    axis, it indicates the predicted value. The intersection of rows and columns indicates
    the relationship of what should have been predicted against what was actually
    predicted. Every entry in the matrix has a special meaning and can lead to other
    meaningful composite performance metrics.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the list of metrics and what they mean:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '| **Acronym** | **Description** | **Interpretation** |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
- en: '| TP | *True Positive* | This is when a data point was of the positive class
    and was correctly predicted to be of the positive class. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '| TN | *True Negative* | This is when a data point was of the negative class
    and was correctly predicted to be of the negative class. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '| FP | *False Positive* | This is when a data point was of the negative class
    and was incorrectly predicted to be of the positive class. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: '| FN | *False Negative* | This is when a data point was of the positive class
    and was incorrectly predicted to be of the negative class. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| PPV | *Positive Predictive Value* or *Precision* | This is the proportion
    of positive values that are predicted correctly out of all the values predicted
    to be positive. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| NPV | *Negative Predictive Value* | This is the proportion of negative values
    that are predicted correctly out of all the values that are predicted to be negative.
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| FDR | *False Discovery Rate* | This is the proportion of incorrect predictions
    as false positives out of all the values that are predicted to be positive. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: '| FOR | *False Omission Rate* | This is the proportion of incorrect predictions
    as false negatives out of all the values that are predicted to be negative. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
- en: '| TPR | *True Positive Rate,* *Sensitivity*, *Recall*, *Hit Rate* | This is
    the proportion of predicted positives that are actually positives out of all that
    should be positives. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
- en: '| FPR | *False Positive Rate *or *Fall-Out* | This is the proportion of predicted
    positives that are actually negatives out of all that should be negatives. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
- en: '| TNR | **True Negative Rate**, *Specificity,* or *Selectivity* | This is the
    proportion of predicted negatives that are actually negatives out of all that
    should be negatives. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '| FNR | **False Negative Rate**or *Miss Rate* | This is the proportion of predicted
    negatives that are actually positives out of all that should be positives. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: Some of these can be a little bit obscure to understand; however, you don't
    have to memorize them now, you can always come back to this table.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'There are other metrics that are a little bit complicated to calculate, such
    as the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '| **Acronym** | **Description** | **Interpretation** |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| ACC | *Accuracy* | This is the rate of correctly predicting the positives
    and the negatives out of all the samples. |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: '| *F*[1] | *F*[1]*-Score* | This is the average of the precisionand sensitivity.
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
- en: '| MCC | *Matthews Correlation Coefficient* | This is the correlation between
    the desired and the predicted classes. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| BER | *Balanced Error Rate* | This is the average error rate for cases where
    there is a class imbalance. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: I included, in this list of *complicated*calculations, acronyms such as **ACC**
    and **BER**, which are acronyms that have a very intuitive meaning. The main issue
    is, however, that these will vary when we have multiple classes. So, their calculation
    will be slightly different in multiple classes. The rest of the metrics remain
    exclusive (as defined) to binary classification.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we discuss metrics for multiple classes, here are the formulas for calculating
    the previous metrics:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5276ec41-4004-4150-8622-dcf51e6d52c6.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: '![](img/40867f27-e549-47ff-95e9-55fe50bf85ad.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
- en: '![](img/29c0a645-a95a-43e3-9a0a-6e7b4f2d3152.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: '![](img/17310bd8-85d1-4b80-8976-ec16f0bdd58b.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: In a general sense, you want **ACC**, **F[1]**, and **MCC** to be high and **BER**
    to be low.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Multiple classes
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we go beyond simple binary classification, we often deal with multiple
    classes, such as *C* = {'*Summer*', '*Fall*', '*Winter*', '*Spring*'} or *C* =
    {0,1,2,3}. This can limit, to a certain point, the way we measure error or success.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the confusion matrix for multiple classes shown here:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b825d44-a56e-451e-8e4f-213c04487453.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 - A confusion matrix for multiple classes
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'From the following diagram, it is evident that the notion of true positive
    or negative has disappeared since we no longer have just positive and negative
    classes, but also sets of finite classes:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9d6ecb6-50a5-4079-84ed-85028b1436ab.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: Individual classes, ![](img/16d50594-4373-4352-bfa9-e7c0c228c469.png), can be
    strings or numbers, as long as they follow the rules of sets. That is, the set
    of classes, ![](img/35755034-de0c-4834-9eb3-e8d7445dc5dd.png), must be finite
    and unique.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'To measure ACC here, we will count all the elements in the main diagonal of
    the confusion matrix and divide it by the total number of samples:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb518092-12fe-4555-986f-95df3fd0102d.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
- en: 'In this equation, ![](img/7e28c26a-52a3-4d61-ba59-d9c1bd3b9356.png) denotes
    the confusion matrix and ![](img/130d0fd7-ce83-47e6-b8c3-df493c208c66.png) denotes
    the trace operation; that is, the sum of the elements in the main diagonal of
    a square matrix. Consequently, the total error is `1-ACC`, but in the case of
    class imbalance, the error metric or plain accuracy may be deceiving. For this,
    we must use the BER metric, which for multiple classes can be defined as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9878abc-5d61-4822-8244-c05f31a27b88.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: In this new formula for BER, ![](img/69426ee5-6e9a-46cf-a421-8d20e26857e7.png) refers
    to the element in the *j*th row and *i*th column of the confusion matrix, ![](img/308bc727-30e0-4f7f-b86d-9ca99ac39cc7.png).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Some machine learning schools of thought use the rows of the confusion matrix
    to denote true labels and the columns to denote the predicted labels. The theory
    behind the analysis is the same and the interpretation is, too. Don't be alarmed
    that `sklearn` uses the flipped approach; this is irrelevant and you should not
    have any problems with following any discussions about this.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, consider the dataset that was shown earlier in *Figure 4.1*.
    If we run a five-layered neural network classifier, we could obtain decision boundaries
    like this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/170655fa-57cc-4652-bd30-d34d624664c8.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 - Classification regions for a sample two-dimensional dataset with
    a five-layer neural net
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, the dataset is not perfectly separable by a non-linear hyperplane;
    there are some data points that cross the boundaries for each class. In the previous
    graph, we can see that only the *Summer* class has no points that are incorrectly
    classified based on the classification boundaries.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this is more evident if we actually calculate and display the confusion
    matrix, shown here:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc71ff7b-05ae-410b-9ec5-b66bf34c08b0.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 - A confusion matrix obtained from training errors on the sample
    two-dimensional dataset
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the accuracy can be calculated as ACC=(25+23+22+24)/100, which
    yields an ACC of 0.94, which seems nice, and an error rate of 1-ACC = 0.06\. This
    particular example has a slight class imbalance. Here are the samples for each
    class:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'Summer: 25'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fall: 25'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Winter: 24'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spring: 26'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Winter group has fewer examples than the rest and the Spring group has more
    examples than the rest. While this is a very small class imbalance, it can be
    enough to yield a deceivingly low error rate. We must now calculate the balanced
    error rate, BER.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'BER can be calculated as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/585f5334-7957-47d0-b576-3aec44b83eac.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
- en: '![](img/366a761b-958b-4dea-bf40-3ca41bcaaa2a.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: Here, the difference between the error rate and BER is a 0.01% under-estimation
    of the error. However, for classes that are highly imbalanced, the gap can be
    much larger and it is our responsibility to measure carefully and report the appropriate
    error measure, BER.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting fact about BER is that it intuitively is the counterpart
    of a balanced accuracy; this means that if we remove the `1–` term in the BER
    equation, we are left with the balanced accuracy. Further, if we examine the terms
    in the numerator, we can see that the fractions on it lead to class-specific accuracies;
    for example, the first class, Summer, has a 100% accuracy, the second, Fall, has
    a 92% accuracy, and so on.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, the `sklearn` library has a class that can determine the confusion
    matrix automatically, given the true and predicted labels. The class is called `confusion_matrix`
    and it belongs to the `metrics` super class and we can use it as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If `y` contains the true labels, and `y_pred` contains the predicted labels,
    then the preceding instructions will output something like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can calculate BER by simply doing this:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will output the following:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Alternatively, `sklearn` has a built-in function to calculate the balanced
    accuracy score in the same super class as the confusion matrix. The class is called `balanced_accuracy_score`
    and we can produce BER by doing the following:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We get the following output:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let's now discuss the metrics for regression.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The most popular metric is **MSE**, which we discussed earlier in this chapter
    when explaining how linear regression works. However, we explained it as a function
    of the choice of hyperparameters. Here, we will redefine it in a general sense
    as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ce4606dc-3c6f-42b1-9172-4094989cc388.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
- en: 'Another metric that is very similar to MSE is **mean absolute error** (**MAE**).
    While MSE penalizes big mistakes more (quadratically) and small errors much less,
    MAE penalizes everything in direct proportion to the absolute difference between
    what should be and what was predicted. This is a formal definition of MAE:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/240ba3a7-8194-473f-9e0f-5bda05e4c582.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: 'Finally, out of the other measures for regression, the popular choice in deep
    learning is the ***R*² score**,also known as the **coefficient of determination**.
    This metric represents the proportion of variance, which is explained by the independent
    variables in the model. It measures how likely the model is to perform well on
    unseen data that follows the same statistical distribution as the training data.
    This is its definition:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f2c6d77-a573-4d0a-b3c6-b582c4f166c7.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
- en: 'The sample mean is defined as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7de549fd-f078-464a-904d-b20a8675fead.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
- en: 'Scikit-learn has classes available for each one of these metrics, indicated
    in the following table:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '| **Regression metric** | **Scikit-learn class** |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| *R*² score | `sklearn.metrics.r2_score` |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '| MAE | `sklearn.metrics.mean_absolute_error` |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| MSE | `sklearn.metrics.mean_squared_error` |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: All of these classes take the true labels and predicted labels as input arguments.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, if we take the data and linear regression model shown in *Figure
    4.3* and *Figure 4.4* as input, we can determine the three error metrics, as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following graph shows the sample data used, along with the performance
    obtained. Clearly, the performance using the three performance metrics is good:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d22cb47d-a379-462d-bf76-0acbf7ddda8e.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 - Error metrics over a linear regression model on data contaminated
    with white noise
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: In general, you always want to have a determination coefficient that is as close
    to `1` as possible and all your errors (MSE and MAE) as close to `0` as possible.
    But while all of these are good metrics to report on our models, we need to be
    careful to report these metrics over **unseen validation** or **test data**. This
    is so that we accurately measure the generalization ability of the model and identify
    overfitting in our models before it becomes a catastrophic error.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Identifying overfitting and generalization
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often, when we are in a controlled machine learning setting, we are given a
    dataset that we can use for training and a different set that we can use for testing.
    The idea is that you only run the learning algorithm on the **training** data,
    but when it comes to seeing how good your model is, you feed your model the **test**
    data and observe the output. It is typical for competitions and hackathons to
    give out the test data but withhold the labels associated with it because the
    winner will be selected based on how well the model performs on the test data
    and you don't want them to cheat by looking at the labels of the test data and
    making adjustments. If this is the case, we can use a **validation** dataset,
    which we can create by ourselves by separating a portion of the training data
    to be the validation data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: The whole point of having separate sets, namely a validation or test dataset,
    is to measure the performance on this data, knowing that our model was not trained
    with it. A model's ability to perform equally, or close to equally, well on unseen
    validation or test data is known as **generalization.**
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Generalization is the ultimate goal of most learning algorithms; all of us professionals
    and practitioners of deep learning dream of achieving great generalization in
    all of our models. Similarly, our greatest nightmare is **overfitting**.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting is the opposite of generalization. It occurs when our models perform
    extremely well on the training data but when presented with validation or test
    data, the performance decreases significantly. This indicates that our model almost
    memorized the intricacies of the training data and missed the big picture generalities
    of the sample space that lead to good models.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'In this and further chapters, we will follow these rules with respect to data
    splits:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: If we are given test data (with labels), we will train on the training set and
    report the performance based on the test set.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we are not given test data (or if we have test data with no labels), we will
    split the training set, creating a validation set that we can report performance
    on using a cross-validation strategy.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's discuss each scenario separately.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: If we have test data
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To begin this discussion, let''s say that we have a deep learning model with
    a set of hyper parameters, ![](img/fb401be2-c787-431a-ac8a-47d74004dcb3.png),
    which could be the weights of the model, the number of neurons, layers, the learning
    rate, the drop-out rate, and so on. Then, we can say that a model, ![](img/d790c8ca-2267-4437-b9df-2eb6ca27611c.png),
    (with parameters ![](img/cb15d854-ebcd-426f-9120-961cdcc51165.png)) that is trained
    with training data, ![](img/dff30c72-c9b3-4a6f-a20a-e3a3017c59e7.png), can have
    a training accuracy as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/43cdd752-074f-4433-a75a-6c958eb9dbda.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
- en: 'This is the training accuracy of a trained model on the training data. Consequently,
    if we are given labeled test data, ![](img/b2cc358b-36e4-4460-a96e-6f6234315997.png), with *M*
    data points, we can simply estimate the **test accuracy** by calculating the following:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b3b5f613-b3a4-40fb-9e26-a7097dd0ea7b.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
- en: 'One important property when reporting test accuracy usually holds true in most
    cases—all test accuracy is usually less than the training accuracy plus some noise
    caused by a poor selection of parameters:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e080952-7eb2-4e89-9893-848d25b5e9ae.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: This usually implies that if your test accuracy is significantly larger than
    your training accuracy, then there could be something wrong with the trained model.
    Also, we could consider the possibility that the test data is drastically different
    from the training data in terms of its statistical distribution and the multidimensional
    manifold that describes it.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: In summary, reporting performance on the test set is very important if we have
    test data that was properly chosen. Nonetheless, it would be completely normal
    for the performance to be less than it was in training. However, if it is significantly
    lower, there could be a problem of overfitting and if it is significantly greater,
    then there could be a problem with the code, the model, and even the choice of
    test data. The problem of overfitting can be solved by choosing better parameters, ![](img/cee96f36-9658-4621-9c99-9eadf7d7d500.png),
    or by choosing a different model, ![](img/d01418e4-a07a-41a4-83dd-3c65bde9d857.png),
    which is discussed in the next section.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's briefly discuss a case where we don't have test data or we have test
    data with no labels.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: No test data? No problem – cross-validate
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cross-validation is a technique that allows us to split the training data, ![](img/dff30c72-c9b3-4a6f-a20a-e3a3017c59e7.png), into
    smaller groups for training purposes. The most important point to remember is
    that the splits are ideally made of an equal number of samples overall and that
    we want to rotate the choice of groups for training and validation sets.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss the famous cross-validation strategy known as ***k*-fold cross-validation** (Kohavi,
    R. 1995). The idea here is to divide the training data into *k* groups, which
    are (ideally) equally large, then select *k*-1 groups for training the model and
    measure the performance of the group that was left out. Then, change the groups
    each time until all the groups have been selected for testing.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous sections, we discussed measuring performance using the standard
    accuracy, ACC, but we could use any performance metric. To show this, we will
    now calculate the MSE. This is how the *k*-fold cross-validation algorithm will
    look:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Input the dataset, ![](img/e304304b-b22e-44a6-bb16-5f682710918c.png), the model, ![](img/17eb0626-a42f-4af0-a282-6e8b4763660f.png),
    the parameters, ![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png), and the number
    of folds, ![](img/1d85f939-85aa-4c66-8a53-c5451f35ba70.png).
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide the set of indices, ![](img/7976dcab-c59d-4f7d-adc1-46aa541730e0.png), into ![](img/7853dbb6-4144-4bdc-b6e9-f536bad0862d.png)groups
    (ideally equal in size), ![](img/1dab9af3-28c9-4288-b612-2871cba7b80e.png), such
    that ![](img/09103fa9-8eb1-4d3c-bda9-34629dee8f42.png).
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each case of ![](img/3ae133ea-6268-4366-b1b1-8a00537970d7.png), do the
    following:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the indices for training as [![](img/84dc0f45-f878-48b2-ade1-11e12122e33d.png)] and
    form the training set, [![](img/5bedbb94-b2d2-43fa-b526-2eda18f88551.png)].
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select the indices for validation as ![](img/5e3df28e-3838-4ca1-b407-8f00962e9d85.png) and
    form the validation set, ![](img/107f4c15-a2f6-4f29-8a47-2393165addff.png).
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train the model with a choice of parameters over the training set: ![](img/9b069e01-510c-4bad-b188-0df9797af76a.png).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compute the error of the model, [![](img/40685b40-6076-4fba-b045-11a6d39face0.png)], on
    the validation set : [![](img/cb27f873-4b41-48ee-b205-215589f73273.png)]'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return ![](img/c8557d04-4efd-4275-845a-ca9183a4be72.png) for all cases of ![](img/355f6774-f073-4a73-9a57-c7df89a2cbbe.png).
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With this, we can calculate the cross-validation error (MSE) given by the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f2e94af6-ec29-4bc0-9c9c-8cb59ba9ed2e.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
- en: 'We can also calculate its corresponding standard deviation:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bba147e0-2d91-4e2c-bcb8-fb4db4c08f9a.png).'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: It is usually a good idea to look at the standard deviation of our performance
    metric—regardless of the choice—since it gives an idea of how consistent our performance
    on the validation sets is. Ideally, we would like to have a cross-validated MSE
    of `0`, ![](img/5f2ba80e-d9bd-4d27-9965-a87fa2cb272a.png), and a standard deviation
    of `1`, ![](img/51bcebac-4507-44fd-bae4-111feca2dbd9.png).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: To explain this, we can use the regression example of the sample data contaminated
    by white noise, shown in *Figure 4.3* and *Figure 4.4*. To keep things simple
    for this example, we will use a total of 100 samples, *N*=100, and we will use
    3 folds. We will use scikit-learn's `KFold` class inside the `model_selection`
    super class and we will obtain the cross-validated MSE and its standard deviation.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we can use the following code and include other metrics as well:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result of this code will return something as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'These results are cross-validated and give a clearer picture of the generalization
    abilities of the model. For comparison purposes, see the results shown in *Figure
    4.9*. You will notice that the results are very consistent between the performance
    measured before using the whole set in *Figure 4.9* and now, using only about
    66% of the data (since we split it into three groups) for training and about 33%
    for testing, as shown:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/352f369c-e46e-403f-80db-daee8d4fc3d2.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 - Cross-validated performance metrics with standard deviation in
    parenthesis
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: The previous graph shows the linear regression solution found for every split
    of the data as well as the true original function; you can see that the solutions
    found are fairly close to the true model, yielding a good performance, as measured
    by ***R*²**, **MAE**, and **MSE**.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise**'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and change the number of folds, progressively increasing it, and document
    your observations. What happens to the cross-validated performances? Do they stay
    the same, increase, or decrease? What happens to the standard deviations of the
    cross-validated performances? Do they stay the same, increase, or decrease? What
    do you think this means?
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Usually, cross-validation is used on a dataset, ![](img/e304304b-b22e-44a6-bb16-5f682710918c.png),
    with a model, ![](img/17eb0626-a42f-4af0-a282-6e8b4763660f.png), trained on parameters, ![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png).
    However, one of the greatest challenges in learning algorithms is finding the
    best set of parameters, ![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png), that
    can yield the best (test or cross-validated) performance. Many machine learning
    scientists believe choosing the set of parameters can be **automated** with some
    algorithms and others believe this is an **art** (Bergstra, J. S., et.al. 2011).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: The art behind learning
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For those of us who have spent decades studying machine learning, experience
    informs the way we choose parameters for our learning algorithms. But for those
    who are new to it, this is a skill that needs to be developed and this skill comes
    after learning how learning algorithms work. Once you have finished this book,
    I believe you will have enough knowledge to choose your parameters wisely. In
    the meantime, we can discuss some ideas for finding parameters automatically using
    standard and novel algorithms here.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go any further, we need to make a distinction at this point and define
    two major sets of parameters that are important in learning algorithms. These
    are as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '**Model parameters:** These are parameters that represent the solution that
    the model represents. For example, in perceptron and linear regression, this would
    be vector ![](img/5c1ca364-6e24-407a-8b15-dd412d3dda71.png)and scalar ![](img/f8b8288d-5510-4840-9753-7b375f040e5a.png),
    while for a deep neural network, this would be a matrix of weights, ![](img/74c8f74e-3b92-4f54-b1c7-85e2dcc4318e.png), and
    a vector of biases, ![](img/9fe4b0b9-c94e-4df7-bb9b-9efa507ee211.png). For a convolutional
    network, this would be filter sets.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hyperparameters:** These are parameters needed by the model to guide the
    learning process to search for a solution (model parameters) and are usually represented
    as ![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png). For example, in the PLA,
    a hyperparameter would be the maximum number of iterations; in a deep neural network,
    it would be the number of layers, the number of neurons, the activation function
    for the neurons, and the learning rate; and for a **convolutional neural network**
    (**CNN**), it would be the number of filters, the size of filters, the stride,
    the pooling size, and so on.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put in other words, the model parameters are determined, in part, by the choice
    of hyperparameters. Usually, unless there is a numerical anomaly, all learning
    algorithms will consistently find solutions (model parameters) for the same set
    of hyperparameters. So, one of the main tasks when learning is finding the best
    set of hyperparameters that will give us the best solutions.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'To observe the effects of altering the hyperparameters of a model, let''s once
    more consider the four-class classification problem of the seasons, shown earlier
    in *Figure 4.7*. We will assume that we are using a fully connected network, such
    as the one described in [*Chapter 1*](e3181710-1bb7-4069-825a-a235355bc116.xhtml),
    *Introduction to Machine Learning*, and the hyperparameter we want to determine
    is the best number of layers. Just for didactic purposes, let''s say that the
    number of neurons in each layer will increase exponentially in each layer, as
    shown:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '| **Layer** | **Neurons in each layer** |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: '| 1 | (8) |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
- en: '| 2 | (16, 8) |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
- en: '| 3 | (32, 16, 8) |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
- en: '| 4 | (64, 32, 16, 8) |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '| 5 | (128, 64, 32, 16, 8) |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: '| 6 | (256, 128, 64, 32, 16, 8) |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
- en: '| 7 | (512, 256, 128, 64, 32, 16, 8) |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
- en: In the previous configuration, the first number in the brackets corresponds
    to the number of neurons closest to the input layer, while the last number in
    the brackets corresponds to the number of neurons closest to the output layer
    (which consists of 4 neurons, one per class).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the number of layers represents ![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png),
    in this example. If we loop through each configuration and determine the cross-validated
    BER, we can determine which architecture yields the best performance; that is,
    we are optimizing ![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png) for performance.
    The results obtained will look as follows:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '| **Layers – [![](img/37ac0424-1c5a-4d6a-9ce1-5e7a1eaff343.png)]** | **1**
    | **2** | **3** | **4** | **5** | **6** | **7** |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
- en: '| **BER** | 0.275 | 0.104 | 0.100 | 0.096 | 0.067 | 0.079 | 0.088 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
- en: '| **Standard deviation** | 0.22 | 0.10 | 0.08 | 0.10 | 0.05 | 0.04 | 0.08 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
- en: 'From the results, we can easily determine that the best architecture is one
    with five layers since it has the lowest BER and the second smallest standard
    deviation. We could, indeed, gather all the data at each split for each configuration
    and produce the box plot shown here:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c159f1a-3d99-48ee-8517-ac6a33da553e.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 - A box plot of the cross-validated data optimizing the number of
    layers
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: This box plot illustrates a couple of important points. First, that there is
    a clear tendency of the model to reduce the BER as the number of layers increases
    up to `5`, then increases after that. This is very common in machine learning
    and it is known as the **overfitting curve**, which is usually a *u *shape (or
    *n *shape, for performance metrics that are better on higher values). The lowest
    point, in this case, would indicate the best set of hyperparameters (at `5`);
    anything to the left of that represents **underfitting** and anything to the right
    represents **overfitting**. The second thing that the box plot shows is that even
    if several models have a similar BER, we will choose the one that shows less variability
    and most consistency.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the differences between underfitting, good fitting, and overfitting,
    we will show the decision boundaries produced by the worst underfit, the best
    fit, and the worst overfit. In this case, the worst underfit is one layer, the
    best fit is five layers, and the worst overfit is seven layers. Their respective
    decision boundaries are shown in *Figure 4.12*, *Figure 4.13*, and *Figure 4.14*, respectively:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e730ac9-4d3a-4868-9313-a783b113408f.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 - Classification boundaries for a one-hidden-layer network that
    is underfitting
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding graph, we can see that the underfit is clear since there are
    decision boundaries that prevent many datapoints from being classified correctly:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e2f7982-3a60-4d8d-941a-0dc2d14e0b42.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
- en: Figure 4.13 - Classification boundaries for a five-hidden-layer network that
    has a relatively good fit
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, the previous graph shows the decision boundaries, but compared to
    *Figure 4.12*, these boundaries seem to provide a nicer separation of the data
    points for the different groups—a good fit:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60fedb99-d5fc-4dfb-b89c-53f1318e7d43.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
- en: Figure 4.14 - Classification boundaries for a seven-hidden-layer network that
    is overfitting
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: If you look closely, *Figure 4.12* shows that some regions are designated very
    poorly, while in *figure 4.14*, the network architecture is trying *too hard* to
    classify all the examples perfectly, to the point where the outlier in the *Fall* class
    (the yellow points) that goes into the region of the *Winter* class (the blue
    points) has its own little region, which may have negative effects down the road.
    The classes in *Figure 4.13* seem to be robust against some of the outliers and
    have well-defined regions, for the most part.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: As we progress through this book, we will deal with more complex sets of hyperparameters.
    Here we just dealt with one, but the theory is the same. This method of looking
    at the best set of hyperparameters is known as an exhaustive search. However,
    there are other ways of looking at parameters, such as performing a **grid search.**
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that you do not have a fixed way of knowing the number of neurons in
    each layer (as opposed to the earlier example); you only know that you would like
    to have something between `4` and `1024` neurons and something between `1` and
    `100` layers to allow deep or shallow models. In that case, you cannot do an exhaustive
    search; it would take too much time! Here, grid searchis used as a solution that
    will sample the search space in—usually—equally-spaced regions.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: For example, grid search can look at a number of neurons in the `[4, 1024]` range on
    10 equally spaced values—`4`, `117`, `230`, `344`, `457`, `570`, `684`, `797`,
    `910`, and `1024`—and the number of layers that is in the `[1,100]` range on 10
    equally spaced values—`1`, `12`, `23`, `34`, `45`, `56`, `67`, `78`, `89`, and
    `100`. Rather than looking at 1020*100=102,000 searches, it will look at 10*10=100,
    instead.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: In `sklearn`, there is a class, `GridSearchCV`, that can return the best models
    and hyperparameters in cross-validation; it is part of the `model_selection` super
    class. The same class group has another class, called `RandomizedSearchCV`, which
    contains a methodology based on randomly searching the space. This is called **random
    search.**
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: In **random search**, the premise is that it will look within the `[4, 1024]` range and
    the `[1,100]` range for neurons and layers, respectively, by randomly drawing
    numbers uniformly until it reaches a maximum limit of total iterations.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Typically, if you know the range and distribution of the parameter search space,
    try a **grid search** approach on the space you believe is likely to have a better
    cross-validated performance. However, if you know very little or nothing about
    the parameter search space, use a **random search** approach. In practice, both
    of these methods work well.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'There are other, more sophisticated methods that work well but whose implementation
    in Python is not yet standard, so we will not cover them in detail here. However,
    you should know about them:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian hyperparameter optimization (Feurer, M., et.al. 2015)
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evolution theory-based hyperparameter optimization (Loshchilov, I., et.al. 2016)
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient-based hyperparameter optimization (Maclaurin, D., et.al. 2015)
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Least squares-based hyperparameter optimization (Rivas-Perea, P., et.al. 2014)
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ethical implications of training deep learning algorithms
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few things that can be said about the ethical implications of training
    deep learning models. There is potential harm whenever you are handling data that
    represents human perceptions. But also, data about humans and human interaction
    has to be rigorously protected and examined carefully before creating a model
    that will generalize based on such data. Such thoughts are organized in the following
    sections.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Reporting using the appropriate performance measures
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Avoid faking good performance by picking the one performance metric that makes
    your model look good. It is not uncommon to read articles and reports of multi-class
    classification models that are trained over clear, class-imbalanced datasets but
    report the standard accuracy. Most likely, these models will report a high standard
    of accuracy since the models will be biased toward the over-sampled class and
    against the under-sampled groups. So, these types of models must report the balanced
    accuracy or the balanced error rate.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, for other types of classification and regression problems, you must
    report the appropriate performance metric. When in doubt, report as many performance
    metrics as you can. Nobody has ever complained about someone reporting model performance
    using too many metrics.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: The consequences of not reporting the appropriate metrics go from having biased
    models that go undetected and are deployed into production systems with disastrous
    consequences to having misleading information that can be detrimental to our understanding
    of specific problems and how models perform. We must recall that what we do may
    affect others and we need to be vigilant.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Being careful with outliers and verifying them
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Outliers are usually seen as bad things to work around during the learning process
    and I agree. Models should be robust against outliers, unless they are not really
    outliers. If we have some data and we don't know anything about it, it is a safe
    assumption to interpret outliers as anomalies.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: However, if we know anything about the data (because we collected it, were given
    all the information about it, or know the sensors that produced it), then we can
    verify that outliers are really outliers. We must verify that they were the product
    of human error when typing data or produced by a faulty sensor, data conversion
    error, or some other artifact because if an outlier is not the product of any
    of these reasons, there is no reasonable basis for us to assume that it is an
    outlier. In fact, data like this gives us important information about situations
    that may not occur frequently but will eventually happen again and the model needs
    to respond properly.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the data shown in the following figure. If we arbitrarily decide to
    ignore outliers without verification (such as in the top diagram), it may be that
    they are in fact not really outliers and the model will create a narrow decision
    space that ignores the outliers. The consequence, in this example, is that one
    point will be incorrectly classified as belonging to another group, while another
    point might be left out of the majority group:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad524a4e-52df-40bc-a71f-6c80e34dd76c.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
- en: Figure 4.15 - Differences in the learned space of my models. The top diagram
    shows the ignoring outliers outcome. The bottom diagram shows the including outliers
    outcome
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: However, if we verify the data and discover that the outliers are completely
    valid input, the models might learn a better decision space that could potentially
    include the outliers. Nonetheless, this can yield a secondary problem where a
    point is classified as belonging to two different groups with different degrees
    of membership. While this is a problem, it is a much smaller risk than incorrectly
    classifying something. It is better to have, say, 60% certainty that a point belongs
    to one class and 40% certainty that it belongs to the other class, rather than
    classifying it incorrectly with 100% certainty.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: If you think about it, models that were built by ignoring outliers and then deployed
    into government systems can cause discrimination problems. They may show bias
    against minority or protected population groups. If deployed into incoming school
    student selection, it could lead to the rejection of exceptional students. If
    deployed into DNA classification systems, it could incorrectly ignore the similarity
    of two very close DNA groups. Therefore, always verify outliers if you can.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Weight classes with undersampled groups
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you have a class imbalance, as in *Figure 4.15*, I recommend you try to
    balance the classes by getting more data rather than reducing it. If this is not
    an option, look into algorithms that allow you to weight some classes differently,
    so as to even out the imbalance. Here are a couple of the most common techniques:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: On small datasets, use `sklearn` and the `class_weight` option. When training
    a model, it penalizes mistakes based on the provided weight for that class. There
    are a couple of automatic alternatives that you can look into that will also help,
    such as `class_weight="auto"` and `class_weight="balanced"`.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On large datasets where batch training is used, use Keras and the `BalancedBatchGenerator`
    class. This will prepare a selection of samples (batches) that is consistently
    balanced each time, thereby guiding the learning algorithm to consider all groups
    equally. The class is part of `imblearn.keras`.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should try to use these strategies every time you want to have a model that
    is not biased toward a majority group. The ethical implications of this are similar
    to the previous points already mentioned. But above all, we must protect life
    and treat people with respect; all people have an equal, infinite worth.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this basic-level chapter, we discussed the basics of learning algorithms
    and their purpose. Then, we studied the most basic way of measuring success and
    failure through performance analysis using accuracies, errors, and other statistical
    devices. We also studied the problem of overfitting and the super important concept
    of generalization, which is its counterpart. Then, we discussed the art behind
    the proper selection of hyperparameters and strategies for their automated search.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: After reading this chapter, you are now able to explain the technical differences
    between classification and regression and how to calculate different performance
    metrics, such as ACC, BER, MSE, and others, as appropriate for different tasks.
    Now, you are capable of detecting overfitting by using train, validation, and
    test datasets under cross-validation strategies, you can experiment with and observe
    the effects of altering the hyperparameters of a learning model. You are also
    ready to think critically about the precautions and devices necessary to prevent
    human harm caused by deep learning algorithms.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is [*Chapter 5*](4e4b45a6-1924-4918-b2cd-81f0448fb213.xhtml), *Training
    a Single Neuron,* which revises and expands the concept of a neuron, which was
    introduced in [*Chapter 1*](e3181710-1bb7-4069-825a-a235355bc116.xhtml), *Introduction
    to Machine Learning*, and shows its implementation in Python using different datasets
    to analyze the potential effects of different data; that is, linear and non-linearly
    separable data. However, before we go there, please try to quiz yourself using
    the following questions.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Questions and answers
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**When you did the exercise on cross-validation, what happened to the standard
    deviation and what does that mean?**'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The standard deviation stabilizes and reduces on more folds. This means that
    the performance measurements are more reliable; it is an accurate measure of generalization
    or overfitting.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '**What is the difference between hyperparameters and model parameters?**'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model parameters are numerical solutions to a learning algorithm; hyperparameters
    are what the model needs to know in order to find a solution effectively.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '**Is a grid search faster than a randomized search for hyperparameters?**'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It depends. If the choice of hyperparameters affects the computational complexity
    of the learning algorithm, then both could behave differently. However, in similar
    search spaces and in the amortized case, both should finish at about the same
    time.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '**Can I use a regression-based learning algorithm for a classification problem?**'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes, as long as the labels, categories, or groups are mapped to a number in
    the set of real numbers.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '**Can I use a classification-based learning algorithm for a regression problem?**'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '**Is the concept of a loss function the same as an error metric?**'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes and no. Yes, in the sense that a loss function will measure performance;
    however, the performance may not necessarily be with respect to the accuracy of
    classifying or regressing the data; it may be with respect to something else,
    such as the quality of groups or distances in information-theoretic spaces. For
    example, linear regression is based on the MSE algorithm as a loss function to
    minimize, while the loss function of the K-means algorithm is the sum of the squared
    distances of the data to their means, which it aims to minimize, but this does
    not necessarily mean it is an error. In the latter case, it is arguably meant
    as a cluster quality measure.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lorena, A. C., De Carvalho, A. C., & Gama, J. M. (2008), A review on the combination
    of binary classifiers in multiclass problems, *Artificial Intelligence Review*,
    30(1-4), 19
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hochreiter, S., Younger, A. S., & Conwell, P. R. (2001, August), Learning to
    learn using gradient descent, in *International Conference on Artificial Neural
    Networks* (pp. 87-94), Springer: Berlin, Heidelberg'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ruder, S. (2016), An overview of gradient descent optimization algorithms, *arXiv*
    *preprint* arXiv:1609.04747
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan, X., Zhang, Y., Tang, S., Shao, J., Wu, F., & Zhuang, Y. (2012, October),
    Logistic tensor regression for classification, in *International Conference on
    Intelligent Science and Intelligent Data Engineering* (pp. 573-581), Springer:
    Berlin, Heidelberg'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krejn, S. G. E. (1982), *Linear Equations in Banach Spaces,* Birkhäuser: Boston'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Golub, G., & Kahan, W. (1965), Calculating the singular values and pseudo-inverse
    of a matrix, *Journal of the Society for Industrial and Applied Mathematics*,
    Series B: Numerical Analysis, 2(2), (pp. 205-224)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kohavi, R. (1995, August), A study of cross-validation and bootstrap for accuracy
    estimation and model selection, in *IJCAI*, 14(2), (pp. 1137-1145)
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bergstra, J. S., Bardenet, R., Bengio, Y., & Kégl, B. (2011), Algorithms for
    hyper-parameter optimization, in *Advances in Neural Information Processing Systems,*
    (pp. 2546-2554)
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feurer, M., Springenberg, J. T., & Hutter, F. (2015, February), Initializing
    Bayesian hyperparameter optimization via meta-learning, in *Twenty-Ninth AAAI
    Conference on Artificial Intelligence*
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loshchilov, I., & Hutter, F. (2016), CMA-ES for hyperparameter optimization
    of deep neural networks, *arXiv preprint* arXiv:1604.07269
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maclaurin, D., Duvenaud, D., & Adams, R. (2015, June), Gradient-based hyperparameter
    optimization through reversible learning, in *International Conference on Machine
    Learning* (pp. 2113-2122)
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rivas-Perea, P., Cota-Ruiz, J., & Rosiles, J. G. (2014), A nonlinear least squares
    quasi-Newton strategy for LP-SVR hyper-parameters selection, *International Journal
    of Machine Learning and Cybernetics*, 5(4), (pp.579-597)
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
