["```py\n    Time (s): 115.22693085670471\n    ```", "```py\n    deeplab_pt_cpu_hybrid.hybridize()\n    Time (s): 64.75840330123901\n    ```", "```py\n    deeplab_pt_cpu_hybrid.hybridize(backend = \"MKLDNN\")\n    Time (s): 55.860424757003784\n    ```", "```py\n    deeplab_pt_cpu_hybrid.hybridize(backend = \"MKLDNN\", static_alloc=True)\n    Time (s): 53.905478715896606\n    ```", "```py\n    deeplab_pt_cpu_hybrid.hybridize(backend = \"MKLDNN\", static_alloc=True, static_shape=True)\n    Time (s): 52.464826822280884\n    ```", "```py\n    Time (s): 13.315197944641113\n    ```", "```py\n    deeplab_pt_gpu_hybrid.hybridize()\n    Time (s): 12.873461246490479\n    ```", "```py\n    deeplab_pt_gpu_hybrid.hybridize(static_alloc=True)\n    Time (s): 12.752988815307617\n    ```", "```py\n    deeplab_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\n    Time (s): 12.583650827407837\n    ```", "```py\ndeeplab_pt_cpu_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_cpu_hybrid, ctx=mx.cpu())\n```", "```py\nTime (s): 56.16465926170349\n```", "```py\ndeeplab_pt_gpu_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_gpu_hybrid, ctx=mx.gpu())\n```", "```py\nTime (s): 3.371366024017334\n```", "```py\na = mx.nd.array([1/3], dtype=mx.np.float32)\n int_value = 85\nscaling_factor = 255\nb = int_value / scaling_factor\nprint(\"1/3 as 0.333... (Float32): {0:.30f}\".format(a.asscalar())))\nprint(\"1/3 as 85/255   (Int8)   : {0:.30f}\".format(b))\n```", "```py\n1/3 as 0.333... (Float32): 0.333333343267440795898437500000\n1/3 as 85/255   (Int8)   : 0.333333333333333314829616256247\n```", "```py\ndeeplab_pt_cpu_q_hybrid = quantization.quantize_net_v2(\ndeeplab_pt_cpu,\n quantized_dtype='auto',\n exclude_layers=None,\n exclude_layers_match=None,\n calib_data=ade20k_cal_loader_gpu_cpu,\n calib_mode='entropy',\n logger=logger,\n ctx=mx.cpu())\n```", "```py\nTime (s): 36.10324692726135\n```", "```py\nmx.profiler.set_config(\nprofile_all=True,\n aggregate_stats=True,\n continuous_dump=True,\n filename='profile_output_cpu.json')\n```", "```py\nmx.profiler.set_state('run')\n[... code statements to analyze ...]\n# Wait until all operations have completed\nmx.nd.waitall()\n# Stop recording\nmx.profiler.set_state('stop')\n# Log results\nmx.profiler.dump()\n```", "```py\nPixAcc:  0.9602144097222223\nmIoU  :  0.4742364603465315\nTime (s): 27.573920726776123\n```", "```py\ndeeplab_pt_cpu_q_hybrid.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)\n```", "```py\n# Dataset Loading & Transforming\n# Limit to 10 samples (last ones)\n max_samples = 10\nsamples = range(0, max_samples)\n p_cal_cpu_pre = mx.gluon.data.SimpleDataset([(pedestrian_val_dataset[-i][0], pedestrian_val_dataset[-i][1]) for i in tqdm(samples)])\n p_cal_gpu_cpu = p_cal_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)\n# DataLoader for Calibration\n# For CPU, Pre-processed in GPU, copied back to CPU memory space)\n num_workers = 0\nbatch_size = 4\np_cal_loader_gpu_cpu = mx.gluon.data.DataLoader(\n    p_cal_gpu_cpu,    batch_size=batch_size,\n    num_workers=num_workers,\n    last_batch=\"discard\")\n```", "```py\ndeeplab_pt_cpu_q_hybrid = quantization.quantize_net_v2(\n    deeplab_pt_cpu,\n    quantized_dtype='auto',\n    exclude_layers=None,\n    exclude_layers_match=None,\n    calib_data=p_cal_loader_gpu_cpu,\n    calib_mode='entropy',\n    logger=logger,\n    ctx=mx.cpu())\n```", "```py\nPixAcc:  0.9595597222222222\nmIoU  :  0.47379941937958425\nTime (s): 8.355125904083252\n```", "```py\n    PixAcc:  0.9602144097222223\n    mIoU  :  0.4742364603465315\n    Time (s): 13.068315982818604\n    ```", "```py\ndeeplab_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\n```", "```py\ndeeplab_pt_gpu_hybrid(single_sample_gpu);\ndeeplab_pt_gpu_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_gpu_hybrid, ctx=mx.gpu())\n```", "```py\nPixAcc:  0.9602565972222222\nmIoU  :  0.4742640561133744\nTime (s): 0.8551054000854492\n```", "```py\ndeeplab_pt_cpu_q_hybrid.export('deeplab_pt_cpu_q_hybrid_sym')\n sym, arg_params, aux_params = mx.model.load_checkpoint('deeplab_pt_cpu_q_hybrid_sym', 0)\n mx.visualization.plot_network(sym)\n```", "```py\ndeeplab_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\n deeplab_pt_gpu_hybrid(single_sample_gpu)\n # Need to be exported externally for the symbols to be loaded\ndeeplab_pt_gpu_hybrid_filename = \"deeplab_resnet101_coco_pt_gpu_hybrid\"\ndeeplab_pt_gpu_hybrid.export(deeplab_pt_gpu_hybrid_filename)\n```", "```py\n# Files exported\nsym_filename = deeplab_pt_gpu_hybrid_filename + \"-symbol.json\"\nparams_filename = deeplab_pt_gpu_hybrid_filename + \"-0000.params\"\nin_shapes = [single_sample_gpu.shape]\n in_types = [mx.np.float32]\n onnx_model_path = mx.onnx.export_model(\n    sym_filename,\n    params_filename,\n    in_shapes,\n    in_types,\n    onnx_file_name)\n```", "```py\n# Model Verification\nimport onnx\n# Load the ONNX model\nonnx_model = onnx.load_model(onnx_model_path)\n # Check the ONNX graph\nonnx.checker.check_graph(onnx_model.graph)\n```", "```py\nimport tensorrt as trt\ntrt_file_name = \"deeplab_resnet101_coco_pt_gpu_hybrid.trt\"\nTRT_LOGGER = trt.Logger(trt.Logger.INFO)\n builder = trt.Builder(TRT_LOGGER)\n config = builder.create_builder_config()\nexplicit_batch = 1 << (int) (trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n deeplab_pt_gpu_hybrid_trt = builder.create_network(explicit_batch)\nwith open(onnx_file_name, 'rb') as model:\n    with trt.OnnxParser(deeplab_pt_gpu_hybrid_trt, TRT_LOGGER) as parser:\n        assert parser.parse(model.read()) == True\n    deeplab_pt_gpu_hybrid_engine_serialized = builder.build_serialized_network(deeplab_pt_gpu_hybrid_trt, config=config)\nwith open(trt_file_name, 'wb') as f:\n    f.write(bytearray(deeplab_pt_gpu_hybrid_engine_serialized))\n```", "```py\n# Check it can be read back\nruntime = trt.Runtime(TRT_LOGGER)\n with open(trt_file_name, 'rb') as f:\n    deeplab_pt_gpu_hybrid_engine_deserialized = runtime.deserialize_cuda_engine(f.read())\n```", "```py\nWMT16 test loss: 1.53; test bleu score: 26.40\nTime (s): 373.5446252822876\n```", "```py\nQualitative Evaluation: Translating from English to German\nExpected translation:\n Ich lerne neue Dinge.\n In English:\n I learn new things every day.\n The German translation is:\n Ich lerne neue Dinge, die in jedem Fall auftreten.\n```", "```py\nwmt_transformer_pt_cpu_hybrid.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)\nloss_function = nlp.loss.MaskedSoftmaxCELoss()\nloss_function.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)\n```", "```py\nWMT16 test loss: 1.53; test bleu score: 26.40\nTime (s): 312.5660226345062\n```", "```py\nQualitative Evaluation: Translating from English to German\nExpected translation:\n Ich lerne neue Dinge.\n In English:\n I learn new things every day.\n The German translation is:\n Ich lerne neue Dinge, die in jedem Fall auftreten.\n```", "```py\n    WMT16 test loss: 1.53; test bleu score: 26.40\n    Time (s): 61.67868137359619\n    ```", "```py\n    Qualitative Evaluation: Translating from English to German\n    Expected translation:\n     Ich lerne neue Dinge.\n     In English:\n     I learn new things every day.\n     The German translation is:\n     Ich lerne neue Dinge, die in jedem Fall auftreten.\n    ```", "```py\nwmt_transformer_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\nloss_function = nlp.loss.MaskedSoftmaxCELoss()\nloss_function.hybridize(static_alloc=True, static_shape=True)\n```", "```py\nWMT16 test loss: 1.53; test bleu score: 26.40\nTime (s): 56.29795598983765\n```", "```py\nQualitative Evaluation: Translating from English to German\nExpected translation:\n Ich lerne neue Dinge.\n In English:\n I learn new things every day.\n The German translation is:\n Ich lerne neue Dinge, die in jedem Fall auftreten.\n```", "```py\nwmt_transformer_pt_gpu_hybrid.save('transformer_pt_gpu_hybrid')\n```", "```py\nassert os.path.exists(\"transformer_pt_gpu_hybrid-model.params\")\nassert os.path.exists(\"transformer_pt_gpu_hybrid-model.json\")\n```"]