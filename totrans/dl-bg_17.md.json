["```py\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Input, Flatten\nfrom tensorflow.keras.layers import BatchNormalization, Dropout, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimg_dims = 28\nimg_chnl = 1 \nltnt_dim = 100\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# this makes sure that each image has a third dimension\nx_train = np.expand_dims(x_train, axis=3)    # 28x28x1\nx_test = np.expand_dims(x_test, axis=3)\n\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n```", "```py\n# building the generator network\ninpt_noise = Input(shape=(ltnt_dim,))\ngl1 = Dense(256, activation='relu')(inpt_noise)\ngl2 = BatchNormalization()(gl1)\ngl3 = Dense(512, activation='relu')(gl2)\ngl4 = BatchNormalization()(gl3)\ngl5 = Dense(1024, activation='relu')(gl4)\ngl6 = BatchNormalization()(gl5)\ngl7 = Dropout(0.5)(gl6)\ngl8= Dense(img_dims*img_dims*img_chnl, activation='sigmoid')(gl7)\ngl9= Reshape((img_dims,img_dims,img_chnl))(gl8)\ngenerator = Model(inpt_noise, gl9)\ngnrtr_img = generator(inpt_noise)\n# uncomment this if you want to see the summary\n# generator.summary()\n```", "```py\n# building the discriminator network\ninpt_img = Input(shape=(img_dims,img_dims,img_chnl))\ndl1 = Flatten()(inpt_img)\ndl2 = Dropout(0.5)(dl1)\ndl3 = Dense(512, activation='relu')(dl2)\ndl4 = Dense(256, activation='relu')(dl3)\ndl5 = Dense(1, activation='sigmoid')(dl4)\ndiscriminator = Model(inpt_img, dl5)\nvalidity = discriminator(gnrtr_img)\n# uncomment this if you want to see the summary\n# discriminator.summary()\n```", "```py\n# you can use either optimizer:\n# optimizer = RMSprop(0.0005)\noptimizer = Adam(0.0002, 0.5)\n\n# compiling the discriminator\ndiscriminator.compile(loss='binary_crossentropy', optimizer=optimizer, \n                      metrics=['accuracy'])\n\n# this will freeze the discriminator in gen_dis below\ndiscriminator.trainable = False\n\ngen_dis = Model(inpt_noise, validity)    # full model\ngen_dis.compile(loss='binary_crossentropy', optimizer=optimizer)\n```", "```py\nepochs = 12001     # this is up to you!\nbatch_size=128    # small batches recommended\nsample_interval=200    # for generating samples\n\n# target vectors\nvalid = np.ones((batch_size, 1))\nfake = np.zeros((batch_size, 1))\n\n# we will need these for plots and generated images\nsamp_imgs = {}\ndloss = []\ngloss = []\ndacc = []\n\n# this loop will train in batches manually for every epoch\nfor epoch in range(epochs):\n  # training the discriminator first >>\n  # batch of valid images\n  idx = np.random.randint(0, x_train.shape[0], batch_size)\n  imgs = x_train[idx]\n\n  # noise batch to generate fake images\n  noise = np.random.uniform(0, 1, (batch_size, ltnt_dim))\n  gen_imgs = generator.predict(noise)\n\n  # gradient descent on the batch\n  d_loss_real = discriminator.train_on_batch(imgs, valid)\n  d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n  # next we train the generator with the discriminator frozen >>\n  # noise batch to generate fake images\n  noise = np.random.uniform(0, 1, (batch_size, ltnt_dim))\n\n  # gradient descent on the batch\n  g_loss = gen_dis.train_on_batch(noise, valid)\n\n  # save performance\n  dloss.append(d_loss[0])\n  dacc.append(d_loss[1])\n  gloss.append(g_loss)\n\n  # print performance every sampling interval\n  if epoch % sample_interval == 0:\n    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % \n           (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n    # use noise to generate some images\n    noise = np.random.uniform(0, 1, (2, ltnt_dim))\n    gen_imgs = generator.predict(noise)\n    samp_imgs[epoch] = gen_imgs    \n```", "```py\n0 [D loss: 0.922930, acc.: 21.48%] [G loss: 0.715504]\n400 [D loss: 0.143821, acc.: 96.88%] [G loss: 4.265501]\n800 [D loss: 0.247173, acc.: 91.80%] [G loss: 4.752715]\n.\n.\n.\n11200 [D loss: 0.617693, acc.: 66.80%] [G loss: 1.071557]\n11600 [D loss: 0.611364, acc.: 66.02%] [G loss: 0.984210]\n12000 [D loss: 0.622592, acc.: 62.50%] [G loss: 1.056955]\n```", "```py\nimport matplotlib.pyplot as plt\n\nfig, ax1 = plt.subplots(figsize=(10,6))\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.plot(range(epochs), gloss, '-.', color='#dc267f', alpha=0.75, \n         label='Generator')\nax1.plot(range(epochs), dloss, '-.', color='#fe6100', alpha=0.75, \n         label='Discriminator')\nax1.legend(loc=1)\nax2 = ax1.twinx()\nax2.set_ylabel('Discriminator Accuracy') \nax2.plot(range(epochs), dacc, color='#785ef0', alpha=0.75, \n         label='Accuracy')\nax2.legend(loc=4)\nfig.tight_layout() \nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(6, 10, figsize=(10,7.5))\ncnt = sample_interval\nfor i in range(6):\n  for j in [0, 2, 4, 6, 8]:\n    img = samp_imgs[cnt]\n    axs[i,j].imshow(img[0,:,:,0], cmap='gray')\n    axs[i,j].axis('off')\n    axs[i,j].set_title(cnt)\n    axs[i,j+1].imshow(img[1,:,:,0], cmap='gray')\n    axs[i,j+1].axis('off')\n    axs[i,j+1].set_title(cnt)\n    cnt += sample_interval\nplt.show()\n```", "```py\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Input, Conv2DTranspose, Flatten\nfrom tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Conv2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimg_dims = 28\nimg_chnl = 1 \nltnt_dim = 100\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = np.expand_dims(x_train, axis=3)\nx_test = np.expand_dims(x_test, axis=3)\n```", "```py\n# building the generator convolutional network\ninpt_noise = Input(shape=(ltnt_dim,))\ngl1 = Dense(7*7*256, activation='relu')(inpt_noise)\ngl2 = BatchNormalization()(gl1)\ngl3 = Reshape((7, 7, 256))(gl2)\ngl4 = Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', \n                      activation='relu')(gl3)\ngl5 = BatchNormalization()(gl4)\ngl6 = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', \n                      activation='relu')(gl5)\ngl7 = BatchNormalization()(gl6)\ngl8 = Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', \n                      activation='sigmoid')(gl7)\ngenerator = Model(inpt_noise, gl8)\ngnrtr_img = generator(inpt_noise)\ngenerator.summary()  # print to verify dimensions\n```", "```py\n# building the critic convolutional network\ninpt_img = Input(shape=(img_dims,img_dims,img_chnl))\ndl1 = Conv2D(64, (5, 5), strides=(2, 2), padding='same', \n             activation='relu')(inpt_img)\ndl2 = Dropout(0.3)(dl1)\ndl3 = Conv2D(128, (5, 5), strides=(2, 2), padding='same', \n             activation='relu')(dl2)\ndl4 = Dropout(0.3)(dl3)\ndl5 = Flatten()(dl4)\ndl6 = Dense(1, activation='sigmoid')(dl5)\ncritic = Model(inpt_img, dl6)\nvalidity = critic(gnrtr_img)\ncritic.summary()   # again, print for verification\n```", "```py\noptimizer = Adam(0.0002, 0.5)\n\ncritic.compile(loss='binary_crossentropy', optimizer=optimizer, \n               metrics=['accuracy'])\n\ncritic.trainable = False\n\ngen_crt = Model(inpt_noise, validity)\ngen_crt.compile(loss='binary_crossentropy', optimizer=optimizer)\n\nepochs = 12001\nbatch_size=64\nsample_interval=400\n```", "```py\nvalid = np.ones((batch_size, 1))\nfake = np.zeros((batch_size, 1))\n\nsamp_imgs = {}\ncloss = []\ngloss = []\ncacc = []\nfor epoch in range(epochs):\n  idx = np.random.randint(0, x_train.shape[0], batch_size)\n  imgs = x_train[idx]\n\n  noise = np.random.uniform(0, 1, (batch_size, ltnt_dim))\n  gen_imgs = generator.predict(noise)\n  c_loss_real = critic.train_on_batch(imgs, valid)\n  c_loss_fake = critic.train_on_batch(gen_imgs, fake)\n  c_loss = 0.5 * np.add(c_loss_real, c_loss_fake)\n\n  noise = np.random.uniform(0, 1, (batch_size, ltnt_dim))\n  g_loss = gen_crt.train_on_batch(noise, valid)\n\n  closs.append(c_loss[0])\n  cacc.append(c_loss[1])\n  gloss.append(g_loss)\n\n  if epoch % sample_interval == 0:\n    print (\"%d [C loss: %f, acc.: %.2f%%] [G loss: %f]\" % \n           (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n    noise = np.random.uniform(0, 1, (2, ltnt_dim))\n    gen_imgs = generator.predict(noise)\n    samp_imgs[epoch] = gen_imgs    \n```", "```py\nModel: \"Generator\"\n_________________________________________________________________\nLayer (type)                   Output Shape       Param # \n=================================================================\ninput_1 (InputLayer)           [(None, 100)]      0 \n_________________________________________________________________\ndense_1 (Dense)                (None, 12544)      1266944 \n_________________________________________________________________\nbatch_normalization_1 (Batch   (None, 12544)      50176 \n_________________________________________________________________\nreshape (Reshape)              (None, 7, 7, 256)  0 \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTran (None, 7, 7, 128)  819328 \n_________________________________________________________________\nbatch_normalization_2 (Batch   (None, 7, 7, 128)  512 \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr   (None, 14, 14, 64) 204864 \n_________________________________________________________________\nbatch_normalization_3 (Batch   (None, 14, 14, 64) 256 \n_________________________________________________________________\nconv2d_transpose_3 (Conv2DTr   (None, 28, 28, 1)  1601 \n=================================================================\nTotal params: 2,343,681\nTrainable params: 2,318,209\nNon-trainable params: 25,472\n```", "```py\n_________________________________________________________________\nModel: \"Critic\"\n_________________________________________________________________\nLayer (type)         Output Shape         Param # \n=================================================================\ninput_2 (InputLayer) [(None, 28, 28, 1)]  0 \n_________________________________________________________________\nconv2d_1 (Conv2D)    (None, 14, 14, 64)   1664 \n_________________________________________________________________\ndropout_1 (Dropout)  (None, 14, 14, 64)   0 \n_________________________________________________________________\nconv2d_2 (Conv2D)    (None, 7, 7, 128)    204928 \n_________________________________________________________________\ndropout_2 (Dropout)  (None, 7, 7, 128)    0 \n_________________________________________________________________\nflatten (Flatten)    (None, 6272)         0 \n_________________________________________________________________\ndense_2 (Dense)      (None, 1)             6273 \n=================================================================\nTotal params: 212,865\nTrainable params: 212,865\nNon-trainable params: 0\n```", "```py\n0 [C loss: 0.719159, acc.: 22.66%] [G loss: 0.680779]\n400 [C loss: 0.000324, acc.: 100.00%] [G loss: 0.000151]\n800 [C loss: 0.731860, acc.: 59.38%] [G loss: 0.572153]\n.\n.\n.\n11200 [C loss: 0.613043, acc.: 66.41%] [G loss: 0.946724]\n11600 [C loss: 0.613043, acc.: 66.41%] [G loss: 0.869602]\n12000 [C loss: 0.613043, acc.: 66.41%] [G loss: 0.854222]\n```", "```py\nimport matplotlib.pyplot as plt\n\nfig, ax1 = plt.subplots(figsize=(10,6))\n\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.plot(range(epochs), gloss, '-.', color='#dc267f', alpha=0.75, \n         label='Generator')\nax1.plot(range(epochs), closs, '-.', color='#fe6100', alpha=0.75, \n         label='Critic')\nax1.legend(loc=1)\nax2 = ax1.twinx() \n\nax2.set_ylabel('Critic Accuracy') \nax2.plot(range(epochs), cacc, color='#785ef0', alpha=0.75, \n         label='Accuracy')\nax2.legend(loc=4)\n\nfig.tight_layout() \nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(10,10))\nsamples = np.random.uniform(0.0, 1.0, size=(400,ltnt_dim))\nimgs = generator.predict(samples)\nfor cnt in range(20*20):\n  plt.subplot(20,20,cnt+1)\n  img = imgs[cnt]\n  plt.imshow(img[:,:,0], cmap='gray')\n  plt.xticks([])\n  plt.yticks([])\nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(10,10))\nsamples = np.random.normal(0.0, 1.0, size=(400,ltnt_dim))\nimgs = decoder.predict(samples)\nfor cnt in range(20*20):\n  plt.subplot(20,20,cnt+1)\n  img = imgs[cnt].reshape((28,28))\n  plt.imshow(img, cmap='gray')\n  plt.xticks([])\n  plt.yticks([])\nplt.show()\n```"]