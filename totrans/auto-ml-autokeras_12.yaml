- en: '*Chapter 9*: Working with Multimodal and Multitasking Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to use the AutoModel API to handle multimodal
    and multitasking data.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned how to use the concepts and
    tools necessary to create models with multiple inputs and multiple outputs. You
    will be able to apply these concepts to your own projects by creating a model
    from scratch or by adapting the practical example shown in this chapter to other,
    similar datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring models with multiple input or outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a multitasking/multimodal model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customizing the search space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But first, let's explain the technical requirements for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the code examples in this book are available as Jupyter notebooks that can
    be downloaded from [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras).
  prefs: []
  type: TYPE_NORMAL
- en: Since code cells can be executed, each notebook can be self-installed; simply
    add the code snippet that contains the requirements you need. For this reason,
    at the beginning of each notebook, there is a code cell for environment setup
    that installs AutoKeras and its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to run the code examples in this chapter, you only need a computer with
    Ubuntu Linux as its OS and must install the Jupyter Notebook with the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Alternatively, you can also run these notebooks using Google Colaboratory, in
    which case you will only need a web browser. See [*Chapter 2*](B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029),
    *AutoKeras with Google Colaboratory*, for more details. Furthermore, in the *Installing
    AutoKeras* section of that chapter, you will find other installation options.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's put these concepts we mentioned in the introduction into practice
    by looking at a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring models with multiple inputs or outputs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we will see later, sometimes, it may interest us that our model feeds on
    information from different sources (multimodal) and/or predicts multiple targets
    at the same time (multitask). AutoKeras has a class called **AutoModel** that
    allows us to define several sources and targets as a list of parameters. Let's
    dive a little deeper into this before looking at a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: What is AutoModel?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AutoModel is a class that allows us to define a model in a granular way by defining
    not only its inputs and outputs but also its intermediate layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'It can be used in two different ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic**: Here, the input/output nodes are specified and AutoModel infers
    the remaining part of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advanced**: Here, the high-level architecture is defined by connecting the
    layers (blocks) with the Functional API, which is the same as the Keras functional
    API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's look at an example of each one.
  prefs: []
  type: TYPE_NORMAL
- en: Basic example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The user only specifies the input nodes and output heads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's look at an advanced example.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The user specifies the high-level architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we configured AutoModel to create a model with multiple
    inputs (multimodal) and several outputs (multitask). Next, we will explain these
    concepts and see them in action by creating our own multimodel.
  prefs: []
  type: TYPE_NORMAL
- en: What is multimodal?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We say that data is multimodal when each data instance contains multiple forms
    of information. For example, we can save a photo as an image, but in addition
    to that image, it also contains *meta* information about where it was taken. This
    meta information can be treated as structured data.
  prefs: []
  type: TYPE_NORMAL
- en: What is multitask?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We say that a model is multitask when it predicts multiple targets with the
    same input features. For example, let's say we want to classify photos of people
    by ethnic groups, but at the same time, we want to specify their age as a number
    between 0 and 100.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows an example of a multimodal and multitask neural
    network model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Example of a multimodal and multitask neural network model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_09_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.1 – Example of a multimodal and multitask neural network model
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that there are two entries: **images** (**ImageInput**) and
    **structured data** (**StructuredDataInput**). Each image is associated with a
    set of attributes in the structured data. From this data, we can try to predict
    the **classification label** (**ClassificationHead**) and the **regression value**
    (**RegressionHead**) at the same time.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at these concepts in more detail by looking at a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a multitask/multimodal model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Based on the example provided at the beginning of this chapter, the model that
    we are going to create will take an image and its structured data attributes as
    input and will predict a category value and a scalar value. In this case, instead
    of using a dataset, we will generate our own data. The notebook we will be using
    that contains the complete source code can be found at [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter09/Chapter9_MultiModel.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter09/Chapter9_MultiModel.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s have a look at the relevant cells of the notebook in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Installing AutoKeras**: As we''ve mentioned in the previous chapters, this
    snippet at the top of the notebook is responsible for installing AutoKeras and
    its dependencies using the pip package manager:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`numpy`, and `AutoKeras` as the necessary dependencies for this project:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Creating the datasets**: First, we are going to create the datasets by generating
    a random image and structured data as multimodal data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, generate some multitask targets for classification and regression:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, it's time to create the model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will create the model using `AutoModel`, first in its basic configuration
    and then in its advanced one. As in the previous examples, we will set a small
    amount of `max_trials` and `epochs` so that the training process doesn't take
    too long.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will initialize the model with multiple inputs and outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the previous code, we have defined two inputs (image and structured data)
    and two outputs (regression and classification). Here, we are telling the model
    that we want to train our input data with a regressor and a classifier at the
    same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s run the training process to search for the optimal model for the
    training dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Notebook output of model training'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_09_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.2 – Notebook output of model training
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the previous examples, here, we can see that the output shows two losses
    – one for the regressor and one for the classifier. In this case, the data is
    generated randomly, so there is no point in looking at performance for evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s look at a little summary of the architecture for the best generated
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Best model architecture summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16953_09_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.3 – Best model architecture summary
  prefs: []
  type: TYPE_NORMAL
- en: Let's briefly describe the blocks that were used for this model.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, AutoKeras creates two submodels – one for each piece of input
    data. It has chosen a deep residual network architecture (**resnet50**), which
    we already presented in [*Chapter 4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063),
    *Image Classification and Regression using AutoKeras*, to process the image data
    and a couple of fully connected layers to ingest the structured data. After digesting
    the two data sources, the results of both submodels are concatenated and separated
    again to generate the two different outputs (a scalar value and a category value).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a visual representation of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Best model architecture visualization](img/B16953_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Best model architecture visualization
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's use AutoModel in a more advanced mode to customize the intermediate
    blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Customizing the search space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned at the beginning of this chapter, there is an advanced way to
    use AutoModel. We can do this by defining the whole model architecture by connecting
    the layers (blocks) with the functional API, which is the same as the Keras functional
    API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do this in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have defined each block sequentially by connecting the output of one
    to the input of the next. In this case, we've customized the model by adding some
    image preprocessing blocks for normalization and augmentation. We've also placed
    a convolutional layer in parallel to the ResNet layer to train the image data,
    which has also been customized. You can even specify the version of the ResNet
    architecture you want to use.
  prefs: []
  type: TYPE_NORMAL
- en: Although this mode is more complex, it is much more powerful and flexible. Note
    that you can even specify the version of the ResNet architecture that you want
    to use (v2). It is important to note that for parameters (such as version) that
    haven't been customized, AutoKeras will try different combinations of values to
    find the most optimal one.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned what a multitasking model is, what a multimodal
    model is, and how to use the powerful AutoModel class to create efficient models
    with multiple inputs and outputs. You are now ready to apply these concepts to
    your own multimodel projects by creating them from scratch or by adapting this
    practical example for your own datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to export our models and how to use a
    powerful visualization tool to track and visualize metrics such as loss and accuracy
    in real-time graphs.
  prefs: []
  type: TYPE_NORMAL
