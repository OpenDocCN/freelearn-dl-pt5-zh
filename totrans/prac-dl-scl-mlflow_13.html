<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer085" class="Content">
			<h1 id="_idParaDest-112"><a id="_idTextAnchor111"/>Section 5 â€“ Deep Learning Model Explainability at Scale</h1>
			<p>In this section, we will learn about the foundational concepts of explainability and <strong class="bold">explainable artificial intelligence</strong> (<strong class="bold">XAI</strong>) and how to implement <strong class="bold">deep learning </strong>(<strong class="bold">DL</strong>) explainability with MLflow. We will start with an overview of the eight dimensions of explainability and then learn how to use <strong class="bold">SHapley Additive exPlanations</strong> (<strong class="bold">SHAP</strong>) and <strong class="bold">Transformers Interpret</strong> to perform explainability for a <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) pipeline. Furthermore, we will learn and analyze the current MLflow integration with SHAP to understand the trade-offs and avoid potential implementation problems. Then, we will show how to implement SHAP using MLflow's logging APIs. Finally, we will learn how to implement a SHAP explainer as an MLflow Python model and then load it as either a Spark UDF for batch explanation or as a web service for online <strong class="bold">Explanation-as-a-Service</strong> (<strong class="bold">EaaS</strong>).</p>
			<p>This section comprises the following chapters:</p>
			<ul>
				<li><a href="B18120_09_ePub.xhtml#_idTextAnchor112"><em class="italic">Chapter 9</em></a>,<em class="italic"> Fundamentals of Deep Learning Explainability</em> </li>
				<li><a href="B18120_10_ePub.xhtml#_idTextAnchor127"><em class="italic">Chapter 10</em></a>, <em class="italic">Implementing DL Explainability with MLflow</em></li>
			</ul>
		</div>
	</div></body></html>