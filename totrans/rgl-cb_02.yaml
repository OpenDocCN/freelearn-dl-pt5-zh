- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine Learning Refresher
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Machine learning** (**ML**) is much more than just models. It is about following
    a certain process and best practices. This chapter will provide a refresher on
    these: from loading data and model evaluation to model training and optimization,
    the main steps and methods will be explained here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Loading data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing quantitative data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing qualitative data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing hyperparameter optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even though the recipes in this chapter are independent from a methodological
    standpoint, they build upon each other and are meant to be executed sequentially.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you will need to be able to run code to load datasets, prepare
    data, and train, optimize, and evaluate ML models. To do so, you will need the
    following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**numpy**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pandas**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scikit-learn**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'They can be installed using `pip` with the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In this book, some best practices such as using virtual environments won’t be
    explicitly mentioned. However, it is highly recommended that you use a virtual
    environment before installing any library using `pip` or any other package manager.
  prefs: []
  type: TYPE_NORMAL
- en: Loading data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary focus of this recipe is to load data from a CSV file. However, this
    is not the only thing that this recipe covers. Since the data is usually the first
    step in any ML project, this recipe is also a good opportunity to give a quick
    recap of the ML workflow, as well as the different types of data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before loading the data, we should keep in mind that an ML model follows a
    two-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: Train a model on a given dataset to create a new model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reuse the previously trained model to infer predictions on new data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'These two steps are summarized in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – A simple view of the two-step ML process](img/B19629_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – A simple view of the two-step ML process
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, in most cases, this is a rather simplistic view. A more detailed
    view can be seen in Figure 2.2:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – A more complete view of the ML process](img/B19629_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – A more complete view of the ML process
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a closer look at the training part of the ML process shown in *Figure
    2**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: First, training data is queried from a data source (this can be a database,
    a data lake, an open dataset, and so on).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The data is preprocessed, such as via feature engineering, rescaling, and so
    on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A model is trained and stored (on a data lake, locally, on the edge, and so
    on).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optionally, the output of this model is post-processed – for example, via formatting,
    heuristics, business rules, and more.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optionally again, this model (with or without postprocessing) is stored in a
    database for later reference or evaluation if needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let’s take a look at the inference part of the ML process:'
  prefs: []
  type: TYPE_NORMAL
- en: The data is queried from a data source (a database, an API query, and so on).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The data goes through the same preprocessing step as the training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The trained model is fetched if it doesn’t already exist locally.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model is used to infer output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optionally, the output of the model is post-processed via the same post-processing
    step as the training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optionally, the output is stored in a database for monitoring and later reference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Even in this schema, many steps were not mentioned: splitting data for training
    purposes, using evaluation metrics, cross-validation, hyperparameter optimization,
    and others. This chapter will dive into the more training-specific steps and apply
    them to the very common but practical Titanic dataset, a binary classification
    problem. But first, we need to load the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, you must download the **Titanic dataset training set** locally. This
    can be performed with the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe is about loading a CSV file and displaying a few lines of code
    so that we can have a first glance at what it is about:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to import the required libraries. Here, the only library
    we need is pandas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can load the data using the `read_csv` function provided by pandas.
    The first argument is the path to the file. Assuming the file is named `train.csv`
    and located in the current folder, we only have to provide `train.csv` as an argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The returned object is a `dataframe` object, which provides many useful methods
    for data processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can display the first five lines of the loaded file using the `.``head()`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code will output the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a description of the data types in each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PassengerId` (qualitative): A unique, arbitrary ID for each passenger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Survived` (qualitative): 1 for yes, 0 for no. This is our label, so this is
    a binary classification problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Pclass` (quantitative, discrete): The class, which is arguably quantitative.
    Is class 1 better than class 2? Most likely yes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Name` (unstructured): The name and title of the passenger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sex` (qualitative): The registered sex of the passenger, either male or female.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Age` (quantitative, discrete): The age of the passenger.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SibSp` (quantitative, discrete): The number of siblings and spouses on board.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Parch` (quantitative, discrete): The number of parents and children on board.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ticket` (unstructured): The ticket reference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Fare` (quantitative, continuous): The ticket price.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Cabin` (unstructured): The cabin number, which is arguably unstructured. It
    can be seen as a qualitative feature with high cardinality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Embarked` (qualitative): The embarked city, either Southampton (`S`), Cherbourg
    (`C`), or Queenstown (`Q`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s talk about the different types of data that are available. Data is a very
    generic word and can describe many things. We are surrounded by data all the time.
    One way to specify data is using opposites.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data can be *structured* or *unstructured*:'
  prefs: []
  type: TYPE_NORMAL
- en: Structured data comes in the form of tables, databases, Excel files, CSV files,
    and JSON files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Unstructured data does not fit in a table: it can be text, sound, image, videos,
    and so on. Even if we tend to have tabular representation, this kind of data does
    not naturally fit in an Excel table.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data can be *quantitative* or *qualitative*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Quantitative data is ordered. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: €100 is greater than €10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1.8 meters is taller than 1.6 meters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 18 years old is younger than 80 years old
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qualitative data has no intrinsic order, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: Blue is not intrinsically better than red
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dog is not intrinsically greater than a cat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A kitchen is not intrinsically more useful than a bathroom
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are not mutually exclusive. An object can have both quantitative and
    qualitative features, as can be seen in the case of the car in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – A single object depicted by both quantitative (left) and qualitative
    (right) features](img/B19629_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – A single object depicted by both quantitative (left) and qualitative
    (right) features
  prefs: []
  type: TYPE_NORMAL
- en: Finally, data can be *continuous* or *discrete*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some data is continuous, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A weight
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A volume
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A price
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the other hand, some data is discrete:'
  prefs: []
  type: TYPE_NORMAL
- en: A color
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A football score
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A nationality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Discrete != qualitative.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a football score is discrete, but there is an intrinsic order:
    3 points is more than 2.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The pandas `read_csv` function has a lot of flexibility as it can use other
    separators, handle headers, and much more. This is described in the official documentation:
    [https://pandas.pydata.org/docs/reference/api/pandas.read_csv.xhtml](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The pandas library allows I/O operations that have different types of inputs.
    For more information, have a look at the official documentation: [https://pandas.pydata.org/docs/reference/io.xhtml](https://pandas.pydata.org/docs/reference/io.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: Splitting data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After loading data, splitting it is a crucial step. This recipe will explain
    why we need to split data, as well as how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Why do we need to split data? An ML model is quite like a student.
  prefs: []
  type: TYPE_NORMAL
- en: You provide a student with many lectures and exercises, with or without the
    answers. But more often than not, students are evaluated on a completely new problem.
    To make sure they fully understand the concepts and methods, they not only learn
    the exercises and solutions – they also understand the underlying concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'An ML model is no different: you train the model on training data and then
    evaluate it on test data. This way, you make sure the model fully understands
    the task and generalizes well to new, unseen data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the dataset is usually split into *train* and *test* sets:'
  prefs: []
  type: TYPE_NORMAL
- en: The train set must be as large as possible to give as many samples as possible
    to the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test set must be large enough to be statistically significant in evaluating
    the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typical splits can be anywhere between 80% to 20% for rather small datasets
    (for example, hundreds of samples), and 99% to 1% for very large datasets (for
    example, millions of samples and more).
  prefs: []
  type: TYPE_NORMAL
- en: For this recipe and the others in this chapter, it is assumed that the code
    has been executed in the same notebook as the previous recipe since each recipe
    reuses the code from the previous ones.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the steps to try out this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can split the data rather easily with scikit-learn and the `train_test_split()`
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This function uses the following parameters as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '`X`: All columns but the `''``Survived''` label'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y`: The `''Survived''` label column'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_size`: This is `0.2`, which means the training size will be 80%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stratify`: This specifies the `''Survived''` column to ensure the same label
    balance is used in both splits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_state`: `0` is any integer to ensure reproducibility'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It returns the following outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`X_train`: The train split of `X`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`X_test`: The test split of `X`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y_train`: The training split of `y`, associated with `X_train`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y_test`: The test split of `y`, associated with `X_test`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `stratify` option is not mandatory but can be critical to ensure a balanced
    split of any qualitative feature, not just the labels, as is the case with imbalanced
    data.
  prefs: []
  type: TYPE_NORMAL
- en: This split should be done as early as possible when performing data processing
    so that you avoid any potential data leakage. From now on, all the preprocessing
    will be computed on the train set, and only then applied to the test set, in agreement
    with *Figure 2**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'See the official documentation for the `train_test_split` function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing quantitative data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Depending on the type of data, how the features must be prepared may differ.
    In this recipe, we’ll cover how to prepare quantitative data, including missing
    data imputation and rescaling.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the Titanic dataset, as well as any other dataset, there may be missing data.
    There are several ways to deal with missing data. For example, you can drop a
    column or a row, or impute a value. There are many imputation techniques, some
    of which are more or less sophisticated. scikit-learn supplies several implementations
    of imputers, such as `SimpleImputer` and `KNNImputer`.
  prefs: []
  type: TYPE_NORMAL
- en: As we will see in this recipe, using `SimpleImputer`, we can impute the missing
    quantitative data with the mean value.
  prefs: []
  type: TYPE_NORMAL
- en: Once the missing data has been handled, we can prepare the quantitative data
    by rescaling it so that all the data is at the same scale.
  prefs: []
  type: TYPE_NORMAL
- en: Several rescaling strategies exist, such as min-max scaling, robust scaling,
    standard scaling, and others.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we will use **standard scaling**. So, for each feature, we
    will subtract the mean value of this feature, and then divide it by the standard
    deviation of that feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Fortunately, scikit-learn provides a fully working implementation via `StandardScaler`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will sequentially handle missing values and rescale the data in this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required classes – `SimpleImputer` for missing data imputation and
    `StandardScaler` for rescaling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select the quantitative features we want to keep. Here, we will keep `''Pclass''`,
    `''Age''`, `''Fare''`, `''SibSp''`, and `''Parch''` and store these features in
    new variables for both the train and test sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the simple imputer with a mean strategy. Here, the missing value
    of a feature will be replaced with the mean value of that feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the imputer on the train set and apply it to the test set so that it avoids
    leakage in the imputation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that imputation has been performed, instantiate the `scaler` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, fit and apply the standard scaler to the train set, and then apply
    it to the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We now have quantitative data with no missing values, fully rescaled, with no
    data leakage.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we used the simple imputer, assuming there was missing data.
    In practice, it is highly recommended that you look at the data first to check
    whether there are missing values, as well as how many. It is possible to look
    at the number of missing values per column with the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This will output the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to this, we know that the `Age` feature has `146` missing values, while
    the other features have no missing data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A few imputers are available in scikit-learn. The list is available here: [https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.impute](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.impute).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways to scale data, and you can find the methods that are available
    in scikit-learn here: [https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.preprocessing).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might be interested in looking at this comparison of several scalers on
    some given data: [https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.xhtml#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.xhtml#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py).'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing qualitative data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will prepare qualitative data, including missing value imputation
    and encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Qualitative data requires different treatment from quantitative data. Imputing
    missing values with the mean value of a feature would make no sense (and would
    not work with non-numeric data): it makes more sense, for example, to use the
    most frequent value or the mode of a feature. The `SimpleImputer` class allows
    us to do such things.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The same goes for rescaling: it would make no sense to rescale qualitative
    data. Instead, it is more common to encode it. One of the most typical techniques
    is called **one-hot encoding**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea is to transform each of the categories, over a total possible *N*
    categories, in a vector holding a 1 and N-1 zeros. In our example, the `Embarked`
    feature’s one-hot encoding would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*‘C’ = [1,* *0, 0]*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*‘Q’ = [0,* *1, 0]*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*‘S’ = [0,* *0, 1]*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Having *N* columns for *N* categories is not necessarily optimal. What happens
    if, in the preceding example, we remove the first column? If the value is not
    *‘Q’ = [1, 0]* nor *‘S’ = [0, 1]*, then it must *be ‘C’ = [0, 0]*. There is no
    need to add one more column to have all the necessary information. This can be
    generalized to *N* categories only requiring *N*-1 columns to have all the information,
    which is why one-hot encoding functions usually allow you to drop a column.
  prefs: []
  type: TYPE_NORMAL
- en: The `sklearn` class’ `OneHotEncoder` allows us to do this. It also allows us
    to deal with unknown categories that may appear in the test set (or the production
    environment) with several strategies, such as an error, ignore, or infrequent
    class. Finally, it allows us to drop the first column after encoding.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just like in the preceding recipe, we will handle any missing data and the
    features will be one-hot encoded:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary classes – `SimpleImputer` for missing data imputation
    (already imported in the previous recipe) and `OneHotEncoder` for encoding. We
    also need to import `numpy` so that we can concatenate the qualitative and quantitative
    data that’s been prepared at the end of this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select the qualitative features we want to keep: `''Sex''` and `''Embarked''`.
    Then, store these features in new variables for both the train and test sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate `SimpleImputer` with `most_frequent strategy`. Any missing values
    will be replaced by the most frequent ones:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit and transform the imputer on the train set, and then transform the test
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the encoder. Here, we will specify the following parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`drop=''first''`: This will drop the first columns of the encoding'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`handle_unknown=''ignore''`: If a new value appears in the test set (or in
    production), it will be encoded as zeros:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit and transform the encoder on the training set, and then transform the test
    set using this encoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We need to use `.toarray()` out of the encoder because the array is a sparse
    matrix object by default and cannot be concatenated in that form with the other
    features.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, all the data has been prepared – both quantitative and qualitative
    (considering this recipe and the previous one). It is now possible to concatenate
    this data before training a model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is possible to save the data as a pickle file, either to share it or save
    it and avoid having to prepare it again. The following code will allow us to do
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We now have fully prepared data that can be used to train ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Several steps have been omitted or simplified here for more clarity. Data may
    need more preparation, such as more thorough missing value imputation, outlier
    and duplicate detection (and perhaps removal), feature engineering, and so on.
    It is assumed that you already have some sense of those aspects and are encouraged
    to read other materials about this topic if required.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This more general documentation about missing data imputation is worth looking
    at: [https://scikit-learn.org/stable/modules/impute.xhtml](https://scikit-learn.org/stable/modules/impute.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, this more general documentation about data preprocessing can be very
    useful: [https://scikit-learn.org/stable/modules/preprocessing.xhtml](https://scikit-learn.org/stable/modules/preprocessing.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: Training a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once data has been fully cleaned and prepared, it is fairly easy to train a
    model thanks to scikit-learn. In this recipe, before training a logistic regression
    model on the Titanic dataset, we will quickly recap the ML paradigm and the different
    types of ML we can use.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you were asked how to differentiate a car from a truck, you may be tempted
    to provide a list of rules, such as the number of wheels, size, weight, and so
    on. By doing so, you would be able to provide a set of explicit rules that would
    allow anyone to identify a car and a truck as different types of vehicles.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional programming is not so different. While developing algorithms, programmers
    often build explicit rules, which allow them to map from data input (for example,
    a vehicle) to answers (for example, a car). We can summarize this paradigm as
    *data + rules =* *answers*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we were to train an ML model to discriminate cars from trucks, we would
    use another strategy: we would feed an ML algorithm with many pieces of data and
    their associated answers, expecting the model to learn to correct rules by itself.
    This is a different approach that can be summarized as *data + answers = rules*.
    This paradigm difference is summarized in *Figure 2**.4*. As little as it might
    look to ML practitioners, it changes everything in terms of regularization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Comparing traditional programming with ML algorithms](img/B19629_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – Comparing traditional programming with ML algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Regularizing traditional algorithms is conceptually straightforward. For example,
    what if the rules for defining a truck overlap with the bus definition? If so,
    we can add the fact that buses have lots of windows.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization in ML is intrinsically implicit. What if the model in this case
    does not discriminate between buses and trucks?
  prefs: []
  type: TYPE_NORMAL
- en: Should we add more data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the model complex enough to capture such a difference?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is it underfitting or overfitting?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This fundamental property of ML makes regularization complex.
  prefs: []
  type: TYPE_NORMAL
- en: ML can be applied to many tasks. Anyone who uses ML knows there is not just
    one type of ML model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Arguably, most ML models fall into three main categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised learning**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unsupervised learning**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reinforcement learning**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As is usually the case for categories, the landscape is more complex, with sub-categories
    and methods overlapping several categories. But this is beyond the scope of this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: 'This book will focus on regularization for supervised learning. In supervised
    learning, the problem is usually quite easy to specify: we have input features,
    *X* (for example, apartment surface), and labels, *y* (for example, apartment
    price). The goal is to train a model so that it’s robust enough to predict *y*,
    given *X*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The two major types of ML are classification and regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification**: The labels are made of qualitative data. For example, the
    task is predicting between two or more classes such as car, bus, and truck.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression**: The labels are made of quantitative data. For example, the
    task is predicting an actual value, such as an apartment price.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Again, the line can be blurry; some tasks can be solved with classification
    while the labels are quantitative data, while others tasks can be both classification
    and regression ones. See *Figure 2**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Regularization versus classification](img/B19629_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – Regularization versus classification
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Assuming we want to train a logistic regression model (which will be explained
    properly in the next chapter), the scikit-learn library provides the `LogisticRegression`
    class, along with the `fit()` and `predict()` methods. Let’s learn how to use
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `LogisticRegression` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `LogisticRegression` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model on the train set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Optionally, compute predictions by using that model on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Even though more details will be provided in the next chapter, you might be
    interested in looking at the documentation of the `LogisticRegression` class:
    [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the model has been trained, it is important to evaluate it. In this recipe,
    we will provide a few insights about a few typical metrics for both classification
    and regression, before evaluating our model on the test set.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many evaluation metrics exist. If we think about predicting a binary classification
    and take a step back, there are only four cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**False positive** (**FP**): Positive prediction, negative ground truth'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True positive** (**TP**): Positive prediction, positive ground truth'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True negative** (**TN**): Negative prediction, negative ground truth'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False negative** (**FN**): Negative prediction, positive ground truth:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Representation of false positive, true positive, true negative,
    and false negative](img/B19629_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 – Representation of false positive, true positive, true negative,
    and false negative
  prefs: []
  type: TYPE_NORMAL
- en: Based on this, we can define a wide range of evaluation metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most common metrics is accuracy, which is the ratio of good predictions.
    The definition of accuracy is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Although very common, the accuracy may be misleading, especially for imbalanced
    labels. For example, let’s assume an extreme case where 99% of Titanic passengers
    survived, and we have a model that predicts that every passenger survived. Our
    model would have a 99% accuracy but would be wrong for 100% of passengers who
    did not survive.
  prefs: []
  type: TYPE_NORMAL
- en: There are several other very common metrics, such as precision, recall, and
    the F1 score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Precision is most suited when you’re trying to maximize the true positives
    and minimize the false positives – for example, making sure you detect only surviving
    passengers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Recall is most suited when you’re trying to maximize the true positives and
    minimize the false negatives – for example, making sure you don’t miss any surviving
    passengers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The F1 score is just a combination of the precision and recall metrics as a
    harmonic mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Another useful classification evaluation metric is the **Receiver Operating
    Characteristic Area Under Curve** (**ROC** **AUC**) score.
  prefs: []
  type: TYPE_NORMAL
- en: 'All these metrics behave similarly: when there are values between 0 and 1,
    the higher the value, the better the model. Some are also more robust to imbalanced
    labels, especially the F1 score and ROC AUC.'
  prefs: []
  type: TYPE_NORMAL
- en: For regression tasks, the most used metrics are the **mean squared error** (**MSE**)
    and the R2 score.
  prefs: []
  type: TYPE_NORMAL
- en: 'The MSE is the averaged square difference between the predictions and the ground
    truth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *m* is the number of samples, *ŷ* is the predictions, and *y* is the
    ground truth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Visualization of the errors for a regression task](img/B19629_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 – Visualization of the errors for a regression task
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of the R2 score, it is a metric that can be negative and is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_02_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: While the R2 score is a typical evaluation metric (the closer to 1, the better),
    the MSE is more typical of a loss function (the closer to 0, the better).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Assuming our chosen evaluation metric here is accuracy, a very simple way to
    evaluate our model is to use the `accuracy_score()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'This outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `accuracy_score()` function provides an accuracy of 78.77%, meaning
    about 79% of our model’s predictions are right.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is a list of the available metrics in scikit-learn: [https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.metrics](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.metrics).'
  prefs: []
  type: TYPE_NORMAL
- en: Performing hyperparameter optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will explain what hyperparameter optimization is and some
    related concepts: the definition of a **hyperparameter**, **cross-validation**,
    and various **hyperparameter optimization methods**. We will then perform a grid
    search to optimize the hyperparameters of the logistic regression task on the
    Titanic dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most of the time, in ML, we do not simply train a model on the training set
    and evaluate it against the test set.
  prefs: []
  type: TYPE_NORMAL
- en: This is because, like most other algorithms, ML algorithms can be fine-tuned.
    This fine-tuning process allows us to optimize hyperparameters to achieve the
    best possible results. This sometimes acts as leverage so that we can regularize
    a model.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In ML, hyperparameters can be tuned by humans, unlike parameters, which are
    learned through the model training process, and thus can’t be tuned.
  prefs: []
  type: TYPE_NORMAL
- en: 'To properly optimize hyperparameters, a third split has to be introduced: the
    validation set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means there are now three splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The training set**: Where the model is trained'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The validation set**: Where the hyperparameters are optimized'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The test set**: Where the model is evaluated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You could create such a set by splitting `X_train` into `X_train` and `X_valid`
    with the `train_test_split()` function from scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'But in practice, most people just use cross-validation and do not bother creating
    this validation set. The k-fold cross-validation method allows us to make *k*
    splits out of the training set and divide it, as presented in *Figure 2**.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Typical split between training, validation, and test sets, without
    cross-validation (top) and with cross-validation (bottom)](img/B19629_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 – Typical split between training, validation, and test sets, without
    cross-validation (top) and with cross-validation (bottom)
  prefs: []
  type: TYPE_NORMAL
- en: In doing so, not just one model is trained, but *k*, for a given set of hyperparameters.
    The performances are averaged over those *k* models, based on a chosen metric
    (for example, accuracy, MSE, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Several sets of hyperparameters can then be tested, and the one that shows the
    best performance is selected. After selecting the best hyperparameter set, the
    model is trained one more time on the entire train set to maximize the data for
    training purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you can implement several strategies to optimize the hyperparameters,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Grid search**: Test all combinations of the provided values of hyperparameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random search**: Randomly search combinations of hyperparameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bayesian search**: Perform Bayesian optimization on the hyperparameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While being rather complicated to explain conceptually, hyperparameter optimization
    with cross-validation is super easy to implement. In this recipe, we’ll assume
    that we want to optimize a logistic regression model to predict whether a passenger
    would have survived:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to import the `GridSearchCV` class from `sklearn.model_selection`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We would like to test the following hyperparameter values for `C`: `[0.01,
    0.03, 0.1]`. We must define a parameter grid with the hyperparameter as the key
    and the list of values to test as the value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `C` hyperparameter is the inverse of the penalization strength: the higher
    `C` is, the lower the regularization. See the next chapter for more details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s assume we want to optimize our model on accuracy, with five
    cross-validation folds. To do this, we will instantiate the `GridSearchCV` object
    and provide the following arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model to optimize, which is a `LogisticRegression` instance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The parameter grid, `param_grid`, which we defined previously
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The scoring on which to optimize – that is, `accuracy`
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of cross-validation folds, which has been set to `5` here
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We must also set `return_train_score` to `True` to get some useful information
    we can use later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, all we have to do is train this object on the train set. This will
    automatically make all the computations and store the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the input dataset and the number of tested hyperparameters, the
    fit may take some time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the fit has been completed, you can get a lot of useful information, such
    as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The hyperparameter set via the `.``best_params` attribute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best accuracy score via the `.``best_score` attribute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cross-validation results via the `.``cv_results` attribute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, you can infer the model that was trained with optimized hyperparameters
    using the `.``predict()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Optionally, you can evaluate the chosen model with the accuracy score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This provides the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to the tools provided by scikit-learn, it is fairly easy to have a well-optimized
    model and evaluate it against several metrics. In the next recipe, we’ll learn
    how to diagnose bias and variance based on such an evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs: []
  type: TYPE_NORMAL
- en: The documentation for `GridSearchCV` can be found at [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.xhtml).
  prefs: []
  type: TYPE_NORMAL
