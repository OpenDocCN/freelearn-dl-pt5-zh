<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer013">
<h1 class="chapter-number" id="_idParaDest-16" lang="en-GB"><a id="_idTextAnchor015"/>1</h1>
<h1 id="_idParaDest-17" lang="en-GB"><a id="_idTextAnchor016"/>Introducing 3D Data Processing</h1>
<p lang="en-GB">In this chapter, we are going to discuss some basic concepts that are very fundamental to 3D deep learning and that will be used frequently in later chapters. We will begin by learning about the most frequently used 3D data formats, as well as the many ways that we are going to manipulate them and convert them to different formats. We will start by setting up our development environment and installing all the necessary software packages, including Anaconda, Python, PyTorch, and PyTorch3D. We will then talk about the most frequently used ways to represent 3D data – for example, point clouds, meshes, and voxels. We will then move on to the 3D data file formats, such as PLY and OBJ files. We will then discuss 3D coordination systems. Finally, we will discuss camera models, which are mostly related to how 3D data is mapped to <span class="No-Break" lang="">2D images.</span></p>
<p lang="en-GB">After reading this chapter, you will be able to debug 3D deep learning algorithms easily by inspecting output data files. With a solid understanding of coordination systems and camera models, you will be ready to build on that knowledge and learn about more advanced 3D deep <span class="No-Break" lang="">learning topics.</span></p>
<p lang="en-GB">In this chapter, we’re going to cover the following <span class="No-Break" lang="">main topics:</span></p>
<ul>
<li lang="en-GB">Setting up a development environment and installing Anaconda, PyTorch, <span class="No-Break" lang="">and PyTorch3D</span></li>
<li lang="en-GB">3D <span class="No-Break" lang="">data representation</span></li>
<li lang="en-GB">3D data formats – PLY and <span class="No-Break" lang="">OBJ files</span></li>
<li lang="en-GB">3D coordination systems and conversion <span class="No-Break" lang="">between them</span></li>
<li lang="en-GB">Camera models – perspective and <span class="No-Break" lang="">orthographic cameras</span></li>
</ul>
<h1 id="_idParaDest-18" lang="en-GB"><a id="_idTextAnchor017"/>Technical requirements</h1>
<p lang="en-GB">In order to run the example code snippets in this book, you will need to have a computer ideally with a GPU. However, running the code snippets with only CPUs <span class="No-Break" lang="">is possible.</span></p>
<p lang="en-GB">The recommended computer configuration includes <span class="No-Break" lang="">the following:</span></p>
<ul>
<li lang="en-GB">A GPU such as the GTX series or RTX series with at least 8 GB <span class="No-Break" lang="">of memory</span></li>
<li lang="en-GB"><span class="No-Break" lang="">Python 3</span></li>
<li lang="en-GB">The PyTorch library and <span class="No-Break" lang="">PyTorch3D libraries</span></li>
</ul>
<p lang="en-GB">The code snippets for this chapter can be found <span class="No-Break" lang="">at </span><a href="https://github.com/PacktPublishing/3D-Deep-Learning-with-Python"><span class="No-Break" lang="">https://github.com/PacktPublishing/3D-Deep-Learning-with-Python</span></a><span class="No-Break" lang="">.</span></p>
<h1 id="_idParaDest-19" lang="en-GB"><a id="_idTextAnchor018"/>Setting up a development environment</h1>
<p lang="en-GB">Let us first <a id="_idIndexMarker000"/>set up a development environment for all the coding exercises in this book. We recommend using a Linux machine for all the Python code examples in <span class="No-Break" lang="">this book:</span></p>
<ol>
<li lang="en-GB">We will first set up Anaconda. Anaconda is a widely used Python distribution that bundles with the powerful CPython implementation. One advantage of using Anaconda is its package management system, enabling users to create virtual environments easily. The individual edition of Anaconda is free for solo practitioners, students, and researchers. To install Anaconda, we recommend visiting the <a id="_idIndexMarker001"/>website, <a href="http://anaconda.com">anaconda.com</a>, for detailed instructions. The easiest way to install Anaconda is usually by running a script downloaded from their website. After setting up Anaconda, run the following command to create a virtual environment of <span class="No-Break" lang="">Python 3.7:</span><p class="source-code" lang="en-GB"><strong class="bold" lang="">$ conda create -n python3d python=3.7</strong></p></li>
</ol>
<p lang="en-GB">This command will create a virtual environment with Python version 3.7. In order to use this virtual environment, we need to activate it first by running <span class="No-Break" lang="">the command:</span></p>
<ol>
<li lang="en-GB" value="2">Activate the newly created virtual environments with the <span class="No-Break" lang="">following command:</span><p class="source-code" lang="en-GB"><strong class="bold" lang="">$ source activate python3d</strong></p></li>
<li lang="en-GB">Install PyTorch. Detailed instructions on installing PyTorch can be found on its web page at <a href="http://www.pytorch.org/get-started/locally/">www.pytorch.org/get-started/locally/</a>. For example, I will install PyTorch 1.9.1 on my Ubuntu desktop with CUDA 11.1, <span class="No-Break" lang="">as follows:</span><p class="source-code" lang="en-GB"><strong class="bold" lang="">$ conda install pytorch torchvision torchaudio cudatoolkit-11.1 -c pytorch -c nvidia</strong></p></li>
<li lang="en-GB">Install PyTorch3D. PyTorch3D is an open source Python library for 3D computer vision recently released by Facebook AI Research. PyTorch3D provides many utility functions to easily manipulate 3D data. Designed with deep learning in mind, almost all 3D data can be handled by mini-batches, such as cameras, point clouds, and meshes. Another key feature of PyTorch3D is the implementation of a very important 3D deep learning technique, called <em class="italic" lang="">differentiable rendering</em>. However, the biggest advantage of PyTorch3D as a 3D deep learning library is its close ties <span class="No-Break" lang="">to PyTorch.</span></li>
</ol>
<p lang="en-GB">PyTorch3D may need some dependencies, and detailed instructions on how to install these<a id="_idIndexMarker002"/> dependencies can be found on the PyTorch3D GitHub home page at <a href="http://github.com/facebookresearch/pytorch3d">github.com/facebookresearch/pytorch3d</a>. After all the dependencies have been installed by following the instructions from the website, installing PyTorch3D can be easily done by running the <span class="No-Break" lang="">following command:</span></p>
<p class="source-code" lang="en-GB"><strong class="bold" lang="">$ conda install pytorch3d -c pytorch3d</strong></p>
<p lang="en-GB">Now that we have set up the development environment, let’s go ahead and start learning <span class="No-Break" lang="">data representation.</span></p>
<h1 id="_idParaDest-20" lang="en-GB"><a id="_idTextAnchor019"/>3D data representation</h1>
<p lang="en-GB">In this section, we <a id="_idIndexMarker003"/>will learn the most frequently used data representation of 3D data. Choosing data representation is a particularly important design decision for many 3D deep learning systems. For example, point clouds do not have grid-like structures, thus convolutions cannot be usually used directly for them. Voxel representations have grid-like structures; however, they tend to consume a high amount of computer memory. We will discuss the pros and cons of these 3D representations in more detail in this section. Widely used 3D data representations usually include <a id="_idIndexMarker004"/>point clouds, meshes, <span class="No-Break" lang="">and voxels.</span></p>
<h2 id="_idParaDest-21" lang="en-GB"><a id="_idTextAnchor020"/>Understanding point cloud representation</h2>
<p lang="en-GB">A 3D point <a id="_idIndexMarker005"/>cloud is a very straightforward<a id="_idIndexMarker006"/> representation of 3D objects, where each point cloud is just a collection of 3D points, and each 3D point is represented by one three-dimensional tuple (<em class="italic" lang="">x</em>, <em class="italic" lang="">y</em>, or <em class="italic" lang="">z</em>). The raw measurements of many depth cameras are usually 3D <span class="No-Break" lang="">point clouds.</span></p>
<p lang="en-GB">From a deep learning point of view, 3D point clouds are one of the unordered and irregular data types. Unlike regular images, where we can define neighboring pixels for each individual pixel, there are no clear and regular definitions for neighboring points for each point in a point cloud – that is, convolutions usually cannot be applied to point clouds. Thus, special types of deep learning models need to be used for processing point clouds, such as <a id="_idIndexMarker007"/><span class="No-Break" lang="">PointNet: </span><a href="https://arxiv.org/abs/1612.00593"><span class="No-Break" lang="">https://arxiv.org/abs/1612.00593</span></a><span class="No-Break" lang="">.</span></p>
<p lang="en-GB">Another issue for point clouds as training data for 3D deep learning is the heterogeneous data issue – that is, for one training dataset, different point clouds may contain different numbers of 3D points. One approach for avoiding such a heterogeneous data issue is forcing all the point clouds to have the same number of points. However, this may not be always possible – for example, the number of points returned by depth cameras may be different from frame <span class="No-Break" lang="">to frame.</span></p>
<p lang="en-GB">The heterogeneous data may create some difficulties for mini-batch gradient descent in training deep learning models. Most deep learning frameworks assume that each mini-batch contains training examples of the same size and dimensions. Such homogeneous data is preferred because it can be most efficiently processed by modern parallel processing hardware, such as GPUs. Handling heterogeneous mini-batches in an efficient way needs some additional work. Luckily, PyTorch3D provides many ways of handling heterogeneous mini-batches efficiently, which are important for 3D <span class="No-Break" lang="">deep learning.</span></p>
<h2 id="_idParaDest-22" lang="en-GB"><a id="_idTextAnchor021"/>Understanding mesh representation</h2>
<p lang="en-GB">Meshes <a id="_idIndexMarker008"/>are another widely used 3D data <a id="_idIndexMarker009"/>representation. Like points in point clouds, each mesh contains a set of 3D points called vertices. In addition, each mesh also contains a set of polygons called faces, which are defined <span class="No-Break" lang="">on vertices.</span></p>
<p lang="en-GB">In most data-driven applications, meshes are a result of post-processing from raw measurements of depth cameras. Often, they are manually created during the process of 3D asset design. Compared to point clouds, meshes contain additional geometric information, encode topology, and have surface-normal information. This additional information becomes especially useful in training learning models. For example, graph convolutional neural networks usually treat meshes as graphs and define convolutional operations using the vertex <span class="No-Break" lang="">neighboring information.</span></p>
<p lang="en-GB">Just like point clouds, meshes also have similar heterogeneous data issues. Again, PyTorch3D provides efficient ways for handling heterogeneous mini-batches for mesh data, which makes 3D deep <span class="No-Break" lang="">learning efficient.</span></p>
<h2 id="_idParaDest-23" lang="en-GB"><a id="_idTextAnchor022"/>Understanding voxel representation</h2>
<p lang="en-GB">Another <a id="_idIndexMarker010"/>important 3D data representation<a id="_idIndexMarker011"/> is voxel representation. A voxel is the counterpart of a pixel in 3D computer vision. A pixel is defined by dividing a rectangle in 2D into smaller rectangles and each small rectangle is one pixel. Similarly, a voxel is defined by dividing a 3D cube into smaller-sized cubes and each cube is called one voxel. The processes are shown in the <span class="No-Break" lang="">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer008">
<img alt="Figure 1.1 – Voxel representation is the 3D counterpart of 2D pixel representation, where a cubic space is divided into small volume elements " height="509" src="image/B18217_01_001Redraw.jpg" width="1530"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Voxel representation is the 3D counterpart of 2D pixel representation, where a cubic space is divided into small volume elements</p>
<p lang="en-GB">Voxel representations<a id="_idIndexMarker012"/> usually use <strong class="bold" lang="">Truncated Signed Distance Functions</strong> (<strong class="bold" lang="">TSDFs</strong>) to represent 3D surfaces. A <strong class="bold" lang="">Signed Distance Function</strong> (<strong class="bold" lang="">SDF</strong>) can <a id="_idIndexMarker013"/>be defined at each voxel as<a id="_idIndexMarker014"/> the (signed) distance between the<a id="_idIndexMarker015"/> center of the voxel to the closest point on the surface. A positive sign in an SDF indicates that the voxel center is outside an object. The only difference between a TSDF and an SDF is that the values of a TSDF are truncated, such that the values of a TSDF always range from -1 <span class="No-Break" lang="">to +1.</span></p>
<p lang="en-GB">Unlike point clouds and meshes, voxel representation is ordered and regular. This property is like pixels in images and enables the use of convolutional filters in deep learning models. One potential disadvantage of voxel representation is that it usually requires more computer memory, but this can be reduced by using techniques such as hashing. Nevertheless, voxel representation is an important 3D <span class="No-Break" lang="">data representation.</span></p>
<p lang="en-GB">There are 3D data representations other than the ones mentioned here. For example, multi-view representations use multiple images taken from different viewpoints to represent a 3D scene. RGB-D representations use an additional depth channel to represent a 3D scene. However, in this book, we will not be diving too deep into these 3D representations. Now that we have learned the basics of 3D data representations, we will dive into <a id="_idIndexMarker016"/>a few commonly used file <a id="_idIndexMarker017"/>formats for point clouds <span class="No-Break" lang="">and meshes.</span></p>
<h1 id="_idParaDest-24" lang="en-GB"><a id="_idTextAnchor023"/>3D data file format – Ply files</h1>
<p lang="en-GB">The PLY file <a id="_idIndexMarker018"/>format was developed in the mid-1990s by a<a id="_idIndexMarker019"/> group of researchers from Stanford University. It has since evolved into one of the most widely used 3D data file formats. The file format has both an ASCII version and a binary version. The binary version is preferred in cases where file sizes and processing efficiencies are needed. The ASCII version makes it quite easy to debug. Here, we will discuss the basic format of PLY files and how to use both Open3D and PyTorch3D to load and visualize 3D data from <span class="No-Break" lang="">PLY files.</span></p>
<p lang="en-GB">In this section, we are going to discuss the two most frequently used data file formats to represent point clouds and meshes, the PLY file format and the OBJ file format. We are going to discuss the formats and how to load and save these file formats using PyTorch3D. PyTorch3D provides excellent utility functions, so loading from and saving to these file formats is efficient and easy using these <span class="No-Break" lang="">utility functions.</span></p>
<p lang="en-GB">An example, a <strong class="source-inline" lang="">cube.ply</strong> file, is shown in the following <span class="No-Break" lang="">code snippet:</span></p>
<pre class="source-code" lang="en-GB">ply</pre>
<pre class="source-code" lang="en-GB">format ascii 1.0</pre>
<pre class="source-code" lang="en-GB">comment created for the book 3D Deep Learning with Python</pre>
<pre class="source-code" lang="en-GB">element vertex 8</pre>
<pre class="source-code" lang="en-GB">property float32 x</pre>
<pre class="source-code" lang="en-GB">property float32 y</pre>
<pre class="source-code" lang="en-GB">property float32 z</pre>
<pre class="source-code" lang="en-GB">element face 12</pre>
<pre class="source-code" lang="en-GB">property list uint8 int32 vertex_indices</pre>
<pre class="source-code" lang="en-GB">end_header</pre>
<pre class="source-code" lang="en-GB">-1 -1 -1</pre>
<pre class="source-code" lang="en-GB">1 -1 -1</pre>
<pre class="source-code" lang="en-GB">1 1 -1</pre>
<pre class="source-code" lang="en-GB">-1 1 -1</pre>
<pre class="source-code" lang="en-GB">-1 -1 1</pre>
<pre class="source-code" lang="en-GB">1 -1 1</pre>
<pre class="source-code" lang="en-GB">1 1 1</pre>
<pre class="source-code" lang="en-GB">-1 1 1</pre>
<pre class="source-code" lang="en-GB">3 0 1 2</pre>
<pre class="source-code" lang="en-GB">3 5 4 7</pre>
<pre class="source-code" lang="en-GB">3 6 2 1</pre>
<pre class="source-code" lang="en-GB">3 3 7 4</pre>
<pre class="source-code" lang="en-GB">3 7 3 2</pre>
<pre class="source-code" lang="en-GB">3 5 1 0</pre>
<pre class="source-code" lang="en-GB">3 0 2 3</pre>
<pre class="source-code" lang="en-GB">3 5 7 6</pre>
<pre class="source-code" lang="en-GB">3 6 1 5</pre>
<pre class="source-code" lang="en-GB">3 3 4 0</pre>
<pre class="source-code" lang="en-GB">3 7 2 6</pre>
<pre class="source-code" lang="en-GB">3 5 0 4</pre>
<p lang="en-GB">As seen here, each<a id="_idIndexMarker020"/> PLY<a id="_idIndexMarker021"/> file contains a header part and a data part. The first line of every ASCII PLY file is always <strong class="source-inline" lang="">ply</strong>, which indicates that this is a PLY file. The second line, <strong class="source-inline" lang="">format ascii 1.0</strong>, shows that the file is of the Ascii type with a version number. Any lines starting with <strong class="source-inline" lang="">comment</strong> will be considered as a comment line, and thus anything following <strong class="source-inline" lang="">comment</strong> will be ignored when the PLY file is loaded by a computer. The <strong class="source-inline" lang="">element vertex 8</strong> line means that the first type of data in the PLY file is vertex and we have eight vertices. <strong class="source-inline" lang="">property float32 x</strong> means that each vertex has a property named <strong class="source-inline" lang="">x</strong> of the <strong class="source-inline" lang="">float32 type</strong>. Similarly, each vertex also has <strong class="source-inline" lang="">y</strong> and <strong class="source-inline" lang="">z</strong> properties. Here, each vertex is one 3D point. The <strong class="source-inline" lang="">element face 12 line</strong> means that the second type of data in this PLY file is of the <strong class="source-inline" lang="">face</strong>  type and we have 12 faces. <strong class="source-inline" lang="">property list unit8 int32 vertex_indices</strong> shows that each face will be a list of vertex indices. The header part of the <strong class="source-inline" lang="">ply</strong> file always ends with an <span class="No-Break" lang=""><strong class="source-inline" lang="">end_header</strong></span><span class="No-Break" lang=""> line.</span></p>
<p lang="en-GB">The first part of the data part of the PLY file consists of eight lines, where each line is the record for one vertex. The three numbers in each line represent the three <strong class="source-inline" lang="">x</strong>, <strong class="source-inline" lang="">y</strong>, and <strong class="source-inline" lang="">z</strong> properties of the vertex. For example, the three numbers -1, -1, -1 specify that the vertex has an <strong class="source-inline" lang="">x</strong> coordinate of <strong class="source-inline" lang="">-1</strong>, <strong class="source-inline" lang="">y</strong> coordinate of <strong class="source-inline" lang="">-1</strong>, and <strong class="source-inline" lang="">z</strong> coordinate <span class="No-Break" lang="">of </span><span class="No-Break" lang=""><strong class="source-inline" lang="">-1</strong></span><span class="No-Break" lang="">.</span></p>
<p lang="en-GB">The second part of the data part of the ply file consists of 12 lines, where each line is the record for one face. The first number in the sequence of numbers indicates the number of vertices that the face has, and the following numbers are the vertex indices. The vertex indices are determined by the order that the vertices are declared in the <span class="No-Break" lang="">PLY file.</span></p>
<p lang="en-GB">We can use both Open3D and PyTorch3D to open the preceding file. Open3D is a Python package that is very handy for visualizing 3D data, and PyTorch3D is handy for using this data for deep learning models. The following is a code snippet, <strong class="source-inline" lang="">ply_example1.py</strong>, for visualizing the<a id="_idIndexMarker022"/> mesh in the <strong class="source-inline" lang="">cube.ply</strong> file and loading the<a id="_idIndexMarker023"/> vertices and meshes as <span class="No-Break" lang="">PyTorch tensors:</span></p>
<pre class="source-code" lang="en-GB">import open3d</pre>
<pre class="source-code" lang="en-GB">from pytorch3d.io import load_ply</pre>
<pre class="source-code" lang="en-GB">mesh_file = "cube.ply"</pre>
<pre class="source-code" lang="en-GB">print('visualizing the mesh using open3D')</pre>
<pre class="source-code" lang="en-GB">mesh = open3d.io.read_triangle_mesh(mesh_file)</pre>
<pre class="source-code" lang="en-GB">open3d.visualization.draw_geometries([mesh],</pre>
<pre class="source-code" lang="en-GB">       mesh_show_wireframe = True,</pre>
<pre class="source-code" lang="en-GB">       mesh_show_back_face = True)</pre>
<pre class="source-code" lang="en-GB">print("Loading the same file with PyTorch3D")</pre>
<pre class="source-code" lang="en-GB">vertices, faces = load_ply(mesh_file)</pre>
<pre class="source-code" lang="en-GB">print('Type of vertices = ', type(vertices))</pre>
<pre class="source-code" lang="en-GB">print("type of faces = ", type(faces))</pre>
<pre class="source-code" lang="en-GB">print('vertices = ', vertices)</pre>
<pre class="source-code" lang="en-GB">print('faces = ', faces)</pre>
<p lang="en-GB">In the preceding Python code snippet, a <strong class="source-inline" lang="">cube.ply</strong> mesh file is first opened by the <strong class="source-inline" lang="">open3d</strong> package by using the <strong class="source-inline" lang="">read_triangle_mesh</strong> function and all the 3D data is read into the mesh variable. The mesh can then be visualized using the Open3D library <strong class="source-inline" lang="">draw_geometries</strong> function. When you run this function, the Open3D library will pop up a window for interactively visualizing the mesh – that is, you can rotate, zoom into, and zoom out of the mesh using your mouse interactively. The <strong class="source-inline" lang="">cube.ply</strong> file, as you can guess, defines a mesh of a cube with eight vertices and six sides, where each side is covered by <span class="No-Break" lang="">two faces.</span></p>
<p lang="en-GB">We can also use the <strong class="source-inline" lang="">PyTorch3D</strong> library to load the same mesh. However, this time, we are going to obtain several PyTorch tensors – for example, one tensor for vertices and one tensor for faces. These tensors can be input into any PyTorch deep learning model directly. In this example, the <strong class="source-inline" lang="">load_ply</strong> function returns a tuple of vertices and faces, both of which are conventionally in the format of PyTorch tensors. When you run this <strong class="source-inline" lang="">ply_example1.py</strong> code snippet, the returned vertices should be a PyTorch tensor with a shape of <strong class="source-inline" lang="">[8, 3]</strong> – that is, there <a id="_idIndexMarker024"/>are eight vertices, and each vertex <a id="_idIndexMarker025"/>has three coordinates. Similarly, the returned faces should be a PyTorch tensor with a shape of [12, 3], that is, there are 12 faces, and each face has 3 <span class="No-Break" lang="">vertex indices.</span></p>
<p lang="en-GB">In the following code snippet, we show another example of the <strong class="source-inline" lang="">parallel_plane_mono.ply</strong> file, which can also be downloaded from our GitHub repository. The only difference between the mesh in this example and the mesh in the <strong class="source-inline" lang="">cube is.ply</strong> file is the number of faces. Instead of the six sides of a cube, here we have only four faces, which form two <span class="No-Break" lang="">parallel planes:</span></p>
<pre class="source-code" lang="en-GB">ply</pre>
<pre class="source-code" lang="en-GB">format ascii 1.0</pre>
<pre class="source-code" lang="en-GB">comment created for the book 3D Deep Learning with Python</pre>
<pre class="source-code" lang="en-GB">element vertex 8</pre>
<pre class="source-code" lang="en-GB">property float32 x</pre>
<pre class="source-code" lang="en-GB">property float32 y</pre>
<pre class="source-code" lang="en-GB">property float32 z</pre>
<pre class="source-code" lang="en-GB">element face 4</pre>
<pre class="source-code" lang="en-GB">property list uint8 int32 vertex_indices</pre>
<pre class="source-code" lang="en-GB">end_header</pre>
<pre class="source-code" lang="en-GB">-1 -1 -1</pre>
<pre class="source-code" lang="en-GB">1 -1 -1</pre>
<pre class="source-code" lang="en-GB">1 1 -1</pre>
<pre class="source-code" lang="en-GB">-1 1 -1</pre>
<pre class="source-code" lang="en-GB">-1 -1 1</pre>
<pre class="source-code" lang="en-GB">1 -1 1</pre>
<pre class="source-code" lang="en-GB">1 1 1</pre>
<pre class="source-code" lang="en-GB">-1 1 1</pre>
<pre class="source-code" lang="en-GB">3 0 1 2</pre>
<pre class="source-code" lang="en-GB">3 0 2 3</pre>
<pre class="source-code" lang="en-GB">3 5 4 7</pre>
<pre class="source-code" lang="en-GB">3 5 7 6</pre>
<p lang="en-GB">The mesh can <a id="_idIndexMarker026"/>be interactively visualized by the <a id="_idIndexMarker027"/><span class="No-Break" lang="">following </span><span class="No-Break" lang=""><strong class="source-inline" lang="">ply_example2.py</strong></span><span class="No-Break" lang="">:</span></p>
<ol>
<li lang="en-GB" value="1">First, we import all the needed <span class="No-Break" lang="">Python libraries:</span><p class="source-code" lang="en-GB">import open3d</p><p class="source-code" lang="en-GB">from pytorch3d.io import load_ply</p></li>
<li lang="en-GB">We load the mesh <span class="No-Break" lang="">using </span><span class="No-Break" lang=""><strong class="source-inline" lang="">open3d</strong></span><span class="No-Break" lang="">:</span><p class="source-code" lang="en-GB">mesh_file = "parallel_plane_mono.ply"</p><p class="source-code" lang="en-GB">print('visualizing the mesh using open3D')</p><p class="source-code" lang="en-GB">mesh = open3d.io.read_triangle_mesh(mesh_file)</p></li>
<li lang="en-GB">We use <strong class="source-inline" lang="">draw_geometries</strong> to open a window for visualizing interactively with <span class="No-Break" lang="">the mesh:</span><p class="source-code" lang="en-GB">open3d.visualization.draw_geometries([mesh],</p><p class="source-code" lang="en-GB">                  mesh_show_wireframe = True,</p><p class="source-code" lang="en-GB">                  mesh_show_back_face = True)</p></li>
<li lang="en-GB">We use <strong class="source-inline" lang="">pytorch3d</strong> to open the <span class="No-Break" lang="">same mesh:</span><p class="source-code" lang="en-GB">print("Loading the same file with PyTorch3D")</p><p class="source-code" lang="en-GB">vertices, faces = load_ply(mesh_file)</p></li>
<li lang="en-GB">We can<a id="_idIndexMarker028"/> print <a id="_idIndexMarker029"/>out the information about the loaded vertices and faces. In fact, they are just ordinary <span class="No-Break" lang="">PyTorch3D tensors:</span><p class="source-code" lang="en-GB">print('Type of vertices = ', type(vertices), ", type of faces = ", type(faces))</p><p class="source-code" lang="en-GB">print('vertices = ', vertices)</p><p class="source-code" lang="en-GB">print('faces = ', faces)</p></li>
</ol>
<p lang="en-GB">For each vertex, we can also define properties other than the <em class="italic" lang="">x</em>, <em class="italic" lang="">y</em>, and <em class="italic" lang="">z</em> coordinates. For example, we can also define colors for each vertex. An example of <strong class="source-inline" lang="">parallel_plane_color.ply</strong> is <span class="No-Break" lang="">shown here:</span></p>
<pre class="source-code" lang="en-GB">ply</pre>
<pre class="source-code" lang="en-GB">format ascii 1.0</pre>
<pre class="source-code" lang="en-GB">comment created for the book 3D Deep Learning with Python</pre>
<pre class="source-code" lang="en-GB">element vertex 8</pre>
<pre class="source-code" lang="en-GB">property float32 x</pre>
<pre class="source-code" lang="en-GB">property float32 y</pre>
<pre class="source-code" lang="en-GB">property float32 z</pre>
<pre class="source-code" lang="en-GB">property uchar red</pre>
<pre class="source-code" lang="en-GB">property uchar green</pre>
<pre class="source-code" lang="en-GB">property uchar blue</pre>
<pre class="source-code" lang="en-GB">element face 4</pre>
<pre class="source-code" lang="en-GB">property list uint8 int32 vertex_indices</pre>
<pre class="source-code" lang="en-GB">end_header</pre>
<pre class="source-code" lang="en-GB">-1 -1 -1 255 0 0</pre>
<pre class="source-code" lang="en-GB">1 -1 -1 255 0 0</pre>
<pre class="source-code" lang="en-GB">1 1 -1 255 0 0</pre>
<pre class="source-code" lang="en-GB">-1 1 -1 255 0 0</pre>
<pre class="source-code" lang="en-GB">-1 -1 1 0 0 255</pre>
<pre class="source-code" lang="en-GB">1 -1 1 0 0 255</pre>
<pre class="source-code" lang="en-GB">1 1 1 0 0 255</pre>
<pre class="source-code" lang="en-GB">-1 1 1 0 0 255</pre>
<pre class="source-code" lang="en-GB">3 0 1 2</pre>
<pre class="source-code" lang="en-GB">3 0 2 3</pre>
<pre class="source-code" lang="en-GB">3 5 4 7</pre>
<pre class="source-code" lang="en-GB">3 5 7 6</pre>
<p lang="en-GB">Note that in<a id="_idIndexMarker030"/> the<a id="_idIndexMarker031"/> preceding example, along with <em class="italic" lang="">x</em>, <em class="italic" lang="">y</em>, and <em class="italic" lang="">z</em>, we also define some additional properties for each vertex – that is, the red, green, and blue properties, all in the <strong class="source-inline" lang="">uchar</strong> data type. Now, each record for one vertex is one line of six numbers. The first three are <em class="italic" lang="">x</em>, <em class="italic" lang="">y</em>, and <em class="italic" lang="">z</em> coordinates. The following three numbers are the <span class="No-Break" lang="">RGB values.</span></p>
<p lang="en-GB">The mesh can be visualized by usi<a id="_idTextAnchor024"/>ng <strong class="source-inline" lang="">ply_example3.py</strong> <span class="No-Break" lang="">as follows:</span></p>
<pre class="source-code" lang="en-GB">import open3d</pre>
<pre class="source-code" lang="en-GB">from pytorch3d.io import load_ply</pre>
<pre class="source-code" lang="en-GB">mesh_file = "parallel_plane_color.ply"</pre>
<pre class="source-code" lang="en-GB">print('visualizing the mesh using open3D')</pre>
<pre class="source-code" lang="en-GB">mesh = open3d.io.read_triangle_mesh(mesh_file)</pre>
<pre class="source-code" lang="en-GB">open3d.visualization.draw_geometries([mesh],</pre>
<pre class="source-code" lang="en-GB">                     mesh_show_wireframe = True,</pre>
<pre class="source-code" lang="en-GB">                     mesh_show_back_face = True)</pre>
<pre class="source-code" lang="en-GB">print("Loading the same file with PyTorch3D")</pre>
<pre class="source-code" lang="en-GB">vertices, faces = load_ply(mesh_file)</pre>
<pre class="source-code" lang="en-GB">print('Type of vertices = ', type(vertices), ", type of faces = ", type(faces))</pre>
<pre class="source-code" lang="en-GB">print('vertices = ', vertices)</pre>
<pre class="source-code" lang="en-GB">print('faces = ', faces)</pre>
<p lang="en-GB">We also provide <strong class="source-inline" lang="">cow.ply</strong>, which is a real-world example of a 3D mesh. The readers can visualize the mesh <span class="No-Break" lang="">using </span><span class="No-Break" lang=""><strong class="source-inline" lang="">ply_example4.py</strong></span><span class="No-Break" lang="">.</span></p>
<p lang="en-GB">By now, we <a id="_idIndexMarker032"/>have talked about the basic elements of <a id="_idIndexMarker033"/>the PLY file format, such as vertices and faces. Next, we will discuss the OBJ 3D <span class="No-Break" lang="">data format.</span></p>
<h1 id="_idParaDest-25" lang="en-GB"><a id="_idTextAnchor025"/>3D data file format – OBJ files</h1>
<p lang="en-GB">In this <a id="_idIndexMarker034"/>section, we are going to discuss another<a id="_idIndexMarker035"/> widely used 3D data file format, the OBJ file format. The OBJ file format was first developed by Wavefront Technologies Inc. Like the PLY file format, the OBJ format also has both an ASCII version and a binary version. The binary version is proprietary and undocumented. So, we are going to discuss the ASCII version in <span class="No-Break" lang="">this section.</span></p>
<p lang="en-GB">Like the previous section, here we are going to learn the file format by looking at examples. The first example, <strong class="source-inline" lang="">cube.obj</strong>, is shown as follows. As you can guess, the OBJ file defines a mesh of <span class="No-Break" lang="">a cube.</span></p>
<p lang="en-GB">The first line, <strong class="source-inline" lang="">mtlib ./cube.mtl</strong>, declares the companion <strong class="bold" lang="">Material Template Library</strong> (<strong class="bold" lang="">MTL</strong>) file. The <strong class="bold" lang="">MTL</strong> file <a id="_idIndexMarker036"/>describes surface shading properties, which will be explained in the next <span class="No-Break" lang="">code snippet.</span></p>
<p lang="en-GB">For the <strong class="source-inline" lang="">o cube</strong> line, the starting letter, <strong class="source-inline" lang="">o</strong>, indicates that the line defines an object, where the name of the object is <strong class="source-inline" lang="">cube</strong>. Any line starting with <strong class="source-inline" lang="">#</strong> is a comment line – that is, the rest of the line will be ignored by a computer. Each line starts with <strong class="source-inline" lang="">v</strong>, which indicates that each line defines a vertex. For example, <strong class="source-inline" lang="">v -0.5 -0.5 0.5</strong> defines a vertex with an <em class="italic" lang="">x</em> coordinate of 0.5, a <em class="italic" lang="">y</em> coordinate of 0.5, and a <em class="italic" lang="">z</em> coordination of 0.5. For each line starting with <strong class="source-inline" lang="">f</strong>, <strong class="source-inline" lang="">f</strong> indicates that each line contains a definition for one face. For example, the <strong class="source-inline" lang="">f 1 2 3</strong> line defines a face, with its three vertices being the vertices with indices 1, 2, <span class="No-Break" lang="">and 3.</span></p>
<p lang="en-GB">The <strong class="source-inline" lang="">usemtl Door</strong> line declares that the surfaces declared after this line should be shaded <a id="_idIndexMarker037"/>using <a id="_idIndexMarker038"/>a material property defined in the MTL file, <span class="No-Break" lang="">named </span><span class="No-Break" lang=""><strong class="source-inline" lang="">Door</strong></span><span class="No-Break" lang="">:</span></p>
<pre class="source-code" lang="en-GB">mtllib ./cube.mtl</pre>
<pre class="source-code" lang="en-GB">o cube</pre>
<pre class="source-code" lang="en-GB"># Vertex list</pre>
<pre class="source-code" lang="en-GB">v -0.5 -0.5 0.5</pre>
<pre class="source-code" lang="en-GB">v -0.5 -0.5 -0.5</pre>
<pre class="source-code" lang="en-GB">v -0.5 0.5 -0.5</pre>
<pre class="source-code" lang="en-GB">v -0.5 0.5 0.5</pre>
<pre class="source-code" lang="en-GB">v 0.5 -0.5 0.5</pre>
<pre class="source-code" lang="en-GB">v 0.5 -0.5 -0.5</pre>
<pre class="source-code" lang="en-GB">v 0.5 0.5 -0.5</pre>
<pre class="source-code" lang="en-GB">v 0.5 0.5 0.5</pre>
<pre class="source-code" lang="en-GB"># Point/Line/Face list</pre>
<pre class="source-code" lang="en-GB">usemtl Door</pre>
<pre class="source-code" lang="en-GB">f 1 2 3</pre>
<pre class="source-code" lang="en-GB">f 6 5 8</pre>
<pre class="source-code" lang="en-GB">f 7 3 2</pre>
<pre class="source-code" lang="en-GB">f 4 8 5</pre>
<pre class="source-code" lang="en-GB">f 8 4 3</pre>
<pre class="source-code" lang="en-GB">f 6 2 1</pre>
<pre class="source-code" lang="en-GB">f 1 3 4</pre>
<pre class="source-code" lang="en-GB">f 6 8 7</pre>
<pre class="source-code" lang="en-GB">f 7 2 6</pre>
<pre class="source-code" lang="en-GB">f 4 5 1</pre>
<pre class="source-code" lang="en-GB">f 8 3 7</pre>
<pre class="source-code" lang="en-GB">f 6 1 5</pre>
<p lang="en-GB">The <strong class="source-inline" lang="">cube.mtl</strong> companion <a id="_idIndexMarker039"/>MTL file is shown as<a id="_idIndexMarker040"/> follows. The file defines a material property <span class="No-Break" lang="">called </span><span class="No-Break" lang=""><strong class="source-inline" lang="">Door</strong></span><span class="No-Break" lang="">:</span></p>
<pre class="source-code" lang="en-GB">newmtl Door</pre>
<pre class="source-code" lang="en-GB">Ka  0.8 0.6 0.4</pre>
<pre class="source-code" lang="en-GB">Kd  0.8 0.6 0.4</pre>
<pre class="source-code" lang="en-GB">Ks  0.9 0.9 0.9</pre>
<pre class="source-code" lang="en-GB">d  1.0</pre>
<pre class="source-code" lang="en-GB">Ns  0.0</pre>
<pre class="source-code" lang="en-GB">illum 2</pre>
<p lang="en-GB">We will not discuss these material properties in detail except for <strong class="source-inline" lang="">map_Kd</strong>. If you are curious, you can refer to a standard computer graphics textbook such as <em class="italic" lang="">Computer Graphics: Principles and Practice</em>. We will list some rough descriptions of these properties as follows, just for the sake <span class="No-Break" lang="">of completeness:</span></p>
<ul>
<li lang="en-GB"><strong class="source-inline" lang="">Ka</strong>: Specifies an <span class="No-Break" lang="">ambient color</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">Kd</strong>: Specifies a <span class="No-Break" lang="">diffuse color</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">Ks</strong>: Specifies a <span class="No-Break" lang="">specular color</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">Ns</strong>: Defines the focus of <span class="No-Break" lang="">specular highlights</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">Ni</strong>: Defines the optical density (a.k.a index <span class="No-Break" lang="">of refraction)</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">d</strong>: Specifies a factor <span class="No-Break" lang="">for dissolve</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">illum</strong>: Specifies an <span class="No-Break" lang="">illumination model</span></li>
<li lang="en-GB"><strong class="source-inline" lang="">map_Kd</strong>: Specifies a color texture file to be applied to the diffuse reflectivity of <span class="No-Break" lang="">the material</span></li>
</ul>
<p lang="en-GB">The <strong class="source-inline" lang="">cube.obj</strong> file can be<a id="_idIndexMarker041"/> opened by both Open3D and <a id="_idIndexMarker042"/>PyTorch3D. The following code snippet, <strong class="source-inline" lang="">obj_example1.py</strong>, can be downloaded from our <span class="No-Break" lang="">GitHub repository:</span></p>
<pre class="source-code" lang="en-GB">import open3d</pre>
<pre class="source-code" lang="en-GB">from pytorch3d.io import load_obj</pre>
<pre class="source-code" lang="en-GB">mesh_file = "cube.obj"</pre>
<pre class="source-code" lang="en-GB">print('visualizing the mesh using open3D')</pre>
<pre class="source-code" lang="en-GB">mesh = open3d.io.read_triangle_mesh(mesh_file)</pre>
<pre class="source-code" lang="en-GB">open3d.visualization.draw_geometries([mesh],</pre>
<pre class="source-code" lang="en-GB">                 mesh_show_wireframe = True,</pre>
<pre class="source-code" lang="en-GB">                 mesh_show_back_face = True)</pre>
<pre class="source-code" lang="en-GB">print("Loading the same file with PyTorch3D")</pre>
<pre class="source-code" lang="en-GB">vertices, faces, aux = load_obj(mesh_file)</pre>
<pre class="source-code" lang="en-GB">print('Type of vertices = ', type(vertices))</pre>
<pre class="source-code" lang="en-GB">print("Type of faces = ", type(faces))</pre>
<pre class="source-code" lang="en-GB">print("Type of aux = ", type(aux))</pre>
<pre class="source-code" lang="en-GB">print('vertices = ', vertices)</pre>
<pre class="source-code" lang="en-GB">print('faces = ', faces)</pre>
<pre class="source-code" lang="en-GB">print('aux = ', aux)</pre>
<p lang="en-GB">In the preceding code snippet, the defined mesh of a cube can be interactively visualized by using the Open3D <strong class="source-inline" lang="">draw_geometries</strong> function. The mesh will be shown in a window, and you can rotate, zoom into, and zoom out of the mesh using your mouse. The mesh can also be loaded using the PyTorch3D <strong class="source-inline" lang="">load_obj</strong> function. The <strong class="source-inline" lang="">load_obj</strong> function will return the <strong class="source-inline" lang="">vertices</strong>, <strong class="source-inline" lang="">faces</strong>, and <strong class="source-inline" lang="">aux</strong> variables, either in the format of a PyTorch tensor or tuples of <span class="No-Break" lang="">PyTorch tensors.</span></p>
<p lang="en-GB">An <a id="_idIndexMarker043"/>example<a id="_idIndexMarker044"/> output of the <strong class="source-inline" lang="">obj_example1.py</strong> code snippet is shown <span class="No-Break" lang="">as follows:</span></p>
<pre class="source-code" lang="en-GB">visualizing the mesh using open3D</pre>
<pre class="source-code" lang="en-GB">Loading the same file with PyTorch3D</pre>
<pre class="source-code" lang="en-GB">Type of vertices =  &lt;class 'torch.Tensor'&gt;</pre>
<pre class="source-code" lang="en-GB">Type of faces =  &lt;class 'pytorch3d.io.obj_io.Faces'&gt;</pre>
<pre class="source-code" lang="en-GB">Type of aux =  &lt;class 'pytorch3d.io.obj_io.Properties'&gt;</pre>
<pre class="source-code" lang="en-GB">vertices =  tensor([[-0.5000, -0.5000,  0.5000],</pre>
<pre class="source-code" lang="en-GB">        [-0.5000, -0.5000, -0.5000],</pre>
<pre class="source-code" lang="en-GB">        [-0.5000,  0.5000, -0.5000],</pre>
<pre class="source-code" lang="en-GB">        [-0.5000,  0.5000,  0.5000],</pre>
<pre class="source-code" lang="en-GB">        [ 0.5000, -0.5000,  0.5000],</pre>
<pre class="source-code" lang="en-GB">        [ 0.5000, -0.5000, -0.5000],</pre>
<pre class="source-code" lang="en-GB">        [ 0.5000,  0.5000, -0.5000],</pre>
<pre class="source-code" lang="en-GB">        [ 0.5000,  0.5000,  0.5000]])</pre>
<pre class="source-code" lang="en-GB">faces =  Faces(verts_idx=tensor([[0, 1, 2],</pre>
<pre class="source-code" lang="en-GB">        [5, 4, 7],</pre>
<pre class="source-code" lang="en-GB">        [6, 2, 1],</pre>
<pre class="source-code" lang="en-GB">        ...</pre>
<pre class="source-code" lang="en-GB">        [3, 4, 0],</pre>
<pre class="source-code" lang="en-GB">        [7, 2, 6],</pre>
<pre class="source-code" lang="en-GB">        [5, 0, 4]]), normals_idx=tensor([[-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        ...</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1]]), textures_idx=tensor([[-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        ...</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1],</pre>
<pre class="source-code" lang="en-GB">        [-1, -1, -1]]), materials_idx=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))</pre>
<pre class="source-code" lang="en-GB">aux =  Properties(normals=None, verts_uvs=None, material_colors={'Door': {'ambient_color': tensor([0.8000, 0.6000, 0.4000]), 'diffuse_color': tensor([0.8000, 0.6000, 0.4000]), 'specular_color': tensor([0.9000, 0.9000, 0.9000]), 'shininess': tensor([0.])}}, texture_images={}, texture_atlas=None)</pre>
<p lang="en-GB">From the<a id="_idIndexMarker045"/> code<a id="_idIndexMarker046"/> snippet output here, we know that the returned vertices variable is a PyTorch tensor with a shape of 8 x 3, where each row is a vertex with the <em class="italic" lang="">x</em>, <em class="italic" lang="">y</em>, and <em class="italic" lang="">z</em> coordinates. The returned variable, <strong class="source-inline" lang="">faces</strong>, is a named tuple of three PyTorch tensors, <strong class="source-inline" lang="">verts_idx</strong>, <strong class="source-inline" lang="">normals_idx</strong>, and <strong class="source-inline" lang="">textures_idx</strong>. In the preceding example, all the <strong class="source-inline" lang="">normals_idx</strong> and <strong class="source-inline" lang="">textures_idx</strong> tensors are invalid because <strong class="source-inline" lang="">cube.obj</strong> does not include definitions for normal and textures. We will see in the next example how normals and textures can be defined in the OBJ file format. <strong class="source-inline" lang="">verts_idx</strong> is the vertex indices for each face. Note that the vertex indices are 0-indexed here in PyTorch3D, where the indices start from 0. However, the vertex indices in OBJ files are 1-indexed, where the indices start from 1. PyTorch3D has already made the conversion between the two ways of vertex indexing <span class="No-Break" lang="">for us.</span></p>
<p lang="en-GB">The return variable, <strong class="source-inline" lang="">aux</strong>, contains some extra mesh information. Note that the <strong class="source-inline" lang="">texture_image</strong> field of the <strong class="source-inline" lang="">aux</strong> variable is empty. The texture images are used in MTL files to define colors on vertices and faces. Again, we will show how to use this feature in our <span class="No-Break" lang="">next example.</span></p>
<p lang="en-GB">In the second example, we will use an example <strong class="source-inline" lang="">cube_texture.obj</strong> file to highlight more OBJ file features. The file is shown <span class="No-Break" lang="">as follows.</span></p>
<p lang="en-GB">The <strong class="source-inline" lang="">cube_texture.obj</strong> file is like the <strong class="source-inline" lang="">cube.obj</strong> file, except for the <span class="No-Break" lang="">following differences:</span></p>
<ul>
<li lang="en-GB">There are <a id="_idIndexMarker047"/>some additional lines starting with <strong class="source-inline" lang="">vt</strong>. Each such line declares a texture vertex with <em class="italic" lang="">x</em> and <em class="italic" lang="">y</em> coordinates. Each texture vertex defines a color. The color is the pixel color at a so-called texture image, where the pixel location is the <em class="italic" lang="">x</em> coordinate of the texture vertex x width, and the <em class="italic" lang="">y</em> coordinate of the texture vertex x height. The texture image would be defined in the <span class="No-Break" lang=""><strong class="source-inline" lang="">cube_texture.mtl</strong></span><span class="No-Break" lang=""> companion.</span></li>
<li lang="en-GB">There are additional lines starting with <strong class="source-inline" lang="">vn</strong>. Each such line declares a normal vector – for example, the <strong class="source-inline" lang="">vn 0.000000 -1.000000 0.000000</strong> line declares a normal vector pointing to the negative <span class="No-Break" lang=""><em class="italic" lang="">z</em></span><span class="No-Break" lang=""> axis.</span></li>
<li lang="en-GB">Each face definition line now contains more information about each vertex. For example, the <strong class="source-inline" lang="">f 2/1/1 3/2/1 4/3/1</strong> line contains the definitions for the three vertices. The first triple, <strong class="source-inline" lang="">2/1/1</strong>, defines the first vertex, the second triple, <strong class="source-inline" lang="">3/2/1</strong>, defines the second vertex, and the third triple, <strong class="source-inline" lang="">4/3/1</strong>, defines the third vertex. Each such triplet is the vertex index, texture vertex index, and normal vector index. For example, <strong class="source-inline" lang="">2/1/1</strong> defines a vertex, where the vertex geometric location is defined in the second line starting with <strong class="source-inline" lang="">v</strong>, the color is defined in the first line starting with <strong class="source-inline" lang="">vt</strong>, and the normal vector is defined in the first line starting <span class="No-Break" lang="">with </span><span class="No-Break" lang=""><strong class="source-inline" lang="">vn</strong></span><span class="No-Break" lang="">:</span></li>
</ul>
<pre class="source-code" lang="en-GB">mtllib cube_texture.mtl</pre>
<pre class="source-code" lang="en-GB">v 1.000000 -1.000000 -1.000000</pre>
<pre class="source-code" lang="en-GB">v 1.000000 -1.000000 1.000000</pre>
<pre class="source-code" lang="en-GB">v -1.000000 -1.000000 1.000000</pre>
<pre class="source-code" lang="en-GB">v -1.000000 -1.000000 -1.000000</pre>
<pre class="source-code" lang="en-GB">v 1.000000 1.000000 -0.999999</pre>
<pre class="source-code" lang="en-GB">v 0.999999 1.000000 1.000001</pre>
<pre class="source-code" lang="en-GB">v -1.000000 1.000000 1.000000</pre>
<pre class="source-code" lang="en-GB">v -1.000000 1.000000 -1.000000</pre>
<pre class="source-code" lang="en-GB">vt 1.000000 0.333333</pre>
<pre class="source-code" lang="en-GB">vt 1.000000 0.666667</pre>
<pre class="source-code" lang="en-GB">vt 0.666667 0.666667</pre>
<pre class="source-code" lang="en-GB">vt 0.666667 0.333333</pre>
<pre class="source-code" lang="en-GB">vt 0.666667 0.000000</pre>
<pre class="source-code" lang="en-GB">vt 0.000000 0.333333</pre>
<pre class="source-code" lang="en-GB">vt 0.000000 0.000000</pre>
<pre class="source-code" lang="en-GB">vt 0.333333 0.000000</pre>
<pre class="source-code" lang="en-GB">vt 0.333333 1.000000</pre>
<pre class="source-code" lang="en-GB">vt 0.000000 1.000000</pre>
<pre class="source-code" lang="en-GB">vt 0.000000 0.666667</pre>
<pre class="source-code" lang="en-GB">vt 0.333333 0.333333</pre>
<pre class="source-code" lang="en-GB">vt 0.333333 0.666667</pre>
<pre class="source-code" lang="en-GB">vt 1.000000 0.000000</pre>
<pre class="source-code" lang="en-GB">vn 0.000000 -1.000000 0.000000</pre>
<pre class="source-code" lang="en-GB">vn 0.000000 1.000000 0.000000</pre>
<pre class="source-code" lang="en-GB">vn 1.000000 0.000000 0.000000</pre>
<pre class="source-code" lang="en-GB">vn -0.000000 0.000000 1.000000</pre>
<pre class="source-code" lang="en-GB">vn -1.000000 -0.000000 -0.000000</pre>
<pre class="source-code" lang="en-GB">vn 0.000000 0.000000 -1.000000</pre>
<pre class="source-code" lang="en-GB">g main</pre>
<pre class="source-code" lang="en-GB">usemtl Skin</pre>
<pre class="source-code" lang="en-GB">s 1</pre>
<pre class="source-code" lang="en-GB">f 2/1/1 3/2/1 4/3/1</pre>
<pre class="source-code" lang="en-GB">f 8/1/2 7/4/2 6/5/2</pre>
<pre class="source-code" lang="en-GB">f 5/6/3 6/7/3 2/8/3</pre>
<pre class="source-code" lang="en-GB">f 6/8/4 7/5/4 3/4/4</pre>
<pre class="source-code" lang="en-GB">f 3/9/5 7/10/5 8/11/5</pre>
<pre class="source-code" lang="en-GB">f 1/12/6 4/13/6 8/11/6</pre>
<pre class="source-code" lang="en-GB">f 1/4/1 2/1/1 4/3/1</pre>
<pre class="source-code" lang="en-GB">f 5/14/2 8/1/2 6/5/2</pre>
<pre class="source-code" lang="en-GB">f 1/12/3 5/6/3 2/8/3</pre>
<pre class="source-code" lang="en-GB">f 2/12/4 6/8/4 3/4/4</pre>
<pre class="source-code" lang="en-GB">f 4/13/5 3/9/5 8/11/5</pre>
<pre class="source-code" lang="en-GB">f 5/6/6 1/12/6 8/11/6</pre>
<p lang="en-GB">The <strong class="source-inline" lang="">cube_texture.mtl</strong> companion<a id="_idIndexMarker048"/> is as follows, where the <a id="_idIndexMarker049"/>line starting with <strong class="source-inline" lang="">map_Kd</strong> declares the texture image. Here, <strong class="source-inline" lang="">wal67ar_small.jpg</strong> is a 250 x 250 RGB image file in the same folder as the <span class="No-Break" lang="">MTL file:</span></p>
<pre class="source-code" lang="en-GB">newmtl Skin</pre>
<pre class="source-code" lang="en-GB">Ka 0.200000 0.200000 0.200000</pre>
<pre class="source-code" lang="en-GB">Kd 0.827451 0.792157 0.772549</pre>
<pre class="source-code" lang="en-GB">Ks 0.000000 0.000000 0.000000</pre>
<pre class="source-code" lang="en-GB">Ns 0.000000</pre>
<pre class="source-code" lang="en-GB">map_Kd ./wal67ar_small.jpg</pre>
<p lang="en-GB">Again, we can use Open3D and PyTorch3D to load the mesh in the <strong class="source-inline" lang="">cube_texture.obj</strong> file – for<a id="_idIndexMarker050"/> example, by using the <a id="_idIndexMarker051"/>following <span class="No-Break" lang=""><strong class="source-inline" lang="">obj_example2.py</strong></span><span class="No-Break" lang=""> file:</span></p>
<pre class="source-code" lang="en-GB">import open3d</pre>
<pre class="source-code" lang="en-GB">from pytorch3d.io import load_obj</pre>
<pre class="source-code" lang="en-GB">import torch</pre>
<pre class="source-code" lang="en-GB">mesh_file = "cube_texture.obj"</pre>
<pre class="source-code" lang="en-GB">print('visualizing the mesh using open3D')</pre>
<pre class="source-code" lang="en-GB">mesh = open3d.io.read_triangle_mesh(mesh_file)</pre>
<pre class="source-code" lang="en-GB">open3d.visualization.draw_geometries([mesh],</pre>
<pre class="source-code" lang="en-GB">                  mesh_show_wireframe = True,</pre>
<pre class="source-code" lang="en-GB">                  mesh_show_back_face = True)</pre>
<pre class="source-code" lang="en-GB">print("Loading the same file with PyTorch3D")</pre>
<pre class="source-code" lang="en-GB">vertices, faces, aux = load_obj(mesh_file)</pre>
<pre class="source-code" lang="en-GB">print('Type of vertices = ', type(vertices))</pre>
<pre class="source-code" lang="en-GB">print("Type of faces = ", type(faces))</pre>
<pre class="source-code" lang="en-GB">print("Type of aux = ", type(aux))</pre>
<pre class="source-code" lang="en-GB">print('vertices = ', vertices)</pre>
<pre class="source-code" lang="en-GB">print('faces = ', faces)</pre>
<pre class="source-code" lang="en-GB">print('aux = ', aux)</pre>
<pre class="source-code" lang="en-GB">texture_images = getattr(aux, 'texture_images')</pre>
<pre class="source-code" lang="en-GB">print('texture_images type = ', type(texture_images))</pre>
<pre class="source-code" lang="en-GB">print(texture_images['Skin'].shape)</pre>
<p lang="en-GB">The output<a id="_idIndexMarker052"/> of the <strong class="source-inline" lang="">obj_example2.py</strong> code snippet <a id="_idIndexMarker053"/>should be <span class="No-Break" lang="">as follows:</span></p>
<pre class="source-code" lang="en-GB">visualizing the mesh using open3D</pre>
<pre class="source-code" lang="en-GB">Loading the same file with PyTorch3D</pre>
<pre class="source-code" lang="en-GB">Type of vertices =  &lt;class 'torch.Tensor'&gt;</pre>
<pre class="source-code" lang="en-GB">Type of faces =  &lt;class 'pytorch3d.io.obj_io.Faces'&gt;</pre>
<pre class="source-code" lang="en-GB">Type of aux =  &lt;class 'pytorch3d.io.obj_io.Properties'&gt;</pre>
<pre class="source-code" lang="en-GB">vertices =  tensor([[ 1.0000, -1.0000, -1.0000],</pre>
<pre class="source-code" lang="en-GB">        [ 1.0000, -1.0000,  1.0000],</pre>
<pre class="source-code" lang="en-GB">        [-1.0000, -1.0000,  1.0000],</pre>
<pre class="source-code" lang="en-GB">        [-1.0000, -1.0000, -1.0000],</pre>
<pre class="source-code" lang="en-GB">        [ 1.0000,  1.0000, -1.0000],</pre>
<pre class="source-code" lang="en-GB">        [ 1.0000,  1.0000,  1.0000],</pre>
<pre class="source-code" lang="en-GB">        [-1.0000,  1.0000,  1.0000],</pre>
<pre class="source-code" lang="en-GB">        [-1.0000,  1.0000, -1.0000]])</pre>
<pre class="source-code" lang="en-GB">faces =  Faces(verts_idx=tensor([[1, 2, 3],</pre>
<pre class="source-code" lang="en-GB">        [7, 6, 5],</pre>
<pre class="source-code" lang="en-GB">        [4, 5, 1],</pre>
<pre class="source-code" lang="en-GB">        [5, 6, 2],</pre>
<pre class="source-code" lang="en-GB">        [2, 6, 7],</pre>
<pre class="source-code" lang="en-GB">        [0, 3, 7],</pre>
<pre class="source-code" lang="en-GB">        [0, 1, 3],</pre>
<pre class="source-code" lang="en-GB">        ...</pre>
<pre class="source-code" lang="en-GB">        [3, 3, 3],</pre>
<pre class="source-code" lang="en-GB">        [4, 4, 4],</pre>
<pre class="source-code" lang="en-GB">        [5, 5, 5]]), textures_idx=tensor([[ 0,  1,  2],</pre>
<pre class="source-code" lang="en-GB">        [ 0,  3,  4],</pre>
<pre class="source-code" lang="en-GB">        [ 5,  6,  7],</pre>
<pre class="source-code" lang="en-GB">        [ 7,  4,  3],</pre>
<pre class="source-code" lang="en-GB">        [ 8,  9, 10],</pre>
<pre class="source-code" lang="en-GB">        [11, 12, 10],</pre>
<pre class="source-code" lang="en-GB">        ...</pre>
<pre class="source-code" lang="en-GB">        [12,  8, 10],</pre>
<pre class="source-code" lang="en-GB">        [ 5, 11, 10]]), materials_idx=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))</pre>
<pre class="source-code" lang="en-GB">aux =  Properties(normals=tensor([[ 0., -1.,  0.],</pre>
<pre class="source-code" lang="en-GB">        [ 0.,  1.,  0.],</pre>
<pre class="source-code" lang="en-GB">        [ 1.,  0.,  0.],</pre>
<pre class="source-code" lang="en-GB">        [-0.,  0.,  1.],</pre>
<pre class="source-code" lang="en-GB">        [-1., -0., -0.],</pre>
<pre class="source-code" lang="en-GB">        [ 0.,  0., -1.]]), verts_uvs=tensor([[1.0000, 0.3333],</pre>
<pre class="source-code" lang="en-GB">        ...</pre>
<pre class="source-code" lang="en-GB">        [0.3333, 0.6667],</pre>
<pre class="source-code" lang="en-GB">        [1.0000, 0.0000]]), material_colors={'Skin': {'ambient_color': tensor([0.2000, 0.2000, 0.2000]), 'diffuse_color': tensor([0.8275, 0.7922, 0.7725]), 'specular_color': tensor([0., 0., 0.]), 'shininess': tensor([0.])}}, texture_images={'Skin': tensor([[[0.2078, 0.1765, 0.1020],</pre>
<pre class="source-code" lang="en-GB">         [0.2039, 0.1725, 0.0980],</pre>
<pre class="source-code" lang="en-GB">         [0.1961, 0.1647, 0.0902],</pre>
<pre class="source-code" lang="en-GB">         ...,</pre>
<pre class="source-code" lang="en-GB">          [0.2235, 0.1882, 0.1294]]])}, texture_atlas=None)</pre>
<pre class="source-code" lang="en-GB">texture_images type =  &lt;class 'dict'&gt;</pre>
<pre class="source-code" lang="en-GB">Skin</pre>
<pre class="source-code" lang="en-GB">torch.Size([250, 250, 3])</pre>
<p class="callout-heading" lang="en-GB">Note</p>
<p class="callout" lang="en-GB">This is not the complete output; please check this while you run <span class="No-Break" lang="">the code.</span></p>
<p lang="en-GB">Compared with the output of the <strong class="source-inline" lang="">obj_example1.py</strong> code snippet, the preceding output has the <span class="No-Break" lang="">following differences.</span></p>
<ul>
<li lang="en-GB">The <strong class="source-inline" lang="">normals_idx</strong> and <strong class="source-inline" lang="">textures_idx</strong> fields of the <strong class="source-inline" lang="">faces</strong> variable all contain valid indices now instead of taking a <strong class="source-inline" lang="">-</strong><span class="No-Break" lang=""><strong class="source-inline" lang="">1</strong></span><span class="No-Break" lang=""> value.</span></li>
<li lang="en-GB">The <strong class="source-inline" lang="">normals</strong> field of the <strong class="source-inline" lang="">aux</strong> variable is a PyTorch tensor now, instead of <span class="No-Break" lang="">being </span><span class="No-Break" lang=""><strong class="source-inline" lang="">None</strong></span><span class="No-Break" lang="">.</span></li>
<li lang="en-GB">The <strong class="source-inline" lang="">verts_uvs</strong> field of the <strong class="source-inline" lang="">aux</strong> variable is a PyTorch tensor now, instead of <span class="No-Break" lang="">being </span><span class="No-Break" lang=""><strong class="source-inline" lang="">None</strong></span><span class="No-Break" lang="">.</span></li>
<li lang="en-GB">The <strong class="source-inline" lang="">texture_images</strong> field of the <strong class="source-inline" lang="">aux</strong> variable is not an empty dictionary any longer. The <strong class="source-inline" lang="">texture_images</strong> dictionary contains one entry with a key, <strong class="source-inline" lang="">Skin</strong>, and a PyTorch tensor with a shape of (250, 250, 3). This tensor is exactly the same as the image contained in the <strong class="source-inline" lang="">wal67ar_small.jpg</strong> file, as defined in the <span class="No-Break" lang=""><strong class="source-inline" lang="">mtl_texture.mtl</strong></span><span class="No-Break" lang=""> file.</span></li>
</ul>
<p lang="en-GB">We <a id="_idIndexMarker054"/>have<a id="_idIndexMarker055"/> learned how to use basic 3D data file formats and PLY and OBJ files. In the next section, we will learn the basic concepts of 3D <span class="No-Break" lang="">coordination systems.</span></p>
<h1 id="_idParaDest-26" lang="en-GB"><a id="_idTextAnchor026"/>Understanding 3D coordination systems</h1>
<p lang="en-GB">In this section, we <a id="_idIndexMarker056"/>are going to learn about the frequently used coordination systems in PyTorch3D. This section is adapted from PyTorch’s documentation of camera coordinate systems: <a href="https://pytorch3d.org/docs/cameras">https://pytorch3d.org/docs/cameras</a>. To understand and use the PyTorch3D rendering system, we usually need to know these coordination systems and how to use them. As discussed in the previous sections, 3D data can be represented by points, faces, and voxels. The location of each point can be represented by a set of <em class="italic" lang="">x</em>, <em class="italic" lang="">y</em>, and <em class="italic" lang="">z</em> coordinates, with respect to a certain coordination system. We usually need to define and use multiple coordination systems, depending on which one is <span class="No-Break" lang="">most convenient.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer009">
<img alt="Figure 1.2 – A world coordinate system, where the origin and axis are defined independently of the camera positions " height="426" src="image/B18217_01_002.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – A world coordinate system, where the origin and axis are defined independently of the camera positions</p>
<p lang="en-GB">The first coordination system we frequently use is called the <strong class="bold" lang="">world coordination system</strong>. This<a id="_idIndexMarker057"/> coordinate system is a 3D coordination system chosen with respect to all the 3D objects, such that the locations of the 3D objects can be easy to determine. Usually, the axis of the world coordination system does not agree with the object orientation or camera orientation. Thus, there exist some non-zero rotations and displacements between the origin of the world coordination system and the object and camera orientations. A figure showing the world coordination system is <span class="No-Break" lang="">shown here:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer010">
<img alt="Figure 1.3 – The camera view coordinate system, where the origin is at the camera projection center and the three axes are defined according to the imaging plane " height="599" src="image/B18217_01_003.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – The camera view coordinate system, where the origin is at the camera projection center and the three axes are defined according to the imaging plane</p>
<p lang="en-GB">Since the axis <a id="_idIndexMarker058"/>of the world coordination system usually does not agree with the camera orientation, for many situations, it is more convenient to define and use a camera view coordination system. In PyTorch3D, the camera view coordination system is defined such that the origin is at the projection point of the camera, the <em class="italic" lang="">x</em> axis points to the left, the <em class="italic" lang="">y</em> axis points upward, and the <em class="italic" lang="">z</em> axis points to <span class="No-Break" lang="">the front.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<img alt="Figure 1.4 – The NDC coordinate system, in which the volume is confined to the ranges that the camera can render " height="892" src="image/B18217_01_004.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – The NDC coordinate system, in which the volume is confined to the ranges that the camera can render</p>
<p lang="en-GB">The <strong class="bold" lang="">normalized device coordinate</strong> (<strong class="bold" lang="">NDC</strong>) confines<a id="_idIndexMarker059"/> the volume that a camera can render. The <em class="italic" lang="">x</em> coordinate <a id="_idIndexMarker060"/>values in the NDC space range from -1 to +1, as do the <em class="italic" lang="">y</em> coordinate values. The <em class="italic" lang="">z</em> coordinate values range from znear to zfar, where znear is the nearest depth and zfar is the farthest depth. Any object out of this znear to zfar range would not be rendered by <span class="No-Break" lang="">the camera.</span></p>
<p lang="en-GB">Finally, the screen coordinate system is defined in terms of how the rendered images are shown on our screens. The coordinate system contains the <em class="italic" lang="">x</em> coordinate as the columns of the pixels, the <em class="italic" lang="">y</em> coordinate as the rows of the pixels, and the <em class="italic" lang="">z</em> coordinate corresponding to the depth of <span class="No-Break" lang="">the object.</span></p>
<p lang="en-GB">To render the 3D object correctly on our 2D screens, we need to switch between these coordinate systems. Luckily, these conversions can be easily carried out by using the PyTorch3D camera <a id="_idIndexMarker061"/>models. We will discuss coordinatation conversion in more detail after we discuss the <span class="No-Break" lang="">camera models.</span></p>
<h1 id="_idParaDest-27" lang="en-GB"><a id="_idTextAnchor027"/>Understanding camera models</h1>
<p lang="en-GB">In this section, we <a id="_idIndexMarker062"/>will learn about camera models. In 3D deep learning, usually we need to use 2D images for 3D detection. Either 3D information is detected solely from 2D images, or 2D images are fused with depth for high accuracy. Nevertheless, camera models are essential to build correspondence between the 2D space and the <span class="No-Break" lang="">3D world.</span></p>
<p lang="en-GB">In PyTorch3D, there are two major camera models, the orthographic camera defined by the <strong class="source-inline" lang="">OrthographicCameras</strong> class and the perspective camera model defined by the <strong class="source-inline" lang="">PerspectiveCameras</strong> class. The following figure shows the differences between the two <span class="No-Break" lang="">camera models.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<img alt="Figure 1.5 – Two major camera models implemented in PyTorch3D, perspective and orthographic " height="482" src="image/B18217_01_005Redraw.jpg" width="1000"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – Two major camera models implemented in PyTorch3D, perspective and orthographic</p>
<p lang="en-GB">The orthographic cameras use orthographic projections to map objects in the 3D world to 2D images, while the perspective cameras use perspective projections to map objects in the 3D world to 2D images. The orthographic projections map objects to 2D images, disregarding the object depth. For example, just as shown in the figure, two objects with the same geometric size at different depths would be mapped to 2D images of the same size. On the other hand, in perspective projections, if an object moved far away from the camera, it would be mapped to a smaller size on the <span class="No-Break" lang="">2D images.</span></p>
<p lang="en-GB">Now that we <a id="_idIndexMarker063"/>have learned about the basic concept of camera models, let us look at some coding examples to see how we can create and use these <span class="No-Break" lang="">camera models.</span></p>
<h1 id="_idParaDest-28" lang="en-GB"><a id="_idTextAnchor028"/>Coding for camera models and coordination systems</h1>
<p lang="en-GB">In this <a id="_idIndexMarker064"/>section, we<a id="_idIndexMarker065"/> are going to leverage everything we have learned to build a concrete camera model and convert between different coordinate systems, using a concrete code snippet example written in Python <span class="No-Break" lang="">and PyTorch3D:</span></p>
<ol>
<li lang="en-GB" value="1">First, we are going to use the following mesh defined by a <strong class="source-inline" lang="">cube.obj</strong> file. Basically, the mesh is <span class="No-Break" lang="">a cube:</span><p class="source-code" lang="en-GB">mtllib ./cube.mtl</p><p class="source-code" lang="en-GB">o cube</p><p class="source-code" lang="en-GB"># Vertex list</p><p class="source-code" lang="en-GB">v -50 -50 20</p><p class="source-code" lang="en-GB">v -50 -50 10</p><p class="source-code" lang="en-GB">v -50 50 10</p><p class="source-code" lang="en-GB">v -50 50 20</p><p class="source-code" lang="en-GB">v 50 -50 20</p><p class="source-code" lang="en-GB">v 50 -50 10</p><p class="source-code" lang="en-GB">v 50 50 10</p><p class="source-code" lang="en-GB">v 50 50 20</p><p class="source-code" lang="en-GB"># Point/Line/Face list</p><p class="source-code" lang="en-GB">usemtl Door</p><p class="source-code" lang="en-GB">f 1 2 3</p><p class="source-code" lang="en-GB">f 6 5 8</p><p class="source-code" lang="en-GB">f 7 3 2</p><p class="source-code" lang="en-GB">f 4 8 5</p><p class="source-code" lang="en-GB">f 8 4 3</p><p class="source-code" lang="en-GB">f 6 2 1</p><p class="source-code" lang="en-GB">f 1 3 4</p><p class="source-code" lang="en-GB">f 6 8 7</p><p class="source-code" lang="en-GB">f 7 2 6</p><p class="source-code" lang="en-GB">f 4 5 1</p><p class="source-code" lang="en-GB">f 8 3 7</p><p class="source-code" lang="en-GB">f 6 1 5</p><p class="source-code" lang="en-GB"># End of file</p></li>
</ol>
<p lang="en-GB">The <a id="_idIndexMarker066"/>example <a id="_idIndexMarker067"/>code snippet is <strong class="source-inline" lang="">camera.py</strong>, which can be downloaded from the book’s <span class="No-Break" lang="">GitHub repository.</span></p>
<ol>
<li lang="en-GB" value="2">Let us import all the modules that <span class="No-Break" lang="">we need:</span><p class="source-code" lang="en-GB">import open3d</p><p class="source-code" lang="en-GB">import torch</p><p class="source-code" lang="en-GB">import pytorch3d</p><p class="source-code" lang="en-GB">from pytorch3d.io import load_obj</p><p class="source-code" lang="en-GB">from scipy.spatial.transform import Rotation as Rotation</p><p class="source-code" lang="en-GB">from pytorch3d.renderer.cameras import PerspectiveCameras</p></li>
<li lang="en-GB">We can load <a id="_idIndexMarker068"/>and <a id="_idIndexMarker069"/>visualize the mesh by using Open3D’s <span class="No-Break" lang=""><strong class="source-inline" lang="">draw_geometrics</strong></span><span class="No-Break" lang=""> function:</span><p class="source-code" lang="en-GB">#Load meshes and visualize it with Open3D</p><p class="source-code" lang="en-GB">mesh_file = "cube.obj"</p><p class="source-code" lang="en-GB">print('visualizing the mesh using open3D')</p><p class="source-code" lang="en-GB">mesh = open3d.io.read_triangle_mesh(mesh_file)</p><p class="source-code" lang="en-GB">open3d.visualization.draw_geometries([mesh],</p><p class="source-code" lang="en-GB">                 mesh_show_wireframe = True,</p><p class="source-code" lang="en-GB">                 mesh_show_back_face = True)</p></li>
<li lang="en-GB">We define a <strong class="source-inline" lang="">camera</strong> variable as a PyTorch3D <strong class="source-inline" lang="">PerspectiveCamera</strong> object. The camera here is actually mini-batched. For example, the rotation matrix, R, is a PyTorch tensor with a shape of [8, 3, 3], which actually defines eight cameras, each with one of the eight rotation matrices. This is the same case for all other camera parameters, such as image sizes, focal lengths, and <span class="No-Break" lang="">principal points:</span><p class="source-code" lang="en-GB">#Define a mini-batch of 8 cameras</p><p class="source-code" lang="en-GB">image_size = torch.ones(8, 2)</p><p class="source-code" lang="en-GB">image_size[:,0] = image_size[:,0] * 1024</p><p class="source-code" lang="en-GB">image_size[:,1] = image_size[:,1] * 512</p><p class="source-code" lang="en-GB">image_size = image_size.cuda()</p><p class="source-code" lang="en-GB">focal_length = torch.ones(8, 2)</p><p class="source-code" lang="en-GB">focal_length[:,0] = focal_length[:,0] * 1200</p><p class="source-code" lang="en-GB">focal_length[:,1] = focal_length[:,1] * 300</p><p class="source-code" lang="en-GB">focal_length = focal_length.cuda()</p><p class="source-code" lang="en-GB">principal_point = torch.ones(8, 2)</p><p class="source-code" lang="en-GB">principal_point[:,0] = principal_point[:,0] * 512</p><p class="source-code" lang="en-GB">principal_point[:,1] = principal_point[:,1] * 256</p><p class="source-code" lang="en-GB">principal_point = principal_point.cuda()</p><p class="source-code" lang="en-GB">R = Rotation.from_euler('zyx', [</p><p class="source-code" lang="en-GB">    [n*5, n, n]  for n in range(-4, 4, 1)], degrees=True).as_matrix()</p><p class="source-code" lang="en-GB">R = torch.from_numpy(R).cuda()</p><p class="source-code" lang="en-GB">T = [ [n, 0, 0] for n in range(-4, 4, 1)]</p><p class="source-code" lang="en-GB">T = torch.FloatTensor(T).cuda()</p><p class="source-code" lang="en-GB">camera = PerspectiveCameras(focal_length = focal_length,</p><p class="source-code" lang="en-GB">                            principal_point = principal_point,</p><p class="source-code" lang="en-GB">                            in_ndc = False,</p><p class="source-code" lang="en-GB">                            image_size = image_size,</p><p class="source-code" lang="en-GB">                            R = R,</p><p class="source-code" lang="en-GB">                            T = T,</p><p class="source-code" lang="en-GB">                            device = 'cuda')</p></li>
<li lang="en-GB">Once we have defined the camera variable, we can call the <strong class="source-inline" lang="">get_world_to_view_transform</strong> class member method to obtain a <strong class="source-inline" lang="">Transform3d</strong> object, <strong class="source-inline" lang="">world_to_view_transform</strong>. We can then use the <strong class="source-inline" lang="">transform_points</strong> member method to convert from world coordination to camera view coordination. Similarly, we can also use the <strong class="source-inline" lang="">get_full_projection_transform</strong> member method to obtain a <strong class="source-inline" lang="">Transform3d</strong> object, which<a id="_idIndexMarker070"/> is for the conversion from world<a id="_idIndexMarker071"/> coordination to <span class="No-Break" lang="">screen coordination:</span><p class="source-code" lang="en-GB">world_to_view_transform = camera.get_world_to_view_transform()</p><p class="source-code" lang="en-GB">world_to_screen_transform = camera.get_full_projection_transform()</p><p class="source-code" lang="en-GB">#Load meshes using PyTorch3D</p><p class="source-code" lang="en-GB">vertices, faces, aux = load_obj(mesh_file)</p><p class="source-code" lang="en-GB">vertices = vertices.cuda()</p><p class="source-code" lang="en-GB">world_to_view_vertices = world_to_view_transform.transform_points(vertices)</p><p class="source-code" lang="en-GB">world_to_screen_vertices = world_to_screen_transform.transform_points(vertices)</p><p class="source-code" lang="en-GB">print('world_to_view_vertices = ', world_to_view_vertices)</p><p class="source-code" lang="en-GB">print('world_to_screen_vertices = ', world_to_screen_vertices</p></li>
</ol>
<p lang="en-GB">The code <a id="_idIndexMarker072"/>example <a id="_idIndexMarker073"/>shows the basic ways that PyTorch3D cameras can be used and how easy it is to switch between different coordinate systems <span class="No-Break" lang="">using PyTorch3D.</span></p>
<h1 id="_idParaDest-29" lang="en-GB"><a id="_idTextAnchor029"/>Summary</h1>
<p lang="en-GB">In this chapter, we first learned how to set up our development environment. We then talked about the most widely used 3D data representations. We then explored some concrete examples of 3D data representation by learning about the 3D data file formats, the PLY format and the OBJ format. Then, we learned about the basic concepts of 3D coordination systems and camera models. In the last part of the chapter, we learned how to build camera models and convert between different coordination systems through a hands-on <span class="No-Break" lang="">coding example.</span></p>
<p lang="en-GB">In the next chapter, we will talk about more important 3D deep learning concepts, such as rendering to convert 3D models to 2D images, heterogeneous mini-batching, and several ways to <span class="No-Break" lang="">represent rotations.</span></p>
</div>
</div></body></html>