<html><head></head><body>
		<div>
			<div id="_idContainer343" class="Content">
			</div>
		</div>
		<div id="_idContainer344" class="Content">
			<h1 id="_idParaDest-196"><a id="_idTextAnchor205"/>8. Deep Learning</h1>
		</div>
		<div id="_idContainer364" class="Content">
			<p>Deep learning is a machine learning method based on deep neural networks. You can create a deep network by adding layers to the networks we've described so far. However, a deep network has problems. This chapter will describe the characteristics, problems, and possibilities of deep learning, as well as an overview of current deep learning practices.</p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor206"/>Making a Network Deeper</h2>
			<p>Throughout this book, we have learned a lot about neural networks, including the various layers that constitute a neural network, effective techniques used in training, CNNs that are especially effective for handling images, and how to optimize parameters. These are all important techniques in deep learning. Here, we will integrate the techniques we have learned so far to create a deep network. Then, we will try our hand at handwritten digit recognition using the MNIST dataset.</p>
			<h3 id="_idParaDest-198"><a id="_idTextAnchor207"/>Deeper Networks</h3>
			<p>First, we will create a CNN that has the network architecture shown in <em class="italics">Figure 8.1</em>. This network is based on the VGG network, which will be described in the next section.</p>
			<p>As shown in <em class="italics">Figure 8.1</em>, the network is deeper than the networks that we have implemented so far. All the convolution layers used here are small 3x3 filters. Here, the number of channels becomes larger as the network deepens (as the number of channels in a convolution layer increases from 16 in the first layer to 16, 32, 32, 64, and 64). As you can see, pooling layers are inserted to reduce the spatial size of intermediate data gradually, while dropout layers are used for the latter fully connected layers:</p>
			<div>
				<div id="_idContainer345" class="IMG---Figure">
					<img src="image/fig08_1.jpg" alt="Figure 8.1: Deep CNN for handwritten digit recognition&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.1: Deep CNN for handwritten digit recognition</h6>
			<p>This network uses the "He initializer" to initialize the weights, and Adam to update the weight parameters, resulting in the following characteristics:</p>
			<ul>
				<li>Convolution layers which use small 3×3 filters</li>
				<li>ReLU as the activation function</li>
				<li>A dropout layer used after a fully connected layer</li>
				<li>Optimization is done by Adam</li>
				<li>"He initializer" for initial weight values</li>
			</ul>
			<p>As these characteristics indicate, the network in <em class="italics">Figure 8.1</em> uses many neural network techniques that we have learned so far. Now, let's use this network for training. The result shows that the recognition accuracy of this network is 99.38% (final recognition accuracies vary slightly, but this network will generally exceed 99%).</p>
			<h4>Note</h4>
			<p class="callout">The source code that implemented the network shown in <em class="italics">Figure 8.1</em> is located at <strong class="inline">ch08/deep_convnet.py</strong>. The code for training is provided at <strong class="inline">ch08/train_deepnet.py</strong>. You can use this code to reproduce the training that will be conducted here. Training in a deep network takes a lot of time (probably more than half a day). This book provides trained weight parameters in <strong class="inline">ch08/deep_conv_net_params.pkl</strong>. The <strong class="inline">deep_convnet.py</strong> code file provides a feature for loading trained parameters. You can use it as required.</p>
			<p>The error rate of the network shown in <em class="italics">Figure 8.1</em> is only 0.62%. Here, we can see what images were incorrectly recognized. <em class="italics">Figure 8.2</em> shows the recognition error examples:</p>
			<div>
				<div id="_idContainer346" class="IMG---Figure">
					<img src="image/fig08_2.jpg" alt="Figure 8.2: Sample images that were recognized incorrectly – the upper left of each image shows the correct label, while the lower right shows the result of prediction by this network&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.2: Sample images that were recognized incorrectly – the upper left of each image shows the correct label, while the lower right shows the result of prediction by this network</h6>
			<p>As shown in <em class="italics">Figure 8.2</em>, these images are difficult even for us humans to recognize. The upper-left image looks like a "0" (the correct answer is "6"), and the one next to it certainly seems to be a "5" (the correct answer is "3"). Generally, the distinctions between "1" and "7", "0" and "6", and "3" and "5" are difficult. These examples explain why they were recognized incorrectly.</p>
			<p>While this deep CNN is very precise, it recognized images incorrectly in the same way as humans would. This also shows us the large potential of a deep CNN.</p>
			<h3 id="_idParaDest-199">Im<a id="_idTextAnchor208"/>proving Recognition Accuracy</h3>
			<p>The website called "What is the class of this image?" <em class="italics">(Rodrigo Benenson's blog</em> "<em class="italics">Classification datasets results</em>" (<a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html">http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html</a>)) ranks the recognition accuracies for various datasets by the techniques published in the related literature (<em class="italics">Figure 8.3</em>):</p>
			<div>
				<div id="_idContainer347" class="IMG---Figure">
					<img src="image/fig08_3.jpg" alt="Figure 8.3: Ranking techniques for the MNIST dataset&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.3: Ranking techniques for the MNIST dataset</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.3</em> is cited from reference, <em class="italics">Rodrigo Benenson's blog</em> "<em class="italics">Classification datasets results</em>" (<a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html">http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html</a>) as of June 2016.</p>
			<p>In the ranking shown in <em class="italics">Figure 8.3</em>, keywords such as "neural networks," "deep," and "convolutional" are noticeable. Many high-ranked techniques are CNN-based. As of June 2016, the highest recognition accuracy for the MNIST dataset is 99.79% (an error rate of 0.21%), and the technique is also CNN-based (<em class="italics">Li Wan, Matthew Zeiler, Sixin Zhang, Yann L. Cun, and Rob Fergus (2013): Regularization of Neural Networks using DropConnect. In Sanjoy Dasgupta &amp; David McAllester, eds. Proceedings of the 30th International Conference on Machine Learning (ICML2013). JMLR Workshop and Conference Proceedings, 1058 – 1066</em>). The CNN that is used there is not very deep (two convolution layers and two fully connected layers).</p>
			<h4>Note</h4>
			<p class="callout">For the MNIST dataset, the highest accuracy can be obtained immediately, even if the network is not very deep. For a relatively simple problem such as handwritten digit recognition, the representation of the network does not need to be very high. Therefore, adding layers is not very beneficial. In the large-scale general object recognition process, adding layers greatly improves recognition accuracy because it is a complicated problem.</p>
			<p>By examining the aforementioned high-ranked techniques, we can find techniques and tips for further improving recognition accuracy. For example, we can see that ensemble learning, learning rate decay, and <strong class="bold">data augmentation</strong> contribute to the improvement of recognition accuracy. Data augmentation is a simple but particularly effective method for improving recognition accuracy.</p>
			<p>Data augmentation uses an algorithm to expand input images (training images) artificially. As shown in <em class="italics">Figure 8.4</em>, it adds the images by slightly changing the input images with rotation or vertical/horizontal movement. This is especially effective when the number of images in the dataset is limited:</p>
			<div>
				<div id="_idContainer348" class="IMG---Figure">
					<img src="image/Figure_8.4.jpg" alt="Figure 8.4: Sample data augmentation&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.4: Sample data augmentation</h6>
			<p>You can use data augmentation to expand images in various ways, other than the modifications shown in <em class="italics">Figure 8.4</em>. For example, you can cut out part of an image (or crop) or reverse an image horizontally (called flipping, though this is only effective when the symmetry of the image does not need to be considered). For ordinary images, changing their appearance (e.g., by adding brightness and scaling them up or down, is also effective. If you can use data augmentation to increase the number of training images, you can improve the recognition accuracy by using deep learning. This may seem a simple trick, but it often brings good results. We will not implement data augmentation here. Since implementing this is easy, please try it for yourself if you are interested.</p>
			<h3 id="_idParaDest-200">Moti<a id="_idTextAnchor209"/>vation for a Deeper Network</h3>
			<p>Ther<a id="_idTextAnchor210"/>e is still much that is not known about the importance of making a network deeper. Although theoretical findings are insufficient now, past research and experiments can explain some things (rather intuitively). This section will provide some data and explanations that support the importance of "making a network deeper."</p>
			<p>First, the results from competitions surrounding large-scale image recognition such as ILSVRC show the importance of "making a network deeper" (please see the next section for details). They indicate that many of the recent high-ranked techniques are based on deep learning and that the networks tend to go deeper. The deeper the network, the better the recognition performance.</p>
			<p>One of the advantages of this is that you can reduce the number of parameters in the network. When a network is deeper, it can achieve similar (or higher) representation with fewer parameters. This is easy to understand when you consider the filter size in a convolution operation. <em class="italics">Figure 8.5</em> shows a convolution layer with a 5x5 filter.</p>
			<p>Please note the area of the input data each node of the output data is calculated in. Of course, each output node is based on the 5x5 area of the input data in the example shown in <em class="italics">Figure 8.5</em>. Now, let's think about a case where 3x3 convolution operations are repeated twice, as shown in <em class="italics">Figure 8.6</em>. In this case, intermediate data is based on a 3x3 area for each output node. So, which area of the previous input data is the 3x3 area of intermediate data based on? When you look at <em class="italics">Figure 8.6</em> carefully, you will notice that it is based on a 5×5 area. Thus, the output data of <em class="italics">Figure 8.6</em> "looks at" a 5×5 area of input data for calculation:</p>
			<div>
				<div id="_idContainer349" class="IMG---Figure">
					<img src="image/Figure_8.5.jpg" alt="Figure 8.5: Example of a 5x5 convolution operation&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.5: Example of a 5x5 convolution operation</h6>
			<div>
				<div id="_idContainer350" class="IMG---Figure">
					<img src="image/Figure_8.6.jpg" alt="Figure 8:6: Example of when 3x3 convolution operations are repeated twice&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8:6: Example of when 3x3 convolution operations are repeated twice</h6>
			<p>The area of one 5x5 convolution operation is equivalent to that of two 3x3 convolution operations. The former uses 25 parameters (5x5), while the latter uses 18 parameters (2x3x3) in total. Thus, multiple convolution layers reduce the number of parameters. As the network gets deeper, the reduced number of parameters becomes larger. For example, when 3x3 convolution operations are repeated three times, the number of parameters is 27 in total. To "look at" the same area with one convolution operation, a 7x7 filter is required, which means that the number of parameters goes up to 49.</p>
			<h4>Note</h4>
			<p class="callout">The advantage of making a network deeper by applying a small filter several times is that it can reduce the number of parameters and expand the <strong class="bold">receptive field</strong> (a local space area that changes neurons). When you add layers, an activation function, such as ReLU, is placed between convolution layers, resulting in an improved network representation. This is because the activation function applies a "nonlinear" force to the network. Multiple nonlinear functions enable more complicated expressions.</p>
			<p>Training efficiency is another advantage of making a network deeper. A deeper network can reduce training data and conduct training quickly. You can understand this intuitively by remembering the description provided in <em class="italics">Visualizing a CNN</em> section in <em class="italics">Chapter 7</em>, <em class="italics">Convolutional Neural Networks</em>. In that section, you learned that the convolution layers in a CNN extract information hierarchically. In the front convolution layer, neurons react to simple shapes such as edges. As a layer becomes deeper, neurons react to hierarchically more complicated shapes, such as textures and object parts.</p>
			<p>With such a hierarchical structure of a network in mind, consider the problem of recognizing a "dog." To solve this problem in a shallow network, convolution layers must "understand" many characteristics of a dog at one time. There are various types of dogs, and what they look like varies, depending on the environment in which the image was shot. Therefore, understanding the characteristics of a dog requires varied training data and a lot of time in training.</p>
			<p>However, you can divide the problem to learn hierarchically by making a network deeper. Then, the problem for each layer to learn becomes simpler. For example, the first layer can concentrate on learning edges. Thus, the network can learn efficiently with a small amount of training data. This is because the number of images that contain edges is larger than that of images of a dog, and the pattern of an edge is simpler than that of a dog.</p>
			<p>It is also important that you can pass information hierarchically by making a network deeper. For example, the layer next to the one that extracted edges can use edge information, so we can expect it to learn more advanced patterns efficiently. In short, by making a network deeper, you can divide the problem for each layer to learn into "simple problems that are easy to solve" so that you can expect efficient training.</p>
			<p>This is the explanation that supports the importance of "making a network deeper." Please note that deeper networks in recent years have been provided by new techniques and environments, such as big data and computer power, which enable correct training in a deep network.</p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor211"/>A Brief History of Deep Learning</h2>
			<p>It is said that deep learning started to draw a lot of attention in the competition of large-scale image recognition due to the <strong class="bold">ImageNet Large Scale Visual Recognition Challenge</strong> (<strong class="bold">ILSRVC</strong>), which was held in 2012. In the competition, a deep learning technique called AlexNet achieved an overwhelming win, overturning the traditional approaches to image recognition. Since deep learning launched a counterattack in 2012, it has always played the leading role in subsequent competitions. Here, we will look at the current trend of deep learning around the competition of large-scale image recognition, known as ILSVRC.</p>
			<h3 id="_idParaDest-202"><a id="_idTextAnchor212"/>ImageNet</h3>
			<p>ImageNet<span lang="en-US" xml:lang="en-US"> </span>(<em class="italics">J. Deng, W. Dong, R. Socher, L.J. Li, Kai Li, and Li Fei-Fei (2009): ImageNet: A large-scale hierarchical image database</em>. In IEEE Conference on <em class="italics">Computer Vision and Pattern Recognition, 2009. CVPR 2009. 248 – 255. DOI</em>: (<a href="http://dx.doi.org/10.1109/CVPR.2009.5206848">http://dx.doi.org/10.1109/CVPR.2009.5206848</a>)) is a dataset that contains more than 1 million images. As shown in <em class="italics">Figure 8.7</em>, it contains various types of images, and each image is associated with a label (class name). An image recognition competition called ILSVRC is held every year using this huge dataset:</p>
			<div>
				<div id="_idContainer351" class="IMG---Figure">
					<img src="image/Figure_8.7.jpg" alt="Figure 8.7: Sample data in the large-scale ImageNet dataset&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.7: Sample data in the large-scale ImageNet dataset</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.7</em> is cited from reference, <em class="italics">J. Deng, W. Dong, R. Socher, L.J. Li, Kai Li, and Li Fei-Fei (2009): ImageNet: A large-scale hierarchical image database</em>. In IEEE Conference on <em class="italics">Computer Vision and Pattern Recognition, 2009. CVPR 2009. 248 – 255. DOI:</em> (<a href="http://dx.doi.org/10.1109/CVPR.2009.5206848">http://dx.doi.org/10.1109/CVPR.2009.5206848</a>).</p>
			<p>The ILSVRC competition provides some test items, and one of them is "classification" (in the "classification" division, 1,000 classes are classified to compete in recognition accuracy). <em class="italics">Figure 8.8</em> shows the results of the winning teams for ILSVRC's classification division since 2010. Here, a classification is regarded as "correct" if the top 5 predictions contain the correct class. The following bar graphs show the error rates:</p>
			<div>
				<div id="_idContainer352" class="IMG---Figure">
					<img src="image/Figure_8.8.jpg" alt="Figure 8.8: The results of the winning teams in ILSVRC – the vertical axis shows error rates, &#13;&#10;while the horizontal axis shows years. Team names or technique names are shown in the &#13;&#10;parentheses on the horizontal axis.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.8: The results of the winning teams in ILSVRC – the vertical axis shows error rates, while the horizontal axis shows years. Team names or technique names are shown in the parentheses on the horizontal axis.</h6>
			<p>Please note from the preceding graph that deep learning techniques have always been on top since 2012. Actually, we can see that, in 2012, AlexNet significantly reduced the error rate. Since then, deep learning techniques have steadily improved in terms of accuracy. This was especially apparent with ResNet in 2015, which was a deep network with more than 150 layers and had reduced the error rate to 3.5%. It is even said that this result exceeded the recognition capability of ordinary humans.</p>
			<p>Among the deep learning networks that have achieved great results for the past several years, VGG, GoogLeNet, and ResNet are the most famous. You will come across them at various places relevant to deep learning. I will introduce these three famous networks briefly next.</p>
			<h3 id="_idParaDest-203"><a id="_idTextAnchor213"/>VGG</h3>
			<p>VGG is a "basic" CNN that consists of convolution layers and pooling layers. As shown in <em class="italics">Figure 8.9</em>, it can have as many as 16 (or 19) layers with weights (convolution layers and fully connected layers) to make itself deep and is sometimes called "VGG16" or "VGG19" based on the number of layers:</p>
			<div>
				<div id="_idContainer353" class="IMG---Figure">
					<img src="image/fig08_9.jpg" alt="Figure 8.9: VGG&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.9: VGG</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.9</em> is cited from reference, <em class="italics">Karen Simonyan and Andrew Zisserman (2014): Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv:1409.1556[cs] (September 2014)</em>.</p>
			<p>VGG contains consecutive convolution layers with a small 3x3 filter. As shown in the preceding image, two or four consecutive convolution layers and a pooling layer halve the size, and this process is repeated. Finally, the result is provided via fully connected layers.</p>
			<h4>Note</h4>
			<p class="callout">VGG won second prize in the 2014 competition (GoogLeNet, which is described next, won in 2014). Its performance was not as good as the first-place network, but many engineers prefer to use VGG-based networks because they are very simple in structure and versatile.</p>
			<h3 id="_idParaDest-204"><a id="_idTextAnchor214"/>GoogLeNet</h3>
			<p><em class="italics">Figure 8.10</em> shows the network architecture for GoogLeNet. The rectangles represent the various layers, such as convolution and pooling layers:</p>
			<div>
				<div id="_idContainer354" class="IMG---Figure">
					<img src="image/fig08_10.jpg" alt="Figure 8.10: GoogLeNet&#13; &#10;"/>
				</div>
			</div>
			<h6>Figure 8.10: GoogLeNet</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.10</em> and <em class="italics">Figure 8.11</em> are cited from  <em class="italics">Christian Szegedy et al. (2015): Going Deeper With Convolutions. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>.</p>
			<p>Its network architecture seems very complicated when you look at it, but it is basically the same as that of a CNN. What is distinctive about GoogLeNet is that the network not only has depth in the vertical direction but also in the horizontal direction (spread).</p>
			<p>GoogLeNet has "width" in the horizontal direction. It is called an "inception architecture" and is based on the structure shown in <em class="italics">Figure 8.11</em>:</p>
			<div>
				<div id="_idContainer355" class="IMG---Figure">
					<img src="image/Figure_8.11.jpg" alt="Figure 8.11: Inception architecture of GoogLeNet&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.11: Inception architecture of GoogLeNet</h6>
			<p>As shown in <em class="italics">Figure 8.11</em>, the inception architecture applies multiple filters of different sizes (and pooling) and combines the results. Using this inception architecture as one building block (component) is the main characteristic of GoogLeNet.</p>
			<p>GoogLeNet uses convolution layers with a 1x1 filter in many places. This 1x1 convolution operation reduces the size in the channel direction to reduce the number of parameters and accelerate processing.</p>
			<h3 id="_idParaDest-205"><a id="_idTextAnchor215"/>ResNet</h3>
			<p>ResNet (<em class="italics">Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun (2015): Deep Residual Learning for Image Recognition. arXiv:1512.03385[cs] (December 2015)</em>) is a network developed by a team at Microsoft. It is characterized by a "mechanism" that can make the network deeper than ever.</p>
			<p>Making a network deeper is important to improve its performance. However, when a network becomes too deep, deep learning fails and the final performance is often poor. To solve this problem, ResNet introduced a "skip architecture" (also called "shortcut" or "bypass"). By introducing this skip architecture, performance can be improved as the network becomes deeper (though there is a limit to permissible depth).</p>
			<p>The skip architecture skips convolution layers in the input data to add the input data to the output, as shown in <em class="italics">Figure 8.12</em>:</p>
			<div>
				<div id="_idContainer356" class="IMG---Figure">
					<img src="image/fig08_12.jpg" alt="Figure 8.12: Components of ResNet – the &quot;weight layer&quot; here indicates a convolution layer&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.12: Components of ResNet – the "weight layer" here indicates a convolution layer</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.12</em> and <em class="italics">Figure 8.13</em> are cited from reference, <em class="italics">Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun (2015): Deep Residual Learning for Image Recognition. arXiv:1512.03385[cs] (December 2015)</em>.</p>
			<p>In <em class="italics">Figure 8.12</em>, the input, <em class="italics">x</em>, is connected to the output by skipping two consecutive convolution layers. The output of two convolution layers is originally <em class="italics">F(x)</em>, while the skip architecture changes it to <em class="italics">F(x) + x</em>. </p>
			<p>Adopting this skip architecture enables efficient learning, even when the network is deep. This is because the skip architecture transmits signals without decay during backward propagation.</p>
			<h4>Note</h4>
			<p class="callout">The skip architecture only passes input data "as it is." In backward propagation, it also passes the gradients from the upper stream "as they are" to the lower stream without them being changed. Therefore, you don't need to be worried about the gradients becoming small (or too large) with the skip architecture. You can expect "meaningful gradients" to be transmitted to the front layers. You can also expect the skip architecture to alleviate a traditional gradient vanishing problem that reduces gradients as the network becomes deeper.</p>
			<p>ResNet is based on the VGG network we described earlier and adopts the skip architecture to make the network deeper. <em class="italics">Figure 8.13</em> shows the result of this:</p>
			<div>
				<div id="_idContainer357" class="IMG---Figure">
					<img src="image/fig08_13.jpg" alt="Figure 8.13: ResNet – blocks support 3x3 convolution layers. Its characteristic is the skip &#13;&#10;architecture, which skips layers.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.13: ResNet – blocks support 3x3 convolution layers. Its characteristic is the skip architecture, which skips layers.</h6>
			<p>As shown in <em class="italics">Figure 8.13</em>, ResNet skips two convolution layers to make the network deeper. Experiments have shown that recognition accuracy continues to improve, even when the network contains 150 or more layers. In the ILSVRC competition, it achieved an amazing result of 3.5% in terms of error rate (the percentage of correct classes that were not included in the top 5 predictions).</p>
			<h4>Note</h4>
			<p class="callout">Weight data that's trained by using the huge ImageNet dataset is often used effectively. This is called <strong class="bold">transfer learning</strong>. Part of the trained weights is copied to another neural network for fine-tuning. For example, a network that has the same structure as VGG is provided. Trained weights are used as initial values, and fine-tuning is conducted for a new dataset. Transfer learning is especially effective when you have a few datasets at hand.</p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor216"/>Accelerating Deep Learning</h2>
			<p>Big data and large-scale networks require massive operations in deep learning. We have used CPUs for calculations so far, but CPUs alone are not sufficient to tackle deep learning. In fact, many deep learning frameworks support <strong class="bold">Graphics Processing Units</strong> (<strong class="bold">GPUs</strong>) to process a large number of operations quickly. Recent frameworks are starting to support distributed learning by using multiple GPUs or machines. This section describes accelerating calculations in deep learning. Our implementations of deep learning ended in section 8.1. We will not implement the acceleration (such as support of GPUs) described here.</p>
			<h3 id="_idParaDest-207"><a id="_idTextAnchor217"/>Challenges to Overcome</h3>
			<p>Before discussing the acceleration of deep learning, let's see what processes take time in deep learning. The pie charts in <em class="italics">Figure 8.14</em> show the time spent on each class in the forward processing of AlexNet:</p>
			<div>
				<div id="_idContainer358" class="IMG---Figure">
					<img src="image/Figure_8.14.jpg" alt="Figure 8.14: Percentage of time that each layer spends in the forward processing of AlexNet – the left-hand chart shows GPU time, while the right-hand one shows CPU time&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.14: Percentage of time that each layer spends in the forward processing of AlexNet – the left-hand chart shows GPU time, while the right-hand one shows CPU time</h6>
			<p>Here, "conv" indicates a convolution layer, "pool" indicates a pooling layer, "fc" indicates a fully connected layer, and "norm" indicates a normalization layer (cited from <em class="italics">Jia Yangqing (2014): Learning Semantic Image Representations at a Large Scale. PhD thesis, EECS Department, University of California, Berkeley, May 2014</em>, (<a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.html">http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.html</a>)).</p>
			<p>As you can see, convolution layers spend a lot of time in AlexNet. Actually, the total processing time in convolution layers reaches 95% of GPU time and 89% of CPU time! Therefore, conducting fast and efficient operations in convolution layers is the main challenge of deep learning. <em class="italics">Figure 8.14</em> shows the results in the inference phase, but convolution layers spend a lot of time in the training phase as well.</p>
			<h4>Note</h4>
			<p class="callout">As explained in the <em class="italics">Convolution Layers</em> topic in <em class="italics">Chapter 7</em>, <em class="italics">Convolutional Neural Networks</em>, operations in convolution layers are basically "multiply-accumulate operations." Therefore, accelerating deep learning depends on how massive "multiply-accumulate operations" are calculated quickly and efficiently.</p>
			<h3 id="_idParaDest-208"><a id="_idTextAnchor218"/>Using GPUs for Acceleration</h3>
			<p>Originally, GPUs were exclusively used for graphics. Recently, they have been used for general numerical calculations, as well as graphics processing. Because GPUs can conduct parallel arithmetic operations quickly, GPU computing uses its overwhelming power for various purposes. </p>
			<p>Deep learning requires massive multiply-accumulate operations (or products of large matrices). GPUs are good at such massive parallel operations, while CPUs are good at continuous and complicated calculations. You can use a GPU to accelerate deep learning operations surprisingly compared to using only a CPU.  <em class="italics">Figure 8.15</em> compares the time that AlexNet took for learning between a CPU and a GPU:</p>
			<div>
				<div id="_idContainer359" class="IMG---Figure">
					<img src="image/Figure_8.15.jpg" alt="Figure 8.15: Comparing the time that AlexNet took for learning between a &quot;16-core Xeon CPU&quot; &#13;&#10;and a &quot;Titan series&quot; GPU&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.15: Comparing the time that AlexNet took for learning between a "16-core Xeon CPU" and a "Titan series" GPU</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.15</em> is cited from reference, <em class="italics">NVIDIA blog "NVIDIA Propels Deep Learning with TITAN X, New DIGITS Training System and DevBox"</em> (<a href="https://blogs.nvidia.com/blog/2015/03/17/digits-devbox/">https://blogs.nvidia.com/blog/2015/03/17/digits-devbox/</a>).</p>
			<p>As you can see, the CPU took more than 40 days, while the GPU took only 6 days. We can also see that using the cuDNN library, which is optimized for deep learning, accelerates the training further.</p>
			<p>GPUs are mainly provided by two companies, NVIDIA and AMD. Although you can use both of their GPUs for general arithmetic operations, NVIDIA's GPUs are more "familiar" with deep learning. Actually, many deep learning frameworks can benefit only from NVIDIA's GPUs. This is because CUDA, which is an integrated development environment for GPU computing provided by NVIDIA, is used in deep learning frameworks. cuDNN, which can be seen in <em class="italics">Figure 8.15</em>, is a library that runs on CUDA in which the functions optimized for deep learning are implemented.</p>
			<h4>Note</h4>
			<p class="callout">We used <strong class="inline">im2col</strong> to convert the operations in a convolution layer into the products of large matrices. Implementing this <strong class="inline">im2col</strong> method is suitable for GPUs. GPUs are good at calculating a large batch at a stretch rather than calculating small batches one by one. Using <strong class="inline">im2col</strong> to calculate the products of huge matrices makes it easy to exhibit a GPU's real power.</p>
			<h3 id="_idParaDest-209"><a id="_idTextAnchor219"/>Distributed Training</h3>
			<p>You can accelerate deep learning operations by using a GPU, but a deep network still requires several days or weeks for training. As we have seen so far, deep learning involves lots of trial and error. You must try many things to create a good network. Naturally, you want to reduce the time required for training as much as possible. Then, scaling deep learning out or "distributed training" becomes important.</p>
			<p>To further accelerate the calculations required for deep learning, you may want to distribute them among multiple GPUs or machines. Now, some deep learning frameworks support distributed training by multiple GPUs or machines. Among them, Google's TensorFlow and Microsoft's <strong class="bold">Computational Network Toolkit</strong> (<strong class="bold">CNTK</strong>) have been developed to focus on distributed training. Based on low-delay and high-throughput networks in huge data centers, distributed training by these frameworks achieves surprising results.</p>
			<p>How much can distributed training accelerate deep learning? The answer is that the larger the number of GPUs, the faster the training speed. In fact, 100 GPUs (a total of 100 GPUs installed on multiple machines) achieves a 56-fold speedup compared with one GPU. This means that training that usually takes 7 days is completed in only 3 hours, for example, and indicates the surprising effect of distributed training.</p>
			<p>"How to distribute calculations" in distributed training is a very difficult problem. It contains many problems that are not easy to solve, such as communication and data synchronization between machines. You can leave such difficult problems to excellent frameworks such as TensorFlow. Here, we will not discuss the details of distributed training. For the technical details of distributed training, please see the technical paper (white paper) about TensorFlow (<em class="italics">Mart í n Abadi et al. (2016): TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv:1603.04467[cs] (March 2016)</em>).</p>
			<h3 id="_idParaDest-210"><a id="_idTextAnchor220"/>Reducing the Bit Number for Arithmetic Precision</h3>
			<p>Memory space and bus bandwidth, as well as computational complexity, can be bottlenecks in accelerating deep learning. For memory space, a large number of weight parameters and intermediate data must be stored in memory. For bus bandwidth, a bottleneck occurs when the data that flows through the GPU (or CPU) bus increases, exceeding a limit. In these cases, you want the bit number of the data flowing in the network to be as small as possible.</p>
			<p>A computer mainly uses 64- or 32-bit floating-point numbers to represent real numbers. Using many bits to represent a number reduces the influence of the error at numerical calculation but increases the processing cost and memory usage, placing a load on the bus bandwidth.</p>
			<p>From what we know about deep learning regarding numerical precision (how many bits are used to represent a numeric value), it does not need very high precision. This is one of the most important characteristics of a neural network due to its robustness. The robustness here means that, for example, the output result will not change in a neural network, even if the input images contain a small amount of noise. Think of it as a small influence on the output result because of the robustness, even if the data flowing in a network is "deteriorated."</p>
			<p>A computer usually uses 32-bit single-precision floating-point representations or 64-bit double-precision floating-point representations to represent a decimal. Experiments have shown that 16-bit <strong class="bold">half-precision floating-point representations</strong> (half <strong class="inline">float</strong>) are sufficient in deep learning (<em class="italics">Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan (2015): Deep learning with limited numerical precision. CoRR, abs/1502.02551 392 (2015)</em>). Actually, the Pascal architecture used for NVIDIA's generation GPUs supports the operation of half-precision floating-point numbers. It is thought that the half format will be used as the standard in the future.</p>
			<h4>Note</h4>
			<p class="callout">NVIDIA's Maxwell generation of GPUs supported the storage of half-accuracy floating-point numbers (to maintain data), but it did not conduct 16-bit operations. The next-generation Pascal architecture conducts 16-bit operations as well. We can expect that only using half-accuracy floating-point numbers for calculations will accelerate processing so that it's around twice as fast as a previous-generation GPU.</p>
			<p>We haven't covered numerical precision in the preceding implementations of deep learning. Python generally uses 64-bit floating-point numbers. NumPy provides a 16-bit half-accuracy floating-point data type (however, it is used only for storage, not for operations). We can easily show that using NumPy's half-accuracy floating-point numbers do not reduce recognition accuracy. If you are interested, please see <strong class="inline">ch08/half_float_network.py</strong>.</p>
			<p>Some research has been conducted into reducing the bit number in deep learning. In recent research, a technique called a "binarized neural network" was proposed (<em class="italics">Matthieu Courbariaux and Yoshua Bengio (2016): Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1. arXiv preprint arXiv:1602.02830 (2016)</em>). It represents the weights and intermediate data by 1 bit. Reducing the number of bits to accelerate deep learning is a topic we should keep our eyes on. It is especially important when we're thinking of using deep learning for embedded devices.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor221"/>Practical Uses of Deep Learning</h2>
			<p>As an example of using deep learning, we have mainly discussed image classification, such as handwritten digit recognition, which is called "object recognition." However, we can apply deep learning to many problems other than object recognition. Deep learning demonstrates excellent performance for many problems, such as image recognition, sound (speech recognition), and natural language processing. This section will introduce what deep learning can do (its applications) in the computer vision field.</p>
			<h3 id="_idParaDest-212"><a id="_idTextAnchor222"/>Object Detection</h3>
			<p>Object detection identifies the positions of objects in images and classifies them. Object detection is more difficult than object recognition. While object recognition targets the entire image, object detection must identify the positions of classes in an image, and multiple objects may exist.</p>
			<p>Some CNN-based techniques have been proposed for object detection. They demonstrate excellent performance, which indicates that deep learning is also effective for object detection.</p>
			<p>Among CNN-based object detection techniques, a technique called R-CNN (<em class="italics">Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik (2014): Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. In 580 – 587</em>) is famous. <em class="italics">Figure 8.16</em> shows the process flow of R-CNN:</p>
			<div>
				<div id="_idContainer360" class="IMG---Figure">
					<img src="image/Figure_8.16.jpg" alt="Figure 8.16: Process flow of R-CNN&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.16: Process flow of R-CNN</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.16</em> is cited from reference, <em class="italics">Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik (2014): Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. In 580 – 587</em>.</p>
			<p>In <em class="italics">Figure 8.16</em>, note the <em class="italics">2. Extract region proposals</em> and <em class="italics">3. Compute CNN features</em> sections. The first technique detects the areas that seem to be objects (in some way) and then applies a CNN to the extracted areas to classify them. R-CNN converts an image into squares and uses <strong class="bold">support vector machines</strong> (<strong class="bold">SVMs</strong>) for classification. Its actual process flow is slightly complicated but mainly consists of the aforementioned processes: the extraction of candidate regions and to compute CNN features.</p>
			<p>In the "Extract region proposals" process of R-CNN, candidates for objects are detected, and this is where various techniques that have been developed in computer vision can be used. In the paper about R-CNN, a technique called selective search is used. Recently, a technique called "Faster R-CNN" (<em class="italics">Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun (2015): Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, &amp; R. Garnett, eds. Advances in Neural Information Processing Systems 28. Curran Associates, Inc., 91 – 99</em>) has been proposed. It even uses CNNs to extract region proposals. Faster R-CNN uses one CNN for the entire process, which enables fast processing.</p>
			<h3 id="_idParaDest-213"><a id="_idTextAnchor223"/>Segmentation</h3>
			<p>Segmentation classifies an image on a pixel basis. It learns by using training data where objects are colored on a pixel basis and classifies all the pixels of an input image during inference. The neural networks we've implemented so far classify the entire image. So, how can we classify it on a pixel basis?</p>
			<p>The simplest method of performing segmentation with a neural network is to make a prediction for each pixel. For example, you can provide a network that classifies a pixel at the center of a rectangular area to make a prediction for all the pixels. As you can see, this requires as many forward processes as the number of pixels, thus taking a lot of time to complete (the problem being that convolution operations re-calculate many areas uselessly). To reduce such useless calculations, a technique called a <strong class="bold">Fully Convolutional Network</strong><span lang="en-US" xml:lang="en-US"> </span>(<strong class="bold">FCN</strong>)<span lang="en-US" xml:lang="en-US"> </span>has been proposed (<em class="italics">Jonathan Long, Evan Shelhamer, and Trevor Darrell (2015): Fully Convolutional Networks for Semantic Segmentation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>). It classifies all the pixels in one forward process (see <em class="italics">Figure 8.20</em>).</p>
			<p>A FCN is a network that consists only of convolution layers. While an ordinary CNN contains fully connected layers, a FCN replaces fully connected layers with <em class="italics">convolution layers that play the same role</em>. In fully connected layers in a network that's used in object recognition, the space volume of the intermediate data is processed as nodes arranged in a line. On the other hand, in a network that consists only of convolution layers, the space volume can be maintained during processing until the last output.</p>
			<p>The main characteristic of a FCN is that the space size is expanded at the end. This expansion can enlarge shrunk intermediate data so that it's the same size as the input image all at once. The expansion at the end of an FCN is an expansion by bi-linear interpolation (bi-linear expansion). An FCN uses deconvolution to conduct the bi-linear expansion (for details, see the paper (<em class="italics">Jonathan Long, Evan Shelhamer, and Trevor Darrell (2015): Fully Convolutional Networks for Semantic Segmentation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em> about FCN).</p>
			<h4>Note</h4>
			<p class="callout">In a fully connected layer, the output is connected to all the inputs. You can also create a connection that's the same structure in a convolution layer. For example, a fully connected layer whose input data size is 32x10x10 (the number of channels is 32, the height is 10, and the width is 10) can be replaced with a convolution layer whose filter size is 32x10x10. If the fully connected layer has 100 output nodes, the convolution layer can achieve completely the same processing by providing 100 of the 32x10x10 filters. In this way, a fully connected layer can be replaced with a convolution layer that conducts equivalent processing.</p>
			<h3 id="_idParaDest-214"><a id="_idTextAnchor224"/>Generating Image Captions</h3>
			<p>There is some interesting research being conducted that combines natural language and computer vision. When an image is provided, the text explaining the image (the image caption) is automatically generated. </p>
			<p>For example, an image of a motorcycle from a dirt bike competition could include the caption: "A person riding a motorcycle on a dirt road" (this text is automatically generated from the image). It is surprising that the system even "understands" that it is on a dirt road and that a person is riding a motorcycle.</p>
			<p>A model called <strong class="bold">Neural Image Caption</strong> (<strong class="bold">NIC</strong>) is typically used to generate image captions for deep learning. NIC consists of a deep CNN and a <strong class="bold">Recurrent Neural Network</strong> (<strong class="bold">RNN</strong>) for handling natural language. An RNN has recursive connections and is often used for sequential data such as natural language and time-series data.</p>
			<p>NIC uses CNN to extract the features from an image and passes them to the RNN. The RNN uses the features extracted by the CNN as initial values to generate a text "recursively." We will not discuss the technical details here. Basically, NIC has a simple architecture that combines two neural networks: a CNN and an RNN. It can generate surprisingly precise image captions. Handling various types of information, such as images and natural language, is called <strong class="bold">multi-modal processing</strong>. Multi-modal processing has gained a lot of attention in recent years:</p>
			<h4>Note</h4>
			<p class="callout">The R in RNN stands for recurrent. "Recurrent" indicates a neural network's recurrent network architecture. Because of the recurrent architecture, the RNN is affected by the information generated before it – in other words, it remembers past information. This is the main characteristic of an RNN. For example, after generating the word "I," it is affected by the word and generates the next word "am." Then, it is affected by the words "I am" that were previously generated and generates the word "sleeping." For continuous data such as natural language and time-series data, the RNN behaves as if it remembered past information.</p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor225"/>The Future of Deep Learning</h2>
			<p>Deep learning is now being used in various fields, as well as in the traditional fields. This section describes the possibilities of deep learning and some research that shows the future of deep learning.</p>
			<h3 id="_idParaDest-216"><a id="_idTextAnchor226"/>Converting Image Styles</h3>
			<p>There is research being conducted that uses deep learning to "draw" a picture as an artist would. One popular use case of neural networks is to create a new image based on two provided images. One of them is called a "content image," while the other is called a "style image." A new image is created based on these two images.</p>
			<p>In one example, you can specify Van Gogh's painting style as the style that will be applied to the content image, deep learning draws a new picture, as specified. This research was published in the paper "A Neural Algorithm of Artistic Style" (<em class="italics">Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge (2015): A Neural Algorithm of Artistic Style. arXiv:1508.06576[cs, q-bio] (August 2015)</em>) and received a lot of attention all over the world as soon as it was published.</p>
			<p>Roughly speaking, in the technique, the intermediate data in the network learn so that it approaches the intermediate data of the "content image." By doing so, the input image can be converted so that it is similar in shape to the content image. To absorb a style from the "style image," the concept of a style matrix is introduced. By training so that the gap of the style matrix is small, the input image can approach Van Gogh's style.</p>
			<h3 id="_idParaDest-217"><a id="_idTextAnchor227"/>Generating Images</h3>
			<p>The preceding example of image style transfer required two images to generate a new image. On the other hand, some research has tried to generate new images without requiring any images (the technique trains by using many images beforehand but needs no images to "draw" a new image.) For example, you can use deep learning to generate the image of a "bedroom" from scratch</p>
			<p>They may seem to be real photographs, but they were newly generated by a DCGAN. The images that were generated by the DCGAN are images that nobody has ever seen (those that do not exist in the training data) and were newly created from scratch.</p>
			<p>When a DCGAN generates images that look like real ones, it creates a model of the process where the images were generated. The model learns by using many images (such as those of bedrooms). After training finishes, you can use the model to generate new images.</p>
			<p>DCGANs use deep learning. The main point of the DCGAN technique is that it uses two neural networks: a generator and a discriminator. The generator generates an image that seems real, while the discriminator determines whether it is real, that is, whether it was generated by the generator or whether it was really photographed. In this way, two networks are trained by making them compete against each other. </p>
			<p>The generator learns a more elaborate technique of creating fake images, while the discriminator grows like an appraiser who can detect fakes with higher precision. What is interesting is that in a technology called a <strong class="bold">Generative Adversarial Network</strong> (<strong class="bold">GAN</strong>), both of them grow through competition. Finally, the generator that has grown through competition can draw images that look real (or may grow even more).</p>
			<h4>Note</h4>
			<p class="callout">The machine learning problems that we have seen so far are called <strong class="bold">supervised learning</strong> problems. They use a dataset that contains image data and labels in pairs, such as in handwritten digit recognition. Meanwhile, label data is not provided in the problem here. Only images (a set of images) are provided. This is called <strong class="bold">unsupervised learning</strong>. Unsupervised learning has been studied for a relatively long time (<strong class="bold">Deep Belief Networks</strong> and <strong class="bold">Deep Boltzmann Machines</strong> are famous), but it seems that these days, it is not being researched very actively. Since techniques using deep learning, such as DCGANs, are attracting more and more attention, it is expected that unsupervised learning will be developed further in the future.</p>
			<h3 id="_idParaDest-218"><a id="_idTextAnchor228"/>Automated Driving</h3>
			<p>"Automated driving" technology, in which a computer drives a car instead of a human, is likely to be realized soon. IT companies, universities, and research institutions, as well as car manufacturers, are competing to realize automated driving. This can only happen when various technologies such as path plan technology, which determines a traffic route, and sensing technology, including cameras and lasers, are combined. It is said that the technology used to recognize the surrounding environment properly is the most important. It is very difficult to recognize an environment that changes every moment of every day, as well as the cars and people that move around freely.</p>
			<p>If the system can properly recognize the travel area robustly and reliably, even in various environments, automated driving may be realized in the near future—a task for which deep learning should prove invaluable. </p>
			<p>For example, a CNN-based network called SegNet (<em class="italics">Vijay Badrinarayanan, Kendall, and Roberto Cipolla (2015): SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. arXiv preprint arXiv:1511.00561 (2015)</em>) can recognize the road environment accurately, as shown in <em class="italics">Figure 8.17</em>:</p>
			<div>
				<div id="_idContainer361" class="IMG---Figure">
					<img src="image/fig08_17.jpg" alt="Figure 8.17: Example of segmenting an image by using deep learning – the road, cars, buildings, and sidewalks are recognized accurately&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.17: Example of segmenting an image by using deep learning – the road, cars, buildings, and sidewalks are recognized accurately</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.17</em> is cited from reference, <em class="italics">SegNet Demo page</em> (<a href="http://mi.eng.cam.ac.uk/projects/segnet/">http://mi.eng.cam.ac.uk/projects/segnet/</a>).</p>
			<p>Segmentation (pixel-level evaluation) is conducted for the input image, as shown in <em class="italics">Figure 8.17</em>. The result indicates that the road, buildings, sidewalks, trees, cars, and motorcycles are distinguished somewhat accurately. If deep learning improves the accuracy and speed of these recognition technologies from now on, automated driving may be put into practical use in the not too distant future.</p>
			<h3 id="_idParaDest-219"><a id="_idTextAnchor229"/>Deep Q-Networks (Reinforcement Learning)</h3>
			<p>There is a research field called <strong class="bold">reinforcement learning</strong> in which computers learn independently through trial and error, just as humans learn how to ride a bicycle, for example. This is different from "supervised learning," where a "supervisor" teaches face to face.</p>
			<p>The basic framework of reinforcement learning is that an agent selects actions, depending on the situation of the environment, and its actions change the environment. After taking an action, the environment offers the agent some reward. The purpose of reinforcement learning is to determine the action policy of the agent so that it can obtain a better reward, as shown here:</p>
			<div>
				<div id="_idContainer362" class="IMG---Figure">
					<img src="image/Figure_8.18.jpg" alt="Figure 8.18: Basic framework of reinforcement learning – the agent learns independently &#13;&#10;to obtain a better reward&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.18: Basic framework of reinforcement learning – the agent learns independently to obtain a better reward</h6>
			<p>The diagram in <em class="italics">Figure 8.18</em> shows the basic framework of reinforcement learning. Note that the reward is not labeled data, as it is in supervised learning. For example, in the video game "Super Mario Brothers," the exact quantity of rewards you gain by moving Mario to the right is not necessarily clear. In that case, the "prospective" reward must be determined by clear indicators such as the game scores (obtaining coins, defeating enemies, and so on) and game-over logic. In supervised learning, each action can be evaluated correctly by the "supervisor."</p>
			<p>A <strong class="bold">Deep Q-Network</strong> (<strong class="bold">DQN</strong>)<span lang="en-US" xml:lang="en-US"> </span>is a reinforcement learning technique (<em class="italics">Volodymyr Mnih et al (2015): Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529 – 533</em>) that uses deep learning. It is based on the algorithm of reinforcement learning called Q-learning. Q-learning determines a function called the optimal action-value function to determine the optimal action. A DQN uses deep learning (CNNs) to approximate the function.</p>
			<p>Some research has shown that DQNs can learn video games automatically to achieve more successful play than humans. As shown in <em class="italics">Figure 8.19</em>, a CNN, when used in a DQN, receives four consecutive frames of game images as input and outputs the "value" of the motion of the game controller (the movement of the joystick and the button operation).</p>
			<p>Traditionally, when a video game was learned by the network, the state of the game (such as the positions of the characters) was usually extracted and provided in advance. Meanwhile, the DQN receives only the images of a video game as input data, as shown in <em class="italics">Figure 8.19</em>. This is what is noteworthy in a DQN and highly improves its applicability. This is because you do not need to change the settings for each game, and you only need to provide game images to the DQN. In fact, DQNs have learned many games, such as "Pac-Man" and "Atari 2600" with the same configuration and achieved better results than humans:</p>
			<div>
				<div id="_idContainer363" class="IMG---Figure">
					<img src="image/fig08_19.jpg" alt="Figure 8.19: Using a Deep Q-Network to learn the operations of a video game. Here, the &#13;&#10;network receives the images of a video game as an input and learns the operation of the game &#13;&#10;controller (joystick) through trial and error&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 8.19: Using a Deep Q-Network to learn the operations of a video game. Here, the network receives the images of a video game as an input and learns the operation of the game controller (joystick) through trial and error</h6>
			<h4>Note</h4>
			<p class="callout"><em class="italics">Figure 8.17</em> is cited from reference, <em class="italics">Volodymyr Mnih et al. (2015): Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529 – 533</em>.</p>
			<h4>Note</h4>
			<p class="callout">The news that an AI called AlphaGo (<em class="italics">David Silver et al. (2016): Mastering the game of Go with deep neural networks and tree search. Nature 529, 7587 (2016), 484 – 489</em>) beat the Go champion attracted much attention. Deep learning and reinforcement learning are also used in AlphaGo. It learned from 30 million game records created by professionals and played against itself many times to accumulate sufficient knowledge. Both AlphaGo and DQNs have been researched by Google's DeepMind. We must keep an eye on their activities in the future.</p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor230"/>Summary</h2>
			<p>In this chapter, we implemented a deep CNN and achieved an excellent recognition result exceeding 99% for handwritten digit recognition. We also discussed the motivation for making a network deeper and the current tendency toward deeper networks. We also looked at the trends and applications of deep learning, and the research is accelerating it, which will advance this technology into the future.</p>
			<p>In the field of deep learning, there is much that is still unknown, and new research is being published all the time. Researchers and engineers around the world continue to research actively and will realize technologies that we cannot even imagine yet.</p>
			<p>The following points were covered in this chapter:</p>
			<ul>
				<li>Making a network deeper will improve performance for many deep learning problems.</li>
				<li>In image recognition competitions, techniques using deep learning get a high ranking, and current networks are deeper than their predecessors</li>
				<li>Famous networks include VGG, GoogLeNet, and ResNet.</li>
				<li>GPUs, distributed training, and the reduction of bit accuracy can accelerate deep learning.</li>
				<li>Deep learning (neural networks) can be used for object detection and segmentation, as well as for object recognition.</li>
				<li>Applications that use deep learning include the generation of image captions, the generation of images, and reinforcement learning. These days, the use of deep learning for automated driving is also expected.</li>
			</ul>
			<p>Thank you for reading this book. We hope that you've gained a better understanding of deep learning and have found it an interesting journey.</p>
		</div>
	</body></html>