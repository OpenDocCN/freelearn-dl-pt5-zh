- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Designing Deep Learning Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we went through the entire deep learning life cycle
    and understood what it means to make a deep learning project successful from end
    to end. With that knowledge, we are now ready to dive further into the technicalities
    of deep learning models. In this chapter, we will dive into common deep learning
    architectures used in the industry and understand the reasons behind each architecture’s
    design. For intermediate and advanced readers, this will be a brief recap to ensure
    alignment in the definitions of terms. For beginner readers, architectures will
    be presented in a way that is easy to digest so that you can get up to speed on
    the useful neural architectures in the world of deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Grasping the methodologies behind a wide variety of architectures allows you
    to innovate custom architectures specific to your use case and, most importantly,
    gain the skill to choose an appropriate foundational architecture based on the
    data input or problem type.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, the focus will be on the **Multilayer Perceptron** (**MLP**)
    network architecture. The comprehensive coverage of MLPs, along with some key
    concepts in general related to neural network implementations, such as gradients,
    activation functions, and regularization methods, will set the stage for exploring
    other, more complex architecture types in later chapters. Specifically, the following
    topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the foundations of neural networks using an MLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding neural network gradients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an MLP from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an MLP using deep learning frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing an MLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter includes some practical implementations in the **Python** programming
    language. To complete it, you will need to have a computer with the following
    libraries installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Matplotlib`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Seaborn`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Scikit-learn`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NumPy`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Keras`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PyTorch`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code files are available on GitHub: [https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_2](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_2).'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the foundations of neural networks using an MLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A deep learning architecture is created when at least three perceptron layers
    are used, excluding the input layer. A perceptron is a single-layer network consisting
    of neuron units. Neuron units hold a bias variable and act as nodes for vertices
    to be connected. These neurons will interact with other neurons in a separate
    layer with weights applied to the connections/vertices between neurons. A perceptron
    is also known as a **fully connected layer** or **dense layer**, and MLPs are
    also known as **feedforward neural networks** or **fully connected** **neural
    networks**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s refer back to the MLP figure from the previous chapter to get a better
    idea.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 2.1 – Simple deep learning architecture, also called \uFEFFan MLP](img/B18187_02_001.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Simple deep learning architecture, also called an MLP
  prefs: []
  type: TYPE_NORMAL
- en: The figure shows how three data column inputs get passed into the input layer,
    then subsequently get propagated to the hidden layer, and finally, through the
    output layer. Although not depicted in the figure, an additional activation function
    is applied at the hidden and output layer outputs. The activation function at
    the hidden layers adds non-linearity to the model and allows the neural network
    to capture non-linear relationships between the input data and output data. The
    activation function used at the output layer depends on the problem type and will
    be discussed in more detail in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125),
    *Exploring Supervised* *Deep Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Before we dive into the relevant hidden activation methods, we need to first
    be aware of the vanishing gradient problem. The vanishing gradient problem is
    a challenge that arises when gradients of the loss function with respect to the
    model’s parameters become very small during backpropagation. This can lead to
    slow learning and poor convergence, as the weights update minimally or not at
    all. The vanishing gradient problem is particularly prominent when using activation
    functions that squash input values into a narrow range. To address this issue,
    the **Rectified Linear Unit** (**ReLU**) activation function has been widely adopted
    due to its ability to mitigate the vanishing gradient problem to a certain extent.
    ReLU maps negative values into zeros and maintains positive values, as depicted
    in *Figure 2**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 2.2 – ReLU, Leaky ReLU, and PReLU inpu\uFEFFt/output graph plot](img/B18187_02_002.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 – ReLU, Leaky ReLU, and PReLU input/output graph plot
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from ReLU, there are other useful hidden layer activation functions that
    can help alleviate the vanishing gradient problem while offering various benefits.
    Some of these include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Leaky ReLU**: Leaky ReLU is a variation of the ReLU function that allows
    a small, non-zero gradient for negative input values. This helps mitigate the
    “dying ReLU” problem, where neurons become inactive and stop learning if their
    input values are consistently negative. Leaky ReLU introduces a small slope for
    negative inputs, ensuring that gradients do not vanish entirely.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parametric ReLU** (**PReLU**): PReLU is another variation of the ReLU function,
    where the negative slope is learned during the training process, allowing the
    model to adapt its behavior. This flexibility can lead to better performance but
    at the cost of increased complexity and the risk of overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, we will be exploring more hidden activation functions as we dive
    into different prominent architectures in this book. Each of these activation
    functions has its strengths and weaknesses, and the choice of activation function
    depends on the specific problem being addressed and the architecture being employed.
    Understanding, experimenting with, and assessing these activation functions is
    crucial for selecting the most suitable one for a given task within a neural network’s
    hidden layers. Furthermore, the recommended method to assess any model-building-related
    experiments will be explored in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125),
    *Exploring Supervised* *Deep Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving on, the process of propagating values from one layer to another is called
    a forward pass or forward propagation, where the formula can be generally defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: a = g( ∑ n=0 neuronswx + b)
  prefs: []
  type: TYPE_NORMAL
- en: Here, a represents the outputs of the neural network layer (called an **activation**),
    g represents the non-linear activation function, w represents the weights between
    neuron connections, x represents the input data or activation, and b represents
    the bias of the neuron. Different types of neural network layers consume and output
    data in different ways but generally still use this formula as a foundation.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding neural network gradients
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of machine learning for an MLP is to find the weights and biases that
    will effectively map the inputs to the desired outputs. The weights and biases
    generally get initialized randomly. In the training process, with a provided dataset,
    they get updated iteratively and objectively in batches to minimize the loss function,
    which uses gradients computed with a method called **backward propagation**, also
    known as **backpropagation**. A batch is a subset of the dataset used for training
    or evaluation, allowing the neural network to process the data in smaller groups
    rather than the entire dataset at once. The loss function is also known as the
    error function or the cost function.
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation is a technique to find out how sensitive a change of weights
    and bias of every neuron is to the overall loss by using the partial derivative
    of the loss with respect to the weights and biases. Partial derivatives from calculus
    are a measure of the rate of change of a function with respect to a variable,
    which uses a technique called **differentiation**, and is effectively applied
    in neural networks. A convenient method called the **chain rule** allows you to
    obtain the derivative of neural networks by calculating the partial derivatives
    of each function, a forward pass in the case of neural networks, separately. To
    be clear, derivatives can be called the sensitivity of change, the gradients,
    and the rate of change. The idea is that when we know which model parameter affects
    the error the most, we can update its weights proportionally according to its
    magnitude and direction. Let’s take a simple case of a two-layer MLP with one
    neuron in each layer as an example to get an idea of this, as depicted in *Figure
    2**.3*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – A diagram of a two-layer MLP](img/B18187_02_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – A diagram of a two-layer MLP
  prefs: []
  type: TYPE_NORMAL
- en: 'For clarity, **w** indicates the weight of neuron connections, **b** indicates
    the bias of the neurons, and **L** indicates layers. Different problem types require
    a different loss function, but for explanation purposes, let’s assume this is
    an MLP for a regression problem, where we will use the mean squared error as a
    loss function to compute the loss component from the final layer activation and
    the numerical target value. The loss function can then be defined as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: L =  1 _ n  ∑ i=1 n (a2 − y) 2
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, n is the total size of neurons. To obtain the rate of change of the loss
    function with respect to the output layer weight **w2**, which is  δL _ δw2, let’s
    define the formula based on the chain rule. Consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: z2 = w2 ∙ a1 + b2
  prefs: []
  type: TYPE_NORMAL
- en: 'So, if a2 = g(z2), where g is a ReLU function, the gradients with respect to
    the output layer weight w2 will be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δw2  =  δL _ δa2  ∙  δa2 _ δz2  ∙  δz2 _ dw2
  prefs: []
  type: TYPE_NORMAL
- en: 'The rate of change of the loss function with respect to w2 can be computed
    by multiplying the three independent change components: namely, the change of
    the loss function with respect to the second-layer outputs, the change of the
    activation outputs with respect to a wrapped z2 that is a forward pass without
    the activation, and the change of the wrapped z2 with respect to w2\. Let’s define
    these components next. Now consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: e = a2 − y
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the chain rule, the first change component will be defined as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δa2  =  δL _ δe  ⋅  δe _ δa2
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δe  = 2e
  prefs: []
  type: TYPE_NORMAL
- en: δe _ δa2  = 1
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting this in the simplified component representation will result in the
    following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δa2  =  2 _ n (a2 − y)
  prefs: []
  type: TYPE_NORMAL
- en: 'For the second change component, it can be defined with the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: δa2 _ δz2  = g ′ (z2) = 1
  prefs: []
  type: TYPE_NORMAL
- en: There is no activation function applied at the output layer in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the third and last change component, it can be defined with the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: δz2 _ δw2  = a1
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, placing the simplified representation of the three components into
    the formula to obtain the gradients of the output layer weights w2 will result
    in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δw2 =  2 _ n(a2 − y) ∙ a1
  prefs: []
  type: TYPE_NORMAL
- en: 'All you need to do now is to plug in the actual values to obtain the layer
    2 weight gradients. The same formula structure can be adapted similarly to the
    hidden layer’s weight w1 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: a1 = g(z1)
  prefs: []
  type: TYPE_NORMAL
- en: z1 = w1 ∙ a0 + b1
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δw1  =  δL _ δa1  ∙  δa1 _ δz1  ∙  δz1 _ δw1
  prefs: []
  type: TYPE_NORMAL
- en: 'After expanding  δL _ δa1 using the chain rule, the formula can then be the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δw1  =  δL _ δa2  ∙  δa2 _ δz2  ∙  δz2 _ δa1  ∙  δa1 _ δz1  ∙  δz1 _ δw1
  prefs: []
  type: TYPE_NORMAL
- en: 'The additional individual components can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: δz2 _ δa1  = w2
  prefs: []
  type: TYPE_NORMAL
- en: δa1 _ δz1  = g ′ (z1) = 0 if a2 < 0, 1 if a2 > 0
  prefs: []
  type: TYPE_NORMAL
- en: δz1 _ δw1  = a0
  prefs: []
  type: TYPE_NORMAL
- en: 'a0 here is the input data. Now, let’s define the gradient of the hidden layer
    weights w1 with the representation where we can plug in actual values to compute
    it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δw1  =  2 _ n (a2 − y) ∙ w2 ∙ g ′ (z1) ∙ a0
  prefs: []
  type: TYPE_NORMAL
- en: 'The same process can be repeated for the bias term to obtain its gradients.
    Only the partial derivative of z with respect to the weights needs to be replaced
    with a partial derivative of z with respect to the biases, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: δz2 _ δb2  =  δz1 _ δb1  = 1
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δb2  =  δL _ δa2  ∙  δa2 _ δz2  ∙  δz2 _ δb2
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δb2  = 2(a2 − y)
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δb1  =  δL _ δa2  ∙  δa2 _ δz2  ∙  δz2 _ δa1  ∙  δa1 _ δz1  ∙  δz1 _ δb1
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s define the gradient of the first bias term with the representation
    where we can plug in actual values to compute it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: δL _ δb1  =  2 _ n  ∙ w2 ∙ (a2 − y) ∙ g ′ (z1)
  prefs: []
  type: TYPE_NORMAL
- en: The previously defined formulae were meant to be specific to the example neural
    network for layers with one neuron. In practical usage, these layers usually contain
    more than one neuron in each of the layers. To compute the loss and derivatives
    for layers with more than one neuron, and for more than one data sample, you simply
    need to obtain an average of all the values.
  prefs: []
  type: TYPE_NORMAL
- en: Once the gradients or derivatives are obtained, different strategies can be
    used to update the weights. The algorithm used to optimize the weights and biases
    of the neural network is called the optimizer. There are many optimizer options
    today and each has its own pros and cons. As gradients are used to optimize weights
    and biases, this process of optimization is called **gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good way to think about loss for a deep learning model is that it exists in
    a three-dimensional loss landscape that has many different hills and valleys,
    with valleys being more optimal, as shown in *Figure 2**.4*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – An example loss landscape](img/B18187_02_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 – An example loss landscape
  prefs: []
  type: TYPE_NORMAL
- en: 'In reality, however, we can only approximate these loss landscapes as the parameter
    values of the neural networks can exist in an infinite number of ways. The most
    common way practitioners use to monitor the behavior of loss during each epoch
    of training and validation is to simply plot a two-dimensional line graph with
    the *x* axis being the epochs executed and the *y* axis being the loss performance.
    An epoch is a single iteration through the entire dataset during the training
    process of a neural network. The loss landscape in *Figure 2**.4* is an approximation
    of the loss landscape in three dimensions of a neural network. To visualize the
    three-dimensional loss landscape in *Figure 2**.4*, we can use two randomly initialized
    parameters and one fully trained parameter from the same neuron positions within
    the neural network. The loss can be calculated by performing a weighted summation
    of these three parameters. The weight of the fully trained parameter remains constant,
    while the weights of the two randomly initialized parameters are adjusted. This
    process allows us to approximate the 3D loss landscape shown in *Figure 2**.4*.
    In this figure, *x* axis and *y* axis are the weights of the two randomly initialized
    parameters of the same neural network and the *z* axis is the loss value. The
    goal of gradient descent is to attempt to find the *global* deepest valleys and
    not be stuck in *local* valleys or *local* minima. The gradients computed provide
    the suggested directions needed to nudge and update the weights and biases iteratively.
    One thing to note is that gradients provide the direction to increase the loss
    function in the fastest way, so for the descent, the parameters are subtracted
    from the gradients. Let’s go through a simple form of gradient descent that controls
    how the weights and biases should be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: w = w − α ∙  δL _ δw
  prefs: []
  type: TYPE_NORMAL
- en: b = b − α ∙  δL _ δb
  prefs: []
  type: TYPE_NORMAL
- en: Here, α refers to the learning rate, which controls how aggressive you want
    the deep learning model to be. A learning rate is a hyperparameter that controls
    the speed at which a neural network learns and updates its weights and biases
    during the optimization process. The higher the learning rate, the bigger the
    steps taken by the deep learning model in the loss landscape. By iteratively applying
    this parameter update step, the neural network will slowly move downhill so that
    the learned set of parameters can allow the network to effectively map the input
    to the desired target values. The gradients are obtained for all the data samples
    and averaged together to obtain a single update direction for the weight and biases
    update.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets can sometimes be too big and cause a slow learning process from basic
    gradient descent due to the need to compute the gradients from every sample before
    an update can be done to the neural network parameters. **Stochastic gradient
    descent** (**SGD**) was created to tackle this problem. The idea is simply to
    learn from the dataset in batches and iteratively learn the entire dataset with
    a different data batch partition instead of waiting for the gradients to be obtained
    from the entire dataset before updating the parameters of the network. This way,
    the learning process can be efficient even for a big-sized dataset with the added
    benefit of seeing initial results quickly.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a lot more variations of gradient descent that offer different advantages
    and are suited for specific situations. Here, we will list gradient descent algorithms
    that, on average across a variety of datasets, work well and are relevant:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Momentum**: A variation of SGD, Momentum incorporates a “momentum” term that
    helps the optimizer navigate through the loss landscape more effectively. This
    momentum term is a moving average of the gradients, which helps the optimizer
    overcome local minima and converge faster. The momentum term also adds some inertia
    to the optimizer, causing it to take bigger steps in directions that have consistent
    gradients, which can speed up convergence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Root Mean Square Propagation** (**RMSProp**): RMSProp is an adaptive learning
    rate optimization algorithm that adjusts the learning rate for each parameter
    individually. By dividing the learning rate by an exponentially decaying average
    of squared gradients, RMSProp helps to prevent the oscillations observed in the
    convergence of SGD. This results in a more stable and faster convergence toward
    the optimal solution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptive Moment Estimation** (**Adam**): Adam is another popular optimization
    algorithm that combines the advantages of both Momentum and RMSProp. It maintains
    separate adaptive learning rates for each parameter, as well as incorporating
    a momentum term. This combination allows Adam to converge quickly and find more
    accurate solutions, making it a popular choice for many deep learning tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While there are many gradient descent algorithms available, choosing the right
    one depends on the specific problem and dataset at hand. In general, Adam is often
    recommended as a good starting point due to its adaptive nature and combination
    of Momentum and RMSProp features. To determine the best fit for your specific
    deep learning task, it is essential to experiment with different algorithms and
    their hyperparameters and validate their performance. Next, we will code up an
    MLP using Python.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing an MLP from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Today, the process to create a neural network and its layers along with the
    backpropagation process has been encapsulated in deep learning frameworks. The
    differentiation process has been automated, where there is no actual need to define
    the derivative formulas manually. Removing the abstraction layer provided by the
    deep learning libraries will help to solidify your understanding of neural network
    internals. So, let’s create this neural network manually and explicitly with the
    logic to forward pass and backward pass instead of using the deep learning libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by importing `numpy` and the methods from the scikit-learn library
    to load sample datasets and perform data partitioning:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we define ReLU, the method that makes an MLP non-linear:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s define partially the class needed to initialize an MLP model with
    a single hidden layer and an output layer that can perform a forward pass. The
    layers are represented by weights, where `w1` is the weight of the hidden layer,
    and `w2` is the weight of the output layer. Additionally, `b1` is the bias for
    the connection between the input layer and the hidden layer and `b2` is the bias
    for the connection between the hidden layer and the output layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To allow the MLP to learn, we will now implement the backward pass method to
    generate the average gradients for the biases and weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that the derivative of the ReLU function is f′(x) = 1 if x > 0 and f′(x)
    = 0 if x <= 0.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For the last class method, we will implement the gradient descent step utilizing
    the average gradients from the backward pass, which is the process that allows
    the bias and weights to be updated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have made a proper class for the MLP manually, let’s set up a dataset
    and attempt to learn from it. The structure of MLP only allows for tabular structured
    dataset types that are both one-dimensional and numerical, so we will be using
    a dataset called `diabetes`, which contains 10 numerical features, that is, age,
    sex, body mass index, average blood pressure, and 6 blood serum measurements,
    as inputs along with a quantitative measure of diabetes disease progression as
    the target data. The data is conveniently saved in the scikit-learn library, so
    let’s first load the input DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will convert the DataFrame into NumPy array values so that it is ready
    to be used by a neural network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final step for loading the data is to load the target data from the diabetes
    data and make sure it has an additional outer dimension as the PyTorch model outputs
    its predictions in this way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s partition the dataset into 80% for training and 20% for validation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that the data is prepared with training and evaluation partitions, let’s
    initialize an MLP model from our defined class with a single 20-neuron hidden
    layer and a 1-neuron output layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the data and model ready, it is time to train the model we built from
    scratch. Since the dataset is small enough, with 442 samples, there isn’t a runtime
    issue using gradient descent, so we will be using the full gradient descent here
    for 100 epochs. One epoch means a full round of training going through the entire
    training dataset once:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s plot the collected mean squared error for both the validation and training
    partitions using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will produce the following plot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Training and validation partition mean squared error versus
    epochs plots](img/B18187_02_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 – Training and validation partition mean squared error versus epochs
    plots
  prefs: []
  type: TYPE_NORMAL
- en: With that, you’ve implemented an MLP and trained it from scratch without depending
    on deep learning frameworks! But is our implementation correct and sound? Let’s
    verify this in the next topic.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing MLP using deep learning frameworks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning frameworks are made to ease and expedite the development of deep
    learning models. They provide a plethora of commonly used neural network layers,
    optimizers, and tools generally used to build neural network models, along with
    very easily extensible interfaces to implement new methods. Backpropagation itself
    is abstracted away from the users of the frameworks as the gradients are computed
    automatically in the background when needed. Most importantly, they allow the
    usage of the GPU for efficient model training and prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will build the same MLP model as in the previous section,
    using a deep learning framework called PyTorch, and verify that both implementations
    produce the same results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by importing the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s define the MLP class with the two fully connected layers along
    with the forward propagation method with arguments that allow us to set the input
    layer size, hidden layer size, and output layer size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will notice that there isn’t a backward propagation function implemented,
    which reduces the amount of effort needed to define a neural network model. When
    you inherit from the `Pytorch` module class, the backward propagation functionality
    will already be provided out of the box with your defined `Pytorch` layers. Finally,
    let’s initialize the MLP using a hidden layer size of 10 along with input and
    output sizes according to the diabetes dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s check the forward and backward propagation functionality with our
    `numpy` variant. First, let’s initialize the `Pytorch` MLP and copy the weights
    from the `numpy`-based MLP model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s prepare the dataset into Tensor objects suitable for PyTorch model
    consumption:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To obtain the same gradients, we have to use the same MSE loss and apply backward
    propagation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s verify the gradients for the two implementations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This solidifies your foundational neural network knowledge, along with knowledge
    of the MLP architecture, and prepares you for more advanced concepts in the realm
    of deep learning. Before we move on to look at a more advanced neural network,
    in the next section, we will explore the topic of regularization, and then finally,
    explore how to design an MLP with a practical use case.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Regularization** in deep learning has evolved into a state where it now means
    any addition or modification to the neural network, data, or training process
    that is used to increase the generalization of the build model to external data.
    All performant neural networks today have some form of regularization embedded
    into the architecture. Some of these regularization methods introduce some extra
    beneficial side effects, such as the speedup of training or the performance on
    the training dataset. But ultimately, the regularizer’s main goal is to improve
    generalization, which in other words is to improve performance metrics and reduce
    errors on external data. As a quick recap, the following list shows a summary
    of some of the more common regularization methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dropout layer**: During training, randomly remove information from all neural
    nodes according to a specified probability level by replacing neural node outputs
    with zeros, effectively nullifying information. This reduces over-reliance on
    any single node/information and increases the probability of generalization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L1/L2 regularization**: These methods add a penalty term to the loss function,
    which discourages the model from assigning high weights to the features. L1 regularization,
    also known as Lasso, uses the absolute value of the weights, while L2 regularization,
    also known as Ridge, uses the squared value of the weights. By controlling the
    magnitude of the weights, these methods help to prevent overfitting and improve
    generalization. Typically, this is applied to the input features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Batch normalization layer**: This method is standardizing the data in both
    training and inferencing on the external data stage by scaling the data to have
    a mean of zero and a standard deviation of one. This is done by removing the computed
    mean and dividing it by the computed standard deviation. The mean and standard
    deviation are computed and iteratively updated by mini-batch (based on the models
    determining the training batch size) during training. During inference, the final
    learned running mean and standard deviation calculated during training are applied.
    This has the side effect of improving the training time, training stability, and
    generalization. Note that each element has its own mean and standard deviation.
    Research has shown that batch normalization smooths out the loss landscape, making
    it way easier to reach an optimum value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Group normalization layer**: Instead of having an individual mean and standard
    deviation for each element across the batch size, group normalization standardizes
    the data by groups per sample, where each group has one mean and one standard
    deviation. The number of groups can be configured. Batch normalization degrades
    the performance when the number of samples in a batch is small due to hardware
    limitations. This layer is used over batch normalization when the amount of data
    per batch is a very small number as the mean and standardization updates do not
    depend on the batch. In large batches, however, batch normalization still triumphs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weight standardization**: This applies the same standardization process to
    the weights of the neural networks. The weights of the neural network might grow
    to very large numbers after training, which would create large output values.
    The idea is that if we use the batch normalization layer, the output values will
    be standardized anyway, so why don’t we take a step back and apply the same process
    to the weights themselves, making sure the values are standardized in some form
    before becoming an output value? Some simple benchmarks have demonstrated that
    it works well when combined with a group normalization layer in low batch sizes,
    achieving a better performance than batch normalization with a high batch size
    setting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stochastic depth**: Instead of conceptually making a neural network with
    narrower layers during the training stage with dropout, stochastic depth reduces
    the depth of the network during training. This regularizing method leverages the
    concept of skip connections from ResNets, which will be introduced later, where
    outputs from earlier layers are additionally forwarded to the later layers. During
    training, the layers in between the skip connections are completely bypassed to
    simulate a shallower network randomly. This regularizer has the effect of a faster
    training time along with an increased generalization performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[0, 0, 0, 1]` and `[0.0001, 0.0001, 0.0001, 0.9999]`, respectively. The idea
    is that we shouldn’t train the model to be overconfident in its result, which
    will signal that it is overfitted to the training data and won’t be able to generalize
    to external data. This method encourages representations of the last layer outputs
    to be closer to each other for samples in the same class and encourages the same
    outputs to be equally distant among samples from different classes. Additionally,
    this helps to mitigate overconfidence in samples that have inaccurate labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data augmentation**: When the raw data does not adequately represent all
    the variations of the data of any label, data augmentation helps to computationally
    add variations in the data to be used for training. This effectively increases
    generalization simply due to the model being able to learn from more complete
    variations of the data. This can be applied to any data modality and will be introduced
    in more detail in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125), *Exploring*
    *Supervised Learning*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularization is an important component in any neural network architecture
    and will be seen in all of the architectures that will be introduced in the chapter.
    When choosing regularization techniques for a specific problem, you should first
    consider the nature of your dataset and the problem you are trying to solve. For
    instance, if you have a small batch size, group normalization or weight standardization
    might be more suitable than batch normalization. If your dataset has limited variations,
    data augmentation can be used to improve generalization. To choose between these
    techniques, start with a simple regularization method such as dropout or L1/L2
    regularization, and evaluate its performance. Then, you can experiment with other
    techniques, either individually or in combination, and compare their impact on
    the model’s performance. It’s essential to monitor the training and validation
    metrics to ensure that the chosen regularization methods are not causing overfitting
    or underfitting. Ultimately, the choice of regularization technique depends on
    a combination of experimentation and validation, domain knowledge, and understanding
    of the specific problem and dataset at hand.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s dive into the design of an MLP.
  prefs: []
  type: TYPE_NORMAL
- en: Designing an MLP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tabular data is not where neural networks shine most, and more often than not,
    boosted decision trees outperform MLPs in terms of metric performance. However,
    sometimes, in some datasets, neural networks can outperform boosted trees. Make
    sure to benchmark MLPs with other non-neural network models when dealing with
    tabular data.
  prefs: []
  type: TYPE_NORMAL
- en: MLPs are the simplest form of neural networks and can be modified at a high
    level in two dimensions similar to all neural networks, which are the width of
    the network and the depth of the network. A common strategy when building standard
    MLP architectures from scratch is to start small with a shallow depth and narrow
    width and gradually increase both dimensions once a small baseline is obtained.
    Usually, for MLPs on tabular data, the performance benefits of increasing the
    depth of the neural network stagnate at around the fourth layer. ReLU is a standard
    activation layer that is proven to allow stable gradients and optimal learning
    of any task. However, if you have time to achieve practical value, consider replacing
    the activation layer with more advanced activation layers. At this point, the
    space of activation layer research is just too nuanced and results are mostly
    not standardized, with mixed responses on different datasets, so there is no guarantee
    of better performance when you use any advanced activation layers.
  prefs: []
  type: TYPE_NORMAL
- en: One adaptation of MLPs is to use a type of neural network called **denoising
    autoencoders** to generate denoised features that can be used as input to MLPs.
    This advancement will be described in more detail later in [*Chapter 5*](B18187_05.xhtml#_idTextAnchor085),
    *Understanding Autoencoders*. Training methods go hand in hand with the architecture
    when trying to achieve good performance. The methods are mostly generic and don’t
    depend on any architecture specifically, so they will be covered in [*Chapter
    8*](B18187_08.xhtml#_idTextAnchor125), *Exploring Supervised Deep Learning*, and
    [*Chapter 9*](B18187_09.xhtml#_idTextAnchor149), *Exploring Unsupervised Deep*
    *Learning*, separately.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s summarize what we’ve learned from this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLPs are the foundational piece of architecture in deep learning that transcends
    just processing tabular data and is more than an old architecture that got superseded.
    MLPs are very commonly utilized as a sub-component in many advanced neural network
    architectures today to either provide more automatic feature engineering, reduce
    the dimensionality of large features, or shape the features into the desired shapes
    for target predictions. Look out for MLPs or, more importantly, the fully connected
    layer, in the next few architectures that are going to be introduced in the next
    few chapters!
  prefs: []
  type: TYPE_NORMAL
- en: The automatic gradient computation provided by deep learning frameworks simplifies
    the implementation of backpropagation and allows us to focus on designing new
    neural networks. It is essential to ensure that the mathematical functions used
    in these networks are differentiable, although this is often taken care of when
    adopting successful research findings. And that’s the beauty of open source research
    coupled with powerful deep learning frameworks!
  prefs: []
  type: TYPE_NORMAL
- en: Regularization is a crucial aspect of neural network design, and while we have
    discussed it in detail in this chapter, upcoming chapters will showcase its application
    in different architectures without delving into further explanations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive into a different kind of neural network, called
    the convolutional neural network, which is particularly suited for image-related
    tasks and has a wide range of applications.
  prefs: []
  type: TYPE_NORMAL
