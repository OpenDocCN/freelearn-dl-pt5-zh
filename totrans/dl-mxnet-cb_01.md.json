["```py\n    import platform\n    platform.python_version()\n    3.7.10\n    ```", "```py\n    !jupyter --version\n    ```", "```py\n    jupyter core : 4.5.0\n    jupyter-notebook : 5.2.2\n    qtconsole : 4.5.2\n    ipython : 5.5.0\n    ipykernel : 4.10.1\n    jupyter client : 5.3.1\n    jupyter lab : not installed\n    nbconvert : 5.5.0\n    ipywidgets : 7.5.0\n    nbformat : 4.4.0\n    traitlets : 4.3.2\n    ```", "```py\n    !lscpu | grep 'Model name'\n    Model name: Intel(R) Xeon(R) CPU @ 2.20GHz\n    ```", "```py\n    !nvidia-smi\n    ```", "```py\n    +-----------------------------------------------------------------+\n    | NVIDIA-SMI 460.67 Driver Version: 460.32.03 CUDA Version: 11.2  |\n    |---------------------------+--------------+----------------------+\n    |GPU Name      Persistence-M|Bus-Id  Disp.A| Volatile Uncorr. ECC |\n    |Fan Temp Perf Pwr:Usage/Cap|  Memory-Usage|  GPU-Util Compute M. |\n    |                           |              |               MIG M. | |===========================+==============+======================|\n    |   0 Tesla T4          Off |0:00:04.0 Off |                    0 |\n    | N/A  37C  P8     9W / 70W |0MiB/15109MiB |      0%      Default |\n                    |              |                  N/A |\n    +---------------------------+--------------+----------------------+\n    +-----------------------------------------------------------------+\n    | Processes:                                                      |\n    |  GPU    GI  CI      PID  Type  Process  name         GPU Memory |\n          ID  ID                                       Usage      | |=================================================================|\n    | No running processes found                                      |\n    +-----------------------------------------------------------------+\n    ```", "```py\n    !nvcc --version\n    ```", "```py\n    nvcc: NVIDIA (R) Cuda compiler driver\n    Copyright (c) 2005-2020 NVIDIA Corporation\n    Built on Wed_Jul_22_19:09:09_PDT_2020\n    Cuda compilation tools, release 11.0, V11.0.221\n    Build cuda_11.0_bu.TC445_37.28845127_0\n    ```", "```py\n        !python3 -m pip install mxnet-cu117\n        ```", "```py\n        !python3 -m pip install mxnet\n        ```", "```py\n        !python3 -m pip install mxnet-mkl\n        ```", "```py\n        !python3 -m pip install mxnet-cu102\n        ```", "```py\n        !python3 -m pip install mxnet-cu110\n        ```", "```py\n    import mxnet\n    mxnet.__version__\n    ```", "```py\n    features = mxnet.runtime.Features()\n    print(features)\n     print(features.is_enabled('CUDA'))\n     print(features.is_enabled('CUDNN'))\n     print(features.is_enabled('MKLDNN'))\n    ```", "```py\n    !python3 -m pip install gluoncv gluonnlp\n    ```", "```py\nimport numpy as np\nimport mxnet as mx\n```", "```py\n    import time\n    x_mx_cpu = mx.np.random.rand(1000, 1000, ctx = mx.cpu())\n    start_time = time.time()\n    mx.np.dot(x_mx_cpu, x_mx_cpu).wait_to_read()\n    print(\"Time of the operation: \", time.time() - start_time)\n    ```", "```py\n    Time of the operation: 0.04673886299133301\n    ```", "```py\n    x_mx_cpu = mx.np.random.rand(1000, 1000, ctx = mx.cpu())\n    start_time = time.time()\n    x_2 = mx.np.dot(x_mx_cpu, x_mx_cpu)\n     print(\"(FAKE, MXNet has lazy evaluation)\")\n     print(\"Time of the operation : \", time.time() - start_time)\n     start_time = time.time()\n    print(x_2)\n     print(\"(FAKE, MXNet has lazy evaluation)\")\n     print(\"Time to display: \", time.time() - start_time)\n    ```", "```py\n    (FAKE, MXNet has lazy evaluation)\n     Time of the operation : 0.00118255615234375\n     [[256.59583 249.70404 249.48639 ... 251.97151 255.06744 255.60669]\n     [255.22629 251.69475 245.7591 ... 252.78784 253.18878 247.78052]\n     [257.54187 254.29262 251.76346 ... 261.0468 268.49127 258.2312 ]\n     ...\n     [256.9957 253.9823 249.59073 ... 256.7088 261.14255 253.37457]\n     [255.94278 248.73282 248.16641 ... 254.39209 252.4108 249.02774]\n     [253.3464 254.55524 250.00716 ... 253.15712 258.53894 255.18658]]\n     (FAKE, MXNet has lazy evaluation)\n     Time to display: 0.042133331298828125\n    ```", "```py\ntimings_np = {}\ntimings_mx_np_cpu = {}\ntimings_mx_np_gpu = {}\ntimings_mx_nd_cpu = {}\ntimings_mx_nd_gpu = {}\n```", "```py\nmatrix_orders = [1, 5, 10, 50, 100, 500, 1000, 5000, 10000]\n```", "```py\ndef create_matrix_np(n):\n    \"\"\"\n    Given n, creates a squared n x n matrix,\n    with each matrix value taken from a random\n    uniform distribution between [0, 1].\n    Returns the created matrix a.\n    Uses NumPy.\n    \"\"\"\n    a = np.random.rand(n, n)\n    return a\ndef create_matrix_mx(n, ctx=mx.cpu()):\n    \"\"\"\n    Given n, creates a squared n x n matrix,\n    with each matrix value taken from a random\n    uniform distribution between [0, 1].\n    Returns the created matrix a.\n    Uses MXNet NumPy syntax and context ctx\n    \"\"\"\n    a = mx.np.random.rand(n, n, ctx=ctx)\n    a.wait_to_read()\n    return a\ndef create_matrix_mx_nd(n, ctx=mx.cpu()):\n    \"\"\"\n    Given n, creates a squared n x n matrix,\n    with each matrix value taken from a random\n    uniform distribution between [0, 1].\n    Returns the created matrix a.\n    Uses MXNet ND native syntax and context ctx\n    \"\"\"\n    a = mx.nd.random.uniform(shape=(n, n), ctx=ctx)\n    a.wait_to_read()\n    return a\n```", "```py\ntimings_np[\"create\"] = []\nfor n in matrix_orders:\n    result = %timeit -o create_matrix_np(n)\n    timings_np[\"create\"].append(result.best)\ntimings_mx_np_cpu[\"create\"] = []\nfor n in matrix_orders:\n    result = %timeit -o create_matrix_mx_np(n)\n    timings_mx_np_cpu[\"create\"].append(result.best)\ntimings_mx_np_gpu[\"create\"] = []\nctx = mx.gpu()\nfor n in matrix_orders:\n    result = %timeit -o create_matrix_mx_np(n, ctx)\n    timings_mx_np_gpu[\"create\"].append(result.best)\ntimings_mx_nd_cpu[\"create\"] = []\nfor n in matrix_orders:\n    result = %timeit -o create_matrix_mx_nd(n)\n    timings_mx_nd_cpu[\"create\"].append(result.best)\ntimings_mx_nd_gpu[\"create\"] = []\nctx = mx.gpu()\nfor n in matrix_orders:\n    result = %timeit -o create_matrix_mx_nd(n, ctx)\n    timings_mx_nd_gpu[\"create\"].append(result.best)\n```", "```py\ndef multiply_matrix_np(a, b):\n    \"\"\"\n    Multiplies 2 squared matrixes a and b\n    and returns the result c.\n    Uses NumPy.\n    \"\"\"\n    #c = np.matmul(a, b)\n    c = np.dot(a, b)\n    return c\ndef multiply_matrix_mx_np(a, b):\n    \"\"\"\n    Multiplies 2 squared matrixes a and b\n    and returns the result c.\n    Uses MXNet NumPy syntax.\n    \"\"\"\n    c = mx.np.dot(a, b)\n    c.wait_to_read()\n    return c\ndef multiply_matrix_mx_nd(a, b):\n    \"\"\"\n    Multiplies 2 squared matrixes a and b\n    and returns the result c.\n    Uses MXNet ND native syntax.\n    \"\"\"\n    c = mx.nd.dot(a, b)\n    c.wait_to_read()\n    return c\n```", "```py\ntimings_np[\"multiply\"] = []\nfor n in matrix_orders:\n    a = create_matrix_np(n)\n    b = create_matrix_np(n)\n    result = %timeit -o multiply_matrix_np(a, b)\n    timings_np[\"multiply\"].append(result.best)\ntimings_mx_np_cpu[\"multiply\"] = []\nfor n in matrix_orders:\n    a = create_matrix_mx_np(n)\n    b = create_matrix_mx_np(n)\n    result = %timeit -o multiply_matrix_mx_np(a, b)\n    timings_mx_np_cpu[\"multiply\"].append(result.best)\ntimings_mx_np_gpu[\"multiply\"] = []\nctx = mx.gpu()\nfor n in matrix_orders:\n    a = create_matrix_mx_np(n, ctx)\n    b = create_matrix_mx_np(n, ctx)\n    result = %timeit -o multiply_matrix_mx_np(a, b)\n    timings_mx_gpu[\"multiply\"].append(result.best)\ntimings_mx_nd_cpu[\"multiply\"] = []\nfor n in matrix_orders:\n    a = create_matrix_mx_nd(n)\n    b = create_matrix_mx_nd(n)\n    result = %timeit -o multiply_matrix_mx_nd(a, b)\n    timings_mx_nd_cpu[\"multiply\"].append(result.best)\ntimings_mx_nd_gpu[\"multiply\"] = []\nctx = mx.gpu()\nfor n in matrix_orders:\n    a = create_matrix_mx_nd(n, ctx)\n    b = create_matrix_mx_nd(n, ctx)\n    result = %timeit -o multiply_matrix_mx_nd(a, b)\n    timings_mx_nd_gpu[\"multiply\"].append(result.best)\n```", "```py\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nplt.plot(matrix_orders, timings_np[\"create\"], color='red', marker='s')\nplt.plot(matrix_orders, timings_mx_np_cpu[\"create\"], color='blue', marker='o')\nplt.plot(matrix_orders, timings_mx_np_gpu[\"create\"], color='green', marker='^')\nplt.plot(matrix_orders, timings_mx_nd_cpu[\"create\"], color='yellow', marker='p')\nplt.plot(matrix_orders, timings_mx_nd_gpu[\"create\"], color='orange', marker='*')\nplt.title(\"Matrix Creation Runtime\", fontsize=14)\nplt.xlabel(\"Matrix Order\", fontsize=14)\nplt.ylabel(\"Runtime (s)\", fontsize=14)\nplt.grid(True)\nax = fig.gca()\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nplt.legend([\"NumPy\", \"MXNet NumPy (CPU)\", \"MXNet NumPy (GPU)\", \"MXNet ND (CPU)\", \"MXNet ND (GPU)\"])\nplt.show()\n```", "```py\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nplt.plot(matrix_orders, timings_np[\"multiply\"], color='red', marker='s')\n plt.plot(matrix_orders, timings_mx_np_cpu[\"multiply\"], color='blue', marker='o')\n plt.plot(matrix_orders, timings_mx_np_gpu[\"multiply\"], color='green', marker='^')\n plt.plot(matrix_orders, timings_mx_nd_cpu[\"multiply\"], color='yellow', marker='p')\n plt.plot(matrix_orders, timings_mx_nd_gpu[\"multiply\"], color='orange', marker='*')\n plt.title(\"Matrix Multiplication Runtime\", fontsize=14)\n plt.xlabel(\"Matrix Order\", fontsize=14)\n plt.ylabel(\"Runtime (s)\", fontsize=14)\n plt.grid(True)\n ax = fig.gca()\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nplt.legend([\"NumPy\", \"MXNet NumPy (CPU)\", \"MXNet NumPy (GPU)\", \"MXNet ND (CPU)\", \"MXNet ND (GPU)\"])\n plt.show()\n```"]