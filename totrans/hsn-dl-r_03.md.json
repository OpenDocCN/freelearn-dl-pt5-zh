["```py\ninstall.packages(\"ReinforcementLearning\")\n```", "```py\ninstall.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"TimoMatzen/RBM\")\n```", "```py\ndevtools::install_github(\"rstudio/keras\")\nlibrary(keras)\n\ninstall_keras()\n```", "```py\n## for the gpu version :\ninstall_keras(gpu=TRUE)\n```", "```py\nuse_python('/Users/pawlus/.virtualenvs/r-tensorflow/bin/python') \n```", "```py\nif (\"package:h2o\" %in% search()) { detach(\"package:h2o\", unload=TRUE) }\nif (\"h2o\" %in% rownames(installed.packages())) { remove.packages(\"h2o\") }\n\npkgs <- c(\"RCurl\",\"jsonlite\")\nfor (pkg in pkgs) {\n  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }\n}\n\ninstall.packages(\"h2o\", type=\"source\", repos=(c(\"http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R\")))\n```", "```py\ncran <- getOption(\"repos\")\ncran[\"dmlc\"] <- \"https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/\"\noptions(repos = cran)\ninstall.packages(\"mxnet\")\n```", "```py\n  cran <- getOption(\"repos\")\n  cran[\"dmlc\"] <- \"https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/GPU/cu92\"\n  options(repos = cran)\n  install.packages(\"mxnet\")\n```", "```py\nbrew install opencv\nbrew install openblas\n```", "```py\nln -sf /usr/local/opt/openblas/lib/libopenblas.dylib /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib\n```", "```py\nlibrary(tidyverse)\nlibrary(caret)\n\ntrain <- read.csv(\"adult_processed_train.csv\")\ntrain <- train %>% dplyr::mutate(dataset = \"train\")\ntest <- read.csv(\"adult_processed_test.csv\")\ntest <- test %>% dplyr::mutate(dataset = \"test\")\n```", "```py\nall <- rbind(train,test)\n\nall <- all[complete.cases(all),]\n\nall <- all %>%\n  mutate_if(~is.factor(.),~trimws(.))\n```", "```py\ntrain <- all %>% filter(dataset == \"train\")\ntrain_target <- as.numeric(factor(train$target))\ntrain <- train %>% select(-target, -dataset)\n```", "```py\ntrain_chars <- train %>%\n  select_if(is.character)\n\ntrain_ints <- train %>%\n  select_if(is.integer)\n```", "```py\nohe <- caret::dummyVars(\" ~ .\", data = train_chars)\ntrain_ohe <- data.frame(predict(ohe, newdata = train_chars))\n```", "```py\ntrain <- cbind(train_ints,train_ohe)\n```", "```py\ntest <- all %>% filter(dataset == \"test\")\ntest_target <- as.numeric(factor(test$target))\ntest <- test %>% select(-target, -dataset)\n\ntest_chars <- test %>%\n  select_if(is.character)\n\ntest_ints <- test %>%\n  select_if(is.integer)\n\nohe <- caret::dummyVars(\" ~ .\", data = test_chars)\ntest_ohe <- data.frame(predict(ohe, newdata = test_chars))\n\ntest <- cbind(test_ints,test_ohe)\n```", "```py\ntrain_target <- train_target-1\ntest_target <- test_target-1\n```", "```py\ntrain <- train %>% select(-native.countryHoland.Netherlands)\n```", "```py\nlibrary(tensorflow)\nlibrary(keras)\n```", "```py\ntrain <- as.matrix(train)\ntest <- as.matrix(test)\n```", "```py\nmodel <- keras_model_sequential()\n\nmodel %>%\n  layer_dense(units=35, activation = 'relu')\n\nmodel %>% keras::compile(loss='binary_crossentropy',\n                         optimizer='adam',\n                         metrics='accuracy')\n```", "```py\nhistory <- model%>%\n  fit(train, \n      train_target,\n      epoch=10,\n     batch=16,\n      validation_split = 0.15)\n```", "```py\nmodel%>%\n  keras::evaluate(test,test_target)\n```", "```py\nlibrary(mxnet)\n```", "```py\nmx.set.seed(0)\n\nmodel <- mx.mlp(data.matrix(train), train_target, hidden_node=10, out_node=2, out_activation=\"softmax\",\n                num.round=10, array.batch.size=20, learning.rate=0.05, momentum=0.8,\n                eval.metric=mx.metric.accuracy)\n```", "```py\npreds = predict(model, data.matrix(test))\n```", "```py\npred.label = max.col(t(preds))-1\ntable(pred.label, test_target)\n```", "```py\n# load H2O package\nlibrary(h2o)\n\n# start H2O\nh2o::h2o.init()\n```", "```py\n## load data \ntrain <- read.csv(\"adult_processed_train.csv\")\ntest <- read.csv(\"adult_processed_test.csv\")\n\n# load data on H2o\ntrain <- as.h2o(train)\ntest <- as.h2o(test)\n```", "```py\n## pre-process\nh2o.impute(train, column = 0, method = c(\"mean\", \"mode\"))\nh2o.impute(test, column = 0, method = c(\"mean\", \"mode\"))\n```", "```py\n#set dependent and independent variables\ntarget <- \"target\"\npredictors <- colnames(train)[1:14]\n```", "```py\n#train the model - without hidden layer\nmodel <- h2o.deeplearning(model_id = \"h2o_dl_example\"\n                          ,training_frame = train\n                          ,seed = 321\n                          ,y = target\n                          ,x = predictors\n                          ,epochs = 10\n                          ,nfolds = 5)\n```", "```py\nh2o.performance(model, xval = TRUE)\n```", "```py\nh2o::h2o.shutdown()\n```", "```py\nlibrary(ReinforcementLearning)\n\ndata <- sampleGridSequence(N = 1000)\n\ncontrol <- list(alpha = 0.1, gamma = 0.1, epsilon = 0.1)\n\nmodel <- ReinforcementLearning(data, s = \"State\", a = \"Action\", r = \"Reward\", s_new = \"NextState\", control = control)\n\nprint(model)\n```", "```py\nlibrary(RBM)\n\ndata(Fashion)\n\ntrain <- Fashion$trainX\ntrain_label <- Fashion$trainY\n\nrbmModel <- RBM(x = t(train), y = train_label, n.iter = 500, n.hidden = 200, size.minibatch = 10)\n\ntest <- Fashion$testX\ntest_label <- Fashion$testY\n\nPredictRBM(test = t(test), labels = test_label, model = rbmModel)\n```"]