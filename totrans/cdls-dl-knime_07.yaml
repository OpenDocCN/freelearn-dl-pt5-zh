- en: '*Chapter 5:* Autoencoder for Fraud Detection'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point in the book, you should already know the basic math and concepts
    behind neural networks and some deep learning paradigms, as well as the most useful
    KNIME nodes for data preparation, how to build a neural network, how to train
    it and test it, and finally, how to evaluate it. We have built together, in [*Chapter
    4*](B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101), *Building and Training a
    Feedforward Neural Network*, two examples of fully connected feedforward neural
    networks: one to solve a multiclass classification problem on the Iris dataset
    and one to solve a binary classification problem on the Adult dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Those were two simple examples using quite small datasets, in which all the
    classes were adequately represented, with just a few hidden layers in the network
    and a straightforward encoding of the output classes. However, they served their
    purpose: to teach you how to assemble, train, and apply a neural network in KNIME
    Analytics Platform.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, the time has come to explore more realistic examples and apply more complex
    neural architectures and more advanced deep learning paradigms in order to solve
    more complicated problems based sometimes on ill-conditioned datasets. In the
    following chapters, you will look at some of these more realistic case studies,
    requiring some more creative solutions than just a fully connected feedforward
    network for classification.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with a binary classification problem with a dataset that has data
    from only one of the two classes. Here, the classic classification approach cannot
    work, since one of the two classes is missing from the training set. There are
    many problems of this kind, such as anomaly detection to predict mechanical failures
    or fraud detection to distinguish legitimate from fraudulent credit card transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter investigates an alternative neural approach to design a solution
    for this extreme situation in fraud detection: the **autoencoder** architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Autoencoders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is Fraud Detection so hard?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and Training the Autoencoder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the Autoencoder Strategy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the Fraud Detector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In previous chapters, we have seen that neural networks are very powerful algorithms.
    The power of each network lies in its architecture, activation functions, and
    regularization terms, plus a few other features. Among the varieties of neural
    architectures, there is a very versatile one, especially useful for three tasks:
    detecting unknown events, detecting unexpected events, and reducing the dimensionality
    of the input space. This neural network is the **autoencoder**.'
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of the Autoencoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The autoencoder (or **autoassociator**) is a multilayer feedforward neural network,
    trained to reproduce the input vector onto the output layer. Like many neural
    networks, it is trained using the gradient descent algorithm, or one of its modern
    variations, against [a loss funct](https://keras.io/losses/)ion, such as the **Mean
    Squared Error** (**MSE**). It can have as many hidden layers as desired. Regularization
    terms and other general parameters that are useful for avoiding overfitting or
    for improving the learning process can be applied here as well.
  prefs: []
  type: TYPE_NORMAL
- en: The only constraint on the architecture is that the number of input units must
    be the same as the number of output units, as the goal is to train the autoencoder
    to reproduce the input vector onto the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest autoencoder has only three layers: one input layer, one hidden
    layer, and one output layer. More complex structured autoencoders might include
    additional hidden layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – A simple autoencoder](img/B16391_05_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – A simple autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders can be used for many different tasks. Let's first see how an autoencoder
    can be used for dimensionality reduction.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the Input Dimensionality with an Autoencoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s consider an autoencoder with a very simple architecture: one input layer
    with ![](img/Formula_B16391_03_252.png) units; one output layer, also with ![](img/Formula_B16391_05_002.png) units;
    and one hidden layer with ![](img/Formula_B16391_03_042.png) units. If ![](img/Formula_B16391_05_004.png),
    the autoencoder produces a compression of the input vector onto the hidden layer,
    reducing its dimensionality from ![](img/Formula_B16391_05_005.png) to ![](img/Formula_B16391_03_044.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the first part of the network, moving the data from a vector
    with size ![](img/Formula_B16391_05_007.png) to a vector with size ![](img/Formula_B16391_05_008.png),
    plays the role of the encoder. The second part of the network, reconstructing
    the input vector from a ![](img/Formula_B16391_05_009.png) space back into a ![](img/Formula_B16391_05_010.png)
    space, is the decoder. The compression rate is then ![](img/Formula_B16391_05_011.png).
    The larger the value of ![](img/Formula_B16391_03_029.png) and the smaller the
    value of ![](img/Formula_B16391_05_013.png), the higher the compression rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Encoder and decoder subnetworks in a three-layer autoencoder](img/B16391_05_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Encoder and decoder subnetworks in a three-layer autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: 'When using the autoencoder for **dimensionality reduction**, the full network
    is first trained to reproduce the input vector onto the output layer. Then, before
    deployment, it is split into two parts: the **encoder** (input layer and hidden
    layer) and the **decoder** (hidden layer and output layer). The two subnetworks
    are stored separately.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in the output of the bottleneck layer, you can configure
    the **Keras Network Executor** node to output the middle layer. Alternatively,
    you can split the network within the **DL Python Network Editor** node by writing
    a few lines of Python code.
  prefs: []
  type: TYPE_NORMAL
- en: During the deployment phase, in order to compress an input record, we just pass
    it through the encoder and save the output of the hidden layer as the compressed
    record. Then, in order to reconstruct the original vector, we pass the compressed
    record through the decoder and save the output values of the output layer as the
    reconstructed vector.
  prefs: []
  type: TYPE_NORMAL
- en: If a more complex structure is used for the autoencoder – for example, with
    more than one hidden layer – one of the hidden layers must work as the compressor
    output, producing the compressed record and separating the encoder from the decoder
    subnetwork.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the question when we talk about data compression is how faithfully can
    the original record be reconstructed? How much information is lost by using the
    output of the hidden layer instead of the original data vector? Of course, this
    all depends on how well the autoencoder performs and how large our error tolerance
    is.
  prefs: []
  type: TYPE_NORMAL
- en: During testing, when we apply the network to new data, we denormalize the output
    values and we calculate the chosen error metric – for example, the **Root Mean
    Square Error** (**RMSE**) – between the original input data and the reconstructed
    data on the whole test set. This error value gives us a measure of the quality
    of the reconstructed data. Of course, the higher the compression rate, the higher
    the reconstruction error. The problem thus becomes to train the network to achieve
    acceptable performance, as per our error tolerance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s move on to the next application field of autoencoders: anomaly detection.'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Anomalies Using an Autoencoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most classification/prediction problems, we have a set of examples covering
    all event classes and based on this dataset, we train a model to classify events.
    However, sometimes, the event class we want to predict is so rare and unexpected
    that no (or almost no) examples are available at all. In this case, we do not
    talk about classification or prediction but about **anomaly detection**.
  prefs: []
  type: TYPE_NORMAL
- en: 'An anomaly can be any rare, unexpected, unknown event: a cardiac arrhythmia,
    a mechanical breakdown, a fraudulent transaction, or other rare, unexpected, unknown
    events. In this case, since no examples of anomalies are available in the training
    set, we need to use neural networks in a more creative way than for conventional,
    standard classification. The autoencoder structure lends itself to such creative
    usage, as required for the solution of an anomaly detection problem (see, for
    example, A.G. Gebresilassie, *Neural Networks for Anomaly (Outliers) Detection*,
    [https://blog.goodaudience.com/neural-networks-for-anomaly-outliers-detection-a454e3fdaae8](https://blog.goodaudience.com/neural-networks-for-anomaly-outliers-detection-a454e3fdaae8)).'
  prefs: []
  type: TYPE_NORMAL
- en: Since no anomaly examples are available, the autoencoder is trained only on
    non-anomaly examples. Let's call these examples of the "normal" class. On a training
    set full of "normal" data, the autoencoder network is trained to reproduce the
    input feature vector onto the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is that, when required to reproduce a vector of the "normal" class,
    the autoencoder is likely to perform a decent job because that is what it was
    trained to do. However, when required to reproduce an anomaly on the output layer,
    it will hopefully fail because it won't have seen this kind of vector throughout
    the whole training phase. Therefore, if we calculate the distance – any distance
    – between the original vector and the reproduced vector, we see a small distance
    for input vectors of the "normal" class and a much larger distance for input vectors
    representing an anomaly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, by setting a threshold, ![](img/Formula_B16391_05_052.png), we should
    be able to detect anomalies with the following rule:'
  prefs: []
  type: TYPE_NORMAL
- en: IF ![](img/Formula_B16391_05_015.png) THEN ![](img/Formula_B16391_05_016.png)
    -> "normal"
  prefs: []
  type: TYPE_NORMAL
- en: IF ![](img/Formula_B16391_05_017.png) THEN ![](img/Formula_B16391_05_018.png)
    -> "anomaly"
  prefs: []
  type: TYPE_NORMAL
- en: Here, ![](img/Formula_B16391_05_019.png) is the reconstruction error for the
    input vector, ![](img/Formula_B16391_05_018.png), and ![](img/Formula_B16391_05_021.png)
    is the set threshold.
  prefs: []
  type: TYPE_NORMAL
- en: This sort of solution has already been implemented successfully for fraud detection,
    as described in a blog post, *Credit Card Fraud Detection using Autoencoders in
    Keras -- TensorFlow for Hackers (Part VI*[*I)*, by Venelin Valkov (https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hacker](https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd)s-part-vii-20e0c85301bd).
    In this chapter, we will use the same idea to build a similar solution using a
    different autoencoder structure.
  prefs: []
  type: TYPE_NORMAL
- en: Let's find out how the idea of an autoencoder can be used to detect fraudulent
    transactions.
  prefs: []
  type: TYPE_NORMAL
- en: Why is Detecting Fraud so Hard?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Fraud detection** is a set of activities undertaken to prevent money or property
    from being obtained through false pretenses. Fraud detection is applied in many
    industries, such as banking or insurance. In banking, fraud may include forging
    checks or using stolen credit cards. For this example, we will focus on fraud
    in credit card transactions.'
  prefs: []
  type: TYPE_NORMAL
- en: This kind of fraud, in credit card transactions, is a huge problem for credit
    card issuers as well as for the final payers. The European Central Bank reported
    that in 2016, the total number of card fraud cases using cards issued in the **Single
    Euro Payments Area** (**SEPA**) amounted to 17.3 million, and the total number
    of card transactions using cards issued in SEPA amounted to 74.9 billion ([https://www.ecb.europa.eu/pub/cardfraud/html/ecb.cardfraudreport201809.en.html#toc1](https://www.ecb.europa.eu/pub/cardfraud/html/ecb.cardfraudreport201809.en.html#toc1)).
  prefs: []
  type: TYPE_NORMAL
- en: However, the amount of fraud is not the only problem. From a data science perspective,
    fraud detection is also a very hard task to solve, because of the small amount
    of data available on fraudulent transactions. That is, often we have tons of data
    on legitimate credit card transactions and just a handful on fraudulent transactions.
    A classic approach (training, then applying a model) is not possible in this case
    since the examples for one of the two classes are missing.
  prefs: []
  type: TYPE_NORMAL
- en: Fraud detection, however, can also be seen as anomaly detection. Anomaly detection
    is any event that is unexpected within a dataset. A fraudulent transaction is
    indeed an unexpected event and therefore we can consider it an anomaly in a dataset
    of legitimate *normal* credit card transactions.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few different approaches to fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: One option is the discriminative approach. Based on a training set with both
    classes, legitimate and fraudulent transactions, we build a model that distinguishes
    between data from the two classes. This could be a simple threshold-based rule
    or a supervised machine learning model. This is the classic approach based on
    a training set including enough examples from both classes.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you can treat a fraud detection problem as outlier detection.
    In this case, you can use a clustering algorithm that leaves space for outliers
    (noise), such as **DBSCAN**; or you can use the **isolation forest technique**,
    which isolates outliers with just a few cuts with respect to legitimate data.
    Fraudulent transactions, though, must belong to the original dataset, to be isolated
    as outliers.
  prefs: []
  type: TYPE_NORMAL
- en: A[nother app](https://en.wikipedia.org/wiki/Generative_model)roach, called the
    **generative approach**, involves using only legitimate transactions during the
    training phase. This allows us to reproduce the input vector onto the output layer.
    Once the model for the autoencoder has been trained, we use it during deployment
    to reproduce the input transaction. We then calculate the distance (or error)
    between the input values and the output values. If that distance falls below a
    given threshold, the transaction is likely to be legitimate; otherwise, it is
    flagged as a fraud candidate.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we will us[e the](https://www.kaggle.com/mlg-ulb/creditcardfraud)
    credit card dataset by Kaggle. This dataset contains credit card transactions
    from European cardholders in September 2013\. Fraudulent transactions have been
    labeled with `1`, while legitimate transactions are labeled with `0`. The dataset
    contains 284,807 transactions, but only 492 (0.2%) of them are fraudulent. Due
    to privacy reasons, principal components are used instead of the original transaction
    features. Thus, each credit card transaction is re[presented by 30 featu](https://en.wikipedia.org/wiki/Principal_component_analysis)res:
    28 principal components extracted from the original credit card data, the transaction
    time, and the transaction amount.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's proceed with the building, training, and testing of the autoencoder.
  prefs: []
  type: TYPE_NORMAL
- en: Building and Training the Autoencoder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s go into detail about the particular application we will build to tackle
    fraud detection with a neural autoencoder. Like all data science projects, it
    includes two separate applications: one to train and optimize the whole strategy
    on dedicated datasets, and one to set it in action to analyze real-world credit
    card transactions. The first application is implemented with the **training workflow**;
    the second application is implemented with the **deployment workflow**.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Often, training and deployment are separate applications since they work on
    different data and have different goals.
  prefs: []
  type: TYPE_NORMAL
- en: The training workflow uses a lab dataset to produce an acceptable model to implement
    the task, sometimes requiring a few different trials. The deployment workflow
    does not change the model or the strategy anymore; it just applies it to real-world
    transactions to get fraud alarms.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will focus on the training phase, including the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Access**: Here, we read the lab data from the file, including all 28
    principal components, the transaction amount, and the corresponding time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Preparation**: The data comes already clean and transformed via **Principal
    Component Analysis** (**PCA**). What remains doing in this phase is to create
    all the data subsets required for the training, optimization, and testing of the
    neural autoencoder and the whole strategy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Building the Neural Network**: An autoencoder is a feedforward neural network
    with as many inputs as outputs. Let''s then decide the number of hidden layers,
    the number of hidden neurons, and the activation functions in each layer, and
    then build it accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training the Neural Autoencoder**: In this part, the autoencoder is trained
    on a training set of just legitimate transactions with one of the training algorithms
    (the optimizers), according to the selected training parameters, such as, at least,
    the loss function, the number of epochs, and the batch size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule for Fraud Alarms**: After the network has been trained and it is able
    to reproduce legitimate transactions on the output layer, we need to complete
    the strategy by calculating the distance between the input and output layers and
    by setting a threshold-based rule to trigger fraud alarms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing the whole Strategy**: The last step is to test the whole strategy
    performance. How many legitimate transactions are correctly recognized? How many
    fraud alarms are correctly triggered and how many are false alarms?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Access and Data Preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The credit card dataset from Kaggle comes already clean and transformed. We
    now need to create all the data subsets. Specifically, we need a training and
    a validation set for the training of the autoencoder. They must consist of only
    legitimate transactions. The training set is used to train the network and the
    validation set is used to monitor the performance of the autoencoder on unseen
    data during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we need an additional data subset, the threshold optimization set, to
    optimize the threshold, ![](img/Formula_B16391_05_052.png), in the rule-based
    fraud alarm generator. This last subset should include all fraudulent transactions,
    in addition to a number of legitimate transactions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 2/3 of all legitimate transactions are dedicated to the autoencoder.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 90% of those legitimate transactions form the **training set**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10% form the **validation set**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1/3 (96K) of all legitimate transactions and all 492 fraudulent transactions
    form the **threshold optimization set**, used to optimize the value of threshold
    ![](img/Formula_B16391_05_023.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This all translates into one **Row Splitter** node to separate legitimate transactions
    from fraudulent transactions, one **Concatenate** node to add back the fraudulent
    transactions into the threshold optimization set, and a number of **Partitioning**
    nodes. All data extraction in the Partitioning nodes is performed at random:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – The datasets used in the fraud detection process ](img/B16391_05_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – The datasets used in the fraud detection process
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The training set, validation set, and threshold optimization set must be completely
    separated. No records can be shared across any of the subsets. This is to ensure
    a meaningful performance measure during evaluation and an independent optimization
    procedure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, all data in each subset must be normalized to fall in ![](img/Formula_B16391_05_024.png).
    Normalization is defined on the training set and applied to the other two subsets.
    The normalization parameters are also saved for the deployment workflow using
    the **Model Writer** node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – The workflow implementing data preparation for fraud detection](img/B16391_05_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – The workflow implementing data preparation for fraud detection
  prefs: []
  type: TYPE_NORMAL
- en: The workflow in *Figure 5.4* shows how the creation of the different datasets
    and the normalization can be performed in KNIME Analytics Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Autoencoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this case study, we built an autoencoder with five hidden layers, with `30-40-20-8-20-40-30`
    units, and sigmoid as the activation function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The neural network was built using the following (see *Figure 5.5*):'
  prefs: []
  type: TYPE_NORMAL
- en: The `Shape = 30`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Five **Keras Dense Layer** nodes to implement the hidden layers, using sigmoid
    as the activation function and 40, 20, 8, 20, and 40 units, respectively
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **Keras Dense Layer** node for the output layer, with 30 units and sigmoid
    as the activation function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Structure of the neural autoencoder trained to reproduce credit
    card transactions from the input layer onto the output layer](img/B16391_05_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Structure of the neural autoencoder trained to reproduce credit
    card transactions from the input layer onto the output layer
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've built the autoencoder, let's train and test it using the data.
  prefs: []
  type: TYPE_NORMAL
- en: Training and Testing the Autoencoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To train and validate the network, we use the **Keras Network Learner** node,
    with the training set and the validation set at the input ports, and the following
    settings (*Figure 5.6*):'
  prefs: []
  type: TYPE_NORMAL
- en: The number of epochs is set to `50`, the batch size for the training and validation
    set is set to `300`, [and](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)
    the **Adam** (an optimized ve[rsion of backpr](https://en.wikipedia.org/wiki/Backpropagation)opagation)
    training algorithm is used, in the **Options** tab.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The loss function is set to be the MSE in the **Target** tab.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The target and input features are the same in the **Input** tab and in the **Target**
    tab and are accepted as simple **Double** numbers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the **Loss** tab of the **Learning Monitor** view of the Keras Network Learner
    node, you can see two curves now: one is the mean loss (or error) per training
    sample in a batch (in red) and the other one is the mean loss per sample on the
    validation data (in blue).'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of the training phase, the final mean loss value fell in around
    [0.0012, 0016] for batches from the training set and in [0.0013, 0.0018] for batches
    from the validation set. The calculated loss is the mean reconstruction error
    for one batch, calculated by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_05_025.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_05_026.png) is the batch size, ![](img/Formula_B16391_05_002.png)
    is the number of units on the output layer, ![](img/Formula_B16391_05_028.png)
    is the output value of neuron *i* in the output layer for training sample *k*,
    and ![](img/Formula_B16391_05_029.png) is the corresponding target answer.
  prefs: []
  type: TYPE_NORMAL
- en: After training, the network is applied to the optimization set, using the **Keras
    Network Executor** node, and it is saved for deployment as a Keras file using
    the **Keras Network Writer** node.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.6* shows the configuration for the **Options** tab in the Keras Network
    Executor node: all 30 input features are passed as **Double** numbers and the
    input columns are kept so that the reconstruction error can be calculated later
    on. The last layer is selected as the output and the values are exported as simple
    **Double** numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – The Keras Network Executor node and its configuration window](img/B16391_05_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – The Keras Network Executor node and its configuration window
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to calculate the distance between the original feature vector
    and the reproduced feature vector, and to apply a threshold, ![](img/Formula_B16391_05_030.png),
    to discover fraud candidates.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Fraudulent Transactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the model training is finished, the autoencoder has learned how to reproduce
    feature vectors representing legitimate transactions onto the output layer. How
    can we now spot suspicious transactions? If we have a new transaction, ![](img/Formula_B16391_05_016.png),
    how can we tell whether it is a suspicious or a legitimate one?
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we run this new transaction, ![](img/Formula_B16391_05_032.png), through
    the autoencoder via the Keras Network Executor node. The reproduction of the original
    transaction is generated at the output layer. Now, a reconstruction error, ![](img/Formula_B16391_05_033.png),
    is calculated, as the distance between the original transaction vector and the
    reproduced one. A transaction is then considered a fraud candidate according to
    the following rule:'
  prefs: []
  type: TYPE_NORMAL
- en: IF ![](img/Formula_B16391_05_034.png) THEN ![](img/Formula_B16391_05_018.png)
    -> "legitimate trx"
  prefs: []
  type: TYPE_NORMAL
- en: IF ![](img/Formula_B16391_05_036.png) THEN ![](img/Formula_B16391_05_016.png)
    -> "fraud candidate trx"
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, ![](img/Formula_B16391_05_019.png) is the reconstruction error value
    for transaction ![](img/Formula_B16391_05_039.png) and *K* is a threshold. The
    MSE was also adopted for the reconstruction error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_05_040.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B16391_05_041.png) is the *i*th feature of transaction
    ![](img/Formula_B16391_05_042.png), and ![](img/Formula_B16391_05_043.png) is
    the corresponding value on the output layer of the network.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B16391_05_044.png) is calculated via a `1` is the fraud candidate
    class and `0` is the legitimate transaction class. A `1`. Specificity is the ratio
    between the number of true legitimate transactions and all transactions that did
    not raise any alarm. Sensitivity, on the opposite side, measures the ratio of
    fraud alarms that actually hit a fraudulent transaction.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specificity produces a measure of the frauds we might have missed, while sensitivity
    produces a measure of the frauds we hit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – The rule implemented in the Rule Engine node, comparing reconstruction
    error with threshold](img/B16391_05_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – The rule implemented in the Rule Engine node, comparing reconstruction
    error with threshold
  prefs: []
  type: TYPE_NORMAL
- en: Now that our model is trained and tested, it needs to be optimized.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the Autoencoder Strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the best value to use for threshold ![](img/Formula_B16391_05_023.png)?
    In the last section, we adopted ![](img/Formula_B16391_05_048.png) based on our
    experience. However, is this the best value for ![](img/Formula_B16391_05_052.png)?
    Threshold ![](img/Formula_B16391_05_052.png), in this case, is not automatically
    optimized via the training procedure. It is just a static parameter external to
    the training algorithm. In KNIME Analytics Platform, it is also possible to optimize
    static parameters outside of the **Learner** nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing Threshold ![](img/Formula_B16391_05_051.png)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Threshold ![](img/Formula_B16391_05_052.png) is defined on a separate subset
    of data, called the **optimization set**. There are two options here:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If an optimization set with labeled fraudulent transactions is available, the
    value of threshold ![](img/Formula_B16391_05_052.png) is optimized against any
    accuracy measure for fraud detection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no labeled fraudulent transactions are available in the dataset, the value
    of threshold ![](img/Formula_B16391_05_052.png) is defined as a high percentile
    of the reconstruction errors on the optimization set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'During the data preparation phase, we generated three data subsets: the training
    set and validation set for the Keras Network Learner node to train and validate
    the autoencoder, and one last subset, which we called the threshold optimization
    set. This final subset includes 1/3 of all the legitimate transactions and the
    handful of fraudulent transactions. We can use this subset to optimize the value
    of threshold ![](img/Formula_B16391_05_023.png) against the accuracy of the whole
    fraud detection strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: To optimize a parameter means to find the value within a range that maximizes
    or minimizes a given measure. Based on our experience, we assume the value of
    *K* to be a positive number (> 0) and to lie below 0.02\. So, to optimize the
    value of threshold ![](img/Formula_B16391_05_023.png) means to find the value
    in ![](img/Formula_B16391_05_057.png) that maximizes the accuracy of the whole
    application.
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy of the application is calculated via a Scorer (JavaScript) node,
    considering the results of the Rule Engine node as the predictions and comparing
    them with the original class (`0` = legitimate transaction, `1` = fraudulent transaction)
    in the optimization set.
  prefs: []
  type: TYPE_NORMAL
- en: The spanning of the value interval and the identification of the threshold value
    for the maximum accuracy is performed by an `loop start` node and a `loop end`
    node. In the optimization loop, these two nodes are the **Parameter Optimization
    Loop Start** node and the **Parameter Optimization Loop End** node.
  prefs: []
  type: TYPE_NORMAL
- en: The **Parameter Optimization Loop Start** node spans parameter values in a given
    interval with a given step size. Interval ![](img/Formula_B16391_05_058.png) and
    step size ![](img/Formula_B16391_05_059.png) have been chosen here based on the
    range of the reconstruction error feature, as shown in the **Lower Bound** and
    **Upper Bound** cells in the **Spec** tab of the data table at the output port
    of the Math Formula node, named **MSE input-output distance**, after the Keras
    Network Executor node.
  prefs: []
  type: TYPE_NORMAL
- en: The **Parameter Optimization Loop End** node collects all results as flow variables,
    detects the best (maximum or minimum) value for the target measure, and exports
    it together with the parameter that generated it. In our case, the target measure
    is the accuracy, measured on the predictions from the Rule Engine node, which
    must be maximized against values for threshold ![](img/Formula_B16391_05_052.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'All nodes in between the loop start and the loop end make the body of the loop
    – that is, the part that gets repeated as many times as needed until the input
    interval of parameter values has all been covered. In the loop body, we add the
    additional constraint that the optimal accuracy should be found only for those
    parameters where the specificity and sensitivity are close in value. This is the
    goal of the metanode named `Coefficient 0/1`. Here, if the specificity and sensitivity
    are more than 10% apart, the coefficient is set to `0`, otherwise to `1`. This
    coefficient then multiplies the overall accuracy coming from the Scorer (JavaScript)
    node. In this way, the maximum accuracy is detected only for those cases where
    the specificity and sensitivity are close to each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – The optimization loop](img/B16391_05_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – The optimization loop
  prefs: []
  type: TYPE_NORMAL
- en: After extracting the optimal threshold, we transform it into a flow variable
    and pass it to the final rule implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up into a Component
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, this whole threshold optimization part seems to be a logical self-contained
    block. To keep our workflow clean and proper, we could wrap this block inside
    a metanode. Even better, we could make sure that the wrapping is close and tight
    via a stronger type of metanode: the **component**.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: A metanode just collects and packages nodes. A component, on the other hand,
    collects and packages nodes together and, in addition, inherits the views of contained
    Widget and JavaScript nodes and the configuration windows of contained Configuration
    nodes. Even further, a component does not allow external flow variables to enter
    or internal flow variables to exit unless specifically defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'A component is created in a similar way to a metanode. Just select the nodes
    to group together, right-click, and select **Create Component…**. When a component
    is created, its context (right-click) menu offers a number of commands to open,
    expand, modify via setup, and share it. To inspect the content of a component,
    just *Ctrl* + double-click the component. Once inside, you can see two nodes:
    **Component Input** and **Component Output**. In the configuration window of these
    two nodes, you can set the flow variables to import inside and export outside
    of the component, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: In the component we created, we set up the **Component Output** node to export
    the flow variable containing the value for the optimal threshold. This flow variable
    needs to exit the component to be used in the final rule for fraud detection.
    The final rule is implemented in a new Rule Engine node and the final predictions
    are evaluated against the original classes in a new Scorer (JavaScript) node.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final workflow to train and test the neural autoencoder using credit card
    transaction data and to implement the fraud detection rule with the optimal threshold
    is shown in *Figure 5.9*. The workflow, named `01_Autoencoder_for_Fraud_Detection_Training`,
    is downloadable from the KNIME Hub: [https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/](https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – The workflow to train and test the autoencoder and to find the
    optimal threshold, K](img/B16391_05_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – The workflow to train and test the autoencoder and to find the
    optimal threshold, K
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have found the best threshold, let's have a look at the performance
    of the autoencoder.
  prefs: []
  type: TYPE_NORMAL
- en: Performance Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we report the performance measures of this approach on the
    threshold optimization set after applying the fraud detection rule. The optimal
    threshold value was found to be ![](img/Formula_B16391_05_061.png) for an accuracy
    of 93.52%.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 5.10*, you can see the **confusion matrix**, the class statistics
    based on it, and the general performance measures, all of them describing how
    well the fraud detector is performing on the optimization set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – Performance metrics of the final fraud detector with optimized
    threshold K](img/B16391_05_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Performance metrics of the final fraud detector with optimized
    threshold K
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider class 1 (fraud) as the positive class. The high number of false
    positives (6,236) shows the weakness of this approach: it is prone to generating
    false positives. In other words, it tends to label perfectly legitimate transactions
    as fraud candidates. Now, there are case studies where false positives are not
    a huge problem, and this is one of those. In the case of a false positive, the
    price to pay is to send a message to the credit card owner about the current transaction.
    If the message turns out to be useless, the damage is not much compared to the
    possible risk. Of course, this tolerance does not apply to all case studies. A
    false positive in medical diagnosis carries a much heavier responsibility than
    a wrong fraud alarm in a credit card transaction.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The whole process could also be forced to lean more toward fraud candidates
    or legitimate transactions, by introducing an expertise-based bias in the definition
    of threshold *K*.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the autoencoder captures 87% of the fraudulent transactions and
    93% of the legitimate transactions in the validation set, for an overall accuracy
    of 85% and a Cohen's kappa of 0.112\. Considering the high imbalance between the
    number of normal and fraudulent transactions in the validation set (96,668 versus
    492), the results are still promising.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that this false positive-prone approach is a desperate solution for a
    case study where no, or almost no, examples from one of the classes exist. A supervised
    classifier on a training set with labeled examples would probably reach better
    performances. But this is the data we have to deal with!
  prefs: []
  type: TYPE_NORMAL
- en: We have now trained the autoencoder and found the best threshold for our rule
    system. We will see, in the next section, how to deploy it in the real world on
    real data.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Fraud Detector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we have an autoencoder network and a rule with acceptable performance
    for fraud detection. In this section, we will implement the **deployment** workflow.
  prefs: []
  type: TYPE_NORMAL
- en: The deployment workflow (*Figure 5.11*), like all deployment workflows, takes
    in new transaction data, passes it through the autoencoder, calculates the distance,
    applies the fraud detection rule, and finally, flags the input transaction as
    fraud or legitimate.
  prefs: []
  type: TYPE_NORMAL
- en: 'This workflow, named `02_Autoencoder_for_Fraud_Detection_Deployment`, is downloadable
    from the KNIME Hub: [https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/](https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%205/):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – The deployment workflow](img/B16391_05_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – The deployment workflow
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a look at the different parts of the workflow in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Reading Network, New Transactions, and Normalization Parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this workflow, first the autoencoder model is read from the previously saved
    Keras file, using the **Keras Network Reader** node.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, data from some new credit card transactions are read from
    the file using the **File Reader** node. This particular file contains two new
    transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The transactions are normalized with the same parameters built on the training
    data and previously saved in the file named `normalizer model`. These normalization
    parameters are read from the file using the **Model Reader** node.
  prefs: []
  type: TYPE_NORMAL
- en: The last file to read contains the value of the optimized threshold, *K*.
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Fraud Detector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transaction data is fed into the autoencoder network and reproduced on the output
    layer with the Keras Network Executor node.
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, the MSEs between the original features and the reconstructed features
    for each transaction are calculated using the **Math Formula** node.
  prefs: []
  type: TYPE_NORMAL
- en: The Rule Engine node applies the threshold, ![](img/Formula_B16391_05_052.png),
    as defined during the optimization phase, to detect possible fraud candidates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the reconstruction errors for the two transactions
    and the consequent class assignment. The application (autoencoder and distance
    rule) defines the first transaction as legitimate and the second transaction as
    a fraud candidate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B16391_05_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Reconstruction errors and fraud class assignment for credit card
    transactions in the dataset used for deployment
  prefs: []
  type: TYPE_NORMAL
- en: Taking Actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the last part of the workflow, we need to take action:'
  prefs: []
  type: TYPE_NORMAL
- en: IF transaction is legitimate (class 0) => do nothing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IF transaction is fraud candidate (class 1) => send message to owner to confirm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IF-THEN** conditions involving actions are implemented in KNIME Analytics
    Platform via switch blocks. Similar to loops, switch blocks have a start node
    and an end node. The end node in switch blocks is optional, however. The switch
    start node activates only one of the output ports, enabling de facto only one
    possible further path for the data flow. The switch end node collects the results
    from the different branches. The most versatile switch block is the **CASE switch**
    in all its declinations: for data, flow variables, or models.'
  prefs: []
  type: TYPE_NORMAL
- en: The active port, and then the active branch, is controlled via the configuration
    window of the **Switch CASE Start** node. This configuration setting is usually
    controlled via a flow variable, whose values enable one or the other output each
    time.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we have two branches. The upper branch is connected to port `0`,
    activated by class `0`, and performs nothing. The second branch is connected to
    port `1`, activated by class `1`, and sends an email to the owner of the credit
    card.
  prefs: []
  type: TYPE_NORMAL
- en: We conclude here the section on the implementation of the autoencoder-based
    strategy for fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed approaches for building a fraud detector for credit
    card transactions in the desperate case when no, or almost no, examples of the
    fraud class are available. This solution trains a neural autoencoder to reproduce
    legitimate transactions from the input onto the output layer. Some postprocessing
    is necessary to set an alarm for the fraud candidate based on the reconstruction
    error.
  prefs: []
  type: TYPE_NORMAL
- en: In describing this solution, we have introduced the concept of training and
    deployment applications, components, optimization loops, and switch blocks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss a special family of neural networks, so-called
    recurrent neural networks, and how they can be used to train neural networks for
    sequential data.
  prefs: []
  type: TYPE_NORMAL
- en: Questions and Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Check your level of understanding of the concepts presented in this chapter
    by answering the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the goal of an autoencoder during training?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) To reproduce the input to the output
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) To learn an automatic encoding
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) To encode the training data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) To train a network that can distinguish between two classes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What are common use cases for autoencoders?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Time series prediction
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) Anomaly detection
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Multiclass classification problems
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) Regression problems
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How can an autoencoder be used for dimensionality reduction?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) By training a network with an output layer with less number than input layers
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) By training an autoencoder and extracting only the encoder
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) By building an autoencoder and extracting only the decoder
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d) By building a network with more hidden neurons than the input and output
    layers
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
