["```py\n    conda activate chapter10-dl-explain\n    ```", "```py\n    import os\n    import matplotlib.pyplot as plt\n    import mlflow\n    from mlflow.tracking import MlflowClient\n    from mlflow.utils.file_utils import TempDir\n    import shap\n    import transformers\n    from shap.plots import *\n    import numpy as np\n    ```", "```py\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n    ```", "```py\n    EXPERIMENT_NAME = \"dl_explain_chapter10\"\n    mlflow.set_tracking_uri('http://localhost')\n    mlflow.set_experiment(EXPERIMENT_NAME)\n    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n    print(\"experiment_id:\", experiment.experiment_id)\n    ```", "```py\nexperiment_id: 14\n```", "```py\nexport MLFLOW_TRACKING_URI=http://localhost\n```", "```py\n    dl_model = transformers.pipeline('sentiment-analysis', return_all_scores=False)\n    explainer = shap.Explainer(dl_model)\n    shap_values = explainer([\"Not a good movie to spend time on.\", \"This is a great movie.\"])\n    ```", "```py\nmlflow.end_run()\n```", "```py\nartifact_root_path = \"model_explanations_shap\"\nartifact_file_name = 'shap_bar_plot'\n```", "```py\n    with mlflow.start_run() as run:\n       with TempDir() as temp_dir:\n            temp_dir_path = temp_dir.path()\n            print(\"temp directory for artifacts: {}\".format(temp_dir_path))\n    ```", "```py\ntemp directory for artifacts: /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpgw520wu1\n```", "```py\n    try:\n         plt.clf()\n         plt.subplots_adjust(bottom=0.2, left=0.4)\n         shap.plots.bar(shap_values[0, :, \"NEGATIVE\"],\n                        show=False)\n         plt.savefig(f\"{temp_dir_path}/{artifact_file_name}\")\n    finally:\n         plt.close(plt.gcf())\n    mlflow.log_artifact(f\"{temp_dir_path}/{artifact_file_name}.png\", artifact_root_path)\n    ```", "```py\n    np.save(f\"{temp_dir_path}/shap_values\", \n            shap_values.values)\n    np.save(f\"{temp_dir_path}/base_values\", \n            shap_values.base_values)\n            mlflow.log_artifact(\n                f\"{temp_dir_path}/shap_values.npy\", \n                artifact_root_path)\n            mlflow.log_artifact(\n                f\"{temp_dir_path}/base_values.npy\", \n                artifact_root_path)      \n    ```", "```py\n    http://localhost/#/experiments/14/runs/10f0655189f740aeb813a015f1f6e115\n    ```", "```py\n    downloaded_local_path = MlflowClient().download_artifacts(run.info.run_id, artifact_root_path)\n    ```", "```py\nbase_values = np.load(os.path.join(downloaded_local_path, \"base_values.npy\"), allow_pickle=True)\nshap_values = np.load(os.path.join(downloaded_local_path, \"shap_values.npy\"), allow_pickle=True)\n```", "```py\npython shap_mlflow_log_artifact.py\n```", "```py\n    class SentimentAnalysisExplainer(mlflow.pyfunc.PythonModel):\n    ```", "```py\n    def load_context(self, context):\n      from transformers import pipeline\n      import shap\n      self.explainer = shap.Explainer(pipeline('sentiment-analysis', return_all_scores=True))\n    ```", "```py\n    def sentiment_classifier_explanation(self, row):\n      shap_values = self.explainer([row['text']])\n      return [pickle.dumps(shap_values)]\n    ```", "```py\n    def predict(self, context, model_input):\n      model_input[['shap_values']] = model_input.apply(\n        self.sentiment_classifier_explanation, axis=1, \n        result_type='expand')\n      model_input.drop(['text'], axis=1, inplace=True)\n      return model_input\n    ```", "```py\n    input = json.dumps([{'name': 'text', 'type': 'string'}])\n    output = json.dumps([{'name': 'shap_values', 'type': 'string'}])\n    signature = ModelSignature.from_dict({'inputs': input, 'outputs': output})\n    ```", "```py\n    with mlflow.start_run() as mlrun:          \n      mlflow.pyfunc.log_model(\n        artifact_path=MODEL_ARTIFACT_PATH, \n        conda_env=CONDA_ENV,                           \n        python_model=SentimentAnalysisExplainer(), \n        signature=signature)\n    ```", "```py\n    python nlp_sentiment_classifier_explainer.py\n    ```", "```py\n2022-05-11 17:49:32,181 Found credentials in environment variables.\n2022-05-11 17:49:32,384 finished logging nlp sentiment classifier explainer run_id: ad1edb09e5ea4d8ca0332b8bc2f5f6c9\n```", "```py\n    mlflow models serve -m runs:/ ad1edb09e5ea4d8ca0332b8bc2f5f6c9/nlp_sentiment_classifier_explainer\n    ```", "```py\n    curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"text\"],\"data\":[[\"This is meh weather\"], [\"This is great weather\"]]}' http://127.0.0.1:5000/invocations\n    ```", "```py\n    run_id = \"ad1edb09e5ea4d8ca0332b8bc2f5f6c9\"\n    logged_explainer = f'runs:/{run_id}/nlp_sentiment_classifier_explainer'\n    explainer = mlflow.pyfunc.load_model(logged_explainer)\n    ```", "```py\nexplainer\n```", "```py\nmlflow.pyfunc.loaded_model: artifact_path: nlp_sentiment_classifier_explainer flavor: mlflow.pyfunc.model run_id: ad1edb09e5ea4d8ca0332b8bc2f5f6c9\n```", "```py\n    import datasets\n    dataset = datasets.load_dataset(\"imdb\", split=\"test\")\n    short_data = [v[:500] for v in dataset[\"text\"][:20]]\n    df_test = pd.DataFrame (short_data, columns = ['text'])\n    ```", "```py\n    results = explainer.predict(df_test)\n    ```", "```py\nPartition explainer: 2it [00:38, 38.67s/it]\n```", "```py\n    results_deserialized = pickle.loads(results['shap_values'][0])\n    print(results_deserialized)\n    ```", "```py\n    shap.plots.text(results_deserialized[:,:,\"POSITIVE\"])\n    ```", "```py\n    python shap_mlflow_pyspark_explainer.py\n    ```", "```py\n    spark = SparkSession.builder.appName(\"Batch explanation with MLflow DL explainer\").getOrCreate()\n    run_id = \"ad1edb09e5ea4d8ca0332b8bc2f5f6c9\"\n    logged_explainer = f'runs:/{run_id}/nlp_sentiment_classifier_explainer'\n    explainer = mlflow.pyfunc.spark_udf(spark, model_uri=logged_explainer, result_type=StringType())\n    ```", "```py\nexplainer\n```", "```py\n<function mlflow.pyfunc.spark_udf.<locals>.udf(iterator: Iterator[Tuple[Union[pandas.core.series.Series, pandas.core.frame.DataFrame], ...]]) -> Iterator[pandas.core.series.Series]>\n```", "```py\n    df_pandas = pd.DataFrame (short_data, columns = ['text'])\n    spark_df = spark.createDataFrame(df_pandas)\n    spark_df = spark_df.withColumn('shap_values', explainer())\n    ```"]