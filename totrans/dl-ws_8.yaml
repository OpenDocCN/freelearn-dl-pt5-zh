- en: Appendix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1\. Building Blocks of Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 1.01: Solving a Quadratic Equation Using an Optimizer'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s solve the following quadratic equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.29: Quadratic equation to be solved'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_01_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.29: Quadratic equation to be solved'
  prefs: []
  type: TYPE_NORMAL
- en: We already know that the solution to this quadratic equation is `x=5`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use an optimizer to solve this. For the optimizer, `x` is the variable
    and the cost function is the left-hand side expression, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.30: Left-hand side expression'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_01_30.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.30: Left-hand side expression'
  prefs: []
  type: TYPE_NORMAL
- en: 'The optimizer will find the value of `x` for which the expression is the minimum
    – in this case, it is `0`. Please note that this will work only for quadratic
    equations that are perfect squares, such as in this case. The left-hand side expression
    is a perfect square that can be explained with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.31: Perfect square'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_01_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.31: Perfect square'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at the code for solving this:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook and rename it *Activity 1.01*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import `tensorflow`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the variable `x` and initialize it to 0.0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Construct the `loss` function as a `lambda` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an instance of an optimizer with a learning rate of `.01`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the optimizer through 10,000 iterations. You can start with a smaller number
    such as 1,000 and keep increasing the number of iterations until you get the solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the value of `x`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the solution to our quadratic equation. It may be noted that, irrespective
    of the number of iterations, you will never get a perfect 5.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3gBTFGA](https://packt.live/3gBTFGA).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Dqa2Id](https://packt.live/2Dqa2Id).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 2.01: Build a Multilayer Neural Network to Classify Sonar Signals'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s see how the solution looks. Remember—this is one solution, but there
    could be many variations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load and examine the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.37: Contents of sonar.csv'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_02_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.37: Contents of sonar.csv'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Observe that there are 60 features, and the target has two values—Rock and Mine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This means that this is a binary classification problem. Let's prepare the data
    before we build the neural network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Separate the features and the labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this code, `X_input` is selecting all the rows of all the columns except
    the `Class` column, and `Y_label` is just selecting the `Class` column.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Labels are in text format. We need to encode them as numbers before we can
    use them with our model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `reshape` function at the end will convert the labels into matrix format,
    which is expected by the model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Build the multilayer model with Keras:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can experiment with the number of layers and neurons, but the last layer
    can only have one neuron with a sigmoid activation function, since this is a binary
    classifier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the training parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The truncated output will be somewhat similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s evaluate the trained model and examine its accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, we have been able to successfully train a multilayer binary
    neural network and get 100% accuracy within 30 epochs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/38EMoDi](https://packt.live/38EMoDi).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2W2sygb](https://packt.live/2W2sygb).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3\. Image Classification with Convolutional Neural Networks (CNNs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 3.01: Building a Multiclass Classifier Based on the Fashion MNIST Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import `tensorflow.keras.datasets.fashion_mnist`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the Fashion MNIST dataset using `fashion_mnist.load_data()` and save the
    results to `(features_train, label_train), (features_test, label_test)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the shape of the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The training set is composed of `60000` images of size `28` by `28`. We will
    need to reshape it and add the channel dimension.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the shape of the testing set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The testing set is composed of `10000` images of size `28` by `28`. We will
    need to reshape it and add the channel dimension
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Reshape the training and testing sets with the dimensions `(number_rows, 28,
    28, 1)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three variables called `batch_size`, `img_height`, and `img_width` that
    take the values `16`, `28`, and `28`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageDataGenerator` called `train_img_gen` with data augmentation:
    `rescale=1./255, rotation_range=40, width_shift_range=0.1, height_shift_range=0.1,
    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=''nearest''`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageDataGenerator` called `val_img_gen` with rescaling (by dividing
    by 255):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `.flow()` and specify
    the batch size, features, and labels from the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `.flow()` and specify the
    batch size, features, and labels from the testing set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set `8` as the seed for `numpy` and `tensorflow` using `np.random_seed()` and
    `tf.random.set_seed()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `tf.keras.Sequential()` class into a variable called `model`
    with the following layers: A convolution layer with `64` kernels of shape `3`,
    `ReLU` as the activation function, and the necessary input dimensions; a max pooling
    layer; a convolution layer with `128` kernels of shape `3` and `ReLU` as the activation
    function; a max pooling layer; a flatten layer; a fully connected layer with `128`
    units and `ReLU` as the activation function; a fully connected layer with `10`
    units and `softmax` as the activation function.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `tf.keras.optimizers.Adam()` class with `0.001` as the learning
    rate and save it to a variable called optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the neural network using `.compile()` with `loss=''sparse_categorical_crossentropy'',
    optimizer=optimizer, metrics=[''accuracy'']`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the neural networks with `fit_generator()` and provide the train and validation
    data generators, `epochs=5`, the steps per epoch, and the validation steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.30: Model training log'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_03_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.30: Model training log'
  prefs: []
  type: TYPE_NORMAL
- en: We trained our CNN on five epochs, and we achieved accuracy scores of `0.8271`
    on the training set and `0.8334` on the validation set, respectively. Our model
    is not overfitting much and achieved quite a high score. The accuracy is still
    increasing after five epochs, so we may get even better results if we keep training
    it. This is something you may try by yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2ObmA8t](https://packt.live/2ObmA8t).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3fiyyJi](https://packt.live/3fiyyJi).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 3.02: Fruit Classification with Transfer Learning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import `tensorflow` as `tf`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `file_url` containing the link to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the aforementioned step, we are using the dataset stored at [https://packt.live/3eePQ8G](https://packt.live/3eePQ8G).
    If you have stored the dataset at any other URL, please change the highlighted
    path accordingly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Download the dataset using `tf.keras.get_file` with `''fruits360.zip'', origin=file_url,
    extract=True` as parameters and save the result to a variable called `zip_dir`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pathlib` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `path` containing the full path to the `fruits360_filtered`
    directory using `pathlib.Path(zip_dir).parent`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `train_dir` and `validation_dir` that take the
    full paths to the train (`Training`) and validation (`Test`) folders, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `total_train` and `total_val` that will get the
    number of images for the training and validation sets, that is, `11398` and `4752`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageDataGenerator` called `train_img_gen` with data augmentation:
    `rescale=1./255, rotation_range=40, width_shift_range=0.1, height_shift_range=0.1,
    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=''nearest''`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageDataGenerator` called `val_img_gen` with rescaling (by dividing
    by 255):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables called `batch_size`, `img_height`, `img_width`, and `channel`
    that take the values `16`, `100`, `100`, and `3`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `.flow_from_directory()`
    and specify the batch size, training folder, and target size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `.flow_from_directory()`
    and specify the batch size, validation folder, and target size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set `8` as the seed for `numpy` and `tensorflow` using `np.random_seed()` and
    `tf.random.set_seed()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `VGG16` from `tensorflow.keras.applications`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `VGG16` model into a variable called `base_model` with the following
    parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set this model to non-trainable using the `.trainable` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the summary of this `VGG16` model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.31: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_03_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.31: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This output shows us the architecture of `VGG16`. We can see that there are
    `14,714,688` parameters in total, but there is no trainable parameter. This is
    expected as we have frozen all the layers of this model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a new model using `tf.keras.Sequential()` by adding the base model to
    the following layers: `Flatten()`, `Dense(1000, activation=''relu'')`, and `Dense(120,
    activation=''softmax'')`. Save this model to a variable called `model`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `tf.keras.optimizers.Adam()` class with `0.001` as the learning
    rate and save it to a variable called `optimizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the neural network using `.compile()` with `loss=''categorical_crossentropy'',
    optimizer=optimizer, metrics=[''accuracy'']`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the neural networks with `fit_generator()` and provide the train and validation
    data generators, `epochs=5`, the steps per epoch, and the validation steps. This
    model may take a few minutes to train:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.32: Expected output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_03_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.32: Expected output'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we used transfer learning to customize a pretrained `VGG16` model on ImageNet
    so that it fits our fruit classification dataset. We replaced the head of the
    model with our own fully connected layers and trained these layers on five epochs.
    We achieved an accuracy score of `0.9106` for the training set and `0.8920` for
    the testing set. These are quite remarkable results given the time and hardware
    used to train this model. You can try to fine-tune this model and see whether
    you can achieve an even better score.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2DsVRCl](https://packt.live/2DsVRCl).
  prefs: []
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Deep Learning for Text – Embeddings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 4.01: Text Preprocessing of the ''Alice in Wonderland'' Text'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You need to perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Before commencing this activity, make sure you have defined the `alice_raw`
    variable as demonstrated in the section titled *Downloading Text Corpora Using
    NLTK*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Change the data to lowercase and separate into sentences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Tokenize the sentences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `punctuation` from the `string` module and `stopwords` from NLTK:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable holding the contextual stop words `--` and `said`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a master list for the stop words to remove words that contain terms
    from punctuation, NLTK stop words, and contextual stop words:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to drop these tokens from any input sentence (tokenized):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Remove the terms in `stop_final` from the tokenized text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s what the first two sentences look like:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `PorterStemmer` algorithm from NLTK, perform stemming on the result.
    Print out the first five sentences of the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2VVNEgf](https://packt.live/2VVNEgf).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/38Gr54r](https://packt.live/38Gr54r).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Activity 4.02: Text Representation for Alice in Wonderland'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You need to perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From *Activity 4.01*, *Text Preprocessing Alice in Wonderland*, print the first
    three sentences from the result after stop word removal. This is the data you
    will work with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `word2vec` from Gensim and train your word embeddings with default parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the `5` terms most similar to `rabbit`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using a `window` size of `2`, retrain the word vectors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the terms most similar to `rabbit`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrain word vectors using the Skip-gram method with a window size of `5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the terms most similar to `rabbit`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the representation for the phrase `white rabbit` by averaging the vectors
    for `white` and `rabbit`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the representation for `mad hatter` by averaging the vectors for `mad`
    and `hatter`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the cosine similarity between these two phrases:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives us the following value:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the pre-trained GloVe embeddings of size 100D using the formatted keyed vectors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find representations for `white rabbit` and `mad hatter`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Find the `cosine` similarity between the two phrases. Has the cosine similarity changed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is the output of the preceding code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we can see that the cosine similarity between the two phrases "`mad hatter`"
    and "`white rabbit`" is far lower from the GloVe model. This is because the GloVe
    model hasn't seen the terms together in its training data as much as they appear
    in the book. In the book, the terms `mad` and `hatter` appear together a lot because
    they form the name of an important character. In other contexts, of course, we
    don't see `mad` and `hatter` together as often.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2VVNEgf](https://packt.live/2VVNEgf).
  prefs: []
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Deep Learning for Sequences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 5.01: Using a Plain RNN Model to Predict IBM Stock Prices'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Import the necessary libraries, load the `.csv` file, reverse the index, and
    plot the time series (the `Close` column) for visual inspection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows, with the closing price plotted on the *Y-axis*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.40: The trend for IBM stock prices'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_05_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.40: The trend for IBM stock prices'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the values for `Close` from the DataFrame as a `numpy` array and plot
    them using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting trend is as follows, with the index plotted on the *X-axis*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.41: The stock price data visualized'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_05_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.41: The stock price data visualized'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Assign the final 25% data as test data and the first 75% as train data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `MinMaxScaler` from `sklearn`, scale the train and test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the `get_lookback` function we defined earlier in this chapter (refer
    to the *Preparing the Data for Stock Price Prediction* section), get the lookback
    data for the train and test sets using a lookback period of 10:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From Keras, import all the necessary layers for employing plain RNNs (`SimpleRNN`,
    `Activation`, `Dropout`, `Dense`, and `Reshape`) and 1D convolutions (Conv1D).
    Also, import the `mean_squared_error` metric from `sklearn`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build a model with a 1D convolution layer (5 filters of size 3) and an RNN
    layer with 32 neurons. Add 25% dropout after the RNN layer. Print the model''s summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.42: Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_05_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.42: Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile the model with the `mean_squared_error` loss and the `adam` optimizer.
    Fit this on the train data in five epochs, with a validation split of 10% and
    a batch size of 1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.43: Training and validation loss'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_05_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.43: Training and validation loss'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using the `get_model_perf` method, print the RMSE of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the predictions – the entire view, as well as the zoomed-in view:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should see the following plot of predictions (dotted lines) versus the actuals
    (solid lines):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.44: Predictions versus actuals'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_05_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.44: Predictions versus actuals'
  prefs: []
  type: TYPE_NORMAL
- en: 'The zoomed-in view is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.45: Predictions (dotted lines) versus actuals (solid lines) – detailed
    view'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15385_05_45.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.45: Predictions (dotted lines) versus actuals (solid lines) – detailed
    view'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the model does a great job of catching the finer patterns and
    does extremely well at predicting the daily stock price.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2ZctArW](https://packt.live/2ZctArW).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/38EDOEA](https://packt.live/38EDOEA).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. LSTMs, GRUs, and Advanced RNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 6.01: Sentiment Analysis of Amazon Product Reviews'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Read in the data files for the `train` and `test` sets. Examine the shapes
    of the datasets and print out the top `5` records from the `train` data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The dataset''s shape and header are as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.26: First five records from the train dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_06_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.26: First five records from the train dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For convenience, when it comes to processing, separate the raw text and the
    labels for the `train` and `test` sets. You should have `4` variables, as follows:
    `train_raw` comprising raw text for the train data, `train_labels` with labels
    for the train data, `test_raw` containing raw text for the test data, and `test_labels`
    comprising Labels for the test data. Print the first two reviews from the `train`
    text.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code results in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.27: Raw text from the train dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_06_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.27: Raw text from the train dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Normalize the case and tokenize the test and train texts using NLTK''s `word_tokenize`
    (after importing it, of course – hint: use a list comprehension for cleaner code).
    Download `punkt` from `nltk` if you haven''t used the tokenizer before. Print
    the first review from the train data to check if the tokenization worked.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The tokenized data gets printed as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.28: Tokenized review from the train dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_06_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.28: Tokenized review from the `train` dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import any stop words (built in to NLTK) and punctuation from the string module.
    Define a function (`drop_stop`) to remove these tokens from any input tokenized
    sentence. Download `stopwords` from NLTK if you haven''t used it before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the defined function (`drop_stop`), remove the redundant stop words from
    the `train` and the `test` texts. Print the first review of the processed `train`
    texts to check whether the function worked:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `PorterStemmer` from NLTK, stem the tokens for both the `train` and `test`
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result should be printed as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the strings for each of the `train` and `text` reviews. This will help
    us work with the utilities in Keras to create and pad the sequences. Create the
    `train_texts` and `test_texts` variables. Print the first review from the processed
    `train` data to confirm this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result of the preceding code is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From Keras'' preprocessing utilities for text (`keras.preprocessing.text`),
    import the `Tokenizer` module. Define a vocabulary size of `10000` and instantiate
    the tokenizer with this vocabulary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the tokenizer on the `train` texts. This works just like `CountVectorizer`
    did in *Chapter 4, Deep Learning for Text – Embeddings*, and trains the vocabulary.
    After fitting, use the `texts_to_sequences` method of the tokenizer on the `train`
    and `test` sets to create the sequences for them. Print the sequence for the first
    review in the train data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The encoded sequence is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to find the optimal length of the sequences to process the model. Get
    the length of the reviews from the `train` set into a list and plot a histogram
    of the lengths:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The distribution of the lengths is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.29: Histogram of text lengths'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_06_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.29: Histogram of text lengths'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The data is now in the same format as the IMDb data we used in this chapter.
    Using a sequence length of `100` (define the `maxlen = 100` variable), use the
    `pad_sequences` method from the `sequence` module in Keras'' preprocessing utilities
    (`keras.preprocessing.sequence`) to limit the sequences to `100` for both the
    `train` and `test` data. Check the shape of the result for the train data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The shape is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To build the model, import all the necessary layers from Keras (`embedding`,
    `spatial dropout`, `LSTM`, `dropout`, and `dense`) and import the `Sequential`
    model. Initialize the `Sequential` model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an embedding layer with `32` as the vector size (`output_dim`). Add a spatial
    dropout of `40%`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build a stacked LSTM model with `2` layers that have `64` cells each. Add a
    dropout layer with `40%` dropout:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a dense layer with `32` neurons with `relu` activation, then a `50%` dropout
    layer, followed by another dense layer of `32` neurons with `relu` activation,
    and follow this up with another dropout layer with `50%` dropout:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add a final dense layer with a single neuron with `sigmoid` `activation` and
    compile the model. Print the model summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The summary of the model will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.30: Stacked LSTM model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_06_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.30: Stacked LSTM model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fit the model on the training data with a `20%` validation split and a batch
    size of `128`. Train for `5` `epochs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will get the following training output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.31: Stacked LSTM model training output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_06_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.31: Stacked LSTM model training output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Make a prediction on the test set using the `predict_classes` method of the
    model. Then, print out the confusion matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will get the following result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using the `accuracy_score` method from `scikit-learn`, calculate the accuracy
    of the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The accuracy we get is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can see, the accuracy score is around `86%`, and looking at the confusion
    matrix (output of *step 18*), the model does a decent job of predicting both classes
    well. We got this accuracy without doing any hyperparameter tuning. You can tweak
    the hyperparameters to get significantly higher accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3fpo0YI](https://packt.live/3fpo0YI).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Wi75QH](https://packt.live/2Wi75QH).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Generative Adversarial Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 7.01: Implementing a DCGAN for the MNIST Fashion Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and name it `Activity 7.01`. Import the following
    library packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function that will generate real data samples from the fashion MNIST data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output from this function is the batch of MNIST data. Please note that we
    normalize the input data by subtracting `127.5`, which is half the max pixel value,
    and dividing by the same value. This will help in converging the solution faster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s generate a set of images from the MNIST dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.36: Generating images from MNIST'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.36: Generating images from MNIST'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s visualize the images with `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the one shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.37: Plotted images'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.37: Plotted images'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the output, we can see the visualization of several fashion articles. We
    can see that the images are centrally located within a white background. This
    are the images that we'll try to recreate.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s define the function to generate inputs for the generator network.
    The inputs are random data points that are generated from a random uniform distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function generates the fake data that was sampled from the random distribution
    as the output.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s define the function for building the generator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Building the generator network is similar to building any CNN network. In this
    generator network, we will use the transpose convolution method for upsampling
    images. In this model, we can see the progressive use of the transpose convolution.
    The initial input starts with a dimension of 100, which is our input feature.
    The dimension of the MNIST dataset is batch size x 28 x 28\. Therefore, we have
    upsampled the data twice to get the output as batch size x 28 x 28.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we define the function that will be used to create fake samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this function, we only return the `X` variable. The output from this function
    is the fake dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the parameters that we will use in many of the functions, along with
    the summary of the generator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.38: Summary of the generative model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.38: Summary of the generative model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the summary, please note how the dimension of the input noise changes with
    each transpose convolution operation. Finally, we get an output that is equal
    in dimension to the real dataset, `( None,28 ,28,1)`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s use the generator function to generate a fake sample before training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s plot the generated fake sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.39: Output of the fake sample'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.39: Output of the fake sample'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the plot of the fake sample before training. After training, we want
    samples like these to look like the MNIST fashion samples we visualized earlier
    in this activity.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Build the discriminator model as a function. The network architecture will
    be similar to a CNN architecture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the discriminator network, we have included all the necessary layers, such
    as the convolutional operations and `LeakyReLU`. Please note that the last layer
    is a sigmoid layer as we want the output as a probability of whether the sample
    is real (1) or fake (0).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the summary of the discriminator network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.40: Discriminator model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.40: Discriminator model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the GAN model as a function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The structure of the GAN model is similar to the one we developed in *Exercise
    7.05*, *Implementing the DCGAN*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, it''s time to invoke the GAN function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Please note that the inputs to the GAN model are the previously defined generator
    model and the discriminator model. You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.41: GAN model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.41: GAN model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Please note that the parameters of each layer of the GAN model are equivalent
    to the parameters of the generator and discriminator models. The GAN model is
    just a wrapper around the two models we defined earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the number of epochs to train the network on using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can start the process of training the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It needs to be noted here that the training of the discriminator model with
    the fake and real samples and the training of the GAN model happens concurrently.
    The only difference is the training of the GAN model proceeds without updating
    the parameters of the discriminator model. The other thing to note is that, inside
    the GAN, the labels for the fake samples would be 1 to generate large loss terms
    that will be backpropagated through the discriminator network to update the generator
    parameters. We also display the predicted probability of the GAN for every 50
    epochs. When calculating the probability, we combine a sample of real data and
    a sample of fake data and then take the mean of the predicted probability. We
    also save a copy of the generated image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You should get an output similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s also look at some of the plots that were generated from the training
    process at various epochs:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.42: Images generated during the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.42: Images generated during the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the preceding plots, we can see the progression of the training process.
    We can see that by epoch 100, the plots were mostly noise. By epoch 600, the forms
    of the fashion articles started to become more pronounced. At epoch 1,500, we
    can see that the fake images are looking very similar to the fashion dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Note:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can take a closer look at these images by going to [https://packt.live/2W1FjaI](https://packt.live/2W1FjaI).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s look at the images that were generated after training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.43: Images generated after the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15385_07_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.43: Images generated after the training process'
  prefs: []
  type: TYPE_NORMAL
- en: From the training accuracy levels, you can see that the accuracy of the discriminator
    model hovers around the .50 range, which is the desired range. The purpose of
    the generator is to create fake images that look like real ones. When the generator
    generates images that look very similar to real images, the discriminator gets
    confused as to whether the image has been generated from the real distribution
    or fake distribution. This phenomenon manifests in an accuracy level of around
    50% for the discriminator, which is the desired level.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3fpobDm](https://packt.live/3fpobDm).
  prefs: []
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs: []
  type: TYPE_NORMAL
