- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building a Reward Matrix – Designing Your Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Experimenting and implementation comprise the two main approaches of artificial
    intelligence. Experimenting largely entails trying ready-to-use datasets and black
    box, ready-to-use Python examples. Implementation involves preparing a dataset,
    developing preprocessing algorithms, and then choosing a model, the proper parameters,
    and hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation usually involves white box work that entails knowing exactly
    how an algorithm works and even being able to modify it.
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 1*, *Getting Started with Next-Generation Artifcial Intelligence
    through Reinforcement Learning*, the MDP-driven Bellman equation relied on a reward
    matrix. In this chapter, we will get our hands dirty in a white box process to
    create that reward matrix.
  prefs: []
  type: TYPE_NORMAL
- en: An MDP process cannot run without a reward matrix. The reward matrix determines
    whether it is possible to go from one cell to another, from A to B. It is like
    a map of a city that tells you if you are allowed to take a street or if it is
    a one-way street, for example. It can also set a goal, such as a place that you
    would like to visit in a city, for example.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve the goal of designing a reward matrix, the raw data provided by other
    systems, software, and sensors needs to go through **preprocessing**. A machine
    learning program will not provide efficient results if the data has not gone through a **standardization**
    process.
  prefs: []
  type: TYPE_NORMAL
- en: The reward matrix, *R*, will be built using a McCulloch-Pitts neuron in TensorFlow.
    Warehouse management has grown exponentially as e-commerce has taken over many
    marketing segments. This chapter introduces automated guided vehicles (AGVs),
    the equivalent of an SDC in a warehouse to store and retrieve products.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge in this chapter will be to understand the preprocessing phase
    in detail. The quality of the processed dataset will influence directly the accuracy
    of any machine learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The McCulloch-Pitts neuron will take the raw data and transform it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic classifiers will begin the neural network process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The logistic sigmoid will squash the values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The softmax function will normalize the values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The one-hot function will choose the target for the reward matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of AGVs in a warehouse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The topics form a list of tools that, in turn, form a pipeline that will take
    raw data and transform it into a reward matrix—an MDP.
  prefs: []
  type: TYPE_NORMAL
- en: Designing datasets – where the dream stops and the hard work begins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As in the previous chapter, bear in mind that a real-life project goes through
    a three-dimensional method in some form or other. First, it's important to think
    and talk about the problem in need of solving without jumping onto a laptop. Once
    that is done, bear in mind that the foundation of machine learning and deep learning
    relies on mathematics. Finally, once the problem has been discussed and mathematically
    represented, it is time to develop the solution.
  prefs: []
  type: TYPE_NORMAL
- en: First, think of a problem in **natural language**. Then, make a **mathematical
    description** of a problem. Only then should you begin the **software implementation**.
  prefs: []
  type: TYPE_NORMAL
- en: Designing datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The reinforcement learning program described in the first chapter can solve
    a variety of problems involving unlabeled classification in an unsupervised decision-making
    process. The Q function can be applied to drone, truck, or car deliveries. It
    can also be applied to decision making in games or real life.
  prefs: []
  type: TYPE_NORMAL
- en: However, in a real-life case study problem (such as defining the reward matrix
    in a warehouse for the AGV, for example), the difficulty will be to produce an
    efficient matrix using the proper **features**.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, an AGV requires information coming from different sources: daily
    forecasts and real-time warehouse flows.'
  prefs: []
  type: TYPE_NORMAL
- en: The warehouse manages thousands of locations and hundreds of thousands of inputs
    and outputs. Trying to fit too many features into the model would be counterproductive.
    Removing both features and worthless data requires careful consideration.
  prefs: []
  type: TYPE_NORMAL
- en: A simple neuron can provide an efficient way to attain the **standardization**
    of the input data.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning and deep learning are frequently used to preprocess input data
    for standardization purposes, normalization, and feature reduction.
  prefs: []
  type: TYPE_NORMAL
- en: Using the McCulloch-Pitts neuron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create the reward matrix, *R*, a robust model for processing the inputs of
    the huge volumes in a warehouse must be reduced to a limited number of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'In one model, for example, the thousands to hundreds of thousands of inputs
    can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Forecast product arrivals with a low priority weight: *w*[1] = 10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Confirmed arrivals with a high priority weight: *w*[2] = 70'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Unplanned arrivals decided by the sales department: *w*[3] = 75'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Forecasts with a high priority weight: *w*[4] = 60'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Confirmed arrivals that have a low turnover and so have a low weight: *w*[5]
    = 20'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The weights have been provided as constants. A McCulloch-Pitts neuron does not
    modify weights. A perceptron neuron does as we will see beginning with *Chapter
    8*, *Solving the XOR Problem with a Feedforward Neural Network*. Experience shows
    that modifying weights is not always necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'These weights form a vector, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_001.png)'
  prefs: []
  type: TYPE_IMG
- en: Each element of the vector represents the weight of a feature of a product stored
    in optimal locations. The ultimate phase of this process will produce a reward
    matrix, *R*, for an MDP to optimize itineraries between warehouse locations.
  prefs: []
  type: TYPE_NORMAL
- en: Let's focus on our neuron. These weights, used through a system such as this
    one, can attain up to more than 50 weights and parameters per neuron. In this
    example, 5 weights are implemented. However, in real-life case, many other parameters
    come into consideration, such as unconfirmed arrivals, unconfirmed arrivals with
    a high priority, confirmed arrivals with a very low priority, arrivals from locations
    that probably do not meet security standards, arrivals with products that are
    potentially dangerous and require special care, and more. At that point, humans
    and even classical software cannot face such a variety of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The reward matrix will be size 6×6\. It contains six locations, A to F. In this
    example, the six locations, `l1` to `l6`, are warehouse storage and retrieval
    locations.
  prefs: []
  type: TYPE_NORMAL
- en: A 6×6 reward matrix represents the target of the McCulloch-Pitts layer implemented
    for the six locations.
  prefs: []
  type: TYPE_NORMAL
- en: When experimenting, the reward matrix, *R*, can be invented for testing purposes.
    In real-life implementations, you will have to find a way to build datasets from
    scratch. The reward matrix becomes the output of the preprocessing phase. The
    following source code shows the input of the reinforcement learning program used
    in the first chapter. The goal of this chapter describes how to produce the following
    reward matrix that we will be building in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For the warehouse example that we are using as for any other domain, the McCulloch-Pitts
    neuron sums up the weights of the input vector described previously to fill in
    the reward matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Each location will require its neuron, with its weights.
  prefs: []
  type: TYPE_NORMAL
- en: '*INPUTS* -> *WEIGHTS* -> *BIAS* -> *VALUES*'
  prefs: []
  type: TYPE_NORMAL
- en: Inputs are the flows in a warehouse or any form of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weights will be defined in this model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bias is for stabilizing the weights. Bias does exactly what it means. It will
    tilt weights. It is very useful as a referee that will keep the weights on the
    right track.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Values will be the output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are as many ways as you can imagine to create reward matrices. This chapter
    describes one way of doing it that works.
  prefs: []
  type: TYPE_NORMAL
- en: The McCulloch-Pitts neuron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The McCulloch-Pitts neuron dates back to 1943\. It contains inputs, weights,
    and an activation function. Part of the preprocessing phase consists of selecting
    the right model. The McCulloch-Pitts neuron can represent a given location efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the McCulloch-Pitts neuron model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_01-2.png](img/B15438_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: The McCulloch-Pitts neuron model'
  prefs: []
  type: TYPE_NORMAL
- en: This model contains several input *x* weights that are summed to either reach
    a threshold that will lead, once transformed, to the output, *y* = 0, or 1\. In
    this model, *y* will be calculated in a more complex way.
  prefs: []
  type: TYPE_NORMAL
- en: '`MCP.py` written with TensorFlow 2 will be used to illustrate the neuron.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following source code, the TensorFlow variables will contain the input
    values (`x`), the weights (`W`), and the bias (`b`). Variables represent the structure
    of your graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the original McCulloch-Pitts artificial neuron, the inputs (*x*) were multiplied
    by the following weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The mathematical function becomes a function with the neuron code triggering
    a logistic activation function (sigmoid), which will be explained in the second
    part of the chapter. Bias (`b`) has been added, which makes this neuron format
    useful even today, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Before starting a session, the McCulloch-Pitts neuron (1943) needs an operator
    to set its weights. That is the main difference between the McCulloch-Pitts neuron
    and the perceptron (1957), which is the model for modern deep learning neurons.
    The perceptron optimizes its weights through optimizing processes. *Chapter 8*,
    *Solving the XOR Problem with a Feedforward Neural Network*, describes why a modern
    perceptron was required.
  prefs: []
  type: TYPE_NORMAL
- en: 'The weights are now provided, and so are the quantities for each input value,
    which are stored in the *x* vector at *l*[1], one of the six locations of this
    warehouse example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The weight values will be divided by 100, to represent percentages in terms
    of 0 to 1 values of warehouse flows in a given location. The following code deals
    with the choice of *one* location, *l*[1] **only**, its values, and parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The neuron function is called, and the weights (`w_t`) and the quantities (`x_1`)
    of the warehouse flow are entered. Bias is set to `1` in this model. No session
    needs to be initialized; the neuron function is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The neuron function `neuron` will calculate the value of the neuron. The program
    returns the following value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This value represents the activity of location *l*[1] at a given date and a
    given time. This example represents only one of the six locations to compute.
    For this location, the higher the value, the closer to 1, the higher the probable
    saturation rate of this area. This means there is little space left to store products
    at that location. That is why the reinforcement learning program for a warehouse
    is looking for the **least loaded** area for a given product in this model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each location has a probable **availability**:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A* = Availability = 1 – load'
  prefs: []
  type: TYPE_NORMAL
- en: The probability of a load of a given storage point lies between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'High values of availability will be close to 1, and low probabilities will
    be close to 0, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For example, the load of *l*[1] has a probable rounded load of 0.99, and its
    probable *availability* is 0.002 maximum. The goal of the AGV is to search and
    find the closest and most available location to optimize its trajectories. *l*[1]
    is not a good candidate at that day and time. **Load** is a keyword in production
    or service activities. The less available resources have the highest load rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'When all six locations'' availabilities have been calculated by the McCulloch-Pitts
    neuron—each with its respective quantity inputs, weights, and bias—a location
    vector of the results of this system will be produced. Then, the program needs
    to be implemented to run all six locations and not just one location through a
    recursive use of the one neuron model:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A*(*L*) = {*a*(*l*[1]),*a*(*l*[2]),*a*(*l*[3]),*a*(*l*[4]),*a*(*l*[5]),*a*(*l*[6])}'
  prefs: []
  type: TYPE_NORMAL
- en: The availability, 1 – *output value of the neuron*, constitutes a six-line vector.
    The following vector, *l*[v], will be obtained by running the previous sample
    code on **all** six locations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_004.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding formula, *l*[v] is the vector containing the value
    of each location for a given AGV to choose from. The values in the vector represent
    availability. 0.0002 means little availability; 0.9 means high availability. With
    this choice, the MDP reinforcement learning program will optimize the AGV's trajectory
    to get to this specific warehouse location.
  prefs: []
  type: TYPE_NORMAL
- en: The *l*[v] is the result of the weighing function of six potential locations
    for the AGV. It is also a vector of transformed inputs.
  prefs: []
  type: TYPE_NORMAL
- en: The Python-TensorFlow architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Implementation of the McCulloch-Pitts neuron can best be viewed as shown in
    the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_02-3.png](img/B15438_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Implementation of the McCulloch-Pitts neuron'
  prefs: []
  type: TYPE_NORMAL
- en: A data flow graph will also help optimize a program when things go wrong as
    in classical computing.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic activation functions and classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that the value of each location of *L* = {*l*[1], *l*[2], *l*[3], *l*[4],
    *l*[5], *l*[6]} contains its availability in a vector, the locations can be sorted
    from the most available to the least available location. From there, the reward
    matrix, *R*, for the MDP process described in *Chapter 1*, *Getting Started with
    Next-Generation Artifcial Intelligence through Reinforcement Learning*, can be
    built.
  prefs: []
  type: TYPE_NORMAL
- en: Overall architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At this point, the overall architecture contains two main components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Chapter 1**: A reinforcement learning program based on the value-action Q
    function using a reward matrix that will be finalized in this chapter. The reward
    matrix was provided in the first chapter as an experiment, but in the implementation
    phase, you''ll often have to build it from scratch. It sometimes takes weeks to
    produce a good reward matrix.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Chapter 2**: Designing a set of 6×1 neurons that represents the flow of products
    at a given time at six locations. The output is the availability probability from
    0 to 1\. The highest value indicates the highest availability. The lowest value
    indicates the lowest availability.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, there is some real-life information we can draw from these two
    main functions through an example:'
  prefs: []
  type: TYPE_NORMAL
- en: An AGV is automatically moving in a warehouse and is waiting to receive its
    next location to use an MDP, to calculate the optimal trajectory of its mission.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AGV is using a reward matrix, *R*, that was given during the experimental
    phase but needed to be designed during the implementation process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A system of six neurons, one per location, weighing the real quantities and probable
    quantities to give an availability vector, *l*[v], has been calculated. It is
    almost ready to provide the necessary reward matrix for the AGV.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To calculate the input values of the reward matrix in this reinforcement learning
    warehouse model, a bridge function between *l*[v] and the reward matrix, *R*,
    is missing.
  prefs: []
  type: TYPE_NORMAL
- en: That bridge function is a logistic classifier based on the outputs of the *n*
    neurons that all perform the same tasks independently or recursively with one
    neuron.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, the system:'
  prefs: []
  type: TYPE_NORMAL
- en: Took corporate data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Used *n* neurons calculated with weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applied an activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The activation function in this model requires a logistic classifier, a commonly
    used one.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The logistic classifier will be applied to *l*[v] (the six location values)
    to find the best location for the AGV. This method can be applied to any other
    domain. It is based on the output of the six neurons as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*input* × *weight* + *bias*'
  prefs: []
  type: TYPE_NORMAL
- en: What are logistic functions? The goal of a logistic classifier is to produce
    a probability distribution from 0 to 1 for each value of the output vector. As
    you have seen so far, artificial intelligence applications use applied mathematics
    with probable values, not raw outputs.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason is that machine learning/deep learning works best with standardization
    and normalization for workable homogeneous data distributions. Otherwise, the
    algorithms will often produce underfitted or overfitted results.
  prefs: []
  type: TYPE_NORMAL
- en: In the warehouse model, for example, the AGV needs to choose the best, most
    probable location, *l*[i]. Even in a well-organized corporate warehouse, many
    uncertainties (late arrivals, product defects, or some unplanned problems) reduce
    the probability of a choice. A probability represents a value between 0 (low probability)
    and 1 (high probability). Logistic functions provide the tools to convert all
    numbers into probabilities between 0 and 1 to *normalize* data.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The logistic sigmoid provides one of the best ways to normalize the weight of
    a given output. The activation function of the neuron will be the logistic sigmoid.
    The threshold is usually a value above which the neuron has a *y* = 1 value; or
    else it has a *y* = 0 value. In this model, the minimum value will be 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logistic function is represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_005.png)'
  prefs: []
  type: TYPE_IMG
- en: '*e* represents Euler''s number, or 2.71828, the natural logarithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x* is the value to be calculated. In this case, *s* is the result of the logistic
    sigmoid function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code has been rearranged in the following example to show the reasoning
    process that produces the output, `y`, of the neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to the logistic sigmoid function, the value for the first location in
    the model comes out squashed between 0 and 1 as 0.99, indicating a high probability
    that this location will be full.
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the availability of the location once the 0.99 value has been
    taken into account, we subtract the load from the total availability, which is
    1, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Availability = 1 – probability of being full (value)
  prefs: []
  type: TYPE_NORMAL
- en: Or
  prefs: []
  type: TYPE_NORMAL
- en: availability = 1 – value
  prefs: []
  type: TYPE_NORMAL
- en: As seen previously, once all locations are calculated in this manner, a final
    availability vector, *l*[v], is obtained.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_004.png)'
  prefs: []
  type: TYPE_IMG
- en: When analyzing *l*[v], a problem has stopped the process. Individually, each
    line appears to be fine. By applying the logistic sigmoid to each output weight
    and subtracting it from 1, each location displays a probable availability between
    0 and 1\. However, the sum of the lines in *l*[v] exceeds 1\. That is not possible.
    A probability cannot exceed 1\. The program needs to fix that.
  prefs: []
  type: TYPE_NORMAL
- en: Each line produces a [0, 1] solution, which fits the prerequisite of being a
    valid probability.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the vector *l*[v] contains more than one value and becomes a probability
    distribution. The sum of *l*[v] cannot exceed 1 and needs to be normalized.
  prefs: []
  type: TYPE_NORMAL
- en: The *softmax* function provides an excellent method to normalize *l*[v]. Softmax
    is widely used in machine learning and deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Bear in mind that *mathematical tools are not rules*. You can adapt them to
    your problem as much as you wish as long as your solution works.
  prefs: []
  type: TYPE_NORMAL
- en: Softmax
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The softmax function appears in many artificial intelligence models to normalize
    data. Softmax can be used for classification purposes and regression. In our example,
    we will use it to find an optimized goal for an MDP.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the warehouse example, an AGV needs to make a probable choice
    between six locations in the *l*[v] vector. However, the total of the *l*[v] values
    exceeds 1. *l*[v] requires normalization of the softmax function, *S*. In the
    source code, the *l*[v] vector will be named `y`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_007.png)'
  prefs: []
  type: TYPE_IMG
- en: The following code used is `SOFTMAX.py`.
  prefs: []
  type: TYPE_NORMAL
- en: '`y` represents the *l*[v] vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![](img/B15438_02_008.png) is the *exp*(*i*) result of each value in `y` (*l*[v]
    in the warehouse example), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![](img/B15438_02_009.png) is the sum of ![](img/B15438_02_010.png) as shown
    in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, each value of the vector is normalized by applying the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B15438_02_011.png)'
  prefs: []
  type: TYPE_IMG
- en: softmax(*l*[v]) provides a normalized vector with a sum equal to 1, as shown
    in this compressed version of the code. The vector obtained is often described
    as containing logits.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows one version of a softmax function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '*l*[v] is now normalized by softmax(*l*[v]) as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The last part of the softmax function requires softmax(*l*[v]) to be rounded
    to 0 or 1\. The higher the value in softmax(*l*[v]), the more probable it will
    be. In clear-cut transformations, the highest value will be close to 1, and the
    others will be closer to 0\. In a decision-making process, the highest value needs
    to be established as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output value is `0.273` and has been chosen as the most probable location.
    It is then set to 1, and the other, lower values are set to 0\. This is called
    a one-hot function. This one-hot function is extremely helpful for encoding the
    data provided. The vector obtained can now be applied to the reward matrix. The
    value 1 probability will become 100 in the *R* reward matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15438_02_013.png)'
  prefs: []
  type: TYPE_IMG
- en: The softmax function is now complete. Location *l*[3] or **C** is the best solution
    for the AGV. The probability value is multiplied by 100, and the reward matrix,
    *R*, can now receive the input.
  prefs: []
  type: TYPE_NORMAL
- en: Before continuing, take some time to play around with the values in the source
    code and run it to become familiar with the softmax function.
  prefs: []
  type: TYPE_NORMAL
- en: We now have the data for the reward matrix. The best way to understand the mathematical
    aspect of the project is to draw the result on a piece of paper using the actual
    warehouse layout from locations **A** to **F**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Line **C** of the reward matrix ={0, 0, 100, 0, 0, 0}, where **C** (the third
    value) is now the target for the self-driving vehicle, in this case, an AGV in
    a warehouse.
  prefs: []
  type: TYPE_NORMAL
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_03-2.png](img/B15438_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Illustration of a warehouse transport problem'
  prefs: []
  type: TYPE_NORMAL
- en: 'We obtain the following reward matrix, *R*, described in *Chapter 1*, *Getting
    Started with Next-Generation Artificial Intelligence through Reinforcement Learning*:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **State/values** | **A** | **B** | **C** | **D** | **E** | **F** |'
  prefs: []
  type: TYPE_TB
- en: '| **A** | - | - | - | - | 1 | - |'
  prefs: []
  type: TYPE_TB
- en: '| **B** | - | - | - | 1 | - | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **C** | - | - | 100 | 1 | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| **D** | - | 1 | 1 | - | 1 | - |'
  prefs: []
  type: TYPE_TB
- en: '| **E** | 1 | - | - | 1 | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| **F** | - | 1 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: 'This reward matrix is exactly the one used in the Python reinforcement learning
    program using the Q function from *Chapter 1*. The output of this chapter is thus
    the input of the *R* matrix. The 0 values are there for the agent to avoid those
    values. The 1 values indicate the reachable cells. The 100 in the C×C cell is
    the result of the softmax output. This program is designed to stay close to probability
    standards with positive values, as shown in the following *R* matrix taken from
    the `mdp01.py` of *Chapter 1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point:'
  prefs: []
  type: TYPE_NORMAL
- en: The output of the functions in this chapter generated a reward matrix, *R*,
    which is the input of the MDP described in *Chapter 1, Getting Started with Next-Generation
    Artificial Intelligence through Reinforcement Learning*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The MDP process was set to run for 50,000 episodes in *Chapter 1*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output of the MDP has multiple uses, as we saw in this chapter and *Chapter
    1*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The building blocks are in place to begin evaluating the execution and performances
    of the reinforcement learning program, as we will see in *Chapter 3*, *Machine
    Intelligence – Evaluation Functions and Numerical Convergence*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using a McCulloch-Pitts neuron with a logistic activation function in a one-layer
    network to build a reward matrix for reinforcement learning shows one way to preprocess
    a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Processing real-life data often requires a generalization of a logistic sigmoid
    function through a softmax function, and a one-hot function applied to logits
    to encode the data.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning functions are tools that must be understood to be able to use
    all or parts of them to solve a problem. With this practical approach to artificial
    intelligence, a whole world of projects awaits you.
  prefs: []
  type: TYPE_NORMAL
- en: This neuronal approach is the parent of the multilayer perceptron that will
    be introduced starting in *Chapter 8*, *Solving the XOR Problem with a Feedforward
    Neural Network*.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter went from an experimental black box machine learning and deep learning
    to white box implementation. Implementation requires a full understanding of machine
    learning algorithms that often require fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: However, artificial intelligence goes beyond understanding machine learning
    algorithms. Machine learning or deep learning require evaluation functions. Performance
    or results cannot be validated without evaluation functions, as explained in *Chapter
    3*, *Machine Intelligence – Evaluation Functions and Numerical Convergence*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, the evaluation process of machine intelligence will be
    illustrated by examples that show the limits of human intelligence and the rise
    of machine power.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Raw data can be the input to a neuron and transformed with weights. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does a neuron require a threshold? (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A logistic sigmoid activation function makes the sum of the weights larger.
    (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A McCulloch-Pitts neuron sums the weights of its inputs. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A logistic sigmoid function is a log10 operation. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A logistic softmax is not necessary if a logistic sigmoid function is applied
    to a vector. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A probability is a value between –1 and 1\. (Yes | No)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The original McCulloch-Pitts neuron 1943 paper: [http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf](http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TensorFlow variables: [https://www.tensorflow.org/beta/guide/variables](https://www.tensorflow.org/beta/guide/variables)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
