["```py\n    # Import the data\n    import pandas as pd\n    df = pd.read_csv(\"../data/pacific_hurricanes.csv\")\n    df.head() \n    ```", "```py\n    df['hurricane'].value_counts()\n    ```", "```py\n    0 22435\n    1 1842\n    Name: hurricane, dtype: int64\n    ```", "```py\n    df['hurricane'].value_counts(normalize=True).loc[0]\n    ```", "```py\n    0.9241257156979857\n    ```", "```py\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred_class)\nprint(cm)\n```", "```py\narray([[89, 2],\n       [13, 4]], dtype=int64)\n```", "```py\n# True Negative\nTN = cm[0,0]\n# False Negative\nFN = cm[1,0]\n# False Positives\nFP = cm[0,1]\n# True Positives\nTP = cm[1,1]\n```", "```py\n    #import the libraries\n    import numpy as np\n    import pandas as pd\n    # Load the Data\n    X = pd.read_csv(\"../data/aps_failure_training_feats.csv\")\n    y = pd.read_csv(\"../data/aps_failure_training_target.csv\")\n    # use the head function view the first 5 rows of the data\n    X.head()\n    ```", "```py\n    # Summary of Numerical Data\n    X.describe()\n    ```", "```py\n    y.head()\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    seed = 42\n    X_train, X_test, \\\n    y_train, y_test= train_test_split(X, y, test_size=0.20, \\\n                                      random_state=seed)\n    ```", "```py\n    # Initialize StandardScaler\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    # Transform the training data\n    X_train = sc.fit_transform(X_train)\n    X_train = pd.DataFrame(X_train,columns=X_test.columns)\n    # Transform the testing data\n    X_test = sc.transform(X_test)\n    X_test = pd.DataFrame(X_test,columns=X_train.columns)\n    ```", "```py\n    # Import the relevant Keras libraries\n    from keras.models import Sequential\n    from keras.layers import Dense\n    from keras.layers import Dropout\n    from tensorflow import random\n    ```", "```py\n    # Initiate the Model with Sequential Class\n    np.random.seed(seed)\n    random.set_seed(seed)\n    model = Sequential()\n    ```", "```py\n    # Add the hidden dense layers and with dropout Layer\n    model.add(Dense(units=64, activation='relu', \\\n                    kernel_initializer='uniform', \\\n                    input_dim=X_train.shape[1]))\n    model.add(Dropout(rate=0.5))\n    model.add(Dense(units=32, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.4))\n    model.add(Dense(units=16, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.3))\n    model.add(Dense(units=8, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.2))\n    model.add(Dense(units=4, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.1))\n    ```", "```py\n    # Add Output Dense Layer\n    model.add(Dense(units=1, activation='sigmoid', \\\n                    kernel_initializer='uniform'))\n    ```", "```py\n    # Compile the model\n    model.compile(optimizer='adam', \\\n                  loss='binary_crossentropy', \\\n                  metrics=['accuracy'])\n    ```", "```py\n    #Fit the Model\n    model.fit(X_train, y_train, epochs=100, \\\n              batch_size=20, verbose=1, \\\n              validation_split=0.2, shuffle=False)\n    ```", "```py\n    test_loss, test_acc = model.evaluate(X_test, y_test)\n    print(f'The loss on the test set is {test_loss:.4f} \\\n    and the accuracy is {test_acc*100:.4f}%')\n    ```", "```py\n    12000/12000 [==============================] - 0s 20us/step\n    The loss on the test set is 0.0802 and the accuracy is 98.9917%\n    ```", "```py\n    \"\"\"\n    Use the value_count function to calculate distinct class values\n    \"\"\"\n    y_test['class'].value_counts()\n    ```", "```py\n    0    11788\n    1      212\n    Name: class, dtype: int64\n    ```", "```py\n    # Calculate the null accuracy \n    y_test['class'].value_counts(normalize=True).loc[0]\n    ```", "```py\n    0.9823333333333333\n    ```", "```py\n    # Import the libraries\n    import numpy as np\n    import pandas as pd\n    # Load the Data\n    X = pd.read_csv(\"../data/aps_failure_training_feats.csv\")\n    y = pd.read_csv(\"../data/aps_failure_training_target.csv\")\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    seed = 42\n    X_train, X_test, \\\n    y_train, y_test = train_test_split(X, y, \\\n                      test_size=0.20, random_state=seed)\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    # Transform the training data\n    X_train = sc.fit_transform(X_train)\n    X_train = pd.DataFrame(X_train,columns=X_test.columns)\n    # Transform the testing data\n    X_test = sc.transform(X_test)\n    X_test = pd.DataFrame(X_test,columns=X_train.columns)\n    ```", "```py\n    # Import the relevant Keras libraries\n    from keras.models import Sequential\n    from keras.layers import Dense\n    from keras.layers import Dropout\n    from tensorflow import random\n    np.random.seed(seed)\n    random.set_seed(seed)\n    model = Sequential()\n    # Add the hidden dense layers and with dropout Layer\n    model.add(Dense(units=64, activation='relu', \\\n                    kernel_initializer='uniform', \\\n                    input_dim=X_train.shape[1]))\n    model.add(Dropout(rate=0.5))\n    model.add(Dense(units=32, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.4))\n    model.add(Dense(units=16, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.3))\n    model.add(Dense(units=8, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.2))\n    model.add(Dense(units=4, activation='relu', \\\n                    kernel_initializer='uniform'))\n    model.add(Dropout(rate=0.1))\n    # Add Output Dense Layer\n    model.add(Dense(units=1, activation='sigmoid', \\\n                    kernel_initializer='uniform'))\n    # Compile the Model\n    model.compile(optimizer='adam', \\\n                  loss='binary_crossentropy', \\\n                  metrics=['accuracy'])\n    ```", "```py\n    model.fit(X_train, y_train, epochs=100, \\\n              batch_size=20, verbose=1, \\\n              validation_split=0.2, shuffle=False)\n    ```", "```py\n    y_pred = model.predict(X_test)\n    y_pred_prob = model.predict_proba(X_test)\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    y_pred_class1 = y_pred > 0.5\n    cm = confusion_matrix(y_test, y_pred_class1)\n    print(cm)\n    ```", "```py\n    [[11730  58]\n     [   69 143]]\n    ```", "```py\n    # True Negative\n    TN = cm[0,0]\n    # False Negative\n    FN = cm[1,0]\n    # False Positives\n    FP = cm[0,1]\n    # True Positives\n    TP = cm[1,1]\n    ```", "```py\n    # Calculating Sensitivity\n    Sensitivity = TP / (TP + FN)\n    print(f'Sensitivity: {Sensitivity:.4f}')\n    ```", "```py\n    Sensitivity: 0.6745\n    ```", "```py\n    # Calculating Specificity\n    Specificity = TN / (TN + FP)\n    print(f'Specificity: {Specificity:.4f}')\n    ```", "```py\n    Specificity: 0.9951\n    ```", "```py\n    # Precision\n    Precision = TP / (TP + FP)\n    print(f'Precision: {Precision:.4f}')\n    ```", "```py\n    Precision: 0.7114\n    ```", "```py\n    # Calculate False positive rate\n    False_Positive_rate = FP / (FP + TN)\n    print(f'False positive rate: \\\n          {False_Positive_rate:.4f}')\n    ```", "```py\n    False positive rate: 0.0049\n    ```", "```py\n    y_pred_class2 = y_pred > 0.3\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    cm = confusion_matrix(y_test,y_pred_class2)\n    print(cm)\n    ```", "```py\n    [[11700  88]\n     [   58 154]]\n    ```", "```py\n    [[11730  58]\n     [   69 143]]\n    ```", "```py\n    # True Negative\n    TN = cm[0,0]\n    # False Negative\n    FN = cm[1,0]\n    # False Positives\n    FP = cm[0,1]\n    # True Positives\n    TP = cm[1,1]\n    ```", "```py\n    # Calculating Sensitivity\n    Sensitivity = TP / (TP + FN)\n    print(f'Sensitivity: {Sensitivity:.4f}')\n    ```", "```py\n    Sensitivity: 0.7264\n    ```", "```py\n    # Calculating Specificity\n    Specificity = TN / (TN + FP)\n    print(f'Specificity: {Specificity:.4f}')\n    ```", "```py\n    Specificity: 0.9925\n    ```", "```py\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    # histogram of class distribution\n    plt.hist(y_pred_prob, bins=100)\n    plt.title(\"Histogram of Predicted Probabilities\")\n    plt.xlabel(\"Predicted Probabilities of APS failure\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n    ```", "```py\n0.944787151628455\n```"]