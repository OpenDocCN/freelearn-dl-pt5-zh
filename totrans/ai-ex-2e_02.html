<html><head></head><body>
  <div id="_idContainer038">
    <h1 class="chapterNumber">2</h1>
    <h1 id="_idParaDest-31" class="chapterTitle">Building a Reward Matrix – Designing Your Datasets</h1>
    <p class="normal">Experimenting and implementation comprise the two main approaches of artificial intelligence. Experimenting largely entails trying ready-to-use datasets and black box, ready-to-use Python examples. Implementation involves preparing a dataset, developing preprocessing algorithms, and then choosing a model, the proper parameters, and hyperparameters.</p>
    <p class="normal">Implementation usually involves white box work that entails knowing exactly how an algorithm works and even being able to modify it.</p>
    <p class="normal">In <em class="italics">Chapter 1</em>, <em class="italics">Getting Started with Next-Generation Artifcial Intelligence through Reinforcement Learning</em>, the MDP-driven Bellman equation relied on a reward matrix. In this chapter, we will get our hands dirty in a white box process to create that reward matrix.</p>
    <p class="normal">An MDP process cannot run without a reward matrix. The reward matrix determines whether it is possible to go from one cell to another, from A to B. It is like a map of a city that tells you if you are allowed to take a street or if it is a one-way street, for example. It can also set a goal, such as a place that you would like to visit in a city, for example.</p>
    <p class="normal">To achieve the goal of designing a reward matrix, the raw data provided by other systems, software, and sensors needs to go through <strong class="bold">preprocessing</strong>. A machine learning program will not provide efficient results if the data has not gone through a <strong class="bold">standardization</strong> process.</p>
    <p class="normal">The reward matrix, <em class="italics">R</em>, will be built using a McCulloch-Pitts neuron in TensorFlow. Warehouse management has grown exponentially as e-commerce has taken over many marketing segments. This chapter introduces automated guided vehicles (AGVs), the equivalent of an SDC in a warehouse to store and retrieve products.</p>
    <p class="normal">The challenge in this chapter will be to understand the preprocessing phase in detail. The quality of the processed dataset will influence directly the accuracy of any machine learning algorithm.</p>
    <p class="normal">This chapter covers the following topics:</p>
    <ul>
      <li class="list">The McCulloch-Pitts neuron will take the raw data and transform it</li>
      <li class="list">Logistic classifiers will begin the neural network process</li>
      <li class="list">The logistic sigmoid will squash the values</li>
      <li class="list">The softmax function will normalize the values</li>
      <li class="list">The one-hot function will choose the target for the reward matrix</li>
      <li class="list">An example of AGVs in a warehouse</li>
    </ul>
    <p class="normal">The topics form a list of tools that, in turn, form a pipeline that will take raw data and transform it into a reward matrix—an MDP.</p>
    <h1 id="_idParaDest-32" class="title">Designing datasets – where the dream stops and the hard work begins</h1>
    <p class="normal">As in the previous<a id="_idIndexMarker063"/> chapter, bear in mind that a real-life project goes through a three-dimensional method in some form or other. First, it's important to think and talk about the problem in need of solving without jumping onto a laptop. Once that is done, bear in mind that the foundation of machine learning and deep learning relies on mathematics. Finally, once the problem has been discussed and mathematically represented, it is time to develop the solution.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">First, think of a <a id="_idIndexMarker064"/>problem in <strong class="bold">natural language</strong>. Then, make<a id="_idIndexMarker065"/> a <strong class="bold">mathematical description</strong> of a problem. Only then <a id="_idIndexMarker066"/>should you begin the <strong class="bold">software implementation</strong>.</p>
    </div>
    <h2 id="_idParaDest-33" class="title">Designing datasets</h2>
    <p class="normal">The reinforcement<a id="_idIndexMarker067"/> learning program described in the first chapter can solve a variety of problems involving unlabeled classification in an unsupervised decision-making process. The Q function can be applied to drone, truck, or car deliveries. It can also be applied to decision making in games or real life.</p>
    <p class="normal">However, in a real-life case study problem (such as defining the reward matrix in a warehouse for the AGV, for example), the difficulty will be to produce an efficient matrix using the <a id="_idIndexMarker068"/>proper <strong class="bold">features</strong>.</p>
    <p class="normal">For example, an AGV requires information coming from different sources: daily forecasts and real-time warehouse flows.</p>
    <p class="normal">The warehouse manages thousands of locations and hundreds of thousands of inputs and outputs. Trying to fit too many features into the model would be counterproductive. Removing both features and worthless data requires careful consideration.</p>
    <p class="normal">A simple neuron can <a id="_idIndexMarker069"/>provide an efficient way to attain the <strong class="bold">standardization</strong> of<a id="_idIndexMarker070"/> the input data.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Machine learning and deep learning are frequently used to preprocess input data for standardization purposes, normalization, and feature reduction.</p>
    </div>
    <h2 id="_idParaDest-34" class="title">Using the McCulloch-Pitts neuron</h2>
    <p class="normal">To create the<a id="_idIndexMarker071"/> reward matrix, <em class="italics">R</em>, a robust model for processing the inputs of the huge volumes in a warehouse must be reduced to a limited number of features.</p>
    <p class="normal">In one model, for example, the thousands to hundreds of thousands of inputs can be described as follows:</p>
    <ul>
      <li class="list">Forecast product arrivals with a low priority weight: <em class="italics">w</em><sub>1</sub> = 10</li>
      <li class="list">Confirmed arrivals with a high priority weight: <em class="italics">w</em><sub>2</sub> = 70</li>
      <li class="list">Unplanned arrivals decided by the sales department: <em class="italics">w</em><sub>3</sub> = 75</li>
      <li class="list">Forecasts with a high priority weight: <em class="italics">w</em><sub>4</sub> = 60</li>
      <li class="list">Confirmed arrivals that have a low turnover and so have a low weight: <em class="italics">w</em><sub>5</sub> = 20</li>
    </ul>
    <p class="normal">The weights have been provided as constants. A McCulloch-Pitts neuron does not modify weights. A perceptron neuron does as we will see beginning with <em class="italics">Chapter 8</em>, <em class="italics">Solving the XOR Problem with a Feedforward Neural Network</em>. Experience shows that modifying weights is not always necessary.</p>
    <p class="normal">These weights form a vector, as shown here:</p>
    <figure class="mediaobject"><img style="height: 5.75em !important" src="../Images/B15438_02_001.png" alt=""/></figure>
    <p class="normal">Each element <a id="_idIndexMarker072"/>of the vector represents the weight of a feature of a product stored in optimal locations. The ultimate phase of this process will produce a reward matrix, <em class="italics">R</em>, for an MDP to optimize itineraries between warehouse locations.</p>
    <p class="normal">Let's focus on our neuron. These weights, used through a system such as this one, can attain up to more than 50 weights and parameters per neuron. In this example, 5 weights are implemented. However, in real-life case, many other parameters come into consideration, such as unconfirmed arrivals, unconfirmed arrivals with a high priority, confirmed arrivals with a very low priority, arrivals from locations that probably do not meet security standards, arrivals with products that are potentially dangerous and require special care, and more. At that point, humans and even classical software cannot face such a variety of parameters.</p>
    <p class="normal">The reward matrix will be size 6×6. It contains six locations, A to F. In this example, the six locations, <code class="Code-In-Text--PACKT-">l1</code> to <code class="Code-In-Text--PACKT-">l6</code>, are warehouse storage and retrieval locations.</p>
    <p class="normal">A 6×6 reward matrix represents the target of the McCulloch-Pitts layer implemented for the six locations.</p>
    <p class="normal">When experimenting, the reward matrix, <em class="italics">R</em>, can be invented for testing purposes. In real-life implementations, you will have to find a way to build datasets from scratch. The reward matrix becomes the output of the preprocessing phase. The following source code shows the input of the reinforcement learning program used in the first chapter. The goal of this chapter describes how to produce the following reward matrix that we will be building in the next sections.</p>
    <pre class="programlisting"><code class="hljs angelscript"># R <span class="hljs-keyword">is</span> The Reward Matrix <span class="hljs-keyword">for</span> each location <span class="hljs-keyword">in</span> a warehouse (<span class="hljs-keyword">or</span> any other problem)
R = ql.matrix([ [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">100</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>] ])
</code></pre>
    <p class="normal">For the warehouse example that we are using as for any other domain, the McCulloch-Pitts neuron sums up the weights of the input vector described previously to fill in the reward matrix.</p>
    <p class="normal">Each location will require its neuron, with its weights.</p>
    <p class="center"><em class="italics">INPUTS</em> -&gt; <em class="italics">WEIGHTS</em> -&gt; <em class="italics">BIAS</em> -&gt; <em class="italics">VALUES</em></p>
    <ul>
      <li class="list">Inputs are the flows in a warehouse or any form of data.</li>
      <li class="list">Weights will be defined in this model.</li>
      <li class="list">Bias is for <a id="_idIndexMarker073"/>stabilizing the weights. Bias does exactly what it means. It will tilt weights. It is very useful as a referee that will keep the weights on the right track.</li>
      <li class="list">Values will be the output.</li>
    </ul>
    <div class="note">
      <p class="Information-Box--PACKT-">There are as many ways as you can imagine to create reward matrices. This chapter describes one way of doing it that works.</p>
    </div>
    <h2 id="_idParaDest-35" class="title">The McCulloch-Pitts neuron</h2>
    <p class="normal">The <a id="_idIndexMarker074"/>McCulloch-Pitts neuron dates back to 1943. It contains inputs, weights, and an activation function. Part of the preprocessing phase consists of selecting the right model. The McCulloch-Pitts neuron can represent a given location efficiently.</p>
    <p class="normal">The following diagram shows the McCulloch-Pitts neuron model:</p>
    <figure class="mediaobject"><img src="../Images/B15438_02_01.png" alt="https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_01-2.png"/></figure>
    <p class="packt_figref">Figure 2.1: The McCulloch-Pitts neuron model</p>
    <p class="normal">This model contains several input <em class="italics">x</em> weights that are summed to either reach a threshold that will lead, once transformed, to the output, <em class="italics">y </em>= 0, or 1. In this model, <em class="italics">y</em> will be calculated in a more complex way.</p>
    <p class="normal"><code class="Code-In-Text--PACKT-">MCP.py</code> written with TensorFlow 2 will be used to illustrate the neuron.</p>
    <p class="normal">In the following source code, the TensorFlow variables will contain the input values (<code class="Code-In-Text--PACKT-">x</code>), the weights (<code class="Code-In-Text--PACKT-">W</code>), and the bias (<code class="Code-In-Text--PACKT-">b</code>). Variables represent the structure of your graph:</p>
    <pre class="programlisting"><code class="hljs lua"># The variables
x = tf.Variable(<span class="hljs-string">[[0.0,0.0,0.0,0.0,0.0]]</span>, dtype = tf.float32)
W = tf.Variable(<span class="hljs-string">[[0.0],[0.0],[0.0],[0.0],[0.0]]</span>, dtype =
    tf.float32)
b = tf.Variable(<span class="hljs-string">[[0.0]]</span>)
</code></pre>
    <p class="normal">In the original McCulloch-Pitts artificial neuron, the inputs (<em class="italics">x</em>) were multiplied by the following weights:</p>
    <figure class="mediaobject"><img style="height: 4em !important" src="../Images/B15438_02_002.png" alt=""/></figure>
    <p class="normal">The mathematical <a id="_idIndexMarker075"/>function becomes a function with the neuron code triggering a logistic activation function (sigmoid), which will be explained in the second part of the chapter. Bias (<code class="Code-In-Text--PACKT-">b</code>) has been added, which makes this neuron format useful even today, shown as follows:</p>
    <pre class="programlisting"><code class="hljs properties"><span class="hljs-comment"># The Neuron</span>
<span class="hljs-attr">def</span> <span class="hljs-string">neuron(x, W, b):</span>
    <span class="hljs-attr">y1</span>=<span class="hljs-string">np.multiply(x,W)+b</span>
    <span class="hljs-attr">y1</span>=<span class="hljs-string">np.sum(y1)</span>
    <span class="hljs-attr">y</span> = <span class="hljs-string">1 / (1 + np.exp(-y1))</span>
    <span class="hljs-attr">return</span> <span class="hljs-string">y</span>
</code></pre>
    <p class="normal">Before starting a session, the McCulloch-Pitts neuron (1943) needs an operator to set its weights. That is the main difference between the McCulloch-Pitts neuron and the perceptron (1957), which is the model for modern deep learning neurons. The perceptron optimizes its weights through optimizing processes. <em class="italics">Chapter 8</em>, <em class="italics">Solving the XOR Problem with a Feedforward Neural Network</em>, describes why a modern perceptron was required.</p>
    <p class="normal">The weights are now provided, and so are the quantities for each input value, which are stored in the <em class="italics">x</em> vector at <em class="italics">l</em><sub>1</sub>, one of the six locations of this warehouse example:</p>
    <figure class="mediaobject"><img style="height: 5.75em !important" src="../Images/B15438_02_001.png" alt=""/></figure>
    <p class="normal">The weight values<a id="_idIndexMarker076"/> will be divided by 100, to represent percentages in terms of 0 to 1 values of warehouse flows in a given location. The following code deals with the choice of <em class="italics">one</em> location, <em class="italics">l</em><sub>1</sub> <strong class="bold">only</strong>, its values, and parameters:</p>
    <pre class="programlisting"><code class="hljs angelscript"># The data
x_1 = [[<span class="hljs-number">10</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">2.</span>]]
w_t = [[<span class="hljs-number">.1</span>, <span class="hljs-number">.7</span>, <span class="hljs-number">.75</span>, <span class="hljs-number">.60</span>, <span class="hljs-number">.20</span>]]
b_1 = [<span class="hljs-number">1.0</span>]
</code></pre>
    <p class="normal">The neuron function is called, and the weights (<code class="Code-In-Text--PACKT-">w_t</code>) and the quantities (<code class="Code-In-Text--PACKT-">x_1</code>) of the warehouse flow are entered. Bias is set to <code class="Code-In-Text--PACKT-">1</code> in this model. No session needs to be initialized; the neuron function is called:</p>
    <pre class="programlisting"><code class="hljs ini"><span class="hljs-comment"># Computing the value of the neuron</span>
<span class="hljs-attr">value</span>=neuron(x_1,w_t,b_1)
</code></pre>
    <p class="normal">The neuron function <code class="Code-In-Text--PACKT-">neuron</code> will calculate the value of the neuron. The program returns the following value:</p>
    <pre class="programlisting"><code class="hljs angelscript">value <span class="hljs-keyword">for</span> threshold calculation:<span class="hljs-number">0.99999</span>
</code></pre>
    <p class="normal">This value represents the activity of location <em class="italics">l</em><sub>1</sub> at a given date and a given time. This example represents only one of the six locations to compute. For this location, the higher the value, the closer to 1, the higher the probable saturation rate of this area. This means there is little space left to store products at that location. That is why the reinforcement learning program for a warehouse is looking for the <strong class="bold">least loaded</strong> area for a given product in this model.</p>
    <p class="normal">Each location has a probable <strong class="bold">availability</strong>:</p>
    <p class="normal"><em class="italics">A</em> = Availability = 1 – load</p>
    <p class="normal">The probability of a load of a given storage point lies between 0 and 1.</p>
    <p class="normal">High values of availability will be close to 1, and low probabilities will be close to 0, as shown in the following example:</p>
    <pre class="programlisting"><code class="hljs gauss">&gt;&gt;&gt; <span class="hljs-keyword">print</span>(<span class="hljs-string">"Availability of location x:{0:.5f}"</span>.<span class="hljs-keyword">format</span>(
...       <span class="hljs-built_in">round</span>(availability,<span class="hljs-number">5</span>)))
Availability of location x:<span class="hljs-number">0.00001</span>
</code></pre>
    <p class="normal">For example, the load of <em class="italics">l</em><sub>1</sub> has a probable rounded load of 0.99, and its probable <em class="italics">availability</em> is 0.002 maximum. The goal of the AGV is to search and find the closest and most available location to optimize its trajectories. <em class="italics">l</em><sub>1</sub> is not a good candidate at that day and time. <strong class="bold">Load</strong> is a keyword <a id="_idIndexMarker077"/>in production or service activities. The less available resources have the highest load rate.</p>
    <p class="normal">When all six locations' availabilities <a id="_idIndexMarker078"/>have been calculated by the McCulloch-Pitts neuron—each with its respective quantity inputs, weights, and bias—a location vector of the results of this system will be produced. Then, the program needs to be implemented to run all six locations and not just one location through a recursive use of the one neuron model:</p>
    <p class="center"><em class="italics">A</em>(<em class="italics">L</em>) = {<em class="italics">a</em>(<em class="italics">l</em><sub>1</sub>),<em class="italics">a</em>(<em class="italics">l</em><sub>2</sub>),<em class="italics">a</em>(<em class="italics">l</em><sub>3</sub>),<em class="italics">a</em>(<em class="italics">l</em><sub>4</sub>),<em class="italics">a</em>(<em class="italics">l</em><sub>5</sub>),<em class="italics">a</em>(<em class="italics">l</em><sub>6</sub>)}</p>
    <p class="normal">The availability, 1 – <em class="italics">output value of the neuron</em>, constitutes a six-line vector. The following vector, <em class="italics">l</em><sub style="font-style: italic;">v</sub>, will be obtained by running the previous sample code on <strong class="bold">all</strong> six locations.</p>
    <figure class="mediaobject"><img style="height: 6.5em !important" src="../Images/B15438_02_004.png" alt=""/></figure>
    <p class="normal">As shown in the preceding formula, <em class="italics">l</em><sub style="font-style: italic;">v</sub> is the vector containing the value of each location for a given AGV to choose from. The values in the vector represent availability. 0.0002 means little availability; 0.9 means high availability. With this choice, the MDP reinforcement learning program will optimize the AGV's trajectory to get to this specific warehouse location.</p>
    <p class="normal">The <em class="italics">l</em><sub style="font-style: italic;">v</sub> is the result of the weighing function of six potential locations for the AGV. It is also a vector of transformed inputs.</p>
    <h2 id="_idParaDest-36" class="title">The Python-TensorFlow architecture</h2>
    <p class="normal">Implementation of the<a id="_idIndexMarker079"/> McCulloch-Pitts neuron can best be viewed as shown in the following graph:</p>
    <figure class="mediaobject"><img src="../Images/B15438_02_02.png" alt="https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_02-3.png"/></figure>
    <p class="packt_figref">Figure 2.2: Implementation of the McCulloch-Pitts neuron</p>
    <p class="normal">A data flow graph will <a id="_idIndexMarker080"/>also help optimize a program when things go wrong as in classical computing.</p>
    <h1 id="_idParaDest-37" class="title">Logistic activation functions and classifiers</h1>
    <p class="normal">Now that the <a id="_idIndexMarker081"/>value of each location of <em class="italics">L</em> = {<em class="italics">l</em><sub>1</sub>, <em class="italics">l</em><sub>2</sub>, <em class="italics">l</em><sub>3</sub>, <em class="italics">l</em><sub>4</sub>, <em class="italics">l</em><sub>5</sub>, <em class="italics">l</em><sub>6</sub>} contains its availability in a vector, the locations can be sorted from the most available to the least available location. From there, the reward matrix, <em class="italics">R</em>, for the MDP process described in <em class="italics">Chapter 1</em>, <em class="italics">Getting Started with Next-Generation Artifcial Intelligence through Reinforcement Learning</em>, can be built.</p>
    <h2 id="_idParaDest-38" class="title">Overall architecture</h2>
    <p class="normal">At this point, the overall architecture contains two main components:</p>
    <ol>
      <li class="list"><strong class="bold">Chapter 1</strong>: A reinforcement learning program based on the value-action Q function using a reward matrix that will be finalized in this chapter. The reward matrix was provided in the first chapter as an experiment, but in the implementation phase, you'll often have to build it from scratch. It sometimes takes weeks to produce a good reward matrix.</li>
      <li class="list"><strong class="bold">Chapter 2</strong>: Designing a set of 6×1 neurons that represents the flow of products at a given time at six locations. The output is the availability probability from 0 to 1. The highest value indicates the highest availability. The lowest value indicates the lowest availability.</li>
    </ol>
    <p class="normal">At this point, there is some real-life information we can draw from these two main functions through an example:</p>
    <ul>
      <li class="list">An AGV is automatically moving in a warehouse and is waiting to receive its next location to use an MDP, to calculate the optimal trajectory of its mission.</li>
      <li class="list">An AGV is using a reward matrix, <em class="italics">R</em>, that was given during the experimental phase but needed to be designed during the implementation process.</li>
      <li class="list">A system of six neurons, one per location, weighing the real quantities and probable quantities to give an availability vector, <em class="italics">l</em><sub style="font-style: italic;">v</sub>, has been calculated. It is almost ready to provide the necessary reward matrix for the AGV.</li>
    </ul>
    <p class="normal">To calculate the input values of the reward matrix in this reinforcement learning warehouse model, a bridge function between <em class="italics">l</em><sub style="font-style: italic;">v</sub> and the reward matrix, <em class="italics">R</em>, is missing.</p>
    <p class="normal">That bridge function is a logistic classifier based on the outputs of the <em class="italics">n</em> neurons that all perform the same tasks independently or recursively with one neuron.</p>
    <p class="normal">At this point, the system:</p>
    <ul>
      <li class="list">Took corporate data</li>
      <li class="list">Used <em class="italics">n</em> neurons calculated with weights</li>
      <li class="list">Applied an activation function</li>
    </ul>
    <p class="normal">The activation function in this model requires a logistic classifier, a commonly used one.</p>
    <h2 id="_idParaDest-39" class="title">Logistic classifier</h2>
    <p class="normal">The logistic classifier<a id="_idIndexMarker082"/> will be applied to <em class="italics">l</em><sub style="font-style: italic;">v</sub> (the six location values) to find the best location for the AGV. This method can be applied to any other domain. It is based on the output of the six neurons as follows:</p>
    <p class="center"><em class="italics">input</em> × <em class="italics">weight</em> + <em class="italics">bias</em></p>
    <p class="normal">What are logistic functions? The goal of a logistic classifier is to produce a probability distribution from 0 to 1 for each value of the output vector. As you have seen so far, artificial intelligence applications use applied mathematics with probable values, not raw outputs. </p>
    <p class="normal">The main reason is that machine learning/deep learning works best with standardization and normalization for workable homogeneous data distributions. Otherwise, the algorithms will often produce underfitted or overfitted results.</p>
    <p class="normal">In the warehouse model, for example, the AGV needs to choose the best, most probable location, <em class="italics">l</em><sub style="font-style: italic;">i</sub>. Even in a well-organized corporate warehouse, many uncertainties (late arrivals, product defects, or some unplanned problems) reduce the probability of a choice. A probability <a id="_idIndexMarker083"/>represents a value between 0 (low probability) and 1 (high probability). Logistic functions provide the tools to convert all numbers into probabilities between 0 and 1 to <em class="italics">normalize</em> data.</p>
    <h2 id="_idParaDest-40" class="title">Logistic function</h2>
    <p class="normal">The logistic<a id="_idIndexMarker084"/> sigmoid provides one of the best ways to normalize the weight of a given output. The activation function of the neuron will be the logistic sigmoid. The threshold is usually a value above which the neuron has a <em class="italics">y</em> = 1 value; or else it has a <em class="italics">y</em> = 0 value. In this model, the minimum value will be 0.</p>
    <p class="normal">The logistic function is represented as follows:</p>
    <figure class="mediaobject"><img style="height: 2.5em !important" src="../Images/B15438_02_005.png" alt=""/></figure>
    <ul>
      <li class="list"><em class="italics">e</em> represents Euler's number, or 2.71828, the natural logarithm.</li>
      <li class="list"><em class="italics">x</em> is the value to be calculated. In this case, <em class="italics">s</em> is the result of the logistic sigmoid function.</li>
    </ul>
    <p class="normal">The code has been rearranged in the following example to show the reasoning process that produces the output, <code class="Code-In-Text--PACKT-">y</code>, of the neuron:</p>
    <pre class="programlisting"><code class="hljs maxima">    y1=<span class="hljs-built_in">np</span>.multiply(x,W)+b
    y1=<span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(y1)
    <span class="highlight">y = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + <span class="hljs-built_in">np</span>.<span class="hljs-built_in">exp</span>(-y1))</span> #logistic Sigmoid
</code></pre>
    <p class="normal">Thanks to the logistic sigmoid function, the value for the first location in the model comes out squashed between 0 and 1 as 0.99, indicating a high probability that this location will be full.</p>
    <p class="normal">To calculate the availability of the location once the 0.99 value has been taken into account, we subtract the load from the total availability, which is 1, as follows:</p>
    <p class="center">Availability = 1 – probability of being full (value)</p>
    <p class="center">Or</p>
    <p class="center">availability = 1 – value</p>
    <p class="normal">As seen previously, once all locations are calculated in this manner, a final availability vector, <em class="italics">l</em><sub style="font-style: italic;">v</sub>, is obtained.</p>
    <figure class="mediaobject"><img style="height: 6.5em !important" src="../Images/B15438_02_004.png" alt=""/></figure>
    <p class="normal">When analyzing <em class="italics">l</em><sub style="font-style: italic;">v</sub>, a problem has stopped the process. Individually, each line appears to be fine. By applying the logistic sigmoid to each output weight and subtracting it from 1, each location displays a probable availability between 0 and 1. However, the sum of the lines in <em class="italics">l</em><sub style="font-style: italic;">v</sub> exceeds 1. That is not possible. A probability cannot exceed 1. The program needs to fix that.</p>
    <p class="normal">Each line produces a [0, 1] solution, which fits the prerequisite of being a valid probability.</p>
    <p class="normal">In this case, the <a id="_idIndexMarker085"/>vector <em class="italics">l</em><sub style="font-style: italic;">v</sub> contains more than one value and becomes a probability distribution. The sum of <em class="italics">l</em><sub style="font-style: italic;">v</sub> cannot exceed 1 and needs to be normalized.</p>
    <p class="normal">The <em class="italics">softmax</em> function provides an excellent method to normalize <em class="italics">l</em><sub style="font-style: italic;">v</sub>. Softmax is widely used in machine learning and deep learning.</p>
    <p class="normal">Bear in mind that <em class="italics">mathematical tools are not rules</em>. You can adapt them to your problem as much as you wish as long as your solution works.</p>
    <h2 id="_idParaDest-41" class="title">Softmax</h2>
    <p class="normal">The softmax function<a id="_idIndexMarker086"/> appears in many artificial intelligence models to normalize data. Softmax can be used for classification purposes and regression. In our example, we will use it to find an optimized goal for an MDP.</p>
    <p class="normal">In the case of the warehouse example, an AGV needs to make a probable choice between six locations in the <em class="italics">l</em><sub style="font-style: italic;">v</sub> vector. However, the total of the <em class="italics">l</em><sub style="font-style: italic;">v</sub> values exceeds 1. <em class="italics">l</em><sub style="font-style: italic;">v</sub> requires normalization of the softmax function, <em class="italics">S</em>. In the source code, the <em class="italics">l</em><sub style="font-style: italic;">v</sub> vector will be named <code class="Code-In-Text--PACKT-">y</code>.</p>
    <figure class="mediaobject"><img style="height: 3.25em !important" src="../Images/B15438_02_007.png" alt=""/></figure>
    <p class="normal">The following code used is <code class="Code-In-Text--PACKT-">SOFTMAX.py</code>.</p>
    <ol>
      <li class="list"><code class="Code-In-Text--PACKT-">y</code> represents the <em class="italics">l</em><sub style="font-style: italic;">v</sub> vector:
        <pre class="programlisting"><code class="hljs angelscript"># y <span class="hljs-keyword">is</span> the vector of the scores of the lv vector <span class="hljs-keyword">in</span> the warehouse example:
y = [<span class="hljs-number">0.0002</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.9</span>,<span class="hljs-number">0.0001</span>,<span class="hljs-number">0.4</span>,<span class="hljs-number">0.6</span>]
</code></pre>
      </li>
      <li class="list"><img style="height: 0.85em !important; vertical-align: baseline;" src="../Images/B15438_02_008.png" alt=""/> is the <em class="italics">exp</em>(<em class="italics">i</em>) result of each value in <code class="Code-In-Text--PACKT-">y</code> (<em class="italics">l</em><sub style="font-style: italic;">v</sub> in the warehouse example), as follows:
        <pre class="programlisting"><code class="hljs matlab">y_exp = [math.<span class="hljs-built_in">exp</span>(<span class="hljs-built_in">i</span>) <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> in y]
</code></pre>
      </li>
      <li class="list"><img style="height: 2.5em !important" src="../Images/B15438_02_009.png" alt=""/> is the sum of <img style="height: 0.85em !important; vertical-align: baseline;" src="../Images/B15438_02_010.png" alt=""/> as shown in the following code:
        <pre class="programlisting"><code class="hljs ini"><span class="hljs-attr">sum_exp_yi</span> = sum(y_exp)
</code></pre>
      </li>
    </ol>
    <p class="normal">Now, each value of the <a id="_idIndexMarker087"/>vector is normalized by applying the following function:</p>
    <pre class="programlisting"><code class="hljs matlab">softmax = [<span class="hljs-built_in">round</span>(<span class="hljs-built_in">i</span> / sum_exp_yi, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> in y_exp]
</code></pre>
    <figure class="mediaobject"><img style="height: 6.5em !important" src="../Images/B15438_02_011.png" alt=""/></figure>
    <p class="normal">softmax(<em class="italics">l</em><sub style="font-style: italic;">v</sub>) provides a normalized vector with a sum equal to 1, as shown in this compressed version of the code. The vector obtained is often described as containing logits.</p>
    <p class="normal">The following code shows one version of a softmax function:</p>
    <pre class="programlisting"><code class="hljs sas">def sof<span class="hljs-meta">tmax(</span><span class="hljs-meta">x</span>):
    <span class="hljs-meta">return</span> np<span class="hljs-meta">.exp(</span><span class="hljs-meta">x</span>) / np<span class="hljs-meta">.sum(</span>np<span class="hljs-meta">.exp(</span><span class="hljs-meta">x</span>), axis=0)
</code></pre>
    <p class="normal"><em class="italics">l</em><sub style="font-style: italic;">v</sub> is now normalized by softmax(<em class="italics">l</em><sub style="font-style: italic;">v</sub>) as follows.</p>
    <figure class="mediaobject"><img style="height: 6.5em !important" src="../Images/B15438_02_011.png" alt=""/></figure>
    <p class="normal">The last part of the <a id="_idIndexMarker088"/>softmax function requires softmax(<em class="italics">l</em><sub style="font-style: italic;">v</sub>) to be rounded to 0 or 1. The higher the value in softmax(<em class="italics">l</em><sub style="font-style: italic;">v</sub>), the more probable it will be. In clear-cut transformations, the highest value will be close to 1, and the others will be closer to 0. In a decision-making process, the highest value needs to be established as follows:</p>
    <pre class="programlisting"><code class="hljs routeros"><span class="hljs-builtin-name">print</span>(<span class="hljs-string">"7C.
Finding the highest value in the normalized y vector : "</span>,ohot)
</code></pre>
    <p class="normal">The output value is <code class="Code-In-Text--PACKT-">0.273</code> and has been chosen as the most probable location. It is then set to 1, and the other, lower values are set to 0. This is called a one-hot function. This one-hot function is extremely helpful for encoding the data provided. The vector obtained can now be applied to the reward matrix. The value 1 probability will become 100 in the <em class="italics">R</em> reward matrix, as follows:</p>
    <figure class="mediaobject"><img style="height: 6.5em !important" src="../Images/B15438_02_013.png" alt=""/></figure>
    <p class="normal">The <a id="_idIndexMarker089"/>softmax function is now complete. Location <em class="italics">l</em><sub>3</sub> or <strong class="bold">C</strong> is the best solution for the AGV. The probability value is multiplied by 100, and the reward matrix, <em class="italics">R</em>, can now receive the input.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Before continuing, take some time to play around with the values in the source code and run it to become familiar with the softmax function. </p>
    </div>
    <p class="normal">We now have the data for the reward matrix. The best way to understand the mathematical aspect of the project is to draw the result on a piece of paper using the actual warehouse layout from locations <strong class="bold">A</strong> to <strong class="bold">F</strong>.</p>
    <pre class="programlisting"><code class="hljs ini"><span class="hljs-attr">Locations</span>={l1-A, l2-B, l3-C, l4-D, l5-E, l6-F}
</code></pre>
    <p class="normal">Line <strong class="bold">C</strong> of the reward matrix ={0, 0, 100, 0, 0, 0}, where <strong class="bold">C</strong> (the third value) is now the target for the self-driving vehicle, in this case, an AGV in a warehouse.</p>
    <figure class="mediaobject"><img src="../Images/B15438_02_03.png" alt="https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_03-2.png"/></figure>
    <p class="packt_figref">Figure 2.3: Illustration of a warehouse transport problem</p>
    <p class="normal">We obtain the following reward matrix, <em class="italics">R</em>, described in <em class="italics">Chapter 1</em>, <em class="italics">Getting Started with Next-Generation Artificial Intelligence through Reinforcement Learning</em>:</p>
    <table id="table001-2" class="No-Table-Style _idGenTablePara-1">
      <colgroup>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
        <col/>
      </colgroup>
      <tbody>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">State/values</strong>
          </td>
          <td class="No-Table-Style">
            <strong class="heading">A</strong>
          </td>
          <td class="No-Table-Style">
            <strong class="heading">B</strong>
          </td>
          <td class="No-Table-Style">
            <strong class="heading">C</strong>
          </td>
          <td class="No-Table-Style">
            <strong class="heading">D</strong>
          </td>
          <td class="No-Table-Style">
            <strong class="heading">E</strong>
          </td>
          <td class="No-Table-Style">
            <strong class="heading">F</strong>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">A</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">B</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">C</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">100</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">D</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">E</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
        </tr>
        <tr class="No-Table-Style">
          <td class="No-Table-Style">
            <strong class="heading">F</strong>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">1</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
          <td class="No-Table-Style">
            <p class="content">-</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="normal">This reward matrix<a id="_idIndexMarker090"/> is exactly the one used in the Python reinforcement learning program using the Q function from <em class="italics">Chapter 1</em>. The output of this chapter is thus the input of the <em class="italics">R</em> matrix. The 0 values are there for the agent to avoid those values. The 1 values indicate the reachable cells. The 100 in the C×C cell is the result of the softmax output. This program is designed to stay close to probability standards with positive values, as shown in the following <em class="italics">R</em> matrix taken from the <code class="Code-In-Text--PACKT-">mdp01.py</code> of <em class="italics">Chapter 1</em>:</p>
    <pre class="programlisting"><code class="hljs angelscript">R = ql.matrix([ [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">100</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],
                [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>] ])
</code></pre>
    <p class="normal">At this point:</p>
    <ul>
      <li class="list">The output of the functions in this chapter generated a reward matrix, <em class="italics">R</em>, which is the input of the MDP described in <em class="italics">Chapter 1, Getting Started with Next-Generation Artificial Intelligence through Reinforcement Learning</em>.</li>
      <li class="list">The MDP process was set to run for 50,000 episodes in <em class="italics">Chapter 1</em>.</li>
      <li class="list">The output of the MDP has multiple uses, as we saw in this chapter and <em class="italics">Chapter 1</em>.</li>
    </ul>
    <p class="normal">The building blocks are in place to begin evaluating the execution and performances of the reinforcement learning program, as we will see in <em class="italics">Chapter 3</em>, <em class="italics">Machine Intelligence – Evaluation Functions and Numerical Convergence</em>.</p>
    <h1 id="_idParaDest-42" class="title">Summary</h1>
    <p class="normal">Using a McCulloch-Pitts neuron with a logistic activation function in a one-layer network to build a reward matrix for reinforcement learning shows one way to preprocess a dataset.</p>
    <p class="normal">Processing real-life data often requires a generalization of a logistic sigmoid function through a softmax function, and a one-hot function applied to logits to encode the data.</p>
    <p class="normal">Machine learning functions are tools that must be understood to be able to use all or parts of them to solve a problem. With this practical approach to artificial intelligence, a whole world of projects awaits you.</p>
    <p class="normal">This neuronal approach is the parent of the multilayer perceptron that will be introduced starting in <em class="italics">Chapter 8</em>, <em class="italics">Solving the XOR Problem with a Feedforward Neural Network</em>.</p>
    <p class="normal">This chapter went from an experimental black box machine learning and deep learning to white box implementation. Implementation requires a full understanding of machine learning algorithms that often require fine-tuning.</p>
    <p class="normal">However, artificial intelligence goes beyond understanding machine learning algorithms. Machine learning or deep learning require evaluation functions. Performance or results cannot be validated without evaluation functions, as explained in <em class="italics">Chapter 3</em>, <em class="italics">Machine Intelligence – Evaluation Functions and Numerical Convergence</em>.</p>
    <p class="normal">In the next chapter, the evaluation process of machine intelligence will be illustrated by examples that show the limits of human intelligence and the rise of machine power.</p>
    <h1 id="_idParaDest-43" class="title">Questions</h1>
    <ol>
      <li class="list">Raw data can be the input to a neuron and transformed with weights. (Yes | No)</li>
      <li class="list">Does a neuron require a threshold? (Yes | No)</li>
      <li class="list">A logistic sigmoid activation function makes the sum of the weights larger. (Yes | No)</li>
      <li class="list">A McCulloch-Pitts neuron sums the weights of its inputs. (Yes | No)</li>
      <li class="list">A logistic sigmoid function is a log10 operation. (Yes | No)</li>
      <li class="list">A logistic softmax is not necessary if a logistic sigmoid function is applied to a vector. (Yes | No)</li>
      <li class="list">A probability is a value between –1 and 1. (Yes | No)</li>
    </ol>
    <h1 id="_idParaDest-44" class="title">Further reading</h1>
    <ul>
      <li class="list">The original McCulloch-Pitts neuron 1943 paper: <a href="http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf"><span class="url">http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf</span></a></li>
      <li class="list">TensorFlow variables: <a href="https://www.tensorflow.org/beta/guide/variables"><span class="url">https://www.tensorflow.org/beta/guide/variables</span></a></li>
    </ul>
  </div>
</body></html>