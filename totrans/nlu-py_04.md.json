["```py\n $ python --version\n```", "```py\n$ python --version\nPython 3.8.5\n```", "```py\n$ pip --version\n```", "```py\n$ pip 21.3.1 from c:\\<installation dir>\\pip (python 3.9)\n```", "```py\n$ pip install jupyterlab\n```", "```py\n$ jupyter lab\n```", "```py\nimport nltk\nimport string\nfrom nltk import word_tokenize\ntext = \"we'd like to book a flight from boston to London\"\ntokenized_text = word_tokenize(text)\nprint(tokenized_text)\n```", "```py\n['we',\n \"'d\",\n 'like',\n 'to',\n 'book',\n 'a',\n 'flight',\n 'from',\n 'boston',\n 'to',\n'London']\n```", "```py\nfrom nltk.probability import FreqDist\nFreqDist(tokenized_text)\nFreqDist({'to': 2, 'we': 1, \"'d\": 1, 'like': 1, 'book': 1, 'a': 1, 'flight': 1, 'from': 1, 'boston': 1, 'london': 1})\n```", "```py\nnltk.pos_tag(tokenized_text)\n[('we', 'PRP'),\n (\"'d\", 'MD'),\n ('like', 'VB'),\n ('to', 'TO'),\n ('book', 'NN'),\n ('a', 'DT'),\n ('flight', 'NN'),\n ('from', 'IN'),\n ('boston', 'NN'),\n ('to', 'TO'),\n ('london', 'VB')]\n```", "```py\n$ pip install nltk\n```", "```py\n$ pip install --user -U nltk\n```", "```py\nimport spacy\nfrom spacy.lang.en import English\nnlp = spacy.load('en_core_web_sm')\ntext = \"we'd like to book a flight from boston to london\"\ndoc = nlp(text)\nprint ([token.text for token in doc])\n['we', \"'d\", 'like', 'to', 'book', 'a', 'flight', 'from', 'boston', 'to', 'london']\n```", "```py\nfrom collections import Counter\nword_freq = Counter(words)\nprint(word_freq)\nCounter({'to': 2, 'we': 1, \"'d\": 1, 'like': 1, 'book': 1, 'a': 1, 'flight': 1, 'from': 1, 'boston': 1, 'london': 1})\n```", "```py\nfor token in doc:\n    print(token.text, token.pos_)\n```", "```py\nwe PRON\n'd AUX\nlike VERB\nto PART\nbook VERB\na DET\nflight NOUN\nfrom ADP\nboston PROPN\nto ADP\nlondon PROPN\n```", "```py\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\ntext = \"we'd like to book a flight from boston to new york\"\ndoc = nlp(text)\ndisplacy.render(doc,style='ent',jupyter=True,options={'distance':200})\n```", "```py\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp('they get in an accident')\ndisplacy.render(doc,style='dep',jupyter=True,options={'distance':200})\n```", "```py\n$ pip install -U spacy\n```", "```py\n$ pip install tensorflow\n```", "```py\n$ jupyter lab\n```", "```py\n# NLP imports\nimport nltk\nimport spacy\nfrom spacy import displacy\n# general numerical and visualization imports\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport numpy as np\n```", "```py\n#import the training data\nfrom nltk.corpus import movie_reviews\nsents = movie_reviews.sents()\nprint(sents)\n[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]\nIn [5]:\nsample = sents[9]\nprint(sample)\n['they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.']\n```", "```py\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp('they get in an accident')\ndisplacy.render(doc,style='dep',jupyter=True,options={'distance':200})\n```", "```py\nwords = movie_reviews.words()\nword_counts = nltk.FreqDist(word.lower() for word in words if word.isalpha())\ntop_words = word_counts.most_common(25)\nall_fdist = pd.Series(dict(top_words))\n# Setting fig and ax into variables\nfig, ax = plt.subplots(figsize=(10,10))\n# Plot with Seaborn plotting tools\nplt.xticks(rotation = 70)\nplt.title(\"Frequency -- Top 25 Words in the Movie Review Corpus\", fontsize = 30)\nplt.xlabel(\"Words\", fontsize = 30)\nplt.ylabel(\"Frequency\", fontsize = 30)\nall_plot = sns.barplot(x = all_fdist.index, y = all_fdist.values, ax=ax)\nplt.xticks(rotation=60)\nplt.show()\n```", "```py\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(background_color = 'white',\n                      max_words = 25,\n                      relative_scaling = 0,\n                      width = 600,height = 300,\n                      max_font_size = 150,\n                      colormap = 'Dark2',\n                      min_font_size = 10).generate_from_frequencies(all_fdist)\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n```", "```py\nmovie_reviews_sentences = movie_reviews.sents()\ntagged_sentences = nltk.pos_tag_sents(movie_reviews_sentences)\ntotal_counts = {}\nfor sentence in tagged_sentences:\n    counts = Counter(tag for word,tag in sentence)\n    total_counts = Counter(total_counts) + Counter(counts)\nsorted_tag_list = sorted(total_counts.items(), key = lambda x: x[1],reverse = True)\nall_tags = pd.DataFrame(sorted_tag_list)\nmost_common_tags = all_tags.head(18)\n# Setting figure and ax into variables\nfig, ax = plt.subplots(figsize=(15,15))\nall_plot = sns.barplot(x = most_common_tags[0], y = most_common_tags[1], ax = ax)\nplt.xticks(rotation = 70)\nplt.title(\"Part of Speech Frequency  in Movie Review Corpus\", fontsize = 30)\nplt.xlabel(\"Part of Speech\", fontsize = 30)\nplt.ylabel(\"Frequency\", fontsize = 30)\nplt.show()\n```"]