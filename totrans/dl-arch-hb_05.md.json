["```py\n    import torch.nn as nn\n    import torchvision\n    from PIL import Image\n    ```", "```py\n    class ConvAutoencoder(nn.Module):\n      def __init__(self):\n        super(ConvAutoencoder, self).__init__()\n        self.encoder = None\n        self.decoder = None\n      def forward(self, x):\n        bottleneck_feature = self.encoder(x)\n        reconstructed_x = self.decoder(\n          bottleneck_feature\n        )\n        return reconstructed_x\n    ```", "```py\n    self.encoder = nn.Sequential(\n          nn.Conv2d(1, 16, 4),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),\n        nn.Conv2d(16, 4, 4),\n        nn.ReLU(),\n        nn.AvgPool2d(9),\n    )\n    ```", "```py\n    self.decoder = nn.Sequential(\n      nn.ConvTranspose2d(4, 16, 5, stride=2),\n      nn.ReLU(),\n      nn.ConvTranspose2d(16, 4, 5, stride=2),\n      nn.ReLU(),\n      nn.ConvTranspose2d(4, 1, 4, stride=2),\n      nn.Sigmoid(),\n    )\n    ```", "```py\n    class FashionMNISTImageTarget(\n      torchvision.datasets.FashionMNIST\n    ):\n      def __getitem__(self, index):\n       img = self.data[index]\n       img = Image.fromarray(\n         img.numpy(), mode=\"L\"\n       )\n       if self.transform is not None:\n         img = self.transform(img)\n       return img, img\n    ```", "```py\n    def transform_image(image):\n        return torchvision.transforms.ToTensor()(image)\n    ```", "```py\n    train_fashion_mnist_data = FashionMNISTImageTarget(\n      'fashion_mnist/', download=True, train=True,\n      transform=transform_image,\n    )\n    valid_fashion_mnist_data = FashionMNISTImageTarget(\n      'fashion_mnist/', download=True, train=False,\n      transform=transform_image,\n    )\n    loaders = {\n      \"train\": DataLoader(\n        train_fashion_mnist_data, batch_size=32,\n        shuffle=True\n      ),\n      \"valid\": DataLoader(\n        valid_fashion_mnist_data, batch_size=32\n      ),\n    }\n    ```", "```py\n    criterion = nn.MSELoss()\n    ```", "```py\n    runner = dl.SupervisedRunner(\n         input_key=\"features\", output_key=\"scores\", target_key=\"targets\", loss_key=\"loss\"\n    )\n    ```", "```py\n    def train_and_evaluate_mlp(\n      trial_number, net, epochs,\n      load_on_stage_start=False, best_or_last='last',\n      verbose=False\n    ):\n      model = net\n      optimizer = optim.Adam(\n        model.parameters(), lr=0.02\n      )\n      checkpoint_logdir = \"logs/trial_{}_autoencoder\".format(\n    trial_number)\n      runner.train(\n        model=model,\n        criterion=criterion,\n        optimizer=optimizer,\n        loaders=loaders,\n        num_epochs=epochs,\n        callbacks=[\n                dl.CheckpointCallback(\n                    logdir=checkpoint_logdir,\n                    loader_key=\"valid\",\n                    metric_key=\"loss\",\n                    load_on_stage_end='best',\n                )\n        ],\n        logdir=\"./logs\",\n        valid_loader=\"valid\",\n        valid_metric=\"loss\",\n        minimize_valid_metric=True,\n        verbose=verbose,\n      )\n      with open(\n        os.path.join(checkpoint_logdir, '_metrics.json'),\n        'r'\n      ) as f:\n        metrics = json.load(f)\n        if best_or_last == 'last':\n          valid_loss = metrics['last']['_score_']\n        else:\n          valid_loss = metrics['best']['valid']['loss']\n      return valid_loss\n    ```", "```py\n    cnn_autoencoder = ConvAutoencoder()\n    best_valid_loss = train_and_evaluate_mlp(\n        0, cnn_autoencoder, 20, load_on_stage_start=False, best_or_last='last', verbose=True\n    )\n    ```", "```py\n    input_image = valid_fashion_mnist_data[0][0].numpy()\n    predicted_image = cnn_autoencoder(\n      torch.unsqueeze(valid_fashion_mnist_data[0][0], 0)\n    )\n    predicted_image = predicted_image.detach().numpy(\n    ).squeeze(0).squeeze(0)\n    f, axarr = plt.subplots(2,1,  figsize=(5, 5))\n    axarr[0].imshow(predicted_image, cmap='gray')\n    axarr[1].imshow(input_image.squeeze(0), cmap='gray')\n    ```"]