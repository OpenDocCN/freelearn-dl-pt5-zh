["```py\nnp.array([[1,1,0,0,1,1],\n         [1,1,0,1,1,0],\n         [1,1,1,0,0,1],\n         [1,1,0,1,1,0],\n         [1,1,0,0,1,0],\n         [1,1,1,0,1,0]]) \n```", "```py\nclass RBM:\n    def __init__(self, num_visible, num_hidden):\n        self.num_hidden = num_hidden\n        self.num_visible = num_visible \n```", "```py\n np_rng = np.random.RandomState(1234)\n        self.weights = np.asarray(np_rng.uniform(\n            low=-0.1 * np.sqrt(6\\. / (num_hidden + num_visible)),\n            high=0.1 * np.sqrt(6\\. / (num_hidden + num_visible)),\n            size=(num_visible, num_hidden))) \n```", "```py\n self.weights = np.insert(self.weights, 0, 0, axis = 0)\n        self.weights = np.insert(self.weights, 0, 0, axis = 1) \n```", "```py\n def train(self, data, max_epochs, learning_rate): \n```", "```py\n    np.array([[1,1,0,0,1,1],\n              [1,1,0,1,1,0],\n              [1,1,1,0,0,1],\n              [1,1,0,1,1,0],\n              [1,1,0,0,1,0],\n              [1,1,1,0,1,0]]) \n    ```", "```py\n data = np.insert(data, 0, 1, axis = 1) \n```", "```py\n for epoch in range(max_epochs): \n```", "```py\n pos_hidden_activations = np.dot(data, self.weights) \n```", "```py\n pos_hidden_probs = self._logistic(\n                pos_hidden_activations) \n```", "```py\n def _logistic(self, x):\n        return 1.0 / (1 + np.exp(-x)) \n```", "```py\n pos_hidden_probs[:,0] = 1 # Fix the bias unit. \n```", "```py\n pos_hidden_states = pos_hidden_probs >\n                np.random.rand(num_examples, self.num_hidden + 1) \n```", "```py\n pos_associations = np.dot(data.T, pos_hidden_probs) \n```", "```py\n neg_visible_activations = np.dot(pos_hidden_states,\n                self.weights.T)\n            neg_visible_probs = self._logistic(\n                neg_visible_activations)\n            neg_visible_probs[:,0] = 1 # Fix the bias unit \n```", "```py\n neg_hidden_activations = np.dot(neg_visible_probs,\n                self.weights)\n            neg_hidden_probs = self._logistic(\n                neg_hidden_activations)\n            neg_associations = np.dot(neg_visible_probs.T,\n                neg_hidden_probs) \n```", "```py\n self.weights += learning_rate * ((pos_associations -\n                neg_associations)) \n```", "```py\n error = np.sum((data - neg_visible_probs) ** 2) \n```", "```py\n energy=-np.sum(data) - np.sum(neg_hidden_probs)-\n                np.sum(pos_associations * self.weights)\n            z=np.sum(data)+np.sum(neg_hidden_probs)\n            if z>0: energy=np.exp(-energy)/z; \n```", "```py\nEpoch 0: error is 8.936507744240409  Energy: 1586106430052073.0\n...\nEpoch 4999: error is 4.498343290467705  Energy: 2.426792619597097e+46 \n```", "```py\n[[ 0.91393138 -0.06594172 -1.1465728 ]\n[ 3.01088157 1.71400554 0.57620638]\n[ 2.9878015 1.73764972 0.58420333]\n[ 0.96733669 0.09742497 -3.26198615]\n[-1.09339128 -1.21252634 2.19432393]\n[ 0.19740106 0.30175338 2.59991769]\n[ 0.99232358 -0.04781768 -3.00195143]] \n```", "```py\n[[ 0.913269 -0.06843517 -1.13654324]\n[ 3.00969897 1.70999493 0.58441134]\n[ 2.98644016 1.73355337 0.59234319]\n[ 0.953465 0.08329804 -3.26016158]\n[-1.10051951 -1.2227973 2.21361701]\n[ 0.20618461 0.30940653 2.59980058]\n[ 0.98040128 -0.06023325 -3.00127746]] \n```", "```py\n for w in range(7):\n        if(w>0):\n            W=print(F[w-1],\":\",r.weights[w,1]+r.weights[w,2]) \n```", "```py\nlove : 2.25265339223\nhappiness : 2.28398311347\nfamily : -3.16621250031\nhorizons : 0.946830830963\naction : 2.88757989766\nviolence : -3.05188501936\nA value>0 is positive, close to 0 slightly positive\nA value<0 is negative, close to 0 slightly negative \n```", "```py\nimport RBM as rp \n```", "```py\n#Create feature files\nf=open(\"features.tsv\",\"w+\")\nf.close \n```", "```py\ng=(\"viewer_name\"+\"\\t\"+\"primary_emotion\"+\"\\t\"+\"secondary_emotion\"+\n    \"\\n\")\nwith open(\"labels.tsv\", \"w\") as f:\n    f.write(g) \n```", "```py\n#Run the RBM feature detection program over v viewers\nprint(\"RBM start\")\nvn=12001\nc=0\nfor v in range (0,vn):\n    rp.main()\n    c+=1\n    if(c==1000):print(v+1);c=0;\nprint(\"RBM over\") \n```", "```py\n # RBM_launcher option\n    pt=0  #restricted printing(0), printing(1) \n```", "```py\n # Part I Feature extractions from data sources\n    # The titles of 10 movies\n    titles=[\"24H in Kamba\",\"Lost\",\"Cube Adventures\",\n            \"A Holiday\",\"Jonathan Brooks\",\n             \"The Melbourne File\", \"WNC Detectives\",\n             \"Stars\",\"Space L\",\"Zone 77\"] \n```", "```py\n # The feature map of each of the 10 movies. Each line is a movie.\n    # Each column is a feature. There are 6 features: ['love', 'happiness', 'family', 'horizons', 'action', 'violence']\n    # 1= the feature is activated, 0= the feature is not activated\n    movies_feature_map = np.array([[1,1,0,0,1,1],\n                                   [1,1,0,1,1,1],\n                                   [1,0,0,0,0,1],\n                                   [1,1,0,1,1,1],\n                                   [1,0,0,0,1,1],\n                                   [1,1,0,1,1,0],\n                                   [1,0,0,0,0,0],\n                                   [1,1,0,1,1,0],\n                                   [1,1,0,0,0,1],\n                                   [1,0,0,1,1,1],\n                                   [1,1,0,0,1,0],\n                                   [1,1,0,1,1,1],\n                                   [1,1,0,0,1,1]]) \n```", "```py\n #The output matrix is empty before the beginning of the analysis\n    #The program will take the user \"likes\" of 6 out of the 10 movies\n\n    dialog_output = np.array([[0,0,0,0,0,0],\n                              [0,0,0,0,0,0],\n                              [0,0,0,0,0,0],\n                              [0,0,0,0,0,0],\n                              [0,0,0,0,0,0],\n                              [0,0,0,0,0,0]]) \n```", "```py\n #An extraction of viewer's first 6 liked 6 movies out n choices\n    #Hundreds of movies can be added. No dialog is needed since a cloud streaming services stores the movie-likes we click on\n    mc=0   #Number of choices limited to 6 in this example\n    a=\"no\" #default input value if rd==1\n    #for m in range(0,10):\n    if pt==1:print(\"Movie likes:\");\n    while mc<6:\n        m=randint(0,9)# filter a chosen movie or allow (this case) a person can watch and like a movie twice=an indication\n        b=randint(0,1)# a person can like(dislike) a movie the first time and not the second(or more) time\n        if mc<6 and (a==\"yes\" or b==1):\n            if pt==1:print(\"title likes: \",titles[m]);\n            for i in range(0,6):dialog_output[mc,i]=\n                movies_feature_map[m,i];\n            mc+=1\n        if mc>=6:\n            break \n```", "```py\n #The dialog_input is now complete\n    if pt==1:print(\"dialog output\",dialog_output); \n```", "```py\n #dialog_output= the training data\n    training_data=dialog_output\n    r = RBM(num_visible = 6, num_hidden = 2)\n    max_epochs=5000\n    learning_rate=0.001\n    r.train(training_data, max_epochs,learning_rate) \n```", "```py\n###Processing the results\n    # feature labels\n    F=[\"love\",\"happiness\",\"family\",\"horizons\",\"action\",\"violence\"]\n    .../...\n        control=[0,0,0,0,0,0]\n        for j in range(0,6):\n            for i in range(0,6):\n                control[i]+=dialog_output[j][i]\n    ###End of processing the results \n```", "```py\n #Selection of the primary feature\n    for w in range(1,7):\n        if(w>0):\n            if pt==1:print(F[w-1],\":\",r.weights[w,0]);\n            tw=r.weights[w,0]+pos\n            if(tw>best1):\n                f1=w-1\n                best1=tw\n            f.write(str(r.weights[w,0]+pos)+\"\\t\")\n    f.write(\"\\n\")\n    f.close() \n```", "```py\n #secondary feature\n    best2=-1000\n    for w in range(1,7):\n        if(w>0):\n            tw=r.weights[w,0]+pos\n            if(tw>best2 and w-1!=f1):\n                f2=w-1\n                best2=tw \n```", "```py\n #saving the metadata with the labels\n    u=randint(1,10000)\n    vname=\"viewer_\"+str(u)\n    if(pt==1):\n        print(\"Control\",control)\n        print(\"Principal Features: \",vname,f1,f2,\"control\")\n\n    f= open(\"labels.tsv\",\"a\")\n    f.write(vname +\"\\t\"+F[f1]+\"\\t\"+F[f2]+\"\\t\")\n    f.write(\"\\n\")\n    f.close() \n```", "```py\nviewer_name    primary_emotion    secondary_emotion\nviewer_8481    love               violence\nviewer_3568    love               violence\nviewer_8667    love               horizons\nviewer_2730    love               violence\nviewer_3970    love               horizons\nviewer_1140    love               happiness \n```", "```py\n    data1 = [1, 2, 3, 4]\n    M1=statistics.mean(data1)\n    print(\"Mean data1\",M1) \n    ```", "```py\n    data2 = [1, 2, 3, 5]\n    M2=statistics.mean(data2)\n    print(\"Mean data2\",M2) \n    ```", "```py\n#var = mean(abs(x - x.mean())**2).\nprint(\"Variance 1\", np.var(data1))\nprint(\"Variance 2\", np.var(data2)) \n```", "```py\nMean data1 2.5\nMean data2 2.75\nVariance 1 1.25\nVariance 2 2.1875 \n```", "```py\nx=np.array([[1, 2, 3, 4],\n            [1, 2, 3, 5]])\na=np.cov(x)\nprint(a) \n```", "```py\n[[1.66666667 2.16666667]\n [2.16666667 2.91666667]] \n```", "```py\ndot(a,v)=w * v \n```", "```py\nfrom numpy import linalg as LA\nw, v = LA.eigh(a)\nprint(\"eigenvalue(s)\",w) \n```", "```py\neigenvalue(s) [0.03665681 4.54667652] \n```", "```py\nfrom numpy import linalg as LA\nw, v = LA.eigh(a)\nprint(\"eigenvalue(s)\",w)\nprint(\"eigenvector(s)\",v) \n```", "```py\neigenvector(s) [[-0.79911221  0.6011819 ]\n [ 0.6011819   0.79911221]] \n```", "```py\nF=[\"love\",\"happiness\",\"family\",\"horizons\",\"action\",\"violence\"] \n```"]